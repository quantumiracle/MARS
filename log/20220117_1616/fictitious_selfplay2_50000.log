pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fb09766a8d0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.013, 0.013, 0.013, ..., 0.013, 0.013, 0.013]) array([0.013, 0.013, 0.013, ..., 0.013, 0.013, 0.013])]
Load checkpoints (policy family):  [list(['50', '5253', '7615', '8835', '9107', '9703', '11990', '12159', '12524', '13308', '13498', '13724', '14178', '14316', '14615', '15091', '15175', '15419', '15750', '16939', '17375', '17843', '17917', '18353', '18640', '19318', '19446', '19648', '20384', '20683', '20884', '21272', '21672', '22747', '23030', '23310', '24520', '24853', '26681', '26940', '28709', '29740', '29846', '30462', '30651', '30760', '31416', '31603', '32106', '32698', '33332', '33767', '33881', '36744', '37270', '38685', '39143', '41292', '42031', '42615', '42749', '43319', '44780', '45269', '45498', '45743', '45999', '46193', '46771', '46952', '47200', '48030', '48564', '48855', '49288', '49557'])
 list(['193', '5289', '7712', '9011', '9134', '9750', '12072', '12183', '12551', '13372', '13527', '13900', '14248', '14538', '14753', '15114', '15219', '15590', '15822', '16961', '17442', '17874', '17965', '18390', '18710', '19358', '19474', '19725', '20485', '20727', '20925', '21436', '21759', '22805', '23082', '23363', '24633', '24918', '26747', '26990', '28804', '29797', '29890', '30570', '30697', '30815', '31505', '31652', '32168', '32769', '33481', '33828', '33952', '36804', '37326', '38773', '39204', '41367', '42118', '42678', '42883', '43395', '44845', '45356', '45577', '45810', '46067', '46269', '46865', '47038', '47292', '48138', '48748', '49098', '49412'])]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_50000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_50000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_50000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7369s / 6.7369 s
agent0:                 episode reward: -1.6958,                 loss: nan
agent1:                 episode reward: 1.6958,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 5.8223s / 12.5592 s
agent0:                 episode reward: 0.3713,                 loss: nan
agent1:                 episode reward: -0.3713,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2642s / 19.8234 s
agent0:                 episode reward: 0.2612,                 loss: nan
agent1:                 episode reward: -0.2612,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4263s / 26.2497 s
agent0:                 episode reward: -0.0345,                 loss: nan
agent1:                 episode reward: 0.0345,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0533s / 33.3030 s
agent0:                 episode reward: 0.3907,                 loss: nan
agent1:                 episode reward: -0.3907,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8365s / 40.1395 s
agent0:                 episode reward: 0.1053,                 loss: nan
agent1:                 episode reward: -0.1053,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.5534s / 47.6930 s
agent0:                 episode reward: -0.0498,                 loss: nan
agent1:                 episode reward: 0.0498,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6462s / 54.3391 s
agent0:                 episode reward: -0.0256,                 loss: nan
agent1:                 episode reward: 0.0256,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2716s / 61.6107 s
agent0:                 episode reward: 0.1917,                 loss: nan
agent1:                 episode reward: -0.1917,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.4104s / 69.0211 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.4157s / 76.4368 s
agent0:                 episode reward: 0.1159,                 loss: nan
agent1:                 episode reward: -0.1159,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.6248s / 173.0616 s
agent0:                 episode reward: 0.7233,                 loss: nan
agent1:                 episode reward: -0.7233,                 loss: 0.2780
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9368s / 410.9984 s
agent0:                 episode reward: -0.0652,                 loss: nan
agent1:                 episode reward: 0.0652,                 loss: 0.2453
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5737s / 652.5721 s
agent0:                 episode reward: 0.0116,                 loss: nan
agent1:                 episode reward: -0.0116,                 loss: 0.2120
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9743s / 892.5463 s
agent0:                 episode reward: 0.6207,                 loss: nan
agent1:                 episode reward: -0.6207,                 loss: 0.1935
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3498s / 1136.8961 s
agent0:                 episode reward: 0.1325,                 loss: nan
agent1:                 episode reward: -0.1325,                 loss: 0.1841
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3408s / 1382.2369 s
agent0:                 episode reward: 0.1630,                 loss: nan
agent1:                 episode reward: -0.1630,                 loss: 0.1777
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3233s / 1621.5602 s
agent0:                 episode reward: 0.0150,                 loss: nan
agent1:                 episode reward: -0.0150,                 loss: 0.1717
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3615s / 1861.9216 s
agent0:                 episode reward: 0.1488,                 loss: nan
agent1:                 episode reward: -0.1488,                 loss: 0.1692
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3663s / 2103.2879 s
agent0:                 episode reward: 0.3673,                 loss: nan
agent1:                 episode reward: -0.3673,                 loss: 0.1637
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6137s / 2343.9017 s
agent0:                 episode reward: 0.3432,                 loss: nan
agent1:                 episode reward: -0.3432,                 loss: 0.1614
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7567s / 2581.6584 s
agent0:                 episode reward: -0.0044,                 loss: nan
agent1:                 episode reward: 0.0044,                 loss: 0.1590
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3107s / 2830.9690 s
agent0:                 episode reward: -0.1170,                 loss: nan
agent1:                 episode reward: 0.1170,                 loss: 0.1576
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3325s / 3082.3016 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1560
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1713s / 3324.4729 s
agent0:                 episode reward: 0.1300,                 loss: nan
agent1:                 episode reward: -0.1300,                 loss: 0.1546
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1685s / 3571.6413 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.1525
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3007s / 3814.9420 s
agent0:                 episode reward: -0.1083,                 loss: nan
agent1:                 episode reward: 0.1083,                 loss: 0.1510
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3172s / 4065.2593 s
agent0:                 episode reward: -0.2002,                 loss: nan
agent1:                 episode reward: 0.2002,                 loss: 0.1515
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3861s / 4312.6454 s
agent0:                 episode reward: 0.2484,                 loss: nan
agent1:                 episode reward: -0.2484,                 loss: 0.1739
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3086s / 4555.9540 s
agent0:                 episode reward: 0.1041,                 loss: nan
agent1:                 episode reward: -0.1041,                 loss: 0.1606
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4245s / 4798.3785 s
agent0:                 episode reward: -0.2538,                 loss: nan
agent1:                 episode reward: 0.2538,                 loss: 0.1585
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2331s / 5044.6116 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1559
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1361s / 5287.7478 s
agent0:                 episode reward: 0.1007,                 loss: nan
agent1:                 episode reward: -0.1007,                 loss: 0.1537
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2399s / 5531.9877 s
agent0:                 episode reward: 0.0827,                 loss: nan
agent1:                 episode reward: -0.0827,                 loss: 0.1522
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0154s / 5781.0030 s
agent0:                 episode reward: -0.0301,                 loss: nan
agent1:                 episode reward: 0.0301,                 loss: 0.1522
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8140s / 6023.8170 s
agent0:                 episode reward: -0.0674,                 loss: nan
agent1:                 episode reward: 0.0674,                 loss: 0.1501
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7719s / 6274.5890 s
agent0:                 episode reward: -0.1301,                 loss: nan
agent1:                 episode reward: 0.1301,                 loss: 0.1506
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1656s / 6515.7546 s
agent0:                 episode reward: 0.0462,                 loss: nan
agent1:                 episode reward: -0.0462,                 loss: 0.1491
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2214s / 6760.9760 s
agent0:                 episode reward: 0.0394,                 loss: nan
agent1:                 episode reward: -0.0394,                 loss: 0.1494
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8829s / 7017.8589 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1472
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9249s / 7257.7838 s
agent0:                 episode reward: 0.0737,                 loss: nan
agent1:                 episode reward: -0.0737,                 loss: 0.1482
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6342s / 7500.4180 s
agent0:                 episode reward: -0.1379,                 loss: nan
agent1:                 episode reward: 0.1379,                 loss: 0.1482
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6986s / 7747.1166 s
agent0:                 episode reward: 0.3149,                 loss: nan
agent1:                 episode reward: -0.3149,                 loss: 0.1465
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7746s / 7986.8912 s
agent0:                 episode reward: 0.1611,                 loss: nan
agent1:                 episode reward: -0.1611,                 loss: 0.1469
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6369s / 8240.5281 s
agent0:                 episode reward: 0.2574,                 loss: nan
agent1:                 episode reward: -0.2574,                 loss: 0.1487
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0415s / 8486.5696 s
agent0:                 episode reward: -0.0661,                 loss: nan
agent1:                 episode reward: 0.0661,                 loss: 0.1430
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7832s / 8733.3529 s
agent0:                 episode reward: 0.1203,                 loss: nan
agent1:                 episode reward: -0.1203,                 loss: 0.1408
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2013s / 8979.5542 s
agent0:                 episode reward: 0.4076,                 loss: nan
agent1:                 episode reward: -0.4076,                 loss: 0.1395
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2856s / 9229.8398 s
agent0:                 episode reward: -0.3330,                 loss: nan
agent1:                 episode reward: 0.3330,                 loss: 0.1394
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3438s / 9472.1836 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.1395
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0799s / 9715.2635 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.1397
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7170s / 9964.9805 s
agent0:                 episode reward: 0.0905,                 loss: nan
agent1:                 episode reward: -0.0905,                 loss: 0.1389
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7917s / 10214.7722 s
agent0:                 episode reward: 0.0237,                 loss: nan
agent1:                 episode reward: -0.0237,                 loss: 0.1379
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1814s / 10457.9536 s
agent0:                 episode reward: -0.1776,                 loss: nan
agent1:                 episode reward: 0.1776,                 loss: 0.1374
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0211s / 10712.9748 s
agent0:                 episode reward: 0.0415,                 loss: nan
agent1:                 episode reward: -0.0415,                 loss: 0.1386
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6665s / 10955.6413 s
agent0:                 episode reward: -0.0626,                 loss: nan
agent1:                 episode reward: 0.0626,                 loss: 0.1362
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0377s / 11203.6789 s
agent0:                 episode reward: 0.2233,                 loss: nan
agent1:                 episode reward: -0.2233,                 loss: 0.1355
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7208s / 11444.3997 s
agent0:                 episode reward: 0.0832,                 loss: nan
agent1:                 episode reward: -0.0832,                 loss: 0.1350
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8500s / 11697.2497 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.1345
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5811s / 11938.8308 s
agent0:                 episode reward: 0.1333,                 loss: nan
agent1:                 episode reward: -0.1333,                 loss: 0.1337
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8920s / 12187.7228 s
agent0:                 episode reward: 0.0364,                 loss: nan
agent1:                 episode reward: -0.0364,                 loss: 0.1346
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5587s / 12433.2815 s
agent0:                 episode reward: 0.1190,                 loss: nan
agent1:                 episode reward: -0.1190,                 loss: 0.1345
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8211s / 12688.1027 s
agent0:                 episode reward: -0.4605,                 loss: nan
agent1:                 episode reward: 0.4605,                 loss: 0.1354
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1351s / 12933.2378 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: 0.1352
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6239s / 13177.8617 s
agent0:                 episode reward: -0.1044,                 loss: nan
agent1:                 episode reward: 0.1044,                 loss: 0.1345
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9150s / 13423.7767 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1333
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7377s / 13677.5144 s
agent0:                 episode reward: 0.1035,                 loss: nan
agent1:                 episode reward: -0.1035,                 loss: 0.1338
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9051s / 13925.4195 s
agent0:                 episode reward: 0.1519,                 loss: nan
agent1:                 episode reward: -0.1519,                 loss: 0.1326
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7163s / 14178.1358 s
agent0:                 episode reward: -0.0553,                 loss: nan
agent1:                 episode reward: 0.0553,                 loss: 0.1335
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0581s / 14425.1939 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.1342
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7221s / 14680.9160 s
agent0:                 episode reward: 0.2835,                 loss: nan
agent1:                 episode reward: -0.2835,                 loss: 0.1325
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5573s / 14928.4733 s
agent0:                 episode reward: -0.1961,                 loss: nan
agent1:                 episode reward: 0.1961,                 loss: 0.1339
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1962s / 15169.6695 s
agent0:                 episode reward: -0.3610,                 loss: nan
agent1:                 episode reward: 0.3610,                 loss: 0.1336
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1750s / 15408.8445 s
agent0:                 episode reward: 0.1341,                 loss: nan
agent1:                 episode reward: -0.1341,                 loss: 0.1335
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1515s / 15654.9960 s
agent0:                 episode reward: 0.1233,                 loss: nan
agent1:                 episode reward: -0.1233,                 loss: 0.1313
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7700s / 15903.7659 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.1303
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9873s / 16146.7532 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.1321
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3960s / 16399.1492 s
agent0:                 episode reward: 0.1220,                 loss: nan
agent1:                 episode reward: -0.1220,                 loss: 0.1315
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3404s / 16647.4896 s
agent0:                 episode reward: 0.0403,                 loss: nan
agent1:                 episode reward: -0.0403,                 loss: 0.1311
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5749s / 16894.0646 s
agent0:                 episode reward: -0.2919,                 loss: nan
agent1:                 episode reward: 0.2919,                 loss: 0.1308
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4928s / 17143.5573 s
agent0:                 episode reward: -0.1093,                 loss: nan
agent1:                 episode reward: 0.1093,                 loss: 0.1292
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1576s / 17394.7149 s
agent0:                 episode reward: -0.1221,                 loss: nan
agent1:                 episode reward: 0.1221,                 loss: 0.1300
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3178s / 17639.0327 s
agent0:                 episode reward: -0.2428,                 loss: nan
agent1:                 episode reward: 0.2428,                 loss: 0.1297
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2922s / 17885.3249 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: 0.1302
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9501s / 18137.2750 s
agent0:                 episode reward: 0.0333,                 loss: nan
agent1:                 episode reward: -0.0333,                 loss: 0.1306
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8458s / 18384.1208 s
agent0:                 episode reward: -0.3885,                 loss: nan
agent1:                 episode reward: 0.3885,                 loss: 0.1306
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2777s / 18624.3985 s
agent0:                 episode reward: 0.0680,                 loss: nan
agent1:                 episode reward: -0.0680,                 loss: 0.1291
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0961s / 18871.4946 s
agent0:                 episode reward: -0.2605,                 loss: nan
agent1:                 episode reward: 0.2605,                 loss: 0.1302
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8650s / 19119.3596 s
agent0:                 episode reward: -0.4991,                 loss: nan
agent1:                 episode reward: 0.4991,                 loss: 0.1293
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3719s / 19361.7315 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.1290
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8459s / 19611.5774 s
agent0:                 episode reward: -0.1992,                 loss: nan
agent1:                 episode reward: 0.1992,                 loss: 0.1303
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5275s / 19858.1048 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: 0.1303
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9937s / 20101.0986 s
agent0:                 episode reward: 0.1007,                 loss: nan
agent1:                 episode reward: -0.1007,                 loss: 0.1297
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8167s / 20342.9152 s
agent0:                 episode reward: 0.3944,                 loss: nan
agent1:                 episode reward: -0.3944,                 loss: 0.1275
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7024s / 20595.6177 s
agent0:                 episode reward: -0.0245,                 loss: nan
agent1:                 episode reward: 0.0245,                 loss: 0.1291
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8633s / 20852.4810 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.1303
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0067s / 21097.4877 s
agent0:                 episode reward: -0.1833,                 loss: nan
agent1:                 episode reward: 0.1833,                 loss: 0.1308
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2831s / 21343.7708 s
agent0:                 episode reward: -0.1877,                 loss: nan
agent1:                 episode reward: 0.1877,                 loss: 0.1296
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9891s / 21596.7599 s
agent0:                 episode reward: 0.0682,                 loss: nan
agent1:                 episode reward: -0.0682,                 loss: 0.1315
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7412s / 21849.5011 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.1300
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0754s / 22098.5765 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1297
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1828s / 22345.7593 s
agent0:                 episode reward: 0.0361,                 loss: nan
agent1:                 episode reward: -0.0361,                 loss: 0.1293
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5866s / 22594.3459 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.1295
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8346s / 22840.1805 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1290
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2978s / 23086.4783 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.1289
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5344s / 23330.0126 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1294
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8544s / 23575.8670 s
agent0:                 episode reward: -0.1752,                 loss: nan
agent1:                 episode reward: 0.1752,                 loss: 0.1303
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5583s / 23827.4253 s
agent0:                 episode reward: 0.0018,                 loss: nan
agent1:                 episode reward: -0.0018,                 loss: 0.1288
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1341s / 24076.5594 s
agent0:                 episode reward: -0.1446,                 loss: nan
agent1:                 episode reward: 0.1446,                 loss: 0.1282
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5436s / 24320.1030 s
agent0:                 episode reward: -0.1301,                 loss: nan
agent1:                 episode reward: 0.1301,                 loss: 0.1298
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6542s / 24562.7572 s
agent0:                 episode reward: 0.1747,                 loss: nan
agent1:                 episode reward: -0.1747,                 loss: 0.1288
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9260s / 24808.6832 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.1311
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1811s / 25050.8643 s
agent0:                 episode reward: -0.1036,                 loss: nan
agent1:                 episode reward: 0.1036,                 loss: 0.1325
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.9603s / 25286.8247 s
agent0:                 episode reward: -0.1715,                 loss: nan
agent1:                 episode reward: 0.1715,                 loss: 0.1340
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0064s / 25538.8311 s
agent0:                 episode reward: -0.1054,                 loss: nan
agent1:                 episode reward: 0.1054,                 loss: 0.1329
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6574s / 25792.4885 s
agent0:                 episode reward: 0.1448,                 loss: nan
agent1:                 episode reward: -0.1448,                 loss: 0.1317
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8169s / 26046.3054 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.1324
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9635s / 26291.2688 s
agent0:                 episode reward: 0.4167,                 loss: nan
agent1:                 episode reward: -0.4167,                 loss: 0.1300
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8967s / 26546.1656 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.1309
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6779s / 26790.8434 s
agent0:                 episode reward: 0.4252,                 loss: nan
agent1:                 episode reward: -0.4252,                 loss: 0.1317
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8852s / 27038.7286 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1317
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3991s / 27295.1277 s
agent0:                 episode reward: -0.0246,                 loss: nan
agent1:                 episode reward: 0.0246,                 loss: 0.1334
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3341s / 27549.4618 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.1321
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6896s / 27796.1513 s
agent0:                 episode reward: -0.0002,                 loss: nan
agent1:                 episode reward: 0.0002,                 loss: 0.1323
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4407s / 28050.5920 s
agent0:                 episode reward: -0.3830,                 loss: nan
agent1:                 episode reward: 0.3830,                 loss: 0.1328
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0651s / 28305.6572 s
agent0:                 episode reward: -0.3311,                 loss: nan
agent1:                 episode reward: 0.3311,                 loss: 0.1319
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5008s / 28553.1580 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: 0.1334
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1570s / 28794.3150 s
agent0:                 episode reward: -0.2147,                 loss: nan
agent1:                 episode reward: 0.2147,                 loss: 0.1319
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4407s / 29034.7557 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.1293
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2217s / 29287.9775 s
agent0:                 episode reward: -0.1151,                 loss: nan
agent1:                 episode reward: 0.1151,                 loss: 0.1273
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5450s / 29536.5224 s
agent0:                 episode reward: 0.0163,                 loss: nan
agent1:                 episode reward: -0.0163,                 loss: 0.1287
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9072s / 29789.4296 s
agent0:                 episode reward: -0.0465,                 loss: nan
agent1:                 episode reward: 0.0465,                 loss: 0.1282
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7223s / 30038.1519 s
agent0:                 episode reward: -0.0384,                 loss: nan
agent1:                 episode reward: 0.0384,                 loss: 0.1276
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8644s / 30290.0162 s
agent0:                 episode reward: -0.1966,                 loss: nan
agent1:                 episode reward: 0.1966,                 loss: 0.1278
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9047s / 30543.9210 s
agent0:                 episode reward: -0.0510,                 loss: nan
agent1:                 episode reward: 0.0510,                 loss: 0.1272
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4089s / 30798.3298 s
agent0:                 episode reward: -0.0133,                 loss: nan
agent1:                 episode reward: 0.0133,                 loss: 0.1266
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8349s / 31049.1647 s
agent0:                 episode reward: -0.1835,                 loss: nan
agent1:                 episode reward: 0.1835,                 loss: 0.1276
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4846s / 31301.6493 s
agent0:                 episode reward: -0.3755,                 loss: nan
agent1:                 episode reward: 0.3755,                 loss: 0.1271
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4386s / 31551.0879 s
agent0:                 episode reward: -0.4472,                 loss: nan
agent1:                 episode reward: 0.4472,                 loss: 0.1272
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2483s / 31796.3362 s
agent0:                 episode reward: 0.2760,                 loss: nan
agent1:                 episode reward: -0.2760,                 loss: 0.1280
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2073s / 32051.5435 s
agent0:                 episode reward: -0.1263,                 loss: nan
agent1:                 episode reward: 0.1263,                 loss: 0.1279
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0401s / 32305.5836 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.1269
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1053s / 32556.6890 s
agent0:                 episode reward: 0.0450,                 loss: nan
agent1:                 episode reward: -0.0450,                 loss: 0.1283
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5794s / 32799.2684 s
agent0:                 episode reward: 0.0053,                 loss: nan
agent1:                 episode reward: -0.0053,                 loss: 0.1269
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7631s / 33050.0315 s
agent0:                 episode reward: -0.3332,                 loss: nan
agent1:                 episode reward: 0.3332,                 loss: 0.1268
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7583s / 33300.7898 s
agent0:                 episode reward: -0.1489,                 loss: nan
agent1:                 episode reward: 0.1489,                 loss: 0.1304
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0546s / 33550.8444 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.1305
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9615s / 33793.8059 s
agent0:                 episode reward: -0.0802,                 loss: nan
agent1:                 episode reward: 0.0802,                 loss: 0.1295
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2553s / 34047.0612 s
agent0:                 episode reward: -0.0857,                 loss: nan
agent1:                 episode reward: 0.0857,                 loss: 0.1313
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9844s / 34293.0456 s
agent0:                 episode reward: -0.4474,                 loss: nan
agent1:                 episode reward: 0.4474,                 loss: 0.1304
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.3512s / 34552.3968 s
agent0:                 episode reward: -0.0186,                 loss: nan
agent1:                 episode reward: 0.0186,                 loss: 0.1316
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3923s / 34796.7891 s
agent0:                 episode reward: 0.0347,                 loss: nan
agent1:                 episode reward: -0.0347,                 loss: 0.1309
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6421s / 35040.4312 s
agent0:                 episode reward: 0.1023,                 loss: nan
agent1:                 episode reward: -0.1023,                 loss: 0.1309
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1287s / 35288.5599 s
agent0:                 episode reward: -0.2213,                 loss: nan
agent1:                 episode reward: 0.2213,                 loss: 0.1316
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5603s / 35533.1202 s
agent0:                 episode reward: -0.2813,                 loss: nan
agent1:                 episode reward: 0.2813,                 loss: 0.1294
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8718s / 35775.9920 s
agent0:                 episode reward: -0.4954,                 loss: nan
agent1:                 episode reward: 0.4954,                 loss: 0.1306
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8795s / 36021.8714 s
agent0:                 episode reward: -0.2003,                 loss: nan
agent1:                 episode reward: 0.2003,                 loss: 0.1286
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1882s / 36270.0597 s
agent0:                 episode reward: 0.0159,                 loss: nan
agent1:                 episode reward: -0.0159,                 loss: 0.1292
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3205s / 36525.3802 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: 0.1291
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8821s / 36781.2623 s
agent0:                 episode reward: 0.1445,                 loss: nan
agent1:                 episode reward: -0.1445,                 loss: 0.1305
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7265s / 37029.9888 s
agent0:                 episode reward: -0.0299,                 loss: nan
agent1:                 episode reward: 0.0299,                 loss: 0.1286
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8779s / 37273.8667 s
agent0:                 episode reward: 0.0266,                 loss: nan
agent1:                 episode reward: -0.0266,                 loss: 0.1278
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6678s / 37515.5345 s
agent0:                 episode reward: -0.2032,                 loss: nan
agent1:                 episode reward: 0.2032,                 loss: 0.1268
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4615s / 37766.9960 s
agent0:                 episode reward: -0.1952,                 loss: nan
agent1:                 episode reward: 0.1952,                 loss: 0.1260
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8083s / 38017.8043 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.1255
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1197s / 38258.9240 s
agent0:                 episode reward: -0.2488,                 loss: nan
agent1:                 episode reward: 0.2488,                 loss: 0.1271
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1743s / 38513.0983 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.1265
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1582s / 38754.2565 s
agent0:                 episode reward: -0.2050,                 loss: nan
agent1:                 episode reward: 0.2050,                 loss: 0.1265
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3113s / 39009.5679 s
agent0:                 episode reward: 0.1267,                 loss: nan
agent1:                 episode reward: -0.1267,                 loss: 0.1256
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9200s / 39263.4879 s
agent0:                 episode reward: -0.4958,                 loss: nan
agent1:                 episode reward: 0.4958,                 loss: 0.1271
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 262.8943s / 39526.3821 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.1278
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1562s / 39764.5384 s
agent0:                 episode reward: -0.0057,                 loss: nan
agent1:                 episode reward: 0.0057,                 loss: 0.1261
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5588s / 40007.0972 s
agent0:                 episode reward: -0.3734,                 loss: nan
agent1:                 episode reward: 0.3734,                 loss: 0.1259
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2618s / 40256.3590 s
agent0:                 episode reward: 0.1390,                 loss: nan
agent1:                 episode reward: -0.1390,                 loss: 0.1255
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2234s / 40508.5823 s
agent0:                 episode reward: -0.1401,                 loss: nan
agent1:                 episode reward: 0.1401,                 loss: 0.1254
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1013s / 40762.6837 s
agent0:                 episode reward: 0.0849,                 loss: nan
agent1:                 episode reward: -0.0849,                 loss: 0.1263
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.0152s / 40999.6989 s
agent0:                 episode reward: -0.0379,                 loss: nan
agent1:                 episode reward: 0.0379,                 loss: 0.1276
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8362s / 41253.5350 s
agent0:                 episode reward: -0.1762,                 loss: nan
agent1:                 episode reward: 0.1762,                 loss: 0.1270
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1407s / 41498.6758 s
agent0:                 episode reward: 0.0316,                 loss: nan
agent1:                 episode reward: -0.0316,                 loss: 0.1259
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5542s / 41745.2299 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: 0.1275
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7139s / 42000.9438 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: 0.1266
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8686s / 42253.8124 s
agent0:                 episode reward: -0.2104,                 loss: nan
agent1:                 episode reward: 0.2104,                 loss: 0.1265
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0750s / 42500.8874 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1275
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1485s / 42748.0359 s
agent0:                 episode reward: 0.0691,                 loss: nan
agent1:                 episode reward: -0.0691,                 loss: 0.1255
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5660s / 42994.6019 s
agent0:                 episode reward: -0.0779,                 loss: nan
agent1:                 episode reward: 0.0779,                 loss: 0.1276
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5530s / 43247.1548 s
agent0:                 episode reward: -0.1690,                 loss: nan
agent1:                 episode reward: 0.1690,                 loss: 0.1264
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3420s / 43495.4969 s
agent0:                 episode reward: -0.0363,                 loss: nan
agent1:                 episode reward: 0.0363,                 loss: 0.1253
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 264.3843s / 43759.8812 s
agent0:                 episode reward: -0.1054,                 loss: nan
agent1:                 episode reward: 0.1054,                 loss: 0.1271
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0286s / 44001.9098 s
agent0:                 episode reward: -0.0995,                 loss: nan
agent1:                 episode reward: 0.0995,                 loss: 0.1247
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6175s / 44250.5273 s
agent0:                 episode reward: -0.1354,                 loss: nan
agent1:                 episode reward: 0.1354,                 loss: 0.1238
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4885s / 44504.0158 s
agent0:                 episode reward: -0.3092,                 loss: nan
agent1:                 episode reward: 0.3092,                 loss: 0.1257
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7497s / 44753.7655 s
agent0:                 episode reward: -0.1649,                 loss: nan
agent1:                 episode reward: 0.1649,                 loss: 0.1250
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0191s / 45004.7846 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.1249
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0850s / 45253.8696 s
agent0:                 episode reward: -0.4595,                 loss: nan
agent1:                 episode reward: 0.4595,                 loss: 0.1266
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4318s / 45497.3014 s
agent0:                 episode reward: -0.0859,                 loss: nan
agent1:                 episode reward: 0.0859,                 loss: 0.1261
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8777s / 45737.1791 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.1240
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9973s / 45987.1764 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.1242
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9019s / 46235.0783 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: 0.1227
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3853s / 46480.4636 s
agent0:                 episode reward: -0.3292,                 loss: nan
agent1:                 episode reward: 0.3292,                 loss: 0.1253
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7339s / 46725.1975 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.1244
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2066s / 46978.4041 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.1243
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8566s / 47224.2607 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.1241
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8573s / 47472.1180 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.1238
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4145s / 47723.5325 s
agent0:                 episode reward: -0.0110,                 loss: nan
agent1:                 episode reward: 0.0110,                 loss: 0.1236
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3842s / 47971.9168 s
agent0:                 episode reward: -0.3404,                 loss: nan
agent1:                 episode reward: 0.3404,                 loss: 0.1229
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0837s / 48214.0004 s
agent0:                 episode reward: -0.4726,                 loss: nan
agent1:                 episode reward: 0.4726,                 loss: 0.1231
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9666s / 48467.9670 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.1228
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3642s / 48715.3312 s
agent0:                 episode reward: 0.0152,                 loss: nan
agent1:                 episode reward: -0.0152,                 loss: 0.1239
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3076s / 48971.6388 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1232
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0688s / 49215.7076 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.1238
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9245s / 49463.6320 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: 0.1222
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8940s / 49719.5261 s
agent0:                 episode reward: -0.4623,                 loss: nan
agent1:                 episode reward: 0.4623,                 loss: 0.1222
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7867s / 49969.3128 s
agent0:                 episode reward: -0.1223,                 loss: nan
agent1:                 episode reward: 0.1223,                 loss: 0.1239
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4656s / 50211.7784 s
agent0:                 episode reward: -0.5488,                 loss: nan
agent1:                 episode reward: 0.5488,                 loss: 0.1240
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9755s / 50462.7540 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.1229
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5320s / 50709.2860 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.1244
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9420s / 50952.2279 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.1247
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6316s / 51199.8595 s
agent0:                 episode reward: 0.0234,                 loss: nan
agent1:                 episode reward: -0.0234,                 loss: 0.1241
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6963s / 51449.5559 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1243
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5355s / 51701.0914 s
agent0:                 episode reward: -0.1224,                 loss: nan
agent1:                 episode reward: 0.1224,                 loss: 0.1241
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0273s / 51944.1186 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1238
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2974s / 52190.4161 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.1243
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2967s / 52436.7128 s
agent0:                 episode reward: -0.1022,                 loss: nan
agent1:                 episode reward: 0.1022,                 loss: 0.1241
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9610s / 52689.6738 s
agent0:                 episode reward: -0.0183,                 loss: nan
agent1:                 episode reward: 0.0183,                 loss: 0.1234
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5883s / 52935.2620 s
agent0:                 episode reward: -0.2607,                 loss: nan
agent1:                 episode reward: 0.2607,                 loss: 0.1226
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1403s / 53186.4024 s
agent0:                 episode reward: -0.1301,                 loss: nan
agent1:                 episode reward: 0.1301,                 loss: 0.1243
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9748s / 53431.3771 s
agent0:                 episode reward: 0.1600,                 loss: nan
agent1:                 episode reward: -0.1600,                 loss: 0.1232
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9218s / 53678.2990 s
agent0:                 episode reward: -0.1150,                 loss: nan
agent1:                 episode reward: 0.1150,                 loss: 0.1222
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0509s / 53932.3498 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.1277
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9483s / 54183.2982 s
agent0:                 episode reward: -0.1382,                 loss: nan
agent1:                 episode reward: 0.1382,                 loss: 0.1280
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.6525s / 54441.9507 s
agent0:                 episode reward: -0.7468,                 loss: nan
agent1:                 episode reward: 0.7468,                 loss: 0.1267
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4764s / 54695.4271 s
agent0:                 episode reward: -0.0720,                 loss: nan
agent1:                 episode reward: 0.0720,                 loss: 0.1280
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.2390s / 54951.6661 s
agent0:                 episode reward: -0.1274,                 loss: nan
agent1:                 episode reward: 0.1274,                 loss: 0.1276
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8070s / 55198.4731 s
agent0:                 episode reward: -0.1084,                 loss: nan
agent1:                 episode reward: 0.1084,                 loss: 0.1266
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.7547s / 55457.2278 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1273
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1719s / 55712.3997 s
agent0:                 episode reward: -0.0442,                 loss: nan
agent1:                 episode reward: 0.0442,                 loss: 0.1264
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 261.8047s / 55974.2044 s
agent0:                 episode reward: -0.5886,                 loss: nan
agent1:                 episode reward: 0.5886,                 loss: 0.1268
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5961s / 56225.8004 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.1269
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1952s / 56473.9957 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.1280
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5273s / 56724.5230 s
agent0:                 episode reward: -0.0405,                 loss: nan
agent1:                 episode reward: 0.0405,                 loss: 0.1265
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7440s / 56971.2670 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.1261
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5209s / 57224.7880 s
agent0:                 episode reward: -0.2583,                 loss: nan
agent1:                 episode reward: 0.2583,                 loss: 0.1250
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2897s / 57472.0776 s
agent0:                 episode reward: -0.4151,                 loss: nan
agent1:                 episode reward: 0.4151,                 loss: 0.1273
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.7685s / 57728.8461 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: 0.1266
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8827s / 57976.7288 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.1276
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5992s / 58234.3280 s
agent0:                 episode reward: -0.1502,                 loss: nan
agent1:                 episode reward: 0.1502,                 loss: 0.1242
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7070s / 58472.0350 s
agent0:                 episode reward: -0.1826,                 loss: nan
agent1:                 episode reward: 0.1826,                 loss: 0.1221
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9220s / 58724.9570 s
agent0:                 episode reward: -0.0770,                 loss: nan
agent1:                 episode reward: 0.0770,                 loss: 0.1218
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7415s / 58975.6985 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.1231
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7179s / 59228.4164 s
agent0:                 episode reward: -0.3970,                 loss: nan
agent1:                 episode reward: 0.3970,                 loss: 0.1245
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9174s / 59480.3338 s
agent0:                 episode reward: -0.4686,                 loss: nan
agent1:                 episode reward: 0.4686,                 loss: 0.1230
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1348s / 59737.4687 s
agent0:                 episode reward: -0.2487,                 loss: nan
agent1:                 episode reward: 0.2487,                 loss: 0.1233
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1266s / 59988.5952 s
agent0:                 episode reward: -0.3308,                 loss: nan
agent1:                 episode reward: 0.3308,                 loss: 0.1232
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7690s / 60243.3642 s
agent0:                 episode reward: -0.0690,                 loss: nan
agent1:                 episode reward: 0.0690,                 loss: 0.1228
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4420s / 60485.8062 s
agent0:                 episode reward: -0.1501,                 loss: nan
agent1:                 episode reward: 0.1501,                 loss: 0.1230
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4124s / 60738.2186 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: 0.1221
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4352s / 60985.6538 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.1224
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8288s / 61233.4826 s
agent0:                 episode reward: -0.2593,                 loss: nan
agent1:                 episode reward: 0.2593,                 loss: 0.1228
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4571s / 61474.9396 s
agent0:                 episode reward: -0.1488,                 loss: nan
agent1:                 episode reward: 0.1488,                 loss: 0.1228
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7956s / 61725.7352 s
agent0:                 episode reward: -0.3266,                 loss: nan
agent1:                 episode reward: 0.3266,                 loss: 0.1222
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5695s / 61971.3048 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1219
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3276s / 62224.6324 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.1235
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0523s / 62471.6847 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1249
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0826s / 62722.7673 s
agent0:                 episode reward: -0.4076,                 loss: nan
agent1:                 episode reward: 0.4076,                 loss: 0.1262
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7932s / 62977.5605 s
agent0:                 episode reward: -0.5205,                 loss: nan
agent1:                 episode reward: 0.5205,                 loss: 0.1258
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3460s / 63227.9065 s
agent0:                 episode reward: -0.1891,                 loss: nan
agent1:                 episode reward: 0.1891,                 loss: 0.1258
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4857s / 63482.3922 s
agent0:                 episode reward: 0.2059,                 loss: nan
agent1:                 episode reward: -0.2059,                 loss: 0.1266
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1795s / 63728.5717 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.1250
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5145s / 63972.0862 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.1255
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1147s / 64215.2008 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.1249
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7115s / 64466.9124 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.1247
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9645s / 64715.8768 s
agent0:                 episode reward: -0.2385,                 loss: nan
agent1:                 episode reward: 0.2385,                 loss: 0.1260
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3458s / 64965.2226 s
agent0:                 episode reward: 0.0023,                 loss: nan
agent1:                 episode reward: -0.0023,                 loss: 0.1255
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1844s / 65211.4070 s
agent0:                 episode reward: -0.5978,                 loss: nan
agent1:                 episode reward: 0.5978,                 loss: 0.1270
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8696s / 65458.2766 s
agent0:                 episode reward: -0.0688,                 loss: nan
agent1:                 episode reward: 0.0688,                 loss: 0.1276
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3075s / 65708.5842 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.1257
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7648s / 65955.3490 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.1270
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0950s / 66207.4440 s
agent0:                 episode reward: -0.4542,                 loss: nan
agent1:                 episode reward: 0.4542,                 loss: 0.1252
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1756s / 66455.6196 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.1229
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4909s / 66705.1105 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.1223
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3711s / 66958.4816 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.1233
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2066s / 67210.6882 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.1225
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1642s / 67459.8524 s
agent0:                 episode reward: -0.6209,                 loss: nan
agent1:                 episode reward: 0.6209,                 loss: 0.1237
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4892s / 67710.3416 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.1229
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9864s / 67958.3280 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.1239
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0439s / 68205.3719 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.1231
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9425s / 68443.3144 s
agent0:                 episode reward: -0.3664,                 loss: nan
agent1:                 episode reward: 0.3664,                 loss: 0.1237
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8546s / 68698.1690 s
agent0:                 episode reward: -0.0494,                 loss: nan
agent1:                 episode reward: 0.0494,                 loss: 0.1229
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6806s / 68949.8496 s
agent0:                 episode reward: -0.2614,                 loss: nan
agent1:                 episode reward: 0.2614,                 loss: 0.1228
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1538s / 69200.0034 s
agent0:                 episode reward: -0.4264,                 loss: nan
agent1:                 episode reward: 0.4264,                 loss: 0.1229
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4220s / 69450.4254 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1231
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9557s / 69693.3811 s
agent0:                 episode reward: -0.1373,                 loss: nan
agent1:                 episode reward: 0.1373,                 loss: 0.1237
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3125s / 69945.6936 s
agent0:                 episode reward: -0.6326,                 loss: nan
agent1:                 episode reward: 0.6326,                 loss: 0.1225
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2512s / 70196.9449 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.1224
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3147s / 70446.2596 s
agent0:                 episode reward: -0.1390,                 loss: nan
agent1:                 episode reward: 0.1390,                 loss: 0.1228
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3960s / 70684.6556 s
agent0:                 episode reward: -0.2404,                 loss: nan
agent1:                 episode reward: 0.2404,                 loss: 0.1227
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6083s / 70936.2639 s
agent0:                 episode reward: -0.5227,                 loss: nan
agent1:                 episode reward: 0.5227,                 loss: 0.1238
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6146s / 71183.8785 s
agent0:                 episode reward: -0.1328,                 loss: nan
agent1:                 episode reward: 0.1328,                 loss: 0.1235
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4809s / 71433.3594 s
agent0:                 episode reward: -0.3155,                 loss: nan
agent1:                 episode reward: 0.3155,                 loss: 0.1238
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5312s / 71682.8905 s
agent0:                 episode reward: -0.2640,                 loss: nan
agent1:                 episode reward: 0.2640,                 loss: 0.1232
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8351s / 71925.7256 s
agent0:                 episode reward: 0.2262,                 loss: nan
agent1:                 episode reward: -0.2262,                 loss: 0.1229
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6517s / 72178.3773 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.1232
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3712s / 72425.7485 s
agent0:                 episode reward: -0.1640,                 loss: nan
agent1:                 episode reward: 0.1640,                 loss: 0.1232
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0084s / 72668.7569 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.1236
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5458s / 72923.3027 s
agent0:                 episode reward: -0.4883,                 loss: nan
agent1:                 episode reward: 0.4883,                 loss: 0.1240
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1373s / 73165.4401 s
agent0:                 episode reward: -0.2491,                 loss: nan
agent1:                 episode reward: 0.2491,                 loss: 0.1233
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9604s / 73410.4005 s
agent0:                 episode reward: -0.3461,                 loss: nan
agent1:                 episode reward: 0.3461,                 loss: 0.1228
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0395s / 73650.4400 s
agent0:                 episode reward: -0.7215,                 loss: nan
agent1:                 episode reward: 0.7215,                 loss: 0.1229
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3312s / 73902.7713 s
agent0:                 episode reward: -0.3041,                 loss: nan
agent1:                 episode reward: 0.3041,                 loss: 0.1232
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5810s / 74150.3523 s
agent0:                 episode reward: -0.0922,                 loss: nan
agent1:                 episode reward: 0.0922,                 loss: 0.1236
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1928s / 74401.5451 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: 0.1218
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.9882s / 74660.5332 s
agent0:                 episode reward: -0.4731,                 loss: nan
agent1:                 episode reward: 0.4731,                 loss: 0.1234
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.5759s / 74917.1091 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: 0.1239
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4982s / 75161.6073 s
agent0:                 episode reward: -0.1200,                 loss: nan
agent1:                 episode reward: 0.1200,                 loss: 0.1219
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5300s / 75398.1373 s
agent0:                 episode reward: -0.0927,                 loss: nan
agent1:                 episode reward: 0.0927,                 loss: 0.1231
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6109s / 75651.7482 s
agent0:                 episode reward: -0.4384,                 loss: nan
agent1:                 episode reward: 0.4384,                 loss: 0.1225
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.7275s / 75909.4757 s
agent0:                 episode reward: -0.0864,                 loss: nan
agent1:                 episode reward: 0.0864,                 loss: 0.1237
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9604s / 76160.4361 s
agent0:                 episode reward: -0.1035,                 loss: nan
agent1:                 episode reward: 0.1035,                 loss: 0.1244
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3921s / 76399.8281 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.1218
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 260.1703s / 76659.9985 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.1215
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9620s / 76910.9604 s
agent0:                 episode reward: 0.0232,                 loss: nan
agent1:                 episode reward: -0.0232,                 loss: 0.1227
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3100s / 77160.2704 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.1213
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5784s / 77410.8488 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.1229
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2070s / 77658.0558 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: 0.1235
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8843s / 77910.9401 s
agent0:                 episode reward: -0.3526,                 loss: nan
agent1:                 episode reward: 0.3526,                 loss: 0.1224
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6181s / 78162.5582 s
agent0:                 episode reward: -0.1774,                 loss: nan
agent1:                 episode reward: 0.1774,                 loss: 0.1227
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1587s / 78413.7169 s
agent0:                 episode reward: -0.3763,                 loss: nan
agent1:                 episode reward: 0.3763,                 loss: 0.1224
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2353s / 78666.9523 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.1233
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8399s / 78911.7921 s
agent0:                 episode reward: -0.6025,                 loss: nan
agent1:                 episode reward: 0.6025,                 loss: 0.1219
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4538s / 79160.2459 s
agent0:                 episode reward: -0.5101,                 loss: nan
agent1:                 episode reward: 0.5101,                 loss: 0.1222
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9449s / 79411.1908 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1223
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7239s / 79658.9147 s
agent0:                 episode reward: -0.3620,                 loss: nan
agent1:                 episode reward: 0.3620,                 loss: 0.1219
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5714s / 79901.4861 s
agent0:                 episode reward: -0.0539,                 loss: nan
agent1:                 episode reward: 0.0539,                 loss: 0.1211
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8832s / 80144.3694 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.1223
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6602s / 80401.0296 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.1195
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0267s / 80647.0563 s
agent0:                 episode reward: -0.1403,                 loss: nan
agent1:                 episode reward: 0.1403,                 loss: 0.1212
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8693s / 80895.9256 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.1225
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9451s / 81148.8707 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.1226
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0343s / 81388.9050 s
agent0:                 episode reward: 0.0120,                 loss: nan
agent1:                 episode reward: -0.0120,                 loss: 0.1213
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5549s / 81643.4599 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.1226
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3791s / 81891.8390 s
agent0:                 episode reward: -0.2614,                 loss: nan
agent1:                 episode reward: 0.2614,                 loss: 0.1212
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1587s / 82146.9977 s
agent0:                 episode reward: -0.6910,                 loss: nan
agent1:                 episode reward: 0.6910,                 loss: 0.1234
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 261.9014s / 82408.8991 s
agent0:                 episode reward: -0.0687,                 loss: nan
agent1:                 episode reward: 0.0687,                 loss: 0.1211
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7701s / 82651.6691 s
agent0:                 episode reward: -0.3868,                 loss: nan
agent1:                 episode reward: 0.3868,                 loss: 0.1220
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5890s / 82898.2582 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.1210
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8485s / 83148.1067 s
agent0:                 episode reward: -0.2589,                 loss: nan
agent1:                 episode reward: 0.2589,                 loss: 0.1220
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1747s / 83404.2814 s
agent0:                 episode reward: -0.3084,                 loss: nan
agent1:                 episode reward: 0.3084,                 loss: 0.1212
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8564s / 83646.1378 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.1215
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 263.2753s / 83909.4131 s
agent0:                 episode reward: -0.4459,                 loss: nan
agent1:                 episode reward: 0.4459,                 loss: 0.1213
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6380s / 84159.0510 s
agent0:                 episode reward: 0.1990,                 loss: nan
agent1:                 episode reward: -0.1990,                 loss: 0.1224
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5219s / 84402.5729 s
agent0:                 episode reward: -0.2116,                 loss: nan
agent1:                 episode reward: 0.2116,                 loss: 0.1222
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2009s / 84652.7738 s
agent0:                 episode reward: -0.3264,                 loss: nan
agent1:                 episode reward: 0.3264,                 loss: 0.1188
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3840s / 84902.1578 s
agent0:                 episode reward: 0.2341,                 loss: nan
agent1:                 episode reward: -0.2341,                 loss: 0.1199
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6504s / 85148.8083 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1229
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6027s / 85404.4110 s
agent0:                 episode reward: -0.5643,                 loss: nan
agent1:                 episode reward: 0.5643,                 loss: 0.1217
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2208s / 85649.6318 s
agent0:                 episode reward: -0.6033,                 loss: nan
agent1:                 episode reward: 0.6033,                 loss: 0.1204
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2862s / 85896.9180 s
agent0:                 episode reward: -0.1644,                 loss: nan
agent1:                 episode reward: 0.1644,                 loss: 0.1219
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7532s / 86145.6713 s
agent0:                 episode reward: -0.1395,                 loss: nan
agent1:                 episode reward: 0.1395,                 loss: 0.1198
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8419s / 86393.5132 s
agent0:                 episode reward: -0.3556,                 loss: nan
agent1:                 episode reward: 0.3556,                 loss: 0.1224
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3563s / 86639.8695 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.1200
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6150s / 86889.4845 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1210
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7643s / 87133.2488 s
agent0:                 episode reward: -0.2619,                 loss: nan
agent1:                 episode reward: 0.2619,                 loss: 0.1206
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7978s / 87388.0466 s
agent0:                 episode reward: -0.1960,                 loss: nan
agent1:                 episode reward: 0.1960,                 loss: 0.1187
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7904s / 87636.8371 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: 0.1203
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7719s / 87885.6089 s
agent0:                 episode reward: -0.2985,                 loss: nan
agent1:                 episode reward: 0.2985,                 loss: 0.1177
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4630s / 88135.0719 s
agent0:                 episode reward: -0.3180,                 loss: nan
agent1:                 episode reward: 0.3180,                 loss: 0.1183
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8374s / 88384.9093 s
agent0:                 episode reward: -0.0595,                 loss: nan
agent1:                 episode reward: 0.0595,                 loss: 0.1183
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1807s / 88641.0900 s
agent0:                 episode reward: -0.2658,                 loss: nan
agent1:                 episode reward: 0.2658,                 loss: 0.1185
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3418s / 88892.4318 s
agent0:                 episode reward: -0.0955,                 loss: nan
agent1:                 episode reward: 0.0955,                 loss: 0.1185
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3006s / 89141.7324 s
agent0:                 episode reward: -0.5089,                 loss: nan
agent1:                 episode reward: 0.5089,                 loss: 0.1175