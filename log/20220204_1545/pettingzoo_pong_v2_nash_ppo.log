pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220204_1545/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220204_1545/pettingzoo_pong_v2_nash_ppo.
Episode: 1/30000 (0.0033%),                 avg. length: 1122.0,                last time consumption/overall running time: 7.3972s / 7.3972 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.2828
env0_second_0:                 episode reward: -2.0000,                 loss: 0.2771
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1192.2,                last time consumption/overall running time: 146.1351s / 153.5323 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3314
env0_second_0:                 episode reward: -1.0500,                 loss: 0.3300
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1142.6,                last time consumption/overall running time: 140.4245s / 293.9568 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.6177
env0_second_0:                 episode reward: -0.4000,                 loss: 0.6010
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1132.75,                last time consumption/overall running time: 146.6693s / 440.6260 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.7319
env0_second_0:                 episode reward: -1.1500,                 loss: 0.7423
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1160.6,                last time consumption/overall running time: 148.5744s / 589.2005 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6451
env0_second_0:                 episode reward: -0.6500,                 loss: 0.6439
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 990.1,                last time consumption/overall running time: 121.1453s / 710.3457 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.6273
env0_second_0:                 episode reward: 6.7500,                 loss: 0.6243
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1065.1,                last time consumption/overall running time: 136.4956s / 846.8413 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.6708
env0_second_0:                 episode reward: -1.2500,                 loss: 0.6702
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1247.95,                last time consumption/overall running time: 151.8339s / 998.6752 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.6688
env0_second_0:                 episode reward: -3.6000,                 loss: 0.6798
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1123.3,                last time consumption/overall running time: 129.9481s / 1128.6234 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.6807
env0_second_0:                 episode reward: -3.4500,                 loss: 0.6693
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1093.55,                last time consumption/overall running time: 138.3048s / 1266.9282 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.7166
env0_second_0:                 episode reward: -3.6500,                 loss: 0.6990
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1188.15,                last time consumption/overall running time: 143.6652s / 1410.5934 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.7515
env0_second_0:                 episode reward: -0.3000,                 loss: 0.7381
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 1120.2,                last time consumption/overall running time: 132.0656s / 1542.6590 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.7567
env0_second_0:                 episode reward: 0.9000,                 loss: 0.7492
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1141.25,                last time consumption/overall running time: 145.3199s / 1687.9788 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.7014
env0_second_0:                 episode reward: 0.3500,                 loss: 0.6807
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1098.4,                last time consumption/overall running time: 141.9917s / 1829.9705 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.7333
env0_second_0:                 episode reward: -0.7500,                 loss: 0.7219
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1154.05,                last time consumption/overall running time: 146.4726s / 1976.4431 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.7212
env0_second_0:                 episode reward: -4.2500,                 loss: 0.7111
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 948.0,                last time consumption/overall running time: 119.5928s / 2096.0359 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.6743
env0_second_0:                 episode reward: 2.6500,                 loss: 0.6735
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 1109.2,                last time consumption/overall running time: 140.1536s / 2236.1895 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.6784
env0_second_0:                 episode reward: 2.4000,                 loss: 0.6593
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 1026.5,                last time consumption/overall running time: 134.7655s / 2370.9551 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.6955
env0_second_0:                 episode reward: -0.9500,                 loss: 0.6886
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 1195.3,                last time consumption/overall running time: 154.8276s / 2525.7827 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.7248
env0_second_0:                 episode reward: 1.2000,                 loss: 0.7144
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 1161.4,                last time consumption/overall running time: 149.3275s / 2675.1102 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.7262
env0_second_0:                 episode reward: -5.4500,                 loss: 0.7148
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 1131.45,                last time consumption/overall running time: 144.8460s / 2819.9562 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.6926
env0_second_0:                 episode reward: -0.7000,                 loss: 0.6848
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1252.7,                last time consumption/overall running time: 159.1262s / 2979.0824 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.6829
env0_second_0:                 episode reward: 4.1000,                 loss: 0.6775
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1118.8,                last time consumption/overall running time: 141.5200s / 3120.6024 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.6489
env0_second_0:                 episode reward: 6.7500,                 loss: 0.6450
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1186.35,                last time consumption/overall running time: 152.8053s / 3273.4077 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.6587
env0_second_0:                 episode reward: 1.2000,                 loss: 0.6495
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 1162.65,                last time consumption/overall running time: 155.1784s / 3428.5861 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.6479
env0_second_0:                 episode reward: 5.3500,                 loss: 0.6466
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 1157.95,                last time consumption/overall running time: 144.0717s / 3572.6578 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.6498
env0_second_0:                 episode reward: 6.8000,                 loss: 0.6430
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1138.0,                last time consumption/overall running time: 142.7280s / 3715.3858 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.5256
env0_second_0:                 episode reward: 8.6000,                 loss: 0.5272
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 1210.0,                last time consumption/overall running time: 157.7334s / 3873.1191 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.4919
env0_second_0:                 episode reward: 10.2000,                 loss: 0.4933
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1178.2,                last time consumption/overall running time: 157.3920s / 4030.5111 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.4383
env0_second_0:                 episode reward: 9.3000,                 loss: 0.4325
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 1198.8,                last time consumption/overall running time: 147.6365s / 4178.1476 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.4488
env0_second_0:                 episode reward: 12.3000,                 loss: 0.4483
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 1129.9,                last time consumption/overall running time: 133.8858s / 4312.0334 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.4400
env0_second_0:                 episode reward: 11.6000,                 loss: 0.4583
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 1124.65,                last time consumption/overall running time: 136.1654s / 4448.1988 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.4197
env0_second_0:                 episode reward: 14.5000,                 loss: 0.4157
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 1216.95,                last time consumption/overall running time: 154.3403s / 4602.5392 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.3916
env0_second_0:                 episode reward: 12.1000,                 loss: 0.3902
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 1380.8,                last time consumption/overall running time: 171.4315s / 4773.9707 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.4051
env0_second_0:                 episode reward: 10.9500,                 loss: 0.4152
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 1741.7,                last time consumption/overall running time: 219.1585s / 4993.1292 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.3557
env0_second_0:                 episode reward: 1.9000,                 loss: 0.3757
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1806.35,                last time consumption/overall running time: 218.3209s / 5211.4501 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.3285
env0_second_0:                 episode reward: -3.7500,                 loss: 0.3451
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1765.95,                last time consumption/overall running time: 217.8574s / 5429.3075 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.3074
env0_second_0:                 episode reward: -4.2000,                 loss: 0.3246
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1946.45,                last time consumption/overall running time: 240.1293s / 5669.4368 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2762
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2993
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 1906.6,                last time consumption/overall running time: 240.3313s / 5909.7681 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3123
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3223
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 1761.25,                last time consumption/overall running time: 211.6679s / 6121.4361 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.3199
env0_second_0:                 episode reward: 4.8000,                 loss: 0.3320
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 1831.15,                last time consumption/overall running time: 216.5270s / 6337.9630 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.3519
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3664
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 1884.3,                last time consumption/overall running time: 230.4006s / 6568.3636 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.3186
env0_second_0:                 episode reward: 4.8000,                 loss: 0.3290
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 1965.65,                last time consumption/overall running time: 215.1707s / 6783.5344 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3075
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3133
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 1861.7,                last time consumption/overall running time: 232.1637s / 7015.6981 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2870
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2947
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 1966.05,                last time consumption/overall running time: 246.4755s / 7262.1736 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.2591
env0_second_0:                 episode reward: -2.4000,                 loss: 0.2583
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2006.45,                last time consumption/overall running time: 252.2789s / 7514.4525 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.2543
env0_second_0:                 episode reward: -2.6500,                 loss: 0.2581
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 1854.4,                last time consumption/overall running time: 234.2698s / 7748.7223 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.2632
env0_second_0:                 episode reward: -2.8500,                 loss: 0.2728
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 1903.25,                last time consumption/overall running time: 221.2638s / 7969.9861 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2559
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2669
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2006.4,                last time consumption/overall running time: 249.3468s / 8219.3328 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.2453
env0_second_0:                 episode reward: 2.8000,                 loss: 0.2606
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2037.1,                last time consumption/overall running time: 257.4547s / 8476.7875 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2488
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2433
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 1905.1,                last time consumption/overall running time: 238.2936s / 8715.0811 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.2422
env0_second_0:                 episode reward: -3.8500,                 loss: 0.2373
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 1951.15,                last time consumption/overall running time: 244.9421s / 8960.0231 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.2329
env0_second_0:                 episode reward: -1.6500,                 loss: 0.2409
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2037.6,                last time consumption/overall running time: 254.7006s / 9214.7238 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2391
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2438
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 1918.65,                last time consumption/overall running time: 238.9438s / 9453.6675 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.2817
env0_second_0:                 episode reward: -3.4500,                 loss: 0.2967
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 1937.9,                last time consumption/overall running time: 247.4950s / 9701.1626 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2516
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2680
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 1958.55,                last time consumption/overall running time: 245.8447s / 9947.0072 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2489
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2447
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2050.25,                last time consumption/overall running time: 263.6375s / 10210.6447 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.2256
env0_second_0:                 episode reward: -2.9500,                 loss: 0.2317
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 1954.45,                last time consumption/overall running time: 254.2086s / 10464.8533 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.2401
env0_second_0:                 episode reward: -3.7000,                 loss: 0.2446
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2057.8,                last time consumption/overall running time: 263.8349s / 10728.6882 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2522
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2634
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2050.25,                last time consumption/overall running time: 261.2039s / 10989.8921 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.2189
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2298
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 1933.3,                last time consumption/overall running time: 241.8712s / 11231.7633 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2695
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2793
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2049.8,                last time consumption/overall running time: 253.4856s / 11485.2489 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.2107
env0_second_0:                 episode reward: 4.5000,                 loss: 0.2338
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 1981.35,                last time consumption/overall running time: 248.2038s / 11733.4527 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2267
env0_second_0:                 episode reward: 6.4500,                 loss: 0.2473
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2014.35,                last time consumption/overall running time: 248.5221s / 11981.9749 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.2292
env0_second_0:                 episode reward: 6.3000,                 loss: 0.2446
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 1888.9,                last time consumption/overall running time: 238.2958s / 12220.2707 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.2193
env0_second_0:                 episode reward: 8.1500,                 loss: 0.2592
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2015.5,                last time consumption/overall running time: 247.5778s / 12467.8484 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2270
env0_second_0:                 episode reward: 8.0500,                 loss: 0.2458
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1981.65,                last time consumption/overall running time: 254.6947s / 12722.5432 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.2252
env0_second_0:                 episode reward: 8.2000,                 loss: 0.2565
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1804.85,                last time consumption/overall running time: 222.2170s / 12944.7602 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1972
env0_second_0:                 episode reward: 12.1000,                 loss: 0.2084
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 1938.0,                last time consumption/overall running time: 240.2516s / 13185.0118 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.1731
env0_second_0:                 episode reward: 9.3500,                 loss: 0.1993
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2026.85,                last time consumption/overall running time: 228.5259s / 13413.5377 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.2187
env0_second_0:                 episode reward: 4.8000,                 loss: 0.2466
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2032.3,                last time consumption/overall running time: 225.3450s / 13638.8827 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.2522
env0_second_0:                 episode reward: 5.3000,                 loss: 0.2698
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 1919.1,                last time consumption/overall running time: 217.6256s / 13856.5084 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.2054
env0_second_0:                 episode reward: 8.9500,                 loss: 0.2314
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 1990.15,                last time consumption/overall running time: 239.3486s / 14095.8569 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.2410
env0_second_0:                 episode reward: 6.7500,                 loss: 0.2545
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 1982.15,                last time consumption/overall running time: 237.2611s / 14333.1180 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.2624
env0_second_0:                 episode reward: 5.9000,                 loss: 0.2744
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 1980.7,                last time consumption/overall running time: 244.9552s / 14578.0733 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.2465
env0_second_0:                 episode reward: 6.3000,                 loss: 0.2653
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2025.95,                last time consumption/overall running time: 258.5631s / 14836.6364 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.2472
env0_second_0:                 episode reward: 4.9000,                 loss: 0.2764
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 1944.0,                last time consumption/overall running time: 229.1542s / 15065.7906 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.2361
env0_second_0:                 episode reward: 5.2500,                 loss: 0.3237
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 1898.8,                last time consumption/overall running time: 236.0700s / 15301.8605 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2489
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2657
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 1937.95,                last time consumption/overall running time: 227.0833s / 15528.9438 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.2465
env0_second_0:                 episode reward: 5.3000,                 loss: 0.2603
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 1896.2,                last time consumption/overall running time: 215.6404s / 15744.5842 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.2090
env0_second_0:                 episode reward: 9.6500,                 loss: 0.2398
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 1866.8,                last time consumption/overall running time: 228.4784s / 15973.0626 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.2139
env0_second_0:                 episode reward: 10.0000,                 loss: 0.2313
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 1874.65,                last time consumption/overall running time: 227.7197s / 16200.7822 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1569
env0_second_0:                 episode reward: 10.8500,                 loss: 0.1751
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 1797.8,                last time consumption/overall running time: 220.0658s / 16420.8480 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.2471
env0_second_0:                 episode reward: 13.4500,                 loss: 0.2877
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 1746.3,                last time consumption/overall running time: 204.2522s / 16625.1002 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1551
env0_second_0:                 episode reward: 13.6500,                 loss: 0.1976
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 1830.0,                last time consumption/overall running time: 211.3112s / 16836.4114 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1459
env0_second_0:                 episode reward: 13.5500,                 loss: 0.1702
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 1802.2,                last time consumption/overall running time: 196.0972s / 17032.5086 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1415
env0_second_0:                 episode reward: 13.1500,                 loss: 0.1555
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 1744.6,                last time consumption/overall running time: 194.4812s / 17226.9899 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1271
env0_second_0:                 episode reward: 13.7500,                 loss: 0.1409
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 1795.7,                last time consumption/overall running time: 209.9898s / 17436.9797 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1515
env0_second_0:                 episode reward: 13.2000,                 loss: 0.1791
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 1734.9,                last time consumption/overall running time: 213.4752s / 17650.4549 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1609
env0_second_0:                 episode reward: 14.7500,                 loss: 0.1678
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 1741.15,                last time consumption/overall running time: 226.1711s / 17876.6260 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1849
env0_second_0:                 episode reward: 12.1000,                 loss: 0.1782
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 1747.15,                last time consumption/overall running time: 231.0656s / 18107.6916 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1659
env0_second_0:                 episode reward: 13.7500,                 loss: 0.2091
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 1766.25,                last time consumption/overall running time: 231.4018s / 18339.0934 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.1101
env0_second_0:                 episode reward: 15.2500,                 loss: 0.1258
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 1714.2,                last time consumption/overall running time: 221.7997s / 18560.8930 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2008
env0_second_0:                 episode reward: 12.8500,                 loss: 0.2006
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 1744.7,                last time consumption/overall running time: 221.1190s / 18782.0120 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.1574
env0_second_0:                 episode reward: 14.4000,                 loss: 0.2381
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 1456.6,                last time consumption/overall running time: 171.0613s / 18953.0733 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.2981
env0_second_0:                 episode reward: 2.4000,                 loss: 0.3189
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 818.35,                last time consumption/overall running time: 108.8126s / 19061.8859 s
env0_first_0:                 episode reward: 17.6000,                 loss: 0.2559
env0_second_0:                 episode reward: -17.6000,                 loss: 0.4702
env1_first_0:                 episode reward: 18.9000,                 loss: nan
env1_second_0:                 episode reward: -18.9000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 1327.6,                last time consumption/overall running time: 164.4675s / 19226.3535 s
env0_first_0:                 episode reward: 10.8000,                 loss: 0.4905
env0_second_0:                 episode reward: -10.8000,                 loss: 0.5224
env1_first_0:                 episode reward: 9.8000,                 loss: nan
env1_second_0:                 episode reward: -9.8000,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 1542.4,                last time consumption/overall running time: 184.5565s / 19410.9100 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.4305
env0_second_0:                 episode reward: -8.1500,                 loss: 0.4225
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 1849.95,                last time consumption/overall running time: 225.1698s / 19636.0797 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.2464
env0_second_0:                 episode reward: 8.2000,                 loss: 0.2860
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 1830.1,                last time consumption/overall running time: 213.7496s / 19849.8293 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1587
env0_second_0:                 episode reward: 12.9000,                 loss: 0.1723
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 1830.4,                last time consumption/overall running time: 205.5536s / 20055.3829 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1343
env0_second_0:                 episode reward: 13.2500,                 loss: 0.1515
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 1806.25,                last time consumption/overall running time: 198.5073s / 20253.8903 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1474
env0_second_0:                 episode reward: 12.9500,                 loss: 0.1572
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 1760.5,                last time consumption/overall running time: 208.9128s / 20462.8031 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1504
env0_second_0:                 episode reward: 14.9500,                 loss: 0.1663
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 1775.45,                last time consumption/overall running time: 193.8659s / 20656.6690 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1260
env0_second_0:                 episode reward: 14.0000,                 loss: 0.1765
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 1750.55,                last time consumption/overall running time: 217.3101s / 20873.9791 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.1094
env0_second_0:                 episode reward: 14.1500,                 loss: 3.5922
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 1774.55,                last time consumption/overall running time: 222.4183s / 21096.3974 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.2095
env0_second_0:                 episode reward: 12.9500,                 loss: 3.7300
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 1844.65,                last time consumption/overall running time: 228.5949s / 21324.9923 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1743
env0_second_0:                 episode reward: 12.5500,                 loss: 5.8199
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 1791.85,                last time consumption/overall running time: 230.9010s / 21555.8933 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1444
env0_second_0:                 episode reward: 14.1000,                 loss: 2.5605
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 1968.5,                last time consumption/overall running time: 240.4691s / 21796.3625 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.1626
env0_second_0:                 episode reward: 10.0000,                 loss: 2.7968
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 1773.25,                last time consumption/overall running time: 196.5422s / 21992.9047 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3342
env0_second_0:                 episode reward: -1.2000,                 loss: 2.7812
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2010.9,                last time consumption/overall running time: 245.6530s / 22238.5577 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.1848
env0_second_0:                 episode reward: 8.4000,                 loss: 2.8861
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 1723.3,                last time consumption/overall running time: 220.3019s / 22458.8595 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.1291
env0_second_0:                 episode reward: 11.9000,                 loss: 2.5722
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 1785.4,                last time consumption/overall running time: 224.1875s / 22683.0470 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1540
env0_second_0:                 episode reward: 12.7500,                 loss: 2.3154
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 1770.9,                last time consumption/overall running time: 221.0435s / 22904.0905 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1925
env0_second_0:                 episode reward: 13.0000,                 loss: 2.0340
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 1771.5,                last time consumption/overall running time: 221.6642s / 23125.7547 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1132
env0_second_0:                 episode reward: 14.9500,                 loss: 2.0183
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 1651.8,                last time consumption/overall running time: 218.0767s / 23343.8314 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.2941
env0_second_0:                 episode reward: 11.7000,                 loss: 3.5412
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 1882.05,                last time consumption/overall running time: 215.8279s / 23559.6593 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.2297
env0_second_0:                 episode reward: 9.9000,                 loss: 3.9485
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 1758.1,                last time consumption/overall running time: 198.3184s / 23757.9778 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1916
env0_second_0:                 episode reward: 12.8500,                 loss: 3.9618
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 1972.85,                last time consumption/overall running time: 230.6955s / 23988.6733 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.1806
env0_second_0:                 episode reward: 9.4000,                 loss: 3.6267
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 1883.85,                last time consumption/overall running time: 235.5379s / 24224.2112 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.2607
env0_second_0:                 episode reward: 7.0000,                 loss: 3.2518
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 1852.35,                last time consumption/overall running time: 228.5715s / 24452.7827 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.1401
env0_second_0:                 episode reward: 13.7000,                 loss: 2.6514
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 1797.85,                last time consumption/overall running time: 219.2654s / 24672.0481 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.1411
env0_second_0:                 episode reward: 13.9000,                 loss: 2.2026
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 1934.9,                last time consumption/overall running time: 254.1017s / 24926.1498 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1272
env0_second_0:                 episode reward: 13.2000,                 loss: 3.5602
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 1958.15,                last time consumption/overall running time: 259.7217s / 25185.8715 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1576
env0_second_0:                 episode reward: 11.1500,                 loss: 3.1040
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 1857.2,                last time consumption/overall running time: 235.1348s / 25421.0064 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1541
env0_second_0:                 episode reward: 15.4500,                 loss: 3.0977
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 1911.45,                last time consumption/overall running time: 249.3390s / 25670.3454 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1216
env0_second_0:                 episode reward: 14.7000,                 loss: 1.7927
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 1967.55,                last time consumption/overall running time: 237.0268s / 25907.3722 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1167
env0_second_0:                 episode reward: 13.1500,                 loss: 2.3880
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 1114.85,                last time consumption/overall running time: 127.0302s / 26034.4025 s
env0_first_0:                 episode reward: 10.5500,                 loss: 0.3143
env0_second_0:                 episode reward: -10.5500,                 loss: 2.1643
env1_first_0:                 episode reward: 9.6500,                 loss: nan
env1_second_0:                 episode reward: -9.6500,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2081.65,                last time consumption/overall running time: 248.9444s / 26283.3468 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2946
env0_second_0:                 episode reward: -1.0500,                 loss: 1.6804
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2197.45,                last time consumption/overall running time: 281.4671s / 26564.8139 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.1647
env0_second_0:                 episode reward: 9.8000,                 loss: 1.9580
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2195.85,                last time consumption/overall running time: 253.8167s / 26818.6307 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.1863
env0_second_0:                 episode reward: 10.1000,                 loss: 1.8642
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2209.0,                last time consumption/overall running time: 254.9444s / 27073.5751 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.2641
env0_second_0:                 episode reward: 5.3500,                 loss: 1.2116
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2022.45,                last time consumption/overall running time: 229.1608s / 27302.7359 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.2278
env0_second_0:                 episode reward: 11.0500,                 loss: 2.4580
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2123.05,                last time consumption/overall running time: 243.5343s / 27546.2701 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.1303
env0_second_0:                 episode reward: 11.2500,                 loss: 2.3081
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2218.25,                last time consumption/overall running time: 270.8284s / 27817.0986 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.1279
env0_second_0:                 episode reward: 11.3000,                 loss: 2.6865
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 1880.65,                last time consumption/overall running time: 216.5551s / 28033.6537 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.2414
env0_second_0:                 episode reward: 7.2000,                 loss: 1.8343
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 1431.9,                last time consumption/overall running time: 177.1606s / 28210.8143 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3023
env0_second_0:                 episode reward: 0.2500,                 loss: 2.4689
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2144.8,                last time consumption/overall running time: 246.5069s / 28457.3212 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.2438
env0_second_0:                 episode reward: 10.9000,                 loss: 2.0535
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 746.15,                last time consumption/overall running time: 96.1614s / 28553.4827 s
env0_first_0:                 episode reward: 19.7500,                 loss: 0.0945
env0_second_0:                 episode reward: -19.7500,                 loss: 1.6791
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 729.05,                last time consumption/overall running time: 93.9161s / 28647.3988 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0605
env0_second_0:                 episode reward: -20.4500,                 loss: 2.3405
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 1180.9,                last time consumption/overall running time: 146.1996s / 28793.5984 s
env0_first_0:                 episode reward: 9.8500,                 loss: 0.4345
env0_second_0:                 episode reward: -9.8500,                 loss: 1.8779
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 879.05,                last time consumption/overall running time: 102.8725s / 28896.4709 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.3457
env0_second_0:                 episode reward: 14.4500,                 loss: 0.7643
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 1503.5,                last time consumption/overall running time: 174.4005s / 29070.8714 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4716
env0_second_0:                 episode reward: -3.7000,                 loss: 1.4442
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 1733.85,                last time consumption/overall running time: 200.3487s / 29271.2201 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.3000
env0_second_0:                 episode reward: -7.6000,                 loss: 1.7640
env1_first_0:                 episode reward: 9.2000,                 loss: nan
env1_second_0:                 episode reward: -9.2000,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2180.15,                last time consumption/overall running time: 258.3651s / 29529.5852 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.2529
env0_second_0:                 episode reward: -2.4000,                 loss: 1.8477
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2239.3,                last time consumption/overall running time: 254.0909s / 29783.6761 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.2322
env0_second_0:                 episode reward: 3.3500,                 loss: 0.8131
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2292.05,                last time consumption/overall running time: 268.5787s / 30052.2548 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.2206
env0_second_0:                 episode reward: 4.2500,                 loss: 0.5665
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2456.2,                last time consumption/overall running time: 299.6123s / 30351.8672 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.2231
env0_second_0:                 episode reward: 2.9000,                 loss: 0.4920
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2425.65,                last time consumption/overall running time: 275.7402s / 30627.6073 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.2115
env0_second_0:                 episode reward: 4.7000,                 loss: 0.8587
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2370.15,                last time consumption/overall running time: 266.0111s / 30893.6184 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2001
env0_second_0:                 episode reward: 8.0500,                 loss: 0.4558
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2348.7,                last time consumption/overall running time: 279.9033s / 31173.5217 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.1905
env0_second_0:                 episode reward: 6.2500,                 loss: 0.4614
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2316.35,                last time consumption/overall running time: 268.9781s / 31442.4998 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.1995
env0_second_0:                 episode reward: 6.1500,                 loss: 0.4083
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2462.95,                last time consumption/overall running time: 301.0814s / 31743.5812 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.1968
env0_second_0:                 episode reward: 7.8500,                 loss: 0.9828
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2283.3,                last time consumption/overall running time: 277.7367s / 32021.3179 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.1946
env0_second_0:                 episode reward: 6.6500,                 loss: 1.7235
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2343.2,                last time consumption/overall running time: 277.9181s / 32299.2361 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.1929
env0_second_0:                 episode reward: 8.7000,                 loss: 1.2525
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2127.55,                last time consumption/overall running time: 274.8121s / 32574.0481 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1807
env0_second_0:                 episode reward: 11.6500,                 loss: 3.0092
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2197.75,                last time consumption/overall running time: 275.7887s / 32849.8369 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1444
env0_second_0:                 episode reward: 13.0500,                 loss: 2.4433
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2150.65,                last time consumption/overall running time: 265.3407s / 33115.1776 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.1345
env0_second_0:                 episode reward: 11.3500,                 loss: 1.6807
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2089.85,                last time consumption/overall running time: 243.5672s / 33358.7447 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1260
env0_second_0:                 episode reward: 13.0000,                 loss: 1.9776
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2169.35,                last time consumption/overall running time: 261.2597s / 33620.0045 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.2077
env0_second_0:                 episode reward: 12.1500,                 loss: 2.0145
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2139.3,                last time consumption/overall running time: 269.0535s / 33889.0580 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1188
env0_second_0:                 episode reward: 13.6500,                 loss: 2.9107
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2095.5,                last time consumption/overall running time: 253.0783s / 34142.1363 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1664
env0_second_0:                 episode reward: 13.0000,                 loss: 2.4323
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 1861.5,                last time consumption/overall running time: 217.2354s / 34359.3717 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.0856
env0_second_0:                 episode reward: 18.0000,                 loss: 2.2684
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 1893.05,                last time consumption/overall running time: 224.1968s / 34583.5685 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.0962
env0_second_0:                 episode reward: 15.0500,                 loss: 2.7637
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 1981.0,                last time consumption/overall running time: 249.5348s / 34833.1033 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1060
env0_second_0:                 episode reward: 15.1500,                 loss: 1.4764
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 1969.75,                last time consumption/overall running time: 224.9485s / 35058.0519 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.2175
env0_second_0:                 episode reward: 12.4500,                 loss: 1.3309
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 834.65,                last time consumption/overall running time: 104.8860s / 35162.9379 s
env0_first_0:                 episode reward: 12.9000,                 loss: 0.4799
env0_second_0:                 episode reward: -12.9000,                 loss: 2.8657
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 1364.5,                last time consumption/overall running time: 158.0450s / 35320.9829 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.4035
env0_second_0:                 episode reward: 15.1000,                 loss: 4.3263
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 1368.85,                last time consumption/overall running time: 182.4347s / 35503.4176 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.2148
env0_second_0:                 episode reward: 16.1500,                 loss: 2.6069
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 1513.1,                last time consumption/overall running time: 188.5973s / 35692.0149 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.2397
env0_second_0:                 episode reward: 15.4000,                 loss: 1.5655
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 1521.6,                last time consumption/overall running time: 182.0176s / 35874.0325 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2750
env0_second_0:                 episode reward: 14.1500,                 loss: 1.1787
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 1797.8,                last time consumption/overall running time: 218.5321s / 36092.5645 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1677
env0_second_0:                 episode reward: 15.3000,                 loss: 0.9848
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 1905.4,                last time consumption/overall running time: 221.8441s / 36314.4087 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0782
env0_second_0:                 episode reward: 15.9000,                 loss: 0.4986
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 2093.45,                last time consumption/overall running time: 234.9857s / 36549.3944 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1577
env0_second_0:                 episode reward: 13.5500,                 loss: 1.7778
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 1671.9,                last time consumption/overall running time: 202.4413s / 36751.8357 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.2582
env0_second_0:                 episode reward: 5.7500,                 loss: 1.6243
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 952.3,                last time consumption/overall running time: 117.1338s / 36868.9695 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3160
env0_second_0:                 episode reward: -1.3500,                 loss: 1.7737
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 1273.2,                last time consumption/overall running time: 154.0124s / 37022.9819 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.0390
env0_second_0:                 episode reward: 17.6500,                 loss: 1.3240
env1_first_0:                 episode reward: -17.5500,                 loss: nan
env1_second_0:                 episode reward: 17.5500,                 loss: nan
Episode: 3541/30000 (11.8033%),                 avg. length: 1254.3,                last time consumption/overall running time: 151.0679s / 37174.0498 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0582
env0_second_0:                 episode reward: 17.4500,                 loss: 0.4178
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 3561/30000 (11.8700%),                 avg. length: 1183.55,                last time consumption/overall running time: 143.1105s / 37317.1603 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.2882
env0_second_0:                 episode reward: 4.9500,                 loss: 0.9991
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3581/30000 (11.9367%),                 avg. length: 838.75,                last time consumption/overall running time: 103.7036s / 37420.8638 s
env0_first_0:                 episode reward: 14.6000,                 loss: 0.3080
env0_second_0:                 episode reward: -14.6000,                 loss: 1.0064
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 3601/30000 (12.0033%),                 avg. length: 1112.45,                last time consumption/overall running time: 135.1805s / 37556.0443 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5284
env0_second_0:                 episode reward: -0.6000,                 loss: 2.0761
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3621/30000 (12.0700%),                 avg. length: 2072.15,                last time consumption/overall running time: 236.1395s / 37792.1839 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2008
env0_second_0:                 episode reward: 12.6000,                 loss: 2.5532
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 3641/30000 (12.1367%),                 avg. length: 2201.25,                last time consumption/overall running time: 264.2623s / 38056.4462 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.1724
env0_second_0:                 episode reward: 11.2500,                 loss: 2.3345
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 3661/30000 (12.2033%),                 avg. length: 2179.75,                last time consumption/overall running time: 265.4080s / 38321.8542 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.2620
env0_second_0:                 episode reward: 8.2500,                 loss: 4.2550
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 3681/30000 (12.2700%),                 avg. length: 731.75,                last time consumption/overall running time: 93.1150s / 38414.9692 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1181
env0_second_0:                 episode reward: -20.7500,                 loss: 4.7417
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 3701/30000 (12.3367%),                 avg. length: 730.0,                last time consumption/overall running time: 92.2921s / 38507.2613 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0947
env0_second_0:                 episode reward: -20.4000,                 loss: 3.3445
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3721/30000 (12.4033%),                 avg. length: 728.85,                last time consumption/overall running time: 89.1036s / 38596.3649 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0474
env0_second_0:                 episode reward: -20.8000,                 loss: 2.1614
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 3741/30000 (12.4700%),                 avg. length: 728.4,                last time consumption/overall running time: 91.7616s / 38688.1265 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0419
env0_second_0:                 episode reward: -20.7000,                 loss: 1.5347
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3761/30000 (12.5367%),                 avg. length: 728.6,                last time consumption/overall running time: 92.3005s / 38780.4270 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0012
env0_second_0:                 episode reward: -20.5500,                 loss: 1.5686
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3781/30000 (12.6033%),                 avg. length: 729.15,                last time consumption/overall running time: 89.8531s / 38870.2801 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0054
env0_second_0:                 episode reward: -20.5500,                 loss: 1.3343
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 3801/30000 (12.6700%),                 avg. length: 729.35,                last time consumption/overall running time: 93.2114s / 38963.4915 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0212
env0_second_0:                 episode reward: -20.4500,                 loss: 1.4691
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3821/30000 (12.7367%),                 avg. length: 728.4,                last time consumption/overall running time: 90.0861s / 39053.5776 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0170
env0_second_0:                 episode reward: -20.7500,                 loss: 1.3776
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 3841/30000 (12.8033%),                 avg. length: 728.4,                last time consumption/overall running time: 90.8441s / 39144.4216 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0387
env0_second_0:                 episode reward: -20.7500,                 loss: 1.5133
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 3861/30000 (12.8700%),                 avg. length: 729.1,                last time consumption/overall running time: 92.7721s / 39237.1938 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0314
env0_second_0:                 episode reward: -20.6500,                 loss: 1.6678
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3881/30000 (12.9367%),                 avg. length: 728.25,                last time consumption/overall running time: 87.5240s / 39324.7178 s
env0_first_0:                 episode reward: 20.7000,                 loss: -0.0001
env0_second_0:                 episode reward: -20.7000,                 loss: 1.2358
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 3901/30000 (13.0033%),                 avg. length: 728.1,                last time consumption/overall running time: 92.2093s / 39416.9271 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0421
env0_second_0:                 episode reward: -20.6000,                 loss: 1.3559
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 3921/30000 (13.0700%),                 avg. length: 728.1,                last time consumption/overall running time: 89.9061s / 39506.8332 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0568
env0_second_0:                 episode reward: -21.0000,                 loss: 3.0894
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3941/30000 (13.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.6776s / 39598.5108 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0680
env0_second_0:                 episode reward: -20.9500,                 loss: 3.6690
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 3961/30000 (13.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 93.8044s / 39692.3152 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0440
env0_second_0:                 episode reward: -21.0000,                 loss: 2.3751
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 3981/30000 (13.2700%),                 avg. length: 746.3,                last time consumption/overall running time: 96.4402s / 39788.7554 s
env0_first_0:                 episode reward: 19.7500,                 loss: 0.1097
env0_second_0:                 episode reward: -19.7500,                 loss: 4.0373
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 4001/30000 (13.3367%),                 avg. length: 1300.4,                last time consumption/overall running time: 166.0665s / 39954.8219 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.5419
env0_second_0:                 episode reward: -4.8500,                 loss: 4.4580
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 4021/30000 (13.4033%),                 avg. length: 1424.05,                last time consumption/overall running time: 173.5205s / 40128.3424 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.2890
env0_second_0:                 episode reward: 13.3000,                 loss: 1.6276
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 4041/30000 (13.4700%),                 avg. length: 1448.85,                last time consumption/overall running time: 179.6006s / 40307.9430 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1718
env0_second_0:                 episode reward: 13.5000,                 loss: 0.8499
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 4061/30000 (13.5367%),                 avg. length: 1612.25,                last time consumption/overall running time: 199.9540s / 40507.8971 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.1603
env0_second_0:                 episode reward: 13.9500,                 loss: 0.6738
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 4081/30000 (13.6033%),                 avg. length: 1936.55,                last time consumption/overall running time: 237.9425s / 40745.8395 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1706
env0_second_0:                 episode reward: 10.5500,                 loss: 1.4976
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 4101/30000 (13.6700%),                 avg. length: 2016.35,                last time consumption/overall running time: 246.4104s / 40992.2499 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1795
env0_second_0:                 episode reward: 14.2000,                 loss: 2.7115
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 4121/30000 (13.7367%),                 avg. length: 2176.9,                last time consumption/overall running time: 257.8686s / 41250.1185 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1500
env0_second_0:                 episode reward: 12.0500,                 loss: 3.7296
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 4141/30000 (13.8033%),                 avg. length: 2173.55,                last time consumption/overall running time: 260.2371s / 41510.3555 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1355
env0_second_0:                 episode reward: 11.7500,                 loss: 5.9485
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4161/30000 (13.8700%),                 avg. length: 2262.45,                last time consumption/overall running time: 271.7340s / 41782.0895 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.1301
env0_second_0:                 episode reward: 12.5000,                 loss: 4.7695
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 4181/30000 (13.9367%),                 avg. length: 2307.35,                last time consumption/overall running time: 272.4773s / 42054.5668 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1645
env0_second_0:                 episode reward: 10.5500,                 loss: 2.5691
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 4201/30000 (14.0033%),                 avg. length: 2172.25,                last time consumption/overall running time: 255.5361s / 42310.1029 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1235
env0_second_0:                 episode reward: 13.6500,                 loss: 1.1344
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4221/30000 (14.0700%),                 avg. length: 2205.25,                last time consumption/overall running time: 266.3631s / 42576.4660 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0998
env0_second_0:                 episode reward: 12.3500,                 loss: 3.6721
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 4241/30000 (14.1367%),                 avg. length: 2186.35,                last time consumption/overall running time: 256.7619s / 42833.2278 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1052
env0_second_0:                 episode reward: 11.7500,                 loss: 1.5752
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 4261/30000 (14.2033%),                 avg. length: 2338.95,                last time consumption/overall running time: 269.4594s / 43102.6873 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0718
env0_second_0:                 episode reward: 12.7000,                 loss: 1.8483
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 4281/30000 (14.2700%),                 avg. length: 2126.25,                last time consumption/overall running time: 255.9845s / 43358.6718 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1229
env0_second_0:                 episode reward: 13.3000,                 loss: 1.6449
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 4301/30000 (14.3367%),                 avg. length: 2207.45,                last time consumption/overall running time: 265.6754s / 43624.3472 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1028
env0_second_0:                 episode reward: 13.2500,                 loss: 2.1513
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 4321/30000 (14.4033%),                 avg. length: 2100.8,                last time consumption/overall running time: 252.1531s / 43876.5003 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.2423
env0_second_0:                 episode reward: 9.3000,                 loss: 3.7733
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 4341/30000 (14.4700%),                 avg. length: 2151.25,                last time consumption/overall running time: 244.6351s / 44121.1354 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1071
env0_second_0:                 episode reward: 13.8000,                 loss: 1.3832
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 4361/30000 (14.5367%),                 avg. length: 1566.65,                last time consumption/overall running time: 198.1268s / 44319.2622 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2420
env0_second_0:                 episode reward: -0.4000,                 loss: 1.2884
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4381/30000 (14.6033%),                 avg. length: 1449.5,                last time consumption/overall running time: 176.7943s / 44496.0565 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4026
env0_second_0:                 episode reward: -5.3000,                 loss: 3.1709
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 4401/30000 (14.6700%),                 avg. length: 1783.85,                last time consumption/overall running time: 213.1371s / 44709.1936 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2495
env0_second_0:                 episode reward: 9.0000,                 loss: 2.0654
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 4421/30000 (14.7367%),                 avg. length: 1721.3,                last time consumption/overall running time: 205.9982s / 44915.1918 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1448
env0_second_0:                 episode reward: 12.5500,                 loss: 2.0656
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 4441/30000 (14.8033%),                 avg. length: 1733.3,                last time consumption/overall running time: 211.9088s / 45127.1006 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1344
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8046
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 4461/30000 (14.8700%),                 avg. length: 1684.0,                last time consumption/overall running time: 215.6353s / 45342.7360 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1660
env0_second_0:                 episode reward: 15.5500,                 loss: 1.9564
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 4481/30000 (14.9367%),                 avg. length: 1542.1,                last time consumption/overall running time: 196.6496s / 45539.3856 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.3081
env0_second_0:                 episode reward: 4.1000,                 loss: 1.5287
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 4501/30000 (15.0033%),                 avg. length: 1969.25,                last time consumption/overall running time: 234.9823s / 45774.3679 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.2294
env0_second_0:                 episode reward: 6.6000,                 loss: 1.3841
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4521/30000 (15.0700%),                 avg. length: 1734.05,                last time consumption/overall running time: 223.3089s / 45997.6768 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1113
env0_second_0:                 episode reward: 13.7500,                 loss: 1.2156
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 4541/30000 (15.1367%),                 avg. length: 1675.95,                last time consumption/overall running time: 213.4134s / 46211.0902 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.1055
env0_second_0:                 episode reward: 17.3000,                 loss: 1.9691
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 4561/30000 (15.2033%),                 avg. length: 1653.65,                last time consumption/overall running time: 205.1301s / 46416.2203 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.1175
env0_second_0:                 episode reward: 16.2000,                 loss: 2.1728
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 4581/30000 (15.2700%),                 avg. length: 1529.9,                last time consumption/overall running time: 200.8391s / 46617.0594 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.4493
env0_second_0:                 episode reward: -0.3500,                 loss: 1.9986
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4601/30000 (15.3367%),                 avg. length: 1787.4,                last time consumption/overall running time: 220.3826s / 46837.4420 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.1564
env0_second_0:                 episode reward: 12.4000,                 loss: 1.3108
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 4621/30000 (15.4033%),                 avg. length: 1750.35,                last time consumption/overall running time: 228.4748s / 47065.9168 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1158
env0_second_0:                 episode reward: 14.6000,                 loss: 0.8264
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 4641/30000 (15.4700%),                 avg. length: 1640.3,                last time consumption/overall running time: 212.8524s / 47278.7691 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.2967
env0_second_0:                 episode reward: 12.3000,                 loss: 1.3664
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 4661/30000 (15.5367%),                 avg. length: 1595.8,                last time consumption/overall running time: 208.5270s / 47487.2962 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1989
env0_second_0:                 episode reward: 13.1500,                 loss: 1.6915
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 4681/30000 (15.6033%),                 avg. length: 1298.45,                last time consumption/overall running time: 159.5209s / 47646.8170 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.3084
env0_second_0:                 episode reward: -7.6000,                 loss: 1.4293
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 4701/30000 (15.6700%),                 avg. length: 1756.6,                last time consumption/overall running time: 205.1882s / 47852.0052 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.1455
env0_second_0:                 episode reward: 14.4500,                 loss: 1.5146
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 4721/30000 (15.7367%),                 avg. length: 1236.9,                last time consumption/overall running time: 165.6344s / 48017.6397 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1939
env0_second_0:                 episode reward: 0.4500,                 loss: 2.1773
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/30000 (15.8033%),                 avg. length: 729.3,                last time consumption/overall running time: 93.5311s / 48111.1707 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0747
env0_second_0:                 episode reward: -20.5500,                 loss: 2.4880
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 4761/30000 (15.8700%),                 avg. length: 1547.75,                last time consumption/overall running time: 196.8149s / 48307.9857 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4720
env0_second_0:                 episode reward: -0.6000,                 loss: 2.1701
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4781/30000 (15.9367%),                 avg. length: 1610.35,                last time consumption/overall running time: 203.9118s / 48511.8974 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.4088
env0_second_0:                 episode reward: 6.1500,                 loss: 2.2196
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4801/30000 (16.0033%),                 avg. length: 1623.2,                last time consumption/overall running time: 211.3224s / 48723.2198 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.3166
env0_second_0:                 episode reward: 7.8500,                 loss: 1.8039
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 4821/30000 (16.0700%),                 avg. length: 1583.35,                last time consumption/overall running time: 205.7094s / 48928.9292 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.3423
env0_second_0:                 episode reward: 9.8500,                 loss: 1.5753
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 4841/30000 (16.1367%),                 avg. length: 1718.15,                last time consumption/overall running time: 218.3280s / 49147.2572 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.3248
env0_second_0:                 episode reward: 9.4500,                 loss: 1.3221
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 4861/30000 (16.2033%),                 avg. length: 1613.7,                last time consumption/overall running time: 205.0685s / 49352.3257 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.2675
env0_second_0:                 episode reward: 12.0000,                 loss: 1.1461
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 4881/30000 (16.2700%),                 avg. length: 1554.0,                last time consumption/overall running time: 198.6181s / 49550.9439 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.2670
env0_second_0:                 episode reward: 10.7000,                 loss: 0.8439
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 4901/30000 (16.3367%),                 avg. length: 1604.75,                last time consumption/overall running time: 203.8423s / 49754.7861 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.2911
env0_second_0:                 episode reward: 11.7500,                 loss: 1.0339
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4921/30000 (16.4033%),                 avg. length: 1333.0,                last time consumption/overall running time: 163.9601s / 49918.7462 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.3515
env0_second_0:                 episode reward: 3.1000,                 loss: 1.1142
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 4941/30000 (16.4700%),                 avg. length: 1009.05,                last time consumption/overall running time: 121.2587s / 50040.0049 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.5243
env0_second_0:                 episode reward: -1.6500,                 loss: 2.1254
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 4961/30000 (16.5367%),                 avg. length: 1596.95,                last time consumption/overall running time: 203.1619s / 50243.1668 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.4208
env0_second_0:                 episode reward: 7.2500,                 loss: 1.6429
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4981/30000 (16.6033%),                 avg. length: 1575.95,                last time consumption/overall running time: 186.7691s / 50429.9359 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.3412
env0_second_0:                 episode reward: 9.6500,                 loss: 1.5263
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 5001/30000 (16.6700%),                 avg. length: 1529.0,                last time consumption/overall running time: 184.4456s / 50614.3815 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.2516
env0_second_0:                 episode reward: 13.3500,                 loss: 1.2002
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5021/30000 (16.7367%),                 avg. length: 1413.2,                last time consumption/overall running time: 172.0953s / 50786.4768 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.2387
env0_second_0:                 episode reward: 15.9000,                 loss: 1.0614
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 5041/30000 (16.8033%),                 avg. length: 1327.8,                last time consumption/overall running time: 171.1655s / 50957.6423 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.2413
env0_second_0:                 episode reward: 14.6500,                 loss: 0.8332
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 5061/30000 (16.8700%),                 avg. length: 796.4,                last time consumption/overall running time: 106.1080s / 51063.7503 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.2200
env0_second_0:                 episode reward: -16.9500,                 loss: 0.7650
env1_first_0:                 episode reward: 16.8000,                 loss: nan
env1_second_0:                 episode reward: -16.8000,                 loss: nan
Episode: 5081/30000 (16.9367%),                 avg. length: 1184.6,                last time consumption/overall running time: 153.3504s / 51217.1007 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.5144
env0_second_0:                 episode reward: -6.3000,                 loss: 1.7868
env1_first_0:                 episode reward: 11.4500,                 loss: nan
env1_second_0:                 episode reward: -11.4500,                 loss: nan
Episode: 5101/30000 (17.0033%),                 avg. length: 1573.95,                last time consumption/overall running time: 195.5401s / 51412.6408 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.4396
env0_second_0:                 episode reward: 6.3000,                 loss: 1.4316
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 5121/30000 (17.0700%),                 avg. length: 1488.55,                last time consumption/overall running time: 172.7434s / 51585.3842 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.2930
env0_second_0:                 episode reward: 13.3000,                 loss: 1.1816
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 5141/30000 (17.1367%),                 avg. length: 1345.05,                last time consumption/overall running time: 163.6902s / 51749.0744 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.2666
env0_second_0:                 episode reward: 15.1000,                 loss: 1.2539
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5161/30000 (17.2033%),                 avg. length: 1455.75,                last time consumption/overall running time: 183.2412s / 51932.3156 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3605
env0_second_0:                 episode reward: 13.2500,                 loss: 1.3501
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5181/30000 (17.2700%),                 avg. length: 1377.3,                last time consumption/overall running time: 168.4636s / 52100.7792 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.6019
env0_second_0:                 episode reward: 0.2500,                 loss: 1.5770
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5201/30000 (17.3367%),                 avg. length: 1900.7,                last time consumption/overall running time: 240.5154s / 52341.2947 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4262
env0_second_0:                 episode reward: 0.7500,                 loss: 1.6710
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5221/30000 (17.4033%),                 avg. length: 1937.2,                last time consumption/overall running time: 243.6858s / 52584.9805 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3709
env0_second_0:                 episode reward: -1.0000,                 loss: 1.4407
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5241/30000 (17.4700%),                 avg. length: 1878.55,                last time consumption/overall running time: 220.3311s / 52805.3115 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.4074
env0_second_0:                 episode reward: -3.1500,                 loss: 1.4767
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5261/30000 (17.5367%),                 avg. length: 1681.4,                last time consumption/overall running time: 210.4915s / 53015.8030 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.4557
env0_second_0:                 episode reward: -3.6500,                 loss: 1.0085
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5281/30000 (17.6033%),                 avg. length: 1940.95,                last time consumption/overall running time: 243.1004s / 53258.9035 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.3758
env0_second_0:                 episode reward: 3.3000,                 loss: 0.9067
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 5301/30000 (17.6700%),                 avg. length: 1627.6,                last time consumption/overall running time: 185.7541s / 53444.6576 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.4403
env0_second_0:                 episode reward: 8.4000,                 loss: 1.6674
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5321/30000 (17.7367%),                 avg. length: 1595.25,                last time consumption/overall running time: 183.6258s / 53628.2834 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.6166
env0_second_0:                 episode reward: 1.7000,                 loss: 2.0578
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5341/30000 (17.8033%),                 avg. length: 1603.6,                last time consumption/overall running time: 202.4714s / 53830.7547 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.2948
env0_second_0:                 episode reward: 13.2500,                 loss: 1.4832
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 5361/30000 (17.8700%),                 avg. length: 1715.1,                last time consumption/overall running time: 208.3975s / 54039.1522 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2132
env0_second_0:                 episode reward: 12.6000,                 loss: 0.9040
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 5381/30000 (17.9367%),                 avg. length: 1733.5,                last time consumption/overall running time: 218.5931s / 54257.7453 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1802
env0_second_0:                 episode reward: 11.6000,                 loss: 1.0037
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 5401/30000 (18.0033%),                 avg. length: 1504.5,                last time consumption/overall running time: 193.0895s / 54450.8348 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1523
env0_second_0:                 episode reward: 15.3000,                 loss: 0.9256
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 5421/30000 (18.0700%),                 avg. length: 1497.05,                last time consumption/overall running time: 191.0654s / 54641.9002 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.1779
env0_second_0:                 episode reward: 15.9000,                 loss: 1.1330
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 5441/30000 (18.1367%),                 avg. length: 740.05,                last time consumption/overall running time: 101.2968s / 54743.1970 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.1823
env0_second_0:                 episode reward: -19.9000,                 loss: 0.9378
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 5461/30000 (18.2033%),                 avg. length: 729.75,                last time consumption/overall running time: 97.5771s / 54840.7741 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0117
env0_second_0:                 episode reward: -20.4500,                 loss: 0.4024
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 5481/30000 (18.2700%),                 avg. length: 728.9,                last time consumption/overall running time: 91.3151s / 54932.0892 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0402
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4006
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 5501/30000 (18.3367%),                 avg. length: 1373.35,                last time consumption/overall running time: 168.9099s / 55100.9991 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.4434
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5823
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5521/30000 (18.4033%),                 avg. length: 1734.9,                last time consumption/overall running time: 209.2225s / 55310.2216 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.2376
env0_second_0:                 episode reward: 11.2500,                 loss: 0.4772
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 5541/30000 (18.4700%),                 avg. length: 1694.95,                last time consumption/overall running time: 204.6985s / 55514.9201 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1940
env0_second_0:                 episode reward: 10.8500,                 loss: 0.5971
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 5561/30000 (18.5367%),                 avg. length: 1529.35,                last time consumption/overall running time: 199.0742s / 55713.9942 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1408
env0_second_0:                 episode reward: 15.1500,                 loss: 0.6123
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 5581/30000 (18.6033%),                 avg. length: 1331.7,                last time consumption/overall running time: 173.7001s / 55887.6943 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.3178
env0_second_0:                 episode reward: 5.4500,                 loss: 1.2364
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 5601/30000 (18.6700%),                 avg. length: 1540.95,                last time consumption/overall running time: 200.4510s / 56088.1453 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.4062
env0_second_0:                 episode reward: 9.6500,                 loss: 1.7052
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5621/30000 (18.7367%),                 avg. length: 1542.8,                last time consumption/overall running time: 202.4236s / 56290.5688 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.2349
env0_second_0:                 episode reward: 13.4000,                 loss: 0.9225
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 5641/30000 (18.8033%),                 avg. length: 1554.5,                last time consumption/overall running time: 200.4891s / 56491.0580 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1978
env0_second_0:                 episode reward: 12.7500,                 loss: 0.7730
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 5661/30000 (18.8700%),                 avg. length: 1101.9,                last time consumption/overall running time: 145.4904s / 56636.5483 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.4270
env0_second_0:                 episode reward: -5.2000,                 loss: 1.9527
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 5681/30000 (18.9367%),                 avg. length: 899.35,                last time consumption/overall running time: 118.2205s / 56754.7688 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.3687
env0_second_0:                 episode reward: -4.8500,                 loss: 1.8589
env1_first_0:                 episode reward: 7.5500,                 loss: nan
env1_second_0:                 episode reward: -7.5500,                 loss: nan
Episode: 5701/30000 (19.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 101.1366s / 56855.9054 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0766
env0_second_0:                 episode reward: -20.9500,                 loss: 1.8479
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 5721/30000 (19.0700%),                 avg. length: 728.05,                last time consumption/overall running time: 98.0870s / 56953.9924 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0774
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9335
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 5741/30000 (19.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.2797s / 57051.2720 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0607
env0_second_0:                 episode reward: -20.8500,                 loss: 0.4225
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 5761/30000 (19.2033%),                 avg. length: 728.25,                last time consumption/overall running time: 99.1630s / 57150.4350 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0144
env0_second_0:                 episode reward: -20.7000,                 loss: 0.3703
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 5781/30000 (19.2700%),                 avg. length: 728.35,                last time consumption/overall running time: 93.6975s / 57244.1326 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0506
env0_second_0:                 episode reward: -20.7500,                 loss: 1.2358
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 5801/30000 (19.3367%),                 avg. length: 1181.5,                last time consumption/overall running time: 154.7403s / 57398.8728 s
env0_first_0:                 episode reward: 10.8500,                 loss: 0.5409
env0_second_0:                 episode reward: -10.8500,                 loss: 4.5092
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 5821/30000 (19.4033%),                 avg. length: 1689.65,                last time consumption/overall running time: 206.4301s / 57605.3029 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.3811
env0_second_0:                 episode reward: -2.2500,                 loss: 3.6920
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 5841/30000 (19.4700%),                 avg. length: 775.35,                last time consumption/overall running time: 103.9880s / 57709.2909 s
env0_first_0:                 episode reward: 9.6000,                 loss: 0.2699
env0_second_0:                 episode reward: -9.6000,                 loss: 1.4059
env1_first_0:                 episode reward: 11.9000,                 loss: nan
env1_second_0:                 episode reward: -11.9000,                 loss: nan
Episode: 5861/30000 (19.5367%),                 avg. length: 800.3,                last time consumption/overall running time: 105.5647s / 57814.8556 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.2843
env0_second_0:                 episode reward: 18.2000,                 loss: 1.2588
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 5881/30000 (19.6033%),                 avg. length: 981.0,                last time consumption/overall running time: 123.2478s / 57938.1034 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.2988
env0_second_0:                 episode reward: 16.5000,                 loss: 2.1275
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5901/30000 (19.6700%),                 avg. length: 862.05,                last time consumption/overall running time: 114.6724s / 58052.7759 s
env0_first_0:                 episode reward: 14.3000,                 loss: 0.3622
env0_second_0:                 episode reward: -14.3000,                 loss: 2.3073
env1_first_0:                 episode reward: 14.4000,                 loss: nan
env1_second_0:                 episode reward: -14.4000,                 loss: nan
Episode: 5921/30000 (19.7367%),                 avg. length: 1587.55,                last time consumption/overall running time: 189.8096s / 58242.5854 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.4737
env0_second_0:                 episode reward: 3.7000,                 loss: 1.6240
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 5941/30000 (19.8033%),                 avg. length: 1514.0,                last time consumption/overall running time: 196.4610s / 58439.0464 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.3489
env0_second_0:                 episode reward: 13.4500,                 loss: 1.1711
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 5961/30000 (19.8700%),                 avg. length: 1676.85,                last time consumption/overall running time: 221.4747s / 58660.5211 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.2463
env0_second_0:                 episode reward: 11.1000,                 loss: 1.0112
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 5981/30000 (19.9367%),                 avg. length: 1728.6,                last time consumption/overall running time: 223.0333s / 58883.5544 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.2125
env0_second_0:                 episode reward: 12.7500,                 loss: 0.9834
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 6001/30000 (20.0033%),                 avg. length: 1682.65,                last time consumption/overall running time: 218.7000s / 59102.2544 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1948
env0_second_0:                 episode reward: 11.4500,                 loss: 0.7810
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 6021/30000 (20.0700%),                 avg. length: 1629.65,                last time consumption/overall running time: 209.1721s / 59311.4265 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1698
env0_second_0:                 episode reward: 14.2000,                 loss: 0.7161
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 6041/30000 (20.1367%),                 avg. length: 885.2,                last time consumption/overall running time: 118.0263s / 59429.4528 s
env0_first_0:                 episode reward: 13.4500,                 loss: 0.2715
env0_second_0:                 episode reward: -13.4500,                 loss: 2.3336
env1_first_0:                 episode reward: 12.9500,                 loss: nan
env1_second_0:                 episode reward: -12.9500,                 loss: nan
Episode: 6061/30000 (20.2033%),                 avg. length: 728.1,                last time consumption/overall running time: 97.2405s / 59526.6933 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0257
env0_second_0:                 episode reward: -20.8500,                 loss: 2.4248
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 6081/30000 (20.2700%),                 avg. length: 758.75,                last time consumption/overall running time: 98.7736s / 59625.4669 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.1755
env0_second_0:                 episode reward: -1.6500,                 loss: 1.4167
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 6101/30000 (20.3367%),                 avg. length: 797.45,                last time consumption/overall running time: 109.1732s / 59734.6401 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.1569
env0_second_0:                 episode reward: 18.3500,                 loss: 1.1829
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 6121/30000 (20.4033%),                 avg. length: 843.7,                last time consumption/overall running time: 107.6341s / 59842.2742 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.1661
env0_second_0:                 episode reward: 18.1500,                 loss: 1.0457
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 6141/30000 (20.4700%),                 avg. length: 1039.5,                last time consumption/overall running time: 132.7480s / 59975.0223 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.4748
env0_second_0:                 episode reward: 13.3500,                 loss: 2.0419
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 6161/30000 (20.5367%),                 avg. length: 1161.2,                last time consumption/overall running time: 148.7775s / 60123.7997 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.3302
env0_second_0:                 episode reward: 14.3500,                 loss: 1.8161
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 6181/30000 (20.6033%),                 avg. length: 1402.95,                last time consumption/overall running time: 172.9336s / 60296.7334 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.3452
env0_second_0:                 episode reward: 13.7000,                 loss: 1.2861
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 6201/30000 (20.6700%),                 avg. length: 1626.95,                last time consumption/overall running time: 196.7350s / 60493.4684 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.2481
env0_second_0:                 episode reward: 13.1000,                 loss: 0.7644
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 6221/30000 (20.7367%),                 avg. length: 1452.1,                last time consumption/overall running time: 181.6781s / 60675.1465 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.2068
env0_second_0:                 episode reward: 14.1000,                 loss: 0.7609
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 6241/30000 (20.8033%),                 avg. length: 1559.6,                last time consumption/overall running time: 192.8650s / 60868.0116 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.3999
env0_second_0:                 episode reward: 11.7000,                 loss: 0.6697
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 6261/30000 (20.8700%),                 avg. length: 1648.75,                last time consumption/overall running time: 206.2584s / 61074.2700 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2620
env0_second_0:                 episode reward: 11.9000,                 loss: 0.5003
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 6281/30000 (20.9367%),                 avg. length: 1643.1,                last time consumption/overall running time: 206.2865s / 61280.5565 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.2254
env0_second_0:                 episode reward: 13.8000,                 loss: 0.7175
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 6301/30000 (21.0033%),                 avg. length: 1648.6,                last time consumption/overall running time: 203.4342s / 61483.9906 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.2538
env0_second_0:                 episode reward: 13.4000,                 loss: 0.6045
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6321/30000 (21.0700%),                 avg. length: 1552.55,                last time consumption/overall running time: 197.9489s / 61681.9395 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.1664
env0_second_0:                 episode reward: 16.0500,                 loss: 0.4796
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 6341/30000 (21.1367%),                 avg. length: 1320.05,                last time consumption/overall running time: 169.3221s / 61851.2616 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.1360
env0_second_0:                 episode reward: 18.0000,                 loss: 0.3760
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 6361/30000 (21.2033%),                 avg. length: 1478.65,                last time consumption/overall running time: 189.3503s / 62040.6118 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.3018
env0_second_0:                 episode reward: 13.9500,                 loss: 0.6034
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 6381/30000 (21.2700%),                 avg. length: 1340.5,                last time consumption/overall running time: 161.5083s / 62202.1201 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.5645
env0_second_0:                 episode reward: -3.1000,                 loss: 1.6655
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 6401/30000 (21.3367%),                 avg. length: 1332.6,                last time consumption/overall running time: 157.0757s / 62359.1957 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.3125
env0_second_0:                 episode reward: 13.8500,                 loss: 0.9434
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6421/30000 (21.4033%),                 avg. length: 2284.8,                last time consumption/overall running time: 245.8988s / 62605.0946 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.2044
env0_second_0:                 episode reward: 8.8000,                 loss: 0.5420
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 6441/30000 (21.4700%),                 avg. length: 1445.25,                last time consumption/overall running time: 185.5945s / 62790.6891 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.2089
env0_second_0:                 episode reward: 14.5500,                 loss: 0.5835
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 6461/30000 (21.5367%),                 avg. length: 1280.6,                last time consumption/overall running time: 160.0699s / 62950.7590 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.1260
env0_second_0:                 episode reward: 17.6500,                 loss: 0.5230
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 6481/30000 (21.6033%),                 avg. length: 1325.6,                last time consumption/overall running time: 161.1481s / 63111.9072 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.1684
env0_second_0:                 episode reward: 17.1000,                 loss: 0.4722
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 6501/30000 (21.6700%),                 avg. length: 1478.3,                last time consumption/overall running time: 188.9227s / 63300.8299 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1289
env0_second_0:                 episode reward: 14.6500,                 loss: 0.4732
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 6521/30000 (21.7367%),                 avg. length: 1532.85,                last time consumption/overall running time: 195.8285s / 63496.6583 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1506
env0_second_0:                 episode reward: 12.8000,                 loss: 0.4730
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 6541/30000 (21.8033%),                 avg. length: 1238.7,                last time consumption/overall running time: 151.9062s / 63648.5646 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.2111
env0_second_0:                 episode reward: 15.3000,                 loss: 0.4257
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 6561/30000 (21.8700%),                 avg. length: 1557.65,                last time consumption/overall running time: 200.3081s / 63848.8727 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.1863
env0_second_0:                 episode reward: 14.3000,                 loss: 0.4809
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 6581/30000 (21.9367%),                 avg. length: 1576.8,                last time consumption/overall running time: 198.1201s / 64046.9928 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.2547
env0_second_0:                 episode reward: 13.0500,                 loss: 0.6358
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 6601/30000 (22.0033%),                 avg. length: 1567.55,                last time consumption/overall running time: 197.3750s / 64244.3678 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.1704
env0_second_0:                 episode reward: 15.3500,                 loss: 0.5511
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 6621/30000 (22.0700%),                 avg. length: 1676.25,                last time consumption/overall running time: 201.3772s / 64445.7450 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1117
env0_second_0:                 episode reward: 14.9500,                 loss: 0.4297
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6641/30000 (22.1367%),                 avg. length: 1530.95,                last time consumption/overall running time: 189.3186s / 64635.0636 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3367
env0_second_0:                 episode reward: 2.1500,                 loss: 0.8098
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 6661/30000 (22.2033%),                 avg. length: 1579.25,                last time consumption/overall running time: 200.8587s / 64835.9223 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.1407
env0_second_0:                 episode reward: 14.8500,                 loss: 0.6949
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 6681/30000 (22.2700%),                 avg. length: 1547.7,                last time consumption/overall running time: 194.4151s / 65030.3373 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.1185
env0_second_0:                 episode reward: 15.7000,                 loss: 0.8840
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 6701/30000 (22.3367%),                 avg. length: 1743.0,                last time consumption/overall running time: 211.5740s / 65241.9114 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1547
env0_second_0:                 episode reward: 13.1500,                 loss: 0.8832
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 6721/30000 (22.4033%),                 avg. length: 1612.1,                last time consumption/overall running time: 205.2900s / 65447.2014 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1415
env0_second_0:                 episode reward: 14.6500,                 loss: 0.7392
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 6741/30000 (22.4700%),                 avg. length: 1775.1,                last time consumption/overall running time: 209.5112s / 65656.7125 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1839
env0_second_0:                 episode reward: 11.4500,                 loss: 0.8928
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 6761/30000 (22.5367%),                 avg. length: 1587.35,                last time consumption/overall running time: 193.0898s / 65849.8023 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.1183
env0_second_0:                 episode reward: 15.9500,                 loss: 1.0077
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 6781/30000 (22.6033%),                 avg. length: 1391.8,                last time consumption/overall running time: 177.8871s / 66027.6894 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0880
env0_second_0:                 episode reward: 16.1500,                 loss: 0.9730
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 6801/30000 (22.6700%),                 avg. length: 1503.9,                last time consumption/overall running time: 191.9934s / 66219.6828 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1362
env0_second_0:                 episode reward: 14.7500,                 loss: 1.0700
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6821/30000 (22.7367%),                 avg. length: 914.05,                last time consumption/overall running time: 119.7587s / 66339.4415 s
env0_first_0:                 episode reward: 14.5500,                 loss: 0.3507
env0_second_0:                 episode reward: -14.5500,                 loss: 1.1827
env1_first_0:                 episode reward: 15.6000,                 loss: nan
env1_second_0:                 episode reward: -15.6000,                 loss: nan
Episode: 6841/30000 (22.8033%),                 avg. length: 849.55,                last time consumption/overall running time: 109.0872s / 66448.5287 s
env0_first_0:                 episode reward: 15.6500,                 loss: 0.2193
env0_second_0:                 episode reward: -15.6500,                 loss: 0.7664
env1_first_0:                 episode reward: 18.4000,                 loss: nan
env1_second_0:                 episode reward: -18.4000,                 loss: nan
Episode: 6861/30000 (22.8700%),                 avg. length: 1779.95,                last time consumption/overall running time: 224.4830s / 66673.0117 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.4042
env0_second_0:                 episode reward: -0.0500,                 loss: 1.4954
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6881/30000 (22.9367%),                 avg. length: 1822.9,                last time consumption/overall running time: 221.4159s / 66894.4276 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.2459
env0_second_0:                 episode reward: 7.5000,                 loss: 1.4849
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 6901/30000 (23.0033%),                 avg. length: 1677.7,                last time consumption/overall running time: 204.9034s / 67099.3310 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1943
env0_second_0:                 episode reward: 13.3000,                 loss: 1.3727
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6921/30000 (23.0700%),                 avg. length: 1844.35,                last time consumption/overall running time: 234.6177s / 67333.9487 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1809
env0_second_0:                 episode reward: 12.2000,                 loss: 2.2441
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 6941/30000 (23.1367%),                 avg. length: 1855.7,                last time consumption/overall running time: 236.8260s / 67570.7747 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3096
env0_second_0:                 episode reward: -1.0000,                 loss: 2.1498
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6961/30000 (23.2033%),                 avg. length: 1709.1,                last time consumption/overall running time: 210.7129s / 67781.4876 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1480
env0_second_0:                 episode reward: 15.2000,                 loss: 1.6611
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6981/30000 (23.2700%),                 avg. length: 1768.95,                last time consumption/overall running time: 222.3261s / 68003.8137 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.1480
env0_second_0:                 episode reward: 16.1000,                 loss: 1.5899
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 7001/30000 (23.3367%),                 avg. length: 1875.1,                last time consumption/overall running time: 233.3093s / 68237.1229 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1617
env0_second_0:                 episode reward: 15.4500,                 loss: 1.6069
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 7021/30000 (23.4033%),                 avg. length: 1828.7,                last time consumption/overall running time: 228.5633s / 68465.6862 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1378
env0_second_0:                 episode reward: 15.5500,                 loss: 1.4550
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 7041/30000 (23.4700%),                 avg. length: 1985.75,                last time consumption/overall running time: 250.4148s / 68716.1009 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1413
env0_second_0:                 episode reward: 15.5500,                 loss: 1.4207
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 7061/30000 (23.5367%),                 avg. length: 1902.25,                last time consumption/overall running time: 239.8043s / 68955.9052 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1458
env0_second_0:                 episode reward: 14.7500,                 loss: 3.2147
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 7081/30000 (23.6033%),                 avg. length: 2299.35,                last time consumption/overall running time: 272.0371s / 69227.9423 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1275
env0_second_0:                 episode reward: 13.4000,                 loss: 1.5004
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 7101/30000 (23.6700%),                 avg. length: 2373.15,                last time consumption/overall running time: 267.1321s / 69495.0744 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1456
env0_second_0:                 episode reward: 11.8000,                 loss: 1.6290
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 7121/30000 (23.7367%),                 avg. length: 2447.75,                last time consumption/overall running time: 295.6568s / 69790.7311 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1180
env0_second_0:                 episode reward: 13.3500,                 loss: 1.4299
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 7141/30000 (23.8033%),                 avg. length: 2246.0,                last time consumption/overall running time: 282.3474s / 70073.0785 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0907
env0_second_0:                 episode reward: 14.9000,                 loss: 1.4852
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 7161/30000 (23.8700%),                 avg. length: 2131.0,                last time consumption/overall running time: 263.6301s / 70336.7086 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.3341
env0_second_0:                 episode reward: 7.9000,                 loss: 2.3128
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 7181/30000 (23.9367%),                 avg. length: 2151.8,                last time consumption/overall running time: 262.5241s / 70599.2327 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0953
env0_second_0:                 episode reward: 15.5000,                 loss: 1.5243
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 7201/30000 (24.0033%),                 avg. length: 2045.85,                last time consumption/overall running time: 259.6999s / 70858.9325 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.3318
env0_second_0:                 episode reward: 9.1000,                 loss: 1.9142
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 7221/30000 (24.0700%),                 avg. length: 2401.9,                last time consumption/overall running time: 294.0601s / 71152.9926 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1300
env0_second_0:                 episode reward: 13.3500,                 loss: 1.5435
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 7241/30000 (24.1367%),                 avg. length: 2124.7,                last time consumption/overall running time: 274.6558s / 71427.6484 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1161
env0_second_0:                 episode reward: 15.4500,                 loss: 1.3883
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 7261/30000 (24.2033%),                 avg. length: 2351.55,                last time consumption/overall running time: 295.1290s / 71722.7774 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.1217
env0_second_0:                 episode reward: 10.9500,                 loss: 1.3718
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 7281/30000 (24.2700%),                 avg. length: 2452.2,                last time consumption/overall running time: 306.5970s / 72029.3744 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1092
env0_second_0:                 episode reward: 12.7500,                 loss: 1.3423
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 7301/30000 (24.3367%),                 avg. length: 2127.75,                last time consumption/overall running time: 264.5722s / 72293.9466 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1696
env0_second_0:                 episode reward: 12.0500,                 loss: 1.6703
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 7321/30000 (24.4033%),                 avg. length: 2464.9,                last time consumption/overall running time: 309.6771s / 72603.6237 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.1046
env0_second_0:                 episode reward: 13.8500,                 loss: 2.3850
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 7341/30000 (24.4700%),                 avg. length: 2454.85,                last time consumption/overall running time: 306.9627s / 72910.5864 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0665
env0_second_0:                 episode reward: 14.2500,                 loss: 2.1025
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 7361/30000 (24.5367%),                 avg. length: 2730.95,                last time consumption/overall running time: 321.8949s / 73232.4812 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0628
env0_second_0:                 episode reward: 13.1000,                 loss: 2.4977
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 7381/30000 (24.6033%),                 avg. length: 2593.1,                last time consumption/overall running time: 324.0455s / 73556.5267 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0795
env0_second_0:                 episode reward: 14.2500,                 loss: 1.6167
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 7401/30000 (24.6700%),                 avg. length: 2562.05,                last time consumption/overall running time: 321.2030s / 73877.7297 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0610
env0_second_0:                 episode reward: 15.7000,                 loss: 1.2987
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 7421/30000 (24.7367%),                 avg. length: 2553.95,                last time consumption/overall running time: 321.9980s / 74199.7277 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0844
env0_second_0:                 episode reward: 14.1500,                 loss: 1.3700
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 7441/30000 (24.8033%),                 avg. length: 2734.6,                last time consumption/overall running time: 342.6780s / 74542.4057 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1044
env0_second_0:                 episode reward: 13.7500,                 loss: 1.3747
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 7461/30000 (24.8700%),                 avg. length: 2645.35,                last time consumption/overall running time: 320.8783s / 74863.2840 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.1207
env0_second_0:                 episode reward: 12.3500,                 loss: 1.4781
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7481/30000 (24.9367%),                 avg. length: 3009.45,                last time consumption/overall running time: 320.6155s / 75183.8995 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.1046
env0_second_0:                 episode reward: 9.9500,                 loss: 1.3095
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 7501/30000 (25.0033%),                 avg. length: 2847.85,                last time consumption/overall running time: 334.8794s / 75518.7789 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0963
env0_second_0:                 episode reward: 13.5500,                 loss: 1.2953
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 7521/30000 (25.0700%),                 avg. length: 2556.4,                last time consumption/overall running time: 320.2569s / 75839.0359 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1161
env0_second_0:                 episode reward: 12.9500,                 loss: 1.3461
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 7541/30000 (25.1367%),                 avg. length: 2423.95,                last time consumption/overall running time: 304.3490s / 76143.3848 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1214
env0_second_0:                 episode reward: 13.7500,                 loss: 1.3859
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7561/30000 (25.2033%),                 avg. length: 2660.45,                last time consumption/overall running time: 326.8017s / 76470.1866 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0740
env0_second_0:                 episode reward: 14.2000,                 loss: 1.3092
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 7581/30000 (25.2700%),                 avg. length: 2655.8,                last time consumption/overall running time: 320.0874s / 76790.2740 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1123
env0_second_0:                 episode reward: 14.2000,                 loss: 1.9341
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 7601/30000 (25.3367%),                 avg. length: 2419.0,                last time consumption/overall running time: 302.5761s / 77092.8501 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.3162
env0_second_0:                 episode reward: 11.2500,                 loss: 2.5340
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 7621/30000 (25.4033%),                 avg. length: 2498.2,                last time consumption/overall running time: 314.1079s / 77406.9579 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1245
env0_second_0:                 episode reward: 14.5000,                 loss: 2.1887
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 7641/30000 (25.4700%),                 avg. length: 3007.5,                last time consumption/overall running time: 375.5365s / 77782.4944 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0852
env0_second_0:                 episode reward: 13.2500,                 loss: 1.7856
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 7661/30000 (25.5367%),                 avg. length: 2902.25,                last time consumption/overall running time: 359.4487s / 78141.9432 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0867
env0_second_0:                 episode reward: 15.0000,                 loss: 1.7519
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 7681/30000 (25.6033%),                 avg. length: 2647.7,                last time consumption/overall running time: 333.8767s / 78475.8199 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1194
env0_second_0:                 episode reward: 12.6500,                 loss: 1.9239
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 7701/30000 (25.6700%),                 avg. length: 3105.55,                last time consumption/overall running time: 390.0703s / 78865.8902 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.1254
env0_second_0:                 episode reward: 8.7500,                 loss: 2.0089
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 7721/30000 (25.7367%),                 avg. length: 2889.25,                last time consumption/overall running time: 364.9317s / 79230.8219 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1294
env0_second_0:                 episode reward: 12.6500,                 loss: 1.7811
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 7741/30000 (25.8033%),                 avg. length: 3047.4,                last time consumption/overall running time: 380.0071s / 79610.8290 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1252
env0_second_0:                 episode reward: 10.6000,                 loss: 1.5752
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7761/30000 (25.8700%),                 avg. length: 2040.05,                last time consumption/overall running time: 256.2598s / 79867.0888 s
env0_first_0:                 episode reward: 7.3000,                 loss: 0.4634
env0_second_0:                 episode reward: -7.3000,                 loss: 2.0959
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 7781/30000 (25.9367%),                 avg. length: 2726.05,                last time consumption/overall running time: 330.1381s / 80197.2269 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.1578
env0_second_0:                 episode reward: 9.9500,                 loss: 1.6365
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7801/30000 (26.0033%),                 avg. length: 2559.9,                last time consumption/overall running time: 321.0769s / 80518.3038 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1531
env0_second_0:                 episode reward: 9.6000,                 loss: 1.6478
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 7821/30000 (26.0700%),                 avg. length: 2810.2,                last time consumption/overall running time: 344.2292s / 80862.5330 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1408
env0_second_0:                 episode reward: 9.6000,                 loss: 1.6134
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 7841/30000 (26.1367%),                 avg. length: 2716.1,                last time consumption/overall running time: 306.1294s / 81168.6623 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1018
env0_second_0:                 episode reward: 12.6000,                 loss: 1.4908
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 7861/30000 (26.2033%),                 avg. length: 2921.95,                last time consumption/overall running time: 351.1675s / 81519.8298 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1383
env0_second_0:                 episode reward: 13.0000,                 loss: 1.4696
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 7881/30000 (26.2700%),                 avg. length: 2664.4,                last time consumption/overall running time: 318.0437s / 81837.8735 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1391
env0_second_0:                 episode reward: 11.8500,                 loss: 1.5197
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7901/30000 (26.3367%),                 avg. length: 2693.75,                last time consumption/overall running time: 319.2835s / 82157.1570 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1507
env0_second_0:                 episode reward: 10.6000,                 loss: 1.5862
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7921/30000 (26.4033%),                 avg. length: 2493.2,                last time consumption/overall running time: 287.7284s / 82444.8853 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.3696
env0_second_0:                 episode reward: 8.5000,                 loss: 2.0030
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 7941/30000 (26.4700%),                 avg. length: 2673.6,                last time consumption/overall running time: 334.9476s / 82779.8329 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.1200
env0_second_0:                 episode reward: 10.9500,                 loss: 1.7686
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 7961/30000 (26.5367%),                 avg. length: 3094.9,                last time consumption/overall running time: 381.5223s / 83161.3552 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0899
env0_second_0:                 episode reward: 9.2500,                 loss: 1.0192
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7981/30000 (26.6033%),                 avg. length: 3184.85,                last time consumption/overall running time: 391.9076s / 83553.2629 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0939
env0_second_0:                 episode reward: 8.9000,                 loss: 1.1089
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8001/30000 (26.6700%),                 avg. length: 2966.15,                last time consumption/overall running time: 371.2012s / 83924.4640 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.1145
env0_second_0:                 episode reward: 8.7500,                 loss: 1.1866
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 8021/30000 (26.7367%),                 avg. length: 3050.15,                last time consumption/overall running time: 378.8437s / 84303.3077 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.1082
env0_second_0:                 episode reward: 10.8000,                 loss: 1.0873
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 8041/30000 (26.8033%),                 avg. length: 2850.05,                last time consumption/overall running time: 349.7313s / 84653.0390 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1102
env0_second_0:                 episode reward: 12.0500,                 loss: 0.8716
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 8061/30000 (26.8700%),                 avg. length: 2978.45,                last time consumption/overall running time: 374.4552s / 85027.4941 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1021
env0_second_0:                 episode reward: 12.7000,                 loss: 1.0751
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8081/30000 (26.9367%),                 avg. length: 2963.55,                last time consumption/overall running time: 371.6035s / 85399.0976 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1228
env0_second_0:                 episode reward: 12.0000,                 loss: 1.0541
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 8101/30000 (27.0033%),                 avg. length: 3371.5,                last time consumption/overall running time: 420.3142s / 85819.4118 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.1235
env0_second_0:                 episode reward: 9.1000,                 loss: 0.9279
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 8121/30000 (27.0700%),                 avg. length: 3157.3,                last time consumption/overall running time: 390.4244s / 86209.8362 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0892
env0_second_0:                 episode reward: 11.9000,                 loss: 1.1643
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 8141/30000 (27.1367%),                 avg. length: 3270.2,                last time consumption/overall running time: 378.4815s / 86588.3177 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0976
env0_second_0:                 episode reward: 9.3500,                 loss: 1.2558
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8161/30000 (27.2033%),                 avg. length: 3249.4,                last time consumption/overall running time: 386.6473s / 86974.9650 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.1250
env0_second_0:                 episode reward: 8.1500,                 loss: 1.0506
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 8181/30000 (27.2700%),                 avg. length: 3357.95,                last time consumption/overall running time: 416.5000s / 87391.4650 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.1109
env0_second_0:                 episode reward: 8.4000,                 loss: 1.0274
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8201/30000 (27.3367%),                 avg. length: 3400.75,                last time consumption/overall running time: 424.6521s / 87816.1171 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.1169
env0_second_0:                 episode reward: 8.3000,                 loss: 0.9715
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8221/30000 (27.4033%),                 avg. length: 3257.65,                last time consumption/overall running time: 410.6360s / 88226.7531 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0961
env0_second_0:                 episode reward: 10.7500,                 loss: 0.8451
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 8241/30000 (27.4700%),                 avg. length: 3336.15,                last time consumption/overall running time: 416.0464s / 88642.7995 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0785
env0_second_0:                 episode reward: 11.1000,                 loss: 0.8273
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8261/30000 (27.5367%),                 avg. length: 3164.8,                last time consumption/overall running time: 395.5310s / 89038.3305 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.1314
env0_second_0:                 episode reward: 8.9500,                 loss: 0.9364
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8281/30000 (27.6033%),                 avg. length: 3069.65,                last time consumption/overall running time: 384.9849s / 89423.3154 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0836
env0_second_0:                 episode reward: 11.0500,                 loss: 1.1425
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 8301/30000 (27.6700%),                 avg. length: 3234.05,                last time consumption/overall running time: 389.7025s / 89813.0179 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.1180
env0_second_0:                 episode reward: 9.1500,                 loss: 1.3009
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 8321/30000 (27.7367%),                 avg. length: 3379.35,                last time consumption/overall running time: 421.8340s / 90234.8519 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.1214
env0_second_0:                 episode reward: 11.4000,                 loss: 2.0375
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 8341/30000 (27.8033%),                 avg. length: 1024.6,                last time consumption/overall running time: 133.2073s / 90368.0592 s
env0_first_0:                 episode reward: 15.5500,                 loss: 0.4055
env0_second_0:                 episode reward: -15.5500,                 loss: 2.7946
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 8361/30000 (27.8700%),                 avg. length: 751.2,                last time consumption/overall running time: 95.9707s / 90464.0299 s
env0_first_0:                 episode reward: 14.9500,                 loss: 0.1957
env0_second_0:                 episode reward: -14.9500,                 loss: 1.4543
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 8381/30000 (27.9367%),                 avg. length: 2016.9,                last time consumption/overall running time: 237.9183s / 90701.9482 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.5141
env0_second_0:                 episode reward: 2.3000,                 loss: 2.4336
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8401/30000 (28.0033%),                 avg. length: 2536.6,                last time consumption/overall running time: 318.2992s / 91020.2474 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.2424
env0_second_0:                 episode reward: 2.7000,                 loss: 1.5785
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8421/30000 (28.0700%),                 avg. length: 2672.25,                last time consumption/overall running time: 334.2251s / 91354.4725 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1918
env0_second_0:                 episode reward: 4.5000,                 loss: 2.6744
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 8441/30000 (28.1367%),                 avg. length: 2457.6,                last time consumption/overall running time: 304.5196s / 91658.9921 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2214
env0_second_0:                 episode reward: 6.4500,                 loss: 2.1780
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 8461/30000 (28.2033%),                 avg. length: 2366.5,                last time consumption/overall running time: 290.0849s / 91949.0770 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.2015
env0_second_0:                 episode reward: 7.1000,                 loss: 1.4117
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 8481/30000 (28.2700%),                 avg. length: 2461.1,                last time consumption/overall running time: 299.0759s / 92248.1530 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.1684
env0_second_0:                 episode reward: 10.2500,                 loss: 1.1542
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 8501/30000 (28.3367%),                 avg. length: 2401.35,                last time consumption/overall running time: 303.5096s / 92551.6626 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.2121
env0_second_0:                 episode reward: 11.1500,                 loss: 1.1374
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 8521/30000 (28.4033%),                 avg. length: 2262.8,                last time consumption/overall running time: 284.3100s / 92835.9726 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.3593
env0_second_0:                 episode reward: 5.7000,                 loss: 1.3939
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 8541/30000 (28.4700%),                 avg. length: 1741.15,                last time consumption/overall running time: 220.0104s / 93055.9829 s
env0_first_0:                 episode reward: 8.9000,                 loss: 0.2997
env0_second_0:                 episode reward: -8.9000,                 loss: 1.5369
env1_first_0:                 episode reward: 8.5500,                 loss: nan
env1_second_0:                 episode reward: -8.5500,                 loss: nan
Episode: 8561/30000 (28.5367%),                 avg. length: 791.2,                last time consumption/overall running time: 105.0596s / 93161.0425 s
env0_first_0:                 episode reward: 19.3500,                 loss: 0.2828
env0_second_0:                 episode reward: -19.3500,                 loss: 1.1562
env1_first_0:                 episode reward: 18.3500,                 loss: nan
env1_second_0:                 episode reward: -18.3500,                 loss: nan
Episode: 8581/30000 (28.6033%),                 avg. length: 777.1,                last time consumption/overall running time: 95.3606s / 93256.4031 s
env0_first_0:                 episode reward: 12.3000,                 loss: 0.4870
env0_second_0:                 episode reward: -12.3000,                 loss: 1.6252
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 8601/30000 (28.6700%),                 avg. length: 824.8,                last time consumption/overall running time: 103.4494s / 93359.8525 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.4788
env0_second_0:                 episode reward: 14.4500,                 loss: 1.8073
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8621/30000 (28.7367%),                 avg. length: 988.4,                last time consumption/overall running time: 129.4357s / 93489.2882 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.6952
env0_second_0:                 episode reward: 1.8000,                 loss: 2.6859
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 8641/30000 (28.8033%),                 avg. length: 1260.95,                last time consumption/overall running time: 157.0240s / 93646.3122 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.5048
env0_second_0:                 episode reward: 10.4000,                 loss: 1.5743
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 8661/30000 (28.8700%),                 avg. length: 1280.55,                last time consumption/overall running time: 164.2400s / 93810.5521 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.5620
env0_second_0:                 episode reward: 13.8500,                 loss: 1.5458
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 8681/30000 (28.9367%),                 avg. length: 1352.5,                last time consumption/overall running time: 173.4686s / 93984.0207 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.4609
env0_second_0:                 episode reward: 12.4500,                 loss: 1.2326
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 8701/30000 (29.0033%),                 avg. length: 1498.3,                last time consumption/overall running time: 191.5311s / 94175.5518 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2639
env0_second_0:                 episode reward: 14.1500,                 loss: 1.4886
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 8721/30000 (29.0700%),                 avg. length: 1597.15,                last time consumption/overall running time: 202.2988s / 94377.8506 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.4012
env0_second_0:                 episode reward: 11.0500,                 loss: 1.8052
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 8741/30000 (29.1367%),                 avg. length: 1712.45,                last time consumption/overall running time: 217.1155s / 94594.9660 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.2762
env0_second_0:                 episode reward: 14.3500,                 loss: 1.6690
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 8761/30000 (29.2033%),                 avg. length: 1396.75,                last time consumption/overall running time: 178.9932s / 94773.9593 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.1939
env0_second_0:                 episode reward: 16.6500,                 loss: 1.4051
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 8781/30000 (29.2700%),                 avg. length: 1433.6,                last time consumption/overall running time: 185.4458s / 94959.4050 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.3084
env0_second_0:                 episode reward: 15.8500,                 loss: 1.7127
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 8801/30000 (29.3367%),                 avg. length: 1013.35,                last time consumption/overall running time: 134.6328s / 95094.0378 s
env0_first_0:                 episode reward: 9.3500,                 loss: 0.4374
env0_second_0:                 episode reward: -9.3500,                 loss: 2.3314
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 8821/30000 (29.4033%),                 avg. length: 804.85,                last time consumption/overall running time: 106.5438s / 95200.5816 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3112
env0_second_0:                 episode reward: 1.3500,                 loss: 1.5421
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8841/30000 (29.4700%),                 avg. length: 808.7,                last time consumption/overall running time: 106.9461s / 95307.5278 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.2051
env0_second_0:                 episode reward: 17.8500,                 loss: 0.9754
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 8861/30000 (29.5367%),                 avg. length: 762.4,                last time consumption/overall running time: 102.9218s / 95410.4496 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.2166
env0_second_0:                 episode reward: 14.7000,                 loss: 1.3428
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 8881/30000 (29.6033%),                 avg. length: 779.45,                last time consumption/overall running time: 104.7951s / 95515.2447 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1493
env0_second_0:                 episode reward: 20.1000,                 loss: 1.3893
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 8901/30000 (29.6700%),                 avg. length: 786.65,                last time consumption/overall running time: 104.5770s / 95619.8218 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.0815
env0_second_0:                 episode reward: 17.9000,                 loss: 1.2842
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 8921/30000 (29.7367%),                 avg. length: 786.0,                last time consumption/overall running time: 98.3283s / 95718.1501 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.2151
env0_second_0:                 episode reward: 16.1000,                 loss: 0.9522
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 8941/30000 (29.8033%),                 avg. length: 751.7,                last time consumption/overall running time: 97.1184s / 95815.2685 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4126
env0_second_0:                 episode reward: -4.7000,                 loss: 2.2441
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 8961/30000 (29.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 94.2822s / 95909.5507 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1096
env0_second_0:                 episode reward: -21.0000,                 loss: 1.6131
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8981/30000 (29.9367%),                 avg. length: 809.3,                last time consumption/overall running time: 102.9841s / 96012.5349 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.2686
env0_second_0:                 episode reward: 11.4500,                 loss: 1.0842
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 9001/30000 (30.0033%),                 avg. length: 784.65,                last time consumption/overall running time: 103.0407s / 96115.5756 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0880
env0_second_0:                 episode reward: 11.5500,                 loss: 1.0858
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 9021/30000 (30.0700%),                 avg. length: 756.35,                last time consumption/overall running time: 101.2199s / 96216.7955 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.1050
env0_second_0:                 episode reward: 16.7000,                 loss: 1.3257
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 9041/30000 (30.1367%),                 avg. length: 758.5,                last time consumption/overall running time: 97.3159s / 96314.1114 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.1445
env0_second_0:                 episode reward: 17.4500,                 loss: 1.3754
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 9061/30000 (30.2033%),                 avg. length: 754.6,                last time consumption/overall running time: 88.0347s / 96402.1461 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1816
env0_second_0:                 episode reward: 12.2000,                 loss: 1.5894
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 9081/30000 (30.2700%),                 avg. length: 754.1,                last time consumption/overall running time: 88.2114s / 96490.3575 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2927
env0_second_0:                 episode reward: 14.0000,                 loss: 1.5949
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 9101/30000 (30.3367%),                 avg. length: 760.05,                last time consumption/overall running time: 97.7290s / 96588.0864 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0902
env0_second_0:                 episode reward: 16.6500,                 loss: 1.3687
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 9121/30000 (30.4033%),                 avg. length: 816.4,                last time consumption/overall running time: 93.4408s / 96681.5273 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.3543
env0_second_0:                 episode reward: 13.8500,                 loss: 1.5690
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 9141/30000 (30.4700%),                 avg. length: 766.65,                last time consumption/overall running time: 96.8107s / 96778.3379 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.2759
env0_second_0:                 episode reward: 14.7500,                 loss: 1.3775
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 9161/30000 (30.5367%),                 avg. length: 816.3,                last time consumption/overall running time: 108.6395s / 96886.9774 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.4205
env0_second_0:                 episode reward: 11.6500,                 loss: 2.5041
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 9181/30000 (30.6033%),                 avg. length: 801.0,                last time consumption/overall running time: 106.3016s / 96993.2789 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.2361
env0_second_0:                 episode reward: 15.0500,                 loss: 1.8285
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 9201/30000 (30.6700%),                 avg. length: 797.7,                last time consumption/overall running time: 105.9338s / 97099.2127 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.1885
env0_second_0:                 episode reward: 17.2500,                 loss: 2.7019
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 9221/30000 (30.7367%),                 avg. length: 781.45,                last time consumption/overall running time: 102.4025s / 97201.6152 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.1135
env0_second_0:                 episode reward: 19.3500,                 loss: 1.5271
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 9241/30000 (30.8033%),                 avg. length: 773.25,                last time consumption/overall running time: 102.8948s / 97304.5100 s
env0_first_0:                 episode reward: -19.7000,                 loss: 0.0460
env0_second_0:                 episode reward: 19.7000,                 loss: 1.6522
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 9261/30000 (30.8700%),                 avg. length: 759.05,                last time consumption/overall running time: 99.2958s / 97403.8058 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.4587
env0_second_0:                 episode reward: 5.6500,                 loss: 2.6143
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 9281/30000 (30.9367%),                 avg. length: 764.0,                last time consumption/overall running time: 93.5798s / 97497.3856 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0759
env0_second_0:                 episode reward: 20.2500,                 loss: 1.3956
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 9301/30000 (31.0033%),                 avg. length: 763.0,                last time consumption/overall running time: 94.6082s / 97591.9938 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0082
env0_second_0:                 episode reward: 20.7000,                 loss: 1.7073
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 9321/30000 (31.0700%),                 avg. length: 787.45,                last time consumption/overall running time: 104.1613s / 97696.1551 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.2002
env0_second_0:                 episode reward: 18.8500,                 loss: 1.4892
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 9341/30000 (31.1367%),                 avg. length: 763.65,                last time consumption/overall running time: 101.5771s / 97797.7321 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0057
env0_second_0:                 episode reward: 20.5500,                 loss: 1.5069
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 9361/30000 (31.2033%),                 avg. length: 773.05,                last time consumption/overall running time: 102.8141s / 97900.5463 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.1570
env0_second_0:                 episode reward: 17.2000,                 loss: 1.5764
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 9381/30000 (31.2700%),                 avg. length: 761.85,                last time consumption/overall running time: 101.2470s / 98001.7932 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.1711
env0_second_0:                 episode reward: 16.4000,                 loss: 1.4783
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 9401/30000 (31.3367%),                 avg. length: 762.15,                last time consumption/overall running time: 101.2942s / 98103.0874 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.2992
env0_second_0:                 episode reward: -5.1500,                 loss: 1.3383
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 9421/30000 (31.4033%),                 avg. length: 728.05,                last time consumption/overall running time: 96.7920s / 98199.8794 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1300
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9603
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9441/30000 (31.4700%),                 avg. length: 728.1,                last time consumption/overall running time: 97.4483s / 98297.3277 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1150
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9835
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9461/30000 (31.5367%),                 avg. length: 728.7,                last time consumption/overall running time: 98.3658s / 98395.6935 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0734
env0_second_0:                 episode reward: -20.8500,                 loss: 1.2863
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 9481/30000 (31.6033%),                 avg. length: 728.35,                last time consumption/overall running time: 97.6759s / 98493.3694 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0884
env0_second_0:                 episode reward: -20.9000,                 loss: 1.0019
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 9501/30000 (31.6700%),                 avg. length: 728.1,                last time consumption/overall running time: 97.2447s / 98590.6141 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0929
env0_second_0:                 episode reward: -20.8000,                 loss: 1.5021
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 9521/30000 (31.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.9380s / 98687.5521 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1550
env0_second_0:                 episode reward: -21.0000,                 loss: 1.2942
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9541/30000 (31.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.7036s / 98785.2557 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1058
env0_second_0:                 episode reward: -21.0000,                 loss: 2.5560
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9561/30000 (31.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.6630s / 98882.9188 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1365
env0_second_0:                 episode reward: -21.0000,                 loss: 1.6229
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9581/30000 (31.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.3366s / 98980.2553 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1321
env0_second_0:                 episode reward: -21.0000,                 loss: 1.9832
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9601/30000 (32.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 95.3580s / 99075.6134 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1295
env0_second_0:                 episode reward: -21.0000,                 loss: 1.5114
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9621/30000 (32.0700%),                 avg. length: 734.5,                last time consumption/overall running time: 93.9753s / 99169.5887 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1423
env0_second_0:                 episode reward: -20.8000,                 loss: 1.3359
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 9641/30000 (32.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 84.9619s / 99254.5505 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1554
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1658
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9661/30000 (32.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4338s / 99351.9844 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0529
env0_second_0:                 episode reward: -21.0000,                 loss: 1.1239
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9681/30000 (32.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4102s / 99449.3946 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.1264
env0_second_0:                 episode reward: -20.9000,                 loss: 1.4754
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9701/30000 (32.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 92.4329s / 99541.8275 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0467
env0_second_0:                 episode reward: -20.9500,                 loss: 2.3155
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9721/30000 (32.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 84.5437s / 99626.3712 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0890
env0_second_0:                 episode reward: -20.9500,                 loss: 1.7296
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 9741/30000 (32.4700%),                 avg. length: 728.55,                last time consumption/overall running time: 88.6062s / 99714.9774 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1079
env0_second_0:                 episode reward: -20.7000,                 loss: 1.6459
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 9761/30000 (32.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.5673s / 99812.5447 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0600
env0_second_0:                 episode reward: -21.0000,                 loss: 2.0984
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9781/30000 (32.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.1483s / 99909.6929 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0650
env0_second_0:                 episode reward: -21.0000,                 loss: 2.4113
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9801/30000 (32.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 88.3817s / 99998.0747 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0437
env0_second_0:                 episode reward: -21.0000,                 loss: 5.5630
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9821/30000 (32.7367%),                 avg. length: 757.25,                last time consumption/overall running time: 96.8608s / 100094.9354 s
env0_first_0:                 episode reward: 20.1000,                 loss: 0.2052
env0_second_0:                 episode reward: -20.1000,                 loss: 1.8727
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 9841/30000 (32.8033%),                 avg. length: 728.05,                last time consumption/overall running time: 84.2954s / 100179.2308 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0433
env0_second_0:                 episode reward: -21.0000,                 loss: 2.9367
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 9861/30000 (32.8700%),                 avg. length: 728.2,                last time consumption/overall running time: 93.8297s / 100273.0604 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0763
env0_second_0:                 episode reward: -20.7500,                 loss: 3.5775
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 9881/30000 (32.9367%),                 avg. length: 728.65,                last time consumption/overall running time: 97.3216s / 100370.3821 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0631
env0_second_0:                 episode reward: -20.5500,                 loss: 3.8575
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 9901/30000 (33.0033%),                 avg. length: 728.65,                last time consumption/overall running time: 97.5029s / 100467.8850 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.1270
env0_second_0:                 episode reward: -20.6500,                 loss: 4.0134
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 9921/30000 (33.0700%),                 avg. length: 730.45,                last time consumption/overall running time: 97.6825s / 100565.5675 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.1309
env0_second_0:                 episode reward: -20.3500,                 loss: 2.7342
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 9941/30000 (33.1367%),                 avg. length: 728.5,                last time consumption/overall running time: 97.4418s / 100663.0093 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0030
env0_second_0:                 episode reward: -20.7500,                 loss: 2.5167
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 9961/30000 (33.2033%),                 avg. length: 769.85,                last time consumption/overall running time: 102.5156s / 100765.5249 s
env0_first_0:                 episode reward: 11.8000,                 loss: 0.1464
env0_second_0:                 episode reward: -11.8000,                 loss: 1.7668
env1_first_0:                 episode reward: 13.4500,                 loss: nan
env1_second_0:                 episode reward: -13.4500,                 loss: nan
Episode: 9981/30000 (33.2700%),                 avg. length: 806.15,                last time consumption/overall running time: 106.2229s / 100871.7478 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.2408
env0_second_0:                 episode reward: 16.9000,                 loss: 1.2749
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 10001/30000 (33.3367%),                 avg. length: 751.7,                last time consumption/overall running time: 99.9494s / 100971.6973 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1998
env0_second_0:                 episode reward: 2.7000,                 loss: 1.4131
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 10021/30000 (33.4033%),                 avg. length: 1222.05,                last time consumption/overall running time: 157.7081s / 101129.4054 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.6949
env0_second_0:                 episode reward: 4.3500,                 loss: 3.5701
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 10041/30000 (33.4700%),                 avg. length: 976.1,                last time consumption/overall running time: 127.0690s / 101256.4744 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.4835
env0_second_0:                 episode reward: 13.2500,                 loss: 2.6056
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 10061/30000 (33.5367%),                 avg. length: 896.95,                last time consumption/overall running time: 118.1979s / 101374.6723 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.3426
env0_second_0:                 episode reward: 16.3500,                 loss: 2.1228
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 10081/30000 (33.6033%),                 avg. length: 796.0,                last time consumption/overall running time: 105.4663s / 101480.1386 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.2074
env0_second_0:                 episode reward: 19.3500,                 loss: 1.7188
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 10101/30000 (33.6700%),                 avg. length: 963.0,                last time consumption/overall running time: 126.5946s / 101606.7332 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.3630
env0_second_0:                 episode reward: 14.8500,                 loss: 2.1619
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 10121/30000 (33.7367%),                 avg. length: 1912.85,                last time consumption/overall running time: 234.2326s / 101840.9658 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.4278
env0_second_0:                 episode reward: 2.9500,                 loss: 2.5847
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 10141/30000 (33.8033%),                 avg. length: 2099.85,                last time consumption/overall running time: 250.1873s / 102091.1531 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.2702
env0_second_0:                 episode reward: 9.1000,                 loss: 2.1599
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 10161/30000 (33.8700%),                 avg. length: 2102.0,                last time consumption/overall running time: 264.2429s / 102355.3960 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.2133
env0_second_0:                 episode reward: 12.0000,                 loss: 1.3402
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 10181/30000 (33.9367%),                 avg. length: 2271.35,                last time consumption/overall running time: 288.1936s / 102643.5896 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.2324
env0_second_0:                 episode reward: 10.8000,                 loss: 1.3424
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 10201/30000 (34.0033%),                 avg. length: 2133.45,                last time consumption/overall running time: 271.0380s / 102914.6276 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.2275
env0_second_0:                 episode reward: 12.8000,                 loss: 1.4076
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 10221/30000 (34.0700%),                 avg. length: 2155.4,                last time consumption/overall running time: 272.5142s / 103187.1418 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1851
env0_second_0:                 episode reward: 13.2000,                 loss: 1.3251
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 10241/30000 (34.1367%),                 avg. length: 2204.95,                last time consumption/overall running time: 277.3413s / 103464.4831 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2289
env0_second_0:                 episode reward: 11.4000,                 loss: 1.2945
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 10261/30000 (34.2033%),                 avg. length: 2379.5,                last time consumption/overall running time: 296.4012s / 103760.8843 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.2246
env0_second_0:                 episode reward: 10.2500,                 loss: 1.3230
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 10281/30000 (34.2700%),                 avg. length: 2122.3,                last time consumption/overall running time: 265.1646s / 104026.0489 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.2330
env0_second_0:                 episode reward: 12.4000,                 loss: 1.3292
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 10301/30000 (34.3367%),                 avg. length: 2289.65,                last time consumption/overall running time: 284.1885s / 104310.2375 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.2214
env0_second_0:                 episode reward: 10.7500,                 loss: 1.8739
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 10321/30000 (34.4033%),                 avg. length: 2377.95,                last time consumption/overall running time: 297.9264s / 104608.1638 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.2058
env0_second_0:                 episode reward: 10.9500,                 loss: 1.5246
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 10341/30000 (34.4700%),                 avg. length: 2185.7,                last time consumption/overall running time: 268.3095s / 104876.4733 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1906
env0_second_0:                 episode reward: 11.6000,                 loss: 2.4922
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 10361/30000 (34.5367%),                 avg. length: 2365.4,                last time consumption/overall running time: 276.4582s / 105152.9315 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.1823
env0_second_0:                 episode reward: 11.5000,                 loss: 3.3515
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 10381/30000 (34.6033%),                 avg. length: 2132.15,                last time consumption/overall running time: 245.1357s / 105398.0672 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1394
env0_second_0:                 episode reward: 13.6500,                 loss: 2.9648
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 10401/30000 (34.6700%),                 avg. length: 2211.6,                last time consumption/overall running time: 250.2381s / 105648.3053 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1049
env0_second_0:                 episode reward: 15.5500,                 loss: 2.6716
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 10421/30000 (34.7367%),                 avg. length: 2074.65,                last time consumption/overall running time: 258.2149s / 105906.5202 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0947
env0_second_0:                 episode reward: 12.7000,                 loss: 2.1729
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 10441/30000 (34.8033%),                 avg. length: 2143.55,                last time consumption/overall running time: 270.4557s / 106176.9759 s
env0_first_0:                 episode reward: -17.3500,                 loss: 0.0769
env0_second_0:                 episode reward: 17.3500,                 loss: 2.8443
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 10461/30000 (34.8700%),                 avg. length: 2050.75,                last time consumption/overall running time: 249.9399s / 106426.9158 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0734
env0_second_0:                 episode reward: 16.0000,                 loss: 1.0871
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 10481/30000 (34.9367%),                 avg. length: 1942.7,                last time consumption/overall running time: 243.1484s / 106670.0642 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.1166
env0_second_0:                 episode reward: 16.1000,                 loss: 0.4322
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 10501/30000 (35.0033%),                 avg. length: 1890.6,                last time consumption/overall running time: 209.3560s / 106879.4202 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.0905
env0_second_0:                 episode reward: 17.3000,                 loss: 0.3586
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 10521/30000 (35.0700%),                 avg. length: 1946.25,                last time consumption/overall running time: 243.2257s / 107122.6458 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0746
env0_second_0:                 episode reward: 16.5000,                 loss: 0.3116
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 10541/30000 (35.1367%),                 avg. length: 1907.0,                last time consumption/overall running time: 218.6341s / 107341.2799 s
env0_first_0:                 episode reward: -18.2500,                 loss: 0.0568
env0_second_0:                 episode reward: 18.2500,                 loss: 0.3409
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 10561/30000 (35.2033%),                 avg. length: 1831.55,                last time consumption/overall running time: 223.4248s / 107564.7047 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.3860
env0_second_0:                 episode reward: 11.4500,                 loss: 0.8009
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 10581/30000 (35.2700%),                 avg. length: 1924.4,                last time consumption/overall running time: 220.9207s / 107785.6254 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.2902
env0_second_0:                 episode reward: 11.6000,                 loss: 0.9300
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 10601/30000 (35.3367%),                 avg. length: 2056.5,                last time consumption/overall running time: 236.7258s / 108022.3512 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.1001
env0_second_0:                 episode reward: 17.7500,                 loss: 0.5668
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 10621/30000 (35.4033%),                 avg. length: 2026.45,                last time consumption/overall running time: 255.4465s / 108277.7977 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.1061
env0_second_0:                 episode reward: 14.2500,                 loss: 0.6096
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 10641/30000 (35.4700%),                 avg. length: 1871.05,                last time consumption/overall running time: 227.5257s / 108505.3235 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.1120
env0_second_0:                 episode reward: 17.0500,                 loss: 0.5440
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 10661/30000 (35.5367%),                 avg. length: 1982.3,                last time consumption/overall running time: 247.2643s / 108752.5878 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.0747
env0_second_0:                 episode reward: 18.0000,                 loss: 1.3574
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 10681/30000 (35.6033%),                 avg. length: 2012.9,                last time consumption/overall running time: 254.6146s / 109007.2024 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1665
env0_second_0:                 episode reward: 13.3500,                 loss: 0.8611
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 10701/30000 (35.6700%),                 avg. length: 967.55,                last time consumption/overall running time: 127.8177s / 109135.0201 s
env0_first_0:                 episode reward: 7.0000,                 loss: 0.4462
env0_second_0:                 episode reward: -7.0000,                 loss: 1.3140
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 10721/30000 (35.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.2483s / 109232.2684 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1747
env0_second_0:                 episode reward: -21.0000,                 loss: 0.5537
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10741/30000 (35.8033%),                 avg. length: 728.05,                last time consumption/overall running time: 97.0171s / 109329.2855 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1912
env0_second_0:                 episode reward: -20.8000,                 loss: 0.7739
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 10761/30000 (35.8700%),                 avg. length: 768.3,                last time consumption/overall running time: 102.5628s / 109431.8483 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2700
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8425
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 10781/30000 (35.9367%),                 avg. length: 767.7,                last time consumption/overall running time: 102.3816s / 109534.2299 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.2276
env0_second_0:                 episode reward: 18.5500,                 loss: 0.9127
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 10801/30000 (36.0033%),                 avg. length: 777.95,                last time consumption/overall running time: 103.0992s / 109637.3291 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.3740
env0_second_0:                 episode reward: 13.7500,                 loss: 2.1117
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 10821/30000 (36.0700%),                 avg. length: 730.2,                last time consumption/overall running time: 98.2130s / 109735.5421 s
env0_first_0:                 episode reward: 18.8000,                 loss: 0.2724
env0_second_0:                 episode reward: -18.8000,                 loss: 1.7839
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 10841/30000 (36.1367%),                 avg. length: 728.2,                last time consumption/overall running time: 98.3166s / 109833.8586 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1103
env0_second_0:                 episode reward: -20.8500,                 loss: 2.4558
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 10861/30000 (36.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.5585s / 109932.4171 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1192
env0_second_0:                 episode reward: -21.0000,                 loss: 2.2075
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 10881/30000 (36.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.1771s / 110028.5942 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1254
env0_second_0:                 episode reward: -21.0000,                 loss: 2.2739
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10901/30000 (36.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.3610s / 110124.9552 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.1256
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1408
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10921/30000 (36.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 96.5227s / 110221.4780 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0345
env0_second_0:                 episode reward: -20.9500,                 loss: 1.9700
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10941/30000 (36.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.8908s / 110318.3688 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0281
env0_second_0:                 episode reward: -20.9500,                 loss: 2.2862
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 10961/30000 (36.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 94.7588s / 110413.1275 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0213
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1126
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 10981/30000 (36.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.5436s / 110510.6711 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0142
env0_second_0:                 episode reward: -20.9500,                 loss: 3.9483
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11001/30000 (36.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 98.1790s / 110608.8501 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0168
env0_second_0:                 episode reward: -21.0000,                 loss: 1.5803
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11021/30000 (36.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 94.2186s / 110703.0688 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0400
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4109
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11041/30000 (36.8033%),                 avg. length: 728.15,                last time consumption/overall running time: 96.5007s / 110799.5695 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0236
env0_second_0:                 episode reward: -20.9000,                 loss: 0.7989
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 11061/30000 (36.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 99.7955s / 110899.3649 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0127
env0_second_0:                 episode reward: -20.9000,                 loss: 1.2976
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 11081/30000 (36.9367%),                 avg. length: 728.1,                last time consumption/overall running time: 97.8853s / 110997.2502 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0535
env0_second_0:                 episode reward: -20.8000,                 loss: 4.1629
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11101/30000 (37.0033%),                 avg. length: 740.35,                last time consumption/overall running time: 97.5516s / 111094.8018 s
env0_first_0:                 episode reward: 16.4500,                 loss: 0.1097
env0_second_0:                 episode reward: -16.4500,                 loss: 4.0164
env1_first_0:                 episode reward: 15.3000,                 loss: nan
env1_second_0:                 episode reward: -15.3000,                 loss: nan
Episode: 11121/30000 (37.0700%),                 avg. length: 761.35,                last time consumption/overall running time: 98.3073s / 111193.1090 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2722
env0_second_0:                 episode reward: 6.4500,                 loss: 5.8215
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 11141/30000 (37.1367%),                 avg. length: 787.35,                last time consumption/overall running time: 96.0500s / 111289.1591 s
env0_first_0:                 episode reward: 11.8500,                 loss: 0.3321
env0_second_0:                 episode reward: -11.8500,                 loss: 4.7204
env1_first_0:                 episode reward: 11.3000,                 loss: nan
env1_second_0:                 episode reward: -11.3000,                 loss: nan
Episode: 11161/30000 (37.2033%),                 avg. length: 1416.0,                last time consumption/overall running time: 161.0163s / 111450.1754 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.6074
env0_second_0:                 episode reward: -2.8000,                 loss: 5.5038
env1_first_0:                 episode reward: 7.2500,                 loss: nan
env1_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 11181/30000 (37.2700%),                 avg. length: 1494.75,                last time consumption/overall running time: 189.2613s / 111639.4366 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.4484
env0_second_0:                 episode reward: 6.1000,                 loss: 2.8495
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 11201/30000 (37.3367%),                 avg. length: 950.8,                last time consumption/overall running time: 121.8852s / 111761.3218 s
env0_first_0:                 episode reward: 15.1000,                 loss: 0.3981
env0_second_0:                 episode reward: -15.1000,                 loss: 2.0220
env1_first_0:                 episode reward: 15.7000,                 loss: nan
env1_second_0:                 episode reward: -15.7000,                 loss: nan
Episode: 11221/30000 (37.4033%),                 avg. length: 749.9,                last time consumption/overall running time: 95.6862s / 111857.0080 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0955
env0_second_0:                 episode reward: -20.4000,                 loss: 0.8989
env1_first_0:                 episode reward: 18.4500,                 loss: nan
env1_second_0:                 episode reward: -18.4500,                 loss: nan
Episode: 11241/30000 (37.4700%),                 avg. length: 741.45,                last time consumption/overall running time: 99.0587s / 111956.0667 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0482
env0_second_0:                 episode reward: -19.9000,                 loss: 1.1036
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 11261/30000 (37.5367%),                 avg. length: 728.4,                last time consumption/overall running time: 96.9458s / 112053.0125 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0747
env0_second_0:                 episode reward: -20.4500,                 loss: 0.6176
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
Episode: 11281/30000 (37.6033%),                 avg. length: 740.45,                last time consumption/overall running time: 96.7272s / 112149.7397 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.1314
env0_second_0:                 episode reward: -16.9500,                 loss: 0.3849
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
Episode: 11301/30000 (37.6700%),                 avg. length: 761.95,                last time consumption/overall running time: 94.1708s / 112243.9105 s
env0_first_0:                 episode reward: 17.5000,                 loss: 0.2094
env0_second_0:                 episode reward: -17.5000,                 loss: 0.3630
env1_first_0:                 episode reward: 19.0500,                 loss: nan
env1_second_0:                 episode reward: -19.0500,                 loss: nan
Episode: 11321/30000 (37.7367%),                 avg. length: 731.15,                last time consumption/overall running time: 93.6089s / 112337.5194 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1264
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2607
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 11341/30000 (37.8033%),                 avg. length: 738.85,                last time consumption/overall running time: 91.4347s / 112428.9541 s
env0_first_0:                 episode reward: 16.3500,                 loss: 0.4818
env0_second_0:                 episode reward: -16.3500,                 loss: 1.9446
env1_first_0:                 episode reward: 16.4500,                 loss: nan
env1_second_0:                 episode reward: -16.4500,                 loss: nan
Episode: 11361/30000 (37.8700%),                 avg. length: 779.75,                last time consumption/overall running time: 101.7763s / 112530.7304 s
env0_first_0:                 episode reward: 18.7000,                 loss: 0.5579
env0_second_0:                 episode reward: -18.7000,                 loss: 3.2932
env1_first_0:                 episode reward: 16.5000,                 loss: nan
env1_second_0:                 episode reward: -16.5000,                 loss: nan
Episode: 11381/30000 (37.9367%),                 avg. length: 1254.0,                last time consumption/overall running time: 154.7541s / 112685.4845 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.4616
env0_second_0:                 episode reward: -2.0000,                 loss: 3.2687
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 11401/30000 (38.0033%),                 avg. length: 735.8,                last time consumption/overall running time: 94.8811s / 112780.3656 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.2700
env0_second_0:                 episode reward: -20.5500,                 loss: 1.6646
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 11421/30000 (38.0700%),                 avg. length: 729.1,                last time consumption/overall running time: 96.4933s / 112876.8589 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1242
env0_second_0:                 episode reward: -20.8000,                 loss: 0.9478
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 11441/30000 (38.1367%),                 avg. length: 728.1,                last time consumption/overall running time: 97.3181s / 112974.1770 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1962
env0_second_0:                 episode reward: -20.8000,                 loss: 2.3083
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11461/30000 (38.2033%),                 avg. length: 730.0,                last time consumption/overall running time: 96.9278s / 113071.1048 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0457
env0_second_0:                 episode reward: -20.6500,                 loss: 0.2401
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 11481/30000 (38.2700%),                 avg. length: 728.25,                last time consumption/overall running time: 97.2683s / 113168.3731 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0687
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2822
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 11501/30000 (38.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 93.2868s / 113261.6599 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0710
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4123
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11521/30000 (38.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.7114s / 113359.3713 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0651
env0_second_0:                 episode reward: -20.9500,                 loss: 0.4302
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11541/30000 (38.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.6732s / 113456.0445 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0402
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1579
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11561/30000 (38.5367%),                 avg. length: 728.05,                last time consumption/overall running time: 97.3360s / 113553.3804 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0281
env0_second_0:                 episode reward: -20.9500,                 loss: 0.0928
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11581/30000 (38.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 92.8430s / 113646.2234 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0451
env0_second_0:                 episode reward: -20.6500,                 loss: 0.9335
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11601/30000 (38.6700%),                 avg. length: 755.75,                last time consumption/overall running time: 91.0183s / 113737.2418 s
env0_first_0:                 episode reward: 19.6500,                 loss: 0.1306
env0_second_0:                 episode reward: -19.6500,                 loss: 3.0302
env1_first_0:                 episode reward: 18.1500,                 loss: nan
env1_second_0:                 episode reward: -18.1500,                 loss: nan
Episode: 11621/30000 (38.7367%),                 avg. length: 752.45,                last time consumption/overall running time: 85.8885s / 113823.1303 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.2300
env0_second_0:                 episode reward: -20.9000,                 loss: 4.2312
env1_first_0:                 episode reward: 19.1500,                 loss: nan
env1_second_0:                 episode reward: -19.1500,                 loss: nan
Episode: 11641/30000 (38.8033%),                 avg. length: 731.0,                last time consumption/overall running time: 84.9789s / 113908.1092 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0752
env0_second_0:                 episode reward: -20.9500,                 loss: 1.3874
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11661/30000 (38.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.8944s / 114006.0035 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0467
env0_second_0:                 episode reward: -21.0000,                 loss: 0.8621
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11681/30000 (38.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.6424s / 114102.6459 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0389
env0_second_0:                 episode reward: -20.9000,                 loss: 0.1160
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11701/30000 (39.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4870s / 114200.1329 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0587
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2079
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 11721/30000 (39.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.1614s / 114297.2943 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0331
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1390
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11741/30000 (39.1367%),                 avg. length: 736.25,                last time consumption/overall running time: 97.7470s / 114395.0413 s
env0_first_0:                 episode reward: 19.3000,                 loss: 0.1557
env0_second_0:                 episode reward: -19.3000,                 loss: 0.2423
env1_first_0:                 episode reward: 17.2500,                 loss: nan
env1_second_0:                 episode reward: -17.2500,                 loss: nan
Episode: 11761/30000 (39.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 96.8869s / 114491.9282 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0259
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2329
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11781/30000 (39.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.3976s / 114589.3258 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0687
env0_second_0:                 episode reward: -21.0000,                 loss: 1.4259
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11801/30000 (39.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.2268s / 114680.5526 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0343
env0_second_0:                 episode reward: -21.0000,                 loss: 2.8738
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11821/30000 (39.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.3170s / 114768.8696 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0382
env0_second_0:                 episode reward: -21.0000,                 loss: 4.2041
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11841/30000 (39.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 94.4346s / 114863.3042 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0272
env0_second_0:                 episode reward: -21.0000,                 loss: 3.2918
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11861/30000 (39.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4029s / 114960.7071 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0209
env0_second_0:                 episode reward: -21.0000,                 loss: 4.8059
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11881/30000 (39.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.0143s / 115048.7215 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0653
env0_second_0:                 episode reward: -21.0000,                 loss: 4.4582
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11901/30000 (39.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 87.1776s / 115135.8991 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0614
env0_second_0:                 episode reward: -21.0000,                 loss: 3.9861
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11921/30000 (39.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 100.7436s / 115236.6427 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0642
env0_second_0:                 episode reward: -21.0000,                 loss: 4.0930
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11941/30000 (39.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.5830s / 115325.2257 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0187
env0_second_0:                 episode reward: -21.0000,                 loss: 4.1648
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11961/30000 (39.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 85.9048s / 115411.1305 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0449
env0_second_0:                 episode reward: -21.0000,                 loss: 4.4604
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11981/30000 (39.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.4662s / 115502.5967 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0330
env0_second_0:                 episode reward: -21.0000,                 loss: 4.2435
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 12001/30000 (40.0033%),                 avg. length: 806.65,                last time consumption/overall running time: 102.8895s / 115605.4861 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.3063
env0_second_0:                 episode reward: 2.0500,                 loss: 2.5492
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 12021/30000 (40.0700%),                 avg. length: 768.45,                last time consumption/overall running time: 100.5283s / 115706.0145 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.2377
env0_second_0:                 episode reward: -4.7500,                 loss: 2.0047
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 12041/30000 (40.1367%),                 avg. length: 789.2,                last time consumption/overall running time: 100.3215s / 115806.3360 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.2924
env0_second_0:                 episode reward: 11.0500,                 loss: 0.5927
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 12061/30000 (40.2033%),                 avg. length: 818.75,                last time consumption/overall running time: 107.4311s / 115913.7671 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3619
env0_second_0:                 episode reward: 13.2500,                 loss: 0.5103
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 12081/30000 (40.2700%),                 avg. length: 850.65,                last time consumption/overall running time: 114.7155s / 116028.4825 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.4093
env0_second_0:                 episode reward: 13.4000,                 loss: 0.5084
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 12101/30000 (40.3367%),                 avg. length: 814.9,                last time consumption/overall running time: 108.1203s / 116136.6028 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.2733
env0_second_0:                 episode reward: 17.3000,                 loss: 0.3552
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 12121/30000 (40.4033%),                 avg. length: 820.4,                last time consumption/overall running time: 108.5342s / 116245.1370 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.2572
env0_second_0:                 episode reward: 14.8500,                 loss: 0.5365
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 12141/30000 (40.4700%),                 avg. length: 730.05,                last time consumption/overall running time: 96.2214s / 116341.3584 s
env0_first_0:                 episode reward: 18.1500,                 loss: 0.1528
env0_second_0:                 episode reward: -18.1500,                 loss: 0.4126
env1_first_0:                 episode reward: 17.7000,                 loss: nan
env1_second_0:                 episode reward: -17.7000,                 loss: nan
Episode: 12161/30000 (40.5367%),                 avg. length: 813.55,                last time consumption/overall running time: 109.2169s / 116450.5753 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.3343
env0_second_0:                 episode reward: 11.9500,                 loss: 0.6120
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 12181/30000 (40.6033%),                 avg. length: 794.3,                last time consumption/overall running time: 107.2803s / 116557.8556 s
env0_first_0:                 episode reward: -18.9000,                 loss: 0.1537
env0_second_0:                 episode reward: 18.9000,                 loss: 0.3496
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 12201/30000 (40.6700%),                 avg. length: 799.9,                last time consumption/overall running time: 107.1830s / 116665.0386 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.1661
env0_second_0:                 episode reward: 18.4000,                 loss: 0.3219
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 12221/30000 (40.7367%),                 avg. length: 780.9,                last time consumption/overall running time: 95.3068s / 116760.3455 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.1136
env0_second_0:                 episode reward: 19.3500,                 loss: 0.3714
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 12241/30000 (40.8033%),                 avg. length: 776.1,                last time consumption/overall running time: 102.3202s / 116862.6657 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0729
env0_second_0:                 episode reward: 19.6000,                 loss: 0.6964
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 12261/30000 (40.8700%),                 avg. length: 778.55,                last time consumption/overall running time: 103.6070s / 116966.2727 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.0811
env0_second_0:                 episode reward: 19.4500,                 loss: 0.5592
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 12281/30000 (40.9367%),                 avg. length: 778.1,                last time consumption/overall running time: 103.0687s / 117069.3414 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0179
env0_second_0:                 episode reward: 19.1000,                 loss: 0.2208
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 12301/30000 (41.0033%),                 avg. length: 778.05,                last time consumption/overall running time: 104.2815s / 117173.6229 s
env0_first_0:                 episode reward: -19.7000,                 loss: 0.0363
env0_second_0:                 episode reward: 19.7000,                 loss: 0.2440
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 12321/30000 (41.0700%),                 avg. length: 828.0,                last time consumption/overall running time: 109.1053s / 117282.7282 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0695
env0_second_0:                 episode reward: 18.1500,                 loss: 0.5989
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 12341/30000 (41.1367%),                 avg. length: 813.65,                last time consumption/overall running time: 108.7540s / 117391.4822 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.1617
env0_second_0:                 episode reward: 15.5000,                 loss: 0.4713
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 12361/30000 (41.2033%),                 avg. length: 833.6,                last time consumption/overall running time: 110.6164s / 117502.0986 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.1668
env0_second_0:                 episode reward: 18.6000,                 loss: 0.9578
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 12381/30000 (41.2700%),                 avg. length: 901.65,                last time consumption/overall running time: 120.6904s / 117622.7890 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.3418
env0_second_0:                 episode reward: 15.0500,                 loss: 1.3770
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 12401/30000 (41.3367%),                 avg. length: 961.6,                last time consumption/overall running time: 126.1162s / 117748.9053 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.2572
env0_second_0:                 episode reward: 16.4500,                 loss: 1.1996
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 12421/30000 (41.4033%),                 avg. length: 970.95,                last time consumption/overall running time: 121.5548s / 117870.4601 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.2478
env0_second_0:                 episode reward: 16.3000,                 loss: 0.3998
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 12441/30000 (41.4700%),                 avg. length: 1117.05,                last time consumption/overall running time: 140.7324s / 118011.1924 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.2931
env0_second_0:                 episode reward: 13.7000,                 loss: 0.3783
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 12461/30000 (41.5367%),                 avg. length: 1328.25,                last time consumption/overall running time: 168.7507s / 118179.9432 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.3081
env0_second_0:                 episode reward: 10.9500,                 loss: 0.8515
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 12481/30000 (41.6033%),                 avg. length: 1657.45,                last time consumption/overall running time: 212.4108s / 118392.3539 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.3670
env0_second_0:                 episode reward: 8.1500,                 loss: 0.7099
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 12501/30000 (41.6700%),                 avg. length: 1540.9,                last time consumption/overall running time: 197.8017s / 118590.1556 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.5104
env0_second_0:                 episode reward: 5.2500,                 loss: 0.6116
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 12521/30000 (41.7367%),                 avg. length: 1861.75,                last time consumption/overall running time: 237.9621s / 118828.1178 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.3074
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3895
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 12541/30000 (41.8033%),                 avg. length: 1903.0,                last time consumption/overall running time: 240.9171s / 119069.0349 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.2578
env0_second_0:                 episode reward: 8.1500,                 loss: 0.3277
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 12561/30000 (41.8700%),                 avg. length: 1974.65,                last time consumption/overall running time: 246.6650s / 119315.6999 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2310
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2985
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 12581/30000 (41.9367%),                 avg. length: 2032.1,                last time consumption/overall running time: 250.5711s / 119566.2710 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.1899
env0_second_0:                 episode reward: 8.4500,                 loss: 0.2825
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 12601/30000 (42.0033%),                 avg. length: 1852.95,                last time consumption/overall running time: 234.0731s / 119800.3441 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1783
env0_second_0:                 episode reward: 10.7000,                 loss: 0.2480
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 12621/30000 (42.0700%),                 avg. length: 1999.4,                last time consumption/overall running time: 252.5560s / 120052.9001 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2153
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2830
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 12641/30000 (42.1367%),                 avg. length: 1147.3,                last time consumption/overall running time: 148.0975s / 120200.9976 s
env0_first_0:                 episode reward: 13.4500,                 loss: 0.4273
env0_second_0:                 episode reward: -13.4500,                 loss: 0.4805
env1_first_0:                 episode reward: 14.1000,                 loss: nan
env1_second_0:                 episode reward: -14.1000,                 loss: nan
Episode: 12661/30000 (42.2033%),                 avg. length: 1757.7,                last time consumption/overall running time: 222.0649s / 120423.0625 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.3537
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4644
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 12681/30000 (42.2700%),                 avg. length: 2110.2,                last time consumption/overall running time: 265.5436s / 120688.6061 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2068
env0_second_0:                 episode reward: 7.6000,                 loss: 0.4959
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 12701/30000 (42.3367%),                 avg. length: 1826.55,                last time consumption/overall running time: 229.6117s / 120918.2179 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.3258
env0_second_0:                 episode reward: -6.3000,                 loss: 0.4875
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 12721/30000 (42.4033%),                 avg. length: 2195.45,                last time consumption/overall running time: 275.8101s / 121194.0280 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.2438
env0_second_0:                 episode reward: 4.5000,                 loss: 0.3833
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 12741/30000 (42.4700%),                 avg. length: 2149.4,                last time consumption/overall running time: 270.1574s / 121464.1854 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.1780
env0_second_0:                 episode reward: 10.3000,                 loss: 0.2991
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 12761/30000 (42.5367%),                 avg. length: 1998.2,                last time consumption/overall running time: 252.6668s / 121716.8523 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.1842
env0_second_0:                 episode reward: 9.9000,                 loss: 0.3096
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 12781/30000 (42.6033%),                 avg. length: 1972.2,                last time consumption/overall running time: 249.9744s / 121966.8267 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1527
env0_second_0:                 episode reward: 11.8000,                 loss: 0.6413
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 12801/30000 (42.6700%),                 avg. length: 2056.0,                last time consumption/overall running time: 258.7012s / 122225.5279 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1271
env0_second_0:                 episode reward: 11.5500,                 loss: 0.2653
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 12821/30000 (42.7367%),                 avg. length: 1835.45,                last time consumption/overall running time: 232.0869s / 122457.6148 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1626
env0_second_0:                 episode reward: 13.0000,                 loss: 0.2700
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 12841/30000 (42.8033%),                 avg. length: 1810.0,                last time consumption/overall running time: 228.5796s / 122686.1944 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2200
env0_second_0:                 episode reward: 12.8500,                 loss: 0.3198
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 12861/30000 (42.8700%),                 avg. length: 1783.05,                last time consumption/overall running time: 225.5780s / 122911.7724 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.2855
env0_second_0:                 episode reward: 13.2000,                 loss: 0.9653
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 12881/30000 (42.9367%),                 avg. length: 1722.55,                last time consumption/overall running time: 218.3612s / 123130.1336 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.2245
env0_second_0:                 episode reward: 13.5500,                 loss: 0.5750
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 12901/30000 (43.0033%),                 avg. length: 1338.35,                last time consumption/overall running time: 171.4663s / 123301.5999 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3533
env0_second_0:                 episode reward: -0.7000,                 loss: 0.7640
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 12921/30000 (43.0700%),                 avg. length: 1008.65,                last time consumption/overall running time: 131.5677s / 123433.1676 s
env0_first_0:                 episode reward: 16.1000,                 loss: 0.2776
env0_second_0:                 episode reward: -16.1000,                 loss: 1.5705
env1_first_0:                 episode reward: 16.2500,                 loss: nan
env1_second_0:                 episode reward: -16.2500,                 loss: nan
Episode: 12941/30000 (43.1367%),                 avg. length: 1853.95,                last time consumption/overall running time: 234.2522s / 123667.4199 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.2691
env0_second_0:                 episode reward: 8.9000,                 loss: 1.9849
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 12961/30000 (43.2033%),                 avg. length: 1835.9,                last time consumption/overall running time: 232.0097s / 123899.4295 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1525
env0_second_0:                 episode reward: 14.9500,                 loss: 1.2824
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 12981/30000 (43.2700%),                 avg. length: 1769.0,                last time consumption/overall running time: 224.5761s / 124124.0056 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.1330
env0_second_0:                 episode reward: 15.2500,                 loss: 0.6231
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 13001/30000 (43.3367%),                 avg. length: 1635.85,                last time consumption/overall running time: 208.0907s / 124332.0963 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.2293
env0_second_0:                 episode reward: 12.9000,                 loss: 0.8139
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 13021/30000 (43.4033%),                 avg. length: 1632.85,                last time consumption/overall running time: 207.7434s / 124539.8397 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1721
env0_second_0:                 episode reward: 14.7500,                 loss: 0.5146
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 13041/30000 (43.4700%),                 avg. length: 1632.85,                last time consumption/overall running time: 207.3823s / 124747.2220 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.2350
env0_second_0:                 episode reward: 11.8000,                 loss: 1.0206
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 13061/30000 (43.5367%),                 avg. length: 1617.55,                last time consumption/overall running time: 205.7267s / 124952.9487 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1427
env0_second_0:                 episode reward: 14.9500,                 loss: 0.3615
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 13081/30000 (43.6033%),                 avg. length: 1575.35,                last time consumption/overall running time: 200.4393s / 125153.3880 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.1774
env0_second_0:                 episode reward: 14.8000,                 loss: 0.6875
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 13101/30000 (43.6700%),                 avg. length: 1556.9,                last time consumption/overall running time: 198.3135s / 125351.7015 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1495
env0_second_0:                 episode reward: 14.1000,                 loss: 0.3632
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 13121/30000 (43.7367%),                 avg. length: 1705.25,                last time consumption/overall running time: 215.7247s / 125567.4263 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2278
env0_second_0:                 episode reward: 12.8500,                 loss: 0.4558
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 13141/30000 (43.8033%),                 avg. length: 1764.75,                last time consumption/overall running time: 223.8677s / 125791.2939 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.1490
env0_second_0:                 episode reward: 14.4000,                 loss: 2.0457
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 13161/30000 (43.8700%),                 avg. length: 1585.75,                last time consumption/overall running time: 203.2593s / 125994.5533 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.3698
env0_second_0:                 episode reward: 7.2500,                 loss: 1.8794
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 13181/30000 (43.9367%),                 avg. length: 1715.25,                last time consumption/overall running time: 219.1518s / 126213.7050 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.1830
env0_second_0:                 episode reward: 13.8500,                 loss: 1.2243
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13201/30000 (44.0033%),                 avg. length: 1698.3,                last time consumption/overall running time: 218.1826s / 126431.8877 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1301
env0_second_0:                 episode reward: 14.7000,                 loss: 4.8252
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 13221/30000 (44.0700%),                 avg. length: 1789.8,                last time consumption/overall running time: 229.1998s / 126661.0874 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.2998
env0_second_0:                 episode reward: 10.0000,                 loss: 0.6187
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 13241/30000 (44.1367%),                 avg. length: 1671.7,                last time consumption/overall running time: 212.9773s / 126874.0647 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.3031
env0_second_0:                 episode reward: 9.3500,                 loss: 0.4761
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 13261/30000 (44.2033%),                 avg. length: 1554.15,                last time consumption/overall running time: 197.1611s / 127071.2258 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3844
env0_second_0:                 episode reward: 1.8500,                 loss: 0.5506
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13281/30000 (44.2700%),                 avg. length: 1752.45,                last time consumption/overall running time: 220.7693s / 127291.9951 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2645
env0_second_0:                 episode reward: 9.0000,                 loss: 0.4553
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 13301/30000 (44.3367%),                 avg. length: 1667.45,                last time consumption/overall running time: 216.0180s / 127508.0130 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.2747
env0_second_0:                 episode reward: 11.1000,                 loss: 0.4893
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 13321/30000 (44.4033%),                 avg. length: 1347.35,                last time consumption/overall running time: 186.9001s / 127694.9131 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.3539
env0_second_0:                 episode reward: 13.8000,                 loss: 1.0616
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 13341/30000 (44.4700%),                 avg. length: 1398.75,                last time consumption/overall running time: 188.7659s / 127883.6790 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.2359
env0_second_0:                 episode reward: 13.6500,                 loss: 0.8464
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 13361/30000 (44.5367%),                 avg. length: 1499.2,                last time consumption/overall running time: 204.4305s / 128088.1095 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2285
env0_second_0:                 episode reward: 14.0000,                 loss: 0.7413
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 13381/30000 (44.6033%),                 avg. length: 1484.85,                last time consumption/overall running time: 202.0047s / 128290.1142 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1839
env0_second_0:                 episode reward: 14.5000,                 loss: 0.5743
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 13401/30000 (44.6700%),                 avg. length: 1399.0,                last time consumption/overall running time: 191.6593s / 128481.7735 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1572
env0_second_0:                 episode reward: 15.5500,                 loss: 0.6410
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 13421/30000 (44.7367%),                 avg. length: 1458.1,                last time consumption/overall running time: 198.7578s / 128680.5312 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.2134
env0_second_0:                 episode reward: 14.8000,                 loss: 1.6187
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 13441/30000 (44.8033%),                 avg. length: 1560.95,                last time consumption/overall running time: 210.8761s / 128891.4074 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.2534
env0_second_0:                 episode reward: 10.3000,                 loss: 1.0394
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 13461/30000 (44.8700%),                 avg. length: 1447.7,                last time consumption/overall running time: 194.5388s / 129085.9462 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.3911
env0_second_0:                 episode reward: 12.7000,                 loss: 1.8830
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 13481/30000 (44.9367%),                 avg. length: 1391.45,                last time consumption/overall running time: 182.4055s / 129268.3516 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2012
env0_second_0:                 episode reward: 15.9500,                 loss: 0.7905
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 13501/30000 (45.0033%),                 avg. length: 1482.0,                last time consumption/overall running time: 189.6706s / 129458.0222 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.4817
env0_second_0:                 episode reward: 7.7000,                 loss: 0.9548
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 13521/30000 (45.0700%),                 avg. length: 1506.8,                last time consumption/overall running time: 195.8401s / 129653.8623 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.2914
env0_second_0:                 episode reward: 12.1000,                 loss: 0.6177
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 13541/30000 (45.1367%),                 avg. length: 1433.65,                last time consumption/overall running time: 186.0882s / 129839.9505 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1891
env0_second_0:                 episode reward: 15.2000,                 loss: 0.4997
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 13561/30000 (45.2033%),                 avg. length: 918.05,                last time consumption/overall running time: 116.6752s / 129956.6256 s
env0_first_0:                 episode reward: 9.0000,                 loss: 0.2298
env0_second_0:                 episode reward: -9.0000,                 loss: 0.6316
env1_first_0:                 episode reward: 9.6000,                 loss: nan
env1_second_0:                 episode reward: -9.6000,                 loss: nan
Episode: 13581/30000 (45.2700%),                 avg. length: 810.0,                last time consumption/overall running time: 104.8542s / 130061.4799 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.3308
env0_second_0:                 episode reward: -2.9000,                 loss: 0.7153
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 13601/30000 (45.3367%),                 avg. length: 1336.75,                last time consumption/overall running time: 170.9744s / 130232.4543 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.5939
env0_second_0:                 episode reward: 7.3500,                 loss: 1.6282
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 13621/30000 (45.4033%),                 avg. length: 1900.85,                last time consumption/overall running time: 241.6296s / 130474.0839 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.4109
env0_second_0:                 episode reward: 1.3000,                 loss: 0.7110
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 13641/30000 (45.4700%),                 avg. length: 2347.3,                last time consumption/overall running time: 287.7145s / 130761.7984 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2544
env0_second_0:                 episode reward: 2.3500,                 loss: 0.5768
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 13661/30000 (45.5367%),                 avg. length: 1983.55,                last time consumption/overall running time: 245.9447s / 131007.7431 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.2948
env0_second_0:                 episode reward: 6.8500,                 loss: 1.0366
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 13681/30000 (45.6033%),                 avg. length: 1866.9,                last time consumption/overall running time: 229.8710s / 131237.6141 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.3035
env0_second_0:                 episode reward: 9.7500,                 loss: 0.6183
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 13701/30000 (45.6700%),                 avg. length: 1769.55,                last time consumption/overall running time: 218.8779s / 131456.4920 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1623
env0_second_0:                 episode reward: 14.5000,                 loss: 0.5387
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13721/30000 (45.7367%),                 avg. length: 1693.35,                last time consumption/overall running time: 213.7334s / 131670.2255 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.1510
env0_second_0:                 episode reward: 15.7500,                 loss: 1.8305
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 13741/30000 (45.8033%),                 avg. length: 1453.25,                last time consumption/overall running time: 184.8913s / 131855.1168 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1894
env0_second_0:                 episode reward: 5.7500,                 loss: 5.8765
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 13761/30000 (45.8700%),                 avg. length: 1635.65,                last time consumption/overall running time: 213.3920s / 132068.5088 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.4711
env0_second_0:                 episode reward: 0.3500,                 loss: 3.6209
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 13781/30000 (45.9367%),                 avg. length: 1691.6,                last time consumption/overall running time: 213.4031s / 132281.9119 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.2907
env0_second_0:                 episode reward: 12.0500,                 loss: 2.9362
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 13801/30000 (46.0033%),                 avg. length: 1881.45,                last time consumption/overall running time: 239.8355s / 132521.7474 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.1944
env0_second_0:                 episode reward: 12.3000,                 loss: 2.3620
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 13821/30000 (46.0700%),                 avg. length: 1947.95,                last time consumption/overall running time: 241.9028s / 132763.6502 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1477
env0_second_0:                 episode reward: 13.1000,                 loss: 2.4363
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13841/30000 (46.1367%),                 avg. length: 1982.05,                last time consumption/overall running time: 243.8555s / 133007.5057 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0803
env0_second_0:                 episode reward: 15.3500,                 loss: 1.9818
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 13861/30000 (46.2033%),                 avg. length: 2123.45,                last time consumption/overall running time: 276.1396s / 133283.6453 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0811
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8479
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 13881/30000 (46.2700%),                 avg. length: 2050.6,                last time consumption/overall running time: 261.9418s / 133545.5871 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0477
env0_second_0:                 episode reward: 15.7500,                 loss: 1.6203
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 13901/30000 (46.3367%),                 avg. length: 2111.7,                last time consumption/overall running time: 270.2014s / 133815.7885 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0110
env0_second_0:                 episode reward: 16.4500,                 loss: 1.9160
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 13921/30000 (46.4033%),                 avg. length: 2112.85,                last time consumption/overall running time: 281.0399s / 134096.8284 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0291
env0_second_0:                 episode reward: 16.8000,                 loss: 1.6708
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 13941/30000 (46.4700%),                 avg. length: 2138.95,                last time consumption/overall running time: 273.1418s / 134369.9703 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 15.9000,                 loss: 1.8886
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 13961/30000 (46.5367%),                 avg. length: 2111.4,                last time consumption/overall running time: 276.4839s / 134646.4541 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 17.7000,                 loss: 1.4886
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 13981/30000 (46.6033%),                 avg. length: 2141.75,                last time consumption/overall running time: 283.3690s / 134929.8232 s
env0_first_0:                 episode reward: -17.1500,                 loss: -0.0017
env0_second_0:                 episode reward: 17.1500,                 loss: 1.5704
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 14001/30000 (46.6700%),                 avg. length: 2186.7,                last time consumption/overall running time: 280.3567s / 135210.1798 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0609
env0_second_0:                 episode reward: 13.0500,                 loss: 1.6580
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 14021/30000 (46.7367%),                 avg. length: 1482.65,                last time consumption/overall running time: 192.3100s / 135402.4899 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1982
env0_second_0:                 episode reward: 14.9000,                 loss: 3.0996
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 14041/30000 (46.8033%),                 avg. length: 1582.1,                last time consumption/overall running time: 202.6197s / 135605.1096 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.2864
env0_second_0:                 episode reward: 13.7000,                 loss: 2.0057
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 14061/30000 (46.8700%),                 avg. length: 1410.95,                last time consumption/overall running time: 181.0602s / 135786.1697 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1732
env0_second_0:                 episode reward: 15.5500,                 loss: 1.6406
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 14081/30000 (46.9367%),                 avg. length: 1358.35,                last time consumption/overall running time: 180.4672s / 135966.6369 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.2049
env0_second_0:                 episode reward: 15.5000,                 loss: 6.4374
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 14101/30000 (47.0033%),                 avg. length: 1391.1,                last time consumption/overall running time: 189.5505s / 136156.1874 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.1541
env0_second_0:                 episode reward: 17.7500,                 loss: 3.1872
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 14121/30000 (47.0700%),                 avg. length: 1470.0,                last time consumption/overall running time: 198.3436s / 136354.5310 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.2526
env0_second_0:                 episode reward: 15.8500,                 loss: 3.5183
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 14141/30000 (47.1367%),                 avg. length: 1250.35,                last time consumption/overall running time: 161.5761s / 136516.1071 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.1775
env0_second_0:                 episode reward: 16.9000,                 loss: 3.1187
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 14161/30000 (47.2033%),                 avg. length: 1068.6,                last time consumption/overall running time: 133.9458s / 136650.0529 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.3486
env0_second_0:                 episode reward: 13.9500,                 loss: 2.9694
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 14181/30000 (47.2700%),                 avg. length: 920.65,                last time consumption/overall running time: 125.3575s / 136775.4104 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.5663
env0_second_0:                 episode reward: 1.9500,                 loss: 2.3472
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 14201/30000 (47.3367%),                 avg. length: 1504.3,                last time consumption/overall running time: 199.8302s / 136975.2406 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.4001
env0_second_0:                 episode reward: 11.5000,                 loss: 2.1096
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 14221/30000 (47.4033%),                 avg. length: 1415.9,                last time consumption/overall running time: 187.6319s / 137162.8725 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2510
env0_second_0:                 episode reward: 15.9500,                 loss: 1.7127
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 14241/30000 (47.4700%),                 avg. length: 1330.65,                last time consumption/overall running time: 173.7665s / 137336.6390 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.2776
env0_second_0:                 episode reward: 13.8500,                 loss: 2.4662
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 14261/30000 (47.5367%),                 avg. length: 1199.5,                last time consumption/overall running time: 156.6892s / 137493.3282 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.3881
env0_second_0:                 episode reward: 9.5500,                 loss: 1.8856
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 14281/30000 (47.6033%),                 avg. length: 1834.35,                last time consumption/overall running time: 235.0820s / 137728.4102 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.4398
env0_second_0:                 episode reward: 1.9500,                 loss: 2.6996
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 14301/30000 (47.6700%),                 avg. length: 1895.35,                last time consumption/overall running time: 242.4634s / 137970.8736 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.2624
env0_second_0:                 episode reward: 7.2000,                 loss: 2.3460
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 14321/30000 (47.7367%),                 avg. length: 1705.45,                last time consumption/overall running time: 218.3467s / 138189.2203 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2603
env0_second_0:                 episode reward: 7.6000,                 loss: 2.4189
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 14341/30000 (47.8033%),                 avg. length: 1611.85,                last time consumption/overall running time: 204.7452s / 138393.9655 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.2781
env0_second_0:                 episode reward: 10.4500,                 loss: 1.9535
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 14361/30000 (47.8700%),                 avg. length: 1318.0,                last time consumption/overall running time: 169.2106s / 138563.1762 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.3101
env0_second_0:                 episode reward: 13.6000,                 loss: 1.3532
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 14381/30000 (47.9367%),                 avg. length: 1495.5,                last time consumption/overall running time: 190.3060s / 138753.4821 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.3139
env0_second_0:                 episode reward: 9.8000,                 loss: 0.8716
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 14401/30000 (48.0033%),                 avg. length: 1532.0,                last time consumption/overall running time: 195.8225s / 138949.3046 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2670
env0_second_0:                 episode reward: 11.4000,                 loss: 1.0059
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 14421/30000 (48.0700%),                 avg. length: 1551.95,                last time consumption/overall running time: 203.0201s / 139152.3247 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.3340
env0_second_0:                 episode reward: 8.2500,                 loss: 0.8962
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 14441/30000 (48.1367%),                 avg. length: 1462.65,                last time consumption/overall running time: 191.1275s / 139343.4522 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.2822
env0_second_0:                 episode reward: 12.5500,                 loss: 0.7943
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 14461/30000 (48.2033%),                 avg. length: 1576.75,                last time consumption/overall running time: 199.2976s / 139542.7498 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2335
env0_second_0:                 episode reward: 11.4000,                 loss: 1.3673
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 14481/30000 (48.2700%),                 avg. length: 1400.1,                last time consumption/overall running time: 183.9991s / 139726.7489 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2275
env0_second_0:                 episode reward: 14.0000,                 loss: 1.8821
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 14501/30000 (48.3367%),                 avg. length: 1527.55,                last time consumption/overall running time: 194.1550s / 139920.9038 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.2571
env0_second_0:                 episode reward: 11.8000,                 loss: 0.8973
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 14521/30000 (48.4033%),                 avg. length: 1781.25,                last time consumption/overall running time: 229.9100s / 140150.8139 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1722
env0_second_0:                 episode reward: 12.8500,                 loss: 1.3918
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 14541/30000 (48.4700%),                 avg. length: 1645.4,                last time consumption/overall running time: 202.3110s / 140353.1249 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.2024
env0_second_0:                 episode reward: 13.3500,                 loss: 1.0728
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 14561/30000 (48.5367%),                 avg. length: 1591.4,                last time consumption/overall running time: 203.6903s / 140556.8152 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.1507
env0_second_0:                 episode reward: 15.0500,                 loss: 1.0673
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 14581/30000 (48.6033%),                 avg. length: 1500.35,                last time consumption/overall running time: 194.1547s / 140750.9699 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0988
env0_second_0:                 episode reward: 17.0000,                 loss: 1.1105
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 14601/30000 (48.6700%),                 avg. length: 1539.55,                last time consumption/overall running time: 196.5093s / 140947.4792 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1455
env0_second_0:                 episode reward: 14.7000,                 loss: 1.0516
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 14621/30000 (48.7367%),                 avg. length: 1694.9,                last time consumption/overall running time: 221.3490s / 141168.8282 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.1295
env0_second_0:                 episode reward: 15.6000,                 loss: 1.0131
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 14641/30000 (48.8033%),                 avg. length: 1517.65,                last time consumption/overall running time: 195.1175s / 141363.9457 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.2159
env0_second_0:                 episode reward: 5.7000,                 loss: 1.4698
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 14661/30000 (48.8700%),                 avg. length: 730.8,                last time consumption/overall running time: 101.3721s / 141465.3178 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.1056
env0_second_0:                 episode reward: -19.2500,                 loss: 1.9668
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14681/30000 (48.9367%),                 avg. length: 761.05,                last time consumption/overall running time: 104.1249s / 141569.4427 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.2826
env0_second_0:                 episode reward: -20.0500,                 loss: 1.8270
env1_first_0:                 episode reward: 19.8500,                 loss: nan
env1_second_0:                 episode reward: -19.8500,                 loss: nan
Episode: 14701/30000 (49.0033%),                 avg. length: 730.75,                last time consumption/overall running time: 96.6263s / 141666.0690 s
env0_first_0:                 episode reward: 20.4500,                 loss: -0.0227
env0_second_0:                 episode reward: -20.4500,                 loss: 1.2972
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14721/30000 (49.0700%),                 avg. length: 730.5,                last time consumption/overall running time: 100.7030s / 141766.7721 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0239
env0_second_0:                 episode reward: -20.6500,                 loss: 1.4864
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 14741/30000 (49.1367%),                 avg. length: 728.5,                last time consumption/overall running time: 97.3445s / 141864.1166 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0585
env0_second_0:                 episode reward: -20.6000,                 loss: 1.5288
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14761/30000 (49.2033%),                 avg. length: 730.8,                last time consumption/overall running time: 98.4642s / 141962.5807 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0647
env0_second_0:                 episode reward: -20.6000,                 loss: 0.9974
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14781/30000 (49.2700%),                 avg. length: 735.45,                last time consumption/overall running time: 102.3090s / 142064.8897 s
env0_first_0:                 episode reward: 18.6500,                 loss: 0.0086
env0_second_0:                 episode reward: -18.6500,                 loss: 0.9761
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 14801/30000 (49.3367%),                 avg. length: 730.55,                last time consumption/overall running time: 100.2141s / 142165.1038 s
env0_first_0:                 episode reward: 20.5000,                 loss: -0.0397
env0_second_0:                 episode reward: -20.5000,                 loss: 0.8739
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 14821/30000 (49.4033%),                 avg. length: 730.3,                last time consumption/overall running time: 100.7530s / 142265.8567 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0541
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4486
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 14841/30000 (49.4700%),                 avg. length: 728.85,                last time consumption/overall running time: 95.8671s / 142361.7239 s
env0_first_0:                 episode reward: 20.5500,                 loss: -0.0023
env0_second_0:                 episode reward: -20.5500,                 loss: 0.3605
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14861/30000 (49.5367%),                 avg. length: 1013.1,                last time consumption/overall running time: 134.4522s / 142496.1760 s
env0_first_0:                 episode reward: 13.7000,                 loss: 0.3999
env0_second_0:                 episode reward: -13.7000,                 loss: 2.4919
env1_first_0:                 episode reward: 14.1500,                 loss: nan
env1_second_0:                 episode reward: -14.1500,                 loss: nan
Episode: 14881/30000 (49.6033%),                 avg. length: 764.35,                last time consumption/overall running time: 106.0077s / 142602.1837 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.2202
env0_second_0:                 episode reward: 4.1500,                 loss: 4.7104
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 14901/30000 (49.6700%),                 avg. length: 758.7,                last time consumption/overall running time: 105.6063s / 142707.7900 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2045
env0_second_0:                 episode reward: -0.7500,                 loss: 1.9032
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 14921/30000 (49.7367%),                 avg. length: 728.95,                last time consumption/overall running time: 98.1916s / 142805.9816 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1092
env0_second_0:                 episode reward: -20.7500,                 loss: 1.1644
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14941/30000 (49.8033%),                 avg. length: 728.7,                last time consumption/overall running time: 104.1093s / 142910.0909 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0626
env0_second_0:                 episode reward: -20.6500,                 loss: 0.7712
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14961/30000 (49.8700%),                 avg. length: 728.65,                last time consumption/overall running time: 100.2916s / 143010.3825 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0138
env0_second_0:                 episode reward: -20.6500,                 loss: 0.8512
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 14981/30000 (49.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4081s / 143108.7906 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.2115
env0_second_0:                 episode reward: -20.8500,                 loss: 0.7569
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 15001/30000 (50.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4497s / 143207.2402 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0629
env0_second_0:                 episode reward: -21.0000,                 loss: 1.1147
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 15021/30000 (50.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 102.9802s / 143310.2204 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0144
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4793
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15041/30000 (50.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 100.2113s / 143410.4317 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0314
env0_second_0:                 episode reward: -21.0000,                 loss: 1.3323
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15061/30000 (50.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4061s / 143508.8378 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0365
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2661
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 15081/30000 (50.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 100.8993s / 143609.7371 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0183
env0_second_0:                 episode reward: -21.0000,                 loss: 0.5670
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 15101/30000 (50.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 99.7833s / 143709.5205 s
env0_first_0:                 episode reward: 20.9500,                 loss: -0.0121
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1893
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15121/30000 (50.4033%),                 avg. length: 822.75,                last time consumption/overall running time: 111.1471s / 143820.6676 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3253
env0_second_0:                 episode reward: 1.1500,                 loss: 0.5940
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 15141/30000 (50.4700%),                 avg. length: 821.65,                last time consumption/overall running time: 108.5214s / 143929.1889 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.2013
env0_second_0:                 episode reward: 8.6000,                 loss: 0.7498
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 15161/30000 (50.5367%),                 avg. length: 763.3,                last time consumption/overall running time: 105.0364s / 144034.2253 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.2093
env0_second_0:                 episode reward: -4.1500,                 loss: 0.4835
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 15181/30000 (50.6033%),                 avg. length: 776.4,                last time consumption/overall running time: 104.5837s / 144138.8090 s
env0_first_0:                 episode reward: -19.9000,                 loss: 0.1929
env0_second_0:                 episode reward: 19.9000,                 loss: 1.0507
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 15201/30000 (50.6700%),                 avg. length: 818.85,                last time consumption/overall running time: 109.4024s / 144248.2114 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.2731
env0_second_0:                 episode reward: 16.7500,                 loss: 1.9698
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 15221/30000 (50.7367%),                 avg. length: 818.55,                last time consumption/overall running time: 110.0270s / 144358.2384 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.1880
env0_second_0:                 episode reward: 18.7000,                 loss: 1.6938
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 15241/30000 (50.8033%),                 avg. length: 930.4,                last time consumption/overall running time: 125.0659s / 144483.3042 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.3622
env0_second_0:                 episode reward: 12.6500,                 loss: 3.3792
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 15261/30000 (50.8700%),                 avg. length: 926.6,                last time consumption/overall running time: 125.2513s / 144608.5555 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.3075
env0_second_0:                 episode reward: 16.8000,                 loss: 3.8890
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 15281/30000 (50.9367%),                 avg. length: 1557.65,                last time consumption/overall running time: 208.0947s / 144816.6502 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2342
env0_second_0:                 episode reward: 11.9000,                 loss: 4.5282
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 15301/30000 (51.0033%),                 avg. length: 1110.3,                last time consumption/overall running time: 143.1417s / 144959.7919 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.1619
env0_second_0:                 episode reward: 7.9500,                 loss: 3.5274
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 15321/30000 (51.0700%),                 avg. length: 765.15,                last time consumption/overall running time: 108.7823s / 145068.5742 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.2381
env0_second_0:                 episode reward: 6.5500,                 loss: 1.8173
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 15341/30000 (51.1367%),                 avg. length: 1322.8,                last time consumption/overall running time: 175.9400s / 145244.5142 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.4292
env0_second_0:                 episode reward: 11.8000,                 loss: 2.6215
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 15361/30000 (51.2033%),                 avg. length: 1353.7,                last time consumption/overall running time: 170.5548s / 145415.0691 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.4398
env0_second_0:                 episode reward: 12.5500,                 loss: 2.4952
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 15381/30000 (51.2700%),                 avg. length: 1326.6,                last time consumption/overall running time: 175.9157s / 145590.9848 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.3559
env0_second_0:                 episode reward: 10.7000,                 loss: 2.1827
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 15401/30000 (51.3367%),                 avg. length: 1276.45,                last time consumption/overall running time: 170.9248s / 145761.9096 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.3351
env0_second_0:                 episode reward: 14.3500,                 loss: 2.1770
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 15421/30000 (51.4033%),                 avg. length: 1295.65,                last time consumption/overall running time: 163.6850s / 145925.5946 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.3259
env0_second_0:                 episode reward: 13.7500,                 loss: 2.1618
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 15441/30000 (51.4700%),                 avg. length: 1484.5,                last time consumption/overall running time: 187.8037s / 146113.3983 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.2905
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8131
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 15461/30000 (51.5367%),                 avg. length: 1589.15,                last time consumption/overall running time: 205.0333s / 146318.4316 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2765
env0_second_0:                 episode reward: 12.6000,                 loss: 2.2277
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 15481/30000 (51.6033%),                 avg. length: 1650.1,                last time consumption/overall running time: 210.3377s / 146528.7693 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.2291
env0_second_0:                 episode reward: 12.2500,                 loss: 2.3107
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 15501/30000 (51.6700%),                 avg. length: 1582.0,                last time consumption/overall running time: 201.2345s / 146730.0038 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.2304
env0_second_0:                 episode reward: 14.6000,                 loss: 1.9471
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 15521/30000 (51.7367%),                 avg. length: 1752.25,                last time consumption/overall running time: 220.7031s / 146950.7069 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.2209
env0_second_0:                 episode reward: 10.5500,                 loss: 1.5717
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 15541/30000 (51.8033%),                 avg. length: 1604.3,                last time consumption/overall running time: 203.3479s / 147154.0549 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1733
env0_second_0:                 episode reward: 15.1500,                 loss: 0.8896
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 15561/30000 (51.8700%),                 avg. length: 1671.5,                last time consumption/overall running time: 218.1032s / 147372.1581 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1490
env0_second_0:                 episode reward: 14.9000,                 loss: 0.8224
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 15581/30000 (51.9367%),                 avg. length: 1714.0,                last time consumption/overall running time: 214.5041s / 147586.6622 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.1575
env0_second_0:                 episode reward: 16.0500,                 loss: 0.8358
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 15601/30000 (52.0033%),                 avg. length: 1608.8,                last time consumption/overall running time: 203.1137s / 147789.7759 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.1734
env0_second_0:                 episode reward: 14.3500,                 loss: 0.7703
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 15621/30000 (52.0700%),                 avg. length: 1839.65,                last time consumption/overall running time: 228.1316s / 148017.9076 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1766
env0_second_0:                 episode reward: 13.7500,                 loss: 0.8347
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 15641/30000 (52.1367%),                 avg. length: 2138.65,                last time consumption/overall running time: 267.8707s / 148285.7783 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.1488
env0_second_0:                 episode reward: 11.7000,                 loss: 0.5897
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 15661/30000 (52.2033%),                 avg. length: 1969.3,                last time consumption/overall running time: 248.9886s / 148534.7669 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1608
env0_second_0:                 episode reward: 12.6500,                 loss: 0.5319
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 15681/30000 (52.2700%),                 avg. length: 2001.35,                last time consumption/overall running time: 256.7643s / 148791.5312 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1264
env0_second_0:                 episode reward: 13.4000,                 loss: 0.4628
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 15701/30000 (52.3367%),                 avg. length: 2000.1,                last time consumption/overall running time: 248.8632s / 149040.3944 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1486
env0_second_0:                 episode reward: 12.6000,                 loss: 0.7778
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 15721/30000 (52.4033%),                 avg. length: 2211.3,                last time consumption/overall running time: 276.3089s / 149316.7033 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1419
env0_second_0:                 episode reward: 12.0500,                 loss: 1.5093
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 15741/30000 (52.4700%),                 avg. length: 2184.65,                last time consumption/overall running time: 275.1496s / 149591.8529 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.1811
env0_second_0:                 episode reward: 9.1500,                 loss: 1.2809
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 15761/30000 (52.5367%),                 avg. length: 2257.25,                last time consumption/overall running time: 287.1030s / 149878.9559 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1380
env0_second_0:                 episode reward: 11.8500,                 loss: 0.8367
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 15781/30000 (52.6033%),                 avg. length: 2151.5,                last time consumption/overall running time: 274.7923s / 150153.7482 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1363
env0_second_0:                 episode reward: 13.0000,                 loss: 0.5309
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 15801/30000 (52.6700%),                 avg. length: 2355.5,                last time consumption/overall running time: 291.6577s / 150445.4059 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1341
env0_second_0:                 episode reward: 10.5500,                 loss: 1.8888
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 15821/30000 (52.7367%),                 avg. length: 2330.8,                last time consumption/overall running time: 304.4778s / 150749.8837 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.1300
env0_second_0:                 episode reward: 12.4500,                 loss: 1.5722
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 15841/30000 (52.8033%),                 avg. length: 2246.6,                last time consumption/overall running time: 299.5276s / 151049.4113 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1166
env0_second_0:                 episode reward: 13.2500,                 loss: 1.4968
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 15861/30000 (52.8700%),                 avg. length: 2070.45,                last time consumption/overall running time: 266.3668s / 151315.7781 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.3549
env0_second_0:                 episode reward: -5.9000,                 loss: 7.3390
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 15881/30000 (52.9367%),                 avg. length: 2564.9,                last time consumption/overall running time: 331.2614s / 151647.0396 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.1572
env0_second_0:                 episode reward: 9.4500,                 loss: 1.6224
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 15901/30000 (53.0033%),                 avg. length: 2587.6,                last time consumption/overall running time: 341.2578s / 151988.2974 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.1267
env0_second_0:                 episode reward: 9.5000,                 loss: 1.8095
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 15921/30000 (53.0700%),                 avg. length: 2778.35,                last time consumption/overall running time: 352.5103s / 152340.8077 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.1430
env0_second_0:                 episode reward: 9.3500,                 loss: 1.7990
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 15941/30000 (53.1367%),                 avg. length: 2603.0,                last time consumption/overall running time: 332.5172s / 152673.3249 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1226
env0_second_0:                 episode reward: 12.9500,                 loss: 1.6667
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 15961/30000 (53.2033%),                 avg. length: 2569.25,                last time consumption/overall running time: 333.0435s / 153006.3684 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.1598
env0_second_0:                 episode reward: 10.4500,                 loss: 1.6770
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 15981/30000 (53.2700%),                 avg. length: 2731.55,                last time consumption/overall running time: 352.2967s / 153358.6651 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.1451
env0_second_0:                 episode reward: 7.9500,                 loss: 2.2220
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 16001/30000 (53.3367%),                 avg. length: 2650.25,                last time consumption/overall running time: 337.1136s / 153695.7786 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1110
env0_second_0:                 episode reward: 10.6000,                 loss: 2.2184
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 16021/30000 (53.4033%),                 avg. length: 2819.15,                last time consumption/overall running time: 366.7230s / 154062.5016 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1169
env0_second_0:                 episode reward: 10.7000,                 loss: 1.9099
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 16041/30000 (53.4700%),                 avg. length: 2098.8,                last time consumption/overall running time: 254.3168s / 154316.8184 s
env0_first_0:                 episode reward: 6.4000,                 loss: 0.3662
env0_second_0:                 episode reward: -6.4000,                 loss: 2.1022
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 16061/30000 (53.5367%),                 avg. length: 2744.15,                last time consumption/overall running time: 345.4347s / 154662.2530 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.2258
env0_second_0:                 episode reward: 3.1500,                 loss: 1.9929
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 16081/30000 (53.6033%),                 avg. length: 2758.3,                last time consumption/overall running time: 340.3240s / 155002.5770 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.1854
env0_second_0:                 episode reward: 8.5500,                 loss: 1.9699
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 16101/30000 (53.6700%),                 avg. length: 2670.75,                last time consumption/overall running time: 334.1710s / 155336.7480 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.3220
env0_second_0:                 episode reward: 5.7000,                 loss: 1.7647
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 16121/30000 (53.7367%),                 avg. length: 871.7,                last time consumption/overall running time: 119.4627s / 155456.2107 s
env0_first_0:                 episode reward: 9.0500,                 loss: 0.6875
env0_second_0:                 episode reward: -9.0500,                 loss: 2.8782
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 16141/30000 (53.8033%),                 avg. length: 931.3,                last time consumption/overall running time: 124.2952s / 155580.5059 s
env0_first_0:                 episode reward: 14.2500,                 loss: 0.6110
env0_second_0:                 episode reward: -14.2500,                 loss: 3.5344
env1_first_0:                 episode reward: 11.4500,                 loss: nan
env1_second_0:                 episode reward: -11.4500,                 loss: nan
Episode: 16161/30000 (53.8700%),                 avg. length: 1593.8,                last time consumption/overall running time: 206.7513s / 155787.2571 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4624
env0_second_0:                 episode reward: -4.1000,                 loss: 3.2532
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 16181/30000 (53.9367%),                 avg. length: 1939.8,                last time consumption/overall running time: 243.8505s / 156031.1076 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.2956
env0_second_0:                 episode reward: 5.7000,                 loss: 3.3128
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 16201/30000 (54.0033%),                 avg. length: 1906.15,                last time consumption/overall running time: 245.9202s / 156277.0279 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1950
env0_second_0:                 episode reward: 14.7500,                 loss: 2.3560
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 16221/30000 (54.0700%),                 avg. length: 1930.3,                last time consumption/overall running time: 246.0372s / 156523.0651 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1284
env0_second_0:                 episode reward: 14.1000,                 loss: 1.9446
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 16241/30000 (54.1367%),                 avg. length: 2084.55,                last time consumption/overall running time: 265.9392s / 156789.0043 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1396
env0_second_0:                 episode reward: 14.0000,                 loss: 2.2244
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 16261/30000 (54.2033%),                 avg. length: 2061.05,                last time consumption/overall running time: 262.4558s / 157051.4600 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1803
env0_second_0:                 episode reward: 11.5500,                 loss: 3.4843
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 16281/30000 (54.2700%),                 avg. length: 1972.5,                last time consumption/overall running time: 250.7863s / 157302.2464 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.1753
env0_second_0:                 episode reward: 14.8000,                 loss: 4.9105
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 16301/30000 (54.3367%),                 avg. length: 1758.25,                last time consumption/overall running time: 219.9134s / 157522.1598 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.2174
env0_second_0:                 episode reward: 13.8000,                 loss: 6.7507
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 16321/30000 (54.4033%),                 avg. length: 862.65,                last time consumption/overall running time: 113.4011s / 157635.5609 s
env0_first_0:                 episode reward: 12.4000,                 loss: 0.4632
env0_second_0:                 episode reward: -12.4000,                 loss: 3.2210
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 16341/30000 (54.4700%),                 avg. length: 802.7,                last time consumption/overall running time: 105.9054s / 157741.4662 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.3814
env0_second_0:                 episode reward: -10.0000,                 loss: 1.7790
env1_first_0:                 episode reward: 9.2500,                 loss: nan
env1_second_0:                 episode reward: -9.2500,                 loss: nan
Episode: 16361/30000 (54.5367%),                 avg. length: 850.95,                last time consumption/overall running time: 110.8430s / 157852.3092 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.3584
env0_second_0:                 episode reward: 15.0000,                 loss: 1.7774
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 16381/30000 (54.6033%),                 avg. length: 799.65,                last time consumption/overall running time: 111.1338s / 157963.4430 s
env0_first_0:                 episode reward: -17.1500,                 loss: 0.2640
env0_second_0:                 episode reward: 17.1500,                 loss: 1.5526
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 16401/30000 (54.6700%),                 avg. length: 839.7,                last time consumption/overall running time: 113.9660s / 158077.4089 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.3032
env0_second_0:                 episode reward: 14.5500,                 loss: 1.8577
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 16421/30000 (54.7367%),                 avg. length: 1016.2,                last time consumption/overall running time: 134.7124s / 158212.1213 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.3101
env0_second_0:                 episode reward: 15.1000,                 loss: 1.5755
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 16441/30000 (54.8033%),                 avg. length: 1733.15,                last time consumption/overall running time: 223.5855s / 158435.7068 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.3852
env0_second_0:                 episode reward: 8.1500,                 loss: 1.7247
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 16461/30000 (54.8700%),                 avg. length: 1304.75,                last time consumption/overall running time: 168.4183s / 158604.1251 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.5447
env0_second_0:                 episode reward: 12.6000,                 loss: 2.1857
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 16481/30000 (54.9367%),                 avg. length: 1387.8,                last time consumption/overall running time: 182.0352s / 158786.1603 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.3018
env0_second_0:                 episode reward: 15.2500,                 loss: 2.6272
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 16501/30000 (55.0033%),                 avg. length: 1504.45,                last time consumption/overall running time: 191.4503s / 158977.6107 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.4440
env0_second_0:                 episode reward: 9.5000,                 loss: 8.4496
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 16521/30000 (55.0700%),                 avg. length: 1953.3,                last time consumption/overall running time: 247.6210s / 159225.2317 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2350
env0_second_0:                 episode reward: 12.8500,                 loss: 3.9854
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 16541/30000 (55.1367%),                 avg. length: 2486.1,                last time consumption/overall running time: 318.6186s / 159543.8503 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.3147
env0_second_0:                 episode reward: 6.2500,                 loss: 3.3912
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 16561/30000 (55.2033%),                 avg. length: 2980.3,                last time consumption/overall running time: 384.7049s / 159928.5552 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1363
env0_second_0:                 episode reward: 11.4500,                 loss: 2.4463
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 16581/30000 (55.2700%),                 avg. length: 2829.7,                last time consumption/overall running time: 366.2361s / 160294.7913 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0987
env0_second_0:                 episode reward: 12.8000,                 loss: 2.0721
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 16601/30000 (55.3367%),                 avg. length: 3119.05,                last time consumption/overall running time: 402.2326s / 160697.0239 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.1152
env0_second_0:                 episode reward: 9.5000,                 loss: 11.0416
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 16621/30000 (55.4033%),                 avg. length: 2824.7,                last time consumption/overall running time: 360.8546s / 161057.8786 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1162
env0_second_0:                 episode reward: 11.6500,                 loss: 2.8909
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 16641/30000 (55.4700%),                 avg. length: 2682.5,                last time consumption/overall running time: 332.9071s / 161390.7856 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.1168
env0_second_0:                 episode reward: 10.3500,                 loss: 2.4239
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 16661/30000 (55.5367%),                 avg. length: 2817.85,                last time consumption/overall running time: 350.0593s / 161740.8449 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0977
env0_second_0:                 episode reward: 13.1000,                 loss: 1.9712
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 16681/30000 (55.6033%),                 avg. length: 2788.4,                last time consumption/overall running time: 343.6524s / 162084.4974 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.2855
env0_second_0:                 episode reward: 6.0500,                 loss: 2.8837
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 16701/30000 (55.6700%),                 avg. length: 2817.75,                last time consumption/overall running time: 353.3668s / 162437.8641 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1019
env0_second_0:                 episode reward: 12.0000,                 loss: 2.9132
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 16721/30000 (55.7367%),                 avg. length: 2714.3,                last time consumption/overall running time: 336.4030s / 162774.2672 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.1620
env0_second_0:                 episode reward: 7.6000,                 loss: 2.9062
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 16741/30000 (55.8033%),                 avg. length: 2905.7,                last time consumption/overall running time: 364.9317s / 163139.1989 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.1209
env0_second_0:                 episode reward: 10.6500,                 loss: 2.5218
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 16761/30000 (55.8700%),                 avg. length: 2879.1,                last time consumption/overall running time: 352.8573s / 163492.0562 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1092
env0_second_0:                 episode reward: 11.4500,                 loss: 3.9929
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 16781/30000 (55.9367%),                 avg. length: 2781.75,                last time consumption/overall running time: 349.3650s / 163841.4212 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.1085
env0_second_0:                 episode reward: 8.9000,                 loss: 2.3217
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 16801/30000 (56.0033%),                 avg. length: 2515.25,                last time consumption/overall running time: 322.5105s / 164163.9317 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.2464
env0_second_0:                 episode reward: -3.1500,                 loss: 2.2337
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 16821/30000 (56.0700%),                 avg. length: 2390.15,                last time consumption/overall running time: 300.8079s / 164464.7396 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2703
env0_second_0:                 episode reward: -0.5000,                 loss: 2.0991
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 16841/30000 (56.1367%),                 avg. length: 3053.15,                last time consumption/overall running time: 387.5878s / 164852.3274 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.1359
env0_second_0:                 episode reward: 7.2000,                 loss: 1.7678
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 16861/30000 (56.2033%),                 avg. length: 2626.2,                last time consumption/overall running time: 335.1836s / 165187.5110 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3472
env0_second_0:                 episode reward: 2.1500,                 loss: 2.1717
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 16881/30000 (56.2700%),                 avg. length: 2703.75,                last time consumption/overall running time: 336.5543s / 165524.0653 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1537
env0_second_0:                 episode reward: 11.1500,                 loss: 2.5068
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 16901/30000 (56.3367%),                 avg. length: 2895.2,                last time consumption/overall running time: 370.8391s / 165894.9044 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1062
env0_second_0:                 episode reward: 10.7000,                 loss: 4.0403
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 16921/30000 (56.4033%),                 avg. length: 2662.85,                last time consumption/overall running time: 333.4717s / 166228.3761 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1112
env0_second_0:                 episode reward: 12.9000,                 loss: 3.6486
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 16941/30000 (56.4700%),                 avg. length: 2883.75,                last time consumption/overall running time: 368.8981s / 166597.2742 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.1106
env0_second_0:                 episode reward: 10.6500,                 loss: 3.2125
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 16961/30000 (56.5367%),                 avg. length: 3001.1,                last time consumption/overall running time: 382.0913s / 166979.3656 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.1173
env0_second_0:                 episode reward: 10.5000,                 loss: 2.3028
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 16981/30000 (56.6033%),                 avg. length: 3040.65,                last time consumption/overall running time: 378.7118s / 167358.0774 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.1171
env0_second_0:                 episode reward: 10.5000,                 loss: 2.1050
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 17001/30000 (56.6700%),                 avg. length: 2859.9,                last time consumption/overall running time: 365.9262s / 167724.0035 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1028
env0_second_0:                 episode reward: 10.7000,                 loss: 2.2843
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 17021/30000 (56.7367%),                 avg. length: 2771.8,                last time consumption/overall running time: 364.3096s / 168088.3131 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.1249
env0_second_0:                 episode reward: 11.4000,                 loss: 3.5650
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 17041/30000 (56.8033%),                 avg. length: 3111.05,                last time consumption/overall running time: 406.7754s / 168495.0885 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.1444
env0_second_0:                 episode reward: 6.3000,                 loss: 3.1471
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 17061/30000 (56.8700%),                 avg. length: 2614.0,                last time consumption/overall running time: 338.5959s / 168833.6844 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.1713
env0_second_0:                 episode reward: 7.2500,                 loss: 3.0306
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 17081/30000 (56.9367%),                 avg. length: 1317.5,                last time consumption/overall running time: 173.7108s / 169007.3952 s
env0_first_0:                 episode reward: 14.9000,                 loss: 0.3514
env0_second_0:                 episode reward: -14.9000,                 loss: 3.5005
env1_first_0:                 episode reward: 13.3000,                 loss: nan
env1_second_0:                 episode reward: -13.3000,                 loss: nan
Episode: 17101/30000 (57.0033%),                 avg. length: 2552.0,                last time consumption/overall running time: 325.8676s / 169333.2628 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2166
env0_second_0:                 episode reward: 2.0500,                 loss: 2.4662
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 17121/30000 (57.0700%),                 avg. length: 2780.85,                last time consumption/overall running time: 354.5244s / 169687.7872 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.1867
env0_second_0:                 episode reward: 1.0500,                 loss: 2.0019
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 17141/30000 (57.1367%),                 avg. length: 3008.15,                last time consumption/overall running time: 415.8407s / 170103.6279 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.1631
env0_second_0:                 episode reward: -3.4000,                 loss: 2.0192
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 17161/30000 (57.2033%),                 avg. length: 3258.5,                last time consumption/overall running time: 468.7869s / 170572.4148 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1450
env0_second_0:                 episode reward: 1.0000,                 loss: 2.4047
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 17181/30000 (57.2700%),                 avg. length: 3255.25,                last time consumption/overall running time: 457.8925s / 171030.3073 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.1318
env0_second_0:                 episode reward: 6.1000,                 loss: 4.1985
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 17201/30000 (57.3367%),                 avg. length: 3271.65,                last time consumption/overall running time: 455.5417s / 171485.8490 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.1286
env0_second_0:                 episode reward: 6.1000,                 loss: 2.8012
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 17221/30000 (57.4033%),                 avg. length: 2625.5,                last time consumption/overall running time: 367.4411s / 171853.2901 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.3172
env0_second_0:                 episode reward: 5.0000,                 loss: 4.8709
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 17241/30000 (57.4700%),                 avg. length: 2859.2,                last time consumption/overall running time: 402.5838s / 172255.8739 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.1507
env0_second_0:                 episode reward: 5.6500,                 loss: 3.0248
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 17261/30000 (57.5367%),                 avg. length: 2899.15,                last time consumption/overall running time: 399.5928s / 172655.4667 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.1501
env0_second_0:                 episode reward: 7.2500,                 loss: 2.6048
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 17281/30000 (57.6033%),                 avg. length: 2914.0,                last time consumption/overall running time: 399.5945s / 173055.0611 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1204
env0_second_0:                 episode reward: 10.6000,                 loss: 1.9484
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 17301/30000 (57.6700%),                 avg. length: 2984.95,                last time consumption/overall running time: 404.0710s / 173459.1321 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.1723
env0_second_0:                 episode reward: 6.7500,                 loss: 2.8567
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 17321/30000 (57.7367%),                 avg. length: 2583.3,                last time consumption/overall running time: 353.7858s / 173812.9179 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.1862
env0_second_0:                 episode reward: 7.8500,                 loss: 2.0375
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 17341/30000 (57.8033%),                 avg. length: 1858.05,                last time consumption/overall running time: 257.4789s / 174070.3968 s
env0_first_0:                 episode reward: 11.0000,                 loss: 0.3382
env0_second_0:                 episode reward: -11.0000,                 loss: 2.6219
env1_first_0:                 episode reward: 9.7000,                 loss: nan
env1_second_0:                 episode reward: -9.7000,                 loss: nan
Episode: 17361/30000 (57.8700%),                 avg. length: 3038.4,                last time consumption/overall running time: 415.3808s / 174485.7776 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.1583
env0_second_0:                 episode reward: -1.1000,                 loss: 2.2234
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 17381/30000 (57.9367%),                 avg. length: 2830.4,                last time consumption/overall running time: 387.7103s / 174873.4879 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.1432
env0_second_0:                 episode reward: 5.1500,                 loss: 2.6872
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 17401/30000 (58.0033%),                 avg. length: 3015.9,                last time consumption/overall running time: 406.5596s / 175280.0475 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.1179
env0_second_0:                 episode reward: 8.8500,                 loss: 2.8480
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 17421/30000 (58.0700%),                 avg. length: 2857.1,                last time consumption/overall running time: 382.0486s / 175662.0961 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.1831
env0_second_0:                 episode reward: 6.6000,                 loss: 2.4051
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 17441/30000 (58.1367%),                 avg. length: 2923.25,                last time consumption/overall running time: 397.6030s / 176059.6991 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.1465
env0_second_0:                 episode reward: 8.5500,                 loss: 2.6946
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 17461/30000 (58.2033%),                 avg. length: 2927.95,                last time consumption/overall running time: 400.0649s / 176459.7640 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.1326
env0_second_0:                 episode reward: 6.9000,                 loss: 2.7392
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 17481/30000 (58.2700%),                 avg. length: 2995.75,                last time consumption/overall running time: 399.4452s / 176859.2092 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.1087
env0_second_0:                 episode reward: 9.8000,                 loss: 2.4662
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 17501/30000 (58.3367%),                 avg. length: 3004.2,                last time consumption/overall running time: 410.0616s / 177269.2708 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.1406
env0_second_0:                 episode reward: 9.0500,                 loss: 2.1760
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 17521/30000 (58.4033%),                 avg. length: 3266.0,                last time consumption/overall running time: 447.1165s / 177716.3873 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.1005
env0_second_0:                 episode reward: 9.6500,                 loss: 1.5908
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 17541/30000 (58.4700%),                 avg. length: 3253.55,                last time consumption/overall running time: 447.0674s / 178163.4547 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.1091
env0_second_0:                 episode reward: 10.2000,                 loss: 1.5175
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 17561/30000 (58.5367%),                 avg. length: 3194.3,                last time consumption/overall running time: 434.3610s / 178597.8156 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.2335
env0_second_0:                 episode reward: 9.8500,                 loss: 2.2869
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 17581/30000 (58.6033%),                 avg. length: 3164.2,                last time consumption/overall running time: 434.2902s / 179032.1059 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1880
env0_second_0:                 episode reward: 0.7000,                 loss: 2.7290
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 17601/30000 (58.6700%),                 avg. length: 3383.85,                last time consumption/overall running time: 457.3972s / 179489.5031 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.1072
env0_second_0:                 episode reward: 8.9000,                 loss: 1.7217
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 17621/30000 (58.7367%),                 avg. length: 3407.35,                last time consumption/overall running time: 466.5401s / 179956.0432 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.1015
env0_second_0:                 episode reward: 10.1000,                 loss: 1.1786
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 17641/30000 (58.8033%),                 avg. length: 3657.0,                last time consumption/overall running time: 501.0614s / 180457.1046 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.1107
env0_second_0:                 episode reward: 7.3000,                 loss: 2.9698
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 17661/30000 (58.8700%),                 avg. length: 3087.45,                last time consumption/overall running time: 413.7148s / 180870.8194 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.3057
env0_second_0:                 episode reward: 7.7500,                 loss: 1.7198
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 17681/30000 (58.9367%),                 avg. length: 1580.1,                last time consumption/overall running time: 214.0103s / 181084.8297 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4749
env0_second_0:                 episode reward: -2.6000,                 loss: 3.0500
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 17701/30000 (59.0033%),                 avg. length: 2183.2,                last time consumption/overall running time: 294.1326s / 181378.9622 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.2628
env0_second_0:                 episode reward: 3.8500,                 loss: 4.0195
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 17721/30000 (59.0700%),                 avg. length: 1836.85,                last time consumption/overall running time: 251.8213s / 181630.7835 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.2061
env0_second_0:                 episode reward: 12.6500,                 loss: 3.1727
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 17741/30000 (59.1367%),                 avg. length: 1770.55,                last time consumption/overall running time: 239.8894s / 181870.6729 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.1967
env0_second_0:                 episode reward: 11.0000,                 loss: 5.2707
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 17761/30000 (59.2033%),                 avg. length: 1782.45,                last time consumption/overall running time: 240.8756s / 182111.5485 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.1911
env0_second_0:                 episode reward: 14.5500,                 loss: 3.2718
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 17781/30000 (59.2700%),                 avg. length: 1552.4,                last time consumption/overall running time: 213.4185s / 182324.9671 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.3536
env0_second_0:                 episode reward: 13.4000,                 loss: 3.1143
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 17801/30000 (59.3367%),                 avg. length: 1440.5,                last time consumption/overall running time: 200.6034s / 182525.5705 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.1928
env0_second_0:                 episode reward: 15.6500,                 loss: 1.3062
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 17821/30000 (59.4033%),                 avg. length: 1820.8,                last time consumption/overall running time: 256.1775s / 182781.7480 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.4534
env0_second_0:                 episode reward: 12.6000,                 loss: 2.0424
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 17841/30000 (59.4700%),                 avg. length: 1354.45,                last time consumption/overall running time: 184.9234s / 182966.6714 s
env0_first_0:                 episode reward: -17.5000,                 loss: 0.1670
env0_second_0:                 episode reward: 17.5000,                 loss: 1.6475
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 17861/30000 (59.5367%),                 avg. length: 1650.55,                last time consumption/overall running time: 225.9004s / 183192.5718 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.2101
env0_second_0:                 episode reward: 14.2500,                 loss: 2.2841
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 17881/30000 (59.6033%),                 avg. length: 1434.75,                last time consumption/overall running time: 199.7664s / 183392.3381 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.3398
env0_second_0:                 episode reward: 7.5000,                 loss: 2.8024
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 17901/30000 (59.6700%),                 avg. length: 1518.8,                last time consumption/overall running time: 217.9562s / 183610.2943 s
env0_first_0:                 episode reward: 10.2000,                 loss: 0.4348
env0_second_0:                 episode reward: -10.2000,                 loss: 2.0076
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 17921/30000 (59.7367%),                 avg. length: 1890.6,                last time consumption/overall running time: 253.8861s / 183864.1805 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3186
env0_second_0:                 episode reward: 1.5500,                 loss: 1.7114
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 17941/30000 (59.8033%),                 avg. length: 1594.7,                last time consumption/overall running time: 224.0431s / 184088.2236 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1451
env0_second_0:                 episode reward: 14.6500,                 loss: 1.6250
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 17961/30000 (59.8700%),                 avg. length: 1667.45,                last time consumption/overall running time: 224.2315s / 184312.4550 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.2936
env0_second_0:                 episode reward: 9.6500,                 loss: 6.5138
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 17981/30000 (59.9367%),                 avg. length: 1612.45,                last time consumption/overall running time: 218.2885s / 184530.7435 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.3176
env0_second_0:                 episode reward: 11.7000,                 loss: 3.5420
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 18001/30000 (60.0033%),                 avg. length: 2507.8,                last time consumption/overall running time: 341.2199s / 184871.9634 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.1988
env0_second_0:                 episode reward: 8.7000,                 loss: 4.0154
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 18021/30000 (60.0700%),                 avg. length: 2643.8,                last time consumption/overall running time: 361.8235s / 185233.7868 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1177
env0_second_0:                 episode reward: 14.0000,                 loss: 2.6590
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 18041/30000 (60.1367%),                 avg. length: 2973.15,                last time consumption/overall running time: 408.9352s / 185642.7220 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.1372
env0_second_0:                 episode reward: 7.7000,                 loss: 2.0366
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 18061/30000 (60.2033%),                 avg. length: 3079.85,                last time consumption/overall running time: 425.4872s / 186068.2092 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.1156
env0_second_0:                 episode reward: 8.0500,                 loss: 2.0345
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 18081/30000 (60.2700%),                 avg. length: 2899.5,                last time consumption/overall running time: 403.3795s / 186471.5887 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.3660
env0_second_0:                 episode reward: 4.7500,                 loss: 2.2257
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 18101/30000 (60.3367%),                 avg. length: 1312.85,                last time consumption/overall running time: 183.8473s / 186655.4359 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.4499
env0_second_0:                 episode reward: -0.9500,                 loss: 2.9966
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 18121/30000 (60.4033%),                 avg. length: 2271.0,                last time consumption/overall running time: 301.3025s / 186956.7385 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1205
env0_second_0:                 episode reward: 13.2000,                 loss: 2.2903
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 18141/30000 (60.4700%),                 avg. length: 2557.45,                last time consumption/overall running time: 351.8654s / 187308.6039 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1537
env0_second_0:                 episode reward: 12.7000,                 loss: 2.2293
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 18161/30000 (60.5367%),                 avg. length: 1938.6,                last time consumption/overall running time: 268.2312s / 187576.8351 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.3974
env0_second_0:                 episode reward: 4.4000,                 loss: 2.0943
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 18181/30000 (60.6033%),                 avg. length: 2673.85,                last time consumption/overall running time: 362.8451s / 187939.6802 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0969
env0_second_0:                 episode reward: 12.7000,                 loss: 2.4625
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 18201/30000 (60.6700%),                 avg. length: 2783.3,                last time consumption/overall running time: 392.7026s / 188332.3828 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0871
env0_second_0:                 episode reward: 12.9500,                 loss: 2.2458
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 18221/30000 (60.7367%),                 avg. length: 2577.95,                last time consumption/overall running time: 363.2640s / 188695.6469 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0786
env0_second_0:                 episode reward: 15.4000,                 loss: 2.3220
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 18241/30000 (60.8033%),                 avg. length: 2751.65,                last time consumption/overall running time: 374.1850s / 189069.8318 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0910
env0_second_0:                 episode reward: 12.3000,                 loss: 2.4662
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 18261/30000 (60.8700%),                 avg. length: 2626.25,                last time consumption/overall running time: 364.8114s / 189434.6432 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1006
env0_second_0:                 episode reward: 12.5500,                 loss: 2.1215
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 18281/30000 (60.9367%),                 avg. length: 1552.1,                last time consumption/overall running time: 219.2193s / 189653.8625 s
env0_first_0:                 episode reward: 6.7000,                 loss: 0.4680
env0_second_0:                 episode reward: -6.7000,                 loss: 3.7745
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
Episode: 18301/30000 (61.0033%),                 avg. length: 728.95,                last time consumption/overall running time: 106.3753s / 189760.2377 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.4136
env0_second_0:                 episode reward: -20.1500,                 loss: 3.7514
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 18321/30000 (61.0700%),                 avg. length: 729.1,                last time consumption/overall running time: 107.6115s / 189867.8493 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.1803
env0_second_0:                 episode reward: -20.3000,                 loss: 1.8862
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 18341/30000 (61.1367%),                 avg. length: 728.4,                last time consumption/overall running time: 105.5728s / 189973.4221 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.1105
env0_second_0:                 episode reward: -20.6000,                 loss: 2.2104
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 18361/30000 (61.2033%),                 avg. length: 728.25,                last time consumption/overall running time: 105.5835s / 190079.0056 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1220
env0_second_0:                 episode reward: -20.7500,                 loss: 2.9841
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 18381/30000 (61.2700%),                 avg. length: 728.35,                last time consumption/overall running time: 109.2486s / 190188.2542 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0723
env0_second_0:                 episode reward: -20.7500,                 loss: 1.9205
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 18401/30000 (61.3367%),                 avg. length: 728.2,                last time consumption/overall running time: 105.2438s / 190293.4980 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0966
env0_second_0:                 episode reward: -20.9000,                 loss: 1.8559
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 18421/30000 (61.4033%),                 avg. length: 728.2,                last time consumption/overall running time: 107.9765s / 190401.4744 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0799
env0_second_0:                 episode reward: -20.7000,                 loss: 1.9446
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 18441/30000 (61.4700%),                 avg. length: 728.1,                last time consumption/overall running time: 106.7087s / 190508.1831 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0486
env0_second_0:                 episode reward: -20.8000,                 loss: 1.0309
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 18461/30000 (61.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 107.1248s / 190615.3079 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.1240
env0_second_0:                 episode reward: -20.9500,                 loss: 1.0332
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 18481/30000 (61.6033%),                 avg. length: 729.0,                last time consumption/overall running time: 106.6718s / 190721.9797 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.1186
env0_second_0:                 episode reward: -20.6500,                 loss: 1.6899
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 18501/30000 (61.6700%),                 avg. length: 729.45,                last time consumption/overall running time: 109.8209s / 190831.8005 s
env0_first_0:                 episode reward: 20.4500,                 loss: -0.0141
env0_second_0:                 episode reward: -20.4500,                 loss: 1.1522
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 18521/30000 (61.7367%),                 avg. length: 729.1,                last time consumption/overall running time: 117.9967s / 190949.7972 s
env0_first_0:                 episode reward: 20.4500,                 loss: -0.0442
env0_second_0:                 episode reward: -20.4500,                 loss: 0.9958
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 18541/30000 (61.8033%),                 avg. length: 947.65,                last time consumption/overall running time: 135.8813s / 191085.6785 s
env0_first_0:                 episode reward: 8.4000,                 loss: 0.2993
env0_second_0:                 episode reward: -8.4000,                 loss: 1.1335
env1_first_0:                 episode reward: 9.8500,                 loss: nan
env1_second_0:                 episode reward: -9.8500,                 loss: nan
Episode: 18561/30000 (61.8700%),                 avg. length: 1607.05,                last time consumption/overall running time: 233.4015s / 191319.0800 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.4575
env0_second_0:                 episode reward: 8.7500,                 loss: 1.4076
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 18581/30000 (61.9367%),                 avg. length: 1506.65,                last time consumption/overall running time: 211.9301s / 191531.0101 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.3396
env0_second_0:                 episode reward: 10.8500,                 loss: 1.2726
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 18601/30000 (62.0033%),                 avg. length: 1607.4,                last time consumption/overall running time: 229.2548s / 191760.2649 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.3068
env0_second_0:                 episode reward: 12.2000,                 loss: 1.0686
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 18621/30000 (62.0700%),                 avg. length: 1382.85,                last time consumption/overall running time: 192.0775s / 191952.3424 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.3598
env0_second_0:                 episode reward: 12.8500,                 loss: 1.0635
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 18641/30000 (62.1367%),                 avg. length: 1537.3,                last time consumption/overall running time: 214.8320s / 192167.1744 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.5721
env0_second_0:                 episode reward: -2.3500,                 loss: 1.0250
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 18661/30000 (62.2033%),                 avg. length: 1712.1,                last time consumption/overall running time: 236.1489s / 192403.3233 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.3511
env0_second_0:                 episode reward: 9.5500,                 loss: 0.7009
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 18681/30000 (62.2700%),                 avg. length: 1706.25,                last time consumption/overall running time: 237.8714s / 192641.1947 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.2520
env0_second_0:                 episode reward: 11.1500,                 loss: 0.7320
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 18701/30000 (62.3367%),                 avg. length: 1636.1,                last time consumption/overall running time: 223.6786s / 192864.8733 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.2568
env0_second_0:                 episode reward: 14.4000,                 loss: 0.5881
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 18721/30000 (62.4033%),                 avg. length: 1322.25,                last time consumption/overall running time: 181.0228s / 193045.8961 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.2583
env0_second_0:                 episode reward: 16.1000,                 loss: 0.5562
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 18741/30000 (62.4700%),                 avg. length: 1398.4,                last time consumption/overall running time: 189.9792s / 193235.8753 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.4796
env0_second_0:                 episode reward: 5.6000,                 loss: 0.8697
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 18761/30000 (62.5367%),                 avg. length: 1180.35,                last time consumption/overall running time: 161.8267s / 193397.7019 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.3082
env0_second_0:                 episode reward: 15.3000,                 loss: 2.2087
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 18781/30000 (62.6033%),                 avg. length: 1198.25,                last time consumption/overall running time: 162.9155s / 193560.6174 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.2839
env0_second_0:                 episode reward: 16.1500,                 loss: 0.8251
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 18801/30000 (62.6700%),                 avg. length: 879.4,                last time consumption/overall running time: 124.1080s / 193684.7254 s
env0_first_0:                 episode reward: -18.4500,                 loss: 0.2023
env0_second_0:                 episode reward: 18.4500,                 loss: 0.6044
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 18821/30000 (62.7367%),                 avg. length: 1291.85,                last time consumption/overall running time: 179.6279s / 193864.3533 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.4573
env0_second_0:                 episode reward: 8.0500,                 loss: 0.8799
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 18841/30000 (62.8033%),                 avg. length: 1150.7,                last time consumption/overall running time: 161.1210s / 194025.4743 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.2419
env0_second_0:                 episode reward: 17.4000,                 loss: 0.8763
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 18861/30000 (62.8700%),                 avg. length: 1170.55,                last time consumption/overall running time: 162.6986s / 194188.1729 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.2675
env0_second_0:                 episode reward: 15.8000,                 loss: 0.9020
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 18881/30000 (62.9367%),                 avg. length: 1191.45,                last time consumption/overall running time: 165.4258s / 194353.5987 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.2203
env0_second_0:                 episode reward: 16.7500,                 loss: 0.7100
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 18901/30000 (63.0033%),                 avg. length: 844.35,                last time consumption/overall running time: 120.2940s / 194473.8928 s
env0_first_0:                 episode reward: -18.6500,                 loss: 0.1843
env0_second_0:                 episode reward: 18.6500,                 loss: 0.6194
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 18921/30000 (63.0700%),                 avg. length: 756.35,                last time consumption/overall running time: 106.8672s / 194580.7600 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.1302
env0_second_0:                 episode reward: -1.8000,                 loss: 1.2825
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 18941/30000 (63.1367%),                 avg. length: 728.05,                last time consumption/overall running time: 106.1272s / 194686.8872 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.1758
env0_second_0:                 episode reward: -20.9000,                 loss: 0.6866
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 18961/30000 (63.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 105.1492s / 194792.0364 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0796
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2678
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 18981/30000 (63.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 104.9397s / 194896.9761 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1309
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2835
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 19001/30000 (63.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 105.8907s / 195002.8668 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1659
env0_second_0:                 episode reward: -21.0000,                 loss: 0.5226
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 19021/30000 (63.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 104.9073s / 195107.7741 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.1354
env0_second_0:                 episode reward: -20.9500,                 loss: 1.0995
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 19041/30000 (63.4700%),                 avg. length: 751.9,                last time consumption/overall running time: 107.1368s / 195214.9109 s
env0_first_0:                 episode reward: 17.9500,                 loss: 0.3018
env0_second_0:                 episode reward: -17.9500,                 loss: 2.2164
env1_first_0:                 episode reward: 14.6000,                 loss: nan
env1_second_0:                 episode reward: -14.6000,                 loss: nan
Episode: 19061/30000 (63.5367%),                 avg. length: 1092.5,                last time consumption/overall running time: 153.3558s / 195368.2667 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.6092
env0_second_0:                 episode reward: 10.4500,                 loss: 1.7184
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 19081/30000 (63.6033%),                 avg. length: 1394.8,                last time consumption/overall running time: 193.9388s / 195562.2055 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.5014
env0_second_0:                 episode reward: 10.2000,                 loss: 1.5841
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 19101/30000 (63.6700%),                 avg. length: 1306.9,                last time consumption/overall running time: 180.0000s / 195742.2055 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.3149
env0_second_0:                 episode reward: 13.0500,                 loss: 0.7810
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 19121/30000 (63.7367%),                 avg. length: 1114.95,                last time consumption/overall running time: 157.2545s / 195899.4600 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.2404
env0_second_0:                 episode reward: 16.8500,                 loss: 0.8656
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 19141/30000 (63.8033%),                 avg. length: 1251.25,                last time consumption/overall running time: 172.6749s / 196072.1349 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.3314
env0_second_0:                 episode reward: 14.8500,                 loss: 1.5055
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 19161/30000 (63.8700%),                 avg. length: 1164.35,                last time consumption/overall running time: 165.9806s / 196238.1154 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.2607
env0_second_0:                 episode reward: 18.8500,                 loss: 1.2817
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 19181/30000 (63.9367%),                 avg. length: 1145.15,                last time consumption/overall running time: 158.7732s / 196396.8886 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.2245
env0_second_0:                 episode reward: 15.1500,                 loss: 1.4813
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 19201/30000 (64.0033%),                 avg. length: 1117.5,                last time consumption/overall running time: 153.2184s / 196550.1070 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.2001
env0_second_0:                 episode reward: 16.3000,                 loss: 1.0655
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 19221/30000 (64.0700%),                 avg. length: 983.65,                last time consumption/overall running time: 147.6543s / 196697.7614 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.1994
env0_second_0:                 episode reward: 16.6000,                 loss: 0.8771
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 19241/30000 (64.1367%),                 avg. length: 1406.5,                last time consumption/overall running time: 202.7594s / 196900.5208 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.2951
env0_second_0:                 episode reward: 13.6000,                 loss: 1.9872
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 19261/30000 (64.2033%),                 avg. length: 884.75,                last time consumption/overall running time: 125.6846s / 197026.2054 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.2084
env0_second_0:                 episode reward: -4.2500,                 loss: 2.2630
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 19281/30000 (64.2700%),                 avg. length: 728.15,                last time consumption/overall running time: 107.1378s / 197133.3431 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0250
env0_second_0:                 episode reward: -20.6500,                 loss: 2.2525
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 19301/30000 (64.3367%),                 avg. length: 734.8,                last time consumption/overall running time: 107.8405s / 197241.1837 s
env0_first_0:                 episode reward: 19.0500,                 loss: 0.2099
env0_second_0:                 episode reward: -19.0500,                 loss: 2.1548
env1_first_0:                 episode reward: 17.6500,                 loss: nan
env1_second_0:                 episode reward: -17.6500,                 loss: nan
Episode: 19321/30000 (64.4033%),                 avg. length: 1221.95,                last time consumption/overall running time: 172.4946s / 197413.6783 s
env0_first_0:                 episode reward: 8.9500,                 loss: 0.4864
env0_second_0:                 episode reward: -8.9500,                 loss: 1.7105
env1_first_0:                 episode reward: 8.8000,                 loss: nan
env1_second_0:                 episode reward: -8.8000,                 loss: nan
Episode: 19341/30000 (64.4700%),                 avg. length: 1752.15,                last time consumption/overall running time: 247.6003s / 197661.2785 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.4679
env0_second_0:                 episode reward: 3.9500,                 loss: 1.1029
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 19361/30000 (64.5367%),                 avg. length: 1506.5,                last time consumption/overall running time: 214.2300s / 197875.5085 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.5027
env0_second_0:                 episode reward: 9.7500,                 loss: 1.3439
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 19381/30000 (64.6033%),                 avg. length: 1151.1,                last time consumption/overall running time: 160.8327s / 198036.3412 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.3304
env0_second_0:                 episode reward: 15.4000,                 loss: 0.7613
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 19401/30000 (64.6700%),                 avg. length: 1122.8,                last time consumption/overall running time: 156.0171s / 198192.3584 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2577
env0_second_0:                 episode reward: 15.9500,                 loss: 0.8833
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 19421/30000 (64.7367%),                 avg. length: 1541.05,                last time consumption/overall running time: 214.9221s / 198407.2804 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.2873
env0_second_0:                 episode reward: 12.3000,                 loss: 0.9971
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 19441/30000 (64.8033%),                 avg. length: 1337.4,                last time consumption/overall running time: 187.7900s / 198595.0705 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.3232
env0_second_0:                 episode reward: 13.6000,                 loss: 1.2057
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 19461/30000 (64.8700%),                 avg. length: 1233.35,                last time consumption/overall running time: 175.7626s / 198770.8331 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.2641
env0_second_0:                 episode reward: 14.2000,                 loss: 1.1279
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 19481/30000 (64.9367%),                 avg. length: 1324.9,                last time consumption/overall running time: 184.3648s / 198955.1979 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.2831
env0_second_0:                 episode reward: 14.9500,                 loss: 0.7873
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 19501/30000 (65.0033%),                 avg. length: 1329.1,                last time consumption/overall running time: 184.3716s / 199139.5695 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.3473
env0_second_0:                 episode reward: 13.3000,                 loss: 1.3025
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 19521/30000 (65.0700%),                 avg. length: 1395.0,                last time consumption/overall running time: 192.9379s / 199332.5074 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.3051
env0_second_0:                 episode reward: 11.5500,                 loss: 1.2667
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 19541/30000 (65.1367%),                 avg. length: 1404.4,                last time consumption/overall running time: 192.6151s / 199525.1225 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2732
env0_second_0:                 episode reward: 14.0000,                 loss: 0.8022
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 19561/30000 (65.2033%),                 avg. length: 1306.35,                last time consumption/overall running time: 181.6918s / 199706.8143 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.2772
env0_second_0:                 episode reward: 15.4000,                 loss: 0.7139
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 19581/30000 (65.2700%),                 avg. length: 1175.1,                last time consumption/overall running time: 162.7133s / 199869.5276 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.2407
env0_second_0:                 episode reward: 17.9000,                 loss: 0.7396
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 19601/30000 (65.3367%),                 avg. length: 959.05,                last time consumption/overall running time: 145.1217s / 200014.6493 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4405
env0_second_0:                 episode reward: -4.7000,                 loss: 2.3879
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 19621/30000 (65.4033%),                 avg. length: 1569.1,                last time consumption/overall running time: 216.6173s / 200231.2665 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5053
env0_second_0:                 episode reward: -0.5000,                 loss: 1.7014
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 19641/30000 (65.4700%),                 avg. length: 1735.85,                last time consumption/overall running time: 238.3796s / 200469.6461 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.3253
env0_second_0:                 episode reward: 8.5500,                 loss: 1.0039
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 19661/30000 (65.5367%),                 avg. length: 1406.95,                last time consumption/overall running time: 194.3194s / 200663.9655 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.1971
env0_second_0:                 episode reward: 16.1000,                 loss: 1.7503
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 19681/30000 (65.6033%),                 avg. length: 1351.05,                last time consumption/overall running time: 188.9780s / 200852.9435 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.1267
env0_second_0:                 episode reward: 15.0000,                 loss: 1.8255
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 19701/30000 (65.6700%),                 avg. length: 1451.85,                last time consumption/overall running time: 198.7846s / 201051.7281 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.1328
env0_second_0:                 episode reward: 15.0000,                 loss: 1.4692
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 19721/30000 (65.7367%),                 avg. length: 1264.15,                last time consumption/overall running time: 177.2014s / 201228.9294 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3296
env0_second_0:                 episode reward: 13.2500,                 loss: 2.2032
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 19741/30000 (65.8033%),                 avg. length: 1447.15,                last time consumption/overall running time: 201.9210s / 201430.8504 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.4741
env0_second_0:                 episode reward: 6.3000,                 loss: 2.2503
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 19761/30000 (65.8700%),                 avg. length: 1292.1,                last time consumption/overall running time: 184.0154s / 201614.8658 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.2187
env0_second_0:                 episode reward: 15.8000,                 loss: 2.4026
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 19781/30000 (65.9367%),                 avg. length: 1293.95,                last time consumption/overall running time: 184.7736s / 201799.6394 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.2553
env0_second_0:                 episode reward: 16.3500,                 loss: 1.1084
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 19801/30000 (66.0033%),                 avg. length: 1384.85,                last time consumption/overall running time: 201.7775s / 202001.4169 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.3994
env0_second_0:                 episode reward: 12.8000,                 loss: 1.1316
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 19821/30000 (66.0700%),                 avg. length: 1595.15,                last time consumption/overall running time: 219.7581s / 202221.1750 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.2560
env0_second_0:                 episode reward: 14.3500,                 loss: 1.5615
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 19841/30000 (66.1367%),                 avg. length: 1380.8,                last time consumption/overall running time: 193.2155s / 202414.3905 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.2778
env0_second_0:                 episode reward: 15.2000,                 loss: 0.9573
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 19861/30000 (66.2033%),                 avg. length: 1599.75,                last time consumption/overall running time: 220.1586s / 202634.5491 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.1862
env0_second_0:                 episode reward: 16.6500,                 loss: 0.7403
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 19881/30000 (66.2700%),                 avg. length: 1753.15,                last time consumption/overall running time: 237.5364s / 202872.0855 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.3355
env0_second_0:                 episode reward: 13.5500,                 loss: 1.7149
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 19901/30000 (66.3367%),                 avg. length: 1707.3,                last time consumption/overall running time: 236.6217s / 203108.7072 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.1547
env0_second_0:                 episode reward: 17.6000,                 loss: 0.8393
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 19921/30000 (66.4033%),                 avg. length: 1642.2,                last time consumption/overall running time: 226.0797s / 203334.7869 s
env0_first_0:                 episode reward: -17.1500,                 loss: 0.1256
env0_second_0:                 episode reward: 17.1500,                 loss: 0.8012
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 19941/30000 (66.4700%),                 avg. length: 1621.2,                last time consumption/overall running time: 227.8641s / 203562.6511 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.2323
env0_second_0:                 episode reward: 13.7500,                 loss: 1.0730
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 19961/30000 (66.5367%),                 avg. length: 1719.65,                last time consumption/overall running time: 238.4251s / 203801.0761 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.1600
env0_second_0:                 episode reward: 15.4000,                 loss: 1.2487
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 19981/30000 (66.6033%),                 avg. length: 1019.35,                last time consumption/overall running time: 144.8845s / 203945.9607 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3209
env0_second_0:                 episode reward: -0.6500,                 loss: 1.3196
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 20001/30000 (66.6700%),                 avg. length: 734.95,                last time consumption/overall running time: 104.4243s / 204050.3850 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0330
env0_second_0:                 episode reward: -20.6000,                 loss: 1.1399
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 20021/30000 (66.7367%),                 avg. length: 776.95,                last time consumption/overall running time: 109.8139s / 204160.1989 s
env0_first_0:                 episode reward: 19.5500,                 loss: 0.1368
env0_second_0:                 episode reward: -19.5500,                 loss: 0.9577
env1_first_0:                 episode reward: 19.1500,                 loss: nan
env1_second_0:                 episode reward: -19.1500,                 loss: nan
Episode: 20041/30000 (66.8033%),                 avg. length: 1673.85,                last time consumption/overall running time: 225.7802s / 204385.9790 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3403
env0_second_0:                 episode reward: 2.1500,                 loss: 1.2822
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 20061/30000 (66.8700%),                 avg. length: 1292.45,                last time consumption/overall running time: 179.8517s / 204565.8307 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1928
env0_second_0:                 episode reward: 15.2000,                 loss: 0.9179
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 20081/30000 (66.9367%),                 avg. length: 1223.5,                last time consumption/overall running time: 169.5023s / 204735.3330 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.3874
env0_second_0:                 episode reward: 9.6500,                 loss: 1.3197
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 20101/30000 (67.0033%),                 avg. length: 1228.55,                last time consumption/overall running time: 168.1814s / 204903.5144 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.3108
env0_second_0:                 episode reward: 16.5500,                 loss: 0.8576
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 20121/30000 (67.0700%),                 avg. length: 1357.35,                last time consumption/overall running time: 185.4584s / 205088.9728 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.2725
env0_second_0:                 episode reward: 14.8000,                 loss: 0.7867
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 20141/30000 (67.1367%),                 avg. length: 1455.05,                last time consumption/overall running time: 199.8364s / 205288.8092 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.2847
env0_second_0:                 episode reward: 12.7000,                 loss: 0.8439
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 20161/30000 (67.2033%),                 avg. length: 1251.35,                last time consumption/overall running time: 172.9766s / 205461.7857 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.3798
env0_second_0:                 episode reward: 11.7500,                 loss: 0.7718
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 20181/30000 (67.2700%),                 avg. length: 1401.1,                last time consumption/overall running time: 192.4319s / 205654.2176 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.3177
env0_second_0:                 episode reward: 14.0000,                 loss: 0.6280
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 20201/30000 (67.3367%),                 avg. length: 1532.95,                last time consumption/overall running time: 209.0248s / 205863.2424 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.3308
env0_second_0:                 episode reward: 15.0000,                 loss: 0.7018
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 20221/30000 (67.4033%),                 avg. length: 1053.65,                last time consumption/overall running time: 150.2272s / 206013.4696 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.6811
env0_second_0:                 episode reward: 9.0000,                 loss: 1.3150
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 20241/30000 (67.4700%),                 avg. length: 1097.6,                last time consumption/overall running time: 153.1972s / 206166.6668 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.4821
env0_second_0:                 episode reward: 7.7000,                 loss: 1.2462
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 20261/30000 (67.5367%),                 avg. length: 728.45,                last time consumption/overall running time: 102.3522s / 206269.0190 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1172
env0_second_0:                 episode reward: -20.8500,                 loss: 1.0716
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 20281/30000 (67.6033%),                 avg. length: 728.05,                last time consumption/overall running time: 105.1943s / 206374.2133 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0351
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9530
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 20301/30000 (67.6700%),                 avg. length: 728.25,                last time consumption/overall running time: 109.2890s / 206483.5023 s
env0_first_0:                 episode reward: 19.5000,                 loss: 0.0623
env0_second_0:                 episode reward: -19.5000,                 loss: 0.6465
env1_first_0:                 episode reward: 20.2500,                 loss: nan
env1_second_0:                 episode reward: -20.2500,                 loss: nan
Episode: 20321/30000 (67.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 103.7220s / 206587.2243 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0263
env0_second_0:                 episode reward: -20.6500,                 loss: 0.1572
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 20341/30000 (67.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 105.6843s / 206692.9086 s
env0_first_0:                 episode reward: 20.8500,                 loss: -0.0141
env0_second_0:                 episode reward: -20.8500,                 loss: 0.2726
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 20361/30000 (67.8700%),                 avg. length: 1060.9,                last time consumption/overall running time: 145.4328s / 206838.3414 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.6313
env0_second_0:                 episode reward: 5.2500,                 loss: 1.8814
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 20381/30000 (67.9367%),                 avg. length: 1476.05,                last time consumption/overall running time: 199.3455s / 207037.6869 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.5009
env0_second_0:                 episode reward: 6.9500,                 loss: 1.3586
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 20401/30000 (68.0033%),                 avg. length: 1801.65,                last time consumption/overall running time: 247.6031s / 207285.2901 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2587
env0_second_0:                 episode reward: 11.9000,                 loss: 0.8989
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 20421/30000 (68.0700%),                 avg. length: 1711.2,                last time consumption/overall running time: 239.0673s / 207524.3574 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1603
env0_second_0:                 episode reward: 14.9500,                 loss: 0.9838
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 20441/30000 (68.1367%),                 avg. length: 1843.5,                last time consumption/overall running time: 257.5325s / 207781.8899 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1427
env0_second_0:                 episode reward: 14.1000,                 loss: 0.7935
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 20461/30000 (68.2033%),                 avg. length: 1837.1,                last time consumption/overall running time: 254.9016s / 208036.7915 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1216
env0_second_0:                 episode reward: 13.3000,                 loss: 0.7979
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 20481/30000 (68.2700%),                 avg. length: 1777.85,                last time consumption/overall running time: 242.6047s / 208279.3962 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0512
env0_second_0:                 episode reward: 16.8000,                 loss: 0.8918
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 20501/30000 (68.3367%),                 avg. length: 1877.3,                last time consumption/overall running time: 257.0158s / 208536.4120 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0686
env0_second_0:                 episode reward: 13.3000,                 loss: 1.0207
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 20521/30000 (68.4033%),                 avg. length: 1978.2,                last time consumption/overall running time: 273.8245s / 208810.2364 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0493
env0_second_0:                 episode reward: 14.4000,                 loss: 0.8209
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 20541/30000 (68.4700%),                 avg. length: 2096.35,                last time consumption/overall running time: 290.6592s / 209100.8956 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.1606
env0_second_0:                 episode reward: 10.0000,                 loss: 1.1029
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 20561/30000 (68.5367%),                 avg. length: 2052.8,                last time consumption/overall running time: 274.5309s / 209375.4265 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1074
env0_second_0:                 episode reward: 12.7500,                 loss: 0.7067
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 20581/30000 (68.6033%),                 avg. length: 1832.5,                last time consumption/overall running time: 242.9762s / 209618.4026 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1278
env0_second_0:                 episode reward: 15.1500,                 loss: 0.6530
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 20601/30000 (68.6700%),                 avg. length: 1094.55,                last time consumption/overall running time: 154.9263s / 209773.3290 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.4151
env0_second_0:                 episode reward: 14.5500,                 loss: 1.0863
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 20621/30000 (68.7367%),                 avg. length: 1698.85,                last time consumption/overall running time: 234.4115s / 210007.7405 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1582
env0_second_0:                 episode reward: 15.5500,                 loss: 0.6296
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 20641/30000 (68.8033%),                 avg. length: 1659.0,                last time consumption/overall running time: 231.4644s / 210239.2049 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.1074
env0_second_0:                 episode reward: 16.3500,                 loss: 0.7669
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 20661/30000 (68.8700%),                 avg. length: 1699.5,                last time consumption/overall running time: 238.6423s / 210477.8472 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.2783
env0_second_0:                 episode reward: 13.7000,                 loss: 1.2878
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 20681/30000 (68.9367%),                 avg. length: 1527.8,                last time consumption/overall running time: 212.7408s / 210690.5880 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.4312
env0_second_0:                 episode reward: 12.0000,                 loss: 0.9333
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 20701/30000 (69.0033%),                 avg. length: 1315.0,                last time consumption/overall running time: 184.3692s / 210874.9572 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.1339
env0_second_0:                 episode reward: 17.6000,                 loss: 0.6669
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 20721/30000 (69.0700%),                 avg. length: 1259.75,                last time consumption/overall running time: 172.1851s / 211047.1423 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.2639
env0_second_0:                 episode reward: 16.5500,                 loss: 1.0617
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 20741/30000 (69.1367%),                 avg. length: 1576.5,                last time consumption/overall running time: 216.9381s / 211264.0804 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.4356
env0_second_0:                 episode reward: 12.8000,                 loss: 1.3261
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 20761/30000 (69.2033%),                 avg. length: 1754.0,                last time consumption/overall running time: 241.8571s / 211505.9375 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.1514
env0_second_0:                 episode reward: 16.0000,                 loss: 0.6894
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 20781/30000 (69.2700%),                 avg. length: 1947.95,                last time consumption/overall running time: 265.4653s / 211771.4028 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1139
env0_second_0:                 episode reward: 15.1500,                 loss: 0.5503
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 20801/30000 (69.3367%),                 avg. length: 2130.05,                last time consumption/overall running time: 294.1834s / 212065.5862 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0780
env0_second_0:                 episode reward: 15.5000,                 loss: 0.4313
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 20821/30000 (69.4033%),                 avg. length: 2086.9,                last time consumption/overall running time: 291.8344s / 212357.4206 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.1084
env0_second_0:                 episode reward: 16.2500,                 loss: 0.4726
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 20841/30000 (69.4700%),                 avg. length: 2184.65,                last time consumption/overall running time: 294.6621s / 212652.0827 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.2421
env0_second_0:                 episode reward: 4.7500,                 loss: 2.0421
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 20861/30000 (69.5367%),                 avg. length: 1028.45,                last time consumption/overall running time: 144.6753s / 212796.7580 s
env0_first_0:                 episode reward: 16.0000,                 loss: 0.3649
env0_second_0:                 episode reward: -16.0000,                 loss: 2.3727
env1_first_0:                 episode reward: 16.0000,                 loss: nan
env1_second_0:                 episode reward: -16.0000,                 loss: nan
Episode: 20881/30000 (69.6033%),                 avg. length: 2085.05,                last time consumption/overall running time: 281.2449s / 213078.0029 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.2917
env0_second_0:                 episode reward: -1.7000,                 loss: 2.2253
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 20901/30000 (69.6700%),                 avg. length: 1605.55,                last time consumption/overall running time: 217.0428s / 213295.0457 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.2924
env0_second_0:                 episode reward: 8.9000,                 loss: 0.6008
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 20921/30000 (69.7367%),                 avg. length: 2126.6,                last time consumption/overall running time: 289.0777s / 213584.1234 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.2046
env0_second_0:                 episode reward: 7.7500,                 loss: 0.5237
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 20941/30000 (69.8033%),                 avg. length: 1633.6,                last time consumption/overall running time: 225.3508s / 213809.4742 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.2387
env0_second_0:                 episode reward: 13.9500,                 loss: 0.4989
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 20961/30000 (69.8700%),                 avg. length: 1747.5,                last time consumption/overall running time: 236.4279s / 214045.9021 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1990
env0_second_0:                 episode reward: 13.3000,                 loss: 0.4987
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 20981/30000 (69.9367%),                 avg. length: 1607.3,                last time consumption/overall running time: 217.5525s / 214263.4546 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.3259
env0_second_0:                 episode reward: 10.3000,                 loss: 0.6465
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 21001/30000 (70.0033%),                 avg. length: 1420.65,                last time consumption/overall running time: 194.1554s / 214457.6100 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.2270
env0_second_0:                 episode reward: 17.2500,                 loss: 0.5758
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 21021/30000 (70.0700%),                 avg. length: 1568.35,                last time consumption/overall running time: 217.3850s / 214674.9949 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.3000
env0_second_0:                 episode reward: 11.5500,                 loss: 0.5763
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 21041/30000 (70.1367%),                 avg. length: 1439.5,                last time consumption/overall running time: 200.1263s / 214875.1212 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.3197
env0_second_0:                 episode reward: 12.1000,                 loss: 0.7037
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 21061/30000 (70.2033%),                 avg. length: 1442.4,                last time consumption/overall running time: 201.7371s / 215076.8583 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.2087
env0_second_0:                 episode reward: 14.4500,                 loss: 0.5317
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 21081/30000 (70.2700%),                 avg. length: 1442.15,                last time consumption/overall running time: 200.5699s / 215277.4282 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.2795
env0_second_0:                 episode reward: 13.0500,                 loss: 0.6318
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 21101/30000 (70.3367%),                 avg. length: 830.25,                last time consumption/overall running time: 119.7960s / 215397.2242 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3904
env0_second_0:                 episode reward: 1.3000,                 loss: 1.2444
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 21121/30000 (70.4033%),                 avg. length: 809.05,                last time consumption/overall running time: 118.5371s / 215515.7613 s
env0_first_0:                 episode reward: -19.1500,                 loss: 0.3089
env0_second_0:                 episode reward: 19.1500,                 loss: 0.8471
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 21141/30000 (70.4700%),                 avg. length: 964.35,                last time consumption/overall running time: 136.2069s / 215651.9682 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.2344
env0_second_0:                 episode reward: 17.2500,                 loss: 0.8548
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 21161/30000 (70.5367%),                 avg. length: 1028.0,                last time consumption/overall running time: 141.9467s / 215793.9149 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.3288
env0_second_0:                 episode reward: 14.6500,                 loss: 0.7754
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 21181/30000 (70.6033%),                 avg. length: 1226.85,                last time consumption/overall running time: 170.4534s / 215964.3684 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.2789
env0_second_0:                 episode reward: 16.6500,                 loss: 0.7392
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 21201/30000 (70.6700%),                 avg. length: 1102.35,                last time consumption/overall running time: 156.3319s / 216120.7003 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.3716
env0_second_0:                 episode reward: 16.6000,                 loss: 0.8956
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 21221/30000 (70.7367%),                 avg. length: 941.9,                last time consumption/overall running time: 134.4336s / 216255.1339 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.3567
env0_second_0:                 episode reward: 16.6500,                 loss: 1.2493
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 21241/30000 (70.8033%),                 avg. length: 848.65,                last time consumption/overall running time: 120.8350s / 216375.9689 s
env0_first_0:                 episode reward: -17.9500,                 loss: 0.1952
env0_second_0:                 episode reward: 17.9500,                 loss: 1.0981
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 21261/30000 (70.8700%),                 avg. length: 924.35,                last time consumption/overall running time: 127.5248s / 216503.4936 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.2792
env0_second_0:                 episode reward: 15.1500,                 loss: 1.0471
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 21281/30000 (70.9367%),                 avg. length: 1126.15,                last time consumption/overall running time: 157.1240s / 216660.6177 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.3955
env0_second_0:                 episode reward: 15.8500,                 loss: 1.3752
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 21301/30000 (71.0033%),                 avg. length: 1834.45,                last time consumption/overall running time: 256.8120s / 216917.4297 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.2887
env0_second_0:                 episode reward: 10.6000,                 loss: 1.3402
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 21321/30000 (71.0700%),                 avg. length: 1810.15,                last time consumption/overall running time: 247.5384s / 217164.9681 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.1181
env0_second_0:                 episode reward: 14.3500,                 loss: 1.2372
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 21341/30000 (71.1367%),                 avg. length: 1679.65,                last time consumption/overall running time: 233.7016s / 217398.6698 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0903
env0_second_0:                 episode reward: 16.8500,                 loss: 1.0833
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 21361/30000 (71.2033%),                 avg. length: 1499.8,                last time consumption/overall running time: 206.9895s / 217605.6593 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.1370
env0_second_0:                 episode reward: 15.9000,                 loss: 0.9884
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 21381/30000 (71.2700%),                 avg. length: 1616.3,                last time consumption/overall running time: 221.1367s / 217826.7959 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.2675
env0_second_0:                 episode reward: 13.1500,                 loss: 1.0250
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 21401/30000 (71.3367%),                 avg. length: 1620.35,                last time consumption/overall running time: 225.1244s / 218051.9203 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.1381
env0_second_0:                 episode reward: 15.0000,                 loss: 0.7961
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 21421/30000 (71.4033%),                 avg. length: 1650.6,                last time consumption/overall running time: 227.0578s / 218278.9781 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1338
env0_second_0:                 episode reward: 15.2000,                 loss: 1.9354
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 21441/30000 (71.4700%),                 avg. length: 1686.2,                last time consumption/overall running time: 232.5842s / 218511.5623 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.3181
env0_second_0:                 episode reward: 9.9500,                 loss: 2.7356
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 21461/30000 (71.5367%),                 avg. length: 1843.6,                last time consumption/overall running time: 255.1249s / 218766.6872 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.1169
env0_second_0:                 episode reward: 16.2500,                 loss: 0.9220
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 21481/30000 (71.6033%),                 avg. length: 1802.75,                last time consumption/overall running time: 246.8756s / 219013.5628 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0674
env0_second_0:                 episode reward: 16.9000,                 loss: 0.7842
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 21501/30000 (71.6700%),                 avg. length: 1788.8,                last time consumption/overall running time: 240.8220s / 219254.3848 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.1062
env0_second_0:                 episode reward: 15.9500,                 loss: 1.2084
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 21521/30000 (71.7367%),                 avg. length: 1717.15,                last time consumption/overall running time: 234.1091s / 219488.4940 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0858
env0_second_0:                 episode reward: 15.7000,                 loss: 0.7397
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 21541/30000 (71.8033%),                 avg. length: 1824.55,                last time consumption/overall running time: 256.2413s / 219744.7353 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.1663
env0_second_0:                 episode reward: 14.0500,                 loss: 0.9272
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 21561/30000 (71.8700%),                 avg. length: 1831.95,                last time consumption/overall running time: 252.2478s / 219996.9831 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0884
env0_second_0:                 episode reward: 16.9000,                 loss: 0.8747
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 21581/30000 (71.9367%),                 avg. length: 2071.1,                last time consumption/overall running time: 290.1005s / 220287.0837 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0593
env0_second_0:                 episode reward: 15.9000,                 loss: 0.5402
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 21601/30000 (72.0033%),                 avg. length: 2087.45,                last time consumption/overall running time: 284.0310s / 220571.1147 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.0823
env0_second_0:                 episode reward: 15.0500,                 loss: 0.5433
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 21621/30000 (72.0700%),                 avg. length: 1883.3,                last time consumption/overall running time: 258.2533s / 220829.3680 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.0878
env0_second_0:                 episode reward: 16.1000,                 loss: 0.6343
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 21641/30000 (72.1367%),                 avg. length: 1913.9,                last time consumption/overall running time: 266.5650s / 221095.9330 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1878
env0_second_0:                 episode reward: 13.0000,                 loss: 1.0568
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 21661/30000 (72.2033%),                 avg. length: 2306.5,                last time consumption/overall running time: 318.1485s / 221414.0816 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1271
env0_second_0:                 episode reward: 13.8000,                 loss: 1.0160
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 21681/30000 (72.2700%),                 avg. length: 2094.95,                last time consumption/overall running time: 290.4645s / 221704.5460 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0817
env0_second_0:                 episode reward: 15.3000,                 loss: 0.8944
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 21701/30000 (72.3367%),                 avg. length: 2100.5,                last time consumption/overall running time: 286.9159s / 221991.4620 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.0470
env0_second_0:                 episode reward: 16.9500,                 loss: 0.6978
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 21721/30000 (72.4033%),                 avg. length: 2245.1,                last time consumption/overall running time: 302.1318s / 222293.5938 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0505
env0_second_0:                 episode reward: 15.8500,                 loss: 0.7539
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 21741/30000 (72.4700%),                 avg. length: 2295.05,                last time consumption/overall running time: 308.7051s / 222602.2989 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.0403
env0_second_0:                 episode reward: 16.5500,                 loss: 0.6412
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 21761/30000 (72.5367%),                 avg. length: 2144.7,                last time consumption/overall running time: 293.6844s / 222895.9833 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1665
env0_second_0:                 episode reward: 12.7500,                 loss: 0.7698
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 21781/30000 (72.6033%),                 avg. length: 2141.95,                last time consumption/overall running time: 289.8667s / 223185.8500 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0992
env0_second_0:                 episode reward: 14.6500,                 loss: 0.7810
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 21801/30000 (72.6700%),                 avg. length: 2283.65,                last time consumption/overall running time: 309.6346s / 223495.4846 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.2078
env0_second_0:                 episode reward: 8.9500,                 loss: 0.9115
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 21821/30000 (72.7367%),                 avg. length: 2139.35,                last time consumption/overall running time: 284.8025s / 223780.2872 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1383
env0_second_0:                 episode reward: 12.6500,                 loss: 0.7978
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 21841/30000 (72.8033%),                 avg. length: 1884.95,                last time consumption/overall running time: 253.7766s / 224034.0638 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.3165
env0_second_0:                 episode reward: 4.3000,                 loss: 1.0885
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 21861/30000 (72.8700%),                 avg. length: 1513.25,                last time consumption/overall running time: 203.6651s / 224237.7288 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.4740
env0_second_0:                 episode reward: 0.2500,                 loss: 1.0754
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 21881/30000 (72.9367%),                 avg. length: 2063.1,                last time consumption/overall running time: 277.5112s / 224515.2400 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1098
env0_second_0:                 episode reward: 15.2000,                 loss: 0.9113
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 21901/30000 (73.0033%),                 avg. length: 2064.9,                last time consumption/overall running time: 278.4011s / 224793.6411 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1631
env0_second_0:                 episode reward: 15.2000,                 loss: 0.9810
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 21921/30000 (73.0700%),                 avg. length: 2180.5,                last time consumption/overall running time: 292.7025s / 225086.3436 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.1706
env0_second_0:                 episode reward: 9.8500,                 loss: 1.1132
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 21941/30000 (73.1367%),                 avg. length: 2146.55,                last time consumption/overall running time: 287.8292s / 225374.1728 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.0611
env0_second_0:                 episode reward: 17.4000,                 loss: 0.9210
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 21961/30000 (73.2033%),                 avg. length: 1040.45,                last time consumption/overall running time: 146.4024s / 225520.5752 s
env0_first_0:                 episode reward: 11.0500,                 loss: 0.4204
env0_second_0:                 episode reward: -11.0500,                 loss: 1.5406
env1_first_0:                 episode reward: 9.4500,                 loss: nan
env1_second_0:                 episode reward: -9.4500,                 loss: nan
Episode: 21981/30000 (73.2700%),                 avg. length: 1926.95,                last time consumption/overall running time: 264.2761s / 225784.8513 s
env0_first_0:                 episode reward: 7.0500,                 loss: 0.3331
env0_second_0:                 episode reward: -7.0500,                 loss: 0.8063
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 22001/30000 (73.3367%),                 avg. length: 2600.7,                last time consumption/overall running time: 353.8140s / 226138.6653 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1916
env0_second_0:                 episode reward: 2.5000,                 loss: 0.6693
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 22021/30000 (73.4033%),                 avg. length: 2416.25,                last time consumption/overall running time: 327.5562s / 226466.2215 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.2837
env0_second_0:                 episode reward: -3.0000,                 loss: 0.7310
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 22041/30000 (73.4700%),                 avg. length: 2616.7,                last time consumption/overall running time: 352.3092s / 226818.5308 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.1563
env0_second_0:                 episode reward: 6.3500,                 loss: 0.7075
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 22061/30000 (73.5367%),                 avg. length: 2293.95,                last time consumption/overall running time: 325.5352s / 227144.0660 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.1240
env0_second_0:                 episode reward: 11.9500,                 loss: 0.6012
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 22081/30000 (73.6033%),                 avg. length: 2586.2,                last time consumption/overall running time: 361.2653s / 227505.3313 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0930
env0_second_0:                 episode reward: 11.9000,                 loss: 0.5148
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 22101/30000 (73.6700%),                 avg. length: 2455.45,                last time consumption/overall running time: 356.3546s / 227861.6858 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1289
env0_second_0:                 episode reward: 12.7000,                 loss: 0.5642
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 22121/30000 (73.7367%),                 avg. length: 2429.15,                last time consumption/overall running time: 338.7056s / 228200.3915 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1057
env0_second_0:                 episode reward: 11.5500,                 loss: 0.5635
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 22141/30000 (73.8033%),                 avg. length: 2396.25,                last time consumption/overall running time: 333.4347s / 228533.8261 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0521
env0_second_0:                 episode reward: 15.9500,                 loss: 0.4963
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 22161/30000 (73.8700%),                 avg. length: 2230.1,                last time consumption/overall running time: 301.9662s / 228835.7924 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.0728
env0_second_0:                 episode reward: 15.8000,                 loss: 1.2266
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 22181/30000 (73.9367%),                 avg. length: 2396.05,                last time consumption/overall running time: 320.2991s / 229156.0915 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0502
env0_second_0:                 episode reward: 17.1000,                 loss: 0.6781
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 22201/30000 (74.0033%),                 avg. length: 2469.65,                last time consumption/overall running time: 337.3811s / 229493.4726 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.1267
env0_second_0:                 episode reward: 13.6000,                 loss: 0.6670
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 22221/30000 (74.0700%),                 avg. length: 2399.25,                last time consumption/overall running time: 328.3524s / 229821.8250 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0361
env0_second_0:                 episode reward: 16.6500,                 loss: 0.4372
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 22241/30000 (74.1367%),                 avg. length: 2365.55,                last time consumption/overall running time: 325.0199s / 230146.8448 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0514
env0_second_0:                 episode reward: 15.2500,                 loss: 0.3989
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 22261/30000 (74.2033%),                 avg. length: 2293.2,                last time consumption/overall running time: 319.4084s / 230466.2533 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0101
env0_second_0:                 episode reward: 16.6500,                 loss: 0.3748
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 22281/30000 (74.2700%),                 avg. length: 2155.35,                last time consumption/overall running time: 300.7599s / 230767.0132 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.2621
env0_second_0:                 episode reward: 5.6500,                 loss: 0.8495
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 22301/30000 (74.3367%),                 avg. length: 2794.95,                last time consumption/overall running time: 387.5381s / 231154.5512 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.1856
env0_second_0:                 episode reward: -1.4000,                 loss: 0.5629
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22321/30000 (74.4033%),                 avg. length: 2552.6,                last time consumption/overall running time: 345.8945s / 231500.4458 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.1123
env0_second_0:                 episode reward: 10.4000,                 loss: 0.5204
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 22341/30000 (74.4700%),                 avg. length: 2179.35,                last time consumption/overall running time: 305.0252s / 231805.4710 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0522
env0_second_0:                 episode reward: 15.2000,                 loss: 0.5065
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 22361/30000 (74.5367%),                 avg. length: 2299.4,                last time consumption/overall running time: 313.6732s / 232119.1442 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0522
env0_second_0:                 episode reward: 16.3500,                 loss: 0.9114
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 22381/30000 (74.6033%),                 avg. length: 1944.0,                last time consumption/overall running time: 272.5088s / 232391.6530 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.2063
env0_second_0:                 episode reward: 9.5500,                 loss: 1.4088
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 22401/30000 (74.6700%),                 avg. length: 779.7,                last time consumption/overall running time: 114.8344s / 232506.4874 s
env0_first_0:                 episode reward: 18.8500,                 loss: 0.2475
env0_second_0:                 episode reward: -18.8500,                 loss: 2.8606
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 22421/30000 (74.7367%),                 avg. length: 733.0,                last time consumption/overall running time: 106.1113s / 232612.5987 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0819
env0_second_0:                 episode reward: -20.6500,                 loss: 0.8203
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 22441/30000 (74.8033%),                 avg. length: 786.2,                last time consumption/overall running time: 111.9112s / 232724.5099 s
env0_first_0:                 episode reward: 18.4000,                 loss: 0.2388
env0_second_0:                 episode reward: -18.4000,                 loss: 1.0078
env1_first_0:                 episode reward: 17.3000,                 loss: nan
env1_second_0:                 episode reward: -17.3000,                 loss: nan
Episode: 22461/30000 (74.8700%),                 avg. length: 2038.0,                last time consumption/overall running time: 280.7847s / 233005.2946 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.2696
env0_second_0:                 episode reward: -5.8500,                 loss: 1.3897
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 22481/30000 (74.9367%),                 avg. length: 2449.55,                last time consumption/overall running time: 334.0177s / 233339.3122 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.1571
env0_second_0:                 episode reward: 6.4000,                 loss: 1.0349
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 22501/30000 (75.0033%),                 avg. length: 2152.35,                last time consumption/overall running time: 294.3619s / 233633.6742 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0893
env0_second_0:                 episode reward: 15.1500,                 loss: 0.7244
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 22521/30000 (75.0700%),                 avg. length: 1994.9,                last time consumption/overall running time: 275.2511s / 233908.9253 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.2219
env0_second_0:                 episode reward: 12.0500,                 loss: 1.1064
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 22541/30000 (75.1367%),                 avg. length: 2014.3,                last time consumption/overall running time: 270.4208s / 234179.3461 s
env0_first_0:                 episode reward: -17.5000,                 loss: 0.0556
env0_second_0:                 episode reward: 17.5000,                 loss: 1.1522
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 22561/30000 (75.2033%),                 avg. length: 2256.35,                last time consumption/overall running time: 304.6499s / 234483.9960 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0709
env0_second_0:                 episode reward: 16.2000,                 loss: 1.0698
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 22581/30000 (75.2700%),                 avg. length: 2205.5,                last time consumption/overall running time: 295.4139s / 234779.4099 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.0066
env0_second_0:                 episode reward: 18.0000,                 loss: 1.2743
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 22601/30000 (75.3367%),                 avg. length: 2152.85,                last time consumption/overall running time: 286.6038s / 235066.0137 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.1285
env0_second_0:                 episode reward: 12.1500,                 loss: 1.3752
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 22621/30000 (75.4033%),                 avg. length: 1517.45,                last time consumption/overall running time: 208.3203s / 235274.3341 s
env0_first_0:                 episode reward: 13.8000,                 loss: 0.2399
env0_second_0:                 episode reward: -13.8000,                 loss: 0.8584
env1_first_0:                 episode reward: 13.9500,                 loss: nan
env1_second_0:                 episode reward: -13.9500,                 loss: nan
Episode: 22641/30000 (75.4700%),                 avg. length: 1859.25,                last time consumption/overall running time: 251.9207s / 235526.2547 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.2034
env0_second_0:                 episode reward: -10.0000,                 loss: 0.7291
env1_first_0:                 episode reward: 9.1500,                 loss: nan
env1_second_0:                 episode reward: -9.1500,                 loss: nan
Episode: 22661/30000 (75.5367%),                 avg. length: 2814.1,                last time consumption/overall running time: 371.1925s / 235897.4472 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1929
env0_second_0:                 episode reward: 1.7500,                 loss: 0.7539
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 22681/30000 (75.6033%),                 avg. length: 2590.9,                last time consumption/overall running time: 345.7812s / 236243.2284 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.1405
env0_second_0:                 episode reward: 7.1000,                 loss: 0.6194
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 22701/30000 (75.6700%),                 avg. length: 2495.15,                last time consumption/overall running time: 338.7305s / 236581.9589 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1094
env0_second_0:                 episode reward: 12.2000,                 loss: 0.8297
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 22721/30000 (75.7367%),                 avg. length: 2323.3,                last time consumption/overall running time: 316.0954s / 236898.0543 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0806
env0_second_0:                 episode reward: 15.3500,                 loss: 1.7004
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 22741/30000 (75.8033%),                 avg. length: 2250.95,                last time consumption/overall running time: 306.8991s / 237204.9535 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0445
env0_second_0:                 episode reward: 15.4500,                 loss: 3.0785
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 22761/30000 (75.8700%),                 avg. length: 2170.85,                last time consumption/overall running time: 300.7921s / 237505.7456 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0601
env0_second_0:                 episode reward: 16.2500,                 loss: 4.1313
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 22781/30000 (75.9367%),                 avg. length: 1098.95,                last time consumption/overall running time: 159.1382s / 237664.8838 s
env0_first_0:                 episode reward: 9.7000,                 loss: 0.3942
env0_second_0:                 episode reward: -9.7000,                 loss: 2.2554
env1_first_0:                 episode reward: 8.7500,                 loss: nan
env1_second_0:                 episode reward: -8.7500,                 loss: nan
Episode: 22801/30000 (76.0033%),                 avg. length: 731.75,                last time consumption/overall running time: 109.2852s / 237774.1690 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1271
env0_second_0:                 episode reward: -20.7000,                 loss: 1.1325
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 22821/30000 (76.0700%),                 avg. length: 1447.15,                last time consumption/overall running time: 204.2060s / 237978.3750 s
env0_first_0:                 episode reward: 10.4000,                 loss: 0.4059
env0_second_0:                 episode reward: -10.4000,                 loss: 1.7956
env1_first_0:                 episode reward: 11.9000,                 loss: nan
env1_second_0:                 episode reward: -11.9000,                 loss: nan
Episode: 22841/30000 (76.1367%),                 avg. length: 2474.25,                last time consumption/overall running time: 341.8892s / 238320.2642 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.2275
env0_second_0:                 episode reward: 6.2500,                 loss: 1.8940
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 22861/30000 (76.2033%),                 avg. length: 2410.15,                last time consumption/overall running time: 327.4231s / 238647.6873 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.1835
env0_second_0:                 episode reward: 10.1500,                 loss: 4.7469
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 22881/30000 (76.2700%),                 avg. length: 2579.9,                last time consumption/overall running time: 352.2676s / 238999.9549 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.1290
env0_second_0:                 episode reward: 10.7500,                 loss: 4.0682
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 22901/30000 (76.3367%),                 avg. length: 2616.8,                last time consumption/overall running time: 351.5482s / 239351.5031 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.1425
env0_second_0:                 episode reward: 11.2000,                 loss: 3.2148
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 22921/30000 (76.4033%),                 avg. length: 2277.2,                last time consumption/overall running time: 314.1579s / 239665.6610 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.1478
env0_second_0:                 episode reward: 14.0500,                 loss: 2.2465
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 22941/30000 (76.4700%),                 avg. length: 2386.4,                last time consumption/overall running time: 329.3728s / 239995.0338 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1187
env0_second_0:                 episode reward: 13.0500,                 loss: 1.6364
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 22961/30000 (76.5367%),                 avg. length: 2321.05,                last time consumption/overall running time: 322.7004s / 240317.7342 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1058
env0_second_0:                 episode reward: 14.2000,                 loss: 1.3838
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 22981/30000 (76.6033%),                 avg. length: 2270.35,                last time consumption/overall running time: 311.0177s / 240628.7519 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1297
env0_second_0:                 episode reward: 14.2000,                 loss: 1.3682
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 23001/30000 (76.6700%),                 avg. length: 2302.45,                last time consumption/overall running time: 316.4875s / 240945.2393 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1175
env0_second_0:                 episode reward: 13.1000,                 loss: 1.2607
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 23021/30000 (76.7367%),                 avg. length: 2210.1,                last time consumption/overall running time: 299.3346s / 241244.5739 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1503
env0_second_0:                 episode reward: 12.9500,                 loss: 1.2784
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 23041/30000 (76.8033%),                 avg. length: 2208.2,                last time consumption/overall running time: 309.2130s / 241553.7869 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0897
env0_second_0:                 episode reward: 14.4000,                 loss: 1.3187
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 23061/30000 (76.8700%),                 avg. length: 2219.1,                last time consumption/overall running time: 303.5871s / 241857.3740 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0943
env0_second_0:                 episode reward: 15.4000,                 loss: 1.1264
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 23081/30000 (76.9367%),                 avg. length: 2197.95,                last time consumption/overall running time: 309.0741s / 242166.4482 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0838
env0_second_0:                 episode reward: 16.2000,                 loss: 1.1557
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 23101/30000 (77.0033%),                 avg. length: 2183.9,                last time consumption/overall running time: 297.0898s / 242463.5380 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0912
env0_second_0:                 episode reward: 16.4500,                 loss: 1.3194
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 23121/30000 (77.0700%),                 avg. length: 2139.05,                last time consumption/overall running time: 298.2621s / 242761.8001 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0758
env0_second_0:                 episode reward: 16.2500,                 loss: 3.7030
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 23141/30000 (77.1367%),                 avg. length: 2127.85,                last time consumption/overall running time: 298.6479s / 243060.4481 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1057
env0_second_0:                 episode reward: 13.5000,                 loss: 2.9018
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 23161/30000 (77.2033%),                 avg. length: 2242.65,                last time consumption/overall running time: 308.6342s / 243369.0823 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0924
env0_second_0:                 episode reward: 13.5500,                 loss: 2.3234
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 23181/30000 (77.2700%),                 avg. length: 2054.35,                last time consumption/overall running time: 278.2217s / 243647.3040 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.0885
env0_second_0:                 episode reward: 16.3000,                 loss: 1.5734
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 23201/30000 (77.3367%),                 avg. length: 2200.7,                last time consumption/overall running time: 306.4983s / 243953.8023 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.1034
env0_second_0:                 episode reward: 15.7500,                 loss: 1.5038
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 23221/30000 (77.4033%),                 avg. length: 2151.5,                last time consumption/overall running time: 293.7208s / 244247.5231 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1209
env0_second_0:                 episode reward: 14.6500,                 loss: 1.5075
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 23241/30000 (77.4700%),                 avg. length: 2165.95,                last time consumption/overall running time: 294.5188s / 244542.0419 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0952
env0_second_0:                 episode reward: 16.1500,                 loss: 1.1898
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 23261/30000 (77.5367%),                 avg. length: 2236.75,                last time consumption/overall running time: 307.9686s / 244850.0105 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0728
env0_second_0:                 episode reward: 16.4500,                 loss: 1.2147
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 23281/30000 (77.6033%),                 avg. length: 2099.25,                last time consumption/overall running time: 288.5069s / 245138.5174 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0828
env0_second_0:                 episode reward: 16.8000,                 loss: 1.4506
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 23301/30000 (77.6700%),                 avg. length: 2340.65,                last time consumption/overall running time: 314.6114s / 245453.1288 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1276
env0_second_0:                 episode reward: 13.3500,                 loss: 1.4270
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 23321/30000 (77.7367%),                 avg. length: 2381.45,                last time consumption/overall running time: 322.2528s / 245775.3815 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0810
env0_second_0:                 episode reward: 13.7500,                 loss: 1.3260
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 23341/30000 (77.8033%),                 avg. length: 2435.8,                last time consumption/overall running time: 326.6536s / 246102.0351 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0697
env0_second_0:                 episode reward: 14.6500,                 loss: 0.8253
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 23361/30000 (77.8700%),                 avg. length: 2290.5,                last time consumption/overall running time: 311.6601s / 246413.6953 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.1075
env0_second_0:                 episode reward: 16.3000,                 loss: 0.6249
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 23381/30000 (77.9367%),                 avg. length: 1933.85,                last time consumption/overall running time: 262.3017s / 246675.9969 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1860
env0_second_0:                 episode reward: 14.6000,                 loss: 0.8858
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 23401/30000 (78.0033%),                 avg. length: 1377.9,                last time consumption/overall running time: 189.5448s / 246865.5418 s
env0_first_0:                 episode reward: 7.2500,                 loss: 0.4868
env0_second_0:                 episode reward: -7.2500,                 loss: 1.4401
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
Episode: 23421/30000 (78.0700%),                 avg. length: 1847.75,                last time consumption/overall running time: 260.5165s / 247126.0583 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.4213
env0_second_0:                 episode reward: -0.2000,                 loss: 1.3573
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 23441/30000 (78.1367%),                 avg. length: 2241.55,                last time consumption/overall running time: 306.5514s / 247432.6097 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1432
env0_second_0:                 episode reward: 14.2000,                 loss: 0.6179
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 23461/30000 (78.2033%),                 avg. length: 2055.65,                last time consumption/overall running time: 282.9022s / 247715.5119 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1543
env0_second_0:                 episode reward: 12.8000,                 loss: 0.6269
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 23481/30000 (78.2700%),                 avg. length: 1936.1,                last time consumption/overall running time: 267.4839s / 247982.9958 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.1445
env0_second_0:                 episode reward: 15.0000,                 loss: 0.4916
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 23501/30000 (78.3367%),                 avg. length: 1797.5,                last time consumption/overall running time: 248.7278s / 248231.7236 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.1339
env0_second_0:                 episode reward: 15.4000,                 loss: 0.7922
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 23521/30000 (78.4033%),                 avg. length: 1727.75,                last time consumption/overall running time: 245.6918s / 248477.4154 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.1295
env0_second_0:                 episode reward: 17.3000,                 loss: 1.3704
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 23541/30000 (78.4700%),                 avg. length: 1709.3,                last time consumption/overall running time: 244.3970s / 248721.8123 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.1314
env0_second_0:                 episode reward: 17.5500,                 loss: 1.0941
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 23561/30000 (78.5367%),                 avg. length: 1647.55,                last time consumption/overall running time: 227.9622s / 248949.7746 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.1575
env0_second_0:                 episode reward: 17.0000,                 loss: 1.3850
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 23581/30000 (78.6033%),                 avg. length: 1714.35,                last time consumption/overall running time: 233.4797s / 249183.2542 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.3859
env0_second_0:                 episode reward: 6.2000,                 loss: 2.1596
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 23601/30000 (78.6700%),                 avg. length: 1819.7,                last time consumption/overall running time: 250.1659s / 249433.4202 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.3054
env0_second_0:                 episode reward: 9.6000,                 loss: 1.8806
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 23621/30000 (78.7367%),                 avg. length: 1598.95,                last time consumption/overall running time: 214.6999s / 249648.1201 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.2988
env0_second_0:                 episode reward: 8.1500,                 loss: 1.9382
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 23641/30000 (78.8033%),                 avg. length: 1223.6,                last time consumption/overall running time: 171.3499s / 249819.4700 s
env0_first_0:                 episode reward: 9.6500,                 loss: 0.3605
env0_second_0:                 episode reward: -9.6500,                 loss: 2.2000
env1_first_0:                 episode reward: 13.3500,                 loss: nan
env1_second_0:                 episode reward: -13.3500,                 loss: nan
Episode: 23661/30000 (78.8700%),                 avg. length: 1841.25,                last time consumption/overall running time: 260.0685s / 250079.5385 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.2740
env0_second_0:                 episode reward: 11.2000,                 loss: 1.5134
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 23681/30000 (78.9367%),                 avg. length: 1818.75,                last time consumption/overall running time: 252.5172s / 250332.0557 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2199
env0_second_0:                 episode reward: 14.1500,                 loss: 1.5865
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 23701/30000 (79.0033%),                 avg. length: 1649.95,                last time consumption/overall running time: 228.5434s / 250560.5990 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.2071
env0_second_0:                 episode reward: 14.4000,                 loss: 1.4857
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 23721/30000 (79.0700%),                 avg. length: 1388.15,                last time consumption/overall running time: 187.9809s / 250748.5799 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.2881
env0_second_0:                 episode reward: 17.0000,                 loss: 1.6149
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 23741/30000 (79.1367%),                 avg. length: 1334.45,                last time consumption/overall running time: 185.4403s / 250934.0202 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.2882
env0_second_0:                 episode reward: 14.2500,                 loss: 1.4880
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 23761/30000 (79.2033%),                 avg. length: 1290.45,                last time consumption/overall running time: 180.5509s / 251114.5711 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.3008
env0_second_0:                 episode reward: 13.7500,                 loss: 1.6891
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 23781/30000 (79.2700%),                 avg. length: 1245.65,                last time consumption/overall running time: 173.6206s / 251288.1916 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.2772
env0_second_0:                 episode reward: 15.8000,                 loss: 1.5982
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 23801/30000 (79.3367%),                 avg. length: 1319.15,                last time consumption/overall running time: 186.3242s / 251474.5158 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.3178
env0_second_0:                 episode reward: 12.3000,                 loss: 1.2188
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 23821/30000 (79.4033%),                 avg. length: 1599.95,                last time consumption/overall running time: 220.8831s / 251695.3989 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.3458
env0_second_0:                 episode reward: 13.2000,                 loss: 1.3306
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 23841/30000 (79.4700%),                 avg. length: 2474.85,                last time consumption/overall running time: 339.3872s / 252034.7861 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.2634
env0_second_0:                 episode reward: 8.6000,                 loss: 1.7079
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 23861/30000 (79.5367%),                 avg. length: 2098.55,                last time consumption/overall running time: 284.4745s / 252319.2606 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.2731
env0_second_0:                 episode reward: 11.6000,                 loss: 1.5918
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 23881/30000 (79.6033%),                 avg. length: 1899.2,                last time consumption/overall running time: 252.9914s / 252572.2520 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.2391
env0_second_0:                 episode reward: 15.1000,                 loss: 1.6108
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 23901/30000 (79.6700%),                 avg. length: 2047.25,                last time consumption/overall running time: 271.8416s / 252844.0937 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.2110
env0_second_0:                 episode reward: 15.5000,                 loss: 1.4518
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 23921/30000 (79.7367%),                 avg. length: 2155.25,                last time consumption/overall running time: 289.7030s / 253133.7966 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1970
env0_second_0:                 episode reward: 14.6500,                 loss: 1.6117
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 23941/30000 (79.8033%),                 avg. length: 2532.4,                last time consumption/overall running time: 347.9642s / 253481.7609 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1984
env0_second_0:                 episode reward: 13.5000,                 loss: 1.4146
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 23961/30000 (79.8700%),                 avg. length: 2706.3,                last time consumption/overall running time: 388.9141s / 253870.6749 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1927
env0_second_0:                 episode reward: 11.5500,                 loss: 1.0806
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 23981/30000 (79.9367%),                 avg. length: 2479.45,                last time consumption/overall running time: 343.1977s / 254213.8726 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.1841
env0_second_0:                 episode reward: 12.5000,                 loss: 1.1887
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 24001/30000 (80.0033%),                 avg. length: 2308.65,                last time consumption/overall running time: 316.8708s / 254530.7435 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.2388
env0_second_0:                 episode reward: 10.2500,                 loss: 1.2209
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 24021/30000 (80.0700%),                 avg. length: 1572.05,                last time consumption/overall running time: 218.7382s / 254749.4817 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.3485
env0_second_0:                 episode reward: 11.5000,                 loss: 1.4178
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 24041/30000 (80.1367%),                 avg. length: 2133.55,                last time consumption/overall running time: 286.0104s / 255035.4921 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.2435
env0_second_0:                 episode reward: 12.6500,                 loss: 1.2294
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 24061/30000 (80.2033%),                 avg. length: 2319.8,                last time consumption/overall running time: 315.5231s / 255351.0152 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.2125
env0_second_0:                 episode reward: 12.1500,                 loss: 1.1661
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 24081/30000 (80.2700%),                 avg. length: 2354.3,                last time consumption/overall running time: 319.2445s / 255670.2597 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2162
env0_second_0:                 episode reward: 11.9000,                 loss: 4.6515
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 24101/30000 (80.3367%),                 avg. length: 2487.05,                last time consumption/overall running time: 342.1702s / 256012.4299 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.2215
env0_second_0:                 episode reward: 11.0000,                 loss: 1.6469
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 24121/30000 (80.4033%),                 avg. length: 2431.85,                last time consumption/overall running time: 343.2992s / 256355.7291 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1874
env0_second_0:                 episode reward: 12.8500,                 loss: 1.1814
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 24141/30000 (80.4700%),                 avg. length: 2739.4,                last time consumption/overall running time: 368.7271s / 256724.4562 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1840
env0_second_0:                 episode reward: 11.5500,                 loss: 1.2810
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 24161/30000 (80.5367%),                 avg. length: 2894.35,                last time consumption/overall running time: 393.7280s / 257118.1842 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.2067
env0_second_0:                 episode reward: 9.7500,                 loss: 0.9238
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 24181/30000 (80.6033%),                 avg. length: 2954.85,                last time consumption/overall running time: 408.8708s / 257527.0551 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.1662
env0_second_0:                 episode reward: 8.6500,                 loss: 0.6770
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 24201/30000 (80.6700%),                 avg. length: 2507.8,                last time consumption/overall running time: 342.9656s / 257870.0206 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.1865
env0_second_0:                 episode reward: 13.6000,                 loss: 0.7240
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 24221/30000 (80.7367%),                 avg. length: 2894.75,                last time consumption/overall running time: 397.7536s / 258267.7742 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1886
env0_second_0:                 episode reward: 12.5500,                 loss: 0.6347
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 24241/30000 (80.8033%),                 avg. length: 2863.3,                last time consumption/overall running time: 403.0207s / 258670.7949 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.1586
env0_second_0:                 episode reward: 13.4500,                 loss: 2.6718
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 24261/30000 (80.8700%),                 avg. length: 2655.4,                last time consumption/overall running time: 390.9633s / 259061.7582 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1735
env0_second_0:                 episode reward: 13.0500,                 loss: 2.8596
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 24281/30000 (80.9367%),                 avg. length: 2780.9,                last time consumption/overall running time: 393.3027s / 259455.0609 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1593
env0_second_0:                 episode reward: 11.6500,                 loss: 1.7896
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 24301/30000 (81.0033%),                 avg. length: 2797.7,                last time consumption/overall running time: 379.6519s / 259834.7128 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.1691
env0_second_0:                 episode reward: 11.5000,                 loss: 1.4183
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 24321/30000 (81.0700%),                 avg. length: 2801.45,                last time consumption/overall running time: 394.0160s / 260228.7289 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.1678
env0_second_0:                 episode reward: 12.3500,                 loss: 0.8072
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 24341/30000 (81.1367%),                 avg. length: 2470.45,                last time consumption/overall running time: 356.5294s / 260585.2583 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.1703
env0_second_0:                 episode reward: 12.5000,                 loss: 0.9770
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 24361/30000 (81.2033%),                 avg. length: 2756.25,                last time consumption/overall running time: 377.2688s / 260962.5271 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1540
env0_second_0:                 episode reward: 11.7500,                 loss: 1.1040
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 24381/30000 (81.2700%),                 avg. length: 2603.6,                last time consumption/overall running time: 353.3724s / 261315.8995 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1483
env0_second_0:                 episode reward: 12.7000,                 loss: 2.0049
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 24401/30000 (81.3367%),                 avg. length: 1995.3,                last time consumption/overall running time: 269.8361s / 261585.7355 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2044
env0_second_0:                 episode reward: 15.9500,                 loss: 1.0126
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 24421/30000 (81.4033%),                 avg. length: 2460.65,                last time consumption/overall running time: 333.0121s / 261918.7477 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1588
env0_second_0:                 episode reward: 12.9000,                 loss: 1.0981
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 24441/30000 (81.4700%),                 avg. length: 2764.8,                last time consumption/overall running time: 388.3554s / 262307.1031 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1449
env0_second_0:                 episode reward: 13.2500,                 loss: 0.8073
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 24461/30000 (81.5367%),                 avg. length: 2402.7,                last time consumption/overall running time: 328.1370s / 262635.2401 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.2043
env0_second_0:                 episode reward: 11.3000,                 loss: 1.1013
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 24481/30000 (81.6033%),                 avg. length: 2583.3,                last time consumption/overall running time: 373.0946s / 263008.3347 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1726
env0_second_0:                 episode reward: 14.7000,                 loss: 1.3665
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 24501/30000 (81.6700%),                 avg. length: 2616.4,                last time consumption/overall running time: 358.6483s / 263366.9830 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1636
env0_second_0:                 episode reward: 14.6000,                 loss: 4.5061
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 24521/30000 (81.7367%),                 avg. length: 2670.1,                last time consumption/overall running time: 362.4065s / 263729.3895 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.1508
env0_second_0:                 episode reward: 14.0500,                 loss: 4.5487
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 24541/30000 (81.8033%),                 avg. length: 2516.7,                last time consumption/overall running time: 343.6422s / 264073.0317 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1378
env0_second_0:                 episode reward: 14.5000,                 loss: 4.9265
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 24561/30000 (81.8700%),                 avg. length: 2502.85,                last time consumption/overall running time: 341.5110s / 264414.5427 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.1590
env0_second_0:                 episode reward: 15.1000,                 loss: 4.4956
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 24581/30000 (81.9367%),                 avg. length: 2592.3,                last time consumption/overall running time: 355.3181s / 264769.8608 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1454
env0_second_0:                 episode reward: 13.0500,                 loss: 4.2680
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 24601/30000 (82.0033%),                 avg. length: 2567.45,                last time consumption/overall running time: 344.1046s / 265113.9653 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1758
env0_second_0:                 episode reward: 12.5500,                 loss: 3.6383
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 24621/30000 (82.0700%),                 avg. length: 2618.95,                last time consumption/overall running time: 353.3343s / 265467.2996 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1697
env0_second_0:                 episode reward: 11.1500,                 loss: 2.9500
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 24641/30000 (82.1367%),                 avg. length: 2529.7,                last time consumption/overall running time: 336.4578s / 265803.7574 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1702
env0_second_0:                 episode reward: 14.6000,                 loss: 2.7014
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 24661/30000 (82.2033%),                 avg. length: 2666.9,                last time consumption/overall running time: 363.8732s / 266167.6306 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.1679
env0_second_0:                 episode reward: 11.0000,                 loss: 3.8331
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 24681/30000 (82.2700%),                 avg. length: 2737.15,                last time consumption/overall running time: 376.0744s / 266543.7050 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.4391
env0_second_0:                 episode reward: 3.5000,                 loss: 3.1630
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 24701/30000 (82.3367%),                 avg. length: 2405.3,                last time consumption/overall running time: 324.7201s / 266868.4251 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.1970
env0_second_0:                 episode reward: 12.5000,                 loss: 2.1519
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 24721/30000 (82.4033%),                 avg. length: 2258.5,                last time consumption/overall running time: 311.0728s / 267179.4979 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.2663
env0_second_0:                 episode reward: 9.6500,                 loss: 1.6542
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 24741/30000 (82.4700%),                 avg. length: 2778.45,                last time consumption/overall running time: 390.8429s / 267570.3408 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.1767
env0_second_0:                 episode reward: 11.0000,                 loss: 1.7910
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 24761/30000 (82.5367%),                 avg. length: 2603.1,                last time consumption/overall running time: 370.4192s / 267940.7600 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1447
env0_second_0:                 episode reward: 12.6000,                 loss: 1.0415
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 24781/30000 (82.6033%),                 avg. length: 2852.3,                last time consumption/overall running time: 396.0255s / 268336.7855 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1307
env0_second_0:                 episode reward: 11.8500,                 loss: 0.9499
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 24801/30000 (82.6700%),                 avg. length: 2928.6,                last time consumption/overall running time: 394.4436s / 268731.2291 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.1393
env0_second_0:                 episode reward: 11.3500,                 loss: 1.1112
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 24821/30000 (82.7367%),                 avg. length: 2659.1,                last time consumption/overall running time: 357.1965s / 269088.4256 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1357
env0_second_0:                 episode reward: 12.8000,                 loss: 1.1487
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 24841/30000 (82.8033%),                 avg. length: 2409.2,                last time consumption/overall running time: 342.1827s / 269430.6084 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.1295
env0_second_0:                 episode reward: 15.4000,                 loss: 1.2094
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 24861/30000 (82.8700%),                 avg. length: 2561.15,                last time consumption/overall running time: 351.8182s / 269782.4266 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1421
env0_second_0:                 episode reward: 14.0000,                 loss: 1.0549
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 24881/30000 (82.9367%),                 avg. length: 2851.95,                last time consumption/overall running time: 395.6465s / 270178.0730 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1339
env0_second_0:                 episode reward: 12.7000,                 loss: 0.9793
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 24901/30000 (83.0033%),                 avg. length: 2851.35,                last time consumption/overall running time: 386.8513s / 270564.9243 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1369
env0_second_0:                 episode reward: 12.2000,                 loss: 1.2529
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 24921/30000 (83.0700%),                 avg. length: 2706.75,                last time consumption/overall running time: 366.4074s / 270931.3317 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1264
env0_second_0:                 episode reward: 12.0500,                 loss: 0.9882
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 24941/30000 (83.1367%),                 avg. length: 2606.55,                last time consumption/overall running time: 354.8584s / 271286.1901 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1633
env0_second_0:                 episode reward: 12.0500,                 loss: 1.0005
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 24961/30000 (83.2033%),                 avg. length: 2481.5,                last time consumption/overall running time: 339.2848s / 271625.4749 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1530
env0_second_0:                 episode reward: 12.9500,                 loss: 1.0846
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 24981/30000 (83.2700%),                 avg. length: 2505.35,                last time consumption/overall running time: 334.9036s / 271960.3785 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1259
env0_second_0:                 episode reward: 14.6000,                 loss: 6.5243
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 25001/30000 (83.3367%),                 avg. length: 2869.8,                last time consumption/overall running time: 391.7620s / 272352.1405 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1197
env0_second_0:                 episode reward: 13.7500,                 loss: 1.9663
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 25021/30000 (83.4033%),                 avg. length: 2602.85,                last time consumption/overall running time: 354.7303s / 272706.8708 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0932
env0_second_0:                 episode reward: 14.9500,                 loss: 1.8699
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 25041/30000 (83.4700%),                 avg. length: 2519.9,                last time consumption/overall running time: 341.7069s / 273048.5777 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.1056
env0_second_0:                 episode reward: 14.4500,                 loss: 2.1962
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 25061/30000 (83.5367%),                 avg. length: 2927.05,                last time consumption/overall running time: 391.3267s / 273439.9043 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0979
env0_second_0:                 episode reward: 13.7500,                 loss: 2.2836
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 25081/30000 (83.6033%),                 avg. length: 3080.35,                last time consumption/overall running time: 414.1602s / 273854.0646 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0960
env0_second_0:                 episode reward: 10.7500,                 loss: 1.8577
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 25101/30000 (83.6700%),                 avg. length: 3143.8,                last time consumption/overall running time: 435.0008s / 274289.0654 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0916
env0_second_0:                 episode reward: 11.0500,                 loss: 1.5130
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 25121/30000 (83.7367%),                 avg. length: 3060.8,                last time consumption/overall running time: 417.2129s / 274706.2783 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1213
env0_second_0:                 episode reward: 13.3000,                 loss: 1.6132
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 25141/30000 (83.8033%),                 avg. length: 3139.3,                last time consumption/overall running time: 414.1750s / 275120.4533 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.1022
env0_second_0:                 episode reward: 12.3000,                 loss: 1.5761
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 25161/30000 (83.8700%),                 avg. length: 2755.65,                last time consumption/overall running time: 387.0718s / 275507.5251 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.1255
env0_second_0:                 episode reward: 12.1500,                 loss: 1.7981
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 25181/30000 (83.9367%),                 avg. length: 3076.95,                last time consumption/overall running time: 418.1183s / 275925.6434 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.1345
env0_second_0:                 episode reward: 9.8500,                 loss: 2.8463
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 25201/30000 (84.0033%),                 avg. length: 2767.7,                last time consumption/overall running time: 368.4118s / 276294.0552 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1266
env0_second_0:                 episode reward: 12.6500,                 loss: 4.4404
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 25221/30000 (84.0700%),                 avg. length: 2830.8,                last time consumption/overall running time: 373.2974s / 276667.3526 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1433
env0_second_0:                 episode reward: 12.5500,                 loss: 2.4700
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 25241/30000 (84.1367%),                 avg. length: 1812.5,                last time consumption/overall running time: 249.4079s / 276916.7604 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.1831
env0_second_0:                 episode reward: 17.0500,                 loss: 1.3147
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 25261/30000 (84.2033%),                 avg. length: 2222.2,                last time consumption/overall running time: 304.2598s / 277221.0203 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.1547
env0_second_0:                 episode reward: 14.3000,                 loss: 1.1212
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 25281/30000 (84.2700%),                 avg. length: 2897.05,                last time consumption/overall running time: 398.9089s / 277619.9291 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1229
env0_second_0:                 episode reward: 12.7500,                 loss: 0.9693
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 25301/30000 (84.3367%),                 avg. length: 2659.2,                last time consumption/overall running time: 364.2714s / 277984.2005 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1490
env0_second_0:                 episode reward: 13.6500,                 loss: 0.9291
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 25321/30000 (84.4033%),                 avg. length: 2444.4,                last time consumption/overall running time: 336.7948s / 278320.9953 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1463
env0_second_0:                 episode reward: 13.0500,                 loss: 3.4253
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 25341/30000 (84.4700%),                 avg. length: 2619.55,                last time consumption/overall running time: 359.1590s / 278680.1543 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.1458
env0_second_0:                 episode reward: 14.4500,                 loss: 4.1059
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 25361/30000 (84.5367%),                 avg. length: 3069.0,                last time consumption/overall running time: 409.7033s / 279089.8576 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.1764
env0_second_0:                 episode reward: 7.5500,                 loss: 1.8222
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 25381/30000 (84.6033%),                 avg. length: 2905.45,                last time consumption/overall running time: 393.9217s / 279483.7792 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1459
env0_second_0:                 episode reward: 11.8500,                 loss: 2.1889
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 25401/30000 (84.6700%),                 avg. length: 2756.9,                last time consumption/overall running time: 377.4757s / 279861.2549 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.1472
env0_second_0:                 episode reward: 9.5500,                 loss: 2.2638
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 25421/30000 (84.7367%),                 avg. length: 2781.7,                last time consumption/overall running time: 374.8377s / 280236.0926 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1583
env0_second_0:                 episode reward: 12.6000,                 loss: 1.7210
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 25441/30000 (84.8033%),                 avg. length: 2821.8,                last time consumption/overall running time: 388.5820s / 280624.6747 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.1308
env0_second_0:                 episode reward: 10.3000,                 loss: 0.9484
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 25461/30000 (84.8700%),                 avg. length: 2561.1,                last time consumption/overall running time: 358.5648s / 280983.2394 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1387
env0_second_0:                 episode reward: 13.4000,                 loss: 1.0538
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 25481/30000 (84.9367%),                 avg. length: 2494.55,                last time consumption/overall running time: 341.4201s / 281324.6595 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1435
env0_second_0:                 episode reward: 14.2000,                 loss: 1.3162
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 25501/30000 (85.0033%),                 avg. length: 2661.85,                last time consumption/overall running time: 357.4999s / 281682.1594 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.1344
env0_second_0:                 episode reward: 14.8500,                 loss: 0.8943
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 25521/30000 (85.0700%),                 avg. length: 2733.15,                last time consumption/overall running time: 364.3809s / 282046.5403 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1491
env0_second_0:                 episode reward: 12.8500,                 loss: 2.1282
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 25541/30000 (85.1367%),                 avg. length: 2589.85,                last time consumption/overall running time: 350.1198s / 282396.6601 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1541
env0_second_0:                 episode reward: 12.8500,                 loss: 4.4010
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 25561/30000 (85.2033%),                 avg. length: 2486.4,                last time consumption/overall running time: 330.6837s / 282727.3439 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.2040
env0_second_0:                 episode reward: 13.4000,                 loss: 3.2940
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 25581/30000 (85.2700%),                 avg. length: 2782.05,                last time consumption/overall running time: 366.7843s / 283094.1282 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.1377
env0_second_0:                 episode reward: 11.5000,                 loss: 1.7724
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 25601/30000 (85.3367%),                 avg. length: 2686.2,                last time consumption/overall running time: 357.6684s / 283451.7966 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.1703
env0_second_0:                 episode reward: 11.7000,                 loss: 1.2137
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 25621/30000 (85.4033%),                 avg. length: 2066.15,                last time consumption/overall running time: 283.9672s / 283735.7639 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2302
env0_second_0:                 episode reward: 12.6000,                 loss: 1.3353
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 25641/30000 (85.4700%),                 avg. length: 2252.5,                last time consumption/overall running time: 304.5077s / 284040.2715 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1734
env0_second_0:                 episode reward: 14.6500,                 loss: 1.7904
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 25661/30000 (85.5367%),                 avg. length: 2528.75,                last time consumption/overall running time: 350.4320s / 284390.7035 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1517
env0_second_0:                 episode reward: 14.7500,                 loss: 1.0481
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 25681/30000 (85.6033%),                 avg. length: 2616.25,                last time consumption/overall running time: 361.5900s / 284752.2936 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1275
env0_second_0:                 episode reward: 11.7500,                 loss: 1.2536
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 25701/30000 (85.6700%),                 avg. length: 2539.85,                last time consumption/overall running time: 343.6129s / 285095.9065 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1407
env0_second_0:                 episode reward: 15.1500,                 loss: 1.8197
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 25721/30000 (85.7367%),                 avg. length: 2470.4,                last time consumption/overall running time: 334.0936s / 285430.0001 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1524
env0_second_0:                 episode reward: 14.2000,                 loss: 1.8899
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 25741/30000 (85.8033%),                 avg. length: 2763.85,                last time consumption/overall running time: 370.0705s / 285800.0706 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1335
env0_second_0:                 episode reward: 12.8000,                 loss: 1.3735
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 25761/30000 (85.8700%),                 avg. length: 2311.15,                last time consumption/overall running time: 304.4972s / 286104.5678 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.5242
env0_second_0:                 episode reward: 3.3000,                 loss: 1.9868
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 25781/30000 (85.9367%),                 avg. length: 2767.3,                last time consumption/overall running time: 372.4856s / 286477.0534 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.1567
env0_second_0:                 episode reward: 11.2000,                 loss: 1.1083
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 25801/30000 (86.0033%),                 avg. length: 2542.4,                last time consumption/overall running time: 338.4600s / 286815.5135 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1484
env0_second_0:                 episode reward: 13.6500,                 loss: 1.2329
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 25821/30000 (86.0700%),                 avg. length: 2726.7,                last time consumption/overall running time: 388.5306s / 287204.0441 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.1511
env0_second_0:                 episode reward: 13.9500,                 loss: 0.7618
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 25841/30000 (86.1367%),                 avg. length: 2811.95,                last time consumption/overall running time: 389.8197s / 287593.8638 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.1160
env0_second_0:                 episode reward: 11.9500,                 loss: 1.1641
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 25861/30000 (86.2033%),                 avg. length: 2819.25,                last time consumption/overall running time: 393.1035s / 287986.9673 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.1255
env0_second_0:                 episode reward: 14.0500,                 loss: 0.8542
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 25881/30000 (86.2700%),                 avg. length: 2506.3,                last time consumption/overall running time: 345.8376s / 288332.8049 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.2874
env0_second_0:                 episode reward: 9.1000,                 loss: 1.2642
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 25901/30000 (86.3367%),                 avg. length: 728.7,                last time consumption/overall running time: 106.2689s / 288439.0738 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.3144
env0_second_0:                 episode reward: -20.6000,                 loss: 1.6664
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 25921/30000 (86.4033%),                 avg. length: 728.05,                last time consumption/overall running time: 111.1614s / 288550.2352 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1400
env0_second_0:                 episode reward: -20.7500,                 loss: 1.0516
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 25941/30000 (86.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 108.3419s / 288658.5771 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1309
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4024
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 25961/30000 (86.5367%),                 avg. length: 1306.4,                last time consumption/overall running time: 187.5622s / 288846.1393 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.5606
env0_second_0:                 episode reward: -6.0500,                 loss: 1.0119
env1_first_0:                 episode reward: 7.0500,                 loss: nan
env1_second_0:                 episode reward: -7.0500,                 loss: nan
Episode: 25981/30000 (86.6033%),                 avg. length: 1902.15,                last time consumption/overall running time: 266.0190s / 289112.1582 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.4111
env0_second_0:                 episode reward: 10.0000,                 loss: 1.1361
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 26001/30000 (86.6700%),                 avg. length: 732.85,                last time consumption/overall running time: 113.8991s / 289226.0573 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.2384
env0_second_0:                 episode reward: -20.9500,                 loss: 1.4449
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 26021/30000 (86.7367%),                 avg. length: 734.55,                last time consumption/overall running time: 113.5231s / 289339.5804 s
env0_first_0:                 episode reward: 17.6500,                 loss: 0.3388
env0_second_0:                 episode reward: -17.6500,                 loss: 0.6734
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 26041/30000 (86.8033%),                 avg. length: 872.1,                last time consumption/overall running time: 126.1901s / 289465.7705 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.5521
env0_second_0:                 episode reward: 18.1500,                 loss: 1.0355
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 26061/30000 (86.8700%),                 avg. length: 768.25,                last time consumption/overall running time: 111.4158s / 289577.1864 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.1485
env0_second_0:                 episode reward: 20.8000,                 loss: 0.8143
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 26081/30000 (86.9367%),                 avg. length: 760.8,                last time consumption/overall running time: 109.2826s / 289686.4690 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.1217
env0_second_0:                 episode reward: 20.6000,                 loss: 0.4456
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 26101/30000 (87.0033%),                 avg. length: 768.45,                last time consumption/overall running time: 109.9388s / 289796.4078 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.1069
env0_second_0:                 episode reward: 20.6500,                 loss: 0.4135
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 26121/30000 (87.0700%),                 avg. length: 743.9,                last time consumption/overall running time: 106.7881s / 289903.1959 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.3069
env0_second_0:                 episode reward: -2.1500,                 loss: 1.4439
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 26141/30000 (87.1367%),                 avg. length: 728.1,                last time consumption/overall running time: 107.2369s / 290010.4328 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.1353
env0_second_0:                 episode reward: -20.9500,                 loss: 0.6011
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26161/30000 (87.2033%),                 avg. length: 764.6,                last time consumption/overall running time: 109.5510s / 290119.9838 s
env0_first_0:                 episode reward: 19.8000,                 loss: 0.1350
env0_second_0:                 episode reward: -19.8000,                 loss: 0.3739
env1_first_0:                 episode reward: 19.4000,                 loss: nan
env1_second_0:                 episode reward: -19.4000,                 loss: nan
Episode: 26181/30000 (87.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 104.6444s / 290224.6282 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0772
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0916
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26201/30000 (87.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 106.9321s / 290331.5603 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0763
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0299
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 26221/30000 (87.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 111.9974s / 290443.5577 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0688
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0751
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 26241/30000 (87.4700%),                 avg. length: 731.9,                last time consumption/overall running time: 112.8452s / 290556.4029 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0630
env0_second_0:                 episode reward: -20.6000,                 loss: 0.3877
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 26261/30000 (87.5367%),                 avg. length: 728.9,                last time consumption/overall running time: 114.2468s / 290670.6496 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0271
env0_second_0:                 episode reward: -20.5500,                 loss: 0.6360
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 26281/30000 (87.6033%),                 avg. length: 728.25,                last time consumption/overall running time: 108.9073s / 290779.5570 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0184
env0_second_0:                 episode reward: -20.8000,                 loss: 0.6404
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 26301/30000 (87.6700%),                 avg. length: 729.25,                last time consumption/overall running time: 104.2588s / 290883.8158 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0257
env0_second_0:                 episode reward: -20.4500,                 loss: 3.3358
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 26321/30000 (87.7367%),                 avg. length: 728.05,                last time consumption/overall running time: 104.0520s / 290987.8678 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0405
env0_second_0:                 episode reward: -20.7500,                 loss: 1.5724
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 26341/30000 (87.8033%),                 avg. length: 764.75,                last time consumption/overall running time: 111.1886s / 291099.0564 s
env0_first_0:                 episode reward: 19.8000,                 loss: 0.0631
env0_second_0:                 episode reward: -19.8000,                 loss: 1.3222
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
Episode: 26361/30000 (87.8700%),                 avg. length: 736.85,                last time consumption/overall running time: 104.1581s / 291203.2145 s
env0_first_0:                 episode reward: 19.9500,                 loss: 0.1308
env0_second_0:                 episode reward: -19.9500,                 loss: 1.3547
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 26381/30000 (87.9367%),                 avg. length: 728.25,                last time consumption/overall running time: 102.3684s / 291305.5829 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0765
env0_second_0:                 episode reward: -20.8000,                 loss: 1.4322
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 26401/30000 (88.0033%),                 avg. length: 728.05,                last time consumption/overall running time: 101.9861s / 291407.5690 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0588
env0_second_0:                 episode reward: -20.8000,                 loss: 1.6322
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 26421/30000 (88.0700%),                 avg. length: 728.6,                last time consumption/overall running time: 102.0724s / 291509.6414 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0576
env0_second_0:                 episode reward: -20.6500,                 loss: 1.3029
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 26441/30000 (88.1367%),                 avg. length: 728.35,                last time consumption/overall running time: 102.7787s / 291612.4201 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0464
env0_second_0:                 episode reward: -20.6000,                 loss: 1.2165
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 26461/30000 (88.2033%),                 avg. length: 774.65,                last time consumption/overall running time: 111.9429s / 291724.3630 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3831
env0_second_0:                 episode reward: 0.5500,                 loss: 1.5502
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 26481/30000 (88.2700%),                 avg. length: 788.6,                last time consumption/overall running time: 110.2561s / 291834.6191 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.2047
env0_second_0:                 episode reward: 18.7500,                 loss: 0.8073
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 26501/30000 (88.3367%),                 avg. length: 780.5,                last time consumption/overall running time: 110.0012s / 291944.6203 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.1922
env0_second_0:                 episode reward: 19.8000,                 loss: 0.8559
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 26521/30000 (88.4033%),                 avg. length: 747.15,                last time consumption/overall running time: 106.1113s / 292050.7316 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.2844
env0_second_0:                 episode reward: -2.3000,                 loss: 2.2808
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 26541/30000 (88.4700%),                 avg. length: 731.3,                last time consumption/overall running time: 104.8165s / 292155.5481 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.1306
env0_second_0:                 episode reward: -20.5500,                 loss: 2.8498
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 26561/30000 (88.5367%),                 avg. length: 728.6,                last time consumption/overall running time: 104.9407s / 292260.4888 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.1636
env0_second_0:                 episode reward: -20.6000,                 loss: 3.5508
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 26581/30000 (88.6033%),                 avg. length: 729.75,                last time consumption/overall running time: 103.4340s / 292363.9228 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.1964
env0_second_0:                 episode reward: -20.5000,                 loss: 2.7687
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
Episode: 26601/30000 (88.6700%),                 avg. length: 848.15,                last time consumption/overall running time: 120.6723s / 292484.5951 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.6808
env0_second_0:                 episode reward: 8.7000,                 loss: 2.2778
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 26621/30000 (88.7367%),                 avg. length: 806.4,                last time consumption/overall running time: 115.5251s / 292600.1202 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.5184
env0_second_0:                 episode reward: 12.1500,                 loss: 2.2754
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 26641/30000 (88.8033%),                 avg. length: 772.8,                last time consumption/overall running time: 107.6702s / 292707.7904 s
env0_first_0:                 episode reward: -20.3000,                 loss: 0.1523
env0_second_0:                 episode reward: 20.3000,                 loss: 0.7805
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 26661/30000 (88.8700%),                 avg. length: 795.7,                last time consumption/overall running time: 110.6418s / 292818.4323 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.1797
env0_second_0:                 episode reward: 19.0500,                 loss: 0.7882
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 26681/30000 (88.9367%),                 avg. length: 766.7,                last time consumption/overall running time: 107.7947s / 292926.2270 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.3958
env0_second_0:                 episode reward: 5.6000,                 loss: 1.7719
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 26701/30000 (89.0033%),                 avg. length: 764.0,                last time consumption/overall running time: 109.2150s / 293035.4420 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.3989
env0_second_0:                 episode reward: 5.8000,                 loss: 1.5897
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 26721/30000 (89.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 104.3692s / 293139.8112 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.1339
env0_second_0:                 episode reward: -20.9500,                 loss: 2.1893
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26741/30000 (89.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 102.6941s / 293242.5053 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1496
env0_second_0:                 episode reward: -21.0000,                 loss: 1.8973
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 26761/30000 (89.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 104.2890s / 293346.7942 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1151
env0_second_0:                 episode reward: -21.0000,                 loss: 2.0706
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26781/30000 (89.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 103.5754s / 293450.3696 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1708
env0_second_0:                 episode reward: -21.0000,                 loss: 2.7466
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26801/30000 (89.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 106.0063s / 293556.3760 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0836
env0_second_0:                 episode reward: -21.0000,                 loss: 2.7453
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 26821/30000 (89.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 105.2513s / 293661.6273 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1038
env0_second_0:                 episode reward: -21.0000,                 loss: 2.5214
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 26841/30000 (89.4700%),                 avg. length: 728.8,                last time consumption/overall running time: 106.2872s / 293767.9145 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1099
env0_second_0:                 episode reward: -20.7500,                 loss: 3.6747
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 26861/30000 (89.5367%),                 avg. length: 739.35,                last time consumption/overall running time: 104.9889s / 293872.9034 s
env0_first_0:                 episode reward: 10.4000,                 loss: 0.1745
env0_second_0:                 episode reward: -10.4000,                 loss: 3.0265
env1_first_0:                 episode reward: 10.4000,                 loss: nan
env1_second_0:                 episode reward: -10.4000,                 loss: nan
Episode: 26881/30000 (89.6033%),                 avg. length: 762.85,                last time consumption/overall running time: 110.1015s / 293983.0049 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.1451
env0_second_0:                 episode reward: 20.5500,                 loss: 11.1994
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 26901/30000 (89.6700%),                 avg. length: 755.75,                last time consumption/overall running time: 107.8682s / 294090.8730 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.2504
env0_second_0:                 episode reward: 16.4500,                 loss: 3.2734
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 26921/30000 (89.7367%),                 avg. length: 760.4,                last time consumption/overall running time: 108.6553s / 294199.5283 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.2361
env0_second_0:                 episode reward: 17.4500,                 loss: 2.8997
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 26941/30000 (89.8033%),                 avg. length: 766.7,                last time consumption/overall running time: 111.2378s / 294310.7661 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.1571
env0_second_0:                 episode reward: 19.3000,                 loss: 1.8680
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 26961/30000 (89.8700%),                 avg. length: 774.35,                last time consumption/overall running time: 111.3473s / 294422.1134 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.4730
env0_second_0:                 episode reward: 10.9500,                 loss: 2.5414
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 26981/30000 (89.9367%),                 avg. length: 799.65,                last time consumption/overall running time: 115.5377s / 294537.6511 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.4677
env0_second_0:                 episode reward: 13.0000,                 loss: 2.0833
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 27001/30000 (90.0033%),                 avg. length: 776.3,                last time consumption/overall running time: 111.4552s / 294649.1062 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.1432
env0_second_0:                 episode reward: 19.9500,                 loss: 1.2541
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 27021/30000 (90.0700%),                 avg. length: 774.3,                last time consumption/overall running time: 109.1670s / 294758.2732 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.1501
env0_second_0:                 episode reward: 19.8500,                 loss: 1.3738
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 27041/30000 (90.1367%),                 avg. length: 775.5,                last time consumption/overall running time: 109.4520s / 294867.7253 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.3216
env0_second_0:                 episode reward: 10.3000,                 loss: 1.9554
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 27061/30000 (90.2033%),                 avg. length: 759.2,                last time consumption/overall running time: 109.9350s / 294977.6603 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.5094
env0_second_0:                 episode reward: -1.4000,                 loss: 2.3129
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 27081/30000 (90.2700%),                 avg. length: 758.55,                last time consumption/overall running time: 110.0480s / 295087.7083 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.3060
env0_second_0:                 episode reward: 3.2500,                 loss: 30.9474
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 27101/30000 (90.3367%),                 avg. length: 841.95,                last time consumption/overall running time: 121.0285s / 295208.7368 s
env0_first_0:                 episode reward: -22.2000,                 loss: 0.2607
env0_second_0:                 episode reward: 22.2000,                 loss: 1.4930
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 27121/30000 (90.4033%),                 avg. length: 769.95,                last time consumption/overall running time: 111.1984s / 295319.9352 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.2348
env0_second_0:                 episode reward: 19.7500,                 loss: 1.7162
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 27141/30000 (90.4700%),                 avg. length: 779.75,                last time consumption/overall running time: 115.2724s / 295435.2076 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.1997
env0_second_0:                 episode reward: 18.7500,                 loss: 1.5932
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 27161/30000 (90.5367%),                 avg. length: 770.0,                last time consumption/overall running time: 116.0707s / 295551.2783 s
env0_first_0:                 episode reward: -19.2500,                 loss: 0.1426
env0_second_0:                 episode reward: 19.2500,                 loss: 1.0211
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 27181/30000 (90.6033%),                 avg. length: 778.95,                last time consumption/overall running time: 117.4406s / 295668.7190 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.1117
env0_second_0:                 episode reward: 19.6500,                 loss: 0.9076
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 27201/30000 (90.6700%),                 avg. length: 768.1,                last time consumption/overall running time: 120.4526s / 295789.1716 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.1553
env0_second_0:                 episode reward: 19.4000,                 loss: 1.5018
env1_first_0:                 episode reward: -18.2000,                 loss: nan
env1_second_0:                 episode reward: 18.2000,                 loss: nan
Episode: 27221/30000 (90.7367%),                 avg. length: 785.8,                last time consumption/overall running time: 123.1160s / 295912.2876 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1359
env0_second_0:                 episode reward: 20.1000,                 loss: 1.4367
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 27241/30000 (90.8033%),                 avg. length: 766.95,                last time consumption/overall running time: 113.9845s / 296026.2720 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1110
env0_second_0:                 episode reward: 20.1000,                 loss: 1.0421
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 27261/30000 (90.8700%),                 avg. length: 800.1,                last time consumption/overall running time: 123.4571s / 296149.7292 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.2004
env0_second_0:                 episode reward: 18.0000,                 loss: 2.2957
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 27281/30000 (90.9367%),                 avg. length: 756.95,                last time consumption/overall running time: 113.4478s / 296263.1770 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1166
env0_second_0:                 episode reward: 20.1000,                 loss: 1.3272
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 27301/30000 (91.0033%),                 avg. length: 757.65,                last time consumption/overall running time: 111.3534s / 296374.5303 s
env0_first_0:                 episode reward: -20.3000,                 loss: 0.0573
env0_second_0:                 episode reward: 20.3000,                 loss: 7.0751
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 27321/30000 (91.0700%),                 avg. length: 911.95,                last time consumption/overall running time: 127.2389s / 296501.7693 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.3919
env0_second_0:                 episode reward: 14.3000,                 loss: 1.8395
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 27341/30000 (91.1367%),                 avg. length: 867.9,                last time consumption/overall running time: 123.4242s / 296625.1935 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.5483
env0_second_0:                 episode reward: 9.3500,                 loss: 2.5746
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 27361/30000 (91.2033%),                 avg. length: 770.3,                last time consumption/overall running time: 111.4256s / 296736.6191 s
env0_first_0:                 episode reward: -18.8000,                 loss: 0.2466
env0_second_0:                 episode reward: 18.8000,                 loss: 1.2445
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 27381/30000 (91.2700%),                 avg. length: 765.05,                last time consumption/overall running time: 108.3798s / 296844.9989 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.1018
env0_second_0:                 episode reward: 20.4500,                 loss: 1.1350
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 27401/30000 (91.3367%),                 avg. length: 743.75,                last time consumption/overall running time: 106.6886s / 296951.6875 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.3391
env0_second_0:                 episode reward: -3.0000,                 loss: 1.6957
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 27421/30000 (91.4033%),                 avg. length: 790.85,                last time consumption/overall running time: 112.2378s / 297063.9253 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.3951
env0_second_0:                 episode reward: 19.1000,                 loss: 1.0742
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 27441/30000 (91.4700%),                 avg. length: 773.6,                last time consumption/overall running time: 108.5627s / 297172.4879 s
env0_first_0:                 episode reward: -20.3500,                 loss: 0.1631
env0_second_0:                 episode reward: 20.3500,                 loss: 0.6285
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 27461/30000 (91.5367%),                 avg. length: 783.45,                last time consumption/overall running time: 110.9063s / 297283.3942 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.1729
env0_second_0:                 episode reward: 19.1000,                 loss: 0.7335
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 27481/30000 (91.6033%),                 avg. length: 746.7,                last time consumption/overall running time: 108.1993s / 297391.5935 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.2817
env0_second_0:                 episode reward: -5.1500,                 loss: 1.0396
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 27501/30000 (91.6700%),                 avg. length: 740.25,                last time consumption/overall running time: 111.2897s / 297502.8832 s
env0_first_0:                 episode reward: 17.0500,                 loss: 0.3164
env0_second_0:                 episode reward: -17.0500,                 loss: 1.3588
env1_first_0:                 episode reward: 15.5500,                 loss: nan
env1_second_0:                 episode reward: -15.5500,                 loss: nan
Episode: 27521/30000 (91.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 104.2931s / 297607.1763 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1123
env0_second_0:                 episode reward: -21.0000,                 loss: 1.2748
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27541/30000 (91.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 104.1206s / 297711.2970 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.2635
env0_second_0:                 episode reward: -21.0000,                 loss: 1.5725
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27561/30000 (91.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 105.4687s / 297816.7657 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0768
env0_second_0:                 episode reward: -21.0000,                 loss: 1.2556
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27581/30000 (91.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 105.3394s / 297922.1050 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1081
env0_second_0:                 episode reward: -21.0000,                 loss: 1.1380
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27601/30000 (92.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 104.4343s / 298026.5393 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1034
env0_second_0:                 episode reward: -21.0000,                 loss: 5.0179
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27621/30000 (92.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 104.7324s / 298131.2717 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1599
env0_second_0:                 episode reward: -21.0000,                 loss: 1.0532
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27641/30000 (92.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 105.3302s / 298236.6019 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1176
env0_second_0:                 episode reward: -21.0000,                 loss: 2.2418
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 27661/30000 (92.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 105.0980s / 298341.6999 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1684
env0_second_0:                 episode reward: -21.0000,                 loss: 1.2534
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 27681/30000 (92.2700%),                 avg. length: 766.95,                last time consumption/overall running time: 109.3613s / 298451.0613 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.2631
env0_second_0:                 episode reward: -3.6000,                 loss: 2.9623
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 27701/30000 (92.3367%),                 avg. length: 802.65,                last time consumption/overall running time: 114.0054s / 298565.0667 s
env0_first_0:                 episode reward: -18.6500,                 loss: 0.1853
env0_second_0:                 episode reward: 18.6500,                 loss: 3.3964
env1_first_0:                 episode reward: -18.9500,                 loss: nan
env1_second_0:                 episode reward: 18.9500,                 loss: nan
Episode: 27721/30000 (92.4033%),                 avg. length: 813.1,                last time consumption/overall running time: 115.7591s / 298680.8258 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3259
env0_second_0:                 episode reward: 13.2500,                 loss: 2.6817
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 27741/30000 (92.4700%),                 avg. length: 781.05,                last time consumption/overall running time: 111.4927s / 298792.3185 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.3135
env0_second_0:                 episode reward: 16.3500,                 loss: 3.4279
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 27761/30000 (92.5367%),                 avg. length: 814.7,                last time consumption/overall running time: 115.3541s / 298907.6727 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.3235
env0_second_0:                 episode reward: 16.7500,                 loss: 4.4478
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
Episode: 27781/30000 (92.6033%),                 avg. length: 805.45,                last time consumption/overall running time: 114.3004s / 299021.9730 s
env0_first_0:                 episode reward: -18.3000,                 loss: 0.2196
env0_second_0:                 episode reward: 18.3000,                 loss: 3.2527
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 27801/30000 (92.6700%),                 avg. length: 804.55,                last time consumption/overall running time: 114.0833s / 299136.0564 s
env0_first_0:                 episode reward: -19.1500,                 loss: 0.1730
env0_second_0:                 episode reward: 19.1500,                 loss: 4.5536
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 27821/30000 (92.7367%),                 avg. length: 1259.35,                last time consumption/overall running time: 170.1453s / 299306.2017 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.4238
env0_second_0:                 episode reward: 10.9000,                 loss: 4.6151
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 27841/30000 (92.8033%),                 avg. length: 1398.6,                last time consumption/overall running time: 187.6951s / 299493.8968 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.4948
env0_second_0:                 episode reward: 12.0500,                 loss: 5.1756
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 27861/30000 (92.8700%),                 avg. length: 1812.65,                last time consumption/overall running time: 241.7601s / 299735.6569 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.4105
env0_second_0:                 episode reward: 6.6500,                 loss: 6.1203
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 27881/30000 (92.9367%),                 avg. length: 1471.3,                last time consumption/overall running time: 202.3093s / 299937.9662 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.4364
env0_second_0:                 episode reward: 15.1000,                 loss: 5.5601
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 27901/30000 (93.0033%),                 avg. length: 1609.55,                last time consumption/overall running time: 218.3009s / 300156.2671 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.2904
env0_second_0:                 episode reward: 13.2000,                 loss: 6.7511
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 27921/30000 (93.0700%),                 avg. length: 1977.7,                last time consumption/overall running time: 266.7011s / 300422.9682 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.3505
env0_second_0:                 episode reward: 9.9000,                 loss: 5.5389
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 27941/30000 (93.1367%),                 avg. length: 1850.95,                last time consumption/overall running time: 250.7561s / 300673.7243 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.3061
env0_second_0:                 episode reward: 13.1500,                 loss: 4.7420
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 27961/30000 (93.2033%),                 avg. length: 1465.0,                last time consumption/overall running time: 200.4047s / 300874.1289 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.2669
env0_second_0:                 episode reward: 15.2000,                 loss: 5.4330
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 27981/30000 (93.2700%),                 avg. length: 1295.75,                last time consumption/overall running time: 178.7753s / 301052.9043 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.2992
env0_second_0:                 episode reward: 15.8500,                 loss: 5.9921
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 28001/30000 (93.3367%),                 avg. length: 1332.6,                last time consumption/overall running time: 190.3209s / 301243.2251 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.3505
env0_second_0:                 episode reward: 15.2500,                 loss: 6.4383
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 28021/30000 (93.4033%),                 avg. length: 1375.25,                last time consumption/overall running time: 195.2970s / 301438.5221 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.4068
env0_second_0:                 episode reward: 15.8500,                 loss: 5.4681
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 28041/30000 (93.4700%),                 avg. length: 966.1,                last time consumption/overall running time: 138.9091s / 301577.4312 s
env0_first_0:                 episode reward: 11.1000,                 loss: 0.4736
env0_second_0:                 episode reward: -11.1000,                 loss: 4.1744
env1_first_0:                 episode reward: 12.2000,                 loss: nan
env1_second_0:                 episode reward: -12.2000,                 loss: nan
Episode: 28061/30000 (93.5367%),                 avg. length: 728.35,                last time consumption/overall running time: 103.4133s / 301680.8445 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.2521
env0_second_0:                 episode reward: -20.6500,                 loss: 4.0552
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 28081/30000 (93.6033%),                 avg. length: 728.3,                last time consumption/overall running time: 103.0776s / 301783.9220 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1718
env0_second_0:                 episode reward: -20.8500,                 loss: 3.0731
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 28101/30000 (93.6700%),                 avg. length: 728.15,                last time consumption/overall running time: 103.2305s / 301887.1526 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0564
env0_second_0:                 episode reward: -20.8500,                 loss: 2.6891
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 28121/30000 (93.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 103.5828s / 301990.7353 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0459
env0_second_0:                 episode reward: -20.9500,                 loss: 2.8184
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 28141/30000 (93.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 106.0271s / 302096.7624 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0737
env0_second_0:                 episode reward: -20.8500,                 loss: 3.1263
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 28161/30000 (93.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 106.3295s / 302203.0919 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0202
env0_second_0:                 episode reward: -20.7500,                 loss: 3.6086
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 28181/30000 (93.9367%),                 avg. length: 728.25,                last time consumption/overall running time: 103.7808s / 302306.8727 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0505
env0_second_0:                 episode reward: -20.6000,                 loss: 3.7021
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 28201/30000 (94.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 101.6417s / 302408.5144 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0098
env0_second_0:                 episode reward: -20.9000,                 loss: 4.1408
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 28221/30000 (94.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 101.6800s / 302510.1943 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0451
env0_second_0:                 episode reward: -20.7000,                 loss: 3.2784
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 28241/30000 (94.1367%),                 avg. length: 728.3,                last time consumption/overall running time: 101.4669s / 302611.6612 s
env0_first_0:                 episode reward: 20.8000,                 loss: -0.0010
env0_second_0:                 episode reward: -20.8000,                 loss: 3.5924
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 28261/30000 (94.2033%),                 avg. length: 728.75,                last time consumption/overall running time: 101.9244s / 302713.5856 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0662
env0_second_0:                 episode reward: -20.4500,                 loss: 3.4367
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 28281/30000 (94.2700%),                 avg. length: 1153.8,                last time consumption/overall running time: 155.2904s / 302868.8761 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.4674
env0_second_0:                 episode reward: -3.6000,                 loss: 5.4672
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Episode: 28301/30000 (94.3367%),                 avg. length: 1927.85,                last time consumption/overall running time: 258.9596s / 303127.8357 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.3301
env0_second_0:                 episode reward: 10.2500,                 loss: 4.9336
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 28321/30000 (94.4033%),                 avg. length: 1968.95,                last time consumption/overall running time: 270.7521s / 303398.5878 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.2944
env0_second_0:                 episode reward: 11.0000,                 loss: 3.4355
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 28341/30000 (94.4700%),                 avg. length: 2052.65,                last time consumption/overall running time: 278.9849s / 303677.5726 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.4054
env0_second_0:                 episode reward: 6.0500,                 loss: 3.2589
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 28361/30000 (94.5367%),                 avg. length: 1926.75,                last time consumption/overall running time: 262.2159s / 303939.7885 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.2638
env0_second_0:                 episode reward: 11.7000,                 loss: 3.1896
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 28381/30000 (94.6033%),                 avg. length: 1934.9,                last time consumption/overall running time: 253.2597s / 304193.0482 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2489
env0_second_0:                 episode reward: 14.0000,                 loss: 2.2394
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 28401/30000 (94.6700%),                 avg. length: 1976.9,                last time consumption/overall running time: 259.6577s / 304452.7059 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.2848
env0_second_0:                 episode reward: 10.6000,                 loss: 2.0175
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 28421/30000 (94.7367%),                 avg. length: 2097.4,                last time consumption/overall running time: 274.7738s / 304727.4797 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.3780
env0_second_0:                 episode reward: 5.1000,                 loss: 2.4989
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 28441/30000 (94.8033%),                 avg. length: 2351.7,                last time consumption/overall running time: 317.6880s / 305045.1677 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.2907
env0_second_0:                 episode reward: 5.8000,                 loss: 30.6325
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 28461/30000 (94.8700%),                 avg. length: 2022.55,                last time consumption/overall running time: 276.9751s / 305322.1427 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.2933
env0_second_0:                 episode reward: 10.0000,                 loss: 2.1967
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 28481/30000 (94.9367%),                 avg. length: 1741.9,                last time consumption/overall running time: 244.1031s / 305566.2459 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.4639
env0_second_0:                 episode reward: -0.0500,                 loss: 2.4561
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 28501/30000 (95.0033%),                 avg. length: 1177.25,                last time consumption/overall running time: 178.0076s / 305744.2534 s
env0_first_0:                 episode reward: 14.6500,                 loss: 0.3852
env0_second_0:                 episode reward: -14.6500,                 loss: 2.6759
env1_first_0:                 episode reward: 14.5500,                 loss: nan
env1_second_0:                 episode reward: -14.5500,                 loss: nan
Episode: 28521/30000 (95.0700%),                 avg. length: 2352.7,                last time consumption/overall running time: 329.8579s / 306074.1113 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.3284
env0_second_0:                 episode reward: 4.5500,                 loss: 2.4860
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 28541/30000 (95.1367%),                 avg. length: 2211.95,                last time consumption/overall running time: 323.6684s / 306397.7798 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.3296
env0_second_0:                 episode reward: 8.1000,                 loss: 2.1141
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 28561/30000 (95.2033%),                 avg. length: 2188.6,                last time consumption/overall running time: 295.7038s / 306693.4835 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.2764
env0_second_0:                 episode reward: 9.3000,                 loss: 2.0147
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 28581/30000 (95.2700%),                 avg. length: 2129.85,                last time consumption/overall running time: 282.6301s / 306976.1136 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2823
env0_second_0:                 episode reward: 9.0000,                 loss: 1.8389
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 28601/30000 (95.3367%),                 avg. length: 2045.55,                last time consumption/overall running time: 271.9391s / 307248.0527 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.2909
env0_second_0:                 episode reward: 11.1500,                 loss: 1.6632
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 28621/30000 (95.4033%),                 avg. length: 2058.3,                last time consumption/overall running time: 273.0991s / 307521.1519 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.2346
env0_second_0:                 episode reward: 12.7500,                 loss: 1.6318
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 28641/30000 (95.4700%),                 avg. length: 2134.35,                last time consumption/overall running time: 284.5644s / 307805.7162 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.3041
env0_second_0:                 episode reward: 10.3500,                 loss: 1.6592
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 28661/30000 (95.5367%),                 avg. length: 2058.05,                last time consumption/overall running time: 275.7732s / 308081.4894 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.2964
env0_second_0:                 episode reward: 9.8000,                 loss: 1.6632
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 28681/30000 (95.6033%),                 avg. length: 1983.75,                last time consumption/overall running time: 270.0704s / 308351.5598 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.2497
env0_second_0:                 episode reward: 11.5500,                 loss: 1.6476
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 28701/30000 (95.6700%),                 avg. length: 2053.75,                last time consumption/overall running time: 278.3480s / 308629.9078 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.2300
env0_second_0:                 episode reward: 13.8500,                 loss: 1.4871
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 28721/30000 (95.7367%),                 avg. length: 2143.8,                last time consumption/overall running time: 290.2849s / 308920.1927 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.2159
env0_second_0:                 episode reward: 13.5500,                 loss: 1.1990
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 28741/30000 (95.8033%),                 avg. length: 2176.6,                last time consumption/overall running time: 292.9493s / 309213.1421 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.2191
env0_second_0:                 episode reward: 13.1000,                 loss: 1.3592
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 28761/30000 (95.8700%),                 avg. length: 1822.9,                last time consumption/overall running time: 247.9142s / 309461.0563 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.3492
env0_second_0:                 episode reward: 14.1500,                 loss: 2.8533
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 28781/30000 (95.9367%),                 avg. length: 2323.35,                last time consumption/overall running time: 312.5714s / 309773.6277 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.9170
env0_second_0:                 episode reward: 14.2000,                 loss: 1.8917
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 28801/30000 (96.0033%),                 avg. length: 2140.6,                last time consumption/overall running time: 286.4563s / 310060.0840 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.2358
env0_second_0:                 episode reward: 13.4500,                 loss: 1.1767
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 28821/30000 (96.0700%),                 avg. length: 2272.25,                last time consumption/overall running time: 299.0681s / 310359.1521 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.2673
env0_second_0:                 episode reward: 9.9500,                 loss: 1.0830
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 28841/30000 (96.1367%),                 avg. length: 2415.5,                last time consumption/overall running time: 324.4948s / 310683.6469 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2536
env0_second_0:                 episode reward: 8.0500,                 loss: 1.1076
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 28861/30000 (96.2033%),                 avg. length: 2350.05,                last time consumption/overall running time: 341.2545s / 311024.9014 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.2286
env0_second_0:                 episode reward: 11.6000,                 loss: 1.0744
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 28881/30000 (96.2700%),                 avg. length: 2349.65,                last time consumption/overall running time: 320.7053s / 311345.6067 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.2925
env0_second_0:                 episode reward: 5.2000,                 loss: 0.8841
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 28901/30000 (96.3367%),                 avg. length: 2265.7,                last time consumption/overall running time: 304.5885s / 311650.1952 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.2527
env0_second_0:                 episode reward: 8.3000,                 loss: 1.3321
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 28921/30000 (96.4033%),                 avg. length: 2362.85,                last time consumption/overall running time: 317.4583s / 311967.6536 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.2400
env0_second_0:                 episode reward: 8.6000,                 loss: 0.8492
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 28941/30000 (96.4700%),                 avg. length: 1130.15,                last time consumption/overall running time: 156.2918s / 312123.9454 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.4114
env0_second_0:                 episode reward: 17.2500,                 loss: 1.7250
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 28961/30000 (96.5367%),                 avg. length: 766.0,                last time consumption/overall running time: 107.7134s / 312231.6587 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.1162
env0_second_0:                 episode reward: 20.1500,                 loss: 1.0334
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 28981/30000 (96.6033%),                 avg. length: 772.5,                last time consumption/overall running time: 110.5561s / 312342.2148 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.2259
env0_second_0:                 episode reward: 19.0500,                 loss: 1.2947
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 29001/30000 (96.6700%),                 avg. length: 788.55,                last time consumption/overall running time: 112.3953s / 312454.6101 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.1597
env0_second_0:                 episode reward: 19.4500,                 loss: 1.0109
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 29021/30000 (96.7367%),                 avg. length: 801.2,                last time consumption/overall running time: 111.5340s / 312566.1441 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.2515
env0_second_0:                 episode reward: 17.6500,                 loss: 1.4290
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 29041/30000 (96.8033%),                 avg. length: 792.25,                last time consumption/overall running time: 110.3632s / 312676.5073 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.3034
env0_second_0:                 episode reward: 18.6000,                 loss: 1.5704
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 29061/30000 (96.8700%),                 avg. length: 854.6,                last time consumption/overall running time: 118.0842s / 312794.5915 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.3081
env0_second_0:                 episode reward: 18.9500,                 loss: 1.6729
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 29081/30000 (96.9367%),                 avg. length: 898.15,                last time consumption/overall running time: 128.7124s / 312923.3039 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.3730
env0_second_0:                 episode reward: 15.5000,                 loss: 2.4615
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 29101/30000 (97.0033%),                 avg. length: 781.6,                last time consumption/overall running time: 114.0740s / 313037.3780 s
env0_first_0:                 episode reward: -19.5000,                 loss: 0.1730
env0_second_0:                 episode reward: 19.5000,                 loss: 1.7603
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 29121/30000 (97.0700%),                 avg. length: 786.75,                last time consumption/overall running time: 114.7755s / 313152.1535 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.1754
env0_second_0:                 episode reward: 19.6000,                 loss: 2.1729
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 29141/30000 (97.1367%),                 avg. length: 992.75,                last time consumption/overall running time: 141.4521s / 313293.6056 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.2892
env0_second_0:                 episode reward: 17.6000,                 loss: 1.8093
env1_first_0:                 episode reward: -18.1500,                 loss: nan
env1_second_0:                 episode reward: 18.1500,                 loss: nan
Episode: 29161/30000 (97.2033%),                 avg. length: 1073.5,                last time consumption/overall running time: 150.5379s / 313444.1435 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.3915
env0_second_0:                 episode reward: 14.7500,                 loss: 2.0569
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 29181/30000 (97.2700%),                 avg. length: 1096.85,                last time consumption/overall running time: 152.0392s / 313596.1827 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.3892
env0_second_0:                 episode reward: 13.9000,                 loss: 1.3592
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 29201/30000 (97.3367%),                 avg. length: 973.3,                last time consumption/overall running time: 135.5651s / 313731.7478 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.2926
env0_second_0:                 episode reward: 17.2500,                 loss: 1.2546
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 29221/30000 (97.4033%),                 avg. length: 966.6,                last time consumption/overall running time: 132.2864s / 313864.0341 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.2555
env0_second_0:                 episode reward: 16.0000,                 loss: 1.0674
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 29241/30000 (97.4700%),                 avg. length: 1147.7,                last time consumption/overall running time: 155.3980s / 314019.4321 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.4627
env0_second_0:                 episode reward: 12.6500,                 loss: 1.4535
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 29261/30000 (97.5367%),                 avg. length: 1240.35,                last time consumption/overall running time: 168.2322s / 314187.6644 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.3333
env0_second_0:                 episode reward: 15.1000,                 loss: 1.2113
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 29281/30000 (97.6033%),                 avg. length: 903.5,                last time consumption/overall running time: 125.6478s / 314313.3122 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.1927
env0_second_0:                 episode reward: 18.6000,                 loss: 1.1381
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 29301/30000 (97.6700%),                 avg. length: 893.4,                last time consumption/overall running time: 123.9379s / 314437.2501 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.1364
env0_second_0:                 episode reward: 17.9000,                 loss: 0.8146
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 29321/30000 (97.7367%),                 avg. length: 847.8,                last time consumption/overall running time: 118.1234s / 314555.3735 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.2429
env0_second_0:                 episode reward: 16.8000,                 loss: 1.1926
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 29341/30000 (97.8033%),                 avg. length: 835.35,                last time consumption/overall running time: 116.2675s / 314671.6410 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.2753
env0_second_0:                 episode reward: 16.3000,                 loss: 1.2938
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 29361/30000 (97.8700%),                 avg. length: 1048.95,                last time consumption/overall running time: 144.4830s / 314816.1240 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.3684
env0_second_0:                 episode reward: 15.7500,                 loss: 19.1734
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 29381/30000 (97.9367%),                 avg. length: 797.65,                last time consumption/overall running time: 112.1646s / 314928.2886 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.5341
env0_second_0:                 episode reward: 10.1000,                 loss: 2.8229
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 29401/30000 (98.0033%),                 avg. length: 1222.1,                last time consumption/overall running time: 164.6437s / 315092.9323 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.3988
env0_second_0:                 episode reward: 12.9000,                 loss: 1.8748
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 29421/30000 (98.0700%),                 avg. length: 1521.9,                last time consumption/overall running time: 203.6899s / 315296.6223 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.3093
env0_second_0:                 episode reward: 13.9000,                 loss: 1.8261
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 29441/30000 (98.1367%),                 avg. length: 1666.15,                last time consumption/overall running time: 226.9381s / 315523.5603 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.3463
env0_second_0:                 episode reward: 13.0000,                 loss: 2.2027
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 29461/30000 (98.2033%),                 avg. length: 1173.7,                last time consumption/overall running time: 163.1699s / 315686.7302 s
env0_first_0:                 episode reward: 14.4000,                 loss: 0.5058
env0_second_0:                 episode reward: -14.4000,                 loss: 2.8061
env1_first_0:                 episode reward: 16.0500,                 loss: nan
env1_second_0:                 episode reward: -16.0500,                 loss: nan
Episode: 29481/30000 (98.2700%),                 avg. length: 1503.05,                last time consumption/overall running time: 204.9093s / 315891.6395 s
env0_first_0:                 episode reward: 10.8500,                 loss: 0.3186
env0_second_0:                 episode reward: -10.8500,                 loss: 2.9528
env1_first_0:                 episode reward: 11.2500,                 loss: nan
env1_second_0:                 episode reward: -11.2500,                 loss: nan
Episode: 29501/30000 (98.3367%),                 avg. length: 1758.2,                last time consumption/overall running time: 237.1774s / 316128.8169 s
env0_first_0:                 episode reward: 8.9500,                 loss: 0.3069
env0_second_0:                 episode reward: -8.9500,                 loss: 3.2813
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 29521/30000 (98.4033%),                 avg. length: 2108.8,                last time consumption/overall running time: 282.0673s / 316410.8841 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3184
env0_second_0:                 episode reward: -1.0500,                 loss: 3.3753
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 29541/30000 (98.4700%),                 avg. length: 2138.5,                last time consumption/overall running time: 288.7493s / 316699.6334 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.2436
env0_second_0:                 episode reward: 12.2000,                 loss: 3.4614
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 29561/30000 (98.5367%),                 avg. length: 2252.3,                last time consumption/overall running time: 300.5791s / 317000.2125 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.2053
env0_second_0:                 episode reward: 10.4500,                 loss: 2.7774
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 29581/30000 (98.6033%),                 avg. length: 2228.15,                last time consumption/overall running time: 298.1435s / 317298.3560 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1767
env0_second_0:                 episode reward: 12.0500,                 loss: 3.2016
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 29601/30000 (98.6700%),                 avg. length: 2147.5,                last time consumption/overall running time: 287.6600s / 317586.0160 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1678
env0_second_0:                 episode reward: 11.8000,                 loss: 3.0160
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 29621/30000 (98.7367%),                 avg. length: 2190.2,                last time consumption/overall running time: 295.3490s / 317881.3651 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.1541
env0_second_0:                 episode reward: 12.4000,                 loss: 2.3057
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 29641/30000 (98.8033%),                 avg. length: 2178.7,                last time consumption/overall running time: 299.8716s / 318181.2366 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1360
env0_second_0:                 episode reward: 13.0500,                 loss: 2.0996
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 29661/30000 (98.8700%),                 avg. length: 2236.25,                last time consumption/overall running time: 302.6500s / 318483.8866 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.1216
env0_second_0:                 episode reward: 13.7000,                 loss: 2.6768
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 29681/30000 (98.9367%),                 avg. length: 2091.1,                last time consumption/overall running time: 276.2498s / 318760.1365 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1036
env0_second_0:                 episode reward: 15.3000,                 loss: 3.0421
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 29701/30000 (99.0033%),                 avg. length: 2105.6,                last time consumption/overall running time: 284.5526s / 319044.6890 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1133
env0_second_0:                 episode reward: 14.5000,                 loss: 2.3628
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 29721/30000 (99.0700%),                 avg. length: 2096.4,                last time consumption/overall running time: 302.6960s / 319347.3851 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1061
env0_second_0:                 episode reward: 13.2000,                 loss: 2.4728
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 29741/30000 (99.1367%),                 avg. length: 2252.55,                last time consumption/overall running time: 302.8075s / 319650.1925 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0813
env0_second_0:                 episode reward: 14.9500,                 loss: 2.8894
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 29761/30000 (99.2033%),                 avg. length: 1813.55,                last time consumption/overall running time: 244.2953s / 319894.4878 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.1153
env0_second_0:                 episode reward: 16.3000,                 loss: 4.0940
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 29781/30000 (99.2700%),                 avg. length: 1808.7,                last time consumption/overall running time: 235.8536s / 320130.3414 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1987
env0_second_0:                 episode reward: 13.3500,                 loss: 5.2218
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 29801/30000 (99.3367%),                 avg. length: 1574.0,                last time consumption/overall running time: 204.7748s / 320335.1162 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.1890
env0_second_0:                 episode reward: 15.0500,                 loss: 5.1587
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 29821/30000 (99.4033%),                 avg. length: 730.35,                last time consumption/overall running time: 99.7672s / 320434.8834 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.2900
env0_second_0:                 episode reward: -20.6500,                 loss: 5.1257
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 29841/30000 (99.4700%),                 avg. length: 730.1,                last time consumption/overall running time: 100.2241s / 320535.1075 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1369
env0_second_0:                 episode reward: -20.7000,                 loss: 4.3542
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 29861/30000 (99.5367%),                 avg. length: 729.15,                last time consumption/overall running time: 101.5693s / 320636.6768 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: 20.5000,                 loss: 0.0206
env0_second_0:                 episode reward: -20.5000,                 loss: 4.1213
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 29881/30000 (99.6033%),                 avg. length: 728.9,                last time consumption/overall running time: 107.6536s / 320744.3304 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0370
env0_second_0:                 episode reward: -20.5000,                 loss: 3.9142
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 29901/30000 (99.6700%),                 avg. length: 820.35,                last time consumption/overall running time: 113.3681s / 320857.6985 s
env0_first_0:                 episode reward: 12.7000,                 loss: 0.2515
env0_second_0:                 episode reward: -12.7000,                 loss: 3.5988
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 29921/30000 (99.7367%),                 avg. length: 851.95,                last time consumption/overall running time: 115.8360s / 320973.5345 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.3741
env0_second_0:                 episode reward: 17.7500,                 loss: 7.9845
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 29941/30000 (99.8033%),                 avg. length: 797.85,                last time consumption/overall running time: 111.4084s / 321084.9429 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2843
env0_second_0:                 episode reward: 14.1500,                 loss: 3.4052
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 29961/30000 (99.8700%),                 avg. length: 848.45,                last time consumption/overall running time: 124.3390s / 321209.2819 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.3820
env0_second_0:                 episode reward: 17.6000,                 loss: 2.5343
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 29981/30000 (99.9367%),                 avg. length: 781.85,                last time consumption/overall running time: 116.7385s / 321326.0204 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.1562
env0_second_0:                 episode reward: 20.2000,                 loss: 2.3514
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
