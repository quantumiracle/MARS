2022-05-10 17:37:49.047875: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 17:37:49.047940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 17:37:49.047945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f5793e150f0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_10000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_10000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8323s / 0.8323 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0638s / 0.8961 s
agent0:                 episode reward: 0.7541,                 loss: nan
agent1:                 episode reward: -0.7541,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0743s / 0.9705 s
agent0:                 episode reward: 0.8118,                 loss: nan
agent1:                 episode reward: -0.8118,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0638s / 1.0343 s
agent0:                 episode reward: 0.8687,                 loss: nan
agent1:                 episode reward: -0.8687,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5966s / 1.6308 s
agent0:                 episode reward: 0.9553,                 loss: nan
agent1:                 episode reward: -0.9553,                 loss: 0.4613
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7390s / 2.3698 s
agent0:                 episode reward: 0.6002,                 loss: nan
agent1:                 episode reward: -0.6002,                 loss: 0.4457
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6909s / 3.0607 s
agent0:                 episode reward: 1.0291,                 loss: nan
agent1:                 episode reward: -1.0291,                 loss: 0.4434
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7116s / 3.7723 s
agent0:                 episode reward: 1.0713,                 loss: nan
agent1:                 episode reward: -1.0713,                 loss: 0.4409
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7097s / 4.4820 s
agent0:                 episode reward: 0.8484,                 loss: nan
agent1:                 episode reward: -0.8484,                 loss: 0.4387
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6971s / 5.1791 s
agent0:                 episode reward: 0.7638,                 loss: nan
agent1:                 episode reward: -0.7638,                 loss: 0.4564
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7079s / 5.8870 s
agent0:                 episode reward: 0.7638,                 loss: nan
agent1:                 episode reward: -0.7638,                 loss: 0.4568
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7121s / 6.5992 s
agent0:                 episode reward: 0.5315,                 loss: nan
agent1:                 episode reward: -0.5315,                 loss: 0.4537
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7245s / 7.3237 s
agent0:                 episode reward: 0.5157,                 loss: nan
agent1:                 episode reward: -0.5157,                 loss: 0.4514
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7119s / 8.0357 s
agent0:                 episode reward: 0.6742,                 loss: nan
agent1:                 episode reward: -0.6742,                 loss: 0.4488
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7542s / 8.7899 s
agent0:                 episode reward: 0.3592,                 loss: nan
agent1:                 episode reward: -0.3592,                 loss: 0.4368
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7477s / 9.5376 s
agent0:                 episode reward: 0.9194,                 loss: nan
agent1:                 episode reward: -0.9194,                 loss: 0.4282
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7325s / 10.2701 s
agent0:                 episode reward: 1.0578,                 loss: nan
agent1:                 episode reward: -1.0578,                 loss: 0.4241
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7266s / 10.9967 s
agent0:                 episode reward: 1.4380,                 loss: nan
agent1:                 episode reward: -1.4380,                 loss: 0.4222
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7370s / 11.7337 s
agent0:                 episode reward: -0.0216,                 loss: nan
agent1:                 episode reward: 0.0216,                 loss: 0.4201
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7833s / 12.5170 s
agent0:                 episode reward: 1.1015,                 loss: nan
agent1:                 episode reward: -1.1015,                 loss: 0.3929
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7613s / 13.2783 s
agent0:                 episode reward: 0.5410,                 loss: nan
agent1:                 episode reward: -0.5410,                 loss: 0.3847
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7300s / 14.0083 s
agent0:                 episode reward: 0.9538,                 loss: nan
agent1:                 episode reward: -0.9538,                 loss: 0.3840
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7288s / 14.7371 s
agent0:                 episode reward: 0.0964,                 loss: nan
agent1:                 episode reward: -0.0964,                 loss: 0.3838
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7339s / 15.4711 s
agent0:                 episode reward: 0.3893,                 loss: nan
agent1:                 episode reward: -0.3893,                 loss: 0.3816
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7543s / 16.2254 s
agent0:                 episode reward: 0.8941,                 loss: nan
agent1:                 episode reward: -0.8941,                 loss: 0.3577
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7593s / 16.9847 s
agent0:                 episode reward: 0.6937,                 loss: nan
agent1:                 episode reward: -0.6937,                 loss: 0.3561
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7471s / 17.7318 s
agent0:                 episode reward: 0.7766,                 loss: nan
agent1:                 episode reward: -0.7766,                 loss: 0.3549
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7544s / 18.4862 s
agent0:                 episode reward: 1.2643,                 loss: nan
agent1:                 episode reward: -1.2643,                 loss: 0.3523
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7962s / 19.2824 s
agent0:                 episode reward: 0.4094,                 loss: nan
agent1:                 episode reward: -0.4094,                 loss: 0.3503
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7792s / 20.0617 s
agent0:                 episode reward: 0.1620,                 loss: nan
agent1:                 episode reward: -0.1620,                 loss: 0.3414
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7614s / 20.8231 s
agent0:                 episode reward: 0.9965,                 loss: nan
agent1:                 episode reward: -0.9965,                 loss: 0.3408
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7590s / 21.5821 s
agent0:                 episode reward: 0.6581,                 loss: nan
agent1:                 episode reward: -0.6581,                 loss: 0.3406
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7905s / 22.3726 s
agent0:                 episode reward: 0.9448,                 loss: nan
agent1:                 episode reward: -0.9448,                 loss: 0.3406
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7915s / 23.1641 s
agent0:                 episode reward: 0.4287,                 loss: nan
agent1:                 episode reward: -0.4287,                 loss: 0.3390
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7583s / 23.9224 s
agent0:                 episode reward: 1.0520,                 loss: nan
agent1:                 episode reward: -1.0520,                 loss: 0.3406
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7619s / 24.6843 s
agent0:                 episode reward: 0.0749,                 loss: nan
agent1:                 episode reward: -0.0749,                 loss: 0.3401
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7904s / 25.4747 s
agent0:                 episode reward: 0.5485,                 loss: nan
agent1:                 episode reward: -0.5485,                 loss: 0.3394
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7950s / 26.2697 s
agent0:                 episode reward: 0.6092,                 loss: nan
agent1:                 episode reward: -0.6092,                 loss: 0.3400
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7698s / 27.0395 s
agent0:                 episode reward: -0.0922,                 loss: nan
agent1:                 episode reward: 0.0922,                 loss: 0.3397
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8028s / 27.8423 s
agent0:                 episode reward: 0.5530,                 loss: nan
agent1:                 episode reward: -0.5530,                 loss: 0.3506
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7945s / 28.6368 s
agent0:                 episode reward: 0.4872,                 loss: nan
agent1:                 episode reward: -0.4872,                 loss: 0.3501
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7868s / 29.4237 s
agent0:                 episode reward: 1.2622,                 loss: nan
agent1:                 episode reward: -1.2622,                 loss: 0.3514
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7797s / 30.2034 s
agent0:                 episode reward: 0.6381,                 loss: nan
agent1:                 episode reward: -0.6381,                 loss: 0.3488
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7933s / 30.9967 s
agent0:                 episode reward: 0.9108,                 loss: nan
agent1:                 episode reward: -0.9108,                 loss: 0.3501
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7838s / 31.7805 s
agent0:                 episode reward: 0.4402,                 loss: nan
agent1:                 episode reward: -0.4402,                 loss: 0.3593
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8102s / 32.5907 s
agent0:                 episode reward: 0.2136,                 loss: nan
agent1:                 episode reward: -0.2136,                 loss: 0.3597
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8624s / 33.4531 s
agent0:                 episode reward: 0.2583,                 loss: nan
agent1:                 episode reward: -0.2583,                 loss: 0.3587
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8136s / 34.2667 s
agent0:                 episode reward: 0.5853,                 loss: nan
agent1:                 episode reward: -0.5853,                 loss: 0.3569
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7961s / 35.0629 s
agent0:                 episode reward: 1.0487,                 loss: nan
agent1:                 episode reward: -1.0487,                 loss: 0.3572
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 35.8631 s
agent0:                 episode reward: 1.0009,                 loss: nan
agent1:                 episode reward: -1.0009,                 loss: 0.3643
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8068s / 36.6699 s
agent0:                 episode reward: 0.5331,                 loss: nan
agent1:                 episode reward: -0.5331,                 loss: 0.3637
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8091s / 37.4790 s
agent0:                 episode reward: 0.8936,                 loss: nan
agent1:                 episode reward: -0.8936,                 loss: 0.3622
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8114s / 38.2904 s
agent0:                 episode reward: 0.6372,                 loss: nan
agent1:                 episode reward: -0.6372,                 loss: 0.3621
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8207s / 39.1112 s
agent0:                 episode reward: 0.8828,                 loss: nan
agent1:                 episode reward: -0.8828,                 loss: 0.3627
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8099s / 39.9210 s
agent0:                 episode reward: 0.5693,                 loss: nan
agent1:                 episode reward: -0.5693,                 loss: 0.3681
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8152s / 40.7362 s
agent0:                 episode reward: 0.6027,                 loss: nan
agent1:                 episode reward: -0.6027,                 loss: 0.3691
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8170s / 41.5532 s
agent0:                 episode reward: 1.5211,                 loss: nan
agent1:                 episode reward: -1.5211,                 loss: 0.3691
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8387s / 42.3919 s
agent0:                 episode reward: 0.6310,                 loss: nan
agent1:                 episode reward: -0.6310,                 loss: 0.3696
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8786s / 43.2704 s
agent0:                 episode reward: 0.8098,                 loss: nan
agent1:                 episode reward: -0.8098,                 loss: 0.3694
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8242s / 44.0947 s
agent0:                 episode reward: 0.8676,                 loss: nan
agent1:                 episode reward: -0.8676,                 loss: 0.3765
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8219s / 44.9165 s
agent0:                 episode reward: 0.5488,                 loss: nan
agent1:                 episode reward: -0.5488,                 loss: 0.3776
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8295s / 45.7461 s
agent0:                 episode reward: 1.1906,                 loss: nan
agent1:                 episode reward: -1.1906,                 loss: 0.3777
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8434s / 46.5894 s
agent0:                 episode reward: 0.3979,                 loss: nan
agent1:                 episode reward: -0.3979,                 loss: 0.3765
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8246s / 47.4140 s
agent0:                 episode reward: 0.4103,                 loss: nan
agent1:                 episode reward: -0.4103,                 loss: 0.3774
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8509s / 48.2649 s
agent0:                 episode reward: 0.8050,                 loss: nan
agent1:                 episode reward: -0.8050,                 loss: 0.3835
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8490s / 49.1139 s
agent0:                 episode reward: 0.2565,                 loss: nan
agent1:                 episode reward: -0.2565,                 loss: 0.3849
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8434s / 49.9573 s
agent0:                 episode reward: 0.5172,                 loss: nan
agent1:                 episode reward: -0.5172,                 loss: 0.3852
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8560s / 50.8133 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: 0.3843
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8582s / 51.6715 s
agent0:                 episode reward: 0.2831,                 loss: nan
agent1:                 episode reward: -0.2831,                 loss: 0.3830
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8552s / 52.5267 s
agent0:                 episode reward: 1.0010,                 loss: nan
agent1:                 episode reward: -1.0010,                 loss: 0.3878
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8976s / 53.4243 s
agent0:                 episode reward: 0.7291,                 loss: nan
agent1:                 episode reward: -0.7291,                 loss: 0.3891
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8508s / 54.2751 s
agent0:                 episode reward: 1.2377,                 loss: nan
agent1:                 episode reward: -1.2377,                 loss: 0.3911
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8711s / 55.1462 s
agent0:                 episode reward: 0.9637,                 loss: nan
agent1:                 episode reward: -0.9637,                 loss: 0.3895
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8491s / 55.9953 s
agent0:                 episode reward: 0.6786,                 loss: nan
agent1:                 episode reward: -0.6786,                 loss: 0.3900
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8631s / 56.8584 s
agent0:                 episode reward: 0.9970,                 loss: nan
agent1:                 episode reward: -0.9970,                 loss: 0.3928
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8569s / 57.7153 s
agent0:                 episode reward: 0.0143,                 loss: nan
agent1:                 episode reward: -0.0143,                 loss: 0.3930
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8929s / 58.6083 s
agent0:                 episode reward: 0.3476,                 loss: nan
agent1:                 episode reward: -0.3476,                 loss: 0.3949
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8697s / 59.4780 s
agent0:                 episode reward: 0.7644,                 loss: nan
agent1:                 episode reward: -0.7644,                 loss: 0.3934
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8591s / 60.3370 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.3925
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8711s / 61.2081 s
agent0:                 episode reward: 0.4303,                 loss: nan
agent1:                 episode reward: -0.4303,                 loss: 0.3894
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8681s / 62.0762 s
agent0:                 episode reward: -0.0416,                 loss: nan
agent1:                 episode reward: 0.0416,                 loss: 0.3876
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8687s / 62.9449 s
agent0:                 episode reward: 0.8369,                 loss: nan
agent1:                 episode reward: -0.8369,                 loss: 0.3892
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9277s / 63.8726 s
agent0:                 episode reward: 0.7462,                 loss: nan
agent1:                 episode reward: -0.7462,                 loss: 0.3872
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8833s / 64.7559 s
agent0:                 episode reward: 0.9275,                 loss: nan
agent1:                 episode reward: -0.9275,                 loss: 0.3873
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8668s / 65.6227 s
agent0:                 episode reward: 1.6221,                 loss: nan
agent1:                 episode reward: -1.6221,                 loss: 0.3796
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8818s / 66.5045 s
agent0:                 episode reward: 0.5878,                 loss: nan
agent1:                 episode reward: -0.5878,                 loss: 0.3805
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9105s / 67.4150 s
agent0:                 episode reward: 0.7898,                 loss: nan
agent1:                 episode reward: -0.7898,                 loss: 0.3795
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 68.2809 s
agent0:                 episode reward: 1.0981,                 loss: nan
agent1:                 episode reward: -1.0981,                 loss: 0.3805
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8774s / 69.1583 s
agent0:                 episode reward: 1.2241,                 loss: nan
agent1:                 episode reward: -1.2241,                 loss: 0.3803
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8863s / 70.0446 s
agent0:                 episode reward: 0.6463,                 loss: nan
agent1:                 episode reward: -0.6463,                 loss: 0.3755
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8975s / 70.9420 s
agent0:                 episode reward: 0.6254,                 loss: nan
agent1:                 episode reward: -0.6254,                 loss: 0.3749
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9034s / 71.8454 s
agent0:                 episode reward: 1.2541,                 loss: nan
agent1:                 episode reward: -1.2541,                 loss: 0.3762
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8841s / 72.7295 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.3764
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9426s / 73.6722 s
agent0:                 episode reward: 1.0675,                 loss: nan
agent1:                 episode reward: -1.0675,                 loss: 0.3763
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9212s / 74.5934 s
agent0:                 episode reward: 0.9576,                 loss: nan
agent1:                 episode reward: -0.9576,                 loss: 0.3732
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9173s / 75.5107 s
agent0:                 episode reward: 1.3366,                 loss: nan
agent1:                 episode reward: -1.3366,                 loss: 0.3728
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9231s / 76.4338 s
agent0:                 episode reward: 0.8724,                 loss: nan
agent1:                 episode reward: -0.8724,                 loss: 0.3716
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9021s / 77.3359 s
agent0:                 episode reward: 0.2375,                 loss: nan
agent1:                 episode reward: -0.2375,                 loss: 0.3741
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9050s / 78.2410 s
agent0:                 episode reward: 0.2641,                 loss: nan
agent1:                 episode reward: -0.2641,                 loss: 0.3720
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9212s / 79.1621 s
agent0:                 episode reward: 0.7635,                 loss: nan
agent1:                 episode reward: -0.7635,                 loss: 0.3706
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9252s / 80.0873 s
agent0:                 episode reward: 0.9748,                 loss: nan
agent1:                 episode reward: -0.9748,                 loss: 0.3689
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9130s / 81.0002 s
agent0:                 episode reward: 0.7630,                 loss: nan
agent1:                 episode reward: -0.7630,                 loss: 0.3676
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9133s / 81.9135 s
agent0:                 episode reward: 0.6696,                 loss: nan
agent1:                 episode reward: -0.6696,                 loss: 0.3689
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9194s / 82.8330 s
agent0:                 episode reward: 0.5192,                 loss: nan
agent1:                 episode reward: -0.5192,                 loss: 0.3677
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9320s / 83.7649 s
agent0:                 episode reward: 0.7599,                 loss: nan
agent1:                 episode reward: -0.7599,                 loss: 0.3658
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9628s / 84.7278 s
agent0:                 episode reward: 0.5713,                 loss: nan
agent1:                 episode reward: -0.5713,                 loss: 0.3651
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9394s / 85.6671 s
agent0:                 episode reward: 1.0077,                 loss: nan
agent1:                 episode reward: -1.0077,                 loss: 0.3646
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9369s / 86.6040 s
agent0:                 episode reward: 1.0240,                 loss: nan
agent1:                 episode reward: -1.0240,                 loss: 0.3634
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9281s / 87.5321 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.3643
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9695s / 88.5016 s
agent0:                 episode reward: 0.1555,                 loss: nan
agent1:                 episode reward: -0.1555,                 loss: 0.3649
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9392s / 89.4409 s
agent0:                 episode reward: 0.1105,                 loss: nan
agent1:                 episode reward: -0.1105,                 loss: 0.3630
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9985s / 90.4394 s
agent0:                 episode reward: 0.8557,                 loss: nan
agent1:                 episode reward: -0.8557,                 loss: 0.3620
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9438s / 91.3832 s
agent0:                 episode reward: 0.4670,                 loss: nan
agent1:                 episode reward: -0.4670,                 loss: 0.3629
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9515s / 92.3347 s
agent0:                 episode reward: 0.8421,                 loss: nan
agent1:                 episode reward: -0.8421,                 loss: 0.3609
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9438s / 93.2785 s
agent0:                 episode reward: 0.0792,                 loss: nan
agent1:                 episode reward: -0.0792,                 loss: 0.3661
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9935s / 94.2720 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.3666
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9524s / 95.2243 s
agent0:                 episode reward: 0.5215,                 loss: nan
agent1:                 episode reward: -0.5215,                 loss: 0.3660
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9491s / 96.1735 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.3661
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9522s / 97.1257 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.3653
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9591s / 98.0849 s
agent0:                 episode reward: 0.5373,                 loss: nan
agent1:                 episode reward: -0.5373,                 loss: 0.3685
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9643s / 99.0492 s
agent0:                 episode reward: 0.4761,                 loss: nan
agent1:                 episode reward: -0.4761,                 loss: 0.3695
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9827s / 100.0318 s
agent0:                 episode reward: 0.2060,                 loss: nan
agent1:                 episode reward: -0.2060,                 loss: 0.3677
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9967s / 101.0286 s
agent0:                 episode reward: 0.3570,                 loss: nan
agent1:                 episode reward: -0.3570,                 loss: 0.3658
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9554s / 101.9840 s
agent0:                 episode reward: -0.0522,                 loss: nan
agent1:                 episode reward: 0.0522,                 loss: 0.3669
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9517s / 102.9357 s
agent0:                 episode reward: 0.6745,                 loss: nan
agent1:                 episode reward: -0.6745,                 loss: 0.3681
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0056s / 103.9412 s
agent0:                 episode reward: 0.7833,                 loss: nan
agent1:                 episode reward: -0.7833,                 loss: 0.3691
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0217s / 104.9629 s
agent0:                 episode reward: -0.0508,                 loss: nan
agent1:                 episode reward: 0.0508,                 loss: 0.3674
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9602s / 105.9232 s
agent0:                 episode reward: -0.1230,                 loss: nan
agent1:                 episode reward: 0.1230,                 loss: 0.3660
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9742s / 106.8974 s
agent0:                 episode reward: 0.3379,                 loss: nan
agent1:                 episode reward: -0.3379,                 loss: 0.3653
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9877s / 107.8851 s
agent0:                 episode reward: 0.3494,                 loss: nan
agent1:                 episode reward: -0.3494,                 loss: 0.3727
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9919s / 108.8770 s
agent0:                 episode reward: 0.2048,                 loss: nan
agent1:                 episode reward: -0.2048,                 loss: 0.3747
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9918s / 109.8688 s
agent0:                 episode reward: 0.2712,                 loss: nan
agent1:                 episode reward: -0.2712,                 loss: 0.3735
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9891s / 110.8579 s
agent0:                 episode reward: 0.9689,                 loss: nan
agent1:                 episode reward: -0.9689,                 loss: 0.3740
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9729s / 111.8308 s
agent0:                 episode reward: 0.5501,                 loss: nan
agent1:                 episode reward: -0.5501,                 loss: 0.3712
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9867s / 112.8176 s
agent0:                 episode reward: 0.5222,                 loss: nan
agent1:                 episode reward: -0.5222,                 loss: 0.3802
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9748s / 113.7924 s
agent0:                 episode reward: 0.8428,                 loss: nan
agent1:                 episode reward: -0.8428,                 loss: 0.3813
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0273s / 114.8197 s
agent0:                 episode reward: 0.3895,                 loss: nan
agent1:                 episode reward: -0.3895,                 loss: 0.3808
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9947s / 115.8144 s
agent0:                 episode reward: 1.0154,                 loss: nan
agent1:                 episode reward: -1.0154,                 loss: 0.3806
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0049s / 116.8193 s
agent0:                 episode reward: 0.0122,                 loss: nan
agent1:                 episode reward: -0.0122,                 loss: 0.3786
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9916s / 117.8109 s
agent0:                 episode reward: 0.8815,                 loss: nan
agent1:                 episode reward: -0.8815,                 loss: 0.3844
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0131s / 118.8240 s
agent0:                 episode reward: 0.7760,                 loss: nan
agent1:                 episode reward: -0.7760,                 loss: 0.3856
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0040s / 119.8280 s
agent0:                 episode reward: 1.0495,                 loss: nan
agent1:                 episode reward: -1.0495,                 loss: 0.3854
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0195s / 120.8475 s
agent0:                 episode reward: 0.7483,                 loss: nan
agent1:                 episode reward: -0.7483,                 loss: 0.3845
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0160s / 121.8635 s
agent0:                 episode reward: 0.8716,                 loss: nan
agent1:                 episode reward: -0.8716,                 loss: 0.3852
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9904s / 122.8539 s
agent0:                 episode reward: 0.2306,                 loss: nan
agent1:                 episode reward: -0.2306,                 loss: 0.3942
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0341s / 123.8880 s
agent0:                 episode reward: 0.2650,                 loss: nan
agent1:                 episode reward: -0.2650,                 loss: 0.3951
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0759s / 124.9639 s
agent0:                 episode reward: 0.7308,                 loss: nan
agent1:                 episode reward: -0.7308,                 loss: 0.3942
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0124s / 125.9763 s
agent0:                 episode reward: 0.5532,                 loss: nan
agent1:                 episode reward: -0.5532,                 loss: 0.3946
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0159s / 126.9922 s
agent0:                 episode reward: 0.3332,                 loss: nan
agent1:                 episode reward: -0.3332,                 loss: 0.3933
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0179s / 128.0101 s
agent0:                 episode reward: 0.6747,                 loss: nan
agent1:                 episode reward: -0.6747,                 loss: 0.3994
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0121s / 129.0223 s
agent0:                 episode reward: 1.3679,                 loss: nan
agent1:                 episode reward: -1.3679,                 loss: 0.3990
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0141s / 130.0364 s
agent0:                 episode reward: 0.7935,                 loss: nan
agent1:                 episode reward: -0.7935,                 loss: 0.3960
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0425s / 131.0789 s
agent0:                 episode reward: 0.5329,                 loss: nan
agent1:                 episode reward: -0.5329,                 loss: 0.3967
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0248s / 132.1037 s
agent0:                 episode reward: 0.2251,                 loss: nan
agent1:                 episode reward: -0.2251,                 loss: 0.3944
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0449s / 133.1486 s
agent0:                 episode reward: 0.5636,                 loss: nan
agent1:                 episode reward: -0.5636,                 loss: 0.3824
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 134.1941 s
agent0:                 episode reward: 0.5451,                 loss: nan
agent1:                 episode reward: -0.5451,                 loss: 0.3773
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0695s / 135.2636 s
agent0:                 episode reward: 0.4515,                 loss: nan
agent1:                 episode reward: -0.4515,                 loss: 0.3773
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 136.2846 s
agent0:                 episode reward: 0.5590,                 loss: nan
agent1:                 episode reward: -0.5590,                 loss: 0.3771
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0292s / 137.3138 s
agent0:                 episode reward: 0.3890,                 loss: nan
agent1:                 episode reward: -0.3890,                 loss: 0.3758
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0217s / 138.3355 s
agent0:                 episode reward: 0.8230,                 loss: nan
agent1:                 episode reward: -0.8230,                 loss: 0.3426
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0425s / 139.3780 s
agent0:                 episode reward: 0.1599,                 loss: nan
agent1:                 episode reward: -0.1599,                 loss: 0.3326
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0615s / 140.4395 s
agent0:                 episode reward: 0.1594,                 loss: nan
agent1:                 episode reward: -0.1594,                 loss: 0.3317
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0508s / 141.4902 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.3323
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0456s / 142.5358 s
agent0:                 episode reward: 0.0480,                 loss: nan
agent1:                 episode reward: -0.0480,                 loss: 0.3279
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 143.5814 s
agent0:                 episode reward: 0.9240,                 loss: nan
agent1:                 episode reward: -0.9240,                 loss: 0.2912
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0396s / 144.6209 s
agent0:                 episode reward: 0.5067,                 loss: nan
agent1:                 episode reward: -0.5067,                 loss: 0.2778
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0870s / 145.7080 s
agent0:                 episode reward: 0.5735,                 loss: nan
agent1:                 episode reward: -0.5735,                 loss: 0.2764
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0526s / 146.7606 s
agent0:                 episode reward: 0.4028,                 loss: nan
agent1:                 episode reward: -0.4028,                 loss: 0.2741
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0638s / 147.8244 s
agent0:                 episode reward: 0.4899,                 loss: nan
agent1:                 episode reward: -0.4899,                 loss: 0.2740
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0653s / 148.8897 s
agent0:                 episode reward: -0.6234,                 loss: nan
agent1:                 episode reward: 0.6234,                 loss: 0.2427
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0585s / 149.9482 s
agent0:                 episode reward: 0.3575,                 loss: nan
agent1:                 episode reward: -0.3575,                 loss: 0.2362
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0476s / 150.9958 s
agent0:                 episode reward: 0.9674,                 loss: nan
agent1:                 episode reward: -0.9674,                 loss: 0.2349
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0599s / 152.0557 s
agent0:                 episode reward: 0.4495,                 loss: nan
agent1:                 episode reward: -0.4495,                 loss: 0.2323
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0461s / 153.1018 s
agent0:                 episode reward: 0.3454,                 loss: nan
agent1:                 episode reward: -0.3454,                 loss: 0.2315
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0482s / 154.1500 s
agent0:                 episode reward: 0.5795,                 loss: nan
agent1:                 episode reward: -0.5795,                 loss: 0.2364
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0604s / 155.2105 s
agent0:                 episode reward: 0.1954,                 loss: nan
agent1:                 episode reward: -0.1954,                 loss: 0.2336
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1114s / 156.3218 s
agent0:                 episode reward: 0.5148,                 loss: nan
agent1:                 episode reward: -0.5148,                 loss: 0.2313
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0683s / 157.3901 s
agent0:                 episode reward: 0.4973,                 loss: nan
agent1:                 episode reward: -0.4973,                 loss: 0.2335
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0865s / 158.4766 s
agent0:                 episode reward: 1.1207,                 loss: nan
agent1:                 episode reward: -1.1207,                 loss: 0.2316
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0658s / 159.5424 s
agent0:                 episode reward: 0.5143,                 loss: nan
agent1:                 episode reward: -0.5143,                 loss: 0.2571
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1066s / 160.6490 s
agent0:                 episode reward: 1.6904,                 loss: nan
agent1:                 episode reward: -1.6904,                 loss: 0.2581
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0734s / 161.7224 s
agent0:                 episode reward: 0.7625,                 loss: nan
agent1:                 episode reward: -0.7625,                 loss: 0.2582
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0801s / 162.8025 s
agent0:                 episode reward: 0.6840,                 loss: nan
agent1:                 episode reward: -0.6840,                 loss: 0.2553
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0935s / 163.8960 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.2551
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0909s / 164.9868 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: 0.2808
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1503s / 166.1371 s
agent0:                 episode reward: 0.1563,                 loss: nan
agent1:                 episode reward: -0.1563,                 loss: 0.2797
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1074s / 167.2446 s
agent0:                 episode reward: 0.7533,                 loss: nan
agent1:                 episode reward: -0.7533,                 loss: 0.2797
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0900s / 168.3345 s
agent0:                 episode reward: 0.7444,                 loss: nan
agent1:                 episode reward: -0.7444,                 loss: 0.2772
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1130s / 169.4475 s
agent0:                 episode reward: 1.1560,                 loss: nan
agent1:                 episode reward: -1.1560,                 loss: 0.2751
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1141s / 170.5616 s
agent0:                 episode reward: 0.4792,                 loss: nan
agent1:                 episode reward: -0.4792,                 loss: 0.2926
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1103s / 171.6719 s
agent0:                 episode reward: 0.5146,                 loss: nan
agent1:                 episode reward: -0.5146,                 loss: 0.2900
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1264s / 172.7983 s
agent0:                 episode reward: 0.8565,                 loss: nan
agent1:                 episode reward: -0.8565,                 loss: 0.2873
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0959s / 173.8941 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: 0.2857
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1114s / 175.0056 s
agent0:                 episode reward: -0.0904,                 loss: nan
agent1:                 episode reward: 0.0904,                 loss: 0.2823
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1642s / 176.1698 s
agent0:                 episode reward: 0.4051,                 loss: nan
agent1:                 episode reward: -0.4051,                 loss: 0.2929
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1122s / 177.2820 s
agent0:                 episode reward: 0.0807,                 loss: nan
agent1:                 episode reward: -0.0807,                 loss: 0.2884
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1063s / 178.3882 s
agent0:                 episode reward: 0.9191,                 loss: nan
agent1:                 episode reward: -0.9191,                 loss: 0.2861
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1109s / 179.4991 s
agent0:                 episode reward: 0.7015,                 loss: nan
agent1:                 episode reward: -0.7015,                 loss: 0.2834
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1188s / 180.6179 s
agent0:                 episode reward: 0.8230,                 loss: nan
agent1:                 episode reward: -0.8230,                 loss: 0.2822
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1517s / 181.7696 s
agent0:                 episode reward: 0.8302,                 loss: nan
agent1:                 episode reward: -0.8302,                 loss: 0.2860
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1306s / 182.9002 s
agent0:                 episode reward: 1.3131,                 loss: nan
agent1:                 episode reward: -1.3131,                 loss: 0.2820
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1207s / 184.0209 s
agent0:                 episode reward: 0.6667,                 loss: nan
agent1:                 episode reward: -0.6667,                 loss: 0.2809
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1610s / 185.1819 s
agent0:                 episode reward: 0.4280,                 loss: nan
agent1:                 episode reward: -0.4280,                 loss: 0.2800
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1468s / 186.3286 s
agent0:                 episode reward: -0.1427,                 loss: nan
agent1:                 episode reward: 0.1427,                 loss: 0.2774
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1718s / 187.5005 s
agent0:                 episode reward: 0.1124,                 loss: nan
agent1:                 episode reward: -0.1124,                 loss: 0.3047
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1341s / 188.6346 s
agent0:                 episode reward: 0.7569,                 loss: nan
agent1:                 episode reward: -0.7569,                 loss: 0.3037
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1341s / 189.7687 s
agent0:                 episode reward: 0.9478,                 loss: nan
agent1:                 episode reward: -0.9478,                 loss: 0.3022
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1665s / 190.9352 s
agent0:                 episode reward: 0.7594,                 loss: nan
agent1:                 episode reward: -0.7594,                 loss: 0.3006
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1577s / 192.0929 s
agent0:                 episode reward: -0.1022,                 loss: nan
agent1:                 episode reward: 0.1022,                 loss: 0.3005
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1445s / 193.2375 s
agent0:                 episode reward: 0.6282,                 loss: nan
agent1:                 episode reward: -0.6282,                 loss: 0.3394
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1618s / 194.3992 s
agent0:                 episode reward: 0.8416,                 loss: nan
agent1:                 episode reward: -0.8416,                 loss: 0.3417
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1564s / 195.5556 s
agent0:                 episode reward: 1.0159,                 loss: nan
agent1:                 episode reward: -1.0159,                 loss: 0.3416
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1947s / 196.7503 s
agent0:                 episode reward: 0.7296,                 loss: nan
agent1:                 episode reward: -0.7296,                 loss: 0.3418
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1862s / 197.9366 s
agent0:                 episode reward: 0.5724,                 loss: nan
agent1:                 episode reward: -0.5724,                 loss: 0.3413
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1554s / 199.0919 s
agent0:                 episode reward: 0.7271,                 loss: nan
agent1:                 episode reward: -0.7271,                 loss: 0.3660
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1871s / 200.2790 s
agent0:                 episode reward: 0.5614,                 loss: nan
agent1:                 episode reward: -0.5614,                 loss: 0.3628
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1614s / 201.4404 s
agent0:                 episode reward: 0.3148,                 loss: nan
agent1:                 episode reward: -0.3148,                 loss: 0.3625
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1695s / 202.6099 s
agent0:                 episode reward: 0.4657,                 loss: nan
agent1:                 episode reward: -0.4657,                 loss: 0.3625
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1684s / 203.7783 s
agent0:                 episode reward: 0.4425,                 loss: nan
agent1:                 episode reward: -0.4425,                 loss: 0.3589
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1521s / 204.9304 s
agent0:                 episode reward: 0.0320,                 loss: nan
agent1:                 episode reward: -0.0320,                 loss: 0.3127
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1719s / 206.1024 s
agent0:                 episode reward: 0.8628,                 loss: nan
agent1:                 episode reward: -0.8628,                 loss: 0.2938
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2113s / 207.3136 s
agent0:                 episode reward: 0.4923,                 loss: nan
agent1:                 episode reward: -0.4923,                 loss: 0.2890
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1989s / 208.5125 s
agent0:                 episode reward: 0.6751,                 loss: nan
agent1:                 episode reward: -0.6751,                 loss: 0.2904
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1877s / 209.7003 s
agent0:                 episode reward: 0.4991,                 loss: nan
agent1:                 episode reward: -0.4991,                 loss: 0.2880
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1872s / 210.8875 s
agent0:                 episode reward: 0.3776,                 loss: nan
agent1:                 episode reward: -0.3776,                 loss: 0.2364
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2017s / 212.0892 s
agent0:                 episode reward: 0.1760,                 loss: nan
agent1:                 episode reward: -0.1760,                 loss: 0.2216
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1820s / 213.2712 s
agent0:                 episode reward: 0.9911,                 loss: nan
agent1:                 episode reward: -0.9911,                 loss: 0.2189
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1667s / 214.4379 s
agent0:                 episode reward: 0.6550,                 loss: nan
agent1:                 episode reward: -0.6550,                 loss: 0.2185
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2008s / 215.6387 s
agent0:                 episode reward: 0.1493,                 loss: nan
agent1:                 episode reward: -0.1493,                 loss: 0.2172
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1966s / 216.8353 s
agent0:                 episode reward: 0.4435,                 loss: nan
agent1:                 episode reward: -0.4435,                 loss: 0.2034
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2511s / 218.0864 s
agent0:                 episode reward: -0.2218,                 loss: nan
agent1:                 episode reward: 0.2218,                 loss: 0.1947
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2007s / 219.2872 s
agent0:                 episode reward: 0.7872,                 loss: nan
agent1:                 episode reward: -0.7872,                 loss: 0.1942
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2063s / 220.4934 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1932
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2178s / 221.7112 s
agent0:                 episode reward: -0.2297,                 loss: nan
agent1:                 episode reward: 0.2297,                 loss: 0.1909
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2088s / 222.9200 s
agent0:                 episode reward: -0.1912,                 loss: nan
agent1:                 episode reward: 0.1912,                 loss: 0.2137
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2250s / 224.1450 s
agent0:                 episode reward: 0.1430,                 loss: nan
agent1:                 episode reward: -0.1430,                 loss: 0.2160
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1996s / 225.3446 s
agent0:                 episode reward: 0.5261,                 loss: nan
agent1:                 episode reward: -0.5261,                 loss: 0.2143
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2199s / 226.5645 s
agent0:                 episode reward: 1.0996,                 loss: nan
agent1:                 episode reward: -1.0996,                 loss: 0.2109
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2738s / 227.8383 s
agent0:                 episode reward: 0.4484,                 loss: nan
agent1:                 episode reward: -0.4484,                 loss: 0.2111
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2162s / 229.0545 s
agent0:                 episode reward: 0.4398,                 loss: nan
agent1:                 episode reward: -0.4398,                 loss: 0.2436
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2442s / 230.2987 s
agent0:                 episode reward: 0.6607,                 loss: nan
agent1:                 episode reward: -0.6607,                 loss: 0.2459
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2161s / 231.5148 s
agent0:                 episode reward: 0.3223,                 loss: nan
agent1:                 episode reward: -0.3223,                 loss: 0.2448
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2558s / 232.7706 s
agent0:                 episode reward: 0.4799,                 loss: nan
agent1:                 episode reward: -0.4799,                 loss: 0.2437
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2227s / 233.9933 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.2436
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2163s / 235.2097 s
agent0:                 episode reward: 0.6711,                 loss: nan
agent1:                 episode reward: -0.6711,                 loss: 0.2665
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2216s / 236.4313 s
agent0:                 episode reward: 0.6242,                 loss: nan
agent1:                 episode reward: -0.6242,                 loss: 0.2641
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2561s / 237.6874 s
agent0:                 episode reward: 0.2254,                 loss: nan
agent1:                 episode reward: -0.2254,                 loss: 0.2639
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2391s / 238.9264 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: 0.2631
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2297s / 240.1561 s
agent0:                 episode reward: -0.0060,                 loss: nan
agent1:                 episode reward: 0.0060,                 loss: 0.2618
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2438s / 241.3999 s
agent0:                 episode reward: -0.2123,                 loss: nan
agent1:                 episode reward: 0.2123,                 loss: 0.2775
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2439s / 242.6438 s
agent0:                 episode reward: 0.0788,                 loss: nan
agent1:                 episode reward: -0.0788,                 loss: 0.2736
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2266s / 243.8705 s
agent0:                 episode reward: 0.0106,                 loss: nan
agent1:                 episode reward: -0.0106,                 loss: 0.2729
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2403s / 245.1107 s
agent0:                 episode reward: 0.3349,                 loss: nan
agent1:                 episode reward: -0.3349,                 loss: 0.2705
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2365s / 246.3472 s
agent0:                 episode reward: -0.0180,                 loss: nan
agent1:                 episode reward: 0.0180,                 loss: 0.2690
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2367s / 247.5839 s
agent0:                 episode reward: 0.3044,                 loss: nan
agent1:                 episode reward: -0.3044,                 loss: 0.2822
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3316s / 248.9155 s
agent0:                 episode reward: 0.2726,                 loss: nan
agent1:                 episode reward: -0.2726,                 loss: 0.2783
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2509s / 250.1664 s
agent0:                 episode reward: 0.3330,                 loss: nan
agent1:                 episode reward: -0.3330,                 loss: 0.2753
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2744s / 251.4407 s
agent0:                 episode reward: -0.3381,                 loss: nan
agent1:                 episode reward: 0.3381,                 loss: 0.2748
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2619s / 252.7026 s
agent0:                 episode reward: -0.3746,                 loss: nan
agent1:                 episode reward: 0.3746,                 loss: 0.2732
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2604s / 253.9630 s
agent0:                 episode reward: 0.7241,                 loss: nan
agent1:                 episode reward: -0.7241,                 loss: 0.2965
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2506s / 255.2136 s
agent0:                 episode reward: 0.9245,                 loss: nan
agent1:                 episode reward: -0.9245,                 loss: 0.2953
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2495s / 256.4631 s
agent0:                 episode reward: -0.3788,                 loss: nan
agent1:                 episode reward: 0.3788,                 loss: 0.2948
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3056s / 257.7687 s
agent0:                 episode reward: 0.6482,                 loss: nan
agent1:                 episode reward: -0.6482,                 loss: 0.2938
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3123s / 259.0810 s
agent0:                 episode reward: 0.7141,                 loss: nan
agent1:                 episode reward: -0.7141,                 loss: 0.2932
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2636s / 260.3446 s
agent0:                 episode reward: 0.1343,                 loss: nan
agent1:                 episode reward: -0.1343,                 loss: 0.3346
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2545s / 261.5991 s
agent0:                 episode reward: 0.4018,                 loss: nan
agent1:                 episode reward: -0.4018,                 loss: 0.3398
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2831s / 262.8822 s
agent0:                 episode reward: 0.5991,                 loss: nan
agent1:                 episode reward: -0.5991,                 loss: 0.3380
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2625s / 264.1447 s
agent0:                 episode reward: 0.5832,                 loss: nan
agent1:                 episode reward: -0.5832,                 loss: 0.3389
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2584s / 265.4031 s
agent0:                 episode reward: 0.7051,                 loss: nan
agent1:                 episode reward: -0.7051,                 loss: 0.3379
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3009s / 266.7040 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.3707
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2804s / 267.9844 s
agent0:                 episode reward: 0.0540,                 loss: nan
agent1:                 episode reward: -0.0540,                 loss: 0.3711
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3332s / 269.3176 s
agent0:                 episode reward: -0.0799,                 loss: nan
agent1:                 episode reward: 0.0799,                 loss: 0.3721
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2586s / 270.5762 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.3702
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2686s / 271.8449 s
agent0:                 episode reward: 0.7860,                 loss: nan
agent1:                 episode reward: -0.7860,                 loss: 0.3707
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2795s / 273.1243 s
agent0:                 episode reward: 0.7489,                 loss: nan
agent1:                 episode reward: -0.7489,                 loss: 0.3557
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2869s / 274.4112 s
agent0:                 episode reward: -0.0540,                 loss: nan
agent1:                 episode reward: 0.0540,                 loss: 0.3473
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2993s / 275.7106 s
agent0:                 episode reward: 0.2262,                 loss: nan
agent1:                 episode reward: -0.2262,                 loss: 0.3462
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3026s / 277.0132 s
agent0:                 episode reward: 0.3741,                 loss: nan
agent1:                 episode reward: -0.3741,                 loss: 0.3460
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2884s / 278.3016 s
agent0:                 episode reward: -0.0186,                 loss: nan
agent1:                 episode reward: 0.0186,                 loss: 0.3447
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3500s / 279.6516 s
agent0:                 episode reward: 0.4124,                 loss: nan
agent1:                 episode reward: -0.4124,                 loss: 0.2850
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2923s / 280.9439 s
agent0:                 episode reward: 0.0916,                 loss: nan
agent1:                 episode reward: -0.0916,                 loss: 0.2698
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3034s / 282.2473 s
agent0:                 episode reward: -0.2649,                 loss: nan
agent1:                 episode reward: 0.2649,                 loss: 0.2658
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3118s / 283.5590 s
agent0:                 episode reward: 0.2566,                 loss: nan
agent1:                 episode reward: -0.2566,                 loss: 0.2650
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3157s / 284.8747 s
agent0:                 episode reward: 0.0086,                 loss: nan
agent1:                 episode reward: -0.0086,                 loss: 0.2664
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2891s / 286.1638 s
agent0:                 episode reward: 0.0477,                 loss: nan
agent1:                 episode reward: -0.0477,                 loss: 0.2317
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2993s / 287.4631 s
agent0:                 episode reward: -0.0015,                 loss: nan
agent1:                 episode reward: 0.0015,                 loss: 0.2207
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3479s / 288.8110 s
agent0:                 episode reward: 1.0979,                 loss: nan
agent1:                 episode reward: -1.0979,                 loss: 0.2206
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3361s / 290.1471 s
agent0:                 episode reward: 0.2930,                 loss: nan
agent1:                 episode reward: -0.2930,                 loss: 0.2191
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3355s / 291.4826 s
agent0:                 episode reward: 0.7053,                 loss: nan
agent1:                 episode reward: -0.7053,                 loss: 0.2192
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3322s / 292.8148 s
agent0:                 episode reward: -0.1201,                 loss: nan
agent1:                 episode reward: 0.1201,                 loss: 0.2251
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3299s / 294.1447 s
agent0:                 episode reward: 0.4754,                 loss: nan
agent1:                 episode reward: -0.4754,                 loss: 0.2232
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3267s / 295.4713 s
agent0:                 episode reward: 0.2849,                 loss: nan
agent1:                 episode reward: -0.2849,                 loss: 0.2216
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3334s / 296.8047 s
agent0:                 episode reward: 0.5377,                 loss: nan
agent1:                 episode reward: -0.5377,                 loss: 0.2216
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3253s / 298.1300 s
agent0:                 episode reward: 0.5025,                 loss: nan
agent1:                 episode reward: -0.5025,                 loss: 0.2223
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4212s / 299.5513 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.2365
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3396s / 300.8908 s
agent0:                 episode reward: 0.5495,                 loss: nan
agent1:                 episode reward: -0.5495,                 loss: 0.2364
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3325s / 302.2233 s
agent0:                 episode reward: 0.5195,                 loss: nan
agent1:                 episode reward: -0.5195,                 loss: 0.2356
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3314s / 303.5547 s
agent0:                 episode reward: 0.6012,                 loss: nan
agent1:                 episode reward: -0.6012,                 loss: 0.2354
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3164s / 304.8711 s
agent0:                 episode reward: -0.2817,                 loss: nan
agent1:                 episode reward: 0.2817,                 loss: 0.2338
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3490s / 306.2201 s
agent0:                 episode reward: 0.7586,                 loss: nan
agent1:                 episode reward: -0.7586,                 loss: 0.2564
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3413s / 307.5614 s
agent0:                 episode reward: -0.2494,                 loss: nan
agent1:                 episode reward: 0.2494,                 loss: 0.2562
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3445s / 308.9059 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.2557
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3891s / 310.2950 s
agent0:                 episode reward: 0.5289,                 loss: nan
agent1:                 episode reward: -0.5289,                 loss: 0.2537
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3628s / 311.6578 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.2508
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3599s / 313.0177 s
agent0:                 episode reward: 0.3464,                 loss: nan
agent1:                 episode reward: -0.3464,                 loss: 0.2611
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3489s / 314.3666 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.2592
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3488s / 315.7155 s
agent0:                 episode reward: 0.0356,                 loss: nan
agent1:                 episode reward: -0.0356,                 loss: 0.2580
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3526s / 317.0681 s
agent0:                 episode reward: 0.2493,                 loss: nan
agent1:                 episode reward: -0.2493,                 loss: 0.2556
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3787s / 318.4468 s
agent0:                 episode reward: 0.4922,                 loss: nan
agent1:                 episode reward: -0.4922,                 loss: 0.2547
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4126s / 319.8593 s
agent0:                 episode reward: -0.1587,                 loss: nan
agent1:                 episode reward: 0.1587,                 loss: 0.2620
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3658s / 321.2252 s
agent0:                 episode reward: 0.2425,                 loss: nan
agent1:                 episode reward: -0.2425,                 loss: 0.2544
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3785s / 322.6037 s
agent0:                 episode reward: -0.0677,                 loss: nan
agent1:                 episode reward: 0.0677,                 loss: 0.2531
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4052s / 324.0089 s
agent0:                 episode reward: 0.2929,                 loss: nan
agent1:                 episode reward: -0.2929,                 loss: 0.2520
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3746s / 325.3834 s
agent0:                 episode reward: 0.1371,                 loss: nan
agent1:                 episode reward: -0.1371,                 loss: 0.2511
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3736s / 326.7570 s
agent0:                 episode reward: 0.3024,                 loss: nan
agent1:                 episode reward: -0.3024,                 loss: 0.2670
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4220s / 328.1790 s
agent0:                 episode reward: 0.6368,                 loss: nan
agent1:                 episode reward: -0.6368,                 loss: 0.2653
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3681s / 329.5472 s
agent0:                 episode reward: 1.2224,                 loss: nan
agent1:                 episode reward: -1.2224,                 loss: 0.2632
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4156s / 330.9628 s
agent0:                 episode reward: 0.0718,                 loss: nan
agent1:                 episode reward: -0.0718,                 loss: 0.2616
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4227s / 332.3854 s
agent0:                 episode reward: -0.0605,                 loss: nan
agent1:                 episode reward: 0.0605,                 loss: 0.2637
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3991s / 333.7846 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: 0.2952
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3765s / 335.1610 s
agent0:                 episode reward: 0.7114,                 loss: nan
agent1:                 episode reward: -0.7114,                 loss: 0.2960
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4226s / 336.5836 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.2961
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3880s / 337.9716 s
agent0:                 episode reward: 0.4788,                 loss: nan
agent1:                 episode reward: -0.4788,                 loss: 0.2942
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3946s / 339.3662 s
agent0:                 episode reward: -0.2450,                 loss: nan
agent1:                 episode reward: 0.2450,                 loss: 0.2950
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4777s / 340.8439 s
agent0:                 episode reward: 0.7153,                 loss: nan
agent1:                 episode reward: -0.7153,                 loss: 0.3343
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4101s / 342.2540 s
agent0:                 episode reward: 0.2464,                 loss: nan
agent1:                 episode reward: -0.2464,                 loss: 0.3359
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4094s / 343.6634 s
agent0:                 episode reward: -0.3460,                 loss: nan
agent1:                 episode reward: 0.3460,                 loss: 0.3352
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4274s / 345.0909 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: 0.3346
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4399s / 346.5307 s
agent0:                 episode reward: 0.9538,                 loss: nan
agent1:                 episode reward: -0.9538,                 loss: 0.3329
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5685s / 348.0992 s
agent0:                 episode reward: 0.6244,                 loss: nan
agent1:                 episode reward: -0.6244,                 loss: 0.3121
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5250s / 349.6242 s
agent0:                 episode reward: -0.4947,                 loss: nan
agent1:                 episode reward: 0.4947,                 loss: 0.2994
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5126s / 351.1368 s
agent0:                 episode reward: 0.5438,                 loss: nan
agent1:                 episode reward: -0.5438,                 loss: 0.2959
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4339s / 352.5708 s
agent0:                 episode reward: -0.2963,                 loss: nan
agent1:                 episode reward: 0.2963,                 loss: 0.2960
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4524s / 354.0231 s
agent0:                 episode reward: -0.4142,                 loss: nan
agent1:                 episode reward: 0.4142,                 loss: 0.2940
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4371s / 355.4603 s
agent0:                 episode reward: -0.1938,                 loss: nan
agent1:                 episode reward: 0.1938,                 loss: 0.2407
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4598s / 356.9201 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.2249
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4468s / 358.3669 s
agent0:                 episode reward: 0.3050,                 loss: nan
agent1:                 episode reward: -0.3050,                 loss: 0.2202
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4611s / 359.8280 s
agent0:                 episode reward: 0.0218,                 loss: nan
agent1:                 episode reward: -0.0218,                 loss: 0.2190
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4987s / 361.3267 s
agent0:                 episode reward: 0.1741,                 loss: nan
agent1:                 episode reward: -0.1741,                 loss: 0.2178
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4579s / 362.7846 s
agent0:                 episode reward: -0.2299,                 loss: nan
agent1:                 episode reward: 0.2299,                 loss: 0.1952
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4693s / 364.2539 s
agent0:                 episode reward: 0.2254,                 loss: nan
agent1:                 episode reward: -0.2254,                 loss: 0.1861
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4933s / 365.7472 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1852
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4351s / 367.1823 s
agent0:                 episode reward: -0.2060,                 loss: nan
agent1:                 episode reward: 0.2060,                 loss: 0.1831
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4485s / 368.6308 s
agent0:                 episode reward: -0.0082,                 loss: nan
agent1:                 episode reward: 0.0082,                 loss: 0.1827
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4802s / 370.1109 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.1971
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5281s / 371.6391 s
agent0:                 episode reward: -0.4681,                 loss: nan
agent1:                 episode reward: 0.4681,                 loss: 0.1973
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4875s / 373.1266 s
agent0:                 episode reward: -0.3512,                 loss: nan
agent1:                 episode reward: 0.3512,                 loss: 0.1976
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4943s / 374.6209 s
agent0:                 episode reward: -0.1868,                 loss: nan
agent1:                 episode reward: 0.1868,                 loss: 0.1958
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4517s / 376.0726 s
agent0:                 episode reward: -0.1097,                 loss: nan
agent1:                 episode reward: 0.1097,                 loss: 0.1943
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4489s / 377.5215 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.2186
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4510s / 378.9725 s
agent0:                 episode reward: 0.1583,                 loss: nan
agent1:                 episode reward: -0.1583,                 loss: 0.2182
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4633s / 380.4358 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.2181
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5390s / 381.9749 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.2168
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4999s / 383.4748 s
agent0:                 episode reward: -0.1337,                 loss: nan
agent1:                 episode reward: 0.1337,                 loss: 0.2149
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4907s / 384.9655 s
agent0:                 episode reward: -0.1975,                 loss: nan
agent1:                 episode reward: 0.1975,                 loss: 0.2457
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4947s / 386.4602 s
agent0:                 episode reward: 0.1717,                 loss: nan
agent1:                 episode reward: -0.1717,                 loss: 0.2471
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4863s / 387.9464 s
agent0:                 episode reward: 0.1369,                 loss: nan
agent1:                 episode reward: -0.1369,                 loss: 0.2464
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4873s / 389.4338 s
agent0:                 episode reward: 0.3714,                 loss: nan
agent1:                 episode reward: -0.3714,                 loss: 0.2468
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5075s / 390.9412 s
agent0:                 episode reward: 0.0763,                 loss: nan
agent1:                 episode reward: -0.0763,                 loss: 0.2436
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5393s / 392.4806 s
agent0:                 episode reward: -0.1838,                 loss: nan
agent1:                 episode reward: 0.1838,                 loss: 0.2605
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5263s / 394.0068 s
agent0:                 episode reward: 0.4036,                 loss: nan
agent1:                 episode reward: -0.4036,                 loss: 0.2580
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4933s / 395.5002 s
agent0:                 episode reward: -0.2490,                 loss: nan
agent1:                 episode reward: 0.2490,                 loss: 0.2576
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4730s / 396.9732 s
agent0:                 episode reward: -0.1581,                 loss: nan
agent1:                 episode reward: 0.1581,                 loss: 0.2558
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5157s / 398.4889 s
agent0:                 episode reward: 0.1585,                 loss: nan
agent1:                 episode reward: -0.1585,                 loss: 0.2535
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5016s / 399.9905 s
agent0:                 episode reward: -0.0136,                 loss: nan
agent1:                 episode reward: 0.0136,                 loss: 0.2597
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5709s / 401.5613 s
agent0:                 episode reward: 0.3913,                 loss: nan
agent1:                 episode reward: -0.3913,                 loss: 0.2553
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5186s / 403.0799 s
agent0:                 episode reward: -0.3192,                 loss: nan
agent1:                 episode reward: 0.3192,                 loss: 0.2540
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5193s / 404.5991 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.2535
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5272s / 406.1264 s
agent0:                 episode reward: -0.0197,                 loss: nan
agent1:                 episode reward: 0.0197,                 loss: 0.2520
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5393s / 407.6657 s
agent0:                 episode reward: -0.0766,                 loss: nan
agent1:                 episode reward: 0.0766,                 loss: 0.2721
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5070s / 409.1727 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.2699
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5281s / 410.7008 s
agent0:                 episode reward: -0.0303,                 loss: nan
agent1:                 episode reward: 0.0303,                 loss: 0.2666
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5771s / 412.2779 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.2653
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5355s / 413.8135 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.2657
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5687s / 415.3822 s
agent0:                 episode reward: -0.1277,                 loss: nan
agent1:                 episode reward: 0.1277,                 loss: 0.2975
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5472s / 416.9294 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.2974
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5400s / 418.4693 s
agent0:                 episode reward: 0.2819,                 loss: nan
agent1:                 episode reward: -0.2819,                 loss: 0.2966
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5542s / 420.0235 s
agent0:                 episode reward: 0.7380,                 loss: nan
agent1:                 episode reward: -0.7380,                 loss: 0.2944
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5402s / 421.5637 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.2963
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6356s / 423.1993 s
agent0:                 episode reward: 0.0240,                 loss: nan
agent1:                 episode reward: -0.0240,                 loss: 0.3177
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5744s / 424.7737 s
agent0:                 episode reward: -0.0491,                 loss: nan
agent1:                 episode reward: 0.0491,                 loss: 0.3172
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5655s / 426.3392 s
agent0:                 episode reward: 0.6001,                 loss: nan
agent1:                 episode reward: -0.6001,                 loss: 0.3160
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5602s / 427.8993 s
agent0:                 episode reward: -0.5171,                 loss: nan
agent1:                 episode reward: 0.5171,                 loss: 0.3128
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5598s / 429.4591 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.3105
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5459s / 431.0050 s
agent0:                 episode reward: 0.8138,                 loss: nan
agent1:                 episode reward: -0.8138,                 loss: 0.2621
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6350s / 432.6400 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.2418
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5787s / 434.2188 s
agent0:                 episode reward: 0.5721,                 loss: nan
agent1:                 episode reward: -0.5721,                 loss: 0.2410
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5729s / 435.7917 s
agent0:                 episode reward: 0.4088,                 loss: nan
agent1:                 episode reward: -0.4088,                 loss: 0.2378
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5914s / 437.3831 s
agent0:                 episode reward: 0.0285,                 loss: nan
agent1:                 episode reward: -0.0285,                 loss: 0.2351
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5757s / 438.9588 s
agent0:                 episode reward: 0.3921,                 loss: nan
agent1:                 episode reward: -0.3921,                 loss: 0.1874
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5918s / 440.5506 s
agent0:                 episode reward: 0.4665,                 loss: nan
agent1:                 episode reward: -0.4665,                 loss: 0.1720
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6219s / 442.1725 s
agent0:                 episode reward: -0.6463,                 loss: nan
agent1:                 episode reward: 0.6463,                 loss: 0.1719
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6375s / 443.8100 s
agent0:                 episode reward: 0.0832,                 loss: nan
agent1:                 episode reward: -0.0832,                 loss: 0.1714
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5859s / 445.3958 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.1699
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5926s / 446.9885 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.1782
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5957s / 448.5841 s
agent0:                 episode reward: -0.1166,                 loss: nan
agent1:                 episode reward: 0.1166,                 loss: 0.1740
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6165s / 450.2006 s
agent0:                 episode reward: 0.3754,                 loss: nan
agent1:                 episode reward: -0.3754,                 loss: 0.1717
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6044s / 451.8050 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.1718
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6746s / 453.4797 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.1711
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6479s / 455.1276 s
agent0:                 episode reward: 0.5696,                 loss: nan
agent1:                 episode reward: -0.5696,                 loss: 0.1890
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6398s / 456.7673 s
agent0:                 episode reward: -0.4648,                 loss: nan
agent1:                 episode reward: 0.4648,                 loss: 0.1873
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6192s / 458.3866 s
agent0:                 episode reward: -0.4625,                 loss: nan
agent1:                 episode reward: 0.4625,                 loss: 0.1880
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6101s / 459.9967 s
agent0:                 episode reward: -0.4889,                 loss: nan
agent1:                 episode reward: 0.4889,                 loss: 0.1867
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6239s / 461.6206 s
agent0:                 episode reward: -0.3460,                 loss: nan
agent1:                 episode reward: 0.3460,                 loss: 0.1870
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6772s / 463.2979 s
agent0:                 episode reward: -0.0034,                 loss: nan
agent1:                 episode reward: 0.0034,                 loss: 0.2174
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6677s / 464.9656 s
agent0:                 episode reward: -1.0542,                 loss: nan
agent1:                 episode reward: 1.0542,                 loss: 0.2213
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6260s / 466.5916 s
agent0:                 episode reward: -0.1802,                 loss: nan
agent1:                 episode reward: 0.1802,                 loss: 0.2195
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6775s / 468.2691 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: 0.2199
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6547s / 469.9238 s
agent0:                 episode reward: -0.5896,                 loss: nan
agent1:                 episode reward: 0.5896,                 loss: 0.2188
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6345s / 471.5583 s
agent0:                 episode reward: 0.1460,                 loss: nan
agent1:                 episode reward: -0.1460,                 loss: 0.2519
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6382s / 473.1966 s
agent0:                 episode reward: -0.0582,                 loss: nan
agent1:                 episode reward: 0.0582,                 loss: 0.2538
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6946s / 474.8912 s
agent0:                 episode reward: -0.2690,                 loss: nan
agent1:                 episode reward: 0.2690,                 loss: 0.2543
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6876s / 476.5788 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.2533
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6676s / 478.2464 s
agent0:                 episode reward: -0.2995,                 loss: nan
agent1:                 episode reward: 0.2995,                 loss: 0.2515
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6648s / 479.9113 s
agent0:                 episode reward: -0.1786,                 loss: nan
agent1:                 episode reward: 0.1786,                 loss: 0.2675
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6695s / 481.5808 s
agent0:                 episode reward: -1.0136,                 loss: nan
agent1:                 episode reward: 1.0136,                 loss: 0.2656
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6760s / 483.2568 s
agent0:                 episode reward: 0.3163,                 loss: nan
agent1:                 episode reward: -0.3163,                 loss: 0.2674
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7136s / 484.9703 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.2624
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6759s / 486.6462 s
agent0:                 episode reward: -0.5292,                 loss: nan
agent1:                 episode reward: 0.5292,                 loss: 0.2627
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6666s / 488.3129 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: 0.2694
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6982s / 490.0111 s
agent0:                 episode reward: 0.3887,                 loss: nan
agent1:                 episode reward: -0.3887,                 loss: 0.2669
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7087s / 491.7198 s
agent0:                 episode reward: -0.4491,                 loss: nan
agent1:                 episode reward: 0.4491,                 loss: 0.2676
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6878s / 493.4075 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.2654
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7387s / 495.1462 s
agent0:                 episode reward: -0.0534,                 loss: nan
agent1:                 episode reward: 0.0534,                 loss: 0.2631
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7123s / 496.8585 s
agent0:                 episode reward: -0.5292,                 loss: nan
agent1:                 episode reward: 0.5292,                 loss: 0.2847
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7201s / 498.5786 s
agent0:                 episode reward: -1.0517,                 loss: nan
agent1:                 episode reward: 1.0517,                 loss: 0.2859
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6884s / 500.2669 s
agent0:                 episode reward: -0.4928,                 loss: nan
agent1:                 episode reward: 0.4928,                 loss: 0.2839
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7120s / 501.9789 s
agent0:                 episode reward: -0.2074,                 loss: nan
agent1:                 episode reward: 0.2074,                 loss: 0.2827
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7231s / 503.7020 s
agent0:                 episode reward: -0.5803,                 loss: nan
agent1:                 episode reward: 0.5803,                 loss: 0.2847
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7483s / 505.4503 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.3050
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7414s / 507.1917 s
agent0:                 episode reward: -0.5316,                 loss: nan
agent1:                 episode reward: 0.5316,                 loss: 0.3031
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7149s / 508.9066 s
agent0:                 episode reward: -0.7949,                 loss: nan
agent1:                 episode reward: 0.7949,                 loss: 0.2999
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7181s / 510.6246 s
agent0:                 episode reward: 0.1239,                 loss: nan
agent1:                 episode reward: -0.1239,                 loss: 0.2989
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7023s / 512.3269 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.2980
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7201s / 514.0470 s
agent0:                 episode reward: -0.4310,                 loss: nan
agent1:                 episode reward: 0.4310,                 loss: 0.2876
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8692s / 515.9163 s
agent0:                 episode reward: -0.1063,                 loss: nan
agent1:                 episode reward: 0.1063,                 loss: 0.2757
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7228s / 517.6390 s
agent0:                 episode reward: -0.8967,                 loss: nan
agent1:                 episode reward: 0.8967,                 loss: 0.2733
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7444s / 519.3834 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.2721
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7301s / 521.1135 s
agent0:                 episode reward: -0.4675,                 loss: nan
agent1:                 episode reward: 0.4675,                 loss: 0.2709
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7605s / 522.8740 s
agent0:                 episode reward: -0.7109,                 loss: nan
agent1:                 episode reward: 0.7109,                 loss: 0.2044
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7596s / 524.6336 s
agent0:                 episode reward: -0.5131,                 loss: nan
agent1:                 episode reward: 0.5131,                 loss: 0.1833
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7792s / 526.4128 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.1806
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7814s / 528.1942 s
agent0:                 episode reward: -0.0587,                 loss: nan
agent1:                 episode reward: 0.0587,                 loss: 0.1795
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7389s / 529.9331 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.1800
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7864s / 531.7195 s
agent0:                 episode reward: 0.0894,                 loss: nan
agent1:                 episode reward: -0.0894,                 loss: 0.1576
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7955s / 533.5150 s
agent0:                 episode reward: -0.0421,                 loss: nan
agent1:                 episode reward: 0.0421,                 loss: 0.1482
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8178s / 535.3328 s
agent0:                 episode reward: -0.4024,                 loss: nan
agent1:                 episode reward: 0.4024,                 loss: 0.1457
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7851s / 537.1178 s
agent0:                 episode reward: -0.0325,                 loss: nan
agent1:                 episode reward: 0.0325,                 loss: 0.1454
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7852s / 538.9030 s
agent0:                 episode reward: -0.3158,                 loss: nan
agent1:                 episode reward: 0.3158,                 loss: 0.1442
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8078s / 540.7108 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.1647
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7978s / 542.5087 s
agent0:                 episode reward: -1.4125,                 loss: nan
agent1:                 episode reward: 1.4125,                 loss: 0.1644
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8004s / 544.3091 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1604
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8660s / 546.1751 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.1606
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7945s / 547.9696 s
agent0:                 episode reward: 0.4747,                 loss: nan
agent1:                 episode reward: -0.4747,                 loss: 0.1611
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7806s / 549.7502 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1900
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7910s / 551.5412 s
agent0:                 episode reward: -0.0314,                 loss: nan
agent1:                 episode reward: 0.0314,                 loss: 0.1928
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7847s / 553.3260 s
agent0:                 episode reward: 0.5073,                 loss: nan
agent1:                 episode reward: -0.5073,                 loss: 0.1918
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8018s / 555.1277 s
agent0:                 episode reward: 0.0653,                 loss: nan
agent1:                 episode reward: -0.0653,                 loss: 0.1914
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8800s / 557.0077 s
agent0:                 episode reward: -0.1553,                 loss: nan
agent1:                 episode reward: 0.1553,                 loss: 0.1900
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8021s / 558.8098 s
agent0:                 episode reward: -0.5620,                 loss: nan
agent1:                 episode reward: 0.5620,                 loss: 0.2244
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8026s / 560.6125 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.2278
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8227s / 562.4352 s
agent0:                 episode reward: -1.0495,                 loss: nan
agent1:                 episode reward: 1.0495,                 loss: 0.2273
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8394s / 564.2746 s
agent0:                 episode reward: 0.4147,                 loss: nan
agent1:                 episode reward: -0.4147,                 loss: 0.2286
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8753s / 566.1499 s
agent0:                 episode reward: -1.0193,                 loss: nan
agent1:                 episode reward: 1.0193,                 loss: 0.2277
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8336s / 567.9836 s
agent0:                 episode reward: -0.2369,                 loss: nan
agent1:                 episode reward: 0.2369,                 loss: 0.2583
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8465s / 569.8300 s
agent0:                 episode reward: -0.5209,                 loss: nan
agent1:                 episode reward: 0.5209,                 loss: 0.2612
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8152s / 571.6452 s
agent0:                 episode reward: 0.0551,                 loss: nan
agent1:                 episode reward: -0.0551,                 loss: 0.2602
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8196s / 573.4648 s
agent0:                 episode reward: -0.2018,                 loss: nan
agent1:                 episode reward: 0.2018,                 loss: 0.2589
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8275s / 575.2923 s
agent0:                 episode reward: -0.5806,                 loss: nan
agent1:                 episode reward: 0.5806,                 loss: 0.2599
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9016s / 577.1940 s
agent0:                 episode reward: -0.1435,                 loss: nan
agent1:                 episode reward: 0.1435,                 loss: 0.2800
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8548s / 579.0487 s
agent0:                 episode reward: -0.4183,                 loss: nan
agent1:                 episode reward: 0.4183,                 loss: 0.2813
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8665s / 580.9152 s
agent0:                 episode reward: 0.0068,                 loss: nan
agent1:                 episode reward: -0.0068,                 loss: 0.2794
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8576s / 582.7728 s
agent0:                 episode reward: -0.8194,                 loss: nan
agent1:                 episode reward: 0.8194,                 loss: 0.2761
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8754s / 584.6482 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.2770
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9011s / 586.5493 s
agent0:                 episode reward: -0.9790,                 loss: nan
agent1:                 episode reward: 0.9790,                 loss: 0.2922
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8521s / 588.4014 s
agent0:                 episode reward: 0.0614,                 loss: nan
agent1:                 episode reward: -0.0614,                 loss: 0.2899
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8701s / 590.2715 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.2905
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8702s / 592.1417 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.2905
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8740s / 594.0157 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.2905
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8633s / 595.8790 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.3120
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9390s / 597.8180 s
agent0:                 episode reward: 0.2729,                 loss: nan
agent1:                 episode reward: -0.2729,                 loss: 0.3114
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8843s / 599.7023 s
agent0:                 episode reward: 0.1988,                 loss: nan
agent1:                 episode reward: -0.1988,                 loss: 0.3096
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8494s / 601.5518 s
agent0:                 episode reward: -0.3146,                 loss: nan
agent1:                 episode reward: 0.3146,                 loss: 0.3087
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8581s / 603.4098 s
agent0:                 episode reward: -0.5784,                 loss: nan
agent1:                 episode reward: 0.5784,                 loss: 0.3086
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8539s / 605.2638 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.3127
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9588s / 607.2225 s
agent0:                 episode reward: -0.1218,                 loss: nan
agent1:                 episode reward: 0.1218,                 loss: 0.3066
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8991s / 609.1216 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.3047
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9075s / 611.0291 s
agent0:                 episode reward: -0.0698,                 loss: nan
agent1:                 episode reward: 0.0698,                 loss: 0.3031
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9176s / 612.9467 s
agent0:                 episode reward: -0.8580,                 loss: nan
agent1:                 episode reward: 0.8580,                 loss: 0.2986/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9041s / 614.8508 s
agent0:                 episode reward: -0.2640,                 loss: nan
agent1:                 episode reward: 0.2640,                 loss: 0.2395
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8956s / 616.7464 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: 0.2202
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9702s / 618.7166 s
agent0:                 episode reward: 0.7150,                 loss: nan
agent1:                 episode reward: -0.7150,                 loss: 0.2169
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9143s / 620.6309 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: 0.2172
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9445s / 622.5754 s
agent0:                 episode reward: -0.0590,                 loss: nan
agent1:                 episode reward: 0.0590,                 loss: 0.2161
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9578s / 624.5331 s
agent0:                 episode reward: 0.2196,                 loss: nan
agent1:                 episode reward: -0.2196,                 loss: 0.1705
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9691s / 626.5022 s
agent0:                 episode reward: -0.0851,                 loss: nan
agent1:                 episode reward: 0.0851,                 loss: 0.1536
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0146s / 628.5168 s
agent0:                 episode reward: -1.1958,                 loss: nan
agent1:                 episode reward: 1.1958,                 loss: 0.1510
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9301s / 630.4469 s
agent0:                 episode reward: -0.1372,                 loss: nan
agent1:                 episode reward: 0.1372,                 loss: 0.1488
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9324s / 632.3793 s
agent0:                 episode reward: -0.5854,                 loss: nan
agent1:                 episode reward: 0.5854,                 loss: 0.1486
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9612s / 634.3405 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1548
