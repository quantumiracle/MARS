2022-05-10 23:13:55.530450: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:13:55.530525: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:13:55.530530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 761
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f414b578588>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/4000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/4000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_4000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_4000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8772s / 0.8772 s
agent0:                 episode reward: 0.7992,                 loss: nan
agent1:                 episode reward: -0.7992,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1208s / 0.9980 s
agent0:                 episode reward: 1.2407,                 loss: nan
agent1:                 episode reward: -1.2407,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1133s / 1.1113 s
agent0:                 episode reward: -0.0733,                 loss: nan
agent1:                 episode reward: 0.0733,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1191s / 1.2304 s
agent0:                 episode reward: 1.1019,                 loss: nan
agent1:                 episode reward: -1.1019,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1130s / 1.3434 s
agent0:                 episode reward: 0.9563,                 loss: nan
agent1:                 episode reward: -0.9563,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1188s / 1.4623 s
agent0:                 episode reward: 0.4404,                 loss: nan
agent1:                 episode reward: -0.4404,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1126s / 1.5749 s
agent0:                 episode reward: 0.8434,                 loss: nan
agent1:                 episode reward: -0.8434,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3478s / 1.9227 s
agent0:                 episode reward: 0.4392,                 loss: nan
agent1:                 episode reward: -0.4392,                 loss: 0.4760
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4362s / 2.3589 s
agent0:                 episode reward: 1.2002,                 loss: nan
agent1:                 episode reward: -1.2002,                 loss: 0.4402
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4532s / 2.8121 s
agent0:                 episode reward: 0.3652,                 loss: nan
agent1:                 episode reward: -0.3652,                 loss: 0.4376
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4444s / 3.2565 s
agent0:                 episode reward: 0.9353,                 loss: nan
agent1:                 episode reward: -0.9353,                 loss: 0.4349
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4277s / 3.6842 s
agent0:                 episode reward: 0.8405,                 loss: nan
agent1:                 episode reward: -0.8405,                 loss: 0.4319
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4448s / 4.1290 s
agent0:                 episode reward: -0.0224,                 loss: nan
agent1:                 episode reward: 0.0224,                 loss: 0.4284
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4523s / 4.5813 s
agent0:                 episode reward: 1.9073,                 loss: nan
agent1:                 episode reward: -1.9073,                 loss: 0.4263
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4405s / 5.0218 s
agent0:                 episode reward: 1.5526,                 loss: nan
agent1:                 episode reward: -1.5526,                 loss: 0.4247
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4489s / 5.4707 s
agent0:                 episode reward: 1.2275,                 loss: nan
agent1:                 episode reward: -1.2275,                 loss: 0.4229
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4647s / 5.9354 s
agent0:                 episode reward: 1.0965,                 loss: nan
agent1:                 episode reward: -1.0965,                 loss: 0.4215
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4468s / 6.3823 s
agent0:                 episode reward: 0.3972,                 loss: nan
agent1:                 episode reward: -0.3972,                 loss: 0.4408
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4509s / 6.8332 s
agent0:                 episode reward: 0.3703,                 loss: nan
agent1:                 episode reward: -0.3703,                 loss: 0.4495
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4473s / 7.2805 s
agent0:                 episode reward: 1.6100,                 loss: nan
agent1:                 episode reward: -1.6100,                 loss: 0.4480
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4483s / 7.7288 s
agent0:                 episode reward: 0.2212,                 loss: nan
agent1:                 episode reward: -0.2212,                 loss: 0.4494
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4522s / 8.1810 s
agent0:                 episode reward: 2.1892,                 loss: nan
agent1:                 episode reward: -2.1892,                 loss: 0.4479
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4526s / 8.6336 s
agent0:                 episode reward: 1.7329,                 loss: nan
agent1:                 episode reward: -1.7329,                 loss: 0.4466
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4690s / 9.1025 s
agent0:                 episode reward: 0.8303,                 loss: nan
agent1:                 episode reward: -0.8303,                 loss: 0.4457
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4560s / 9.5585 s
agent0:                 episode reward: 1.1888,                 loss: nan
agent1:                 episode reward: -1.1888,                 loss: 0.4447
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4565s / 10.0150 s
agent0:                 episode reward: 0.4337,                 loss: nan
agent1:                 episode reward: -0.4337,                 loss: 0.4431
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4622s / 10.4772 s
agent0:                 episode reward: 1.4891,                 loss: nan
agent1:                 episode reward: -1.4891,                 loss: 0.4426
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4622s / 10.9394 s
agent0:                 episode reward: 1.1795,                 loss: nan
agent1:                 episode reward: -1.1795,                 loss: 0.4480
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5092s / 11.4487 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.4488
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4728s / 11.9214 s
agent0:                 episode reward: 0.5870,                 loss: nan
agent1:                 episode reward: -0.5870,                 loss: 0.4478
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4615s / 12.3830 s
agent0:                 episode reward: -0.3068,                 loss: nan
agent1:                 episode reward: 0.3068,                 loss: 0.4455
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4621s / 12.8450 s
agent0:                 episode reward: 1.5997,                 loss: nan
agent1:                 episode reward: -1.5997,                 loss: 0.4456
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4543s / 13.2993 s
agent0:                 episode reward: 1.6741,                 loss: nan
agent1:                 episode reward: -1.6741,                 loss: 0.4444
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4611s / 13.7604 s
agent0:                 episode reward: 0.0933,                 loss: nan
agent1:                 episode reward: -0.0933,                 loss: 0.4443
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4648s / 14.2252 s
agent0:                 episode reward: 0.1996,                 loss: nan
agent1:                 episode reward: -0.1996,                 loss: 0.4443
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4718s / 14.6971 s
agent0:                 episode reward: 0.9670,                 loss: nan
agent1:                 episode reward: -0.9670,                 loss: 0.4427
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4644s / 15.1615 s
agent0:                 episode reward: 0.8780,                 loss: nan
agent1:                 episode reward: -0.8780,                 loss: 0.4441
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4692s / 15.6307 s
agent0:                 episode reward: -0.2678,                 loss: nan
agent1:                 episode reward: 0.2678,                 loss: 0.4379
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4649s / 16.0956 s
agent0:                 episode reward: 0.8788,                 loss: nan
agent1:                 episode reward: -0.8788,                 loss: 0.4343
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4655s / 16.5611 s
agent0:                 episode reward: 1.4311,                 loss: nan
agent1:                 episode reward: -1.4311,                 loss: 0.4331
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4732s / 17.0343 s
agent0:                 episode reward: 0.9173,                 loss: nan
agent1:                 episode reward: -0.9173,                 loss: 0.4334
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4836s / 17.5179 s
agent0:                 episode reward: 1.6094,                 loss: nan
agent1:                 episode reward: -1.6094,                 loss: 0.4308
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4752s / 17.9931 s
agent0:                 episode reward: 0.5328,                 loss: nan
agent1:                 episode reward: -0.5328,                 loss: 0.4305
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4697s / 18.4627 s
agent0:                 episode reward: 1.1316,                 loss: nan
agent1:                 episode reward: -1.1316,                 loss: 0.4308
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4719s / 18.9346 s
agent0:                 episode reward: 0.5185,                 loss: nan
agent1:                 episode reward: -0.5185,                 loss: 0.4320
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4622s / 19.3969 s
agent0:                 episode reward: 1.2086,                 loss: nan
agent1:                 episode reward: -1.2086,                 loss: 0.4297
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4725s / 19.8693 s
agent0:                 episode reward: 1.1186,                 loss: nan
agent1:                 episode reward: -1.1186,                 loss: 0.4305
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4720s / 20.3414 s
agent0:                 episode reward: 0.3706,                 loss: nan
agent1:                 episode reward: -0.3706,                 loss: 0.4129
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4876s / 20.8289 s
agent0:                 episode reward: 1.2538,                 loss: nan
agent1:                 episode reward: -1.2538,                 loss: 0.4024
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5305s / 21.3594 s
agent0:                 episode reward: 1.1692,                 loss: nan
agent1:                 episode reward: -1.1692,                 loss: 0.4022
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5042s / 21.8636 s
agent0:                 episode reward: 1.0143,                 loss: nan
agent1:                 episode reward: -1.0143,                 loss: 0.4026
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4782s / 22.3418 s
agent0:                 episode reward: 0.3580,                 loss: nan
agent1:                 episode reward: -0.3580,                 loss: 0.3998
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4763s / 22.8180 s
agent0:                 episode reward: 0.5500,                 loss: nan
agent1:                 episode reward: -0.5500,                 loss: 0.4019
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4829s / 23.3010 s
agent0:                 episode reward: 0.6912,                 loss: nan
agent1:                 episode reward: -0.6912,                 loss: 0.3978
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4877s / 23.7887 s
agent0:                 episode reward: 0.6499,                 loss: nan
agent1:                 episode reward: -0.6499,                 loss: 0.3985
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4790s / 24.2677 s
agent0:                 episode reward: 1.8338,                 loss: nan
agent1:                 episode reward: -1.8338,                 loss: 0.3960
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4830s / 24.7507 s
agent0:                 episode reward: 1.1636,                 loss: nan
agent1:                 episode reward: -1.1636,                 loss: 0.3980
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4841s / 25.2348 s
agent0:                 episode reward: 0.7594,                 loss: nan
agent1:                 episode reward: -0.7594,                 loss: 0.3675
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5074s / 25.7422 s
agent0:                 episode reward: 0.8830,                 loss: nan
agent1:                 episode reward: -0.8830,                 loss: 0.3522
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4712s / 26.2134 s
agent0:                 episode reward: 0.4029,                 loss: nan
agent1:                 episode reward: -0.4029,                 loss: 0.3523
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4836s / 26.6970 s
agent0:                 episode reward: 1.3091,                 loss: nan
agent1:                 episode reward: -1.3091,                 loss: 0.3514
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4926s / 27.1896 s
agent0:                 episode reward: 1.3478,                 loss: nan
agent1:                 episode reward: -1.3478,                 loss: 0.3495
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4902s / 27.6798 s
agent0:                 episode reward: 1.3715,                 loss: nan
agent1:                 episode reward: -1.3715,                 loss: 0.3466
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4884s / 28.1682 s
agent0:                 episode reward: 0.5179,                 loss: nan
agent1:                 episode reward: -0.5179,                 loss: 0.3479
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4927s / 28.6610 s
agent0:                 episode reward: 0.3547,                 loss: nan
agent1:                 episode reward: -0.3547,                 loss: 0.3448
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4891s / 29.1501 s
agent0:                 episode reward: 0.2941,                 loss: nan
agent1:                 episode reward: -0.2941,                 loss: 0.3443
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4882s / 29.6383 s
agent0:                 episode reward: 0.7717,                 loss: nan
agent1:                 episode reward: -0.7717,                 loss: 0.3454
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4890s / 30.1273 s
agent0:                 episode reward: 2.0615,                 loss: nan
agent1:                 episode reward: -2.0615,                 loss: 0.3271
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5002s / 30.6275 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: 0.3180
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4959s / 31.1234 s
agent0:                 episode reward: 0.7112,                 loss: nan
agent1:                 episode reward: -0.7112,                 loss: 0.3159
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5596s / 31.6830 s
agent0:                 episode reward: 0.8389,                 loss: nan
agent1:                 episode reward: -0.8389,                 loss: 0.3154
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5011s / 32.1840 s
agent0:                 episode reward: 2.0386,                 loss: nan
agent1:                 episode reward: -2.0386,                 loss: 0.3165
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4947s / 32.6787 s
agent0:                 episode reward: 0.4097,                 loss: nan
agent1:                 episode reward: -0.4097,                 loss: 0.3148
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4898s / 33.1685 s
agent0:                 episode reward: 0.8696,                 loss: nan
agent1:                 episode reward: -0.8696,                 loss: 0.3143
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4971s / 33.6655 s
agent0:                 episode reward: 0.6600,                 loss: nan
agent1:                 episode reward: -0.6600,                 loss: 0.3147
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5193s / 34.1849 s
agent0:                 episode reward: 0.6646,                 loss: nan
agent1:                 episode reward: -0.6646,                 loss: 0.3120
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4998s / 34.6847 s
agent0:                 episode reward: 0.4450,                 loss: nan
agent1:                 episode reward: -0.4450,                 loss: 0.3120
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4961s / 35.1808 s
agent0:                 episode reward: 0.1550,                 loss: nan
agent1:                 episode reward: -0.1550,                 loss: 0.3019
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5046s / 35.6854 s
agent0:                 episode reward: 0.4210,                 loss: nan
agent1:                 episode reward: -0.4210,                 loss: 0.2952
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5022s / 36.1876 s
agent0:                 episode reward: 0.8929,                 loss: nan
agent1:                 episode reward: -0.8929,                 loss: 0.2969
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5009s / 36.6884 s
agent0:                 episode reward: 1.3936,                 loss: nan
agent1:                 episode reward: -1.3936,                 loss: 0.2962
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4992s / 37.1876 s
agent0:                 episode reward: 0.8092,                 loss: nan
agent1:                 episode reward: -0.8092,                 loss: 0.2953
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4984s / 37.6860 s
agent0:                 episode reward: 0.4532,                 loss: nan
agent1:                 episode reward: -0.4532,                 loss: 0.2933
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4990s / 38.1850 s
agent0:                 episode reward: 0.9214,                 loss: nan
agent1:                 episode reward: -0.9214,                 loss: 0.2920
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5022s / 38.6872 s
agent0:                 episode reward: 0.4327,                 loss: nan
agent1:                 episode reward: -0.4327,                 loss: 0.2933
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5027s / 39.1899 s
agent0:                 episode reward: -0.0024,                 loss: nan
agent1:                 episode reward: 0.0024,                 loss: 0.2923
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5022s / 39.6921 s
agent0:                 episode reward: 1.0210,                 loss: nan
agent1:                 episode reward: -1.0210,                 loss: 0.2890
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4962s / 40.1882 s
agent0:                 episode reward: 0.6572,                 loss: nan
agent1:                 episode reward: -0.6572,                 loss: 0.2889
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5055s / 40.6938 s
agent0:                 episode reward: 0.4932,                 loss: nan
agent1:                 episode reward: -0.4932,                 loss: 0.2893
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5079s / 41.2017 s
agent0:                 episode reward: 0.8566,                 loss: nan
agent1:                 episode reward: -0.8566,                 loss: 0.2847
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5191s / 41.7207 s
agent0:                 episode reward: 1.6027,                 loss: nan
agent1:                 episode reward: -1.6027,                 loss: 0.2876
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5718s / 42.2926 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.2862
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5048s / 42.7973 s
agent0:                 episode reward: 0.1359,                 loss: nan
agent1:                 episode reward: -0.1359,                 loss: 0.2877
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5100s / 43.3074 s
agent0:                 episode reward: 1.3605,                 loss: nan
agent1:                 episode reward: -1.3605,                 loss: 0.2868
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5553s / 43.8627 s
agent0:                 episode reward: 0.9403,                 loss: nan
agent1:                 episode reward: -0.9403,                 loss: 0.2847
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5071s / 44.3698 s
agent0:                 episode reward: 1.0906,                 loss: nan
agent1:                 episode reward: -1.0906,                 loss: 0.2868
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5211s / 44.8909 s
agent0:                 episode reward: 0.3892,                 loss: nan
agent1:                 episode reward: -0.3892,                 loss: 0.2828
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5036s / 45.3945 s
agent0:                 episode reward: 0.0454,                 loss: nan
agent1:                 episode reward: -0.0454,                 loss: 0.2915
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5279s / 45.9224 s
agent0:                 episode reward: 0.4713,                 loss: nan
agent1:                 episode reward: -0.4713,                 loss: 0.2927
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5093s / 46.4317 s
agent0:                 episode reward: 0.0838,                 loss: nan
agent1:                 episode reward: -0.0838,                 loss: 0.2913
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5200s / 46.9517 s
agent0:                 episode reward: 0.8904,                 loss: nan
agent1:                 episode reward: -0.8904,                 loss: 0.2906
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5100s / 47.4616 s
agent0:                 episode reward: 1.0879,                 loss: nan
agent1:                 episode reward: -1.0879,                 loss: 0.2936
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5237s / 47.9853 s
agent0:                 episode reward: 1.2041,                 loss: nan
agent1:                 episode reward: -1.2041,                 loss: 0.2880
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5110s / 48.4963 s
agent0:                 episode reward: 0.2435,                 loss: nan
agent1:                 episode reward: -0.2435,                 loss: 0.2895
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5328s / 49.0291 s
agent0:                 episode reward: 0.4349,                 loss: nan
agent1:                 episode reward: -0.4349,                 loss: 0.2881
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5146s / 49.5437 s
agent0:                 episode reward: 0.5336,                 loss: nan
agent1:                 episode reward: -0.5336,                 loss: 0.2887
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5159s / 50.0596 s
agent0:                 episode reward: 0.3515,                 loss: nan
agent1:                 episode reward: -0.3515,                 loss: 0.2855
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5342s / 50.5939 s
agent0:                 episode reward: -0.3121,                 loss: nan
agent1:                 episode reward: 0.3121,                 loss: 0.3035
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5287s / 51.1225 s
agent0:                 episode reward: 1.0123,                 loss: nan
agent1:                 episode reward: -1.0123,                 loss: 0.3111
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5169s / 51.6394 s
agent0:                 episode reward: 0.7314,                 loss: nan
agent1:                 episode reward: -0.7314,                 loss: 0.3080
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5735s / 52.2129 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.3081
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5236s / 52.7364 s
agent0:                 episode reward: 0.3140,                 loss: nan
agent1:                 episode reward: -0.3140,                 loss: 0.3071
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5296s / 53.2661 s
agent0:                 episode reward: 0.3733,                 loss: nan
agent1:                 episode reward: -0.3733,                 loss: 0.3054
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5338s / 53.7999 s
agent0:                 episode reward: 1.5145,                 loss: nan
agent1:                 episode reward: -1.5145,                 loss: 0.3062
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5194s / 54.3193 s
agent0:                 episode reward: 0.9515,                 loss: nan
agent1:                 episode reward: -0.9515,                 loss: 0.3063
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5242s / 54.8435 s
agent0:                 episode reward: 1.6082,                 loss: nan
agent1:                 episode reward: -1.6082,                 loss: 0.3040
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5253s / 55.3688 s
agent0:                 episode reward: 0.7532,                 loss: nan
agent1:                 episode reward: -0.7532,                 loss: 0.3036
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5248s / 55.8937 s
agent0:                 episode reward: -0.0634,                 loss: nan
agent1:                 episode reward: 0.0634,                 loss: 0.3228
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5224s / 56.4161 s
agent0:                 episode reward: 0.0786,                 loss: nan
agent1:                 episode reward: -0.0786,                 loss: 0.3268
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5363s / 56.9524 s
agent0:                 episode reward: 0.7903,                 loss: nan
agent1:                 episode reward: -0.7903,                 loss: 0.3277
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5332s / 57.4856 s
agent0:                 episode reward: -0.8145,                 loss: nan
agent1:                 episode reward: 0.8145,                 loss: 0.3264
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5361s / 58.0216 s
agent0:                 episode reward: 0.5065,                 loss: nan
agent1:                 episode reward: -0.5065,                 loss: 0.3265
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5517s / 58.5733 s
agent0:                 episode reward: 0.6552,                 loss: nan
agent1:                 episode reward: -0.6552,                 loss: 0.3234
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5326s / 59.1059 s
agent0:                 episode reward: 0.7970,                 loss: nan
agent1:                 episode reward: -0.7970,                 loss: 0.3232
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5281s / 59.6340 s
agent0:                 episode reward: 1.6838,                 loss: nan
agent1:                 episode reward: -1.6838,                 loss: 0.3227
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5446s / 60.1786 s
agent0:                 episode reward: 0.6954,                 loss: nan
agent1:                 episode reward: -0.6954,                 loss: 0.3206
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5319s / 60.7105 s
agent0:                 episode reward: 0.5874,                 loss: nan
agent1:                 episode reward: -0.5874,                 loss: 0.3231
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5289s / 61.2394 s
agent0:                 episode reward: 1.0408,                 loss: nan
agent1:                 episode reward: -1.0408,                 loss: 0.3275
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5563s / 61.7957 s
agent0:                 episode reward: 0.1688,                 loss: nan
agent1:                 episode reward: -0.1688,                 loss: 0.3251
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5496s / 62.3453 s
agent0:                 episode reward: 0.2403,                 loss: nan
agent1:                 episode reward: -0.2403,                 loss: 0.3242
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6380s / 62.9833 s
agent0:                 episode reward: 0.9099,                 loss: nan
agent1:                 episode reward: -0.9099,                 loss: 0.3212
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5406s / 63.5239 s
agent0:                 episode reward: 0.3437,                 loss: nan
agent1:                 episode reward: -0.3437,                 loss: 0.3228
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5330s / 64.0569 s
agent0:                 episode reward: 0.9249,                 loss: nan
agent1:                 episode reward: -0.9249,                 loss: 0.3204
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5255s / 64.5824 s
agent0:                 episode reward: 0.9006,                 loss: nan
agent1:                 episode reward: -0.9006,                 loss: 0.3207
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5346s / 65.1171 s
agent0:                 episode reward: 1.4807,                 loss: nan
agent1:                 episode reward: -1.4807,                 loss: 0.3197
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5317s / 65.6488 s
agent0:                 episode reward: 0.5458,                 loss: nan
agent1:                 episode reward: -0.5458,                 loss: 0.3192
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5438s / 66.1926 s
agent0:                 episode reward: 1.0710,                 loss: nan
agent1:                 episode reward: -1.0710,                 loss: 0.3190
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5435s / 66.7361 s
agent0:                 episode reward: 0.9781,                 loss: nan
agent1:                 episode reward: -0.9781,                 loss: 0.3321
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5429s / 67.2791 s
agent0:                 episode reward: 0.1356,                 loss: nan
agent1:                 episode reward: -0.1356,                 loss: 0.3316
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5407s / 67.8198 s
agent0:                 episode reward: 0.4645,                 loss: nan
agent1:                 episode reward: -0.4645,                 loss: 0.3317
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5393s / 68.3591 s
agent0:                 episode reward: 0.6831,                 loss: nan
agent1:                 episode reward: -0.6831,                 loss: 0.3286
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5492s / 68.9083 s
agent0:                 episode reward: 0.7702,                 loss: nan
agent1:                 episode reward: -0.7702,                 loss: 0.3289
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5378s / 69.4461 s
agent0:                 episode reward: 0.7556,                 loss: nan
agent1:                 episode reward: -0.7556,                 loss: 0.3307
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5455s / 69.9916 s
agent0:                 episode reward: -0.0101,                 loss: nan
agent1:                 episode reward: 0.0101,                 loss: 0.3279
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5471s / 70.5387 s
agent0:                 episode reward: 0.4717,                 loss: nan
agent1:                 episode reward: -0.4717,                 loss: 0.3238
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5387s / 71.0773 s
agent0:                 episode reward: 0.2644,                 loss: nan
agent1:                 episode reward: -0.2644,                 loss: 0.3252
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5444s / 71.6217 s
agent0:                 episode reward: 0.4603,                 loss: nan
agent1:                 episode reward: -0.4603,                 loss: 0.3234
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5503s / 72.1720 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.3323
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5986s / 72.7705 s
agent0:                 episode reward: 1.4061,                 loss: nan
agent1:                 episode reward: -1.4061,                 loss: 0.3301
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5512s / 73.3218 s
agent0:                 episode reward: 0.6531,                 loss: nan
agent1:                 episode reward: -0.6531,                 loss: 0.3311
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5373s / 73.8591 s
agent0:                 episode reward: -0.7876,                 loss: nan
agent1:                 episode reward: 0.7876,                 loss: 0.3278
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5411s / 74.4002 s
agent0:                 episode reward: 0.0051,                 loss: nan
agent1:                 episode reward: -0.0051,                 loss: 0.3276
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5512s / 74.9514 s
agent0:                 episode reward: 2.4241,                 loss: nan
agent1:                 episode reward: -2.4241,                 loss: 0.3240
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5633s / 75.5147 s
agent0:                 episode reward: 2.7994,                 loss: nan
agent1:                 episode reward: -2.7994,                 loss: 0.3231
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5450s / 76.0597 s
agent0:                 episode reward: 0.3280,                 loss: nan
agent1:                 episode reward: -0.3280,                 loss: 0.3206
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5501s / 76.6098 s
agent0:                 episode reward: -0.1552,                 loss: nan
agent1:                 episode reward: 0.1552,                 loss: 0.3200
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5495s / 77.1593 s
agent0:                 episode reward: 1.4122,                 loss: nan
agent1:                 episode reward: -1.4122,                 loss: 0.3187
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5503s / 77.7096 s
agent0:                 episode reward: 1.5427,                 loss: nan
agent1:                 episode reward: -1.5427,                 loss: 0.3353
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5590s / 78.2686 s
agent0:                 episode reward: 0.4805,                 loss: nan
agent1:                 episode reward: -0.4805,                 loss: 0.3431
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5398s / 78.8084 s
agent0:                 episode reward: 0.5909,                 loss: nan
agent1:                 episode reward: -0.5909,                 loss: 0.3425
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5453s / 79.3537 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.3396
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5445s / 79.8982 s
agent0:                 episode reward: 1.2563,                 loss: nan
agent1:                 episode reward: -1.2563,                 loss: 0.3397
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5499s / 80.4482 s
agent0:                 episode reward: 0.5290,                 loss: nan
agent1:                 episode reward: -0.5290,                 loss: 0.3365
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5546s / 81.0027 s
agent0:                 episode reward: 0.8979,                 loss: nan
agent1:                 episode reward: -0.8979,                 loss: 0.3366
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5427s / 81.5454 s
agent0:                 episode reward: 1.0549,                 loss: nan
agent1:                 episode reward: -1.0549,                 loss: 0.3365
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5526s / 82.0980 s
agent0:                 episode reward: 1.7441,                 loss: nan
agent1:                 episode reward: -1.7441,                 loss: 0.3348
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5451s / 82.6431 s
agent0:                 episode reward: 1.3605,                 loss: nan
agent1:                 episode reward: -1.3605,                 loss: 0.3342
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6288s / 83.2719 s
agent0:                 episode reward: 0.0154,                 loss: nan
agent1:                 episode reward: -0.0154,                 loss: 0.3630
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5804s / 83.8523 s
agent0:                 episode reward: 0.9011,                 loss: nan
agent1:                 episode reward: -0.9011,                 loss: 0.3726
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5430s / 84.3954 s
agent0:                 episode reward: 1.0243,                 loss: nan
agent1:                 episode reward: -1.0243,                 loss: 0.3707
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5507s / 84.9460 s
agent0:                 episode reward: 0.2873,                 loss: nan
agent1:                 episode reward: -0.2873,                 loss: 0.3693
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5466s / 85.4927 s
agent0:                 episode reward: -0.2525,                 loss: nan
agent1:                 episode reward: 0.2525,                 loss: 0.3694
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5461s / 86.0388 s
agent0:                 episode reward: 0.5135,                 loss: nan
agent1:                 episode reward: -0.5135,                 loss: 0.3682
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5505s / 86.5892 s
agent0:                 episode reward: 0.8405,                 loss: nan
agent1:                 episode reward: -0.8405,                 loss: 0.3677
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5583s / 87.1476 s
agent0:                 episode reward: 0.6557,                 loss: nan
agent1:                 episode reward: -0.6557,                 loss: 0.3678
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5495s / 87.6971 s
agent0:                 episode reward: 0.5973,                 loss: nan
agent1:                 episode reward: -0.5973,                 loss: 0.3680
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5463s / 88.2433 s
agent0:                 episode reward: 1.2979,                 loss: nan
agent1:                 episode reward: -1.2979,                 loss: 0.3686
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5745s / 88.8178 s
agent0:                 episode reward: 0.4132,                 loss: nan
agent1:                 episode reward: -0.4132,                 loss: 0.3915
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5700s / 89.3878 s
agent0:                 episode reward: 0.7655,                 loss: nan
agent1:                 episode reward: -0.7655,                 loss: 0.3911
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5699s / 89.9577 s
agent0:                 episode reward: -0.1652,                 loss: nan
agent1:                 episode reward: 0.1652,                 loss: 0.3886
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5582s / 90.5160 s
agent0:                 episode reward: 0.0524,                 loss: nan
agent1:                 episode reward: -0.0524,                 loss: 0.3890
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5573s / 91.0733 s
agent0:                 episode reward: 1.2201,                 loss: nan
agent1:                 episode reward: -1.2201,                 loss: 0.3870
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5715s / 91.6448 s
agent0:                 episode reward: 1.7677,                 loss: nan
agent1:                 episode reward: -1.7677,                 loss: 0.3863
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5804s / 92.2252 s
agent0:                 episode reward: 1.2754,                 loss: nan
agent1:                 episode reward: -1.2754,                 loss: 0.3853
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5719s / 92.7971 s
agent0:                 episode reward: 1.0637,                 loss: nan
agent1:                 episode reward: -1.0637,                 loss: 0.3840
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6132s / 93.4103 s
agent0:                 episode reward: 0.3221,                 loss: nan
agent1:                 episode reward: -0.3221,                 loss: 0.3870
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5635s / 93.9738 s
agent0:                 episode reward: 1.0440,                 loss: nan
agent1:                 episode reward: -1.0440,                 loss: 0.3852
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5649s / 94.5387 s
agent0:                 episode reward: 1.1550,                 loss: nan
agent1:                 episode reward: -1.1550,                 loss: 0.3581
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5644s / 95.1031 s
agent0:                 episode reward: 1.3182,                 loss: nan
agent1:                 episode reward: -1.3182,                 loss: 0.3298
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5659s / 95.6690 s
agent0:                 episode reward: 0.3214,                 loss: nan
agent1:                 episode reward: -0.3214,                 loss: 0.3265
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5719s / 96.2409 s
agent0:                 episode reward: 0.3237,                 loss: nan
agent1:                 episode reward: -0.3237,                 loss: 0.3274
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5693s / 96.8102 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.3230
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5586s / 97.3688 s
agent0:                 episode reward: 0.4997,                 loss: nan
agent1:                 episode reward: -0.4997,                 loss: 0.3218
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5650s / 97.9338 s
agent0:                 episode reward: 0.3754,                 loss: nan
agent1:                 episode reward: -0.3754,                 loss: 0.3237
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5659s / 98.4997 s
agent0:                 episode reward: 0.7596,                 loss: nan
agent1:                 episode reward: -0.7596,                 loss: 0.3224
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5674s / 99.0671 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.3236
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5681s / 99.6352 s
agent0:                 episode reward: 0.0716,                 loss: nan
agent1:                 episode reward: -0.0716,                 loss: 0.3236
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5820s / 100.2172 s
agent0:                 episode reward: 0.3009,                 loss: nan
agent1:                 episode reward: -0.3009,                 loss: 0.2658
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5640s / 100.7812 s
agent0:                 episode reward: 0.4978,                 loss: nan
agent1:                 episode reward: -0.4978,                 loss: 0.2297
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5661s / 101.3473 s
agent0:                 episode reward: 0.0934,                 loss: nan
agent1:                 episode reward: -0.0934,                 loss: 0.2303
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5839s / 101.9313 s
agent0:                 episode reward: 1.4409,                 loss: nan
agent1:                 episode reward: -1.4409,                 loss: 0.2290
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6046s / 102.5358 s
agent0:                 episode reward: 1.7382,                 loss: nan
agent1:                 episode reward: -1.7382,                 loss: 0.2292
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5706s / 103.1064 s
agent0:                 episode reward: 0.8692,                 loss: nan
agent1:                 episode reward: -0.8692,                 loss: 0.2259
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6160s / 103.7223 s
agent0:                 episode reward: 1.4562,                 loss: nan
agent1:                 episode reward: -1.4562,                 loss: 0.2262
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5698s / 104.2922 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.2263
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5740s / 104.8662 s
agent0:                 episode reward: -0.2371,                 loss: nan
agent1:                 episode reward: 0.2371,                 loss: 0.2252
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5681s / 105.4343 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.2254
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5687s / 106.0030 s
agent0:                 episode reward: -0.1475,                 loss: nan
agent1:                 episode reward: 0.1475,                 loss: 0.2070
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5742s / 106.5772 s
agent0:                 episode reward: 0.3703,                 loss: nan
agent1:                 episode reward: -0.3703,                 loss: 0.1995
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5690s / 107.1462 s
agent0:                 episode reward: 0.9188,                 loss: nan
agent1:                 episode reward: -0.9188,                 loss: 0.1988
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5670s / 107.7132 s
agent0:                 episode reward: -0.0282,                 loss: nan
agent1:                 episode reward: 0.0282,                 loss: 0.1976
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5954s / 108.3087 s
agent0:                 episode reward: 1.1251,                 loss: nan
agent1:                 episode reward: -1.1251,                 loss: 0.1976
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5741s / 108.8828 s
agent0:                 episode reward: 0.7332,                 loss: nan
agent1:                 episode reward: -0.7332,                 loss: 0.1953
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5728s / 109.4555 s
agent0:                 episode reward: 0.2392,                 loss: nan
agent1:                 episode reward: -0.2392,                 loss: 0.1971
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6048s / 110.0603 s
agent0:                 episode reward: 1.5537,                 loss: nan
agent1:                 episode reward: -1.5537,                 loss: 0.1968
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5718s / 110.6321 s
agent0:                 episode reward: 1.0740,                 loss: nan
agent1:                 episode reward: -1.0740,                 loss: 0.1945
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5863s / 111.2184 s
agent0:                 episode reward: 0.5680,                 loss: nan
agent1:                 episode reward: -0.5680,                 loss: 0.1951
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5734s / 111.7918 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: 0.2111
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5820s / 112.3738 s
agent0:                 episode reward: 0.2452,                 loss: nan
agent1:                 episode reward: -0.2452,                 loss: 0.2126
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6154s / 112.9892 s
agent0:                 episode reward: 0.4156,                 loss: nan
agent1:                 episode reward: -0.4156,                 loss: 0.2093
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5968s / 113.5860 s
agent0:                 episode reward: 0.0101,                 loss: nan
agent1:                 episode reward: -0.0101,                 loss: 0.2122
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6120s / 114.1980 s
agent0:                 episode reward: 0.5692,                 loss: nan
agent1:                 episode reward: -0.5692,                 loss: 0.2110
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6320s / 114.8300 s
agent0:                 episode reward: 1.3254,                 loss: nan
agent1:                 episode reward: -1.3254,                 loss: 0.2097
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5815s / 115.4115 s
agent0:                 episode reward: -0.2488,                 loss: nan
agent1:                 episode reward: 0.2488,                 loss: 0.2136
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5818s / 115.9934 s
agent0:                 episode reward: 0.3446,                 loss: nan
agent1:                 episode reward: -0.3446,                 loss: 0.2108
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6011s / 116.5944 s
agent0:                 episode reward: 0.1002,                 loss: nan
agent1:                 episode reward: -0.1002,                 loss: 0.2075
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5787s / 117.1731 s
agent0:                 episode reward: 0.5820,                 loss: nan
agent1:                 episode reward: -0.5820,                 loss: 0.2110
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 117.7563 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.2340
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5912s / 118.3475 s
agent0:                 episode reward: 1.0105,                 loss: nan
agent1:                 episode reward: -1.0105,                 loss: 0.2420
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5783s / 118.9258 s
agent0:                 episode reward: 0.0998,                 loss: nan
agent1:                 episode reward: -0.0998,                 loss: 0.2392
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5877s / 119.5135 s
agent0:                 episode reward: -0.2804,                 loss: nan
agent1:                 episode reward: 0.2804,                 loss: 0.2380
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5924s / 120.1059 s
agent0:                 episode reward: 0.7381,                 loss: nan
agent1:                 episode reward: -0.7381,                 loss: 0.2387
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5807s / 120.6867 s
agent0:                 episode reward: 0.9937,                 loss: nan
agent1:                 episode reward: -0.9937,                 loss: 0.2406
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5890s / 121.2756 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.2368
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5902s / 121.8659 s
agent0:                 episode reward: 1.1142,                 loss: nan
agent1:                 episode reward: -1.1142,                 loss: 0.2369
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5817s / 122.4476 s
agent0:                 episode reward: 0.3113,                 loss: nan
agent1:                 episode reward: -0.3113,                 loss: 0.2374
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6010s / 123.0486 s
agent0:                 episode reward: 0.8817,                 loss: nan
agent1:                 episode reward: -0.8817,                 loss: 0.2368
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6006s / 123.6492 s
agent0:                 episode reward: 0.6682,                 loss: nan
agent1:                 episode reward: -0.6682,                 loss: 0.2657
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6350s / 124.2842 s
agent0:                 episode reward: -0.4437,                 loss: nan
agent1:                 episode reward: 0.4437,                 loss: 0.2723
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6220s / 124.9062 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.2679
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5963s / 125.5026 s
agent0:                 episode reward: 0.9836,                 loss: nan
agent1:                 episode reward: -0.9836,                 loss: 0.2671
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6071s / 126.1097 s
agent0:                 episode reward: 0.8514,                 loss: nan
agent1:                 episode reward: -0.8514,                 loss: 0.2663
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5919s / 126.7016 s
agent0:                 episode reward: 1.2403,                 loss: nan
agent1:                 episode reward: -1.2403,                 loss: 0.2676
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5900s / 127.2916 s
agent0:                 episode reward: 0.4696,                 loss: nan
agent1:                 episode reward: -0.4696,                 loss: 0.2689
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5886s / 127.8802 s
agent0:                 episode reward: 0.6878,                 loss: nan
agent1:                 episode reward: -0.6878,                 loss: 0.2660
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5862s / 128.4663 s
agent0:                 episode reward: 1.6246,                 loss: nan
agent1:                 episode reward: -1.6246,                 loss: 0.2659
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6220s / 129.0884 s
agent0:                 episode reward: 0.3273,                 loss: nan
agent1:                 episode reward: -0.3273,                 loss: 0.2677
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5912s / 129.6796 s
agent0:                 episode reward: 0.8516,                 loss: nan
agent1:                 episode reward: -0.8516,                 loss: 0.2979
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5923s / 130.2719 s
agent0:                 episode reward: 0.6723,                 loss: nan
agent1:                 episode reward: -0.6723,                 loss: 0.3049
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5955s / 130.8673 s
agent0:                 episode reward: 0.3891,                 loss: nan
agent1:                 episode reward: -0.3891,                 loss: 0.3023
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5937s / 131.4611 s
agent0:                 episode reward: 0.3601,                 loss: nan
agent1:                 episode reward: -0.3601,                 loss: 0.3011
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5965s / 132.0576 s
agent0:                 episode reward: 0.3884,                 loss: nan
agent1:                 episode reward: -0.3884,                 loss: 0.3015
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5956s / 132.6532 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.2965
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6299s / 133.2830 s
agent0:                 episode reward: 0.1371,                 loss: nan
agent1:                 episode reward: -0.1371,                 loss: 0.2978
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5922s / 133.8752 s
agent0:                 episode reward: 1.1790,                 loss: nan
agent1:                 episode reward: -1.1790,                 loss: 0.2985
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6615s / 134.5367 s
agent0:                 episode reward: 0.6706,                 loss: nan
agent1:                 episode reward: -0.6706,                 loss: 0.2987
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6084s / 135.1451 s
agent0:                 episode reward: 1.4648,                 loss: nan
agent1:                 episode reward: -1.4648,                 loss: 0.2965
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6016s / 135.7467 s
agent0:                 episode reward: 0.5035,                 loss: nan
agent1:                 episode reward: -0.5035,                 loss: 0.3149
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6008s / 136.3475 s
agent0:                 episode reward: 1.2385,                 loss: nan
agent1:                 episode reward: -1.2385,                 loss: 0.3101
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6062s / 136.9537 s
agent0:                 episode reward: 0.3541,                 loss: nan
agent1:                 episode reward: -0.3541,                 loss: 0.3081
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6028s / 137.5564 s
agent0:                 episode reward: -0.4595,                 loss: nan
agent1:                 episode reward: 0.4595,                 loss: 0.3064
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6067s / 138.1631 s
agent0:                 episode reward: 0.6730,                 loss: nan
agent1:                 episode reward: -0.6730,                 loss: 0.3062
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6027s / 138.7659 s
agent0:                 episode reward: -0.0137,                 loss: nan
agent1:                 episode reward: 0.0137,                 loss: 0.3086
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5970s / 139.3629 s
agent0:                 episode reward: 0.3294,                 loss: nan
agent1:                 episode reward: -0.3294,                 loss: 0.3055
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6065s / 139.9694 s
agent0:                 episode reward: 1.2106,                 loss: nan
agent1:                 episode reward: -1.2106,                 loss: 0.3038
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6144s / 140.5838 s
agent0:                 episode reward: 1.5601,                 loss: nan
agent1:                 episode reward: -1.5601,                 loss: 0.3052
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6012s / 141.1850 s
agent0:                 episode reward: 0.4701,                 loss: nan
agent1:                 episode reward: -0.4701,                 loss: 0.3035
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6212s / 141.8062 s
agent0:                 episode reward: 0.5387,                 loss: nan
agent1:                 episode reward: -0.5387,                 loss: 0.3127
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5997s / 142.4059 s
agent0:                 episode reward: -0.4086,                 loss: nan
agent1:                 episode reward: 0.4086,                 loss: 0.3082
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6212s / 143.0271 s
agent0:                 episode reward: 2.4240,                 loss: nan
agent1:                 episode reward: -2.4240,                 loss: 0.3065
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6009s / 143.6280 s
agent0:                 episode reward: 0.5230,                 loss: nan
agent1:                 episode reward: -0.5230,                 loss: 0.3030
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6029s / 144.2309 s
agent0:                 episode reward: 1.2849,                 loss: nan
agent1:                 episode reward: -1.2849,                 loss: 0.3038
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6461s / 144.8769 s
agent0:                 episode reward: -0.0287,                 loss: nan
agent1:                 episode reward: 0.0287,                 loss: 0.3024
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6006s / 145.4775 s
agent0:                 episode reward: 0.7699,                 loss: nan
agent1:                 episode reward: -0.7699,                 loss: 0.3022
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5998s / 146.0773 s
agent0:                 episode reward: 0.2816,                 loss: nan
agent1:                 episode reward: -0.2816,                 loss: 0.3018
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6053s / 146.6825 s
agent0:                 episode reward: 0.7095,                 loss: nan
agent1:                 episode reward: -0.7095,                 loss: 0.3028
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6215s / 147.3040 s
agent0:                 episode reward: 0.8653,                 loss: nan
agent1:                 episode reward: -0.8653,                 loss: 0.3007
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6160s / 147.9200 s
agent0:                 episode reward: 1.2528,                 loss: nan
agent1:                 episode reward: -1.2528,                 loss: 0.3213
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6137s / 148.5337 s
agent0:                 episode reward: 0.4156,                 loss: nan
agent1:                 episode reward: -0.4156,                 loss: 0.3196
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6001s / 149.1338 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.3166
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6516s / 149.7854 s
agent0:                 episode reward: 0.7007,                 loss: nan
agent1:                 episode reward: -0.7007,                 loss: 0.3165
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6095s / 150.3949 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.3145
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6119s / 151.0067 s
agent0:                 episode reward: 0.3123,                 loss: nan
agent1:                 episode reward: -0.3123,                 loss: 0.3127
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6086s / 151.6154 s
agent0:                 episode reward: 0.4619,                 loss: nan
agent1:                 episode reward: -0.4619,                 loss: 0.3155
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6105s / 152.2259 s
agent0:                 episode reward: 0.4907,                 loss: nan
agent1:                 episode reward: -0.4907,                 loss: 0.3160
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6183s / 152.8442 s
agent0:                 episode reward: 0.3986,                 loss: nan
agent1:                 episode reward: -0.3986,                 loss: 0.3126
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6184s / 153.4627 s
agent0:                 episode reward: -0.3230,                 loss: nan
agent1:                 episode reward: 0.3230,                 loss: 0.3127
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6043s / 154.0670 s
agent0:                 episode reward: 0.5496,                 loss: nan
agent1:                 episode reward: -0.5496,                 loss: 0.3289
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6521s / 154.7190 s
agent0:                 episode reward: 0.6053,                 loss: nan
agent1:                 episode reward: -0.6053,                 loss: 0.3223
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6456s / 155.3647 s
agent0:                 episode reward: -0.4356,                 loss: nan
agent1:                 episode reward: 0.4356,                 loss: 0.3210
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6152s / 155.9798 s
agent0:                 episode reward: -1.0407,                 loss: nan
agent1:                 episode reward: 1.0407,                 loss: 0.3218
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6235s / 156.6033 s
agent0:                 episode reward: -0.1360,                 loss: nan
agent1:                 episode reward: 0.1360,                 loss: 0.3173
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6217s / 157.2250 s
agent0:                 episode reward: 1.0535,                 loss: nan
agent1:                 episode reward: -1.0535,                 loss: 0.3175
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6299s / 157.8549 s
agent0:                 episode reward: 0.2825,                 loss: nan
agent1:                 episode reward: -0.2825,                 loss: 0.3178
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6194s / 158.4743 s
agent0:                 episode reward: 0.6856,                 loss: nan
agent1:                 episode reward: -0.6856,                 loss: 0.3165
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6227s / 159.0970 s
agent0:                 episode reward: 0.7835,                 loss: nan
agent1:                 episode reward: -0.7835,                 loss: 0.3151
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6194s / 159.7164 s
agent0:                 episode reward: -0.3279,                 loss: nan
agent1:                 episode reward: 0.3279,                 loss: 0.3153
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6207s / 160.3371 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.2940
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6476s / 160.9846 s
agent0:                 episode reward: 0.1739,                 loss: nan
agent1:                 episode reward: -0.1739,                 loss: 0.2663
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6226s / 161.6073 s
agent0:                 episode reward: 0.4841,                 loss: nan
agent1:                 episode reward: -0.4841,                 loss: 0.2635
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6249s / 162.2322 s
agent0:                 episode reward: 0.1214,                 loss: nan
agent1:                 episode reward: -0.1214,                 loss: 0.2649
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6269s / 162.8591 s
agent0:                 episode reward: 0.2823,                 loss: nan
agent1:                 episode reward: -0.2823,                 loss: 0.2637
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6300s / 163.4891 s
agent0:                 episode reward: 0.4317,                 loss: nan
agent1:                 episode reward: -0.4317,                 loss: 0.2586
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6180s / 164.1070 s
agent0:                 episode reward: 1.2385,                 loss: nan
agent1:                 episode reward: -1.2385,                 loss: 0.2589
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6291s / 164.7361 s
agent0:                 episode reward: 0.4628,                 loss: nan
agent1:                 episode reward: -0.4628,                 loss: 0.2571
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6732s / 165.4093 s
agent0:                 episode reward: -0.2726,                 loss: nan
agent1:                 episode reward: 0.2726,                 loss: 0.2573
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6417s / 166.0511 s
agent0:                 episode reward: 1.5508,                 loss: nan
agent1:                 episode reward: -1.5508,                 loss: 0.2574
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6369s / 166.6880 s
agent0:                 episode reward: 1.1517,                 loss: nan
agent1:                 episode reward: -1.1517,                 loss: 0.2260
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6321s / 167.3200 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1965
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6351s / 167.9551 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.1919
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 168.5827 s
agent0:                 episode reward: 0.9223,                 loss: nan
agent1:                 episode reward: -0.9223,                 loss: 0.1913
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6266s / 169.2093 s
agent0:                 episode reward: -0.1441,                 loss: nan
agent1:                 episode reward: 0.1441,                 loss: 0.1925
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6264s / 169.8357 s
agent0:                 episode reward: 0.8943,                 loss: nan
agent1:                 episode reward: -0.8943,                 loss: 0.1899
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6298s / 170.4655 s
agent0:                 episode reward: 0.9357,                 loss: nan
agent1:                 episode reward: -0.9357,                 loss: 0.1914
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6379s / 171.1034 s
agent0:                 episode reward: 0.3918,                 loss: nan
agent1:                 episode reward: -0.3918,                 loss: 0.1887
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6409s / 171.7443 s
agent0:                 episode reward: 0.3580,                 loss: nan
agent1:                 episode reward: -0.3580,                 loss: 0.1868
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6375s / 172.3818 s
agent0:                 episode reward: 0.2276,                 loss: nan
agent1:                 episode reward: -0.2276,                 loss: 0.1887
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6245s / 173.0063 s
agent0:                 episode reward: 0.7220,                 loss: nan
agent1:                 episode reward: -0.7220,                 loss: 0.1847
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6362s / 173.6425 s
agent0:                 episode reward: 0.3922,                 loss: nan
agent1:                 episode reward: -0.3922,                 loss: 0.1693
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6587s / 174.3012 s
agent0:                 episode reward: 1.0001,                 loss: nan
agent1:                 episode reward: -1.0001,                 loss: 0.1710
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6470s / 174.9482 s
agent0:                 episode reward: 0.3812,                 loss: nan
agent1:                 episode reward: -0.3812,                 loss: 0.1692
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6694s / 175.6176 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.1696
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6302s / 176.2478 s
agent0:                 episode reward: 0.2976,                 loss: nan
agent1:                 episode reward: -0.2976,                 loss: 0.1692
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6338s / 176.8816 s
agent0:                 episode reward: -1.5807,                 loss: nan
agent1:                 episode reward: 1.5807,                 loss: 0.1692
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6344s / 177.5160 s
agent0:                 episode reward: 0.9516,                 loss: nan
agent1:                 episode reward: -0.9516,                 loss: 0.1689
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6342s / 178.1503 s
agent0:                 episode reward: 1.4134,                 loss: nan
agent1:                 episode reward: -1.4134,                 loss: 0.1698
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6390s / 178.7892 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.1702
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6287s / 179.4179 s
agent0:                 episode reward: -0.0072,                 loss: nan
agent1:                 episode reward: 0.0072,                 loss: 0.1925
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6571s / 180.0750 s
agent0:                 episode reward: 0.7056,                 loss: nan
agent1:                 episode reward: -0.7056,                 loss: 0.2012
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6335s / 180.7085 s
agent0:                 episode reward: 0.8378,                 loss: nan
agent1:                 episode reward: -0.8378,                 loss: 0.1989
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6371s / 181.3456 s
agent0:                 episode reward: 0.9050,                 loss: nan
agent1:                 episode reward: -0.9050,                 loss: 0.1962
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6421s / 181.9878 s
agent0:                 episode reward: 0.3596,                 loss: nan
agent1:                 episode reward: -0.3596,                 loss: 0.1981
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6309s / 182.6186 s
agent0:                 episode reward: -0.0841,                 loss: nan
agent1:                 episode reward: 0.0841,                 loss: 0.1993
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6533s / 183.2719 s
agent0:                 episode reward: 1.3554,                 loss: nan
agent1:                 episode reward: -1.3554,                 loss: 0.1961
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6442s / 183.9160 s
agent0:                 episode reward: 1.0307,                 loss: nan
agent1:                 episode reward: -1.0307,                 loss: 0.1991
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6669s / 184.5829 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: 0.1972
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6770s / 185.2599 s
agent0:                 episode reward: 0.0477,                 loss: nan
agent1:                 episode reward: -0.0477,                 loss: 0.1965
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6819s / 185.9418 s
agent0:                 episode reward: 0.0934,                 loss: nan
agent1:                 episode reward: -0.0934,                 loss: 0.2293
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6419s / 186.5836 s
agent0:                 episode reward: -0.4097,                 loss: nan
agent1:                 episode reward: 0.4097,                 loss: 0.2418
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6314s / 187.2150 s
agent0:                 episode reward: 0.7299,                 loss: nan
agent1:                 episode reward: -0.7299,                 loss: 0.2399
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6418s / 187.8569 s
agent0:                 episode reward: 0.2203,                 loss: nan
agent1:                 episode reward: -0.2203,                 loss: 0.2377
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6518s / 188.5087 s
agent0:                 episode reward: 0.5400,                 loss: nan
agent1:                 episode reward: -0.5400,                 loss: 0.2373
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6463s / 189.1550 s
agent0:                 episode reward: -0.1649,                 loss: nan
agent1:                 episode reward: 0.1649,                 loss: 0.2371
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6498s / 189.8049 s
agent0:                 episode reward: 0.3001,                 loss: nan
agent1:                 episode reward: -0.3001,                 loss: 0.2371
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6413s / 190.4461 s
agent0:                 episode reward: 0.3021,                 loss: nan
agent1:                 episode reward: -0.3021,                 loss: 0.2384
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6537s / 191.0998 s
agent0:                 episode reward: 1.1145,                 loss: nan
agent1:                 episode reward: -1.1145,                 loss: 0.2409
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6481s / 191.7479 s
agent0:                 episode reward: 0.6499,                 loss: nan
agent1:                 episode reward: -0.6499,                 loss: 0.2360
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6539s / 192.4018 s
agent0:                 episode reward: -0.2519,                 loss: nan
agent1:                 episode reward: 0.2519,                 loss: 0.2718
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6527s / 193.0545 s
agent0:                 episode reward: 0.0615,                 loss: nan
agent1:                 episode reward: -0.0615,                 loss: 0.2803
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6529s / 193.7075 s
agent0:                 episode reward: -0.0532,                 loss: nan
agent1:                 episode reward: 0.0532,                 loss: 0.2788
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6623s / 194.3698 s
agent0:                 episode reward: 0.9784,                 loss: nan
agent1:                 episode reward: -0.9784,                 loss: 0.2830
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6518s / 195.0215 s
agent0:                 episode reward: 0.9579,                 loss: nan
agent1:                 episode reward: -0.9579,                 loss: 0.2809
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7068s / 195.7283 s
agent0:                 episode reward: -0.2548,                 loss: nan
agent1:                 episode reward: 0.2548,                 loss: 0.2772
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6535s / 196.3819 s
agent0:                 episode reward: 0.0317,                 loss: nan
agent1:                 episode reward: -0.0317,                 loss: 0.2760
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6525s / 197.0344 s
agent0:                 episode reward: 0.9879,                 loss: nan
agent1:                 episode reward: -0.9879,                 loss: 0.2744
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6496s / 197.6840 s
agent0:                 episode reward: 0.1501,                 loss: nan
agent1:                 episode reward: -0.1501,                 loss: 0.2760
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6709s / 198.3548 s
agent0:                 episode reward: -0.8950,                 loss: nan
agent1:                 episode reward: 0.8950,                 loss: 0.2782
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6453s / 199.0002 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.3036
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6705s / 199.6706 s
agent0:                 episode reward: 0.9343,                 loss: nan
agent1:                 episode reward: -0.9343,                 loss: 0.3110
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6533s / 200.3239 s
agent0:                 episode reward: 0.5667,                 loss: nan
agent1:                 episode reward: -0.5667,                 loss: 0.3105
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6482s / 200.9721 s
agent0:                 episode reward: 0.3096,                 loss: nan
agent1:                 episode reward: -0.3096,                 loss: 0.3094
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6614s / 201.6335 s
agent0:                 episode reward: 0.0505,                 loss: nan
agent1:                 episode reward: -0.0505,                 loss: 0.3108
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6485s / 202.2820 s
agent0:                 episode reward: 0.6705,                 loss: nan
agent1:                 episode reward: -0.6705,                 loss: 0.3104
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6482s / 202.9302 s
agent0:                 episode reward: 0.3380,                 loss: nan
agent1:                 episode reward: -0.3380,                 loss: 0.3080
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6516s / 203.5818 s
agent0:                 episode reward: -0.2842,                 loss: nan
agent1:                 episode reward: 0.2842,                 loss: 0.3104
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6692s / 204.2511 s
agent0:                 episode reward: -0.0544,                 loss: nan
agent1:                 episode reward: 0.0544,                 loss: 0.3065
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6496s / 204.9006 s
agent0:                 episode reward: 0.8705,                 loss: nan
agent1:                 episode reward: -0.8705,                 loss: 0.3088
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6622s / 205.5628 s
agent0:                 episode reward: 0.1508,                 loss: nan
agent1:                 episode reward: -0.1508,                 loss: 0.3232
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6969s / 206.2597 s
agent0:                 episode reward: 0.3608,                 loss: nan
agent1:                 episode reward: -0.3608,                 loss: 0.3196
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6604s / 206.9202 s
agent0:                 episode reward: 0.5128,                 loss: nan
agent1:                 episode reward: -0.5128,                 loss: 0.3189
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6897s / 207.6099 s
agent0:                 episode reward: 1.2468,                 loss: nan
agent1:                 episode reward: -1.2468,                 loss: 0.3187
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6722s / 208.2821 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.3166
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6552s / 208.9373 s
agent0:                 episode reward: 0.0652,                 loss: nan
agent1:                 episode reward: -0.0652,                 loss: 0.3165
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6663s / 209.6036 s
agent0:                 episode reward: 0.4920,                 loss: nan
agent1:                 episode reward: -0.4920,                 loss: 0.3151
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6797s / 210.2833 s
agent0:                 episode reward: 0.1567,                 loss: nan
agent1:                 episode reward: -0.1567,                 loss: 0.3151
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6655s / 210.9488 s
agent0:                 episode reward: 0.8425,                 loss: nan
agent1:                 episode reward: -0.8425,                 loss: 0.3133
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6639s / 211.6126 s
agent0:                 episode reward: 1.8834,                 loss: nan
agent1:                 episode reward: -1.8834,                 loss: 0.3135
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6977s / 212.3104 s
agent0:                 episode reward: 0.3279,                 loss: nan
agent1:                 episode reward: -0.3279,                 loss: 0.3276
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6628s / 212.9732 s
agent0:                 episode reward: -0.1787,                 loss: nan
agent1:                 episode reward: 0.1787,                 loss: 0.3219
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6716s / 213.6448 s
agent0:                 episode reward: 0.3343,                 loss: nan
agent1:                 episode reward: -0.3343,                 loss: 0.3174
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6654s / 214.3102 s
agent0:                 episode reward: -0.0243,                 loss: nan
agent1:                 episode reward: 0.0243,                 loss: 0.3168
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6902s / 215.0004 s
agent0:                 episode reward: 0.0430,                 loss: nan
agent1:                 episode reward: -0.0430,                 loss: 0.3190
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7072s / 215.7076 s
agent0:                 episode reward: 0.4708,                 loss: nan
agent1:                 episode reward: -0.4708,                 loss: 0.3166
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7360s / 216.4436 s
agent0:                 episode reward: 0.9764,                 loss: nan
agent1:                 episode reward: -0.9764,                 loss: 0.3155
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6591s / 217.1028 s
agent0:                 episode reward: 0.3316,                 loss: nan
agent1:                 episode reward: -0.3316,                 loss: 0.3159
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6689s / 217.7716 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.3150
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6688s / 218.4405 s
agent0:                 episode reward: 0.8115,                 loss: nan
agent1:                 episode reward: -0.8115,                 loss: 0.3148
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6697s / 219.1102 s
agent0:                 episode reward: 1.1260,                 loss: nan
agent1:                 episode reward: -1.1260,                 loss: 0.3218
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6683s / 219.7785 s
agent0:                 episode reward: 0.3417,                 loss: nan
agent1:                 episode reward: -0.3417,                 loss: 0.3127
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6701s / 220.4487 s
agent0:                 episode reward: 1.0864,                 loss: nan
agent1:                 episode reward: -1.0864,                 loss: 0.3087
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6732s / 221.1218 s
agent0:                 episode reward: 0.1261,                 loss: nan
agent1:                 episode reward: -0.1261,                 loss: 0.3098
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6692s / 221.7910 s
agent0:                 episode reward: -0.0568,                 loss: nan
agent1:                 episode reward: 0.0568,                 loss: 0.3080
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6891s / 222.4801 s
agent0:                 episode reward: 0.6527,                 loss: nan
agent1:                 episode reward: -0.6527,                 loss: 0.3069
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6662s / 223.1464 s
agent0:                 episode reward: -0.5194,                 loss: nan
agent1:                 episode reward: 0.5194,                 loss: 0.3068
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6720s / 223.8183 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3062
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6960s / 224.5144 s
agent0:                 episode reward: 0.4440,                 loss: nan
agent1:                 episode reward: -0.4440,                 loss: 0.3059
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6801s / 225.1945 s
agent0:                 episode reward: -0.3321,                 loss: nan
agent1:                 episode reward: 0.3321,                 loss: 0.3066
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6729s / 225.8674 s
agent0:                 episode reward: -0.0099,                 loss: nan
agent1:                 episode reward: 0.0099,                 loss: 0.3095
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7332s / 226.6005 s
agent0:                 episode reward: -1.0581,                 loss: nan
agent1:                 episode reward: 1.0581,                 loss: 0.2903
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6745s / 227.2751 s
agent0:                 episode reward: 1.6487,                 loss: nan
agent1:                 episode reward: -1.6487,                 loss: 0.2857
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6731s / 227.9482 s
agent0:                 episode reward: 0.3809,                 loss: nan
agent1:                 episode reward: -0.3809,                 loss: 0.2832
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6860s / 228.6342 s
agent0:                 episode reward: 0.5368,                 loss: nan
agent1:                 episode reward: -0.5368,                 loss: 0.2805
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6691s / 229.3033 s
agent0:                 episode reward: 0.3672,                 loss: nan
agent1:                 episode reward: -0.3672,                 loss: 0.2804
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6797s / 229.9830 s
agent0:                 episode reward: -0.1094,                 loss: nan
agent1:                 episode reward: 0.1094,                 loss: 0.2795
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6704s / 230.6534 s
agent0:                 episode reward: -0.2210,                 loss: nan
agent1:                 episode reward: 0.2210,                 loss: 0.2785
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6751s / 231.3285 s
agent0:                 episode reward: -0.0681,                 loss: nan
agent1:                 episode reward: 0.0681,                 loss: 0.2772
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6715s / 232.0000 s
agent0:                 episode reward: 0.2543,                 loss: nan
agent1:                 episode reward: -0.2543,                 loss: 0.2777
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6978s / 232.6978 s
agent0:                 episode reward: 0.0707,                 loss: nan
agent1:                 episode reward: -0.0707,                 loss: 0.2483
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6785s / 233.3762 s
agent0:                 episode reward: -0.1194,                 loss: nan
agent1:                 episode reward: 0.1194,                 loss: 0.2137
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6678s / 234.0440 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.2106
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6886s / 234.7326 s
agent0:                 episode reward: -0.2277,                 loss: nan
agent1:                 episode reward: 0.2277,                 loss: 0.2094
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6982s / 235.4308 s
agent0:                 episode reward: -0.1976,                 loss: nan
agent1:                 episode reward: 0.1976,                 loss: 0.2107
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6807s / 236.1115 s
agent0:                 episode reward: 0.0050,                 loss: nan
agent1:                 episode reward: -0.0050,                 loss: 0.2070
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7259s / 236.8374 s
agent0:                 episode reward: 0.8846,                 loss: nan
agent1:                 episode reward: -0.8846,                 loss: 0.2041
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6944s / 237.5318 s
agent0:                 episode reward: 1.2698,                 loss: nan
agent1:                 episode reward: -1.2698,                 loss: 0.2049
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6848s / 238.2166 s
agent0:                 episode reward: 0.6384,                 loss: nan
agent1:                 episode reward: -0.6384,                 loss: 0.2059
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6780s / 238.8945 s
agent0:                 episode reward: 0.3642,                 loss: nan
agent1:                 episode reward: -0.3642,                 loss: 0.2040
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 239.5795 s
agent0:                 episode reward: 1.1547,                 loss: nan
agent1:                 episode reward: -1.1547,                 loss: 0.1876
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6895s / 240.2689 s
agent0:                 episode reward: 0.3556,                 loss: nan
agent1:                 episode reward: -0.3556,                 loss: 0.1674
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6995s / 240.9684 s
agent0:                 episode reward: 0.8793,                 loss: nan
agent1:                 episode reward: -0.8793,                 loss: 0.1689
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6859s / 241.6543 s
agent0:                 episode reward: 0.3773,                 loss: nan
agent1:                 episode reward: -0.3773,                 loss: 0.1644
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6874s / 242.3418 s
agent0:                 episode reward: 0.0436,                 loss: nan
agent1:                 episode reward: -0.0436,                 loss: 0.1651
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6818s / 243.0236 s
agent0:                 episode reward: -0.1212,                 loss: nan
agent1:                 episode reward: 0.1212,                 loss: 0.1625
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6916s / 243.7151 s
agent0:                 episode reward: -0.2430,                 loss: nan
agent1:                 episode reward: 0.2430,                 loss: 0.1619
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6936s / 244.4088 s
agent0:                 episode reward: 0.0203,                 loss: nan
agent1:                 episode reward: -0.0203,                 loss: 0.1613
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6863s / 245.0951 s
agent0:                 episode reward: 0.6839,                 loss: nan
agent1:                 episode reward: -0.6839,                 loss: 0.1595
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6842s / 245.7793 s
agent0:                 episode reward: 0.1219,                 loss: nan
agent1:                 episode reward: -0.1219,                 loss: 0.1605
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6892s / 246.4685 s
agent0:                 episode reward: 0.0511,                 loss: nan
agent1:                 episode reward: -0.0511,                 loss: 0.1681
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7269s / 247.1954 s
agent0:                 episode reward: 2.6302,                 loss: nan
agent1:                 episode reward: -2.6302,                 loss: 0.1635
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6890s / 247.8844 s
agent0:                 episode reward: 1.7195,                 loss: nan
agent1:                 episode reward: -1.7195,                 loss: 0.1636
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6779s / 248.5623 s
agent0:                 episode reward: 1.1555,                 loss: nan
agent1:                 episode reward: -1.1555,                 loss: 0.1624
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7266s / 249.2889 s
agent0:                 episode reward: 0.2388,                 loss: nan
agent1:                 episode reward: -0.2388,                 loss: 0.1640
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7016s / 249.9905 s
agent0:                 episode reward: 0.9865,                 loss: nan
agent1:                 episode reward: -0.9865,                 loss: 0.1650
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7240s / 250.7145 s
agent0:                 episode reward: 0.4533,                 loss: nan
agent1:                 episode reward: -0.4533,                 loss: 0.1637
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6875s / 251.4020 s
agent0:                 episode reward: 0.0999,                 loss: nan
agent1:                 episode reward: -0.0999,                 loss: 0.1628
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6859s / 252.0879 s
agent0:                 episode reward: 0.2792,                 loss: nan
agent1:                 episode reward: -0.2792,                 loss: 0.1619
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6966s / 252.7845 s
agent0:                 episode reward: 0.8007,                 loss: nan
agent1:                 episode reward: -0.8007,                 loss: 0.1617
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6913s / 253.4758 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.1909
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6893s / 254.1651 s
agent0:                 episode reward: 0.7422,                 loss: nan
agent1:                 episode reward: -0.7422,                 loss: 0.2010
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7416s / 254.9067 s
agent0:                 episode reward: 0.0498,                 loss: nan
agent1:                 episode reward: -0.0498,                 loss: 0.1993
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6944s / 255.6010 s
agent0:                 episode reward: 0.2396,                 loss: nan
agent1:                 episode reward: -0.2396,                 loss: 0.1959
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6896s / 256.2906 s
agent0:                 episode reward: -0.0606,                 loss: nan
agent1:                 episode reward: 0.0606,                 loss: 0.1991
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7014s / 256.9920 s
agent0:                 episode reward: 0.0562,                 loss: nan
agent1:                 episode reward: -0.0562,                 loss: 0.1979
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7326s / 257.7247 s
agent0:                 episode reward: -0.0519,                 loss: nan
agent1:                 episode reward: 0.0519,                 loss: 0.1981
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6998s / 258.4245 s
agent0:                 episode reward: 0.0395,                 loss: nan
agent1:                 episode reward: -0.0395,                 loss: 0.1979
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6967s / 259.1212 s
agent0:                 episode reward: 0.6019,                 loss: nan
agent1:                 episode reward: -0.6019,                 loss: 0.1967
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6901s / 259.8113 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.1976
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6996s / 260.5109 s
agent0:                 episode reward: 0.3531,                 loss: nan
agent1:                 episode reward: -0.3531,                 loss: 0.2299
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7010s / 261.2119 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.2437
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6982s / 261.9102 s
agent0:                 episode reward: 0.1212,                 loss: nan
agent1:                 episode reward: -0.1212,                 loss: 0.2409
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6908s / 262.6010 s
agent0:                 episode reward: 0.1003,                 loss: nan
agent1:                 episode reward: -0.1003,                 loss: 0.2401
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6928s / 263.2937 s
agent0:                 episode reward: 0.0249,                 loss: nan
agent1:                 episode reward: -0.0249,                 loss: 0.2410
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7003s / 263.9940 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: 0.2411
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7171s / 264.7111 s
agent0:                 episode reward: 0.5985,                 loss: nan
agent1:                 episode reward: -0.5985,                 loss: 0.2395
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7069s / 265.4180 s
agent0:                 episode reward: 0.6232,                 loss: nan
agent1:                 episode reward: -0.6232,                 loss: 0.2396
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7026s / 266.1206 s
agent0:                 episode reward: 0.7719,                 loss: nan
agent1:                 episode reward: -0.7719,                 loss: 0.2382
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6982s / 266.8188 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.2400
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7419s / 267.5607 s
agent0:                 episode reward: 0.8914,                 loss: nan
agent1:                 episode reward: -0.8914,                 loss: 0.2691
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7096s / 268.2703 s
agent0:                 episode reward: 0.4954,                 loss: nan
agent1:                 episode reward: -0.4954,                 loss: 0.2799
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6985s / 268.9688 s
agent0:                 episode reward: 0.4177,                 loss: nan
agent1:                 episode reward: -0.4177,                 loss: 0.2787
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6955s / 269.6643 s
agent0:                 episode reward: 0.1505,                 loss: nan
agent1:                 episode reward: -0.1505,                 loss: 0.2771
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7053s / 270.3697 s
agent0:                 episode reward: 1.0461,                 loss: nan
agent1:                 episode reward: -1.0461,                 loss: 0.2783
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6991s / 271.0687 s
agent0:                 episode reward: 1.2284,                 loss: nan
agent1:                 episode reward: -1.2284,                 loss: 0.2779
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7018s / 271.7706 s
agent0:                 episode reward: 0.8235,                 loss: nan
agent1:                 episode reward: -0.8235,                 loss: 0.2778
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6980s / 272.4685 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.2740
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7006s / 273.1692 s
agent0:                 episode reward: 0.9927,                 loss: nan
agent1:                 episode reward: -0.9927,                 loss: 0.2760
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7186s / 273.8878 s
agent0:                 episode reward: 0.7173,                 loss: nan
agent1:                 episode reward: -0.7173,                 loss: 0.2764
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7204s / 274.6082 s
agent0:                 episode reward: -0.6158,                 loss: nan
agent1:                 episode reward: 0.6158,                 loss: 0.3015
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7085s / 275.3168 s
agent0:                 episode reward: -0.4160,                 loss: nan
agent1:                 episode reward: 0.4160,                 loss: 0.3031
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7134s / 276.0301 s
agent0:                 episode reward: 0.2335,                 loss: nan
agent1:                 episode reward: -0.2335,                 loss: 0.2964
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7189s / 276.7490 s
agent0:                 episode reward: -0.3989,                 loss: nan
agent1:                 episode reward: 0.3989,                 loss: 0.2932
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7399s / 277.4889 s
agent0:                 episode reward: 0.1734,                 loss: nan
agent1:                 episode reward: -0.1734,                 loss: 0.2922
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7222s / 278.2111 s
agent0:                 episode reward: -0.5686,                 loss: nan
agent1:                 episode reward: 0.5686,                 loss: 0.2887
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7106s / 278.9217 s
agent0:                 episode reward: 0.8520,                 loss: nan
agent1:                 episode reward: -0.8520,                 loss: 0.2912
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7169s / 279.6386 s
agent0:                 episode reward: 0.0714,                 loss: nan
agent1:                 episode reward: -0.0714,                 loss: 0.2888
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7060s / 280.3446 s
agent0:                 episode reward: -0.4328,                 loss: nan
agent1:                 episode reward: 0.4328,                 loss: 0.2902
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7113s / 281.0559 s
agent0:                 episode reward: 0.2777,                 loss: nan
agent1:                 episode reward: -0.2777,                 loss: 0.2911
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7052s / 281.7611 s
agent0:                 episode reward: -0.1652,                 loss: nan
agent1:                 episode reward: 0.1652,                 loss: 0.3088
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7424s / 282.5036 s
agent0:                 episode reward: -0.2942,                 loss: nan
agent1:                 episode reward: 0.2942,                 loss: 0.3093
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7166s / 283.2201 s
agent0:                 episode reward: 0.6231,                 loss: nan
agent1:                 episode reward: -0.6231,                 loss: 0.3076
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7211s / 283.9412 s
agent0:                 episode reward: 0.9953,                 loss: nan
agent1:                 episode reward: -0.9953,                 loss: 0.3066
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7193s / 284.6605 s
agent0:                 episode reward: 0.3748,                 loss: nan
agent1:                 episode reward: -0.3748,                 loss: 0.3033
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7298s / 285.3903 s
agent0:                 episode reward: 1.3056,                 loss: nan
agent1:                 episode reward: -1.3056,                 loss: 0.3034
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7208s / 286.1111 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: 0.3014
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7179s / 286.8290 s
agent0:                 episode reward: 0.4540,                 loss: nan
agent1:                 episode reward: -0.4540,                 loss: 0.3023
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7130s / 287.5420 s
agent0:                 episode reward: 1.3563,                 loss: nan
agent1:                 episode reward: -1.3563,                 loss: 0.3001
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 288.3066 s
agent0:                 episode reward: -0.2794,                 loss: nan
agent1:                 episode reward: 0.2794,                 loss: 0.3018
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7151s / 289.0217 s
agent0:                 episode reward: -0.0344,                 loss: nan
agent1:                 episode reward: 0.0344,                 loss: 0.3059
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7119s / 289.7336 s
agent0:                 episode reward: 0.5028,                 loss: nan
agent1:                 episode reward: -0.5028,                 loss: 0.2959
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7268s / 290.4604 s
agent0:                 episode reward: -0.8336,                 loss: nan
agent1:                 episode reward: 0.8336,                 loss: 0.2936
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7108s / 291.1711 s
agent0:                 episode reward: 0.2310,                 loss: nan
agent1:                 episode reward: -0.2310,                 loss: 0.2930
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7271s / 291.8982 s
agent0:                 episode reward: 0.4484,                 loss: nan
agent1:                 episode reward: -0.4484,                 loss: 0.2939
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7253s / 292.6236 s
agent0:                 episode reward: -0.0141,                 loss: nan
agent1:                 episode reward: 0.0141,                 loss: 0.2934
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7163s / 293.3399 s
agent0:                 episode reward: 0.8397,                 loss: nan
agent1:                 episode reward: -0.8397,                 loss: 0.2938
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7187s / 294.0586 s
agent0:                 episode reward: 0.9692,                 loss: nan
agent1:                 episode reward: -0.9692,                 loss: 0.2895
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7266s / 294.7852 s
agent0:                 episode reward: 0.5891,                 loss: nan
agent1:                 episode reward: -0.5891,                 loss: 0.2915
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7275s / 295.5127 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.2907
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7199s / 296.2326 s
agent0:                 episode reward: 0.3161,                 loss: nan
agent1:                 episode reward: -0.3161,                 loss: 0.3076
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7248s / 296.9574 s
agent0:                 episode reward: 0.8373,                 loss: nan
agent1:                 episode reward: -0.8373,                 loss: 0.2965
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7981s / 297.7554 s
agent0:                 episode reward: -0.0947,                 loss: nan
agent1:                 episode reward: 0.0947,                 loss: 0.2906
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7835s / 298.5389 s
agent0:                 episode reward: 0.6592,                 loss: nan
agent1:                 episode reward: -0.6592,                 loss: 0.2905
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7215s / 299.2604 s
agent0:                 episode reward: 1.2046,                 loss: nan
agent1:                 episode reward: -1.2046,                 loss: 0.2891
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7277s / 299.9881 s
agent0:                 episode reward: -0.5699,                 loss: nan
agent1:                 episode reward: 0.5699,                 loss: 0.2870
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7410s / 300.7291 s
agent0:                 episode reward: 1.0843,                 loss: nan
agent1:                 episode reward: -1.0843,                 loss: 0.2888
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7346s / 301.4637 s
agent0:                 episode reward: 0.4843,                 loss: nan
agent1:                 episode reward: -0.4843,                 loss: 0.2884
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7222s / 302.1859 s
agent0:                 episode reward: 0.4532,                 loss: nan
agent1:                 episode reward: -0.4532,                 loss: 0.2875
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7489s / 302.9348 s
agent0:                 episode reward: -0.8080,                 loss: nan
agent1:                 episode reward: 0.8080,                 loss: 0.2849
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7382s / 303.6730 s
agent0:                 episode reward: 0.4700,                 loss: nan
agent1:                 episode reward: -0.4700,                 loss: 0.2844
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7233s / 304.3962 s
agent0:                 episode reward: -0.3791,                 loss: nan
agent1:                 episode reward: 0.3791,                 loss: 0.2667
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7349s / 305.1311 s
agent0:                 episode reward: 0.8488,                 loss: nan
agent1:                 episode reward: -0.8488,                 loss: 0.2674
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7274s / 305.8585 s
agent0:                 episode reward: 0.2480,                 loss: nan
agent1:                 episode reward: -0.2480,                 loss: 0.2625
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7364s / 306.5949 s
agent0:                 episode reward: 0.3544,                 loss: nan
agent1:                 episode reward: -0.3544,                 loss: 0.2633
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7396s / 307.3345 s
agent0:                 episode reward: 0.3683,                 loss: nan
agent1:                 episode reward: -0.3683,                 loss: 0.2610
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7310s / 308.0655 s
agent0:                 episode reward: 0.0703,                 loss: nan
agent1:                 episode reward: -0.0703,                 loss: 0.2595
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7702s / 308.8356 s
agent0:                 episode reward: 0.7379,                 loss: nan
agent1:                 episode reward: -0.7379,                 loss: 0.2619
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7387s / 309.5743 s
agent0:                 episode reward: 0.3293,                 loss: nan
agent1:                 episode reward: -0.3293,                 loss: 0.2601
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7377s / 310.3121 s
agent0:                 episode reward: 0.1707,                 loss: nan
agent1:                 episode reward: -0.1707,                 loss: 0.2601
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7297s / 311.0418 s
agent0:                 episode reward: -0.3041,                 loss: nan
agent1:                 episode reward: 0.3041,                 loss: 0.2184
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7349s / 311.7767 s
agent0:                 episode reward: 0.6618,                 loss: nan
agent1:                 episode reward: -0.6618,                 loss: 0.1845
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7462s / 312.5229 s
agent0:                 episode reward: -1.0239,                 loss: nan
agent1:                 episode reward: 1.0239,                 loss: 0.1807
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7356s / 313.2584 s
agent0:                 episode reward: -0.5435,                 loss: nan
agent1:                 episode reward: 0.5435,                 loss: 0.1827
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7354s / 313.9938 s
agent0:                 episode reward: 0.4845,                 loss: nan
agent1:                 episode reward: -0.4845,                 loss: 0.1809
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 314.7261 s
agent0:                 episode reward: -0.3600,                 loss: nan
agent1:                 episode reward: 0.3600,                 loss: 0.1805
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7635s / 315.4896 s
agent0:                 episode reward: 1.2745,                 loss: nan
agent1:                 episode reward: -1.2745,                 loss: 0.1807
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 316.2383 s
agent0:                 episode reward: 0.1883,                 loss: nan
agent1:                 episode reward: -0.1883,                 loss: 0.1812
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7384s / 316.9767 s
agent0:                 episode reward: 0.4033,                 loss: nan
agent1:                 episode reward: -0.4033,                 loss: 0.1805
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 317.7090 s
agent0:                 episode reward: 0.0114,                 loss: nan
agent1:                 episode reward: -0.0114,                 loss: 0.1812
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7957s / 318.5046 s
agent0:                 episode reward: -0.0711,                 loss: nan
agent1:                 episode reward: 0.0711,                 loss: 0.1703
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7451s / 319.2497 s
agent0:                 episode reward: 0.1901,                 loss: nan
agent1:                 episode reward: -0.1901,                 loss: 0.1527
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7393s / 319.9890 s
agent0:                 episode reward: 0.3953,                 loss: nan
agent1:                 episode reward: -0.3953,                 loss: 0.1507
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7620s / 320.7511 s
agent0:                 episode reward: 0.6170,                 loss: nan
agent1:                 episode reward: -0.6170,                 loss: 0.1487
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7688s / 321.5199 s
agent0:                 episode reward: 1.3607,                 loss: nan
agent1:                 episode reward: -1.3607,                 loss: 0.1502
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7383s / 322.2582 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.1495
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7419s / 323.0001 s
agent0:                 episode reward: 0.6571,                 loss: nan
agent1:                 episode reward: -0.6571,                 loss: 0.1498
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7595s / 323.7596 s
agent0:                 episode reward: 0.9246,                 loss: nan
agent1:                 episode reward: -0.9246,                 loss: 0.1488
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7436s / 324.5032 s
agent0:                 episode reward: 0.2987,                 loss: nan
agent1:                 episode reward: -0.2987,                 loss: 0.1493
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7453s / 325.2485 s
agent0:                 episode reward: 0.1725,                 loss: nan
agent1:                 episode reward: -0.1725,                 loss: 0.1477
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7464s / 325.9949 s
agent0:                 episode reward: 0.3224,                 loss: nan
agent1:                 episode reward: -0.3224,                 loss: 0.1602
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7394s / 326.7343 s
agent0:                 episode reward: 0.5702,                 loss: nan
agent1:                 episode reward: -0.5702,                 loss: 0.1563
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7395s / 327.4738 s
agent0:                 episode reward: 0.6999,                 loss: nan
agent1:                 episode reward: -0.6999,                 loss: 0.1533
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7600s / 328.2338 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.1533
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7787s / 329.0125 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1530
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7369s / 329.7494 s
agent0:                 episode reward: -0.1609,                 loss: nan
agent1:                 episode reward: 0.1609,                 loss: 0.1549
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7542s / 330.5036 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: 0.1535
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7509s / 331.2545 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.1540
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7654s / 332.0199 s
agent0:                 episode reward: 0.6159,                 loss: nan
agent1:                 episode reward: -0.6159,                 loss: 0.1516
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7470s / 332.7669 s
agent0:                 episode reward: 0.5756,                 loss: nan
agent1:                 episode reward: -0.5756,                 loss: 0.1525
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7635s / 333.5304 s
agent0:                 episode reward: 0.7066,                 loss: nan
agent1:                 episode reward: -0.7066,                 loss: 0.1866
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7542s / 334.2846 s
agent0:                 episode reward: 0.5743,                 loss: nan
agent1:                 episode reward: -0.5743,                 loss: 0.1950
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7843s / 335.0689 s
agent0:                 episode reward: -0.1323,                 loss: nan
agent1:                 episode reward: 0.1323,                 loss: 0.1943
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7547s / 335.8237 s
agent0:                 episode reward: 0.3630,                 loss: nan
agent1:                 episode reward: -0.3630,                 loss: 0.1920
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7621s / 336.5858 s
agent0:                 episode reward: -0.1284,                 loss: nan
agent1:                 episode reward: 0.1284,                 loss: 0.1940
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7524s / 337.3382 s
agent0:                 episode reward: -0.4016,                 loss: nan
agent1:                 episode reward: 0.4016,                 loss: 0.1932
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7462s / 338.0844 s
agent0:                 episode reward: 0.2458,                 loss: nan
agent1:                 episode reward: -0.2458,                 loss: 0.1936
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7593s / 338.8437 s
agent0:                 episode reward: 0.7798,                 loss: nan
agent1:                 episode reward: -0.7798,                 loss: 0.1917
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7993s / 339.6430 s
agent0:                 episode reward: 0.5089,                 loss: nan
agent1:                 episode reward: -0.5089,                 loss: 0.1914
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7756s / 340.4186 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: 0.1921
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7970s / 341.2156 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.2320
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7662s / 341.9818 s
agent0:                 episode reward: -0.3258,                 loss: nan
agent1:                 episode reward: 0.3258,                 loss: 0.2421
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7653s / 342.7471 s
agent0:                 episode reward: 0.2579,                 loss: nan
agent1:                 episode reward: -0.2579,                 loss: 0.2412
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7598s / 343.5068 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.2383
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7517s / 344.2586 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.2398
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7541s / 345.0127 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: 0.2381
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7836s / 345.7963 s
agent0:                 episode reward: 0.8650,                 loss: nan
agent1:                 episode reward: -0.8650,                 loss: 0.2382
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7660s / 346.5623 s
agent0:                 episode reward: 0.4456,                 loss: nan
agent1:                 episode reward: -0.4456,                 loss: 0.2396
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8003s / 347.3627 s
agent0:                 episode reward: 0.0683,                 loss: nan
agent1:                 episode reward: -0.0683,                 loss: 0.2375
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7679s / 348.1306 s
agent0:                 episode reward: 0.6698,                 loss: nan
agent1:                 episode reward: -0.6698,                 loss: 0.2366
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7827s / 348.9133 s
agent0:                 episode reward: -0.2160,                 loss: nan
agent1:                 episode reward: 0.2160,                 loss: 0.2812
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7969s / 349.7102 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.2898
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7737s / 350.4839 s
agent0:                 episode reward: 0.2600,                 loss: nan
agent1:                 episode reward: -0.2600,                 loss: 0.2893
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7702s / 351.2541 s
agent0:                 episode reward: -0.4615,                 loss: nan
agent1:                 episode reward: 0.4615,                 loss: 0.2886
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7703s / 352.0244 s
agent0:                 episode reward: 0.2084,                 loss: nan
agent1:                 episode reward: -0.2084,                 loss: 0.2861
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7723s / 352.7967 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: 0.2861
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7872s / 353.5838 s
agent0:                 episode reward: 0.0390,                 loss: nan
agent1:                 episode reward: -0.0390,                 loss: 0.2872
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7610s / 354.3448 s
agent0:                 episode reward: 0.3799,                 loss: nan
agent1:                 episode reward: -0.3799,                 loss: 0.2869
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7781s / 355.1229 s
agent0:                 episode reward: 1.4628,                 loss: nan
agent1:                 episode reward: -1.4628,                 loss: 0.2858
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7800s / 355.9029 s
agent0:                 episode reward: 1.2741,                 loss: nan
agent1:                 episode reward: -1.2741,                 loss: 0.2854
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7813s / 356.6842 s
agent0:                 episode reward: 0.9025,                 loss: nan
agent1:                 episode reward: -0.9025,                 loss: 0.3182
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7683s / 357.4525 s
agent0:                 episode reward: 0.6835,                 loss: nan
agent1:                 episode reward: -0.6835,                 loss: 0.3238
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7691s / 358.2216 s
agent0:                 episode reward: 0.1966,                 loss: nan
agent1:                 episode reward: -0.1966,                 loss: 0.3218
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7778s / 358.9994 s
agent0:                 episode reward: 0.7759,                 loss: nan
agent1:                 episode reward: -0.7759,                 loss: 0.3198
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8102s / 359.8096 s
agent0:                 episode reward: 0.1232,                 loss: nan
agent1:                 episode reward: -0.1232,                 loss: 0.3178
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 360.5876 s
agent0:                 episode reward: -0.2384,                 loss: nan
agent1:                 episode reward: 0.2384,                 loss: 0.3167
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7730s / 361.3606 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3174
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7684s / 362.1290 s
agent0:                 episode reward: -0.3165,                 loss: nan
agent1:                 episode reward: 0.3165,                 loss: 0.3199
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7713s / 362.9003 s
agent0:                 episode reward: -0.0299,                 loss: nan
agent1:                 episode reward: 0.0299,                 loss: 0.3162
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7845s / 363.6848 s
agent0:                 episode reward: -0.6171,                 loss: nan
agent1:                 episode reward: 0.6171,                 loss: 0.3192
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7694s / 364.4542 s
agent0:                 episode reward: -0.0106,                 loss: nan
agent1:                 episode reward: 0.0106,                 loss: 0.3245
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7897s / 365.2440 s
agent0:                 episode reward: -0.2653,                 loss: nan
agent1:                 episode reward: 0.2653,                 loss: 0.3194
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7871s / 366.0311 s
agent0:                 episode reward: 0.7331,                 loss: nan
agent1:                 episode reward: -0.7331,                 loss: 0.3151
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7855s / 366.8166 s
agent0:                 episode reward: 0.2548,                 loss: nan
agent1:                 episode reward: -0.2548,                 loss: 0.3171
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7892s / 367.6057 s
agent0:                 episode reward: -0.2781,                 loss: nan
agent1:                 episode reward: 0.2781,                 loss: 0.3155
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 368.3838 s
agent0:                 episode reward: 0.6368,                 loss: nan
agent1:                 episode reward: -0.6368,                 loss: 0.3146
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7771s / 369.1609 s
agent0:                 episode reward: 0.2579,                 loss: nan
agent1:                 episode reward: -0.2579,                 loss: 0.3106
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8201s / 369.9810 s
agent0:                 episode reward: 0.4782,                 loss: nan
agent1:                 episode reward: -0.4782,                 loss: 0.3126
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7746s / 370.7556 s
agent0:                 episode reward: -0.7124,                 loss: nan
agent1:                 episode reward: 0.7124,                 loss: 0.3127
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7787s / 371.5343 s
agent0:                 episode reward: 0.3958,                 loss: nan
agent1:                 episode reward: -0.3958,                 loss: 0.3118
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7841s / 372.3184 s
agent0:                 episode reward: 0.1544,                 loss: nan
agent1:                 episode reward: -0.1544,                 loss: 0.3260
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8063s / 373.1247 s
agent0:                 episode reward: 0.3977,                 loss: nan
agent1:                 episode reward: -0.3977,                 loss: 0.3239
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 373.8997 s
agent0:                 episode reward: -1.0641,                 loss: nan
agent1:                 episode reward: 1.0641,                 loss: 0.3265
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7777s / 374.6774 s
agent0:                 episode reward: 0.1860,                 loss: nan
agent1:                 episode reward: -0.1860,                 loss: 0.3237
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7865s / 375.4639 s
agent0:                 episode reward: 0.9325,                 loss: nan
agent1:                 episode reward: -0.9325,                 loss: 0.3251
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8184s / 376.2823 s
agent0:                 episode reward: 0.1262,                 loss: nan
agent1:                 episode reward: -0.1262,                 loss: 0.3255
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7868s / 377.0691 s
agent0:                 episode reward: -0.0026,                 loss: nan
agent1:                 episode reward: 0.0026,                 loss: 0.3237
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7851s / 377.8542 s
agent0:                 episode reward: 0.2546,                 loss: nan
agent1:                 episode reward: -0.2546,                 loss: 0.3227
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7837s / 378.6379 s
agent0:                 episode reward: 0.5385,                 loss: nan
agent1:                 episode reward: -0.5385,                 loss: 0.3241
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7878s / 379.4257 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.3244
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8249s / 380.2506 s
agent0:                 episode reward: 0.2602,                 loss: nan
agent1:                 episode reward: -0.2602,                 loss: 0.3158
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7890s / 381.0396 s
agent0:                 episode reward: 0.9386,                 loss: nan
agent1:                 episode reward: -0.9386,                 loss: 0.3056
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8094s / 381.8490 s
agent0:                 episode reward: 1.4392,                 loss: nan
agent1:                 episode reward: -1.4392,                 loss: 0.3014
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7932s / 382.6423 s
agent0:                 episode reward: 0.3154,                 loss: nan
agent1:                 episode reward: -0.3154,                 loss: 0.2986
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8236s / 383.4659 s
agent0:                 episode reward: 1.3531,                 loss: nan
agent1:                 episode reward: -1.3531,                 loss: 0.2877
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7872s / 384.2531 s
agent0:                 episode reward: 0.4582,                 loss: nan
agent1:                 episode reward: -0.4582,                 loss: 0.2817
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7918s / 385.0449 s
agent0:                 episode reward: 0.1548,                 loss: nan
agent1:                 episode reward: -0.1548,                 loss: 0.2801
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7875s / 385.8324 s
agent0:                 episode reward: 0.0575,                 loss: nan
agent1:                 episode reward: -0.0575,                 loss: 0.2789
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7975s / 386.6298 s
agent0:                 episode reward: 0.6265,                 loss: nan
agent1:                 episode reward: -0.6265,                 loss: 0.2794
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8480s / 387.4778 s
agent0:                 episode reward: 1.1236,                 loss: nan
agent1:                 episode reward: -1.1236,                 loss: 0.2806
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8181s / 388.2958 s
agent0:                 episode reward: 0.7120,                 loss: nan
agent1:                 episode reward: -0.7120,                 loss: 0.2250
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7880s / 389.0838 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.1920
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8676s / 389.9514 s
agent0:                 episode reward: 0.3060,                 loss: nan
agent1:                 episode reward: -0.3060,                 loss: 0.1903
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8509s / 390.8023 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.1903
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7988s / 391.6011 s
agent0:                 episode reward: 0.7373,                 loss: nan
agent1:                 episode reward: -0.7373,                 loss: 0.1919
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7918s / 392.3929 s
agent0:                 episode reward: 0.1412,                 loss: nan
agent1:                 episode reward: -0.1412,                 loss: 0.1920
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7894s / 393.1823 s
agent0:                 episode reward: 0.7620,                 loss: nan
agent1:                 episode reward: -0.7620,                 loss: 0.1899
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8091s / 393.9914 s
agent0:                 episode reward: -0.1233,                 loss: nan
agent1:                 episode reward: 0.1233,                 loss: 0.1889
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7955s / 394.7870 s
agent0:                 episode reward: 0.4176,                 loss: nan
agent1:                 episode reward: -0.4176,                 loss: 0.1909
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7940s / 395.5809 s
agent0:                 episode reward: 0.5632,                 loss: nan
agent1:                 episode reward: -0.5632,                 loss: 0.1885
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8007s / 396.3816 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1743
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8125s / 397.1941 s
agent0:                 episode reward: -0.0817,                 loss: nan
agent1:                 episode reward: 0.0817,                 loss: 0.1617
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 397.9943 s
agent0:                 episode reward: 0.5138,                 loss: nan
agent1:                 episode reward: -0.5138,                 loss: 0.1594
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8136s / 398.8079 s
agent0:                 episode reward: 0.4942,                 loss: nan
agent1:                 episode reward: -0.4942,                 loss: 0.1576
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7966s / 399.6044 s
agent0:                 episode reward: 0.4201,                 loss: nan
agent1:                 episode reward: -0.4201,                 loss: 0.1594
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8435s / 400.4479 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.1599
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8019s / 401.2499 s
agent0:                 episode reward: 1.1961,                 loss: nan
agent1:                 episode reward: -1.1961,                 loss: 0.1561
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8040s / 402.0539 s
agent0:                 episode reward: 1.0819,                 loss: nan
agent1:                 episode reward: -1.0819,                 loss: 0.1590
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8164s / 402.8703 s
agent0:                 episode reward: 0.0781,                 loss: nan
agent1:                 episode reward: -0.0781,                 loss: 0.1591
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8047s / 403.6750 s
agent0:                 episode reward: 0.4163,                 loss: nan
agent1:                 episode reward: -0.4163,                 loss: 0.1583
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8597s / 404.5347 s
agent0:                 episode reward: -0.2106,                 loss: nan
agent1:                 episode reward: 0.2106,                 loss: 0.1656
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8010s / 405.3358 s
agent0:                 episode reward: 0.2021,                 loss: nan
agent1:                 episode reward: -0.2021,                 loss: 0.1626
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8109s / 406.1467 s
agent0:                 episode reward: -0.6441,                 loss: nan
agent1:                 episode reward: 0.6441,                 loss: 0.1664
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8279s / 406.9746 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1644
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8095s / 407.7841 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: 0.1652
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8069s / 408.5910 s
agent0:                 episode reward: 0.3220,                 loss: nan
agent1:                 episode reward: -0.3220,                 loss: 0.1631
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8166s / 409.4076 s
agent0:                 episode reward: 0.5214,                 loss: nan
agent1:                 episode reward: -0.5214,                 loss: 0.1634
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8413s / 410.2489 s
agent0:                 episode reward: 0.7538,                 loss: nan
agent1:                 episode reward: -0.7538,                 loss: 0.1629
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8527s / 411.1017 s
agent0:                 episode reward: 1.2502,                 loss: nan
agent1:                 episode reward: -1.2502,                 loss: 0.1625
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8231s / 411.9248 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.1601
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8146s / 412.7394 s
agent0:                 episode reward: -0.6122,                 loss: nan
agent1:                 episode reward: 0.6122,                 loss: 0.1917
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8061s / 413.5455 s
agent0:                 episode reward: 0.1921,                 loss: nan
agent1:                 episode reward: -0.1921,                 loss: 0.1971
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8070s / 414.3525 s
agent0:                 episode reward: 0.7075,                 loss: nan
agent1:                 episode reward: -0.7075,                 loss: 0.1967
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8314s / 415.1839 s
agent0:                 episode reward: 0.7090,                 loss: nan
agent1:                 episode reward: -0.7090,                 loss: 0.1964
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8079s / 415.9918 s
agent0:                 episode reward: 0.0606,                 loss: nan
agent1:                 episode reward: -0.0606,                 loss: 0.1948
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8144s / 416.8062 s
agent0:                 episode reward: -0.0455,                 loss: nan
agent1:                 episode reward: 0.0455,                 loss: 0.1943
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8124s / 417.6186 s
agent0:                 episode reward: -0.3600,                 loss: nan
agent1:                 episode reward: 0.3600,                 loss: 0.1942
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8256s / 418.4442 s
agent0:                 episode reward: -0.0260,                 loss: nan
agent1:                 episode reward: 0.0260,                 loss: 0.1966
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8101s / 419.2543 s
agent0:                 episode reward: 0.3021,                 loss: nan
agent1:                 episode reward: -0.3021,                 loss: 0.1962
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8093s / 420.0636 s
agent0:                 episode reward: 0.1012,                 loss: nan
agent1:                 episode reward: -0.1012,                 loss: 0.1948
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8555s / 420.9190 s
agent0:                 episode reward: 0.1074,                 loss: nan
agent1:                 episode reward: -0.1074,                 loss: 0.2339
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8289s / 421.7479 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.2473
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8170s / 422.5649 s
agent0:                 episode reward: 0.2024,                 loss: nan
agent1:                 episode reward: -0.2024,                 loss: 0.2479
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8268s / 423.3917 s
agent0:                 episode reward: 0.0124,                 loss: nan
agent1:                 episode reward: -0.0124,                 loss: 0.2452
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8396s / 424.2313 s
agent0:                 episode reward: 0.7386,                 loss: nan
agent1:                 episode reward: -0.7386,                 loss: 0.2454
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8212s / 425.0525 s
agent0:                 episode reward: -0.2127,                 loss: nan
agent1:                 episode reward: 0.2127,                 loss: 0.2456
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8186s / 425.8710 s
agent0:                 episode reward: 0.8383,                 loss: nan
agent1:                 episode reward: -0.8383,                 loss: 0.2478
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8248s / 426.6958 s
agent0:                 episode reward: -0.3384,                 loss: nan
agent1:                 episode reward: 0.3384,                 loss: 0.2439
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8397s / 427.5355 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: 0.2424
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8207s / 428.3563 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.2453
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8202s / 429.1765 s
agent0:                 episode reward: 0.5534,                 loss: nan
agent1:                 episode reward: -0.5534,                 loss: 0.2845
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8303s / 430.0068 s
agent0:                 episode reward: 0.1029,                 loss: nan
agent1:                 episode reward: -0.1029,                 loss: 0.2968
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8295s / 430.8363 s
agent0:                 episode reward: -0.1469,                 loss: nan
agent1:                 episode reward: 0.1469,                 loss: 0.2943
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8839s / 431.7202 s
agent0:                 episode reward: 0.4713,                 loss: nan
agent1:                 episode reward: -0.4713,                 loss: 0.2935
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8247s / 432.5449 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.2957
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8379s / 433.3828 s
agent0:                 episode reward: 0.1378,                 loss: nan
agent1:                 episode reward: -0.1378,                 loss: 0.2917
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8284s / 434.2112 s
agent0:                 episode reward: -0.2100,                 loss: nan
agent1:                 episode reward: 0.2100,                 loss: 0.2914
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8254s / 435.0366 s
agent0:                 episode reward: -0.7918,                 loss: nan
agent1:                 episode reward: 0.7918,                 loss: 0.2951
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8282s / 435.8648 s
agent0:                 episode reward: 0.6526,                 loss: nan
agent1:                 episode reward: -0.6526,                 loss: 0.2921
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8339s / 436.6987 s
agent0:                 episode reward: 0.8574,                 loss: nan
agent1:                 episode reward: -0.8574,                 loss: 0.2914
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8333s / 437.5320 s
agent0:                 episode reward: 0.7548,                 loss: nan
agent1:                 episode reward: -0.7548,                 loss: 0.3228
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8363s / 438.3683 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.3253
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8453s / 439.2136 s
agent0:                 episode reward: 1.1324,                 loss: nan
agent1:                 episode reward: -1.1324,                 loss: 0.3266
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8500s / 440.0636 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.3255
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8344s / 440.8980 s
agent0:                 episode reward: -0.1212,                 loss: nan
agent1:                 episode reward: 0.1212,                 loss: 0.3260
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8753s / 441.7733 s
agent0:                 episode reward: 1.0790,                 loss: nan
agent1:                 episode reward: -1.0790,                 loss: 0.3253
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8656s / 442.6389 s
agent0:                 episode reward: 0.6966,                 loss: nan
agent1:                 episode reward: -0.6966,                 loss: 0.3235
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8374s / 443.4763 s
agent0:                 episode reward: 0.1527,                 loss: nan
agent1:                 episode reward: -0.1527,                 loss: 0.3242
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8266s / 444.3028 s
agent0:                 episode reward: 0.3223,                 loss: nan
agent1:                 episode reward: -0.3223,                 loss: 0.3261
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8438s / 445.1466 s
agent0:                 episode reward: 0.7870,                 loss: nan
agent1:                 episode reward: -0.7870,                 loss: 0.3252
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8362s / 445.9828 s
agent0:                 episode reward: 0.9713,                 loss: nan
agent1:                 episode reward: -0.9713,                 loss: 0.3360
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8328s / 446.8156 s
agent0:                 episode reward: 0.0075,                 loss: nan
agent1:                 episode reward: -0.0075,                 loss: 0.3368
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8456s / 447.6612 s
agent0:                 episode reward: 0.3081,                 loss: nan
agent1:                 episode reward: -0.3081,                 loss: 0.3373
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8519s / 448.5131 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.3381
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8457s / 449.3589 s
agent0:                 episode reward: -0.0212,                 loss: nan
agent1:                 episode reward: 0.0212,                 loss: 0.3349
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8448s / 450.2037 s
agent0:                 episode reward: 1.3108,                 loss: nan
agent1:                 episode reward: -1.3108,                 loss: 0.3355
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8467s / 451.0504 s
agent0:                 episode reward: 0.4160,                 loss: nan
agent1:                 episode reward: -0.4160,                 loss: 0.3345
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8936s / 451.9440 s
agent0:                 episode reward: 0.4839,                 loss: nan
agent1:                 episode reward: -0.4839,                 loss: 0.3348
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8420s / 452.7860 s
agent0:                 episode reward: 0.1205,                 loss: nan
agent1:                 episode reward: -0.1205,                 loss: 0.3354
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8375s / 453.6235 s
agent0:                 episode reward: 0.1168,                 loss: nan
agent1:                 episode reward: -0.1168,                 loss: 0.3327
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8475s / 454.4710 s
agent0:                 episode reward: 0.0438,                 loss: nan
agent1:                 episode reward: -0.0438,                 loss: 0.3467
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8418s / 455.3128 s
agent0:                 episode reward: 0.5658,                 loss: nan
agent1:                 episode reward: -0.5658,                 loss: 0.3515
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8662s / 456.1790 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3497
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8639s / 457.0429 s
agent0:                 episode reward: 0.1699,                 loss: nan
agent1:                 episode reward: -0.1699,                 loss: 0.3478
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8496s / 457.8925 s
agent0:                 episode reward: 0.3552,                 loss: nan
agent1:                 episode reward: -0.3552,                 loss: 0.3477
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8433s / 458.7358 s
agent0:                 episode reward: 0.3731,                 loss: nan
agent1:                 episode reward: -0.3731,                 loss: 0.3481
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8474s / 459.5831 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.3471
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8534s / 460.4366 s
agent0:                 episode reward: -0.0116,                 loss: nan
agent1:                 episode reward: 0.0116,                 loss: 0.3474
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8432s / 461.2798 s
agent0:                 episode reward: -0.0559,                 loss: nan
agent1:                 episode reward: 0.0559,                 loss: 0.3458
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8796s / 462.1593 s
agent0:                 episode reward: 0.7046,                 loss: nan
agent1:                 episode reward: -0.7046,                 loss: 0.3485
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8626s / 463.0219 s
agent0:                 episode reward: 0.4956,                 loss: nan
agent1:                 episode reward: -0.4956,                 loss: 0.3488
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8534s / 463.8753 s
agent0:                 episode reward: 0.3127,                 loss: nan
agent1:                 episode reward: -0.3127,                 loss: 0.3463
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8633s / 464.7386 s
agent0:                 episode reward: -0.5287,                 loss: nan
agent1:                 episode reward: 0.5287,                 loss: 0.3443
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8575s / 465.5961 s
agent0:                 episode reward: -1.0745,                 loss: nan
agent1:                 episode reward: 1.0745,                 loss: 0.3477
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8610s / 466.4571 s
agent0:                 episode reward: -0.0469,                 loss: nan
agent1:                 episode reward: 0.0469,                 loss: 0.3450
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8618s / 467.3189 s
agent0:                 episode reward: -0.7124,                 loss: nan
agent1:                 episode reward: 0.7124,                 loss: 0.3455
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8585s / 468.1775 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: 0.3456
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8571s / 469.0345 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.3447
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8566s / 469.8911 s
agent0:                 episode reward: -1.0398,                 loss: nan
agent1:                 episode reward: 1.0398,                 loss: 0.3432
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8533s / 470.7444 s
agent0:                 episode reward: 0.4789,                 loss: nan
agent1:                 episode reward: -0.4789,                 loss: 0.3444
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8602s / 471.6046 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.3088
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9061s / 472.5106 s
agent0:                 episode reward: 0.8240,                 loss: nan
agent1:                 episode reward: -0.8240,                 loss: 0.2832
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8700s / 473.3806 s
agent0:                 episode reward: 0.0070,                 loss: nan
agent1:                 episode reward: -0.0070,                 loss: 0.2846
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8628s / 474.2434 s
agent0:                 episode reward: 0.0892,                 loss: nan
agent1:                 episode reward: -0.0892,                 loss: 0.2845
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8662s / 475.1097 s
agent0:                 episode reward: 0.2090,                 loss: nan
agent1:                 episode reward: -0.2090,                 loss: 0.2829
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8603s / 475.9700 s
agent0:                 episode reward: -1.0504,                 loss: nan
agent1:                 episode reward: 1.0504,                 loss: 0.2805
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8550s / 476.8250 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.2815
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8701s / 477.6951 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.2813
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8662s / 478.5613 s
agent0:                 episode reward: 0.5348,                 loss: nan
agent1:                 episode reward: -0.5348,                 loss: 0.2803
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8768s / 479.4381 s
agent0:                 episode reward: 0.4910,                 loss: nan
agent1:                 episode reward: -0.4910,                 loss: 0.2816
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8810s / 480.3191 s
agent0:                 episode reward: -0.1530,                 loss: nan
agent1:                 episode reward: 0.1530,                 loss: 0.2366
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8935s / 481.2126 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.2098
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8711s / 482.0837 s
agent0:                 episode reward: 1.0260,                 loss: nan
agent1:                 episode reward: -1.0260,                 loss: 0.2136
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9052s / 482.9890 s
agent0:                 episode reward: -0.1529,                 loss: nan
agent1:                 episode reward: 0.1529,                 loss: 0.2118
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8655s / 483.8545 s
agent0:                 episode reward: 0.3270,                 loss: nan
agent1:                 episode reward: -0.3270,                 loss: 0.2108
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8692s / 484.7237 s
agent0:                 episode reward: 0.5842,                 loss: nan
agent1:                 episode reward: -0.5842,                 loss: 0.2116
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8671s / 485.5908 s
agent0:                 episode reward: 0.3194,                 loss: nan
agent1:                 episode reward: -0.3194,                 loss: 0.2119
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8899s / 486.4807 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: 0.2100
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9096s / 487.3903 s
agent0:                 episode reward: 0.0115,                 loss: nan
agent1:                 episode reward: -0.0115,                 loss: 0.2099
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8712s / 488.2614 s
agent0:                 episode reward: -0.3044,                 loss: nan
agent1:                 episode reward: 0.3044,                 loss: 0.2090
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8697s / 489.1312 s
agent0:                 episode reward: -0.8102,                 loss: nan
agent1:                 episode reward: 0.8102,                 loss: 0.1904
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8877s / 490.0189 s
agent0:                 episode reward: 0.1557,                 loss: nan
agent1:                 episode reward: -0.1557,                 loss: 0.1758
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8790s / 490.8979 s
agent0:                 episode reward: 0.3842,                 loss: nan
agent1:                 episode reward: -0.3842,                 loss: 0.1757
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8715s / 491.7693 s
agent0:                 episode reward: 0.1111,                 loss: nan
agent1:                 episode reward: -0.1111,                 loss: 0.1771
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9060s / 492.6753 s
agent0:                 episode reward: 0.4328,                 loss: nan
agent1:                 episode reward: -0.4328,                 loss: 0.1745
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9085s / 493.5838 s
agent0:                 episode reward: -0.1302,                 loss: nan
agent1:                 episode reward: 0.1302,                 loss: 0.1759
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8754s / 494.4592 s
agent0:                 episode reward: 0.6383,                 loss: nan
agent1:                 episode reward: -0.6383,                 loss: 0.1742
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8704s / 495.3296 s
agent0:                 episode reward: 0.7561,                 loss: nan
agent1:                 episode reward: -0.7561,                 loss: 0.1745
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8947s / 496.2243 s
agent0:                 episode reward: -1.3932,                 loss: nan
agent1:                 episode reward: 1.3932,                 loss: 0.1753
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8906s / 497.1150 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.1761
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8994s / 498.0144 s
agent0:                 episode reward: 0.6888,                 loss: nan
agent1:                 episode reward: -0.6888,                 loss: 0.1852
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8943s / 498.9086 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.1874
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8845s / 499.7931 s
agent0:                 episode reward: -1.4288,                 loss: nan
agent1:                 episode reward: 1.4288,                 loss: 0.1861
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8805s / 500.6736 s
agent0:                 episode reward: 0.4486,                 loss: nan
agent1:                 episode reward: -0.4486,                 loss: 0.1874
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8838s / 501.5574 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: 0.1851
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9004s / 502.4578 s
agent0:                 episode reward: 1.4141,                 loss: nan
agent1:                 episode reward: -1.4141,                 loss: 0.1833
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9359s / 503.3937 s
agent0:                 episode reward: -0.9249,                 loss: nan
agent1:                 episode reward: 0.9249,                 loss: 0.1853
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8876s / 504.2814 s
agent0:                 episode reward: 0.2735,                 loss: nan
agent1:                 episode reward: -0.2735,                 loss: 0.1861
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8921s / 505.1734 s
agent0:                 episode reward: 0.2263,                 loss: nan
agent1:                 episode reward: -0.2263,                 loss: 0.1830
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9539s / 506.1274 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.1831
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8900s / 507.0174 s
agent0:                 episode reward: 0.2920,                 loss: nan
agent1:                 episode reward: -0.2920,                 loss: 0.2082
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9208s / 507.9382 s
agent0:                 episode reward: 0.2909,                 loss: nan
agent1:                 episode reward: -0.2909,                 loss: 0.2189
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9033s / 508.8416 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.2190
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8778s / 509.7194 s
agent0:                 episode reward: 0.3705,                 loss: nan
agent1:                 episode reward: -0.3705,                 loss: 0.2163
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8899s / 510.6093 s
agent0:                 episode reward: 0.4756,                 loss: nan
agent1:                 episode reward: -0.4756,                 loss: 0.2178
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8924s / 511.5017 s
agent0:                 episode reward: -0.0449,                 loss: nan
agent1:                 episode reward: 0.0449,                 loss: 0.2168
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8822s / 512.3839 s
agent0:                 episode reward: -0.6372,                 loss: nan
agent1:                 episode reward: 0.6372,                 loss: 0.2156
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9343s / 513.3182 s
agent0:                 episode reward: -0.2877,                 loss: nan
agent1:                 episode reward: 0.2877,                 loss: 0.2161
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9055s / 514.2237 s
agent0:                 episode reward: -0.2688,                 loss: nan
agent1:                 episode reward: 0.2688,                 loss: 0.2169
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9007s / 515.1245 s
agent0:                 episode reward: 0.4737,                 loss: nan
agent1:                 episode reward: -0.4737,                 loss: 0.2172
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8845s / 516.0090 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.2479
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8972s / 516.9061 s
agent0:                 episode reward: 0.4521,                 loss: nan
agent1:                 episode reward: -0.4521,                 loss: 0.2584
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9037s / 517.8098 s
agent0:                 episode reward: 0.6787,                 loss: nan
agent1:                 episode reward: -0.6787,                 loss: 0.2568
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9048s / 518.7146 s
agent0:                 episode reward: -0.7756,                 loss: nan
agent1:                 episode reward: 0.7756,                 loss: 0.2572
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8898s / 519.6044 s
agent0:                 episode reward: -0.0509,                 loss: nan
agent1:                 episode reward: 0.0509,                 loss: 0.2579
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9055s / 520.5099 s
agent0:                 episode reward: 0.3587,                 loss: nan
agent1:                 episode reward: -0.3587,                 loss: 0.2588
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8947s / 521.4047 s
agent0:                 episode reward: 0.1241,                 loss: nan
agent1:                 episode reward: -0.1241,                 loss: 0.2594
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9135s / 522.3181 s
agent0:                 episode reward: 1.1436,                 loss: nan
agent1:                 episode reward: -1.1436,                 loss: 0.2601
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9182s / 523.2363 s
agent0:                 episode reward: -0.8220,                 loss: nan
agent1:                 episode reward: 0.8220,                 loss: 0.2578
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9565s / 524.1927 s
agent0:                 episode reward: -0.9942,                 loss: nan
agent1:                 episode reward: 0.9942,                 loss: 0.2592
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8968s / 525.0896 s
agent0:                 episode reward: 0.2657,                 loss: nan
agent1:                 episode reward: -0.2657,                 loss: 0.2964
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9179s / 526.0075 s
agent0:                 episode reward: 0.8067,                 loss: nan
agent1:                 episode reward: -0.8067,                 loss: 0.3080
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9305s / 526.9380 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.3072
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9086s / 527.8466 s
agent0:                 episode reward: 0.1077,                 loss: nan
agent1:                 episode reward: -0.1077,                 loss: 0.3047
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9091s / 528.7558 s
agent0:                 episode reward: -1.2530,                 loss: nan
agent1:                 episode reward: 1.2530,                 loss: 0.3051
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9041s / 529.6599 s
agent0:                 episode reward: -0.2030,                 loss: nan
agent1:                 episode reward: 0.2030,                 loss: 0.3058
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9027s / 530.5625 s
agent0:                 episode reward: -0.5494,                 loss: nan
agent1:                 episode reward: 0.5494,                 loss: 0.3044
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9279s / 531.4904 s
agent0:                 episode reward: -0.2078,                 loss: nan
agent1:                 episode reward: 0.2078,                 loss: 0.3031
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9286s / 532.4190 s
agent0:                 episode reward: -0.1340,                 loss: nan
agent1:                 episode reward: 0.1340,                 loss: 0.3013
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9221s / 533.3411 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.3024
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9667s / 534.3077 s
agent0:                 episode reward: -0.8305,                 loss: nan
agent1:                 episode reward: 0.8305,                 loss: 0.3273
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9156s / 535.2233 s
agent0:                 episode reward: 0.7572,                 loss: nan
agent1:                 episode reward: -0.7572,                 loss: 0.3341
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9306s / 536.1539 s
agent0:                 episode reward: 0.2719,                 loss: nan
agent1:                 episode reward: -0.2719,                 loss: 0.3357
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9169s / 537.0708 s
agent0:                 episode reward: 0.2104,                 loss: nan
agent1:                 episode reward: -0.2104,                 loss: 0.3308
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9117s / 537.9824 s
agent0:                 episode reward: 0.7220,                 loss: nan
agent1:                 episode reward: -0.7220,                 loss: 0.3307
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9347s / 538.9172 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: 0.3315
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9456s / 539.8627 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.3304
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9216s / 540.7843 s
agent0:                 episode reward: -0.2068,                 loss: nan
agent1:                 episode reward: 0.2068,                 loss: 0.3333
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9316s / 541.7159 s
agent0:                 episode reward: 0.3311,                 loss: nan
agent1:                 episode reward: -0.3311,                 loss: 0.3315
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9301s / 542.6460 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: 0.3305
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9301s / 543.5761 s
agent0:                 episode reward: -0.8372,                 loss: nan
agent1:                 episode reward: 0.8372,                 loss: 0.3440
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9539s / 544.5300 s
agent0:                 episode reward: 0.4754,                 loss: nan
agent1:                 episode reward: -0.4754,                 loss: 0.3422
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9379s / 545.4680 s
agent0:                 episode reward: -0.8782,                 loss: nan
agent1:                 episode reward: 0.8782,                 loss: 0.3410
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9209s / 546.3888 s
agent0:                 episode reward: -0.6511,                 loss: nan
agent1:                 episode reward: 0.6511,                 loss: 0.3352
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9396s / 547.3284 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.3371
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9475s / 548.2759 s
agent0:                 episode reward: 0.7790,                 loss: nan
agent1:                 episode reward: -0.7790,                 loss: 0.3391
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9597s / 549.2356 s
agent0:                 episode reward: 1.3430,                 loss: nan
agent1:                 episode reward: -1.3430,                 loss: 0.3387
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9223s / 550.1579 s
agent0:                 episode reward: -0.0045,                 loss: nan
agent1:                 episode reward: 0.0045,                 loss: 0.3370
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9308s / 551.0887 s
agent0:                 episode reward: -0.1638,                 loss: nan
agent1:                 episode reward: 0.1638,                 loss: 0.3369
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9296s / 552.0183 s
agent0:                 episode reward: 0.4968,                 loss: nan
agent1:                 episode reward: -0.4968,                 loss: 0.3378
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9298s / 552.9481 s
agent0:                 episode reward: 0.2922,                 loss: nan
agent1:                 episode reward: -0.2922,                 loss: 0.3350
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9330s / 553.8811 s
agent0:                 episode reward: -1.0558,                 loss: nan
agent1:                 episode reward: 1.0558,                 loss: 0.3237
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9736s / 554.8548 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.3218
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9466s / 555.8014 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.3233
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9541s / 556.7555 s
agent0:                 episode reward: -0.2491,                 loss: nan
agent1:                 episode reward: 0.2491,                 loss: 0.3225
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9362s / 557.6917 s
agent0:                 episode reward: -0.7246,                 loss: nan
agent1:                 episode reward: 0.7246,                 loss: 0.3242
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9460s / 558.6377 s
agent0:                 episode reward: -0.8132,                 loss: nan
agent1:                 episode reward: 0.8132,                 loss: 0.3245
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9410s / 559.5787 s
agent0:                 episode reward: 0.0018,                 loss: nan
agent1:                 episode reward: -0.0018,                 loss: 0.3206
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9470s / 560.5257 s
agent0:                 episode reward: 1.3399,                 loss: nan
agent1:                 episode reward: -1.3399,                 loss: 0.3224
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9326s / 561.4583 s
agent0:                 episode reward: -0.1929,                 loss: nan
agent1:                 episode reward: 0.1929,                 loss: 0.3232
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9469s / 562.4052 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.2994
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9358s / 563.3410 s
agent0:                 episode reward: 0.4739,                 loss: nan
agent1:                 episode reward: -0.4739,                 loss: 0.2815
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0190s / 564.3600 s
agent0:                 episode reward: 0.3089,                 loss: nan
agent1:                 episode reward: -0.3089,                 loss: 0.2814
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9442s / 565.3041 s
agent0:                 episode reward: 0.3183,                 loss: nan
agent1:                 episode reward: -0.3183,                 loss: 0.2803
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9477s / 566.2518 s
agent0:                 episode reward: -0.1845,                 loss: nan
agent1:                 episode reward: 0.1845,                 loss: 0.2773
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9417s / 567.1935 s
agent0:                 episode reward: 0.8189,                 loss: nan
agent1:                 episode reward: -0.8189,                 loss: 0.2787
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9582s / 568.1517 s
agent0:                 episode reward: 0.3117,                 loss: nan
agent1:                 episode reward: -0.3117,                 loss: 0.2761
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9573s / 569.1090 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.2747
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9408s / 570.0497 s
agent0:                 episode reward: 0.6302,                 loss: nan
agent1:                 episode reward: -0.6302,                 loss: 0.2777
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9501s / 570.9999 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.2761
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9642s / 571.9641 s
agent0:                 episode reward: -0.3109,                 loss: nan
agent1:                 episode reward: 0.3109,                 loss: 0.2309
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9574s / 572.9215 s
agent0:                 episode reward: 1.1202,                 loss: nan
agent1:                 episode reward: -1.1202,                 loss: 0.2014
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9529s / 573.8744 s
agent0:                 episode reward: -0.8961,                 loss: nan
agent1:                 episode reward: 0.8961,                 loss: 0.2005
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 574.8954 s
agent0:                 episode reward: 0.4995,                 loss: nan
agent1:                 episode reward: -0.4995,                 loss: 0.2027
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9572s / 575.8526 s
agent0:                 episode reward: 0.8329,                 loss: nan
agent1:                 episode reward: -0.8329,                 loss: 0.1967
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9612s / 576.8138 s
agent0:                 episode reward: -0.4348,                 loss: nan
agent1:                 episode reward: 0.4348,                 loss: 0.1999
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9550s / 577.7688 s
agent0:                 episode reward: 1.1528,                 loss: nan
agent1:                 episode reward: -1.1528,                 loss: 0.2008
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9624s / 578.7312 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.2005
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9588s / 579.6901 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.2014
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9758s / 580.6659 s
agent0:                 episode reward: -0.6260,                 loss: nan
agent1:                 episode reward: 0.6260,                 loss: 0.1992
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9589s / 581.6248 s
agent0:                 episode reward: 0.1180,                 loss: nan
agent1:                 episode reward: -0.1180,                 loss: 0.1787
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9629s / 582.5876 s
agent0:                 episode reward: 0.6087,                 loss: nan
agent1:                 episode reward: -0.6087,                 loss: 0.1661
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9662s / 583.5538 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.1638
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9592s / 584.5131 s
agent0:                 episode reward: -0.2988,                 loss: nan
agent1:                 episode reward: 0.2988,                 loss: 0.1643
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9932s / 585.5062 s
agent0:                 episode reward: -0.8790,                 loss: nan
agent1:                 episode reward: 0.8790,                 loss: 0.1658
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9650s / 586.4712 s
agent0:                 episode reward: 0.3527,                 loss: nan
agent1:                 episode reward: -0.3527,                 loss: 0.1648
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9722s / 587.4434 s
agent0:                 episode reward: 0.9187,                 loss: nan
agent1:                 episode reward: -0.9187,                 loss: 0.1634
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9685s / 588.4119 s
agent0:                 episode reward: 0.2099,                 loss: nan
agent1:                 episode reward: -0.2099,                 loss: 0.1641
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0156s / 589.4275 s
agent0:                 episode reward: 0.5693,                 loss: nan
agent1:                 episode reward: -0.5693,                 loss: 0.1637
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9801s / 590.4076 s
agent0:                 episode reward: -1.1915,                 loss: nan
agent1:                 episode reward: 1.1915,                 loss: 0.1642
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9568s / 591.3644 s
agent0:                 episode reward: 0.2381,                 loss: nan
agent1:                 episode reward: -0.2381,                 loss: 0.1826
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9679s / 592.3323 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1861
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9727s / 593.3050 s
agent0:                 episode reward: 0.0754,                 loss: nan
agent1:                 episode reward: -0.0754,                 loss: 0.1850
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9727s / 594.2777 s
agent0:                 episode reward: -0.0968,                 loss: nan
agent1:                 episode reward: 0.0968,                 loss: 0.1859
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0094s / 595.2871 s
agent0:                 episode reward: -0.0890,                 loss: nan
agent1:                 episode reward: 0.0890,                 loss: 0.1859
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9795s / 596.2666 s
agent0:                 episode reward: -1.6366,                 loss: nan
agent1:                 episode reward: 1.6366,                 loss: 0.1875
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0003s / 597.2669 s
agent0:                 episode reward: 0.2277,                 loss: nan
agent1:                 episode reward: -0.2277,                 loss: 0.1865
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9781s / 598.2450 s
agent0:                 episode reward: 0.0489,                 loss: nan
agent1:                 episode reward: -0.0489,                 loss: 0.1853
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9896s / 599.2346 s
agent0:                 episode reward: 0.0531,                 loss: nan
agent1:                 episode reward: -0.0531,                 loss: 0.1827
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9744s / 600.2090 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.1841
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9852s / 601.1943 s
agent0:                 episode reward: -0.2909,                 loss: nan
agent1:                 episode reward: 0.2909,                 loss: 0.2117
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9797s / 602.1740 s
agent0:                 episode reward: -1.1961,                 loss: nan
agent1:                 episode reward: 1.1961,                 loss: 0.2192
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0124s / 603.1863 s
agent0:                 episode reward: 0.2824,                 loss: nan
agent1:                 episode reward: -0.2824,                 loss: 0.2194
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9923s / 604.1786 s
agent0:                 episode reward: -0.6791,                 loss: nan
agent1:                 episode reward: 0.6791,                 loss: 0.2150
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9748s / 605.1534 s
agent0:                 episode reward: -0.0303,                 loss: nan
agent1:                 episode reward: 0.0303,                 loss: 0.2178
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0396s / 606.1929 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.2164
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9814s / 607.1743 s
agent0:                 episode reward: -0.1675,                 loss: nan
agent1:                 episode reward: 0.1675,                 loss: 0.2188
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9767s / 608.1510 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.2165
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9932s / 609.1442 s
agent0:                 episode reward: 0.3599,                 loss: nan
agent1:                 episode reward: -0.3599,                 loss: 0.2152
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9883s / 610.1326 s
agent0:                 episode reward: 0.9459,                 loss: nan
agent1:                 episode reward: -0.9459,                 loss: 0.2159
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0117s / 611.1442 s
agent0:                 episode reward: -1.0700,                 loss: nan
agent1:                 episode reward: 1.0700,                 loss: 0.2533
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9866s / 612.1309 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: 0.2634
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9788s / 613.1097 s
agent0:                 episode reward: 0.6848,                 loss: nan
agent1:                 episode reward: -0.6848,                 loss: 0.2595
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0128s / 614.1225 s
agent0:                 episode reward: 0.2750,                 loss: nan
agent1:                 episode reward: -0.2750,                 loss: 0.2611
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9961s / 615.1186 s
agent0:                 episode reward: 0.3922,                 loss: nan
agent1:                 episode reward: -0.3922,                 loss: 0.2625
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0323s / 616.1509 s
agent0:                 episode reward: 0.0604,                 loss: nan
agent1:                 episode reward: -0.0604,                 loss: 0.2611
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0096s / 617.1605 s
agent0:                 episode reward: -0.1180,                 loss: nan
agent1:                 episode reward: 0.1180,                 loss: 0.2610
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0118s / 618.1723 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: 0.2620
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0004s / 619.1727 s
agent0:                 episode reward: 0.6985,                 loss: nan
agent1:                 episode reward: -0.6985,                 loss: 0.2618
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9957s / 620.1684 s
agent0:                 episode reward: 1.1140,                 loss: nan
agent1:                 episode reward: -1.1140,                 loss: 0.2609
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0035s / 621.1718 s
agent0:                 episode reward: -0.5303,                 loss: nan
agent1:                 episode reward: 0.5303,                 loss: 0.2903
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0371s / 622.2089 s
agent0:                 episode reward: 0.9347,                 loss: nan
agent1:                 episode reward: -0.9347,                 loss: 0.2972
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0205s / 623.2294 s
agent0:                 episode reward: 0.3624,                 loss: nan
agent1:                 episode reward: -0.3624,                 loss: 0.2969
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9974s / 624.2268 s
agent0:                 episode reward: 0.1387,                 loss: nan
agent1:                 episode reward: -0.1387,                 loss: 0.2965
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0001s / 625.2269 s
agent0:                 episode reward: -0.4727,                 loss: nan
agent1:                 episode reward: 0.4727,                 loss: 0.2963
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0504s / 626.2772 s
agent0:                 episode reward: -0.5410,                 loss: nan
agent1:                 episode reward: 0.5410,                 loss: 0.2972
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9915s / 627.2687 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.2947
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9937s / 628.2624 s
agent0:                 episode reward: -0.1123,                 loss: nan
agent1:                 episode reward: 0.1123,                 loss: 0.2951
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0088s / 629.2712 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.2949
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0025s / 630.2737 s
agent0:                 episode reward: -0.1909,                 loss: nan
agent1:                 episode reward: 0.1909,                 loss: 0.2951
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0201s / 631.2938 s
agent0:                 episode reward: -0.5293,                 loss: nan
agent1:                 episode reward: 0.5293,                 loss: 0.3248
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0023s / 632.2961 s
agent0:                 episode reward: 0.3562,                 loss: nan
agent1:                 episode reward: -0.3562,                 loss: 0.3325
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0053s / 633.3014 s
agent0:                 episode reward: 0.8838,                 loss: nan
agent1:                 episode reward: -0.8838,                 loss: 0.3314
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0042s / 634.3057 s
agent0:                 episode reward: 0.2008,                 loss: nan
agent1:                 episode reward: -0.2008,                 loss: 0.3306
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0106s / 635.3163 s
agent0:                 episode reward: -0.2038,                 loss: nan
agent1:                 episode reward: 0.2038,                 loss: 0.3312
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0508s / 636.3671 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.3299
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0049s / 637.3719 s
agent0:                 episode reward: -0.1013,                 loss: nan
agent1:                 episode reward: 0.1013,                 loss: 0.3322
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0212s / 638.3931 s
agent0:                 episode reward: -0.1763,                 loss: nan
agent1:                 episode reward: 0.1763,                 loss: 0.3293
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0314s / 639.4246 s
agent0:                 episode reward: 0.2433,                 loss: nan
agent1:                 episode reward: -0.2433,                 loss: 0.3290
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0073s / 640.4319 s
agent0:                 episode reward: -0.9101,                 loss: nan
agent1:                 episode reward: 0.9101,                 loss: 0.3285
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0328s / 641.4647 s
agent0:                 episode reward: -0.2743,                 loss: nan
agent1:                 episode reward: 0.2743,                 loss: 0.3440
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0021s / 642.4668 s
agent0:                 episode reward: 0.0834,                 loss: nan
agent1:                 episode reward: -0.0834,                 loss: 0.3377
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0318s / 643.4985 s
agent0:                 episode reward: -0.4851,                 loss: nan
agent1:                 episode reward: 0.4851,                 loss: 0.3396
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0135s / 644.5120 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: 0.3377
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0118s / 645.5238 s
agent0:                 episode reward: 0.3547,                 loss: nan
agent1:                 episode reward: -0.3547,                 loss: 0.3382
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0604s / 646.5842 s
agent0:                 episode reward: 0.5249,                 loss: nan
agent1:                 episode reward: -0.5249,                 loss: 0.3388
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0207s / 647.6050 s
agent0:                 episode reward: -0.9372,                 loss: nan
agent1:                 episode reward: 0.9372,                 loss: 0.3374
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0348s / 648.6398 s
agent0:                 episode reward: -0.4983,                 loss: nan
agent1:                 episode reward: 0.4983,                 loss: 0.3370
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0392s / 649.6790 s
agent0:                 episode reward: -0.5346,                 loss: nan
agent1:                 episode reward: 0.5346,                 loss: 0.3364
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9991s / 650.6780 s
agent0:                 episode reward: 0.2232,                 loss: nan
agent1:                 episode reward: -0.2232,                 loss: 0.3370
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0201s / 651.6982 s
agent0:                 episode reward: -0.3211,                 loss: nan
agent1:                 episode reward: 0.3211,                 loss: 0.3299
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0305s / 652.7286 s
agent0:                 episode reward: -0.0119,                 loss: nan
agent1:                 episode reward: 0.0119,                 loss: 0.3175
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0511s / 653.7798 s
agent0:                 episode reward: -0.7928,                 loss: nan
agent1:                 episode reward: 0.7928,                 loss: 0.3199
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0328s / 654.8126 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3160
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0555s / 655.8681 s
agent0:                 episode reward: -0.3490,                 loss: nan
agent1:                 episode reward: 0.3490,                 loss: 0.3162
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0739s / 656.9420 s
agent0:                 episode reward: 0.0285,                 loss: nan
agent1:                 episode reward: -0.0285,                 loss: 0.3164
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0368s / 657.9788 s
agent0:                 episode reward: 0.9631,                 loss: nan
agent1:                 episode reward: -0.9631,                 loss: 0.3156
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0162s / 658.9950 s
agent0:                 episode reward: 0.4532,                 loss: nan
agent1:                 episode reward: -0.4532,                 loss: 0.3174
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0165s / 660.0115 s
agent0:                 episode reward: 0.4456,                 loss: nan
agent1:                 episode reward: -0.4456,                 loss: 0.3151
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0308s / 661.0423 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.3163
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0308s / 662.0731 s
agent0:                 episode reward: 0.8592,                 loss: nan
agent1:                 episode reward: -0.8592,                 loss: 0.3006
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0260s / 663.0991 s
agent0:                 episode reward: -1.2831,                 loss: nan
agent1:                 episode reward: 1.2831,                 loss: 0.2799
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0418s / 664.1409 s
agent0:                 episode reward: 0.0319,                 loss: nan
agent1:                 episode reward: -0.0319,                 loss: 0.2787
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0213s / 665.1622 s
agent0:                 episode reward: 0.5205,                 loss: nan
agent1:                 episode reward: -0.5205,                 loss: 0.2775
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0150s / 666.1772 s
agent0:                 episode reward: -0.1518,                 loss: nan
agent1:                 episode reward: 0.1518,                 loss: 0.2774
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0517s / 667.2290 s
agent0:                 episode reward: 0.1434,                 loss: nan
agent1:                 episode reward: -0.1434,                 loss: 0.2769
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0289s / 668.2579 s
agent0:                 episode reward: 0.2086,                 loss: nan
agent1:                 episode reward: -0.2086,                 loss: 0.2753
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0273s / 669.2852 s
agent0:                 episode reward: -0.1070,                 loss: nan
agent1:                 episode reward: 0.1070,                 loss: 0.2751
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0413s / 670.3264 s
agent0:                 episode reward: -0.4754,                 loss: nan
agent1:                 episode reward: 0.4754,                 loss: 0.2783
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0115s / 671.3380 s
agent0:                 episode reward: 0.5406,                 loss: nan
agent1:                 episode reward: -0.5406,                 loss: 0.2790
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0370s / 672.3750 s
agent0:                 episode reward: -0.8016,                 loss: nan
agent1:                 episode reward: 0.8016,                 loss: 0.2323
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0254s / 673.4004 s
agent0:                 episode reward: 0.0025,                 loss: nan
agent1:                 episode reward: -0.0025,                 loss: 0.1991
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0177s / 674.4181 s
agent0:                 episode reward: -0.8730,                 loss: nan
agent1:                 episode reward: 0.8730,                 loss: 0.1977
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0101s / 675.4282 s
agent0:                 episode reward: -1.5898,                 loss: nan
agent1:                 episode reward: 1.5898,                 loss: 0.2002
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0085s / 676.4367 s
agent0:                 episode reward: -0.1479,                 loss: nan
agent1:                 episode reward: 0.1479,                 loss: 0.1947
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0881s / 677.5248 s
agent0:                 episode reward: -0.6837,                 loss: nan
agent1:                 episode reward: 0.6837,                 loss: 0.1952
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0377s / 678.5625 s
agent0:                 episode reward: -0.1544,                 loss: nan
agent1:                 episode reward: 0.1544,                 loss: 0.1946
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1038s / 679.6663 s
agent0:                 episode reward: 0.5896,                 loss: nan
agent1:                 episode reward: -0.5896,                 loss: 0.1949
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0399s / 680.7062 s
agent0:                 episode reward: -0.0977,                 loss: nan
agent1:                 episode reward: 0.0977,                 loss: 0.1938
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0170s / 681.7232 s
agent0:                 episode reward: -0.7752,                 loss: nan
agent1:                 episode reward: 0.7752,                 loss: 0.1955
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0336s / 682.7568 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.1814
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0384s / 683.7951 s
agent0:                 episode reward: 0.2106,                 loss: nan
agent1:                 episode reward: -0.2106,                 loss: 0.1719
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0372s / 684.8324 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.1713
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0384s / 685.8708 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.1711
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0081s / 686.8789 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: 0.1723
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0680s / 687.9469 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.1706
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0813s / 689.0282 s
agent0:                 episode reward: -0.1879,                 loss: nan
agent1:                 episode reward: 0.1879,                 loss: 0.1691
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0154s / 690.0437 s
agent0:                 episode reward: -0.1012,                 loss: nan
agent1:                 episode reward: 0.1012,                 loss: 0.1686
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0296s / 691.0733 s
agent0:                 episode reward: -0.1320,                 loss: nan
agent1:                 episode reward: 0.1320,                 loss: 0.1693
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0659s / 692.1392 s
agent0:                 episode reward: 0.6093,                 loss: nan
agent1:                 episode reward: -0.6093,                 loss: 0.1728
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0438s / 693.1830 s
agent0:                 episode reward: -0.6682,                 loss: nan
agent1:                 episode reward: 0.6682,                 loss: 0.1855
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0253s / 694.2083 s
agent0:                 episode reward: 0.2814,                 loss: nan
agent1:                 episode reward: -0.2814,                 loss: 0.1887
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0772s / 695.2855 s
agent0:                 episode reward: -0.1837,                 loss: nan
agent1:                 episode reward: 0.1837,                 loss: 0.1886
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0343s / 696.3198 s
agent0:                 episode reward: 0.4535,                 loss: nan
agent1:                 episode reward: -0.4535,                 loss: 0.1875
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0918s / 697.4116 s
agent0:                 episode reward: -0.0818,                 loss: nan
agent1:                 episode reward: 0.0818,                 loss: 0.1892
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0939s / 698.5055 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.1885
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0578s / 699.5633 s
agent0:                 episode reward: 0.3143,                 loss: nan
agent1:                 episode reward: -0.3143,                 loss: 0.1882
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0517s / 700.6150 s
agent0:                 episode reward: 0.2149,                 loss: nan
agent1:                 episode reward: -0.2149,                 loss: 0.1898
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0594s / 701.6744 s
agent0:                 episode reward: -0.0608,                 loss: nan
agent1:                 episode reward: 0.0608,                 loss: 0.1883
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0689s / 702.7433 s
agent0:                 episode reward: 0.3632,                 loss: nan
agent1:                 episode reward: -0.3632,                 loss: 0.1886
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0579s / 703.8012 s
agent0:                 episode reward: -0.9439,                 loss: nan
agent1:                 episode reward: 0.9439,                 loss: 0.2172
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0518s / 704.8530 s
agent0:                 episode reward: 0.5747,                 loss: nan
agent1:                 episode reward: -0.5747,                 loss: 0.2294
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0827s / 705.9358 s
agent0:                 episode reward: -0.2069,                 loss: nan
agent1:                 episode reward: 0.2069,                 loss: 0.2265
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0729s / 707.0087 s
agent0:                 episode reward: -0.1879,                 loss: nan
agent1:                 episode reward: 0.1879,                 loss: 0.2282
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0978s / 708.1065 s
agent0:                 episode reward: -0.9912,                 loss: nan
agent1:                 episode reward: 0.9912,                 loss: 0.2230
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0750s / 709.1815 s
agent0:                 episode reward: 0.2142,                 loss: nan
agent1:                 episode reward: -0.2142,                 loss: 0.2258
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0867s / 710.2683 s
agent0:                 episode reward: 0.0806,                 loss: nan
agent1:                 episode reward: -0.0806,                 loss: 0.2274
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0776s / 711.3459 s
agent0:                 episode reward: 0.7338,                 loss: nan
agent1:                 episode reward: -0.7338,                 loss: 0.2260
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0637s / 712.4095 s
agent0:                 episode reward: -0.0051,                 loss: nan
agent1:                 episode reward: 0.0051,                 loss: 0.2243
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1011s / 713.5107 s
agent0:                 episode reward: 0.0130,                 loss: nan
agent1:                 episode reward: -0.0130,                 loss: 0.2269
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0831s / 714.5938 s
agent0:                 episode reward: -1.0390,                 loss: nan
agent1:                 episode reward: 1.0390,                 loss: 0.2570
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0714s / 715.6652 s
agent0:                 episode reward: 1.3092,                 loss: nan
agent1:                 episode reward: -1.3092,                 loss: 0.2654
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0756s / 716.7408 s
agent0:                 episode reward: 0.1932,                 loss: nan
agent1:                 episode reward: -0.1932,                 loss: 0.2652
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0876s / 717.8284 s
agent0:                 episode reward: -0.1158,                 loss: nan
agent1:                 episode reward: 0.1158,                 loss: 0.2665
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1088s / 718.9372 s
agent0:                 episode reward: -0.0514,                 loss: nan
agent1:                 episode reward: 0.0514,                 loss: 0.2640
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0955s / 720.0327 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.2637
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0906s / 721.1233 s
agent0:                 episode reward: 0.7090,                 loss: nan
agent1:                 episode reward: -0.7090,                 loss: 0.2635
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1138s / 722.2372 s
agent0:                 episode reward: -0.4116,                 loss: nan
agent1:                 episode reward: 0.4116,                 loss: 0.2652
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0883s / 723.3255 s
agent0:                 episode reward: -0.7775,                 loss: nan
agent1:                 episode reward: 0.7775,                 loss: 0.2619
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0869s / 724.4124 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.2631
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1005s / 725.5129 s
agent0:                 episode reward: 0.5090,                 loss: nan
agent1:                 episode reward: -0.5090,                 loss: 0.2877
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0955s / 726.6083 s
agent0:                 episode reward: 0.0044,                 loss: nan
agent1:                 episode reward: -0.0044,                 loss: 0.2947
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0780s / 727.6863 s
agent0:                 episode reward: -0.1018,                 loss: nan
agent1:                 episode reward: 0.1018,                 loss: 0.2961
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1275s / 728.8139 s
agent0:                 episode reward: 0.3203,                 loss: nan
agent1:                 episode reward: -0.3203,                 loss: 0.2942
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1017s / 729.9156 s
agent0:                 episode reward: -0.6491,                 loss: nan
agent1:                 episode reward: 0.6491,                 loss: 0.2919
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0840s / 730.9995 s
agent0:                 episode reward: 0.3300,                 loss: nan
agent1:                 episode reward: -0.3300,                 loss: 0.2949
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0777s / 732.0772 s
agent0:                 episode reward: -1.1508,                 loss: nan
agent1:                 episode reward: 1.1508,                 loss: 0.2942
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0729s / 733.1501 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: -0.2674,                 loss: nan
agent1:                 episode reward: 0.2674,                 loss: 0.2909
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0942s / 734.2443 s
agent0:                 episode reward: -0.3305,                 loss: nan
agent1:                 episode reward: 0.3305,                 loss: 0.2930
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0798s / 735.3241 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: 0.2925
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0843s / 736.4085 s
agent0:                 episode reward: 0.1016,                 loss: nan
agent1:                 episode reward: -0.1016,                 loss: 0.3232
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0962s / 737.5046 s
agent0:                 episode reward: -0.9671,                 loss: nan
agent1:                 episode reward: 0.9671,                 loss: 0.3308
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1439s / 738.6485 s
agent0:                 episode reward: -0.9083,                 loss: nan
agent1:                 episode reward: 0.9083,                 loss: 0.3295
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0799s / 739.7284 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3283
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0966s / 740.8250 s
agent0:                 episode reward: -0.1544,                 loss: nan
agent1:                 episode reward: 0.1544,                 loss: 0.3280
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0801s / 741.9051 s
agent0:                 episode reward: 0.4883,                 loss: nan
agent1:                 episode reward: -0.4883,                 loss: 0.3265
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0768s / 742.9819 s
agent0:                 episode reward: 0.5182,                 loss: nan
agent1:                 episode reward: -0.5182,                 loss: 0.3291
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0916s / 744.0735 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.3265
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0773s / 745.1508 s
agent0:                 episode reward: 0.7230,                 loss: nan
agent1:                 episode reward: -0.7230,                 loss: 0.3267
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0816s / 746.2324 s
agent0:                 episode reward: 0.2003,                 loss: nan
agent1:                 episode reward: -0.2003,                 loss: 0.3253
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0980s / 747.3305 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3468
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0863s / 748.4167 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.3462
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1279s / 749.5447 s
agent0:                 episode reward: -0.4549,                 loss: nan
agent1:                 episode reward: 0.4549,                 loss: 0.3450
