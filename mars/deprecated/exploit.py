from utils.func import LoadYAML2Dict
from env.import_env import make_env
from rollout import rollout
from rl.algorithm import *

### Load configurations
# yaml_file = 'confs/gym_cartpolev1_dqn'
# yaml_file = 'confs/gym_cartpolev1_ppo'
yaml_file = 'confs/pettingzoo_boxingv1_selfplay_dqn'
# yaml_file = 'confs/pettingzoo_surroundv1_selfplay_dqn' 
# yaml_file = 'confs/slimevolley_slimevolleyv0_dqn'
# yaml_file = 'confs/slimevolley_slimevolleyv0_ppo'
# yaml_file = 'confs/slimevolley_slimevolleyv0_nash_dqn_exploiter'


args = LoadYAML2Dict(yaml_file, toAttr=True)
print(args)

## Change/specify some arguments if necessary
args.against_baseline = False
args.test = False
args.exploit = True
# args.render = True
# args.load_model_full_path = '../model/slimevolley_SlimeVolley-v0_selfplay_DQN_0/1'
# args.load_model_full_path = '../model/slimevolley_SlimeVolley-v0_selfplay_DQN_20210720065155/1'
# args.load_model_full_path = '../data/model/20211109_1530/pettingzoo_surroundv1_selfplay_dqn/1'
# args.load_model_full_path = '../model/pettingzoo_boxing_v1_selfplay_DQN_20211105172837/1'
args.load_model_full_path = '../data/model/20211109_1530/pettingzoo_boxing_v1_selfplay/1'

### Create env
env = make_env(args)
print(env)

### Specify models for each agent
# args.net_architecture['hidden_dim_list'] = [1024, 1024, 1024, 1024]  
trained_model = eval(args.algorithm)(env, args)
args.net_architecture['hidden_dim_list'] = [64, 64, 64]
exploiter = DQN(env, args)
exploiter.reinit()
trained_model.fix()

model = MultiAgent(env, [trained_model, exploiter], args)

### Rollout
rollout(env, model, args)