pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fb263198050>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.037 0.037 0.037 ... 0.037 0.037 0.037]
 [0.037 0.037 0.037 ... 0.037 0.037 0.037]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '18640' '19318' '19446']
 ['193' '5289' '7712' ... '18710' '19358' '19474']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_20000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_20000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_20000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 4.8413s / 4.8413 s
agent0:                 episode reward: 1.8927,                 loss: nan
agent1:                 episode reward: -1.8927,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7598s / 11.6011 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7471s / 18.3482 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.2169s / 24.5651 s
agent0:                 episode reward: -0.0938,                 loss: nan
agent1:                 episode reward: 0.0938,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.3908s / 30.9559 s
agent0:                 episode reward: 0.0578,                 loss: nan
agent1:                 episode reward: -0.0578,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.3678s / 38.3236 s
agent0:                 episode reward: -0.0224,                 loss: nan
agent1:                 episode reward: 0.0224,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8633s / 45.1869 s
agent0:                 episode reward: -0.1636,                 loss: nan
agent1:                 episode reward: 0.1636,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.4642s / 52.6511 s
agent0:                 episode reward: 0.4286,                 loss: nan
agent1:                 episode reward: -0.4286,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2619s / 59.9130 s
agent0:                 episode reward: -0.2185,                 loss: nan
agent1:                 episode reward: 0.2185,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.7706s / 67.6836 s
agent0:                 episode reward: 0.2451,                 loss: nan
agent1:                 episode reward: -0.2451,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8625s / 74.5461 s
agent0:                 episode reward: 0.1484,                 loss: nan
agent1:                 episode reward: -0.1484,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.7865s / 172.3326 s
agent0:                 episode reward: 0.6362,                 loss: nan
agent1:                 episode reward: -0.6362,                 loss: 0.1764
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6334s / 419.9660 s
agent0:                 episode reward: -0.0667,                 loss: nan
agent1:                 episode reward: 0.0667,                 loss: 0.1720
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7188s / 662.6848 s
agent0:                 episode reward: -0.0190,                 loss: nan
agent1:                 episode reward: 0.0190,                 loss: 0.1665
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6615s / 905.3464 s
agent0:                 episode reward: 0.0488,                 loss: nan
agent1:                 episode reward: -0.0488,                 loss: 0.1630
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.0220s / 1142.3684 s
agent0:                 episode reward: 0.4486,                 loss: nan
agent1:                 episode reward: -0.4486,                 loss: 0.1602
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1293s / 1387.4976 s
agent0:                 episode reward: 0.1816,                 loss: nan
agent1:                 episode reward: -0.1816,                 loss: 0.1563
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7602s / 1630.2578 s
agent0:                 episode reward: 0.0907,                 loss: nan
agent1:                 episode reward: -0.0907,                 loss: 0.1522
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8087s / 1879.0666 s
agent0:                 episode reward: 0.0608,                 loss: nan
agent1:                 episode reward: -0.0608,                 loss: 0.1502
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9254s / 2121.9920 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1483
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6382s / 2361.6301 s
agent0:                 episode reward: -0.0641,                 loss: nan
agent1:                 episode reward: 0.0641,                 loss: 0.1456
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9260s / 2599.5561 s
agent0:                 episode reward: -0.1229,                 loss: nan
agent1:                 episode reward: 0.1229,                 loss: 0.1439
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6660s / 2840.2222 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.1439
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5502s / 3091.7723 s
agent0:                 episode reward: 0.3255,                 loss: nan
agent1:                 episode reward: -0.3255,                 loss: 0.1428
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6966s / 3333.4689 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.1434
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8049s / 3579.2739 s
agent0:                 episode reward: -0.1268,                 loss: nan
agent1:                 episode reward: 0.1268,                 loss: 0.1442
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9476s / 3824.2215 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.1429
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5326s / 4068.7541 s
agent0:                 episode reward: -0.2005,                 loss: nan
agent1:                 episode reward: 0.2005,                 loss: 0.1426
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5806s / 4309.3347 s
agent0:                 episode reward: -0.2247,                 loss: nan
agent1:                 episode reward: 0.2247,                 loss: 0.1420
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6666s / 4553.0013 s
agent0:                 episode reward: -0.1664,                 loss: nan
agent1:                 episode reward: 0.1664,                 loss: 0.1404
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1821s / 4799.1834 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: 0.1404
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9859s / 5051.1693 s
agent0:                 episode reward: -0.0559,                 loss: nan
agent1:                 episode reward: 0.0559,                 loss: 0.1402
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7266s / 5295.8959 s
agent0:                 episode reward: 0.0430,                 loss: nan
agent1:                 episode reward: -0.0430,                 loss: 0.1398
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1298s / 5536.0258 s
agent0:                 episode reward: -0.0177,                 loss: nan
agent1:                 episode reward: 0.0177,                 loss: 0.1397
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3665s / 5781.3922 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: 0.1392
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3737s / 6026.7659 s
agent0:                 episode reward: -0.0669,                 loss: nan
agent1:                 episode reward: 0.0669,                 loss: 0.1395
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8432s / 6274.6091 s
agent0:                 episode reward: -0.0204,                 loss: nan
agent1:                 episode reward: 0.0204,                 loss: 0.1412
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2867s / 6515.8959 s
agent0:                 episode reward: 0.0391,                 loss: nan
agent1:                 episode reward: -0.0391,                 loss: 0.1403
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7101s / 6760.6060 s
agent0:                 episode reward: -0.1499,                 loss: nan
agent1:                 episode reward: 0.1499,                 loss: 0.1393
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0888s / 7010.6948 s
agent0:                 episode reward: -0.1514,                 loss: nan
agent1:                 episode reward: 0.1514,                 loss: 0.1387
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3625s / 7251.0573 s
agent0:                 episode reward: -0.0245,                 loss: nan
agent1:                 episode reward: 0.0245,                 loss: 0.1373
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7236s / 7494.7809 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.1372
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7636s / 7739.5445 s
agent0:                 episode reward: -0.1630,                 loss: nan
agent1:                 episode reward: 0.1630,                 loss: 0.1371
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.9238s / 7976.4683 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.1383
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0858s / 8219.5541 s
agent0:                 episode reward: 0.1691,                 loss: nan
agent1:                 episode reward: -0.1691,                 loss: 0.1374
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0461s / 8463.6001 s
agent0:                 episode reward: 0.2023,                 loss: nan
agent1:                 episode reward: -0.2023,                 loss: 0.1376
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1327s / 8709.7329 s
agent0:                 episode reward: 0.1393,                 loss: nan
agent1:                 episode reward: -0.1393,                 loss: 0.1358
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8376s / 8955.5705 s
agent0:                 episode reward: 0.4357,                 loss: nan
agent1:                 episode reward: -0.4357,                 loss: 0.1347
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5593s / 9202.1299 s
agent0:                 episode reward: 0.2508,                 loss: nan
agent1:                 episode reward: -0.2508,                 loss: 0.1359
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8642s / 9442.9941 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.1343
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0810s / 9687.0751 s
agent0:                 episode reward: -0.0766,                 loss: nan
agent1:                 episode reward: 0.0766,                 loss: 0.1352
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4290s / 9936.5040 s
agent0:                 episode reward: -0.1086,                 loss: nan
agent1:                 episode reward: 0.1086,                 loss: 0.1339
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8327s / 10186.3368 s
agent0:                 episode reward: 0.1392,                 loss: nan
agent1:                 episode reward: -0.1392,                 loss: 0.1343
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4290s / 10432.7658 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: 0.1358
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3101s / 10675.0759 s
agent0:                 episode reward: -0.0607,                 loss: nan
agent1:                 episode reward: 0.0607,                 loss: 0.1335
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8499s / 10916.9258 s
agent0:                 episode reward: -0.1379,                 loss: nan
agent1:                 episode reward: 0.1379,                 loss: 0.1339
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5935s / 11164.5193 s
agent0:                 episode reward: 0.0976,                 loss: nan
agent1:                 episode reward: -0.0976,                 loss: 0.1326
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5462s / 11412.0656 s
agent0:                 episode reward: 0.1992,                 loss: nan
agent1:                 episode reward: -0.1992,                 loss: 0.1351
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6348s / 11664.7004 s
agent0:                 episode reward: -0.0461,                 loss: nan
agent1:                 episode reward: 0.0461,                 loss: 0.1342
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6110s / 11914.3114 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1322
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5225s / 12154.8339 s
agent0:                 episode reward: 0.3711,                 loss: nan
agent1:                 episode reward: -0.3711,                 loss: 0.1323
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8276s / 12407.6615 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.1318
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5451s / 12654.2065 s
agent0:                 episode reward: -0.1467,                 loss: nan
agent1:                 episode reward: 0.1467,                 loss: 0.1336
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.9146s / 12893.1211 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.1333
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8338s / 13135.9549 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.1328
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7373s / 13379.6922 s
agent0:                 episode reward: 0.3046,                 loss: nan
agent1:                 episode reward: -0.3046,                 loss: 0.1313
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7131s / 13625.4053 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: 0.1324
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5711s / 13878.9763 s
agent0:                 episode reward: -0.3978,                 loss: nan
agent1:                 episode reward: 0.3978,                 loss: 0.1340
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8127s / 14132.7891 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.1333
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2991s / 14381.0881 s
agent0:                 episode reward: -0.6776,                 loss: nan
agent1:                 episode reward: 0.6776,                 loss: 0.1321
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7888s / 14632.8769 s
agent0:                 episode reward: -0.2157,                 loss: nan
agent1:                 episode reward: 0.2157,                 loss: 0.1325
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0334s / 14879.9103 s
agent0:                 episode reward: -0.1141,                 loss: nan
agent1:                 episode reward: 0.1141,                 loss: 0.1332
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3603s / 15134.2706 s
agent0:                 episode reward: 0.2187,                 loss: nan
agent1:                 episode reward: -0.2187,                 loss: 0.1314
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8847s / 15375.1553 s
agent0:                 episode reward: -0.1137,                 loss: nan
agent1:                 episode reward: 0.1137,                 loss: 0.1323
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2718s / 15622.4272 s
agent0:                 episode reward: -0.2789,                 loss: nan
agent1:                 episode reward: 0.2789,                 loss: 0.1319
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9651s / 15870.3923 s
agent0:                 episode reward: 0.2877,                 loss: nan
agent1:                 episode reward: -0.2877,                 loss: 0.1308
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9252s / 16117.3175 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.1312
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6431s / 16360.9606 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.1309
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5610s / 16609.5216 s
agent0:                 episode reward: -0.2555,                 loss: nan
agent1:                 episode reward: 0.2555,                 loss: 0.1320
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6125s / 16862.1340 s
agent0:                 episode reward: 0.0055,                 loss: nan
agent1:                 episode reward: -0.0055,                 loss: 0.1327
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8327s / 17104.9667 s
agent0:                 episode reward: -0.1215,                 loss: nan
agent1:                 episode reward: 0.1215,                 loss: 0.1329
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1560s / 17346.1227 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.1319
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6978s / 17599.8205 s
agent0:                 episode reward: -0.2391,                 loss: nan
agent1:                 episode reward: 0.2391,                 loss: 0.1310
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5630s / 17850.3835 s
agent0:                 episode reward: -0.7991,                 loss: nan
agent1:                 episode reward: 0.7991,                 loss: 0.1320
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.7443s / 18107.1278 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.1317
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4351s / 18353.5629 s
agent0:                 episode reward: 0.0035,                 loss: nan
agent1:                 episode reward: -0.0035,                 loss: 0.1313
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7502s / 18600.3131 s
agent0:                 episode reward: -0.0808,                 loss: nan
agent1:                 episode reward: 0.0808,                 loss: 0.1317
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0401s / 18841.3532 s
agent0:                 episode reward: -0.3904,                 loss: nan
agent1:                 episode reward: 0.3904,                 loss: 0.1307
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2826s / 19093.6358 s
agent0:                 episode reward: -0.3255,                 loss: nan
agent1:                 episode reward: 0.3255,                 loss: 0.1310
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7507s / 19338.3865 s
agent0:                 episode reward: -0.1424,                 loss: nan
agent1:                 episode reward: 0.1424,                 loss: 0.1297
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5287s / 19589.9152 s
agent0:                 episode reward: -0.1120,                 loss: nan
agent1:                 episode reward: 0.1120,                 loss: 0.1310
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 232.4838s / 19822.3990 s
agent0:                 episode reward: 0.1069,                 loss: nan
agent1:                 episode reward: -0.1069,                 loss: 0.1305
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6476s / 20071.0466 s
agent0:                 episode reward: -0.5241,                 loss: nan
agent1:                 episode reward: 0.5241,                 loss: 0.1299
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1025s / 20314.1492 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1305
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5020s / 20555.6512 s
agent0:                 episode reward: 0.1509,                 loss: nan
agent1:                 episode reward: -0.1509,                 loss: 0.1308
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0781s / 20807.7293 s
agent0:                 episode reward: 0.0862,                 loss: nan
agent1:                 episode reward: -0.0862,                 loss: 0.1348
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0797s / 21055.8090 s
agent0:                 episode reward: 0.0846,                 loss: nan
agent1:                 episode reward: -0.0846,                 loss: 0.1337
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2599s / 21304.0689 s
agent0:                 episode reward: -0.0395,                 loss: nan
agent1:                 episode reward: 0.0395,                 loss: 0.1342
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6238s / 21549.6928 s
agent0:                 episode reward: 0.0112,                 loss: nan
agent1:                 episode reward: -0.0112,                 loss: 0.1339
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6644s / 21789.3572 s
agent0:                 episode reward: 0.0235,                 loss: nan
agent1:                 episode reward: -0.0235,                 loss: 0.1341
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6661s / 22035.0232 s
agent0:                 episode reward: 0.5044,                 loss: nan
agent1:                 episode reward: -0.5044,                 loss: 0.1349
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4201s / 22276.4433 s
agent0:                 episode reward: -0.1277,                 loss: nan
agent1:                 episode reward: 0.1277,                 loss: 0.1346
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3286s / 22525.7719 s
agent0:                 episode reward: -0.0800,                 loss: nan
agent1:                 episode reward: 0.0800,                 loss: 0.1333
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3865s / 22765.1584 s
agent0:                 episode reward: -0.0160,                 loss: nan
agent1:                 episode reward: 0.0160,                 loss: 0.1320
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7372s / 23001.8956 s
agent0:                 episode reward: -0.1838,                 loss: nan
agent1:                 episode reward: 0.1838,                 loss: 0.1346
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4468s / 23249.3424 s
agent0:                 episode reward: -0.2924,                 loss: nan
agent1:                 episode reward: 0.2924,                 loss: 0.1329
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3766s / 23498.7190 s
agent0:                 episode reward: -0.1346,                 loss: nan
agent1:                 episode reward: 0.1346,                 loss: 0.1322
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 260.6467s / 23759.3657 s
agent0:                 episode reward: -0.0684,                 loss: nan
agent1:                 episode reward: 0.0684,                 loss: 0.1339
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3224s / 24005.6881 s
agent0:                 episode reward: 0.1655,                 loss: nan
agent1:                 episode reward: -0.1655,                 loss: 0.1328
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4716s / 24253.1597 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: 0.1317
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9704s / 24497.1301 s
agent0:                 episode reward: -0.4492,                 loss: nan
agent1:                 episode reward: 0.4492,                 loss: 0.1316
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8126s / 24742.9427 s
agent0:                 episode reward: -0.2601,                 loss: nan
agent1:                 episode reward: 0.2601,                 loss: 0.1318
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.8568s / 24980.7996 s
agent0:                 episode reward: 0.0634,                 loss: nan
agent1:                 episode reward: -0.0634,                 loss: 0.1319
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6769s / 25231.4765 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.1324
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8375s / 25471.3140 s
agent0:                 episode reward: -0.0478,                 loss: nan
agent1:                 episode reward: 0.0478,                 loss: 0.1335
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9271s / 25719.2411 s
agent0:                 episode reward: -0.0829,                 loss: nan
agent1:                 episode reward: 0.0829,                 loss: 0.1307
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6404s / 25967.8815 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: 0.1317
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0585s / 26218.9400 s
agent0:                 episode reward: -0.1191,                 loss: nan
agent1:                 episode reward: 0.1191,                 loss: 0.1312
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2082s / 26465.1482 s
agent0:                 episode reward: -0.0917,                 loss: nan
agent1:                 episode reward: 0.0917,                 loss: 0.1314
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8725s / 26707.0207 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: 0.1323
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9280s / 26956.9487 s
agent0:                 episode reward: 0.1847,                 loss: nan
agent1:                 episode reward: -0.1847,                 loss: 0.1314
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.7987s / 27190.7475 s
agent0:                 episode reward: -0.3682,                 loss: nan
agent1:                 episode reward: 0.3682,                 loss: 0.1311
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2483s / 27442.9958 s
agent0:                 episode reward: 0.1594,                 loss: nan
agent1:                 episode reward: -0.1594,                 loss: 0.1298
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0006s / 27694.9964 s
agent0:                 episode reward: -0.0944,                 loss: nan
agent1:                 episode reward: 0.0944,                 loss: 0.1311
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2357s / 27942.2320 s
agent0:                 episode reward: -0.2582,                 loss: nan
agent1:                 episode reward: 0.2582,                 loss: 0.1302
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0681s / 28190.3001 s
agent0:                 episode reward: -0.2506,                 loss: nan
agent1:                 episode reward: 0.2506,                 loss: 0.1300
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5840s / 28435.8842 s
agent0:                 episode reward: -0.1951,                 loss: nan
agent1:                 episode reward: 0.1951,                 loss: 0.1284
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6106s / 28677.4947 s
agent0:                 episode reward: 0.0338,                 loss: nan
agent1:                 episode reward: -0.0338,                 loss: 0.1297
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8535s / 28924.3482 s
agent0:                 episode reward: -0.1746,                 loss: nan
agent1:                 episode reward: 0.1746,                 loss: 0.1314
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1872s / 29174.5354 s
agent0:                 episode reward: 0.1245,                 loss: nan
agent1:                 episode reward: -0.1245,                 loss: 0.1330
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1224s / 29425.6578 s
agent0:                 episode reward: -0.0211,                 loss: nan
agent1:                 episode reward: 0.0211,                 loss: 0.1322
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8459s / 29674.5037 s
agent0:                 episode reward: -0.1659,                 loss: nan
agent1:                 episode reward: 0.1659,                 loss: 0.1314
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1679s / 29928.6716 s
agent0:                 episode reward: 0.1968,                 loss: nan
agent1:                 episode reward: -0.1968,                 loss: 0.1310
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0810s / 30181.7526 s
agent0:                 episode reward: 0.0744,                 loss: nan
agent1:                 episode reward: -0.0744,                 loss: 0.1303
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6197s / 30428.3723 s
agent0:                 episode reward: 0.0688,                 loss: nan
agent1:                 episode reward: -0.0688,                 loss: 0.1293
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5148s / 30680.8871 s
agent0:                 episode reward: -0.2245,                 loss: nan
agent1:                 episode reward: 0.2245,                 loss: 0.1300
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0890s / 30931.9761 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.1306
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2500s / 31183.2261 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.1305
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9975s / 31432.2236 s
agent0:                 episode reward: -0.0607,                 loss: nan
agent1:                 episode reward: 0.0607,                 loss: 0.1303
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1122s / 31687.3358 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1309
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7367s / 31938.0725 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.1298
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3731s / 32186.4456 s
agent0:                 episode reward: -0.1863,                 loss: nan
agent1:                 episode reward: 0.1863,                 loss: 0.1291
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8708s / 32436.3165 s
agent0:                 episode reward: 0.2095,                 loss: nan
agent1:                 episode reward: -0.2095,                 loss: 0.1304
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1950s / 32682.5115 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.1298
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9036s / 32929.4151 s
agent0:                 episode reward: -0.1346,                 loss: nan
agent1:                 episode reward: 0.1346,                 loss: 0.1301
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7142s / 33181.1294 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.1337
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7355s / 33425.8649 s
agent0:                 episode reward: -0.2570,                 loss: nan
agent1:                 episode reward: 0.2570,                 loss: 0.1342
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2223s / 33677.0872 s
agent0:                 episode reward: -0.0732,                 loss: nan
agent1:                 episode reward: 0.0732,                 loss: 0.1336
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0570s / 33924.1442 s
agent0:                 episode reward: -0.1974,                 loss: nan
agent1:                 episode reward: 0.1974,                 loss: 0.1336
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4187s / 34166.5629 s
agent0:                 episode reward: -0.3748,                 loss: nan
agent1:                 episode reward: 0.3748,                 loss: 0.1338
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0335s / 34408.5964 s
agent0:                 episode reward: 0.1500,                 loss: nan
agent1:                 episode reward: -0.1500,                 loss: 0.1342
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0237s / 34656.6201 s
agent0:                 episode reward: -0.1043,                 loss: nan
agent1:                 episode reward: 0.1043,                 loss: 0.1330
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5471s / 34899.1672 s
agent0:                 episode reward: 0.0792,                 loss: nan
agent1:                 episode reward: -0.0792,                 loss: 0.1333
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3014s / 35145.4687 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.1340
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9000s / 35387.3687 s
agent0:                 episode reward: -0.2429,                 loss: nan
agent1:                 episode reward: 0.2429,                 loss: 0.1341
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8121s / 35637.1808 s
agent0:                 episode reward: -0.2561,                 loss: nan
agent1:                 episode reward: 0.2561,                 loss: 0.1334
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0505s / 35886.2313 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: 0.1329
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0339s / 36125.2652 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.1337
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8070s / 36371.0722 s
agent0:                 episode reward: 0.3574,                 loss: nan
agent1:                 episode reward: -0.3574,                 loss: 0.1336
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7732s / 36608.8454 s
agent0:                 episode reward: 0.0085,                 loss: nan
agent1:                 episode reward: -0.0085,                 loss: 0.1317
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4451s / 36860.2906 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.1328
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3457s / 37108.6363 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: 0.1329
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1906s / 37354.8268 s
agent0:                 episode reward: -0.2368,                 loss: nan
agent1:                 episode reward: 0.2368,                 loss: 0.1341
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8167s / 37597.6435 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1326
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3461s / 37839.9896 s
agent0:                 episode reward: -0.1242,                 loss: nan
agent1:                 episode reward: 0.1242,                 loss: 0.1336
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0348s / 38090.0244 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.1347
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8224s / 38340.8469 s
agent0:                 episode reward: 0.3144,                 loss: nan
agent1:                 episode reward: -0.3144,                 loss: 0.1349
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5805s / 38585.4274 s
agent0:                 episode reward: -0.3027,                 loss: nan
agent1:                 episode reward: 0.3027,                 loss: 0.1337
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4647s / 38831.8921 s
agent0:                 episode reward: -0.3949,                 loss: nan
agent1:                 episode reward: 0.3949,                 loss: 0.1339
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3210s / 39085.2131 s
agent0:                 episode reward: -0.2587,                 loss: nan
agent1:                 episode reward: 0.2587,                 loss: 0.1328
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7398s / 39331.9529 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.1330
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6531s / 39579.6060 s
agent0:                 episode reward: 0.0307,                 loss: nan
agent1:                 episode reward: -0.0307,                 loss: 0.1319
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5682s / 39827.1742 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.1339
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6113s / 40077.7855 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.1345
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1918s / 40330.9773 s
agent0:                 episode reward: 0.1410,                 loss: nan
agent1:                 episode reward: -0.1410,                 loss: 0.1341
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5149s / 40583.4922 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.1330
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9234s / 40830.4156 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.1325
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7829s / 41080.1985 s
agent0:                 episode reward: -0.2878,                 loss: nan
agent1:                 episode reward: 0.2878,                 loss: 0.1341
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0402s / 41327.2387 s
agent0:                 episode reward: -0.0296,                 loss: nan
agent1:                 episode reward: 0.0296,                 loss: 0.1341
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5335s / 41577.7721 s
agent0:                 episode reward: -0.0973,                 loss: nan
agent1:                 episode reward: 0.0973,                 loss: 0.1348
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7469s / 41826.5190 s
agent0:                 episode reward: -0.2563,                 loss: nan
agent1:                 episode reward: 0.2563,                 loss: 0.1357
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3279s / 42079.8470 s
agent0:                 episode reward: -0.0896,                 loss: nan
agent1:                 episode reward: 0.0896,                 loss: 0.1364
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7743s / 42322.6212 s
agent0:                 episode reward: -0.2089,                 loss: nan
agent1:                 episode reward: 0.2089,                 loss: 0.1351
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3639s / 42566.9851 s
agent0:                 episode reward: -0.2434,                 loss: nan
agent1:                 episode reward: 0.2434,                 loss: 0.1362
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3506s / 42815.3356 s
agent0:                 episode reward: 0.0982,                 loss: nan
agent1:                 episode reward: -0.0982,                 loss: 0.1341
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1836s / 43060.5193 s
agent0:                 episode reward: -0.1712,                 loss: nan
agent1:                 episode reward: 0.1712,                 loss: 0.1369
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6338s / 43302.1531 s
agent0:                 episode reward: 0.0462,                 loss: nan
agent1:                 episode reward: -0.0462,                 loss: 0.1368
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7801s / 43553.9332 s
agent0:                 episode reward: -0.1402,                 loss: nan
agent1:                 episode reward: 0.1402,                 loss: 0.1342
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1713s / 43809.1045 s
agent0:                 episode reward: -0.1514,                 loss: nan
agent1:                 episode reward: 0.1514,                 loss: 0.1350
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1550s / 44056.2595 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: 0.1331
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9476s / 44307.2072 s
agent0:                 episode reward: 0.1566,                 loss: nan
agent1:                 episode reward: -0.1566,                 loss: 0.1357
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2507s / 44550.4579 s
agent0:                 episode reward: -0.0103,                 loss: nan
agent1:                 episode reward: 0.0103,                 loss: 0.1345
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4718s / 44799.9297 s
agent0:                 episode reward: -0.2017,                 loss: nan
agent1:                 episode reward: 0.2017,                 loss: 0.1360
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7755s / 45053.7052 s
agent0:                 episode reward: -0.0514,                 loss: nan
agent1:                 episode reward: 0.0514,                 loss: 0.1369
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4065s / 45300.1117 s
agent0:                 episode reward: -0.2119,                 loss: nan
agent1:                 episode reward: 0.2119,                 loss: 0.1335
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6743s / 45544.7860 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.1329
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1929s / 45796.9790 s
agent0:                 episode reward: -0.1032,                 loss: nan
agent1:                 episode reward: 0.1032,                 loss: 0.1368
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4865s / 46046.4655 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1352
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0844s / 46297.5499 s
agent0:                 episode reward: -0.4837,                 loss: nan
agent1:                 episode reward: 0.4837,                 loss: 0.1343
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1570s / 46548.7069 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.1356
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5224s / 46799.2294 s
agent0:                 episode reward: -0.0673,                 loss: nan
agent1:                 episode reward: 0.0673,                 loss: 0.1344
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4817s / 47049.7110 s
agent0:                 episode reward: -0.4389,                 loss: nan
agent1:                 episode reward: 0.4389,                 loss: 0.1354
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1621s / 47297.8731 s
agent0:                 episode reward: 0.0248,                 loss: nan
agent1:                 episode reward: -0.0248,                 loss: 0.1340
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1117s / 47547.9848 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.1330
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2677s / 47788.2526 s
agent0:                 episode reward: -0.0674,                 loss: nan
agent1:                 episode reward: 0.0674,                 loss: 0.1349
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5033s / 48031.7559 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.1334
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0749s / 48281.8308 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.1342
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5297s / 48530.3605 s
agent0:                 episode reward: 0.0528,                 loss: nan
agent1:                 episode reward: -0.0528,                 loss: 0.1338
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9448s / 48771.3053 s
agent0:                 episode reward: -0.3554,                 loss: nan
agent1:                 episode reward: 0.3554,                 loss: 0.1360
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5804s / 49023.8857 s
agent0:                 episode reward: -0.4797,                 loss: nan
agent1:                 episode reward: 0.4797,                 loss: 0.1325
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4032s / 49272.2889 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1326
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3752s / 49519.6641 s
agent0:                 episode reward: 0.0951,                 loss: nan
agent1:                 episode reward: -0.0951,                 loss: 0.1326
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4168s / 49767.0809 s
agent0:                 episode reward: 0.1250,                 loss: nan
agent1:                 episode reward: -0.1250,                 loss: 0.1319
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6568s / 50017.7377 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.1331
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 229.8327s / 50247.5703 s
agent0:                 episode reward: -0.0899,                 loss: nan
agent1:                 episode reward: 0.0899,                 loss: 0.1339
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4320s / 50490.0023 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1343
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7124s / 50731.7148 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.1325
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9505s / 50981.6653 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1327
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5859s / 51222.2512 s
agent0:                 episode reward: -0.5251,                 loss: nan
agent1:                 episode reward: 0.5251,                 loss: 0.1330
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0960s / 51463.3472 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.1331
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5053s / 51706.8526 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.1312
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0914s / 51956.9440 s
agent0:                 episode reward: -0.1646,                 loss: nan
agent1:                 episode reward: 0.1646,                 loss: 0.1318
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9815s / 52207.9255 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: 0.1315
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8258s / 52460.7513 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.1321
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8843s / 52706.6356 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.1322
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7655s / 52952.4011 s
agent0:                 episode reward: 0.0155,                 loss: nan
agent1:                 episode reward: -0.0155,                 loss: 0.1307
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8043s / 53206.2054 s
agent0:                 episode reward: -0.1620,                 loss: nan
agent1:                 episode reward: 0.1620,                 loss: 0.1312
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8534s / 53450.0587 s
agent0:                 episode reward: 0.1222,                 loss: nan
agent1:                 episode reward: -0.1222,                 loss: 0.1329
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7119s / 53696.7706 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1320
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6357s / 53941.4064 s
agent0:                 episode reward: -0.4576,                 loss: nan
agent1:                 episode reward: 0.4576,                 loss: 0.1310
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6343s / 54197.0406 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1300
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3020s / 54444.3426 s
agent0:                 episode reward: -0.2988,                 loss: nan
agent1:                 episode reward: 0.2988,                 loss: 0.1296
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0715s / 54690.4141 s
agent0:                 episode reward: -0.3330,                 loss: nan
agent1:                 episode reward: 0.3330,                 loss: 0.1305
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6686s / 54933.0827 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.1304
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7351s / 55176.8178 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: 0.1313
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9977s / 55432.8155 s
agent0:                 episode reward: 0.0725,                 loss: nan
agent1:                 episode reward: -0.0725,                 loss: 0.1310
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7740s / 55682.5895 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.1317
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9329s / 55927.5224 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: 0.1311
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8575s / 56176.3799 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.1297
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5489s / 56422.9288 s
agent0:                 episode reward: -0.0455,                 loss: nan
agent1:                 episode reward: 0.0455,                 loss: 0.1305
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0405s / 56669.9694 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.1310
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0802s / 56922.0496 s
agent0:                 episode reward: -0.1377,                 loss: nan
agent1:                 episode reward: 0.1377,                 loss: 0.1323
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5603s / 57175.6099 s
agent0:                 episode reward: -0.7900,                 loss: nan
agent1:                 episode reward: 0.7900,                 loss: 0.1299
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3426s / 57416.9525 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.1293
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0637s / 57673.0163 s
agent0:                 episode reward: -0.4299,                 loss: nan
agent1:                 episode reward: 0.4299,                 loss: 0.1312
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1142s / 57921.1305 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1287
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5802s / 58166.7107 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.1292
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4971s / 58415.2078 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.1309
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6769s / 58655.8848 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1308
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3197s / 58901.2045 s
agent0:                 episode reward: -0.8768,                 loss: nan
agent1:                 episode reward: 0.8768,                 loss: 0.1305
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.0203s / 59134.2248 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.1300
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4860s / 59384.7107 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.1301
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4778s / 59630.1885 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.1310
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2482s / 59878.4367 s
agent0:                 episode reward: -0.5934,                 loss: nan
agent1:                 episode reward: 0.5934,                 loss: 0.1290
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5092s / 60126.9459 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.1301
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8245s / 60375.7704 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.1307
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 259.3724s / 60635.1428 s
agent0:                 episode reward: -0.2079,                 loss: nan
agent1:                 episode reward: 0.2079,                 loss: 0.1299
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0911s / 60876.2339 s
agent0:                 episode reward: 0.1477,                 loss: nan
agent1:                 episode reward: -0.1477,                 loss: 0.1298
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8591s / 61123.0931 s
agent0:                 episode reward: 0.0417,                 loss: nan
agent1:                 episode reward: -0.0417,                 loss: 0.1293
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9143s / 61370.0073 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.1317
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6520s / 61615.6593 s
agent0:                 episode reward: -0.3534,                 loss: nan
agent1:                 episode reward: 0.3534,                 loss: 0.1304
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4798s / 61855.1391 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.1329
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5098s / 62105.6489 s
agent0:                 episode reward: -0.4929,                 loss: nan
agent1:                 episode reward: 0.4929,                 loss: 0.1335
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9400s / 62356.5890 s
agent0:                 episode reward: -0.2987,                 loss: nan
agent1:                 episode reward: 0.2987,                 loss: 0.1309
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3760s / 62609.9649 s
agent0:                 episode reward: -0.1911,                 loss: nan
agent1:                 episode reward: 0.1911,                 loss: 0.1309
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9918s / 62854.9567 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.1321
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4351s / 63098.3918 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.1317
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8036s / 63343.1954 s
agent0:                 episode reward: -0.0382,                 loss: nan
agent1:                 episode reward: 0.0382,                 loss: 0.1313
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0874s / 63595.2828 s
agent0:                 episode reward: 0.0605,                 loss: nan
agent1:                 episode reward: -0.0605,                 loss: 0.1324
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9602s / 63847.2430 s
agent0:                 episode reward: -0.3529,                 loss: nan
agent1:                 episode reward: 0.3529,                 loss: 0.1300
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5786s / 64102.8216 s
agent0:                 episode reward: -0.4712,                 loss: nan
agent1:                 episode reward: 0.4712,                 loss: 0.1303
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3453s / 64357.1669 s
agent0:                 episode reward: -0.1007,                 loss: nan
agent1:                 episode reward: 0.1007,                 loss: 0.1319
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6417s / 64606.8086 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.1322
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4120s / 64855.2206 s
agent0:                 episode reward: -0.3449,                 loss: nan
agent1:                 episode reward: 0.3449,                 loss: 0.1329
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3892s / 65101.6098 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.1316
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1132s / 65351.7230 s
agent0:                 episode reward: -0.2795,                 loss: nan
agent1:                 episode reward: 0.2795,                 loss: 0.1326
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2027s / 65603.9256 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: 0.1319
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8389s / 65849.7645 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.1301
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3666s / 66099.1311 s
agent0:                 episode reward: -0.0340,                 loss: nan
agent1:                 episode reward: 0.0340,                 loss: 0.1286
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2767s / 66346.4078 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.1294
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8243s / 66600.2322 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1275
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8243s / 66846.0565 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.1288
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9736s / 67093.0301 s
agent0:                 episode reward: -0.3767,                 loss: nan
agent1:                 episode reward: 0.3767,                 loss: 0.1283
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3934s / 67345.4236 s
agent0:                 episode reward: -0.1973,                 loss: nan
agent1:                 episode reward: 0.1973,                 loss: 0.1289
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7095s / 67592.1330 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1299
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9123s / 67839.0453 s
agent0:                 episode reward: -0.2146,                 loss: nan
agent1:                 episode reward: 0.2146,                 loss: 0.1282
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6195s / 68089.6647 s
agent0:                 episode reward: -0.0980,                 loss: nan
agent1:                 episode reward: 0.0980,                 loss: 0.1283
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8667s / 68335.5315 s
agent0:                 episode reward: -0.1756,                 loss: nan
agent1:                 episode reward: 0.1756,                 loss: 0.1284
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5743s / 68587.1058 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.1301
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8872s / 68838.9931 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.1291
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1351s / 69086.1282 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.1285
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5005s / 69332.6286 s
agent0:                 episode reward: -0.7810,                 loss: nan
agent1:                 episode reward: 0.7810,                 loss: 0.1291
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6479s / 69586.2765 s
agent0:                 episode reward: -0.2549,                 loss: nan
agent1:                 episode reward: 0.2549,                 loss: 0.1293
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6359s / 69830.9124 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.1279
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7497s / 70076.6621 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.1296
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7305s / 70322.3926 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.1283
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7316s / 70567.1243 s
agent0:                 episode reward: -0.4217,                 loss: nan
agent1:                 episode reward: 0.4217,                 loss: 0.1296
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5291s / 70818.6534 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.1302
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4531s / 71063.1066 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.1304
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1024s / 71303.2089 s
agent0:                 episode reward: -0.4654,                 loss: nan
agent1:                 episode reward: 0.4654,                 loss: 0.1290
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1392s / 71552.3481 s
agent0:                 episode reward: -0.2779,                 loss: nan
agent1:                 episode reward: 0.2779,                 loss: 0.1297
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5486s / 71802.8968 s
agent0:                 episode reward: -0.9135,                 loss: nan
agent1:                 episode reward: 0.9135,                 loss: 0.1290
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7975s / 72045.6943 s
agent0:                 episode reward: -0.4926,                 loss: nan
agent1:                 episode reward: 0.4926,                 loss: 0.1301
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8396s / 72292.5338 s
agent0:                 episode reward: -0.5547,                 loss: nan
agent1:                 episode reward: 0.5547,                 loss: 0.1282
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0887s / 72543.6225 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.1309
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4285s / 72796.0510 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.1297
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6202s / 73046.6713 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1305
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5324s / 73299.2036 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.1308
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 260.8405s / 73560.0441 s
agent0:                 episode reward: -0.1897,                 loss: nan
agent1:                 episode reward: 0.1897,                 loss: 0.1282
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5575s / 73801.6017 s
agent0:                 episode reward: -0.4826,                 loss: nan
agent1:                 episode reward: 0.4826,                 loss: 0.1266
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6236s / 74050.2252 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.1296
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1159s / 74298.3411 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: 0.1277
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6556s / 74549.9967 s
agent0:                 episode reward: 0.0733,                 loss: nan
agent1:                 episode reward: -0.0733,                 loss: 0.1285
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6783s / 74798.6750 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.1294
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1969s / 75043.8719 s
agent0:                 episode reward: -0.1688,                 loss: nan
agent1:                 episode reward: 0.1688,                 loss: 0.1279
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4882s / 75292.3601 s
agent0:                 episode reward: -0.2671,                 loss: nan
agent1:                 episode reward: 0.2671,                 loss: 0.1277
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5815s / 75545.9416 s
agent0:                 episode reward: -0.2511,                 loss: nan
agent1:                 episode reward: 0.2511,                 loss: 0.1289
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9428s / 75801.8844 s
agent0:                 episode reward: -0.0244,                 loss: nan
agent1:                 episode reward: 0.0244,                 loss: 0.1264
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1183s / 76050.0027 s
agent0:                 episode reward: -0.2049,                 loss: nan
agent1:                 episode reward: 0.2049,                 loss: 0.1294
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1054s / 76299.1081 s
agent0:                 episode reward: -0.5308,                 loss: nan
agent1:                 episode reward: 0.5308,                 loss: 0.1278
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2851s / 76538.3933 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.1281
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5054s / 76795.8986 s
agent0:                 episode reward: 0.1242,                 loss: nan
agent1:                 episode reward: -0.1242,                 loss: 0.1288
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5849s / 77046.4836 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.1281
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8804s / 77295.3640 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.1307
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8453s / 77550.2093 s
agent0:                 episode reward: -0.3852,                 loss: nan
agent1:                 episode reward: 0.3852,                 loss: 0.1291
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1468s / 77797.3561 s
agent0:                 episode reward: -0.4531,                 loss: nan
agent1:                 episode reward: 0.4531,                 loss: 0.1277
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0296s / 78049.3857 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.1291
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9594s / 78303.3451 s
agent0:                 episode reward: -0.3539,                 loss: nan
agent1:                 episode reward: 0.3539,                 loss: 0.1290
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4180s / 78552.7632 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1285
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5690s / 78802.3322 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1263
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7720s / 79056.1041 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.1285
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7687s / 79300.8729 s
agent0:                 episode reward: -0.4183,                 loss: nan
agent1:                 episode reward: 0.4183,                 loss: 0.1273
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3517s / 79555.2246 s
agent0:                 episode reward: -0.2705,                 loss: nan
agent1:                 episode reward: 0.2705,                 loss: 0.1277
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5692s / 79800.7938 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.1280
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2191s / 80045.0129 s
agent0:                 episode reward: 0.0832,                 loss: nan
agent1:                 episode reward: -0.0832,                 loss: 0.1290
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6282s / 80293.6411 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.1261
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2484s / 80541.8895 s
agent0:                 episode reward: -0.6377,                 loss: nan
agent1:                 episode reward: 0.6377,                 loss: 0.1293
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9052s / 80796.7947 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.1288
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9552s / 81050.7500 s
agent0:                 episode reward: -0.1062,                 loss: nan
agent1:                 episode reward: 0.1062,                 loss: 0.1284
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0775s / 81299.8275 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.1287
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.9327s / 81557.7601 s
agent0:                 episode reward: 0.2094,                 loss: nan
agent1:                 episode reward: -0.2094,                 loss: 0.1268
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8191s / 81803.5793 s
agent0:                 episode reward: -0.3601,                 loss: nan
agent1:                 episode reward: 0.3601,                 loss: 0.1293
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8223s / 82058.4015 s
agent0:                 episode reward: -0.9023,                 loss: nan
agent1:                 episode reward: 0.9023,                 loss: 0.1268
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3526s / 82303.7541 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.1288
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0907s / 82559.8448 s
agent0:                 episode reward: -0.5047,                 loss: nan
agent1:                 episode reward: 0.5047,                 loss: 0.1286
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1548s / 82809.9996 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.1302
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3636s / 83056.3632 s
agent0:                 episode reward: -0.2059,                 loss: nan
agent1:                 episode reward: 0.2059,                 loss: 0.1292
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1303s / 83304.4935 s
agent0:                 episode reward: 0.1662,                 loss: nan
agent1:                 episode reward: -0.1662,                 loss: 0.1274
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7002s / 83557.1938 s
agent0:                 episode reward: -0.3363,                 loss: nan
agent1:                 episode reward: 0.3363,                 loss: 0.1305
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6021s / 83797.7958 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.1282
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6010s / 84043.3969 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.1282
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3160s / 84291.7129 s
agent0:                 episode reward: 0.0258,                 loss: nan
agent1:                 episode reward: -0.0258,                 loss: 0.1286
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.9388s / 84549.6517 s
agent0:                 episode reward: -0.0409,                 loss: nan
agent1:                 episode reward: 0.0409,                 loss: 0.1284
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6643s / 84802.3160 s
agent0:                 episode reward: -0.4875,                 loss: nan
agent1:                 episode reward: 0.4875,                 loss: 0.1285
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0720s / 85054.3880 s
agent0:                 episode reward: -0.2770,                 loss: nan
agent1:                 episode reward: 0.2770,                 loss: 0.1296
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6440s / 85300.0320 s
agent0:                 episode reward: 0.0797,                 loss: nan
agent1:                 episode reward: -0.0797,                 loss: 0.1284
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3875s / 85541.4195 s
agent0:                 episode reward: -0.1558,                 loss: nan
agent1:                 episode reward: 0.1558,                 loss: 0.1280
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4750s / 85785.8945 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.1285
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1266s / 86038.0211 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.1290
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4890s / 86291.5101 s
agent0:                 episode reward: -0.1815,                 loss: nan
agent1:                 episode reward: 0.1815,                 loss: 0.1291
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4226s / 86542.9327 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: 0.1275
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4678s / 86792.4005 s
agent0:                 episode reward: 0.0838,                 loss: nan
agent1:                 episode reward: -0.0838,                 loss: 0.1277
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3119s / 87042.7123 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.1281
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3174s / 87285.0297 s
agent0:                 episode reward: -0.3106,                 loss: nan
agent1:                 episode reward: 0.3106,                 loss: 0.1291
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3713s / 87534.4011 s
agent0:                 episode reward: -0.4027,                 loss: nan
agent1:                 episode reward: 0.4027,                 loss: 0.1271
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.3411s / 87792.7422 s
agent0:                 episode reward: -0.4336,                 loss: nan
agent1:                 episode reward: 0.4336,                 loss: 0.1281
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4646s / 88045.2068 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: 0.1283
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2608s / 88287.4675 s
agent0:                 episode reward: -0.2469,                 loss: nan
agent1:                 episode reward: 0.2469,                 loss: 0.1274
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1360s / 88539.6036 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1283
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7762s / 88794.3797 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.1284
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0092s / 89038.3889 s
agent0:                 episode reward: -0.4815,                 loss: nan
agent1:                 episode reward: 0.4815,                 loss: 0.1271
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0539s / 89287.4427 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.1284
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5644s / 89542.0071 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1287
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1374s / 89792.1446 s
agent0:                 episode reward: -0.0975,                 loss: nan
agent1:                 episode reward: 0.0975,                 loss: 0.1291
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.2336s / 90048.3782 s