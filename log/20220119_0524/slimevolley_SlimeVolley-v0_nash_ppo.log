pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 753.0,                last time consumption/overall running time: 8.1355s / 8.1355 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0181
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0333
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 111.2156s / 119.3511 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0180
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0280
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 614.25,                last time consumption/overall running time: 167.4682s / 286.8193 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1521
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1568
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 560.45,                last time consumption/overall running time: 169.4041s / 456.2235 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.1944
env0_second_0:                 episode reward: -0.9500,                 loss: 0.1830
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 594.55,                last time consumption/overall running time: 178.4442s / 634.6677 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2200
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2038
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 598.85,                last time consumption/overall running time: 177.4753s / 812.1430 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2054
env0_second_0:                 episode reward: -1.2000,                 loss: 0.1800
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 586.05,                last time consumption/overall running time: 174.1263s / 986.2693 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.1807
env0_second_0:                 episode reward: -1.4000,                 loss: 0.1694
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 523.4,                last time consumption/overall running time: 159.6470s / 1145.9163 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.1826
env0_second_0:                 episode reward: -1.0500,                 loss: 0.1779
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 571.15,                last time consumption/overall running time: 171.3120s / 1317.2283 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1958
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1748
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 588.9,                last time consumption/overall running time: 175.4560s / 1492.6843 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1994
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1883
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 602.55,                last time consumption/overall running time: 179.1984s / 1671.8827 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1927
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1790
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 172.7775s / 1844.6602 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2081
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2072
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 582.7,                last time consumption/overall running time: 173.3478s / 2018.0079 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2378
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2324
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 571.5,                last time consumption/overall running time: 171.6531s / 2189.6611 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2141
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2076
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 591.4,                last time consumption/overall running time: 176.5968s / 2366.2578 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2166
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2060
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 571.05,                last time consumption/overall running time: 171.2681s / 2537.5260 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2359
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2377
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 583.25,                last time consumption/overall running time: 174.9912s / 2712.5171 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2609
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2469
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 597.35,                last time consumption/overall running time: 176.6241s / 2889.1413 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2490
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2487
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 523.55,                last time consumption/overall running time: 159.1624s / 3048.3036 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2508
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2479
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 603.0,                last time consumption/overall running time: 180.3535s / 3228.6572 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2589
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2471
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 572.3,                last time consumption/overall running time: 171.3302s / 3399.9874 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2504
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2525
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 581.2,                last time consumption/overall running time: 175.0345s / 3575.0219 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2553
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2419
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 584.05,                last time consumption/overall running time: 174.9144s / 3749.9363 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2762
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2825
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 578.3,                last time consumption/overall running time: 172.8563s / 3922.7926 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2697
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2690
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 529.55,                last time consumption/overall running time: 159.2061s / 4081.9986 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2651
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 538.05,                last time consumption/overall running time: 163.5067s / 4245.5053 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2811
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2725
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 584.3,                last time consumption/overall running time: 177.2393s / 4422.7446 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2691
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2690
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 563.1,                last time consumption/overall running time: 168.5576s / 4591.3022 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2463
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2401
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 577.35,                last time consumption/overall running time: 173.1478s / 4764.4501 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2562
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 558.85,                last time consumption/overall running time: 169.1349s / 4933.5850 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2395
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2375
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 499.3,                last time consumption/overall running time: 151.5658s / 5085.1508 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2297
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2322
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 587.7,                last time consumption/overall running time: 175.1702s / 5260.3210 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2817
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2716
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 553.9,                last time consumption/overall running time: 166.6572s / 5426.9782 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2467
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2302
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 583.25,                last time consumption/overall running time: 174.3990s / 5601.3772 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2392
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2316
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 540.95,                last time consumption/overall running time: 163.4883s / 5764.8655 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2187
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2193
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 545.75,                last time consumption/overall running time: 164.5114s / 5929.3769 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2615
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2513
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 559.9,                last time consumption/overall running time: 169.4278s / 6098.8047 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2537
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2397
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 525.25,                last time consumption/overall running time: 157.4238s / 6256.2285 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2352
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2268
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 548.3,                last time consumption/overall running time: 165.5210s / 6421.7495 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2477
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2371
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 550.55,                last time consumption/overall running time: 164.9429s / 6586.6925 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2571
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2518
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 580.5,                last time consumption/overall running time: 174.0580s / 6760.7505 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2690
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2582
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 548.35,                last time consumption/overall running time: 164.7623s / 6925.5127 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2613
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2509
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 570.95,                last time consumption/overall running time: 172.6469s / 7098.1596 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2620
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2561
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 561.8,                last time consumption/overall running time: 168.1556s / 7266.3152 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2521
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2498
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 600.1,                last time consumption/overall running time: 176.9019s / 7443.2171 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2643
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2653
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 573.1,                last time consumption/overall running time: 173.4783s / 7616.6954 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2558
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2461
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 575.8,                last time consumption/overall running time: 172.8088s / 7789.5042 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2719
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2746
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 554.95,                last time consumption/overall running time: 167.0212s / 7956.5254 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2570
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2578
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 579.3,                last time consumption/overall running time: 175.3919s / 8131.9173 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2388
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2368
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 577.95,                last time consumption/overall running time: 173.5829s / 8305.5002 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2432
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2485
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 552.55,                last time consumption/overall running time: 165.4699s / 8470.9701 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2714
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2609
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 536.25,                last time consumption/overall running time: 161.5234s / 8632.4935 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2520
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2605
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 587.95,                last time consumption/overall running time: 176.8977s / 8809.3913 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2357
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2386
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 564.4,                last time consumption/overall running time: 168.8751s / 8978.2663 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2464
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2494
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 554.1,                last time consumption/overall running time: 165.6985s / 9143.9648 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2425
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2461
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 600.5,                last time consumption/overall running time: 180.1113s / 9324.0761 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2492
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2548
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 574.15,                last time consumption/overall running time: 173.2088s / 9497.2849 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2505
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2458
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 549.1,                last time consumption/overall running time: 165.7686s / 9663.0535 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2656
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2553
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 608.2,                last time consumption/overall running time: 179.7749s / 9842.8284 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2579
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2505
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 603.2,                last time consumption/overall running time: 178.7693s / 10021.5977 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2644
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2723
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 574.8,                last time consumption/overall running time: 172.7473s / 10194.3449 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2905
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2912
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 574.05,                last time consumption/overall running time: 171.0126s / 10365.3575 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2906
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2857
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 555.65,                last time consumption/overall running time: 167.4191s / 10532.7766 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2627
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2592
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 532.9,                last time consumption/overall running time: 159.9017s / 10692.6783 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2750
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2791
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 572.2,                last time consumption/overall running time: 171.0552s / 10863.7334 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2558
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2482
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 567.45,                last time consumption/overall running time: 169.9692s / 11033.7026 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2677
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2612
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 589.4,                last time consumption/overall running time: 176.3746s / 11210.0773 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2640
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2638
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 590.9,                last time consumption/overall running time: 176.0832s / 11386.1605 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2575
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2654
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 603.05,                last time consumption/overall running time: 180.3911s / 11566.5516 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2686
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2624
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 550.95,                last time consumption/overall running time: 164.9119s / 11731.4635 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2743
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2695
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 584.25,                last time consumption/overall running time: 175.0490s / 11906.5125 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2775
env0_second_0:                 episode reward: 1.6000,                 loss: 0.2771
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 577.55,                last time consumption/overall running time: 171.1202s / 12077.6327 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2630
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2703
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 584.5,                last time consumption/overall running time: 175.1222s / 12252.7549 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2685
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2637
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 566.5,                last time consumption/overall running time: 169.2870s / 12422.0419 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2862
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2815
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 580.5,                last time consumption/overall running time: 171.7336s / 12593.7755 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2841
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3008
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 567.6,                last time consumption/overall running time: 169.4319s / 12763.2074 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2824
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2774
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 563.0,                last time consumption/overall running time: 168.6412s / 12931.8486 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2808
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2818
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 584.25,                last time consumption/overall running time: 174.3577s / 13106.2063 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2572
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2573
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 580.65,                last time consumption/overall running time: 172.7619s / 13278.9682 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2662
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2651
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 556.65,                last time consumption/overall running time: 166.4233s / 13445.3915 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2414
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2506
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 589.3,                last time consumption/overall running time: 175.3381s / 13620.7296 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2674
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 552.3,                last time consumption/overall running time: 167.6631s / 13788.3927 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2637
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2628
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 534.45,                last time consumption/overall running time: 158.7916s / 13947.1843 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2656
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2706
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 606.7,                last time consumption/overall running time: 180.1444s / 14127.3287 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2829
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 570.5,                last time consumption/overall running time: 169.9521s / 14297.2808 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2756
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2751
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 551.9,                last time consumption/overall running time: 165.9969s / 14463.2778 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2905
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2896
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 639.75,                last time consumption/overall running time: 189.1752s / 14652.4530 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2554
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2558
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 546.6,                last time consumption/overall running time: 163.8592s / 14816.3122 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2609
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2603
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 602.8,                last time consumption/overall running time: 178.2239s / 14994.5361 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2864
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2894
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 574.2,                last time consumption/overall running time: 172.0500s / 15166.5861 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2748
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 574.4,                last time consumption/overall running time: 170.5097s / 15337.0959 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2662
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2591
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 563.25,                last time consumption/overall running time: 167.4858s / 15504.5817 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2777
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2751
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 553.35,                last time consumption/overall running time: 165.0937s / 15669.6754 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2653
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2601
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 533.65,                last time consumption/overall running time: 159.8916s / 15829.5671 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2704
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 564.6,                last time consumption/overall running time: 168.1516s / 15997.7186 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2734
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2723
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 576.9,                last time consumption/overall running time: 172.4745s / 16170.1932 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2662
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2613
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 594.4,                last time consumption/overall running time: 177.4938s / 16347.6870 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2796
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2789
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 545.9,                last time consumption/overall running time: 163.0425s / 16510.7295 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2688
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2616
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 561.15,                last time consumption/overall running time: 169.4468s / 16680.1763 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2666
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2609
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 586.0,                last time consumption/overall running time: 174.6282s / 16854.8045 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2506
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2525
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 592.85,                last time consumption/overall running time: 175.1643s / 17029.9688 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2804
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2798
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 590.9,                last time consumption/overall running time: 175.4359s / 17205.4047 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2780
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2785
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 563.5,                last time consumption/overall running time: 167.7211s / 17373.1258 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2786
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2815
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 587.15,                last time consumption/overall running time: 175.9978s / 17549.1236 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2600
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2637
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 596.35,                last time consumption/overall running time: 175.4218s / 17724.5454 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2852
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2838
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 573.3,                last time consumption/overall running time: 169.7728s / 17894.3182 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2586
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2619
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 526.05,                last time consumption/overall running time: 158.0166s / 18052.3349 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2837
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2792
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 556.45,                last time consumption/overall running time: 167.6867s / 18220.0216 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2661
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2713
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 576.5,                last time consumption/overall running time: 171.9019s / 18391.9235 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2836
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2817
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 559.7,                last time consumption/overall running time: 167.4036s / 18559.3271 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2817
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2756
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 562.45,                last time consumption/overall running time: 168.4441s / 18727.7712 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2818
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2759
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 566.35,                last time consumption/overall running time: 168.7597s / 18896.5309 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2760
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2811
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 558.85,                last time consumption/overall running time: 165.5273s / 19062.0582 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2667
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2711
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 556.6,                last time consumption/overall running time: 166.5798s / 19228.6380 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2520
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2464
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 570.85,                last time consumption/overall running time: 170.0224s / 19398.6604 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2477
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2534
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 599.8,                last time consumption/overall running time: 178.7218s / 19577.3822 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2642
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2544
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 517.15,                last time consumption/overall running time: 156.8985s / 19734.2807 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2668
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 568.5,                last time consumption/overall running time: 170.2469s / 19904.5276 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2752
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2758
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 563.1,                last time consumption/overall running time: 166.9568s / 20071.4844 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2689
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 576.3,                last time consumption/overall running time: 170.9881s / 20242.4725 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2560
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 571.05,                last time consumption/overall running time: 170.7119s / 20413.1844 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2568
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2490
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 582.3,                last time consumption/overall running time: 173.0358s / 20586.2201 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2859
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2772
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 567.0,                last time consumption/overall running time: 169.9096s / 20756.1297 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2530
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2528
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 551.05,                last time consumption/overall running time: 165.2475s / 20921.3772 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2841
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2907
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 563.0,                last time consumption/overall running time: 168.2617s / 21089.6389 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2643
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2699
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 573.5,                last time consumption/overall running time: 169.9264s / 21259.5653 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2818
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2876
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 576.35,                last time consumption/overall running time: 171.9037s / 21431.4691 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2843
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2835
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 551.85,                last time consumption/overall running time: 164.1774s / 21595.6464 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2852
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2869
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 596.05,                last time consumption/overall running time: 177.2069s / 21772.8533 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2730
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2765
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 543.6,                last time consumption/overall running time: 163.2425s / 21936.0958 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2788
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2846
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 549.1,                last time consumption/overall running time: 165.2506s / 22101.3464 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2887
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2879
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 567.2,                last time consumption/overall running time: 168.4916s / 22269.8380 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2732
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2586
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 587.7,                last time consumption/overall running time: 174.6378s / 22444.4757 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2764
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2789
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 542.35,                last time consumption/overall running time: 162.1593s / 22606.6350 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2690
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2655
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 588.85,                last time consumption/overall running time: 175.0739s / 22781.7089 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2816
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2797
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 550.35,                last time consumption/overall running time: 163.6596s / 22945.3685 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2793
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2803
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 577.35,                last time consumption/overall running time: 172.2250s / 23117.5935 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2532
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2596
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 546.6,                last time consumption/overall running time: 162.8707s / 23280.4643 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2754
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2716
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 554.5,                last time consumption/overall running time: 167.5924s / 23448.0566 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2917
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2807
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 580.5,                last time consumption/overall running time: 173.8938s / 23621.9504 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2791
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2780
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 545.85,                last time consumption/overall running time: 164.1202s / 23786.0706 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2758
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2899
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 526.75,                last time consumption/overall running time: 158.4705s / 23944.5411 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2966
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2971
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 570.3,                last time consumption/overall running time: 168.1478s / 24112.6889 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2969
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3024
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 535.45,                last time consumption/overall running time: 161.7201s / 24274.4090 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2623
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2610
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 164.9405s / 24439.3496 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2852
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2847
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 588.45,                last time consumption/overall running time: 174.6142s / 24613.9638 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2858
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2928
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 568.8,                last time consumption/overall running time: 169.9398s / 24783.9036 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2889
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 558.3,                last time consumption/overall running time: 164.2427s / 24948.1463 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2768
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2666
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 170.3389s / 25118.4852 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2855
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2888
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 573.8,                last time consumption/overall running time: 173.2843s / 25291.7695 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2840
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2795
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 527.75,                last time consumption/overall running time: 156.7100s / 25448.4794 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2827
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2851
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 555.4,                last time consumption/overall running time: 165.4801s / 25613.9595 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2925
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3034
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 555.6,                last time consumption/overall running time: 166.0305s / 25779.9900 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2890
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2873
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 572.7,                last time consumption/overall running time: 169.9087s / 25949.8987 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2801
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2774
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 545.15,                last time consumption/overall running time: 162.9679s / 26112.8666 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2829
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2950
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 574.0,                last time consumption/overall running time: 170.4775s / 26283.3441 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2848
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2933
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 528.15,                last time consumption/overall running time: 159.4203s / 26442.7644 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2756
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2791
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 533.25,                last time consumption/overall running time: 160.3105s / 26603.0749 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2779
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2795
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 532.55,                last time consumption/overall running time: 159.0479s / 26762.1227 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2711
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2625
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 584.65,                last time consumption/overall running time: 172.6068s / 26934.7295 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2836
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2877
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 575.75,                last time consumption/overall running time: 171.3520s / 27106.0816 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2848
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2800
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 567.2,                last time consumption/overall running time: 168.5622s / 27274.6438 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2856
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2980
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 570.45,                last time consumption/overall running time: 168.6504s / 27443.2942 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2656
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2806
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 553.2,                last time consumption/overall running time: 164.3864s / 27607.6806 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2605
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2548
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 568.4,                last time consumption/overall running time: 170.3595s / 27778.0401 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2628
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2831
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 583.15,                last time consumption/overall running time: 172.2154s / 27950.2555 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2623
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2596
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 573.3,                last time consumption/overall running time: 170.9850s / 28121.2405 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2666
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2784
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 567.4,                last time consumption/overall running time: 169.5659s / 28290.8065 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2651
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2770
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 564.8,                last time consumption/overall running time: 168.4195s / 28459.2259 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3165
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3220
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 582.05,                last time consumption/overall running time: 173.3195s / 28632.5454 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3029
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3034
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 599.3,                last time consumption/overall running time: 179.2011s / 28811.7465 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2799
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2912
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 553.2,                last time consumption/overall running time: 164.8512s / 28976.5977 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2677
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2678
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 587.4,                last time consumption/overall running time: 173.6332s / 29150.2309 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2816
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2875
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 581.15,                last time consumption/overall running time: 172.8174s / 29323.0483 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2916
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 560.7,                last time consumption/overall running time: 166.5376s / 29489.5859 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2753
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2857
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 553.6,                last time consumption/overall running time: 165.7883s / 29655.3743 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2819
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2856
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 581.5,                last time consumption/overall running time: 171.7066s / 29827.0809 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2796
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2838
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 548.3,                last time consumption/overall running time: 163.5156s / 29990.5964 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2585
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2614
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 549.4,                last time consumption/overall running time: 165.4045s / 30156.0009 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2735
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2732
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 628.75,                last time consumption/overall running time: 185.5851s / 30341.5860 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2854
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2935
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 569.85,                last time consumption/overall running time: 169.3657s / 30510.9517 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2694
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2741
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 550.45,                last time consumption/overall running time: 163.9307s / 30674.8824 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3011
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3051
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 584.4,                last time consumption/overall running time: 172.7621s / 30847.6444 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2950
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3041
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 558.4,                last time consumption/overall running time: 166.3028s / 31013.9472 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2904
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2934
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 541.25,                last time consumption/overall running time: 162.3658s / 31176.3130 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3025
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3139
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 574.6,                last time consumption/overall running time: 169.8033s / 31346.1163 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2815
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2902
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 584.4,                last time consumption/overall running time: 175.2569s / 31521.3733 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2784
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2900
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 583.0,                last time consumption/overall running time: 173.6237s / 31694.9969 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2708
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2589
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 558.0,                last time consumption/overall running time: 165.8960s / 31860.8930 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2713
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2723
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 548.55,                last time consumption/overall running time: 164.8046s / 32025.6976 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2668
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2675
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 566.05,                last time consumption/overall running time: 168.8034s / 32194.5011 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2549
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2565
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 586.2,                last time consumption/overall running time: 173.3640s / 32367.8651 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2643
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2691
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 559.75,                last time consumption/overall running time: 167.1795s / 32535.0446 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2821
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2892
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 562.2,                last time consumption/overall running time: 167.3486s / 32702.3932 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2703
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2903
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 549.75,                last time consumption/overall running time: 163.3159s / 32865.7090 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2944
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2952
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 580.35,                last time consumption/overall running time: 172.6351s / 33038.3441 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2744
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2895
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 568.6,                last time consumption/overall running time: 170.9856s / 33209.3298 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3024
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3098
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 559.4,                last time consumption/overall running time: 167.1289s / 33376.4587 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2520
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2520
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 566.35,                last time consumption/overall running time: 166.7398s / 33543.1985 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2921
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2986
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 587.3,                last time consumption/overall running time: 175.1443s / 33718.3428 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2827
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2992
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 572.45,                last time consumption/overall running time: 171.1576s / 33889.5004 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2611
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2773
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 588.25,                last time consumption/overall running time: 173.3099s / 34062.8103 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2747
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2813
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 553.65,                last time consumption/overall running time: 164.9403s / 34227.7506 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2668
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2736
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 580.0,                last time consumption/overall running time: 172.8273s / 34400.5779 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2695
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2728
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 554.25,                last time consumption/overall running time: 164.9835s / 34565.5614 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2681
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2802
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 590.85,                last time consumption/overall running time: 174.5140s / 34740.0755 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2617
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2676
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 566.45,                last time consumption/overall running time: 168.1585s / 34908.2340 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2539
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2594
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 571.85,                last time consumption/overall running time: 170.8278s / 35079.0617 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2579
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2632
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 560.9,                last time consumption/overall running time: 167.3712s / 35246.4329 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2746
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2912
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 586.8,                last time consumption/overall running time: 174.6482s / 35421.0811 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2776
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2804
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 538.9,                last time consumption/overall running time: 161.3860s / 35582.4671 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2659
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2724
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 588.25,                last time consumption/overall running time: 173.8599s / 35756.3270 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2911
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2976
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 553.1,                last time consumption/overall running time: 164.8061s / 35921.1331 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2645
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2627
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 583.0,                last time consumption/overall running time: 174.3929s / 36095.5260 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2771
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2815
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 577.5,                last time consumption/overall running time: 169.1546s / 36264.6806 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2537
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2548
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 592.0,                last time consumption/overall running time: 175.3644s / 36440.0450 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2704
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2715
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 169.6305s / 36609.6755 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2863
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2961
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 563.8,                last time consumption/overall running time: 169.8431s / 36779.5186 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2950
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2989
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 561.6,                last time consumption/overall running time: 166.2763s / 36945.7950 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2769
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2866
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 560.55,                last time consumption/overall running time: 168.0691s / 37113.8640 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2919
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2994
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 590.15,                last time consumption/overall running time: 184.2973s / 37298.1613 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2679
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2786
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 604.35,                last time consumption/overall running time: 203.3947s / 37501.5560 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2698
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2724
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 591.65,                last time consumption/overall running time: 204.0052s / 37705.5612 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2753
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2712
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 582.6,                last time consumption/overall running time: 209.8672s / 37915.4284 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2563
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2495
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 537.85,                last time consumption/overall running time: 195.6436s / 38111.0720 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2683
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2867
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 548.5,                last time consumption/overall running time: 198.5209s / 38309.5929 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2813
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2847
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 540.9,                last time consumption/overall running time: 197.6998s / 38507.2927 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2580
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2681
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 540.85,                last time consumption/overall running time: 196.2838s / 38703.5765 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2546
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2516
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 555.7,                last time consumption/overall running time: 201.7522s / 38905.3287 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2557
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2607
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 567.85,                last time consumption/overall running time: 206.2336s / 39111.5623 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2741
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2788
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 574.95,                last time consumption/overall running time: 208.6411s / 39320.2034 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2613
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2640
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 536.15,                last time consumption/overall running time: 194.6151s / 39514.8185 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2839
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2796
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 561.6,                last time consumption/overall running time: 203.7751s / 39718.5936 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2718
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2891
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 569.55,                last time consumption/overall running time: 205.1621s / 39923.7558 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2495
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2498
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 554.8,                last time consumption/overall running time: 199.9879s / 40123.7437 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3003
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3082
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 558.9,                last time consumption/overall running time: 202.4526s / 40326.1963 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2543
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2553
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 582.45,                last time consumption/overall running time: 211.5849s / 40537.7812 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2810
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2878
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 533.55,                last time consumption/overall running time: 193.3400s / 40731.1212 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2729
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2785
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 583.2,                last time consumption/overall running time: 210.3303s / 40941.4515 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3054
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3040
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 573.45,                last time consumption/overall running time: 207.4661s / 41148.9176 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2650
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2792
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 567.65,                last time consumption/overall running time: 203.4556s / 41352.3731 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2741
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2783
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 583.2,                last time consumption/overall running time: 210.2698s / 41562.6430 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2904
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2896
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 544.75,                last time consumption/overall running time: 197.5508s / 41760.1938 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2688
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2905
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 582.25,                last time consumption/overall running time: 210.7845s / 41970.9783 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2782
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2902
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 589.45,                last time consumption/overall running time: 212.6104s / 42183.5887 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2768
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2954
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 582.1,                last time consumption/overall running time: 208.2451s / 42391.8338 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2680
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2804
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 580.8,                last time consumption/overall running time: 209.1321s / 42600.9659 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2719
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2899
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 586.6,                last time consumption/overall running time: 211.9972s / 42812.9631 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2718
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2731
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 558.85,                last time consumption/overall running time: 201.6768s / 43014.6399 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2861
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3026
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 561.5,                last time consumption/overall running time: 203.1901s / 43217.8300 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2834
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2947
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 556.55,                last time consumption/overall running time: 201.7361s / 43419.5661 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2700
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2893
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 597.25,                last time consumption/overall running time: 214.2372s / 43633.8033 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2891
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2973
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 555.5,                last time consumption/overall running time: 202.3501s / 43836.1533 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2906
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3015
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 543.55,                last time consumption/overall running time: 198.2612s / 44034.4145 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2760
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2923
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 582.35,                last time consumption/overall running time: 210.0789s / 44244.4934 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3017
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3191
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 542.15,                last time consumption/overall running time: 197.6067s / 44442.1001 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2695
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2784
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 575.85,                last time consumption/overall running time: 208.7789s / 44650.8790 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2955
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3062
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 574.9,                last time consumption/overall running time: 207.6093s / 44858.4883 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2825
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2990
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 564.25,                last time consumption/overall running time: 204.6463s / 45063.1346 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3015
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3109
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 558.0,                last time consumption/overall running time: 200.9918s / 45264.1263 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2872
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3004
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 518.95,                last time consumption/overall running time: 189.8842s / 45454.0105 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2859
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2975
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 587.15,                last time consumption/overall running time: 211.0206s / 45665.0311 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2907
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2933
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 569.25,                last time consumption/overall running time: 207.3559s / 45872.3871 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2919
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3002
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 564.15,                last time consumption/overall running time: 204.9103s / 46077.2974 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2959
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3093
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 593.05,                last time consumption/overall running time: 214.5528s / 46291.8502 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2885
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2996
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 556.9,                last time consumption/overall running time: 202.8886s / 46494.7388 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2836
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2993
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 573.15,                last time consumption/overall running time: 207.5735s / 46702.3123 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3118
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3314
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 556.6,                last time consumption/overall running time: 201.0739s / 46903.3861 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2937
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3090
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 551.75,                last time consumption/overall running time: 200.9448s / 47104.3309 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2730
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2771
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 553.1,                last time consumption/overall running time: 199.8455s / 47304.1764 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2993
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3020
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 565.2,                last time consumption/overall running time: 205.3111s / 47509.4876 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2674
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2836
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 570.8,                last time consumption/overall running time: 208.1017s / 47717.5892 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2781
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2862
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 554.35,                last time consumption/overall running time: 200.3163s / 47917.9056 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2783
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2925
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 543.9,                last time consumption/overall running time: 198.0169s / 48115.9224 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2782
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2851
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 570.7,                last time consumption/overall running time: 206.1316s / 48322.0540 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2867
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2907
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 547.5,                last time consumption/overall running time: 199.3222s / 48521.3762 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2717
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2874
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 538.2,                last time consumption/overall running time: 196.2435s / 48717.6197 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2646
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2992
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 524.2,                last time consumption/overall running time: 191.2439s / 48908.8636 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2593
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2919
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 586.6,                last time consumption/overall running time: 212.1274s / 49120.9910 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2678
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2888
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 585.25,                last time consumption/overall running time: 210.7899s / 49331.7809 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2992
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3237
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 533.15,                last time consumption/overall running time: 193.8618s / 49525.6427 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2791
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3080
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 573.25,                last time consumption/overall running time: 206.7975s / 49732.4402 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2853
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3154
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 584.0,                last time consumption/overall running time: 210.2511s / 49942.6912 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3040
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3386
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 581.85,                last time consumption/overall running time: 209.8299s / 50152.5211 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2964
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3134
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 526.8,                last time consumption/overall running time: 192.2622s / 50344.7833 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2970
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3280
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 585.1,                last time consumption/overall running time: 212.2001s / 50556.9834 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2978
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3379
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 578.5,                last time consumption/overall running time: 209.2536s / 50766.2371 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2995
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3213
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 558.1,                last time consumption/overall running time: 201.8219s / 50968.0590 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2901
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3078
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 565.55,                last time consumption/overall running time: 206.4814s / 51174.5404 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.2812
env0_second_0:                 episode reward: 1.7000,                 loss: 0.3041
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 555.0,                last time consumption/overall running time: 199.6677s / 51374.2081 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2760
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2921
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 595.25,                last time consumption/overall running time: 214.4842s / 51588.6924 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2845
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3128
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 574.0,                last time consumption/overall running time: 206.6678s / 51795.3602 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2896
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3207
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 563.9,                last time consumption/overall running time: 204.3685s / 51999.7287 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2801
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3155
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 553.2,                last time consumption/overall running time: 200.9635s / 52200.6922 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2871
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 555.8,                last time consumption/overall running time: 202.4130s / 52403.1052 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2867
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3081
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 609.15,                last time consumption/overall running time: 218.0861s / 52621.1913 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2858
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2958
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 586.4,                last time consumption/overall running time: 212.4382s / 52833.6296 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2731
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2832
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 574.7,                last time consumption/overall running time: 206.7950s / 53040.4245 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2961
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3074
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 572.5,                last time consumption/overall running time: 208.0049s / 53248.4294 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2814
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3157
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 547.2,                last time consumption/overall running time: 198.0116s / 53446.4410 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2780
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3003
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 539.15,                last time consumption/overall running time: 194.8548s / 53641.2958 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2949
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2981
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 572.65,                last time consumption/overall running time: 207.1946s / 53848.4904 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2923
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3102
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 537.55,                last time consumption/overall running time: 195.1514s / 54043.6419 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2814
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3065
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 585.2,                last time consumption/overall running time: 212.0078s / 54255.6497 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3098
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3244
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 580.35,                last time consumption/overall running time: 209.0043s / 54464.6540 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2974
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3172
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 550.4,                last time consumption/overall running time: 198.7928s / 54663.4468 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3024
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3265
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 546.8,                last time consumption/overall running time: 198.7020s / 54862.1487 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2875
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2950
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 579.25,                last time consumption/overall running time: 209.1570s / 55071.3057 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2957
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3046
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 542.05,                last time consumption/overall running time: 197.7023s / 55269.0080 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3074
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3158
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 576.7,                last time consumption/overall running time: 208.6331s / 55477.6411 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3164
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3316
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 562.35,                last time consumption/overall running time: 203.3215s / 55680.9626 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2857
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2998
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 591.25,                last time consumption/overall running time: 213.5048s / 55894.4674 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2905
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2986
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 585.15,                last time consumption/overall running time: 211.6387s / 56106.1061 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2900
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3036
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 606.25,                last time consumption/overall running time: 218.0750s / 56324.1811 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2974
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3012
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 578.0,                last time consumption/overall running time: 207.9478s / 56532.1289 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2802
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2913
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 532.2,                last time consumption/overall running time: 193.8285s / 56725.9574 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2932
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3182
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 593.0,                last time consumption/overall running time: 213.8147s / 56939.7721 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3038
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3227
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 567.8,                last time consumption/overall running time: 204.3851s / 57144.1572 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2737
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2843
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 592.8,                last time consumption/overall running time: 213.8254s / 57357.9826 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3025
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3051
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 581.65,                last time consumption/overall running time: 210.4328s / 57568.4154 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2885
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3000
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 574.15,                last time consumption/overall running time: 208.6218s / 57777.0372 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2831
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3000
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 576.15,                last time consumption/overall running time: 208.3424s / 57985.3796 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2840
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2936
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 562.05,                last time consumption/overall running time: 204.0299s / 58189.4095 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2859
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3080
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 592.55,                last time consumption/overall running time: 214.0016s / 58403.4111 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2792
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2918
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 578.4,                last time consumption/overall running time: 207.9485s / 58611.3596 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2540
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2615
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 550.0,                last time consumption/overall running time: 200.7650s / 58812.1246 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2631
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2721
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 551.4,                last time consumption/overall running time: 200.9096s / 59013.0342 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2737
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2914
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 544.6,                last time consumption/overall running time: 197.4376s / 59210.4718 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2730
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2871
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 557.6,                last time consumption/overall running time: 201.8066s / 59412.2784 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2760
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2877
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 582.85,                last time consumption/overall running time: 210.3765s / 59622.6550 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2763
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2894
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 568.85,                last time consumption/overall running time: 205.3738s / 59828.0288 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2783
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3017
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 617.2,                last time consumption/overall running time: 221.8325s / 60049.8613 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2873
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3022
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 541.65,                last time consumption/overall running time: 197.7266s / 60247.5879 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2861
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3008
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 560.7,                last time consumption/overall running time: 203.3574s / 60450.9454 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2864
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3057
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 593.65,                last time consumption/overall running time: 213.1808s / 60664.1262 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2655
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2758
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 576.1,                last time consumption/overall running time: 208.7098s / 60872.8360 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2529
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2754
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 534.9,                last time consumption/overall running time: 195.0480s / 61067.8840 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2717
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2966
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 560.2,                last time consumption/overall running time: 203.0886s / 61270.9726 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2802
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2999
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 578.95,                last time consumption/overall running time: 208.6300s / 61479.6026 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2691
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2967
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 616.35,                last time consumption/overall running time: 220.5501s / 61700.1527 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2681
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2872
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 581.4,                last time consumption/overall running time: 209.2272s / 61909.3799 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2620
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2922
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 578.2,                last time consumption/overall running time: 208.9810s / 62118.3609 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2749
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2961
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 590.9,                last time consumption/overall running time: 213.9193s / 62332.2802 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2641
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2772
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 594.75,                last time consumption/overall running time: 214.4093s / 62546.6895 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2639
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2889
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 574.95,                last time consumption/overall running time: 207.0142s / 62753.7037 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2705
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2835
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 617.65,                last time consumption/overall running time: 221.1488s / 62974.8525 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2852
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3097
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 561.95,                last time consumption/overall running time: 203.5692s / 63178.4217 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2930
env0_second_0:                 episode reward: -1.0500,                 loss: 0.3202
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 556.1,                last time consumption/overall running time: 201.1124s / 63379.5341 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2599
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2886
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 579.7,                last time consumption/overall running time: 207.7424s / 63587.2765 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2746
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3014
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 616.75,                last time consumption/overall running time: 222.4443s / 63809.7208 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2630
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2643
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 571.45,                last time consumption/overall running time: 206.2403s / 64015.9612 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2805
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2941
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 578.5,                last time consumption/overall running time: 209.0411s / 64225.0023 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2966
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3174
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 587.5,                last time consumption/overall running time: 211.8370s / 64436.8392 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2515
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2679
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 579.4,                last time consumption/overall running time: 209.7659s / 64646.6051 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2668
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2921
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 616.7,                last time consumption/overall running time: 220.9760s / 64867.5811 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2586
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2706
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 581.4,                last time consumption/overall running time: 211.2855s / 65078.8666 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2628
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2789
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 562.25,                last time consumption/overall running time: 203.3311s / 65282.1977 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2878
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3171
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 590.6,                last time consumption/overall running time: 210.8407s / 65493.0384 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2784
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2895
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 530.8,                last time consumption/overall running time: 194.9779s / 65688.0162 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2887
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3030
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 605.0,                last time consumption/overall running time: 217.2154s / 65905.2316 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2922
env0_second_0:                 episode reward: -1.1500,                 loss: 0.3013
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 538.9,                last time consumption/overall running time: 196.2586s / 66101.4902 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2801
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2943
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 568.5,                last time consumption/overall running time: 205.7565s / 66307.2467 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2878
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2892
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 570.8,                last time consumption/overall running time: 207.3520s / 66514.5987 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2753
env0_second_0:                 episode reward: -1.1500,                 loss: 0.3086
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 558.85,                last time consumption/overall running time: 202.8925s / 66717.4913 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2781
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2825
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 552.75,                last time consumption/overall running time: 200.8780s / 66918.3693 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2701
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2980
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 623.4,                last time consumption/overall running time: 224.8362s / 67143.2055 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2554
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2625
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 594.5,                last time consumption/overall running time: 214.4459s / 67357.6514 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2507
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2737
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 562.1,                last time consumption/overall running time: 204.5435s / 67562.1950 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2669
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2909
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 565.75,                last time consumption/overall running time: 205.8584s / 67768.0534 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2554
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2772
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 636.5,                last time consumption/overall running time: 228.4989s / 67996.5523 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2576
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2860
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 582.2,                last time consumption/overall running time: 210.5212s / 68207.0735 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2762
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3048
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 608.25,                last time consumption/overall running time: 218.7682s / 68425.8416 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2725
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2882
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 546.65,                last time consumption/overall running time: 199.5808s / 68625.4225 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2786
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3055
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 607.2,                last time consumption/overall running time: 220.5682s / 68845.9906 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2714
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2913
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 604.8,                last time consumption/overall running time: 217.3340s / 69063.3246 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2562
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2645
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 589.0,                last time consumption/overall running time: 212.5814s / 69275.9060 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2608
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2705
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 570.0,                last time consumption/overall running time: 204.6128s / 69480.5188 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2692
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2895
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 601.65,                last time consumption/overall running time: 215.9636s / 69696.4825 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2697
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2772
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 598.7,                last time consumption/overall running time: 217.7878s / 69914.2703 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2444
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2599
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 579.95,                last time consumption/overall running time: 208.3499s / 70122.6201 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2408
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2747
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 550.05,                last time consumption/overall running time: 200.8311s / 70323.4512 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2750
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2946
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 585.05,                last time consumption/overall running time: 210.8579s / 70534.3091 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2558
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2803
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 565.55,                last time consumption/overall running time: 207.1476s / 70741.4567 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2471
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2675
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 571.1,                last time consumption/overall running time: 208.2229s / 70949.6797 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2689
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2863
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 671.75,                last time consumption/overall running time: 239.4885s / 71189.1682 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2184
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2573
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 609.05,                last time consumption/overall running time: 218.1262s / 71407.2943 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2487
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2874
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 651.5,                last time consumption/overall running time: 232.8280s / 71640.1223 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2281
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2541
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 620.15,                last time consumption/overall running time: 222.4860s / 71862.6083 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2061
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2442
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 628.0,                last time consumption/overall running time: 227.7798s / 72090.3881 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2474
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2582
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 572.9,                last time consumption/overall running time: 206.9234s / 72297.3115 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2542
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2700
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 625.65,                last time consumption/overall running time: 224.2986s / 72521.6101 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2289
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2622
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 651.2,                last time consumption/overall running time: 232.8535s / 72754.4636 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2213
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2481
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 632.95,                last time consumption/overall running time: 227.3172s / 72981.7809 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2151
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2409
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 621.2,                last time consumption/overall running time: 224.7923s / 73206.5732 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2564
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2976
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 682.55,                last time consumption/overall running time: 240.8304s / 73447.4036 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2248
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2660
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 582.75,                last time consumption/overall running time: 211.2029s / 73658.6065 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.2304
env0_second_0:                 episode reward: -2.3500,                 loss: 0.2873
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 622.55,                last time consumption/overall running time: 222.5369s / 73881.1433 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.2352
env0_second_0:                 episode reward: -1.5000,                 loss: 0.2781
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 586.65,                last time consumption/overall running time: 211.7001s / 74092.8434 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.1958
env0_second_0:                 episode reward: -1.8000,                 loss: 0.2429
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 621.1,                last time consumption/overall running time: 223.1688s / 74316.0122 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.2232
env0_second_0:                 episode reward: -1.4000,                 loss: 0.2740
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 575.3,                last time consumption/overall running time: 210.4310s / 74526.4432 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.2269
env0_second_0:                 episode reward: -1.4500,                 loss: 0.2581
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 691.0,                last time consumption/overall running time: 243.6516s / 74770.0949 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2154
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2578
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 643.7,                last time consumption/overall running time: 231.7576s / 75001.8525 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2146
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2682
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 610.45,                last time consumption/overall running time: 221.0153s / 75222.8678 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.2073
env0_second_0:                 episode reward: -1.4500,                 loss: 0.2658
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 644.95,                last time consumption/overall running time: 231.2410s / 75454.1088 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2257
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2605
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 645.55,                last time consumption/overall running time: 232.2455s / 75686.3543 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2138
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2440
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 584.9,                last time consumption/overall running time: 212.0985s / 75898.4528 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.2337
env0_second_0:                 episode reward: -1.8000,                 loss: 0.2543
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 616.1,                last time consumption/overall running time: 220.7527s / 76119.2055 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.1846
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2321
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 633.3,                last time consumption/overall running time: 227.4461s / 76346.6516 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.1810
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2259
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 663.9,                last time consumption/overall running time: 236.1971s / 76582.8487 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.2080
env0_second_0:                 episode reward: -1.6500,                 loss: 0.2576
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 630.95,                last time consumption/overall running time: 226.9615s / 76809.8102 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.1987
env0_second_0:                 episode reward: -2.1500,                 loss: 0.2414
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 651.2,                last time consumption/overall running time: 231.6385s / 77041.4487 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2133
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2649
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 663.0,                last time consumption/overall running time: 234.6835s / 77276.1322 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2179
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2657
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 641.8,                last time consumption/overall running time: 231.1219s / 77507.2541 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2391
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2931
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 668.6,                last time consumption/overall running time: 237.8005s / 77745.0546 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2157
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2531
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 633.25,                last time consumption/overall running time: 227.1818s / 77972.2364 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2171
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2852
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 603.55,                last time consumption/overall running time: 217.5604s / 78189.7968 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.2171
env0_second_0:                 episode reward: -1.5000,                 loss: 0.2833
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 581.95,                last time consumption/overall running time: 209.3452s / 78399.1420 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.2154
env0_second_0:                 episode reward: -2.2000,                 loss: 0.2540
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 624.3,                last time consumption/overall running time: 224.8849s / 78624.0269 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2140
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2686
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 693.15,                last time consumption/overall running time: 245.8244s / 78869.8513 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.2173
env0_second_0:                 episode reward: -1.5500,                 loss: 0.2674
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 671.25,                last time consumption/overall running time: 239.7122s / 79109.5635 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2236
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2555
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 612.5,                last time consumption/overall running time: 218.8468s / 79328.4103 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.1958
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2379
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 700.65,                last time consumption/overall running time: 249.5130s / 79577.9233 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.2059
env0_second_0:                 episode reward: -1.4000,                 loss: 0.2529
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 641.3,                last time consumption/overall running time: 228.8430s / 79806.7663 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.1802
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2245
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 630.8,                last time consumption/overall running time: 225.2708s / 80032.0371 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.2040
env0_second_0:                 episode reward: -1.7500,                 loss: 0.2517
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 629.95,                last time consumption/overall running time: 226.2828s / 80258.3198 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.1945
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2453
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 640.25,                last time consumption/overall running time: 229.0616s / 80487.3815 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.1889
env0_second_0:                 episode reward: -2.0000,                 loss: 0.2512
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 616.7,                last time consumption/overall running time: 221.4683s / 80708.8498 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.1962
env0_second_0:                 episode reward: -2.1000,                 loss: 0.2424
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 642.0,                last time consumption/overall running time: 230.1544s / 80939.0041 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.1825
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2239
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 633.4,                last time consumption/overall running time: 226.8486s / 81165.8528 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.1985
env0_second_0:                 episode reward: -1.7000,                 loss: 0.2381
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 614.4,                last time consumption/overall running time: 221.8609s / 81387.7137 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.2125
env0_second_0:                 episode reward: -1.8000,                 loss: 0.2645
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 693.65,                last time consumption/overall running time: 245.3466s / 81633.0603 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.1757
env0_second_0:                 episode reward: -1.9500,                 loss: 0.2321
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 713.65,                last time consumption/overall running time: 253.1847s / 81886.2450 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.1775
env0_second_0:                 episode reward: -1.8500,                 loss: 0.2284
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 581.4,                last time consumption/overall running time: 207.8744s / 82094.1194 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.1837
env0_second_0:                 episode reward: -2.5500,                 loss: 0.2466
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 569.6,                last time consumption/overall running time: 206.3619s / 82300.4813 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.1581
env0_second_0:                 episode reward: -2.5000,                 loss: 0.2014
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 609.25,                last time consumption/overall running time: 220.0386s / 82520.5200 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.1503
env0_second_0:                 episode reward: -2.5000,                 loss: 0.2195
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 633.8,                last time consumption/overall running time: 227.7090s / 82748.2290 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.1641
env0_second_0:                 episode reward: -2.9000,                 loss: 0.2317
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 589.2,                last time consumption/overall running time: 212.7583s / 82960.9873 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.1736
env0_second_0:                 episode reward: -2.1500,                 loss: 0.2272
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 678.55,                last time consumption/overall running time: 241.3620s / 83202.3493 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.1510
env0_second_0:                 episode reward: -1.9000,                 loss: 0.2152
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 578.95,                last time consumption/overall running time: 211.0641s / 83413.4134 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.1773
env0_second_0:                 episode reward: -1.8000,                 loss: 0.2342
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 593.55,                last time consumption/overall running time: 214.8117s / 83628.2251 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.1603
env0_second_0:                 episode reward: -3.0500,                 loss: 0.2171
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 564.4,                last time consumption/overall running time: 204.6969s / 83832.9220 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.1631
env0_second_0:                 episode reward: -3.0500,                 loss: 0.2219
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 616.9,                last time consumption/overall running time: 221.0951s / 84054.0170 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.1468
env0_second_0:                 episode reward: -2.9500,                 loss: 0.2224
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 636.85,                last time consumption/overall running time: 226.5384s / 84280.5554 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.1343
env0_second_0:                 episode reward: -2.8500,                 loss: 0.1926
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 627.5,                last time consumption/overall running time: 224.6316s / 84505.1870 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.1294
env0_second_0:                 episode reward: -3.2500,                 loss: 0.1798
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 628.4,                last time consumption/overall running time: 226.2809s / 84731.4679 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.1176
env0_second_0:                 episode reward: -2.8000,                 loss: 0.1715
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 624.55,                last time consumption/overall running time: 225.1517s / 84956.6196 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.1116
env0_second_0:                 episode reward: -3.3000,                 loss: 0.1804
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 559.25,                last time consumption/overall running time: 202.1295s / 85158.7491 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.1445
env0_second_0:                 episode reward: -3.3000,                 loss: 0.2178
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 573.2,                last time consumption/overall running time: 208.1676s / 85366.9167 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.1312
env0_second_0:                 episode reward: -3.1500,                 loss: 0.1935
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 641.7,                last time consumption/overall running time: 229.6059s / 85596.5227 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.1215
env0_second_0:                 episode reward: -3.4500,                 loss: 0.1969
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 591.05,                last time consumption/overall running time: 212.5039s / 85809.0265 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.1545
env0_second_0:                 episode reward: -3.1000,                 loss: 0.2212
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 573.6,                last time consumption/overall running time: 207.6931s / 86016.7197 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.1329
env0_second_0:                 episode reward: -2.9000,                 loss: 0.2063
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 622.55,                last time consumption/overall running time: 225.7006s / 86242.4203 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.1288
env0_second_0:                 episode reward: -3.0000,                 loss: 0.1901
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 612.7,                last time consumption/overall running time: 221.3826s / 86463.8029 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.1161
env0_second_0:                 episode reward: -3.5000,                 loss: 0.2119
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 625.3,                last time consumption/overall running time: 223.9978s / 86687.8007 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.1512
env0_second_0:                 episode reward: -2.8500,                 loss: 0.2078
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 610.55,                last time consumption/overall running time: 222.7269s / 86910.5277 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.1370
env0_second_0:                 episode reward: -2.0500,                 loss: 0.2027
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 566.25,                last time consumption/overall running time: 206.4611s / 87116.9888 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.1335
env0_second_0:                 episode reward: -2.9500,                 loss: 0.1981
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 665.0,                last time consumption/overall running time: 237.7463s / 87354.7351 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.1221
env0_second_0:                 episode reward: -2.5500,                 loss: 0.1835
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 626.1,                last time consumption/overall running time: 226.9918s / 87581.7268 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.1297
env0_second_0:                 episode reward: -2.8000,                 loss: 0.1855
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 669.55,                last time consumption/overall running time: 239.7074s / 87821.4343 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.1029
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1775
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 590.8,                last time consumption/overall running time: 216.1014s / 88037.5356 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.1127
env0_second_0:                 episode reward: -2.5000,                 loss: 0.1977
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 612.7,                last time consumption/overall running time: 220.5623s / 88258.0980 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.1074
env0_second_0:                 episode reward: -3.3000,                 loss: 0.1900
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 624.35,                last time consumption/overall running time: 226.2146s / 88484.3126 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.1269
env0_second_0:                 episode reward: -2.9500,                 loss: 0.2022
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 606.6,                last time consumption/overall running time: 218.7026s / 88703.0152 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0912
env0_second_0:                 episode reward: -3.0000,                 loss: 0.1652
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 623.65,                last time consumption/overall running time: 226.6134s / 88929.6286 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0985
env0_second_0:                 episode reward: -3.5500,                 loss: 0.1656
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 658.3,                last time consumption/overall running time: 237.5586s / 89167.1872 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.1087
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1783
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 659.35,                last time consumption/overall running time: 236.7659s / 89403.9531 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.1175
env0_second_0:                 episode reward: -3.2500,                 loss: 0.1777
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 599.95,                last time consumption/overall running time: 216.4910s / 89620.4440 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.1058
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1587
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 559.85,                last time consumption/overall running time: 205.0604s / 89825.5045 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0945
env0_second_0:                 episode reward: -3.5000,                 loss: 0.1556
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 620.1,                last time consumption/overall running time: 224.0634s / 90049.5679 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.1214
env0_second_0:                 episode reward: -3.1500,                 loss: 0.2077
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 577.6,                last time consumption/overall running time: 210.1458s / 90259.7137 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.1064
env0_second_0:                 episode reward: -3.7000,                 loss: 0.1696
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 651.1,                last time consumption/overall running time: 235.5455s / 90495.2592 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0870
env0_second_0:                 episode reward: -3.0500,                 loss: 0.1599
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 637.0,                last time consumption/overall running time: 231.5964s / 90726.8557 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0856
env0_second_0:                 episode reward: -2.9000,                 loss: 0.1591
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 629.8,                last time consumption/overall running time: 227.3254s / 90954.1811 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0927
env0_second_0:                 episode reward: -3.3500,                 loss: 0.1623
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 600.35,                last time consumption/overall running time: 217.3447s / 91171.5258 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0882
env0_second_0:                 episode reward: -3.8000,                 loss: 0.1524
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 650.5,                last time consumption/overall running time: 234.3570s / 91405.8828 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.1110
env0_second_0:                 episode reward: -3.5500,                 loss: 0.1942
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 595.1,                last time consumption/overall running time: 217.7328s / 91623.6156 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0800
env0_second_0:                 episode reward: -3.8500,                 loss: 0.1610
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 574.55,                last time consumption/overall running time: 208.2987s / 91831.9143 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.1123
env0_second_0:                 episode reward: -3.8500,                 loss: 0.1660
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 605.15,                last time consumption/overall running time: 219.0798s / 92050.9941 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0954
env0_second_0:                 episode reward: -3.0000,                 loss: 0.1720
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 547.9,                last time consumption/overall running time: 200.4553s / 92251.4493 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.1059
env0_second_0:                 episode reward: -3.2500,                 loss: 0.1774
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 587.9,                last time consumption/overall running time: 211.7733s / 92463.2226 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0647
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1408
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 567.35,                last time consumption/overall running time: 205.9089s / 92669.1315 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.1198
env0_second_0:                 episode reward: -3.7000,                 loss: 0.1855
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 563.05,                last time consumption/overall running time: 206.4847s / 92875.6162 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.1192
env0_second_0:                 episode reward: -3.4500,                 loss: 0.1738
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 618.15,                last time consumption/overall running time: 222.7363s / 93098.3525 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0810
env0_second_0:                 episode reward: -3.7000,                 loss: 0.1450
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 636.35,                last time consumption/overall running time: 229.9885s / 93328.3410 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0982
env0_second_0:                 episode reward: -3.2000,                 loss: 0.1545
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 573.35,                last time consumption/overall running time: 211.1704s / 93539.5114 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.1270
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1751
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 567.85,                last time consumption/overall running time: 206.6668s / 93746.1782 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.1120
env0_second_0:                 episode reward: -3.5500,                 loss: 0.1725
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 567.65,                last time consumption/overall running time: 207.3214s / 93953.4995 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.1314
env0_second_0:                 episode reward: -3.6000,                 loss: 0.1976
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 623.7,                last time consumption/overall running time: 224.8917s / 94178.3912 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.1388
env0_second_0:                 episode reward: -3.3500,                 loss: 0.1920
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 577.75,                last time consumption/overall running time: 210.8406s / 94389.2318 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0884
env0_second_0:                 episode reward: -3.2000,                 loss: 0.1479
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 593.05,                last time consumption/overall running time: 214.9500s / 94604.1819 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.1198
env0_second_0:                 episode reward: -3.9500,                 loss: 0.2033
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 621.8,                last time consumption/overall running time: 223.6860s / 94827.8678 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0820Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_second_0:                 episode reward: -3.3000,                 loss: 0.1487
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 641.5,                last time consumption/overall running time: 231.9634s / 95059.8312 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0954
env0_second_0:                 episode reward: -3.4000,                 loss: 0.1713
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 581.3,                last time consumption/overall running time: 211.4097s / 95271.2409 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.1022
env0_second_0:                 episode reward: -3.5500,                 loss: 0.1740
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 589.25,                last time consumption/overall running time: 213.0951s / 95484.3360 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.1047
env0_second_0:                 episode reward: -4.0000,                 loss: 0.1832
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 590.45,                last time consumption/overall running time: 198.0047s / 95682.3407 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0980
env0_second_0:                 episode reward: -3.4000,                 loss: 0.1739
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 535.5,                last time consumption/overall running time: 180.6222s / 95862.9629 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.1235
env0_second_0:                 episode reward: -3.4500,                 loss: 0.1783
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 627.85,                last time consumption/overall running time: 208.5905s / 96071.5534 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0873
env0_second_0:                 episode reward: -3.8000,                 loss: 0.1783
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 574.2,                last time consumption/overall running time: 193.8354s / 96265.3888 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0796
env0_second_0:                 episode reward: -3.7500,                 loss: 0.1429
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 599.6,                last time consumption/overall running time: 201.4379s / 96466.8267 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.1040
env0_second_0:                 episode reward: -3.5500,                 loss: 0.1896
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 533.2,                last time consumption/overall running time: 181.3300s / 96648.1567 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0915
env0_second_0:                 episode reward: -4.0000,                 loss: 0.1442
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
