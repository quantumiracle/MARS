pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd171ff1210>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.256 0.046 0.123 ... 0.    0.    0.   ]
 [0.064 0.03  0.054 ... 0.    0.    0.   ]]
Load checkpoints (policy family):  [['83' '5753' '6419' ... '68870' '69079' '69130']
 ['121' '6342' '6627' ... '68960' '69100' '69268']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_70000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_70000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_70000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3115s / 1.3115 s
agent0:                 episode reward: -0.9838,                 loss: nan
agent1:                 episode reward: 0.9838,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 1.6510 s
agent0:                 episode reward: -0.0334,                 loss: nan
agent1:                 episode reward: 0.0334,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 1.8308 s
agent0:                 episode reward: -0.0240,                 loss: nan
agent1:                 episode reward: 0.0240,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6582s / 2.4890 s
agent0:                 episode reward: -0.1039,                 loss: nan
agent1:                 episode reward: 0.1039,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 2.6816 s
agent0:                 episode reward: -0.1303,                 loss: nan
agent1:                 episode reward: 0.1303,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5156s / 3.1972 s
agent0:                 episode reward: 0.0094,                 loss: nan
agent1:                 episode reward: -0.0094,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6620s / 3.8591 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 4.5255 s
agent0:                 episode reward: 0.1345,                 loss: nan
agent1:                 episode reward: -0.1345,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0200s / 5.5455 s
agent0:                 episode reward: 0.2691,                 loss: nan
agent1:                 episode reward: -0.2691,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9764s / 6.5219 s
agent0:                 episode reward: -0.0095,                 loss: nan
agent1:                 episode reward: 0.0095,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.4493s / 7.9712 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 36.8655s / 44.8367 s
agent0:                 episode reward: -0.0599,                 loss: nan
agent1:                 episode reward: 0.0599,                 loss: 0.2360
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 96.9845s / 141.8212 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.2069
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8858s / 240.7070 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: 0.1750
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 102.6325s / 343.3395 s
agent0:                 episode reward: -0.0298,                 loss: nan
agent1:                 episode reward: 0.0298,                 loss: 0.1640
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.8768s / 444.2163 s
agent0:                 episode reward: 0.0982,                 loss: nan
agent1:                 episode reward: -0.0982,                 loss: 0.1595
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.2802s / 541.4965 s
agent0:                 episode reward: -0.1773,                 loss: nan
agent1:                 episode reward: 0.1773,                 loss: 0.1536
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 103.2875s / 644.7841 s
agent0:                 episode reward: 0.4195,                 loss: nan
agent1:                 episode reward: -0.4195,                 loss: 0.1502
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.4815s / 742.2656 s
agent0:                 episode reward: 0.1911,                 loss: nan
agent1:                 episode reward: -0.1911,                 loss: 0.1500
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.1911s / 839.4567 s
agent0:                 episode reward: 0.1843,                 loss: nan
agent1:                 episode reward: -0.1843,                 loss: 0.1471
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5327s / 939.9894 s
agent0:                 episode reward: 0.1016,                 loss: nan
agent1:                 episode reward: -0.1016,                 loss: 0.1479
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.5673s / 1042.5568 s
agent0:                 episode reward: 0.1409,                 loss: nan
agent1:                 episode reward: -0.1409,                 loss: 0.1480
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 103.0046s / 1145.5614 s
agent0:                 episode reward: 0.0724,                 loss: nan
agent1:                 episode reward: -0.0724,                 loss: 0.1472
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 107.1823s / 1252.7437 s
agent0:                 episode reward: 0.1209,                 loss: nan
agent1:                 episode reward: -0.1209,                 loss: 0.1472
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 109.4592s / 1362.2028 s
agent0:                 episode reward: 0.2851,                 loss: nan
agent1:                 episode reward: -0.2851,                 loss: 0.1459
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 110.7749s / 1472.9777 s
agent0:                 episode reward: 0.0457,                 loss: nan
agent1:                 episode reward: -0.0457,                 loss: 0.1459
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 104.5691s / 1577.5468 s
agent0:                 episode reward: 0.2460,                 loss: nan
agent1:                 episode reward: -0.2460,                 loss: 0.1453
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 105.3673s / 1682.9141 s
agent0:                 episode reward: -0.1547,                 loss: nan
agent1:                 episode reward: 0.1547,                 loss: 0.1462
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 107.9729s / 1790.8870 s
agent0:                 episode reward: -0.0585,                 loss: nan
agent1:                 episode reward: 0.0585,                 loss: 0.1699
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.4215s / 1899.3085 s
agent0:                 episode reward: -0.0337,                 loss: nan
agent1:                 episode reward: 0.0337,                 loss: 0.1581
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 108.6688s / 2007.9772 s
agent0:                 episode reward: 0.5495,                 loss: nan
agent1:                 episode reward: -0.5495,                 loss: 0.1590
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.8096s / 2117.7869 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.1581
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 109.1439s / 2226.9308 s
agent0:                 episode reward: 0.0745,                 loss: nan
agent1:                 episode reward: -0.0745,                 loss: 0.1571
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 110.3353s / 2337.2662 s
agent0:                 episode reward: -0.3499,                 loss: nan
agent1:                 episode reward: 0.3499,                 loss: 0.1567
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 108.7620s / 2446.0282 s
agent0:                 episode reward: -0.0352,                 loss: nan
agent1:                 episode reward: 0.0352,                 loss: 0.1563
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 107.7134s / 2553.7416 s
agent0:                 episode reward: 0.5338,                 loss: nan
agent1:                 episode reward: -0.5338,                 loss: 0.1550
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 111.1749s / 2664.9165 s
agent0:                 episode reward: -0.1817,                 loss: nan
agent1:                 episode reward: 0.1817,                 loss: 0.1568
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 152.1677s / 2817.0842 s
agent0:                 episode reward: -0.0112,                 loss: nan
agent1:                 episode reward: 0.0112,                 loss: 0.1565
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6101s / 3057.6942 s
agent0:                 episode reward: -0.3013,                 loss: nan
agent1:                 episode reward: 0.3013,                 loss: 0.1564
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3562s / 3298.0504 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1546
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0419s / 3543.0923 s
agent0:                 episode reward: 0.2048,                 loss: nan
agent1:                 episode reward: -0.2048,                 loss: 0.1568
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3995s / 3785.4919 s
agent0:                 episode reward: 0.0972,                 loss: nan
agent1:                 episode reward: -0.0972,                 loss: 0.1555
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3742s / 4029.8661 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1547
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.9194s / 4266.7855 s
agent0:                 episode reward: 0.0741,                 loss: nan
agent1:                 episode reward: -0.0741,                 loss: 0.1561
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4141s / 4503.1996 s
agent0:                 episode reward: 0.1008,                 loss: nan
agent1:                 episode reward: -0.1008,                 loss: 0.1556
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2939s / 4741.4935 s
agent0:                 episode reward: 0.0306,                 loss: nan
agent1:                 episode reward: -0.0306,                 loss: 0.1499
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2651s / 4979.7586 s
agent0:                 episode reward: -0.2116,                 loss: nan
agent1:                 episode reward: 0.2116,                 loss: 0.1459
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7555s / 5222.5141 s
agent0:                 episode reward: 0.0442,                 loss: nan
agent1:                 episode reward: -0.0442,                 loss: 0.1470
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2061s / 5464.7202 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: 0.1450
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8362s / 5706.5564 s
agent0:                 episode reward: 0.0788,                 loss: nan
agent1:                 episode reward: -0.0788,                 loss: 0.1458
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2558s / 5948.8122 s
agent0:                 episode reward: 0.3245,                 loss: nan
agent1:                 episode reward: -0.3245,                 loss: 0.1459
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0050s / 6190.8172 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: 0.1453
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9005s / 6434.7177 s
agent0:                 episode reward: 0.1670,                 loss: nan
agent1:                 episode reward: -0.1670,                 loss: 0.1447
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0425s / 6681.7602 s
agent0:                 episode reward: -0.0203,                 loss: nan
agent1:                 episode reward: 0.0203,                 loss: 0.1445
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7148s / 6933.4749 s
agent0:                 episode reward: -0.0387,                 loss: nan
agent1:                 episode reward: 0.0387,                 loss: 0.1443
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1930s / 7182.6679 s
agent0:                 episode reward: -0.2309,                 loss: nan
agent1:                 episode reward: 0.2309,                 loss: 0.1436
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9700s / 7420.6379 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1438
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7565s / 7662.3943 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.1434
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8560s / 7908.2504 s
agent0:                 episode reward: -0.1989,                 loss: nan
agent1:                 episode reward: 0.1989,                 loss: 0.1436
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7809s / 8157.0312 s
agent0:                 episode reward: -0.0950,                 loss: nan
agent1:                 episode reward: 0.0950,                 loss: 0.1425
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5586s / 8403.5898 s
agent0:                 episode reward: 0.2202,                 loss: nan
agent1:                 episode reward: -0.2202,                 loss: 0.1435
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1961s / 8643.7859 s
agent0:                 episode reward: -0.0359,                 loss: nan
agent1:                 episode reward: 0.0359,                 loss: 0.1446
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8970s / 8883.6828 s
agent0:                 episode reward: -0.1562,                 loss: nan
agent1:                 episode reward: 0.1562,                 loss: 0.1454
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1039s / 9128.7867 s
agent0:                 episode reward: -0.1277,                 loss: nan
agent1:                 episode reward: 0.1277,                 loss: 0.1458
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3892s / 9374.1760 s
agent0:                 episode reward: 0.4767,                 loss: nan
agent1:                 episode reward: -0.4767,                 loss: 0.1460
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3359s / 9619.5118 s
agent0:                 episode reward: 0.2874,                 loss: nan
agent1:                 episode reward: -0.2874,                 loss: 0.1465
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0856s / 9861.5974 s
agent0:                 episode reward: 0.3516,                 loss: nan
agent1:                 episode reward: -0.3516,                 loss: 0.1466
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7922s / 10107.3896 s
agent0:                 episode reward: 0.1388,                 loss: nan
agent1:                 episode reward: -0.1388,                 loss: 0.1467
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4012s / 10354.7908 s
agent0:                 episode reward: -0.5154,                 loss: nan
agent1:                 episode reward: 0.5154,                 loss: 0.1471
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7229s / 10594.5137 s
agent0:                 episode reward: 0.1647,                 loss: nan
agent1:                 episode reward: -0.1647,                 loss: 0.1467
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1323s / 10840.6461 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: 0.1458
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1893s / 11088.8354 s
agent0:                 episode reward: 0.0304,                 loss: nan
agent1:                 episode reward: -0.0304,                 loss: 0.1443
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1224s / 11325.9578 s
agent0:                 episode reward: -0.0772,                 loss: nan
agent1:                 episode reward: 0.0772,                 loss: 0.1468
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7307s / 11567.6885 s
agent0:                 episode reward: -0.2149,                 loss: nan
agent1:                 episode reward: 0.2149,                 loss: 0.1459
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6217s / 11811.3101 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.1451
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1226s / 12063.4327 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.1476
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0027s / 12309.4354 s
agent0:                 episode reward: -0.5347,                 loss: nan
agent1:                 episode reward: 0.5347,                 loss: 0.1483
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4308s / 12555.8662 s
agent0:                 episode reward: -0.3073,                 loss: nan
agent1:                 episode reward: 0.3073,                 loss: 0.1469
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7255s / 12800.5917 s
agent0:                 episode reward: -0.2296,                 loss: nan
agent1:                 episode reward: 0.2296,                 loss: 0.1484
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0104s / 13038.6021 s
agent0:                 episode reward: 0.0929,                 loss: nan
agent1:                 episode reward: -0.0929,                 loss: 0.1501
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1156s / 13285.7177 s
agent0:                 episode reward: 0.3247,                 loss: nan
agent1:                 episode reward: -0.3247,                 loss: 0.1487
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6472s / 13533.3649 s
agent0:                 episode reward: -0.2811,                 loss: nan
agent1:                 episode reward: 0.2811,                 loss: 0.1492
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8293s / 13774.1941 s
agent0:                 episode reward: -0.0823,                 loss: nan
agent1:                 episode reward: 0.0823,                 loss: 0.1495
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2975s / 14028.4916 s
agent0:                 episode reward: -0.0701,                 loss: nan
agent1:                 episode reward: 0.0701,                 loss: 0.1483
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1930s / 14278.6845 s
agent0:                 episode reward: 0.0817,                 loss: nan
agent1:                 episode reward: -0.0817,                 loss: 0.1508
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9902s / 14534.6747 s
agent0:                 episode reward: -0.1322,                 loss: nan
agent1:                 episode reward: 0.1322,                 loss: 0.1497
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6876s / 14785.3624 s
agent0:                 episode reward: 0.0523,                 loss: nan
agent1:                 episode reward: -0.0523,                 loss: 0.1498
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2330s / 15032.5953 s
agent0:                 episode reward: 0.2765,                 loss: nan
agent1:                 episode reward: -0.2765,                 loss: 0.1503
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2048s / 15273.8001 s
agent0:                 episode reward: -0.1551,                 loss: nan
agent1:                 episode reward: 0.1551,                 loss: 0.1490
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4127s / 15524.2128 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: 0.1496
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0292s / 15763.2419 s
agent0:                 episode reward: 0.2195,                 loss: nan
agent1:                 episode reward: -0.2195,                 loss: 0.1494
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1004s / 16010.3423 s
agent0:                 episode reward: -0.0106,                 loss: nan
agent1:                 episode reward: 0.0106,                 loss: 0.1497
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6367s / 16253.9790 s
agent0:                 episode reward: -0.1071,                 loss: nan
agent1:                 episode reward: 0.1071,                 loss: 0.1499
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8662s / 16501.8452 s
agent0:                 episode reward: 0.0554,                 loss: nan
agent1:                 episode reward: -0.0554,                 loss: 0.1500
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9452s / 16750.7904 s
agent0:                 episode reward: -0.1843,                 loss: nan
agent1:                 episode reward: 0.1843,                 loss: 0.1497
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1552s / 16992.9456 s
agent0:                 episode reward: -0.3683,                 loss: nan
agent1:                 episode reward: 0.3683,                 loss: 0.1558
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9786s / 17241.9243 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.1560
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6080s / 17491.5322 s
agent0:                 episode reward: 0.2237,                 loss: nan
agent1:                 episode reward: -0.2237,                 loss: 0.1555
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0718s / 17746.6041 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: 0.1561
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3418s / 17997.9459 s
agent0:                 episode reward: 0.0230,                 loss: nan
agent1:                 episode reward: -0.0230,                 loss: 0.1550
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4517s / 18244.3976 s
agent0:                 episode reward: 0.0727,                 loss: nan
agent1:                 episode reward: -0.0727,                 loss: 0.1556
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8268s / 18485.2243 s
agent0:                 episode reward: 0.0030,                 loss: nan
agent1:                 episode reward: -0.0030,                 loss: 0.1539
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9536s / 18732.1779 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1559
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8559s / 18974.0338 s
agent0:                 episode reward: -0.0467,                 loss: nan
agent1:                 episode reward: 0.0467,                 loss: 0.1562
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2422s / 19220.2759 s
agent0:                 episode reward: 0.2804,                 loss: nan
agent1:                 episode reward: -0.2804,                 loss: 0.1553
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.0869s / 19457.3628 s
agent0:                 episode reward: 0.3019,                 loss: nan
agent1:                 episode reward: -0.3019,                 loss: 0.1576
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.4588s / 19695.8216 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1566
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5137s / 19937.3353 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.1567
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3559s / 20187.6912 s
agent0:                 episode reward: 0.3842,                 loss: nan
agent1:                 episode reward: -0.3842,                 loss: 0.1557
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4909s / 20430.1820 s
agent0:                 episode reward: 0.0783,                 loss: nan
agent1:                 episode reward: -0.0783,                 loss: 0.1553
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3106s / 20678.4926 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.1554
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.5178s / 20916.0105 s
agent0:                 episode reward: 0.3040,                 loss: nan
agent1:                 episode reward: -0.3040,                 loss: 0.1556
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1168s / 21160.1273 s
agent0:                 episode reward: -0.0894,                 loss: nan
agent1:                 episode reward: 0.0894,                 loss: 0.1527
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0824s / 21406.2097 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.1529
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6085s / 21659.8182 s
agent0:                 episode reward: 0.2490,                 loss: nan
agent1:                 episode reward: -0.2490,                 loss: 0.1533
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5947s / 21898.4129 s
agent0:                 episode reward: -0.1773,                 loss: nan
agent1:                 episode reward: 0.1773,                 loss: 0.1532
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4737s / 22150.8866 s
agent0:                 episode reward: 0.1144,                 loss: nan
agent1:                 episode reward: -0.1144,                 loss: 0.1526
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5945s / 22393.4812 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.1521
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1782s / 22639.6593 s
agent0:                 episode reward: -0.1966,                 loss: nan
agent1:                 episode reward: 0.1966,                 loss: 0.1529
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7366s / 22880.3959 s
agent0:                 episode reward: 0.0072,                 loss: nan
agent1:                 episode reward: -0.0072,                 loss: 0.1536
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1570s / 23119.5529 s
agent0:                 episode reward: -0.0471,                 loss: nan
agent1:                 episode reward: 0.0471,                 loss: 0.1514
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0259s / 23366.5788 s
agent0:                 episode reward: -0.2175,                 loss: nan
agent1:                 episode reward: 0.2175,                 loss: 0.1523
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5482s / 23618.1270 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.1522
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.0922s / 23853.2192 s
agent0:                 episode reward: 0.2882,                 loss: nan
agent1:                 episode reward: -0.2882,                 loss: 0.1539
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8311s / 24097.0503 s
agent0:                 episode reward: -0.3293,                 loss: nan
agent1:                 episode reward: 0.3293,                 loss: 0.1522
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0631s / 24340.1134 s
agent0:                 episode reward: -0.0948,                 loss: nan
agent1:                 episode reward: 0.0948,                 loss: 0.1520
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8930s / 24587.0064 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: 0.1530
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8024s / 24831.8088 s
agent0:                 episode reward: -0.3854,                 loss: nan
agent1:                 episode reward: 0.3854,                 loss: 0.1519
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7548s / 25074.5636 s
agent0:                 episode reward: 0.1080,                 loss: nan
agent1:                 episode reward: -0.1080,                 loss: 0.1503
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7479s / 25325.3115 s
agent0:                 episode reward: -0.5699,                 loss: nan
agent1:                 episode reward: 0.5699,                 loss: 0.1515
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3773s / 25572.6888 s
agent0:                 episode reward: -0.2299,                 loss: nan
agent1:                 episode reward: 0.2299,                 loss: 0.1515
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8304s / 25814.5192 s
agent0:                 episode reward: -0.2943,                 loss: nan
agent1:                 episode reward: 0.2943,                 loss: 0.1531
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4261s / 26053.9453 s
agent0:                 episode reward: -0.0431,                 loss: nan
agent1:                 episode reward: 0.0431,                 loss: 0.1528
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6284s / 26305.5737 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.1522
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2682s / 26549.8418 s
agent0:                 episode reward: -0.3842,                 loss: nan
agent1:                 episode reward: 0.3842,                 loss: 0.1515
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3749s / 26788.2168 s
agent0:                 episode reward: -0.0773,                 loss: nan
agent1:                 episode reward: 0.0773,                 loss: 0.1512
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6104s / 27028.8271 s
agent0:                 episode reward: 0.0902,                 loss: nan
agent1:                 episode reward: -0.0902,                 loss: 0.1522
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8609s / 27265.6881 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.1509
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6261s / 27509.3141 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: 0.1490
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8357s / 27750.1498 s
agent0:                 episode reward: 0.3205,                 loss: nan
agent1:                 episode reward: -0.3205,                 loss: 0.1511
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2099s / 27998.3598 s
agent0:                 episode reward: 0.0135,                 loss: nan
agent1:                 episode reward: -0.0135,                 loss: 0.1508
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5889s / 28239.9487 s
agent0:                 episode reward: -0.2558,                 loss: nan
agent1:                 episode reward: 0.2558,                 loss: 0.1526
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5696s / 28478.5183 s
agent0:                 episode reward: 0.0931,                 loss: nan
agent1:                 episode reward: -0.0931,                 loss: 0.1531
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9280s / 28722.4463 s
agent0:                 episode reward: -0.2425,                 loss: nan
agent1:                 episode reward: 0.2425,                 loss: 0.1511
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5390s / 28960.9853 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.1531
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4256s / 29215.4109 s
agent0:                 episode reward: 0.2256,                 loss: nan
agent1:                 episode reward: -0.2256,                 loss: 0.1553
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7441s / 29465.1550 s
agent0:                 episode reward: -0.0302,                 loss: nan
agent1:                 episode reward: 0.0302,                 loss: 0.1550
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7096s / 29720.8647 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.1538
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6219s / 29963.4866 s
agent0:                 episode reward: -0.6620,                 loss: nan
agent1:                 episode reward: 0.6620,                 loss: 0.1537
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9240s / 30203.4106 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.1547
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7642s / 30444.1748 s
agent0:                 episode reward: 0.2256,                 loss: nan
agent1:                 episode reward: -0.2256,                 loss: 0.1560
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8036s / 30693.9783 s
agent0:                 episode reward: -0.0200,                 loss: nan
agent1:                 episode reward: 0.0200,                 loss: 0.1556
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9000s / 30935.8784 s
agent0:                 episode reward: 0.0398,                 loss: nan
agent1:                 episode reward: -0.0398,                 loss: 0.1543
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5385s / 31181.4169 s
agent0:                 episode reward: -0.1482,                 loss: nan
agent1:                 episode reward: 0.1482,                 loss: 0.1543
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5884s / 31421.0053 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.1553
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4351s / 31668.4404 s
agent0:                 episode reward: 0.1302,                 loss: nan
agent1:                 episode reward: -0.1302,                 loss: 0.1552
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6319s / 31915.0723 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.1531
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6423s / 32161.7146 s
agent0:                 episode reward: 0.0201,                 loss: nan
agent1:                 episode reward: -0.0201,                 loss: 0.1546
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9139s / 32404.6286 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.1557
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3024s / 32647.9310 s
agent0:                 episode reward: -0.0897,                 loss: nan
agent1:                 episode reward: 0.0897,                 loss: 0.1519
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6963s / 32894.6273 s
agent0:                 episode reward: 0.2502,                 loss: nan
agent1:                 episode reward: -0.2502,                 loss: 0.1542
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1592s / 33142.7865 s
agent0:                 episode reward: -0.4255,                 loss: nan
agent1:                 episode reward: 0.4255,                 loss: 0.1537
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8545s / 33391.6411 s
agent0:                 episode reward: 0.2436,                 loss: nan
agent1:                 episode reward: -0.2436,                 loss: 0.1544
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3180s / 33638.9591 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.1550
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9435s / 33885.9026 s
agent0:                 episode reward: 0.0955,                 loss: nan
agent1:                 episode reward: -0.0955,                 loss: 0.1537
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3917s / 34130.2943 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.1555
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7792s / 34381.0735 s
agent0:                 episode reward: 0.1402,                 loss: nan
agent1:                 episode reward: -0.1402,                 loss: 0.1540
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 234.0281s / 34615.1016 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: 0.1543
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7235s / 34870.8251 s
agent0:                 episode reward: 0.1779,                 loss: nan
agent1:                 episode reward: -0.1779,                 loss: 0.1546
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5546s / 35111.3797 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.1566
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2868s / 35364.6665 s
agent0:                 episode reward: -0.4211,                 loss: nan
agent1:                 episode reward: 0.4211,                 loss: 0.1551
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3496s / 35608.0161 s
agent0:                 episode reward: 0.1812,                 loss: nan
agent1:                 episode reward: -0.1812,                 loss: 0.1558
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9937s / 35846.0098 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.1547
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5770s / 36087.5868 s
agent0:                 episode reward: -0.2311,                 loss: nan
agent1:                 episode reward: 0.2311,                 loss: 0.1558
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3065s / 36333.8933 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.1542
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8652s / 36583.7585 s
agent0:                 episode reward: 0.1971,                 loss: nan
agent1:                 episode reward: -0.1971,                 loss: 0.1550
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0435s / 36836.8021 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.1534
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9971s / 37078.7992 s
agent0:                 episode reward: 0.2655,                 loss: nan
agent1:                 episode reward: -0.2655,                 loss: 0.1542
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2181s / 37327.0173 s
agent0:                 episode reward: 0.0664,                 loss: nan
agent1:                 episode reward: -0.0664,                 loss: 0.1563
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5053s / 37569.5226 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.1559
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8404s / 37814.3630 s
agent0:                 episode reward: -0.2292,                 loss: nan
agent1:                 episode reward: 0.2292,                 loss: 0.1565
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8612s / 38054.2242 s
agent0:                 episode reward: -0.2133,                 loss: nan
agent1:                 episode reward: 0.2133,                 loss: 0.1558
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3736s / 38293.5978 s
agent0:                 episode reward: -0.0268,                 loss: nan
agent1:                 episode reward: 0.0268,                 loss: 0.1558
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5635s / 38547.1612 s
agent0:                 episode reward: -0.3774,                 loss: nan
agent1:                 episode reward: 0.3774,                 loss: 0.1541
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8370s / 38788.9982 s
agent0:                 episode reward: 0.0683,                 loss: nan
agent1:                 episode reward: -0.0683,                 loss: 0.1548
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7080s / 39036.7062 s
agent0:                 episode reward: -0.0421,                 loss: nan
agent1:                 episode reward: 0.0421,                 loss: 0.1551
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0734s / 39278.7796 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: 0.1567
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0988s / 39529.8784 s
agent0:                 episode reward: -0.1538,                 loss: nan
agent1:                 episode reward: 0.1538,                 loss: 0.1564
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 233.4138s / 39763.2922 s
agent0:                 episode reward: -0.5066,                 loss: nan
agent1:                 episode reward: 0.5066,                 loss: 0.1565
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7720s / 40013.0642 s
agent0:                 episode reward: 0.4120,                 loss: nan
agent1:                 episode reward: -0.4120,                 loss: 0.1580
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1842s / 40261.2485 s
agent0:                 episode reward: -0.2253,                 loss: nan
agent1:                 episode reward: 0.2253,                 loss: 0.1569
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6029s / 40505.8514 s
agent0:                 episode reward: -0.4102,                 loss: nan
agent1:                 episode reward: 0.4102,                 loss: 0.1548
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3113s / 40750.1626 s
agent0:                 episode reward: -0.0186,                 loss: nan
agent1:                 episode reward: 0.0186,                 loss: 0.1559
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.1386s / 40984.3013 s
agent0:                 episode reward: -0.5008,                 loss: nan
agent1:                 episode reward: 0.5008,                 loss: 0.1559
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9918s / 41233.2930 s
agent0:                 episode reward: 0.0641,                 loss: nan
agent1:                 episode reward: -0.0641,                 loss: 0.1559
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6446s / 41472.9376 s
agent0:                 episode reward: -0.1043,                 loss: nan
agent1:                 episode reward: 0.1043,                 loss: 0.1537
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7731s / 41713.7107 s
agent0:                 episode reward: 0.0148,                 loss: nan
agent1:                 episode reward: -0.0148,                 loss: 0.1527
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6801s / 41961.3908 s
agent0:                 episode reward: -0.1838,                 loss: nan
agent1:                 episode reward: 0.1838,                 loss: 0.1556
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0815s / 42210.4723 s
agent0:                 episode reward: -0.4323,                 loss: nan
agent1:                 episode reward: 0.4323,                 loss: 0.1515
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5749s / 42455.0472 s
agent0:                 episode reward: -0.4017,                 loss: nan
agent1:                 episode reward: 0.4017,                 loss: 0.1529
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7940s / 42703.8412 s
agent0:                 episode reward: -0.2706,                 loss: nan
agent1:                 episode reward: 0.2706,                 loss: 0.1551
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3204s / 42948.1616 s
agent0:                 episode reward: -0.5293,                 loss: nan
agent1:                 episode reward: 0.5293,                 loss: 0.1540
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0766s / 43200.2382 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.1522
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2494s / 43450.4875 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.1522
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.6433s / 43688.1308 s
agent0:                 episode reward: -0.3204,                 loss: nan
agent1:                 episode reward: 0.3204,                 loss: 0.1537
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5877s / 43935.7186 s
agent0:                 episode reward: -0.0387,                 loss: nan
agent1:                 episode reward: 0.0387,                 loss: 0.1543
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3307s / 44173.0492 s
agent0:                 episode reward: 0.0655,                 loss: nan
agent1:                 episode reward: -0.0655,                 loss: 0.1540
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4098s / 44417.4590 s
agent0:                 episode reward: -0.3353,                 loss: nan
agent1:                 episode reward: 0.3353,                 loss: 0.1532
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3325s / 44662.7915 s
agent0:                 episode reward: -0.2535,                 loss: nan
agent1:                 episode reward: 0.2535,                 loss: 0.1517
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1487s / 44902.9402 s
agent0:                 episode reward: -0.1811,                 loss: nan
agent1:                 episode reward: 0.1811,                 loss: 0.1547
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7435s / 45145.6837 s
agent0:                 episode reward: 0.2479,                 loss: nan
agent1:                 episode reward: -0.2479,                 loss: 0.1533
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.6516s / 45382.3352 s
agent0:                 episode reward: -0.0146,                 loss: nan
agent1:                 episode reward: 0.0146,                 loss: 0.1550
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8674s / 45629.2026 s
agent0:                 episode reward: 0.3696,                 loss: nan
agent1:                 episode reward: -0.3696,                 loss: 0.1565
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7228s / 45865.9254 s
agent0:                 episode reward: -0.2999,                 loss: nan
agent1:                 episode reward: 0.2999,                 loss: 0.1577
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0395s / 46118.9649 s
agent0:                 episode reward: 0.1731,                 loss: nan
agent1:                 episode reward: -0.1731,                 loss: 0.1576
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9645s / 46370.9294 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1579
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0579s / 46619.9873 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: 0.1575
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2208s / 46864.2080 s
agent0:                 episode reward: -0.6781,                 loss: nan
agent1:                 episode reward: 0.6781,                 loss: 0.1563
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1192s / 47119.3273 s
agent0:                 episode reward: -0.1688,                 loss: nan
agent1:                 episode reward: 0.1688,                 loss: 0.1575
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0932s / 47363.4205 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.1578
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0893s / 47610.5097 s
agent0:                 episode reward: -0.1584,                 loss: nan
agent1:                 episode reward: 0.1584,                 loss: 0.1560
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2644s / 47856.7741 s
agent0:                 episode reward: -0.1619,                 loss: nan
agent1:                 episode reward: 0.1619,                 loss: 0.1557
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5527s / 48110.3268 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.1577
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5794s / 48353.9062 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: 0.1577
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.7923s / 48589.6985 s
agent0:                 episode reward: -0.2647,                 loss: nan
agent1:                 episode reward: 0.2647,                 loss: 0.1568
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7497s / 48838.4481 s
agent0:                 episode reward: 0.1297,                 loss: nan
agent1:                 episode reward: -0.1297,                 loss: 0.1559
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0365s / 49080.4846 s
agent0:                 episode reward: -0.1719,                 loss: nan
agent1:                 episode reward: 0.1719,                 loss: 0.1583
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4771s / 49319.9617 s
agent0:                 episode reward: 0.0299,                 loss: nan
agent1:                 episode reward: -0.0299,                 loss: 0.1574
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0376s / 49560.9993 s
agent0:                 episode reward: 0.4661,                 loss: nan
agent1:                 episode reward: -0.4661,                 loss: 0.1555
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9463s / 49810.9456 s
agent0:                 episode reward: -0.3127,                 loss: nan
agent1:                 episode reward: 0.3127,                 loss: 0.1540
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6270s / 50059.5726 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.1535
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2782s / 50302.8508 s
agent0:                 episode reward: 0.0237,                 loss: nan
agent1:                 episode reward: -0.0237,                 loss: 0.1550
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7805s / 50552.6313 s
agent0:                 episode reward: 0.0844,                 loss: nan
agent1:                 episode reward: -0.0844,                 loss: 0.1550
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0344s / 50798.6657 s
agent0:                 episode reward: -0.1413,                 loss: nan
agent1:                 episode reward: 0.1413,                 loss: 0.1553
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7404s / 51047.4060 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.1540
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4000s / 51298.8061 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: 0.1538
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2450s / 51548.0511 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.1546
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8628s / 51793.9138 s
agent0:                 episode reward: -0.1733,                 loss: nan
agent1:                 episode reward: 0.1733,                 loss: 0.1563
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9036s / 52048.8175 s
agent0:                 episode reward: -0.0983,                 loss: nan
agent1:                 episode reward: 0.0983,                 loss: 0.1548
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2652s / 52297.0826 s
agent0:                 episode reward: 0.1140,                 loss: nan
agent1:                 episode reward: -0.1140,                 loss: 0.1556
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5874s / 52541.6701 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.1547
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7644s / 52790.4344 s
agent0:                 episode reward: -0.1858,                 loss: nan
agent1:                 episode reward: 0.1858,                 loss: 0.1556
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2631s / 53041.6976 s
agent0:                 episode reward: -0.0317,                 loss: nan
agent1:                 episode reward: 0.0317,                 loss: 0.1558
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.9377s / 53298.6353 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.1562
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9723s / 53544.6076 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: 0.1559
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6207s / 53783.2283 s
agent0:                 episode reward: 0.0243,                 loss: nan
agent1:                 episode reward: -0.0243,                 loss: 0.1534
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7993s / 54031.0275 s
agent0:                 episode reward: -0.4831,                 loss: nan
agent1:                 episode reward: 0.4831,                 loss: 0.1535
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5908s / 54275.6184 s
agent0:                 episode reward: -0.1091,                 loss: nan
agent1:                 episode reward: 0.1091,                 loss: 0.1534
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9536s / 54526.5720 s
agent0:                 episode reward: -0.3483,                 loss: nan
agent1:                 episode reward: 0.3483,                 loss: 0.1546
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8695s / 54770.4415 s
agent0:                 episode reward: 0.0316,                 loss: nan
agent1:                 episode reward: -0.0316,                 loss: 0.1564
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2414s / 55010.6829 s
agent0:                 episode reward: -0.4855,                 loss: nan
agent1:                 episode reward: 0.4855,                 loss: 0.1533
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5826s / 55251.2655 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: 0.1540
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.0483s / 55508.3138 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.1518
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1088s / 55754.4226 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.1542
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.3404s / 56012.7631 s
agent0:                 episode reward: -0.5460,                 loss: nan
agent1:                 episode reward: 0.5460,                 loss: 0.1531
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9532s / 56253.7163 s
agent0:                 episode reward: -0.2484,                 loss: nan
agent1:                 episode reward: 0.2484,                 loss: 0.1544
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9220s / 56501.6383 s
agent0:                 episode reward: -0.1370,                 loss: nan
agent1:                 episode reward: 0.1370,                 loss: 0.1535
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7830s / 56748.4212 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1527
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9794s / 56995.4007 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.1531
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4116s / 57242.8123 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1529
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7241s / 57487.5364 s
agent0:                 episode reward: 0.3225,                 loss: nan
agent1:                 episode reward: -0.3225,                 loss: 0.1537
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0715s / 57732.6079 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.1533
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2376s / 57977.8455 s
agent0:                 episode reward: 0.0429,                 loss: nan
agent1:                 episode reward: -0.0429,                 loss: 0.1539
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2286s / 58223.0740 s
agent0:                 episode reward: -0.1750,                 loss: nan
agent1:                 episode reward: 0.1750,                 loss: 0.1534
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6795s / 58471.7535 s
agent0:                 episode reward: 0.4039,                 loss: nan
agent1:                 episode reward: -0.4039,                 loss: 0.1535
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7220s / 58722.4755 s
agent0:                 episode reward: -0.3843,                 loss: nan
agent1:                 episode reward: 0.3843,                 loss: 0.1537
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2479s / 58962.7234 s
agent0:                 episode reward: -0.2229,                 loss: nan
agent1:                 episode reward: 0.2229,                 loss: 0.1533
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5792s / 59208.3026 s
agent0:                 episode reward: -0.0730,                 loss: nan
agent1:                 episode reward: 0.0730,                 loss: 0.1531
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.4087s / 59441.7114 s
agent0:                 episode reward: 0.1436,                 loss: nan
agent1:                 episode reward: -0.1436,                 loss: 0.1526
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7193s / 59684.4306 s
agent0:                 episode reward: -0.1658,                 loss: nan
agent1:                 episode reward: 0.1658,                 loss: 0.1539
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8223s / 59932.2530 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.1553
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0588s / 60173.3118 s
agent0:                 episode reward: -0.3563,                 loss: nan
agent1:                 episode reward: 0.3563,                 loss: 0.1527
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8067s / 60427.1184 s
agent0:                 episode reward: -0.4013,                 loss: nan
agent1:                 episode reward: 0.4013,                 loss: 0.1538
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5526s / 60681.6711 s
agent0:                 episode reward: -0.1894,                 loss: nan
agent1:                 episode reward: 0.1894,                 loss: 0.1521
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8592s / 60935.5303 s
agent0:                 episode reward: -0.0049,                 loss: nan
agent1:                 episode reward: 0.0049,                 loss: 0.1542
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6214s / 61190.1517 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.1547
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3899s / 61436.5416 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.1545
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.8935s / 61670.4351 s
agent0:                 episode reward: -0.2920,                 loss: nan
agent1:                 episode reward: 0.2920,                 loss: 0.1538
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9636s / 61925.3987 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.1561
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8728s / 62174.2715 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.1563
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9624s / 62415.2339 s
agent0:                 episode reward: -0.0673,                 loss: nan
agent1:                 episode reward: 0.0673,                 loss: 0.1563
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2930s / 62661.5269 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.1566
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8799s / 62910.4067 s
agent0:                 episode reward: -0.2542,                 loss: nan
agent1:                 episode reward: 0.2542,                 loss: 0.1567
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1837s / 63157.5905 s
agent0:                 episode reward: 0.0892,                 loss: nan
agent1:                 episode reward: -0.0892,                 loss: 0.1557
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9666s / 63402.5571 s
agent0:                 episode reward: -0.0574,                 loss: nan
agent1:                 episode reward: 0.0574,                 loss: 0.1571
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5803s / 63644.1374 s
agent0:                 episode reward: -0.1674,                 loss: nan
agent1:                 episode reward: 0.1674,                 loss: 0.1567
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0742s / 63897.2116 s
agent0:                 episode reward: -0.1520,                 loss: nan
agent1:                 episode reward: 0.1520,                 loss: 0.1588
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6764s / 64142.8880 s
agent0:                 episode reward: -0.2550,                 loss: nan
agent1:                 episode reward: 0.2550,                 loss: 0.1552
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4099s / 64394.2979 s
agent0:                 episode reward: -0.0239,                 loss: nan
agent1:                 episode reward: 0.0239,                 loss: 0.1562
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2964s / 64637.5943 s
agent0:                 episode reward: -0.0194,                 loss: nan
agent1:                 episode reward: 0.0194,                 loss: 0.1557
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7520s / 64880.3463 s
agent0:                 episode reward: -0.3170,                 loss: nan
agent1:                 episode reward: 0.3170,                 loss: 0.1588
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3681s / 65128.7144 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.1559
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2041s / 65377.9185 s
agent0:                 episode reward: -0.6209,                 loss: nan
agent1:                 episode reward: 0.6209,                 loss: 0.1550
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7428s / 65622.6613 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.1556
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4343s / 65869.0956 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1572
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5918s / 66117.6874 s
agent0:                 episode reward: -0.2174,                 loss: nan
agent1:                 episode reward: 0.2174,                 loss: 0.1592
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9596s / 66367.6470 s
agent0:                 episode reward: -0.2375,                 loss: nan
agent1:                 episode reward: 0.2375,                 loss: 0.1577
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5595s / 66619.2066 s
agent0:                 episode reward: -0.1632,                 loss: nan
agent1:                 episode reward: 0.1632,                 loss: 0.1593
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4867s / 66858.6932 s
agent0:                 episode reward: -0.3478,                 loss: nan
agent1:                 episode reward: 0.3478,                 loss: 0.1590
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0288s / 67103.7220 s
agent0:                 episode reward: -0.1595,                 loss: nan
agent1:                 episode reward: 0.1595,                 loss: 0.1582
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4890s / 67352.2109 s
agent0:                 episode reward: -0.4440,                 loss: nan
agent1:                 episode reward: 0.4440,                 loss: 0.1568
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7143s / 67599.9252 s
agent0:                 episode reward: 0.1611,                 loss: nan
agent1:                 episode reward: -0.1611,                 loss: 0.1586
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0688s / 67852.9940 s
agent0:                 episode reward: -0.4225,                 loss: nan
agent1:                 episode reward: 0.4225,                 loss: 0.1571
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.0501s / 68112.0441 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: 0.1596
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4083s / 68354.4524 s
agent0:                 episode reward: -0.2903,                 loss: nan
agent1:                 episode reward: 0.2903,                 loss: 0.1613
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2702s / 68601.7226 s
agent0:                 episode reward: 0.0911,                 loss: nan
agent1:                 episode reward: -0.0911,                 loss: 0.1609
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5331s / 68854.2557 s
agent0:                 episode reward: -0.3294,                 loss: nan
agent1:                 episode reward: 0.3294,                 loss: 0.1580
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6108s / 69105.8665 s
agent0:                 episode reward: 0.2077,                 loss: nan
agent1:                 episode reward: -0.2077,                 loss: 0.1591
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6800s / 69354.5465 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.1590
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4352s / 69599.9817 s
agent0:                 episode reward: -0.3925,                 loss: nan
agent1:                 episode reward: 0.3925,                 loss: 0.1599
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1081s / 69854.0897 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.1587
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0801s / 70103.1698 s
agent0:                 episode reward: 0.0265,                 loss: nan
agent1:                 episode reward: -0.0265,                 loss: 0.1596
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2030s / 70347.3728 s
agent0:                 episode reward: -0.3112,                 loss: nan
agent1:                 episode reward: 0.3112,                 loss: 0.1549
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6115s / 70593.9844 s
agent0:                 episode reward: -0.3438,                 loss: nan
agent1:                 episode reward: 0.3438,                 loss: 0.1563
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0341s / 70844.0185 s
agent0:                 episode reward: -0.2106,                 loss: nan
agent1:                 episode reward: 0.2106,                 loss: 0.1557
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8008s / 71094.8192 s
agent0:                 episode reward: -0.1245,                 loss: nan
agent1:                 episode reward: 0.1245,                 loss: 0.1549
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1633s / 71342.9826 s
agent0:                 episode reward: -0.0252,                 loss: nan
agent1:                 episode reward: 0.0252,                 loss: 0.1564
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4264s / 71593.4089 s
agent0:                 episode reward: 0.1792,                 loss: nan
agent1:                 episode reward: -0.1792,                 loss: 0.1560
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0584s / 71839.4673 s
agent0:                 episode reward: -0.4114,                 loss: nan
agent1:                 episode reward: 0.4114,                 loss: 0.1558
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3731s / 72087.8405 s
agent0:                 episode reward: -0.2798,                 loss: nan
agent1:                 episode reward: 0.2798,                 loss: 0.1545
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3775s / 72342.2179 s
agent0:                 episode reward: -0.2943,                 loss: nan
agent1:                 episode reward: 0.2943,                 loss: 0.1565
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.2726s / 72598.4905 s
agent0:                 episode reward: -0.2921,                 loss: nan
agent1:                 episode reward: 0.2921,                 loss: 0.1569
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4266s / 72853.9171 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.1549
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3858s / 73094.3029 s
agent0:                 episode reward: -0.0134,                 loss: nan
agent1:                 episode reward: 0.0134,                 loss: 0.1557
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2902s / 73349.5931 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.1563
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7144s / 73591.3075 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.1559
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2403s / 73841.5478 s
agent0:                 episode reward: -0.2255,                 loss: nan
agent1:                 episode reward: 0.2255,                 loss: 0.1554
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6378s / 74081.1857 s
agent0:                 episode reward: -0.2598,                 loss: nan
agent1:                 episode reward: 0.2598,                 loss: 0.1549
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1341s / 74332.3198 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.1575
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0818s / 74577.4016 s
agent0:                 episode reward: -0.3997,                 loss: nan
agent1:                 episode reward: 0.3997,                 loss: 0.1565
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4938s / 74819.8954 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.1574
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5184s / 75064.4137 s
agent0:                 episode reward: -0.2328,                 loss: nan
agent1:                 episode reward: 0.2328,                 loss: 0.1570
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9485s / 75310.3622 s
agent0:                 episode reward: -0.1985,                 loss: nan
agent1:                 episode reward: 0.1985,                 loss: 0.1564
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2468s / 75557.6090 s
agent0:                 episode reward: 0.1977,                 loss: nan
agent1:                 episode reward: -0.1977,                 loss: 0.1594
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5088s / 75812.1178 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.1579
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5158s / 76063.6336 s
agent0:                 episode reward: -0.2567,                 loss: nan
agent1:                 episode reward: 0.2567,                 loss: 0.1588
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7301s / 76306.3637 s
agent0:                 episode reward: -0.0902,                 loss: nan
agent1:                 episode reward: 0.0902,                 loss: 0.1558
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3188s / 76549.6825 s
agent0:                 episode reward: -0.3385,                 loss: nan
agent1:                 episode reward: 0.3385,                 loss: 0.1566
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 233.6843s / 76783.3668 s
agent0:                 episode reward: 0.2984,                 loss: nan
agent1:                 episode reward: -0.2984,                 loss: 0.1561
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8659s / 77032.2327 s
agent0:                 episode reward: -0.0659,                 loss: nan
agent1:                 episode reward: 0.0659,                 loss: 0.1569
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4486s / 77280.6813 s
agent0:                 episode reward: -0.1093,                 loss: nan
agent1:                 episode reward: 0.1093,                 loss: 0.1573
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7852s / 77528.4664 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.1586
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2495s / 77778.7160 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.1575
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0553s / 78022.7713 s
agent0:                 episode reward: 0.0445,                 loss: nan
agent1:                 episode reward: -0.0445,                 loss: 0.1582
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.4065s / 78280.1777 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.1577
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1708s / 78521.3486 s
agent0:                 episode reward: -0.1216,                 loss: nan
agent1:                 episode reward: 0.1216,                 loss: 0.1539
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3183s / 78768.6669 s
agent0:                 episode reward: -0.1794,                 loss: nan
agent1:                 episode reward: 0.1794,                 loss: 0.1551
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0139s / 79019.6808 s
agent0:                 episode reward: -0.5004,                 loss: nan
agent1:                 episode reward: 0.5004,                 loss: 0.1534
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8870s / 79262.5678 s
agent0:                 episode reward: -0.1317,                 loss: nan
agent1:                 episode reward: 0.1317,                 loss: 0.1555
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2542s / 79513.8220 s
agent0:                 episode reward: -0.1815,                 loss: nan
agent1:                 episode reward: 0.1815,                 loss: 0.1561
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5806s / 79761.4026 s
agent0:                 episode reward: -0.1146,                 loss: nan
agent1:                 episode reward: 0.1146,                 loss: 0.1541
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8042s / 80010.2068 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1541
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7896s / 80263.9964 s
agent0:                 episode reward: 0.0451,                 loss: nan
agent1:                 episode reward: -0.0451,                 loss: 0.1545
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0896s / 80513.0860 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: 0.1544
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7668s / 80760.8528 s
agent0:                 episode reward: -0.3465,                 loss: nan
agent1:                 episode reward: 0.3465,                 loss: 0.1539
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6592s / 81000.5120 s
agent0:                 episode reward: -0.4573,                 loss: nan
agent1:                 episode reward: 0.4573,                 loss: 0.1556
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4648s / 81251.9768 s
agent0:                 episode reward: -0.2094,                 loss: nan
agent1:                 episode reward: 0.2094,                 loss: 0.1555
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1455s / 81503.1224 s
agent0:                 episode reward: 0.3841,                 loss: nan
agent1:                 episode reward: -0.3841,                 loss: 0.1538
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6171s / 81750.7395 s
agent0:                 episode reward: -0.2486,                 loss: nan
agent1:                 episode reward: 0.2486,                 loss: 0.1574
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6910s / 81995.4305 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.1546
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3293s / 82240.7598 s
agent0:                 episode reward: 0.0989,                 loss: nan
agent1:                 episode reward: -0.0989,                 loss: 0.1554
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6026s / 82491.3624 s
agent0:                 episode reward: -0.0724,                 loss: nan
agent1:                 episode reward: 0.0724,                 loss: 0.1542
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1323s / 82744.4947 s
agent0:                 episode reward: -0.0125,                 loss: nan
agent1:                 episode reward: 0.0125,                 loss: 0.1548
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8722s / 82991.3669 s
agent0:                 episode reward: -0.0047,                 loss: nan
agent1:                 episode reward: 0.0047,                 loss: 0.1535
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2313s / 83238.5982 s
agent0:                 episode reward: 0.0447,                 loss: nan
agent1:                 episode reward: -0.0447,                 loss: 0.1538
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3403s / 83485.9384 s
agent0:                 episode reward: 0.0099,                 loss: nan
agent1:                 episode reward: -0.0099,                 loss: 0.1544
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5714s / 83731.5098 s
agent0:                 episode reward: -0.0619,                 loss: nan
agent1:                 episode reward: 0.0619,                 loss: 0.1533
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 260.3955s / 83991.9053 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.1558
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9051s / 84241.8103 s
agent0:                 episode reward: -0.2696,                 loss: nan
agent1:                 episode reward: 0.2696,                 loss: 0.1541
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0883s / 84486.8987 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: 0.1558
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6429s / 84737.5416 s
agent0:                 episode reward: -0.2640,                 loss: nan
agent1:                 episode reward: 0.2640,                 loss: 0.1540
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7619s / 84979.3034 s
agent0:                 episode reward: -0.1782,                 loss: nan
agent1:                 episode reward: 0.1782,                 loss: 0.1532
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9173s / 85228.2208 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1546
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0349s / 85475.2556 s
agent0:                 episode reward: 0.1998,                 loss: nan
agent1:                 episode reward: -0.1998,                 loss: 0.1536
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4634s / 85717.7191 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.1550
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2942s / 85967.0133 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.1514
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9239s / 86217.9371 s
agent0:                 episode reward: -0.1852,                 loss: nan
agent1:                 episode reward: 0.1852,                 loss: 0.1542
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3846s / 86471.3217 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.1548
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1349s / 86722.4566 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.1581
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8417s / 86975.2983 s
agent0:                 episode reward: -0.5728,                 loss: nan
agent1:                 episode reward: 0.5728,                 loss: 0.1578
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3344s / 87223.6327 s
agent0:                 episode reward: 0.0337,                 loss: nan
agent1:                 episode reward: -0.0337,                 loss: 0.1580
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3387s / 87464.9713 s
agent0:                 episode reward: 0.1088,                 loss: nan
agent1:                 episode reward: -0.1088,                 loss: 0.1573
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4813s / 87710.4526 s
agent0:                 episode reward: -0.2173,                 loss: nan
agent1:                 episode reward: 0.2173,                 loss: 0.1582
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9998s / 87962.4525 s
agent0:                 episode reward: -0.1936,                 loss: nan
agent1:                 episode reward: 0.1936,                 loss: 0.1565
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8721s / 88206.3246 s
agent0:                 episode reward: 0.0867,                 loss: nan
agent1:                 episode reward: -0.0867,                 loss: 0.1573
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7725s / 88450.0971 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1597
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2926s / 88700.3897 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.1579
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0633s / 88948.4530 s
agent0:                 episode reward: 0.0437,                 loss: nan
agent1:                 episode reward: -0.0437,                 loss: 0.1585
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6682s / 89205.1212 s
agent0:                 episode reward: -0.5053,                 loss: nan
agent1:                 episode reward: 0.5053,                 loss: 0.1573
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6796s / 89449.8008 s
agent0:                 episode reward: -0.0738,                 loss: nan
agent1:                 episode reward: 0.0738,                 loss: 0.1570
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7743s / 89690.5752 s
agent0:                 episode reward: -0.3061,                 loss: nan
agent1:                 episode reward: 0.3061,                 loss: 0.1590
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9594s / 89939.5345 s
agent0:                 episode reward: -0.0863,                 loss: nan
agent1:                 episode reward: 0.0863,                 loss: 0.1577
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3456s / 90193.8801 s
agent0:                 episode reward: 0.0363,                 loss: nan
agent1:                 episode reward: -0.0363,                 loss: 0.1567
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0103s / 90442.8904 s
agent0:                 episode reward: 0.2946,                 loss: nan
agent1:                 episode reward: -0.2946,                 loss: 0.1583
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.3491s / 90676.2395 s
agent0:                 episode reward: -0.5847,                 loss: nan
agent1:                 episode reward: 0.5847,                 loss: 0.1582
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9135s / 90929.1530 s
agent0:                 episode reward: 0.0859,                 loss: nan
agent1:                 episode reward: -0.0859,                 loss: 0.1579
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.5141s / 91163.6672 s
agent0:                 episode reward: -0.0916,                 loss: nan
agent1:                 episode reward: 0.0916,                 loss: 0.1580
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5598s / 91406.2270 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1574
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6091s / 91654.8361 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.1581
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8493s / 91899.6855 s
agent0:                 episode reward: 0.1817,                 loss: nan
agent1:                 episode reward: -0.1817,                 loss: 0.1567
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3819s / 92148.0673 s
agent0:                 episode reward: -0.0344,                 loss: nan
agent1:                 episode reward: 0.0344,                 loss: 0.1592
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.3265s / 92383.3938 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.1577