2022-05-11 10:23:16.806672: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:23:16.806759: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:23:16.806765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 218
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f01c8c52518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/6000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 8000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_6000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_6000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8228s / 0.8228 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1111s / 0.9339 s
agent0:                 episode reward: 1.3400,                 loss: nan
agent1:                 episode reward: -1.3400,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1164s / 1.0503 s
agent0:                 episode reward: 0.6517,                 loss: nan
agent1:                 episode reward: -0.6517,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1137s / 1.1641 s
agent0:                 episode reward: 1.3057,                 loss: nan
agent1:                 episode reward: -1.3057,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1152s / 1.2793 s
agent0:                 episode reward: 1.5033,                 loss: nan
agent1:                 episode reward: -1.5033,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1090s / 1.3883 s
agent0:                 episode reward: 1.1947,                 loss: nan
agent1:                 episode reward: -1.1947,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1084s / 1.4966 s
agent0:                 episode reward: 1.9726,                 loss: nan
agent1:                 episode reward: -1.9726,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3503s / 1.8470 s
agent0:                 episode reward: 1.3752,                 loss: nan
agent1:                 episode reward: -1.3752,                 loss: 0.4662
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4393s / 2.2863 s
agent0:                 episode reward: 1.9961,                 loss: nan
agent1:                 episode reward: -1.9961,                 loss: 0.4554
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4388s / 2.7251 s
agent0:                 episode reward: 0.9942,                 loss: nan
agent1:                 episode reward: -0.9942,                 loss: 0.4536
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4608s / 3.1859 s
agent0:                 episode reward: 1.4178,                 loss: nan
agent1:                 episode reward: -1.4178,                 loss: 0.4530
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4382s / 3.6241 s
agent0:                 episode reward: 2.2051,                 loss: nan
agent1:                 episode reward: -2.2051,                 loss: 0.4498
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4450s / 4.0691 s
agent0:                 episode reward: 0.9597,                 loss: nan
agent1:                 episode reward: -0.9597,                 loss: 0.4485
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4587s / 4.5278 s
agent0:                 episode reward: 1.6547,                 loss: nan
agent1:                 episode reward: -1.6547,                 loss: 0.4443
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4564s / 4.9842 s
agent0:                 episode reward: 1.9681,                 loss: nan
agent1:                 episode reward: -1.9681,                 loss: 0.4415
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4485s / 5.4327 s
agent0:                 episode reward: 1.3472,                 loss: nan
agent1:                 episode reward: -1.3472,                 loss: 0.4386
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4476s / 5.8803 s
agent0:                 episode reward: 0.9672,                 loss: nan
agent1:                 episode reward: -0.9672,                 loss: 0.4377
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4488s / 6.3290 s
agent0:                 episode reward: 2.0409,                 loss: nan
agent1:                 episode reward: -2.0409,                 loss: 0.4286
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5066s / 6.8356 s
agent0:                 episode reward: 0.5055,                 loss: nan
agent1:                 episode reward: -0.5055,                 loss: 0.4227
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4487s / 7.2843 s
agent0:                 episode reward: 0.5903,                 loss: nan
agent1:                 episode reward: -0.5903,                 loss: 0.4200
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4603s / 7.7446 s
agent0:                 episode reward: 0.0675,                 loss: nan
agent1:                 episode reward: -0.0675,                 loss: 0.4177
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4522s / 8.1968 s
agent0:                 episode reward: 0.6671,                 loss: nan
agent1:                 episode reward: -0.6671,                 loss: 0.4153
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4567s / 8.6535 s
agent0:                 episode reward: 1.0981,                 loss: nan
agent1:                 episode reward: -1.0981,                 loss: 0.4135
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4512s / 9.1047 s
agent0:                 episode reward: 0.9691,                 loss: nan
agent1:                 episode reward: -0.9691,                 loss: 0.4100
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4585s / 9.5632 s
agent0:                 episode reward: 1.4981,                 loss: nan
agent1:                 episode reward: -1.4981,                 loss: 0.4086
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4499s / 10.0131 s
agent0:                 episode reward: 0.9968,                 loss: nan
agent1:                 episode reward: -0.9968,                 loss: 0.4059
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4581s / 10.4712 s
agent0:                 episode reward: 0.4470,                 loss: nan
agent1:                 episode reward: -0.4470,                 loss: 0.4017
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4587s / 10.9299 s
agent0:                 episode reward: 1.0026,                 loss: nan
agent1:                 episode reward: -1.0026,                 loss: 0.3705
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4813s / 11.4112 s
agent0:                 episode reward: 1.7304,                 loss: nan
agent1:                 episode reward: -1.7304,                 loss: 0.3462
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4836s / 11.8948 s
agent0:                 episode reward: 0.9510,                 loss: nan
agent1:                 episode reward: -0.9510,                 loss: 0.3404
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4629s / 12.3577 s
agent0:                 episode reward: 0.4557,                 loss: nan
agent1:                 episode reward: -0.4557,                 loss: 0.3364
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4628s / 12.8205 s
agent0:                 episode reward: 0.9030,                 loss: nan
agent1:                 episode reward: -0.9030,                 loss: 0.3331
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4603s / 13.2809 s
agent0:                 episode reward: 1.4767,                 loss: nan
agent1:                 episode reward: -1.4767,                 loss: 0.3291
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4667s / 13.7476 s
agent0:                 episode reward: 0.7656,                 loss: nan
agent1:                 episode reward: -0.7656,                 loss: 0.3264
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4705s / 14.2180 s
agent0:                 episode reward: 1.5104,                 loss: nan
agent1:                 episode reward: -1.5104,                 loss: 0.3234
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4634s / 14.6814 s
agent0:                 episode reward: 1.4106,                 loss: nan
agent1:                 episode reward: -1.4106,                 loss: 0.3221
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4583s / 15.1397 s
agent0:                 episode reward: 0.0970,                 loss: nan
agent1:                 episode reward: -0.0970,                 loss: 0.3184
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4822s / 15.6219 s
agent0:                 episode reward: 0.7456,                 loss: nan
agent1:                 episode reward: -0.7456,                 loss: 0.2762
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4669s / 16.0888 s
agent0:                 episode reward: 0.9755,                 loss: nan
agent1:                 episode reward: -0.9755,                 loss: 0.2506
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4866s / 16.5754 s
agent0:                 episode reward: 0.2093,                 loss: nan
agent1:                 episode reward: -0.2093,                 loss: 0.2470
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5136s / 17.0889 s
agent0:                 episode reward: 0.7136,                 loss: nan
agent1:                 episode reward: -0.7136,                 loss: 0.2451
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4785s / 17.5674 s
agent0:                 episode reward: 1.3261,                 loss: nan
agent1:                 episode reward: -1.3261,                 loss: 0.2434
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4713s / 18.0388 s
agent0:                 episode reward: 0.4621,                 loss: nan
agent1:                 episode reward: -0.4621,                 loss: 0.2431
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4787s / 18.5174 s
agent0:                 episode reward: 0.9005,                 loss: nan
agent1:                 episode reward: -0.9005,                 loss: 0.2397
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4731s / 18.9905 s
agent0:                 episode reward: 0.1159,                 loss: nan
agent1:                 episode reward: -0.1159,                 loss: 0.2389
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4946s / 19.4850 s
agent0:                 episode reward: 1.2197,                 loss: nan
agent1:                 episode reward: -1.2197,                 loss: 0.2398
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4773s / 19.9623 s
agent0:                 episode reward: 0.8000,                 loss: nan
agent1:                 episode reward: -0.8000,                 loss: 0.2395
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4772s / 20.4396 s
agent0:                 episode reward: 1.2040,                 loss: nan
agent1:                 episode reward: -1.2040,                 loss: 0.2339
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4781s / 20.9177 s
agent0:                 episode reward: 1.2514,                 loss: nan
agent1:                 episode reward: -1.2514,                 loss: 0.2262
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4778s / 21.3955 s
agent0:                 episode reward: 0.4084,                 loss: nan
agent1:                 episode reward: -0.4084,                 loss: 0.2251
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4811s / 21.8766 s
agent0:                 episode reward: 1.4139,                 loss: nan
agent1:                 episode reward: -1.4139,                 loss: 0.2243
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4801s / 22.3567 s
agent0:                 episode reward: 0.2994,                 loss: nan
agent1:                 episode reward: -0.2994,                 loss: 0.2238
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5083s / 22.8650 s
agent0:                 episode reward: 0.4590,                 loss: nan
agent1:                 episode reward: -0.4590,                 loss: 0.2250
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4828s / 23.3478 s
agent0:                 episode reward: 0.2769,                 loss: nan
agent1:                 episode reward: -0.2769,                 loss: 0.2241
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4808s / 23.8285 s
agent0:                 episode reward: 0.1196,                 loss: nan
agent1:                 episode reward: -0.1196,                 loss: 0.2223
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4712s / 24.2998 s
agent0:                 episode reward: 1.7431,                 loss: nan
agent1:                 episode reward: -1.7431,                 loss: 0.2224
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4823s / 24.7820 s
agent0:                 episode reward: 1.1205,                 loss: nan
agent1:                 episode reward: -1.1205,                 loss: 0.2255
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4920s / 25.2740 s
agent0:                 episode reward: 1.3497,                 loss: nan
agent1:                 episode reward: -1.3497,                 loss: 0.2455
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4960s / 25.7701 s
agent0:                 episode reward: 1.0665,                 loss: nan
agent1:                 episode reward: -1.0665,                 loss: 0.2500
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4899s / 26.2600 s
agent0:                 episode reward: 0.9820,                 loss: nan
agent1:                 episode reward: -0.9820,                 loss: 0.2507
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4821s / 26.7421 s
agent0:                 episode reward: 1.4166,                 loss: nan
agent1:                 episode reward: -1.4166,                 loss: 0.2458
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5371s / 27.2791 s
agent0:                 episode reward: 0.2793,                 loss: nan
agent1:                 episode reward: -0.2793,                 loss: 0.2462
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5069s / 27.7861 s
agent0:                 episode reward: 0.9406,                 loss: nan
agent1:                 episode reward: -0.9406,                 loss: 0.2443
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5016s / 28.2877 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.2464
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4987s / 28.7864 s
agent0:                 episode reward: 0.1173,                 loss: nan
agent1:                 episode reward: -0.1173,                 loss: 0.2477
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4911s / 29.2775 s
agent0:                 episode reward: 1.5283,                 loss: nan
agent1:                 episode reward: -1.5283,                 loss: 0.2443
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4913s / 29.7688 s
agent0:                 episode reward: 0.0922,                 loss: nan
agent1:                 episode reward: -0.0922,                 loss: 0.2430
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4934s / 30.2622 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.2756
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4905s / 30.7527 s
agent0:                 episode reward: 0.2128,                 loss: nan
agent1:                 episode reward: -0.2128,                 loss: 0.2780
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5130s / 31.2657 s
agent0:                 episode reward: 0.3746,                 loss: nan
agent1:                 episode reward: -0.3746,                 loss: 0.2784
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5080s / 31.7738 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.2777
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4938s / 32.2676 s
agent0:                 episode reward: 0.3059,                 loss: nan
agent1:                 episode reward: -0.3059,                 loss: 0.2758
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4981s / 32.7657 s
agent0:                 episode reward: 1.0339,                 loss: nan
agent1:                 episode reward: -1.0339,                 loss: 0.2764
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4925s / 33.2581 s
agent0:                 episode reward: 0.5221,                 loss: nan
agent1:                 episode reward: -0.5221,                 loss: 0.2757
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4922s / 33.7504 s
agent0:                 episode reward: 1.2524,                 loss: nan
agent1:                 episode reward: -1.2524,                 loss: 0.2759
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4982s / 34.2486 s
agent0:                 episode reward: 0.1228,                 loss: nan
agent1:                 episode reward: -0.1228,                 loss: 0.2746
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5124s / 34.7610 s
agent0:                 episode reward: 0.5668,                 loss: nan
agent1:                 episode reward: -0.5668,                 loss: 0.2755
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5238s / 35.2848 s
agent0:                 episode reward: 0.9065,                 loss: nan
agent1:                 episode reward: -0.9065,                 loss: 0.2924
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5026s / 35.7873 s
agent0:                 episode reward: -0.6074,                 loss: nan
agent1:                 episode reward: 0.6074,                 loss: 0.2942
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5249s / 36.3122 s
agent0:                 episode reward: 0.9999,                 loss: nan
agent1:                 episode reward: -0.9999,                 loss: 0.2953
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5112s / 36.8234 s
agent0:                 episode reward: -0.1913,                 loss: nan
agent1:                 episode reward: 0.1913,                 loss: 0.2931
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5010s / 37.3244 s
agent0:                 episode reward: 0.6515,                 loss: nan
agent1:                 episode reward: -0.6515,                 loss: 0.2937
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5517s / 37.8761 s
agent0:                 episode reward: -0.0647,                 loss: nan
agent1:                 episode reward: 0.0647,                 loss: 0.2927
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5138s / 38.3899 s
agent0:                 episode reward: 0.7498,                 loss: nan
agent1:                 episode reward: -0.7498,                 loss: 0.2935
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5137s / 38.9036 s
agent0:                 episode reward: 0.3254,                 loss: nan
agent1:                 episode reward: -0.3254,                 loss: 0.2928
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5044s / 39.4080 s
agent0:                 episode reward: 1.1899,                 loss: nan
agent1:                 episode reward: -1.1899,                 loss: 0.2896
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5239s / 39.9319 s
agent0:                 episode reward: 0.9304,                 loss: nan
agent1:                 episode reward: -0.9304,                 loss: 0.2917
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5161s / 40.4480 s
agent0:                 episode reward: -0.0324,                 loss: nan
agent1:                 episode reward: 0.0324,                 loss: 0.3000
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5157s / 40.9637 s
agent0:                 episode reward: 0.7505,                 loss: nan
agent1:                 episode reward: -0.7505,                 loss: 0.2961
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5064s / 41.4701 s
agent0:                 episode reward: 0.7765,                 loss: nan
agent1:                 episode reward: -0.7765,                 loss: 0.2934
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5183s / 41.9884 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.2924
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5108s / 42.4992 s
agent0:                 episode reward: 0.5893,                 loss: nan
agent1:                 episode reward: -0.5893,                 loss: 0.2918
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5057s / 43.0049 s
agent0:                 episode reward: 0.5709,                 loss: nan
agent1:                 episode reward: -0.5709,                 loss: 0.2923
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5129s / 43.5178 s
agent0:                 episode reward: 1.1877,                 loss: nan
agent1:                 episode reward: -1.1877,                 loss: 0.2909
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5337s / 44.0516 s
agent0:                 episode reward: -0.2184,                 loss: nan
agent1:                 episode reward: 0.2184,                 loss: 0.2904
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5329s / 44.5845 s
agent0:                 episode reward: 0.0197,                 loss: nan
agent1:                 episode reward: -0.0197,                 loss: 0.2914
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5080s / 45.0925 s
agent0:                 episode reward: 0.0497,                 loss: nan
agent1:                 episode reward: -0.0497,                 loss: 0.2901
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5134s / 45.6059 s
agent0:                 episode reward: -0.0702,                 loss: nan
agent1:                 episode reward: 0.0702,                 loss: 0.2955
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5144s / 46.1204 s
agent0:                 episode reward: 0.0548,                 loss: nan
agent1:                 episode reward: -0.0548,                 loss: 0.2941
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5290s / 46.6494 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: 0.2934
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5231s / 47.1725 s
agent0:                 episode reward: 1.0057,                 loss: nan
agent1:                 episode reward: -1.0057,                 loss: 0.2913
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5737s / 47.7462 s
agent0:                 episode reward: 0.8202,                 loss: nan
agent1:                 episode reward: -0.8202,                 loss: 0.2903
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5264s / 48.2726 s
agent0:                 episode reward: 0.9288,                 loss: nan
agent1:                 episode reward: -0.9288,                 loss: 0.2930
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5121s / 48.7847 s
agent0:                 episode reward: 1.1891,                 loss: nan
agent1:                 episode reward: -1.1891,                 loss: 0.2921
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5130s / 49.2977 s
agent0:                 episode reward: 0.8427,                 loss: nan
agent1:                 episode reward: -0.8427,                 loss: 0.2920
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5669s / 49.8646 s
agent0:                 episode reward: 0.9695,                 loss: nan
agent1:                 episode reward: -0.9695,                 loss: 0.2918
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5213s / 50.3860 s
agent0:                 episode reward: 0.0424,                 loss: nan
agent1:                 episode reward: -0.0424,                 loss: 0.2893
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5134s / 50.8994 s
agent0:                 episode reward: 0.9100,                 loss: nan
agent1:                 episode reward: -0.9100,                 loss: 0.3017
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5074s / 51.4067 s
agent0:                 episode reward: 0.3184,                 loss: nan
agent1:                 episode reward: -0.3184,                 loss: 0.3054
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5180s / 51.9247 s
agent0:                 episode reward: 0.6691,                 loss: nan
agent1:                 episode reward: -0.6691,                 loss: 0.3032
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5196s / 52.4443 s
agent0:                 episode reward: 0.5836,                 loss: nan
agent1:                 episode reward: -0.5836,                 loss: 0.3043
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5368s / 52.9811 s
agent0:                 episode reward: 0.6907,                 loss: nan
agent1:                 episode reward: -0.6907,                 loss: 0.3020
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5161s / 53.4972 s
agent0:                 episode reward: 0.4280,                 loss: nan
agent1:                 episode reward: -0.4280,                 loss: 0.3049
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5210s / 54.0182 s
agent0:                 episode reward: 1.2964,                 loss: nan
agent1:                 episode reward: -1.2964,                 loss: 0.3023
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5150s / 54.5332 s
agent0:                 episode reward: 0.6185,                 loss: nan
agent1:                 episode reward: -0.6185,                 loss: 0.3033
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5103s / 55.0434 s
agent0:                 episode reward: 0.8048,                 loss: nan
agent1:                 episode reward: -0.8048,                 loss: 0.3007
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5109s / 55.5543 s
agent0:                 episode reward: 0.1760,                 loss: nan
agent1:                 episode reward: -0.1760,                 loss: 0.3012
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5335s / 56.0878 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: 0.3242
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5178s / 56.6056 s
agent0:                 episode reward: 1.2304,                 loss: nan
agent1:                 episode reward: -1.2304,                 loss: 0.3300
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5223s / 57.1279 s
agent0:                 episode reward: 0.1692,                 loss: nan
agent1:                 episode reward: -0.1692,                 loss: 0.3261
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5167s / 57.6446 s
agent0:                 episode reward: -0.0915,                 loss: nan
agent1:                 episode reward: 0.0915,                 loss: 0.3292
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5717s / 58.2164 s
agent0:                 episode reward: 0.0738,                 loss: nan
agent1:                 episode reward: -0.0738,                 loss: 0.3275
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5218s / 58.7382 s
agent0:                 episode reward: 0.4791,                 loss: nan
agent1:                 episode reward: -0.4791,                 loss: 0.3256
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5229s / 59.2611 s
agent0:                 episode reward: 0.9043,                 loss: nan
agent1:                 episode reward: -0.9043,                 loss: 0.3260
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5274s / 59.7885 s
agent0:                 episode reward: 0.1062,                 loss: nan
agent1:                 episode reward: -0.1062,                 loss: 0.3248
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5268s / 60.3153 s
agent0:                 episode reward: 0.2237,                 loss: nan
agent1:                 episode reward: -0.2237,                 loss: 0.3259
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5147s / 60.8301 s
agent0:                 episode reward: 0.8755,                 loss: nan
agent1:                 episode reward: -0.8755,                 loss: 0.3244
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5368s / 61.3668 s
agent0:                 episode reward: 1.0658,                 loss: nan
agent1:                 episode reward: -1.0658,                 loss: 0.3456
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5646s / 61.9314 s
agent0:                 episode reward: 1.5245,                 loss: nan
agent1:                 episode reward: -1.5245,                 loss: 0.3493
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5143s / 62.4458 s
agent0:                 episode reward: 1.1472,                 loss: nan
agent1:                 episode reward: -1.1472,                 loss: 0.3509
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5178s / 62.9635 s
agent0:                 episode reward: 1.3841,                 loss: nan
agent1:                 episode reward: -1.3841,                 loss: 0.3495
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5103s / 63.4738 s
agent0:                 episode reward: 0.4324,                 loss: nan
agent1:                 episode reward: -0.4324,                 loss: 0.3488
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5245s / 63.9983 s
agent0:                 episode reward: 0.4464,                 loss: nan
agent1:                 episode reward: -0.4464,                 loss: 0.3480
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5654s / 64.5637 s
agent0:                 episode reward: 0.5787,                 loss: nan
agent1:                 episode reward: -0.5787,                 loss: 0.3490
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5478s / 65.1115 s
agent0:                 episode reward: 0.5969,                 loss: nan
agent1:                 episode reward: -0.5969,                 loss: 0.3483
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5372s / 65.6487 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: 0.3470
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5288s / 66.1775 s
agent0:                 episode reward: 0.6375,                 loss: nan
agent1:                 episode reward: -0.6375,                 loss: 0.3482
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5370s / 66.7146 s
agent0:                 episode reward: 0.5774,                 loss: nan
agent1:                 episode reward: -0.5774,                 loss: 0.3581
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5310s / 67.2456 s
agent0:                 episode reward: 0.9983,                 loss: nan
agent1:                 episode reward: -0.9983,                 loss: 0.3636
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5413s / 67.7869 s
agent0:                 episode reward: 0.7401,                 loss: nan
agent1:                 episode reward: -0.7401,                 loss: 0.3623
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5789s / 68.3659 s
agent0:                 episode reward: 0.6754,                 loss: nan
agent1:                 episode reward: -0.6754,                 loss: 0.3618
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5338s / 68.8997 s
agent0:                 episode reward: 0.7520,                 loss: nan
agent1:                 episode reward: -0.7520,                 loss: 0.3645
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5578s / 69.4574 s
agent0:                 episode reward: 0.5045,                 loss: nan
agent1:                 episode reward: -0.5045,                 loss: 0.3607
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5380s / 69.9954 s
agent0:                 episode reward: -0.4107,                 loss: nan
agent1:                 episode reward: 0.4107,                 loss: 0.3603
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5424s / 70.5378 s
agent0:                 episode reward: 1.0352,                 loss: nan
agent1:                 episode reward: -1.0352,                 loss: 0.3579
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5506s / 71.0884 s
agent0:                 episode reward: 0.8391,                 loss: nan
agent1:                 episode reward: -0.8391,                 loss: 0.3631
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5433s / 71.6316 s
agent0:                 episode reward: 0.6059,                 loss: nan
agent1:                 episode reward: -0.6059,                 loss: 0.3610
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5556s / 72.1873 s
agent0:                 episode reward: 0.5608,                 loss: nan
agent1:                 episode reward: -0.5608,                 loss: 0.3700
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5425s / 72.7298 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.3703
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5324s / 73.2622 s
agent0:                 episode reward: 0.0682,                 loss: nan
agent1:                 episode reward: -0.0682,                 loss: 0.3709
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5491s / 73.8113 s
agent0:                 episode reward: -0.4000,                 loss: nan
agent1:                 episode reward: 0.4000,                 loss: 0.3717
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5430s / 74.3542 s
agent0:                 episode reward: -0.1773,                 loss: nan
agent1:                 episode reward: 0.1773,                 loss: 0.3711
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5452s / 74.8995 s
agent0:                 episode reward: 0.1290,                 loss: nan
agent1:                 episode reward: -0.1290,                 loss: 0.3712
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5375s / 75.4370 s
agent0:                 episode reward: 0.4853,                 loss: nan
agent1:                 episode reward: -0.4853,                 loss: 0.3697
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5450s / 75.9820 s
agent0:                 episode reward: -0.0051,                 loss: nan
agent1:                 episode reward: 0.0051,                 loss: 0.3690
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5466s / 76.5286 s
agent0:                 episode reward: 1.1413,                 loss: nan
agent1:                 episode reward: -1.1413,                 loss: 0.3701
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5593s / 77.0879 s
agent0:                 episode reward: 0.4110,                 loss: nan
agent1:                 episode reward: -0.4110,                 loss: 0.3695
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5655s / 77.6535 s
agent0:                 episode reward: 0.6555,                 loss: nan
agent1:                 episode reward: -0.6555,                 loss: 0.3654
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5506s / 78.2041 s
agent0:                 episode reward: 0.5906,                 loss: nan
agent1:                 episode reward: -0.5906,                 loss: 0.3599
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6045s / 78.8086 s
agent0:                 episode reward: 0.4977,                 loss: nan
agent1:                 episode reward: -0.4977,                 loss: 0.3563
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5509s / 79.3595 s
agent0:                 episode reward: 0.7861,                 loss: nan
agent1:                 episode reward: -0.7861,                 loss: 0.3579
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5489s / 79.9084 s
agent0:                 episode reward: 0.1527,                 loss: nan
agent1:                 episode reward: -0.1527,                 loss: 0.3578
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5936s / 80.5020 s
agent0:                 episode reward: 0.4302,                 loss: nan
agent1:                 episode reward: -0.4302,                 loss: 0.3551
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5498s / 81.0518 s
agent0:                 episode reward: 0.4219,                 loss: nan
agent1:                 episode reward: -0.4219,                 loss: 0.3555
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5513s / 81.6031 s
agent0:                 episode reward: 0.1787,                 loss: nan
agent1:                 episode reward: -0.1787,                 loss: 0.3546
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5505s / 82.1536 s
agent0:                 episode reward: 0.0818,                 loss: nan
agent1:                 episode reward: -0.0818,                 loss: 0.3564
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5552s / 82.7088 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: 0.3577
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5719s / 83.2807 s
agent0:                 episode reward: 0.6111,                 loss: nan
agent1:                 episode reward: -0.6111,                 loss: 0.3432
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5513s / 83.8320 s
agent0:                 episode reward: 0.4919,                 loss: nan
agent1:                 episode reward: -0.4919,                 loss: 0.3347
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5466s / 84.3786 s
agent0:                 episode reward: 0.0065,                 loss: nan
agent1:                 episode reward: -0.0065,                 loss: 0.3330
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5564s / 84.9350 s
agent0:                 episode reward: -0.0100,                 loss: nan
agent1:                 episode reward: 0.0100,                 loss: 0.3329
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5591s / 85.4941 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.3331
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5859s / 86.0799 s
agent0:                 episode reward: 0.3240,                 loss: nan
agent1:                 episode reward: -0.3240,                 loss: 0.3317
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5601s / 86.6400 s
agent0:                 episode reward: 0.2938,                 loss: nan
agent1:                 episode reward: -0.2938,                 loss: 0.3319
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5629s / 87.2029 s
agent0:                 episode reward: -0.0885,                 loss: nan
agent1:                 episode reward: 0.0885,                 loss: 0.3294
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5554s / 87.7583 s
agent0:                 episode reward: 0.2170,                 loss: nan
agent1:                 episode reward: -0.2170,                 loss: 0.3305
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5549s / 88.3132 s
agent0:                 episode reward: 0.7876,                 loss: nan
agent1:                 episode reward: -0.7876,                 loss: 0.3299
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6172s / 88.9304 s
agent0:                 episode reward: 0.1508,                 loss: nan
agent1:                 episode reward: -0.1508,                 loss: 0.3175
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5673s / 89.4977 s
agent0:                 episode reward: 0.7836,                 loss: nan
agent1:                 episode reward: -0.7836,                 loss: 0.3098
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5617s / 90.0594 s
agent0:                 episode reward: 1.3429,                 loss: nan
agent1:                 episode reward: -1.3429,                 loss: 0.3102
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5559s / 90.6152 s
agent0:                 episode reward: 0.1254,                 loss: nan
agent1:                 episode reward: -0.1254,                 loss: 0.3098
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5697s / 91.1849 s
agent0:                 episode reward: 1.0995,                 loss: nan
agent1:                 episode reward: -1.0995,                 loss: 0.3112
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5636s / 91.7485 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.3080
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5765s / 92.3251 s
agent0:                 episode reward: 0.7862,                 loss: nan
agent1:                 episode reward: -0.7862,                 loss: 0.3108
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5588s / 92.8838 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.3100
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5648s / 93.4487 s
agent0:                 episode reward: 0.7437,                 loss: nan
agent1:                 episode reward: -0.7437,                 loss: 0.3099
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5713s / 94.0200 s
agent0:                 episode reward: 0.1886,                 loss: nan
agent1:                 episode reward: -0.1886,                 loss: 0.3104
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5800s / 94.5999 s
agent0:                 episode reward: 0.7370,                 loss: nan
agent1:                 episode reward: -0.7370,                 loss: 0.3059
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5731s / 95.1730 s
agent0:                 episode reward: 0.7132,                 loss: nan
agent1:                 episode reward: -0.7132,                 loss: 0.3005
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5762s / 95.7492 s
agent0:                 episode reward: 0.6253,                 loss: nan
agent1:                 episode reward: -0.6253,                 loss: 0.2984
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5731s / 96.3223 s
agent0:                 episode reward: -0.1174,                 loss: nan
agent1:                 episode reward: 0.1174,                 loss: 0.3004
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5793s / 96.9016 s
agent0:                 episode reward: 1.0798,                 loss: nan
agent1:                 episode reward: -1.0798,                 loss: 0.3004
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5587s / 97.4603 s
agent0:                 episode reward: 0.2714,                 loss: nan
agent1:                 episode reward: -0.2714,                 loss: 0.2986
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5707s / 98.0310 s
agent0:                 episode reward: 1.4664,                 loss: nan
agent1:                 episode reward: -1.4664,                 loss: 0.2977
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5667s / 98.5977 s
agent0:                 episode reward: -0.4867,                 loss: nan
agent1:                 episode reward: 0.4867,                 loss: 0.2978
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6128s / 99.2106 s
agent0:                 episode reward: 0.4501,                 loss: nan
agent1:                 episode reward: -0.4501,                 loss: 0.2989
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5683s / 99.7788 s
agent0:                 episode reward: 0.6509,                 loss: nan
agent1:                 episode reward: -0.6509,                 loss: 0.2960
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5724s / 100.3512 s
agent0:                 episode reward: 0.6665,                 loss: nan
agent1:                 episode reward: -0.6665,                 loss: 0.3023
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5765s / 100.9277 s
agent0:                 episode reward: 0.6379,                 loss: nan
agent1:                 episode reward: -0.6379,                 loss: 0.3023
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 101.5109 s
agent0:                 episode reward: -0.2740,                 loss: nan
agent1:                 episode reward: 0.2740,                 loss: 0.3019
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5758s / 102.0867 s
agent0:                 episode reward: 1.4977,                 loss: nan
agent1:                 episode reward: -1.4977,                 loss: 0.3022
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6004s / 102.6871 s
agent0:                 episode reward: 0.5528,                 loss: nan
agent1:                 episode reward: -0.5528,                 loss: 0.3035
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5899s / 103.2770 s
agent0:                 episode reward: 0.9126,                 loss: nan
agent1:                 episode reward: -0.9126,                 loss: 0.3004
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5788s / 103.8558 s
agent0:                 episode reward: 0.3225,                 loss: nan
agent1:                 episode reward: -0.3225,                 loss: 0.3044
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5804s / 104.4362 s
agent0:                 episode reward: 0.5839,                 loss: nan
agent1:                 episode reward: -0.5839,                 loss: 0.3032
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5762s / 105.0124 s
agent0:                 episode reward: 0.4964,                 loss: nan
agent1:                 episode reward: -0.4964,                 loss: 0.3019
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5831s / 105.5955 s
agent0:                 episode reward: 0.2974,                 loss: nan
agent1:                 episode reward: -0.2974,                 loss: 0.3032
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5799s / 106.1754 s
agent0:                 episode reward: -0.3755,                 loss: nan
agent1:                 episode reward: 0.3755,                 loss: 0.3199
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5864s / 106.7619 s
agent0:                 episode reward: 0.3111,                 loss: nan
agent1:                 episode reward: -0.3111,                 loss: 0.3248
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5863s / 107.3482 s
agent0:                 episode reward: 0.4699,                 loss: nan
agent1:                 episode reward: -0.4699,                 loss: 0.3254
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5770s / 107.9253 s
agent0:                 episode reward: -0.1128,                 loss: nan
agent1:                 episode reward: 0.1128,                 loss: 0.3234
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5777s / 108.5030 s
agent0:                 episode reward: 0.4730,                 loss: nan
agent1:                 episode reward: -0.4730,                 loss: 0.3224
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5995s / 109.1024 s
agent0:                 episode reward: 0.6494,                 loss: nan
agent1:                 episode reward: -0.6494,                 loss: 0.3221
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6256s / 109.7280 s
agent0:                 episode reward: 0.8372,                 loss: nan
agent1:                 episode reward: -0.8372,                 loss: 0.3252
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5913s / 110.3193 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3210
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6005s / 110.9198 s
agent0:                 episode reward: 0.9149,                 loss: nan
agent1:                 episode reward: -0.9149,                 loss: 0.3235
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5733s / 111.4930 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.3242
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5805s / 112.0736 s
agent0:                 episode reward: 0.0511,                 loss: nan
agent1:                 episode reward: -0.0511,                 loss: 0.3485
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5946s / 112.6682 s
agent0:                 episode reward: 1.1207,                 loss: nan
agent1:                 episode reward: -1.1207,                 loss: 0.3578
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6012s / 113.2694 s
agent0:                 episode reward: -1.1227,                 loss: nan
agent1:                 episode reward: 1.1227,                 loss: 0.3584
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5871s / 113.8565 s
agent0:                 episode reward: 0.5760,                 loss: nan
agent1:                 episode reward: -0.5760,                 loss: 0.3580
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5809s / 114.4374 s
agent0:                 episode reward: -0.0449,                 loss: nan
agent1:                 episode reward: 0.0449,                 loss: 0.3578
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6440s / 115.0815 s
agent0:                 episode reward: 0.6450,                 loss: nan
agent1:                 episode reward: -0.6450,                 loss: 0.3588
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5918s / 115.6732 s
agent0:                 episode reward: 0.8611,                 loss: nan
agent1:                 episode reward: -0.8611,                 loss: 0.3574
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5928s / 116.2660 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3584
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5780s / 116.8440 s
agent0:                 episode reward: 1.5042,                 loss: nan
agent1:                 episode reward: -1.5042,                 loss: 0.3593
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5835s / 117.4275 s
agent0:                 episode reward: 0.4325,                 loss: nan
agent1:                 episode reward: -0.4325,                 loss: 0.3583
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5933s / 118.0209 s
agent0:                 episode reward: 0.5809,                 loss: nan
agent1:                 episode reward: -0.5809,                 loss: 0.3786
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5821s / 118.6030 s
agent0:                 episode reward: 0.7490,                 loss: nan
agent1:                 episode reward: -0.7490,                 loss: 0.3859
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6206s / 119.2236 s
agent0:                 episode reward: 1.0610,                 loss: nan
agent1:                 episode reward: -1.0610,                 loss: 0.3865
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6500s / 119.8735 s
agent0:                 episode reward: 0.7942,                 loss: nan
agent1:                 episode reward: -0.7942,                 loss: 0.3863
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5879s / 120.4614 s
agent0:                 episode reward: 0.0939,                 loss: nan
agent1:                 episode reward: -0.0939,                 loss: 0.3854
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5898s / 121.0513 s
agent0:                 episode reward: 0.5739,                 loss: nan
agent1:                 episode reward: -0.5739,                 loss: 0.3851
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5900s / 121.6412 s
agent0:                 episode reward: 0.3546,                 loss: nan
agent1:                 episode reward: -0.3546,                 loss: 0.3842
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5968s / 122.2380 s
agent0:                 episode reward: -0.2356,                 loss: nan
agent1:                 episode reward: 0.2356,                 loss: 0.3850
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5987s / 122.8366 s
agent0:                 episode reward: 0.1123,                 loss: nan
agent1:                 episode reward: -0.1123,                 loss: 0.3838
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5945s / 123.4311 s
agent0:                 episode reward: 0.4336,                 loss: nan
agent1:                 episode reward: -0.4336,                 loss: 0.3850
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6005s / 124.0316 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.3871
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6021s / 124.6336 s
agent0:                 episode reward: 0.7045,                 loss: nan
agent1:                 episode reward: -0.7045,                 loss: 0.3806
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5937s / 125.2273 s
agent0:                 episode reward: 0.9588,                 loss: nan
agent1:                 episode reward: -0.9588,                 loss: 0.3813
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6058s / 125.8331 s
agent0:                 episode reward: 1.7097,                 loss: nan
agent1:                 episode reward: -1.7097,                 loss: 0.3820
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5989s / 126.4320 s
agent0:                 episode reward: 1.5626,                 loss: nan
agent1:                 episode reward: -1.5626,                 loss: 0.3794
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5955s / 127.0274 s
agent0:                 episode reward: 1.0137,                 loss: nan
agent1:                 episode reward: -1.0137,                 loss: 0.3816
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6057s / 127.6332 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.3812
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5932s / 128.2263 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.3813
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6024s / 128.8287 s
agent0:                 episode reward: 0.5113,                 loss: nan
agent1:                 episode reward: -0.5113,                 loss: 0.3794
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5952s / 129.4239 s
agent0:                 episode reward: 0.0537,                 loss: nan
agent1:                 episode reward: -0.0537,                 loss: 0.3808
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6406s / 130.0645 s
agent0:                 episode reward: -0.4164,                 loss: nan
agent1:                 episode reward: 0.4164,                 loss: 0.3552
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5994s / 130.6639 s
agent0:                 episode reward: 1.6121,                 loss: nan
agent1:                 episode reward: -1.6121,                 loss: 0.3459
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6051s / 131.2690 s
agent0:                 episode reward: 1.3476,                 loss: nan
agent1:                 episode reward: -1.3476,                 loss: 0.3454
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6009s / 131.8699 s
agent0:                 episode reward: 0.8789,                 loss: nan
agent1:                 episode reward: -0.8789,                 loss: 0.3442
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6145s / 132.4844 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.3439
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6059s / 133.0903 s
agent0:                 episode reward: 0.5407,                 loss: nan
agent1:                 episode reward: -0.5407,                 loss: 0.3470
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5949s / 133.6852 s
agent0:                 episode reward: -0.1026,                 loss: nan
agent1:                 episode reward: 0.1026,                 loss: 0.3441
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6080s / 134.2932 s
agent0:                 episode reward: -0.3064,                 loss: nan
agent1:                 episode reward: 0.3064,                 loss: 0.3444
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6030s / 134.8962 s
agent0:                 episode reward: 1.1041,                 loss: nan
agent1:                 episode reward: -1.1041,                 loss: 0.3419
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5998s / 135.4960 s
agent0:                 episode reward: -0.7891,                 loss: nan
agent1:                 episode reward: 0.7891,                 loss: 0.3433
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6258s / 136.1218 s
agent0:                 episode reward: 0.5415,                 loss: nan
agent1:                 episode reward: -0.5415,                 loss: 0.3283
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6054s / 136.7273 s
agent0:                 episode reward: 0.8883,                 loss: nan
agent1:                 episode reward: -0.8883,                 loss: 0.3197
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6064s / 137.3336 s
agent0:                 episode reward: 0.0347,                 loss: nan
agent1:                 episode reward: -0.0347,                 loss: 0.3174
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6039s / 137.9376 s
agent0:                 episode reward: -0.1226,                 loss: nan
agent1:                 episode reward: 0.1226,                 loss: 0.3186
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6108s / 138.5484 s
agent0:                 episode reward: 1.0006,                 loss: nan
agent1:                 episode reward: -1.0006,                 loss: 0.3203
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6033s / 139.1517 s
agent0:                 episode reward: 1.0277,                 loss: nan
agent1:                 episode reward: -1.0277,                 loss: 0.3175
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6024s / 139.7541 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.3190
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6908s / 140.4449 s
agent0:                 episode reward: 0.3384,                 loss: nan
agent1:                 episode reward: -0.3384,                 loss: 0.3166
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6064s / 141.0514 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3188
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6044s / 141.6557 s
agent0:                 episode reward: 0.2195,                 loss: nan
agent1:                 episode reward: -0.2195,                 loss: 0.3185
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6066s / 142.2624 s
agent0:                 episode reward: 0.3074,                 loss: nan
agent1:                 episode reward: -0.3074,                 loss: 0.3105
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6112s / 142.8736 s
agent0:                 episode reward: 1.4277,                 loss: nan
agent1:                 episode reward: -1.4277,                 loss: 0.3054
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6222s / 143.4958 s
agent0:                 episode reward: 1.4680,                 loss: nan
agent1:                 episode reward: -1.4680,                 loss: 0.3046
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6285s / 144.1243 s
agent0:                 episode reward: 0.4974,                 loss: nan
agent1:                 episode reward: -0.4974,                 loss: 0.3064
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6176s / 144.7419 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.3065
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6655s / 145.4074 s
agent0:                 episode reward: 0.1024,                 loss: nan
agent1:                 episode reward: -0.1024,                 loss: 0.3041
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6134s / 146.0208 s
agent0:                 episode reward: -0.0444,                 loss: nan
agent1:                 episode reward: 0.0444,                 loss: 0.3030
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6140s / 146.6348 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.3051
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6122s / 147.2471 s
agent0:                 episode reward: -0.5302,                 loss: nan
agent1:                 episode reward: 0.5302,                 loss: 0.3049
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6095s / 147.8566 s
agent0:                 episode reward: 0.3467,                 loss: nan
agent1:                 episode reward: -0.3467,                 loss: 0.3048
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6057s / 148.4623 s
agent0:                 episode reward: 0.1365,                 loss: nan
agent1:                 episode reward: -0.1365,                 loss: 0.2966
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6179s / 149.0802 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.2921
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6224s / 149.7025 s
agent0:                 episode reward: -0.2062,                 loss: nan
agent1:                 episode reward: 0.2062,                 loss: 0.2925
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6752s / 150.3778 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.2917
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6239s / 151.0017 s
agent0:                 episode reward: -0.0226,                 loss: nan
agent1:                 episode reward: 0.0226,                 loss: 0.2904
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6245s / 151.6262 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.2899
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6231s / 152.2492 s
agent0:                 episode reward: -0.1453,                 loss: nan
agent1:                 episode reward: 0.1453,                 loss: 0.2908
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6514s / 152.9006 s
agent0:                 episode reward: -0.1015,                 loss: nan
agent1:                 episode reward: 0.1015,                 loss: 0.2918
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6359s / 153.5365 s
agent0:                 episode reward: 0.2325,                 loss: nan
agent1:                 episode reward: -0.2325,                 loss: 0.2907
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6145s / 154.1510 s
agent0:                 episode reward: 0.6767,                 loss: nan
agent1:                 episode reward: -0.6767,                 loss: 0.2907
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6219s / 154.7729 s
agent0:                 episode reward: -0.2895,                 loss: nan
agent1:                 episode reward: 0.2895,                 loss: 0.2894
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6208s / 155.3937 s
agent0:                 episode reward: 0.6109,                 loss: nan
agent1:                 episode reward: -0.6109,                 loss: 0.2821
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6259s / 156.0196 s
agent0:                 episode reward: 0.7447,                 loss: nan
agent1:                 episode reward: -0.7447,                 loss: 0.2829
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6272s / 156.6469 s
agent0:                 episode reward: 0.2164,                 loss: nan
agent1:                 episode reward: -0.2164,                 loss: 0.2820
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6238s / 157.2707 s
agent0:                 episode reward: -0.2311,                 loss: nan
agent1:                 episode reward: 0.2311,                 loss: 0.2790
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6261s / 157.8968 s
agent0:                 episode reward: 0.1226,                 loss: nan
agent1:                 episode reward: -0.1226,                 loss: 0.2804
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6417s / 158.5385 s
agent0:                 episode reward: -0.6092,                 loss: nan
agent1:                 episode reward: 0.6092,                 loss: 0.2767
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6210s / 159.1594 s
agent0:                 episode reward: 0.1208,                 loss: nan
agent1:                 episode reward: -0.1208,                 loss: 0.2803
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6256s / 159.7851 s
agent0:                 episode reward: 1.1758,                 loss: nan
agent1:                 episode reward: -1.1758,                 loss: 0.2794
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6661s / 160.4512 s
agent0:                 episode reward: 0.4110,                 loss: nan
agent1:                 episode reward: -0.4110,                 loss: 0.2802
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6262s / 161.0775 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.2941
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6339s / 161.7113 s
agent0:                 episode reward: -0.1960,                 loss: nan
agent1:                 episode reward: 0.1960,                 loss: 0.2971
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6312s / 162.3425 s
agent0:                 episode reward: 0.3164,                 loss: nan
agent1:                 episode reward: -0.3164,                 loss: 0.2961
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6243s / 162.9668 s
agent0:                 episode reward: 0.5123,                 loss: nan
agent1:                 episode reward: -0.5123,                 loss: 0.2969
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6340s / 163.6009 s
agent0:                 episode reward: 0.8580,                 loss: nan
agent1:                 episode reward: -0.8580,                 loss: 0.2958
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6261s / 164.2269 s
agent0:                 episode reward: 0.1707,                 loss: nan
agent1:                 episode reward: -0.1707,                 loss: 0.2933
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6303s / 164.8572 s
agent0:                 episode reward: 0.6245,                 loss: nan
agent1:                 episode reward: -0.6245,                 loss: 0.2967
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6242s / 165.4815 s
agent0:                 episode reward: 0.5002,                 loss: nan
agent1:                 episode reward: -0.5002,                 loss: 0.2944
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6309s / 166.1124 s
agent0:                 episode reward: -0.3091,                 loss: nan
agent1:                 episode reward: 0.3091,                 loss: 0.2950
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6335s / 166.7460 s
agent0:                 episode reward: 0.2468,                 loss: nan
agent1:                 episode reward: -0.2468,                 loss: 0.2965
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6268s / 167.3727 s
agent0:                 episode reward: 0.6464,                 loss: nan
agent1:                 episode reward: -0.6464,                 loss: 0.3296
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6297s / 168.0024 s
agent0:                 episode reward: 0.1072,                 loss: nan
agent1:                 episode reward: -0.1072,                 loss: 0.3366
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6442s / 168.6466 s
agent0:                 episode reward: 0.1994,                 loss: nan
agent1:                 episode reward: -0.1994,                 loss: 0.3365
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6399s / 169.2865 s
agent0:                 episode reward: -0.0142,                 loss: nan
agent1:                 episode reward: 0.0142,                 loss: 0.3364
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6330s / 169.9195 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.3355
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6459s / 170.5654 s
agent0:                 episode reward: 0.0808,                 loss: nan
agent1:                 episode reward: -0.0808,                 loss: 0.3351
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6988s / 171.2642 s
agent0:                 episode reward: 1.3027,                 loss: nan
agent1:                 episode reward: -1.3027,                 loss: 0.3374
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6327s / 171.8968 s
agent0:                 episode reward: 0.0009,                 loss: nan
agent1:                 episode reward: -0.0009,                 loss: 0.3352
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6360s / 172.5329 s
agent0:                 episode reward: 0.1132,                 loss: nan
agent1:                 episode reward: -0.1132,                 loss: 0.3342
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6453s / 173.1782 s
agent0:                 episode reward: -0.2187,                 loss: nan
agent1:                 episode reward: 0.2187,                 loss: 0.3356
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6448s / 173.8230 s
agent0:                 episode reward: -0.9295,                 loss: nan
agent1:                 episode reward: 0.9295,                 loss: 0.3516
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6307s / 174.4537 s
agent0:                 episode reward: 1.2386,                 loss: nan
agent1:                 episode reward: -1.2386,                 loss: 0.3498
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6359s / 175.0896 s
agent0:                 episode reward: 0.5454,                 loss: nan
agent1:                 episode reward: -0.5454,                 loss: 0.3494
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6377s / 175.7273 s
agent0:                 episode reward: 0.5907,                 loss: nan
agent1:                 episode reward: -0.5907,                 loss: 0.3495
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6368s / 176.3641 s
agent0:                 episode reward: 0.3075,                 loss: nan
agent1:                 episode reward: -0.3075,                 loss: 0.3493
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6720s / 177.0361 s
agent0:                 episode reward: 0.7737,                 loss: nan
agent1:                 episode reward: -0.7737,                 loss: 0.3495
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6401s / 177.6762 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.3505
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6369s / 178.3131 s
agent0:                 episode reward: -0.2897,                 loss: nan
agent1:                 episode reward: 0.2897,                 loss: 0.3497
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6415s / 178.9546 s
agent0:                 episode reward: 0.0940,                 loss: nan
agent1:                 episode reward: -0.0940,                 loss: 0.3503
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6419s / 179.5965 s
agent0:                 episode reward: -0.1541,                 loss: nan
agent1:                 episode reward: 0.1541,                 loss: 0.3489
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6393s / 180.2358 s
agent0:                 episode reward: 0.2846,                 loss: nan
agent1:                 episode reward: -0.2846,                 loss: 0.3128
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6610s / 180.8968 s
agent0:                 episode reward: 0.2865,                 loss: nan
agent1:                 episode reward: -0.2865,                 loss: 0.2765
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6603s / 181.5571 s
agent0:                 episode reward: 0.3275,                 loss: nan
agent1:                 episode reward: -0.3275,                 loss: 0.2757
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6434s / 182.2005 s
agent0:                 episode reward: -0.7244,                 loss: nan
agent1:                 episode reward: 0.7244,                 loss: 0.2743
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6427s / 182.8432 s
agent0:                 episode reward: 0.8866,                 loss: nan
agent1:                 episode reward: -0.8866,                 loss: 0.2728
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6457s / 183.4889 s
agent0:                 episode reward: 0.6118,                 loss: nan
agent1:                 episode reward: -0.6118,                 loss: 0.2730
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6508s / 184.1397 s
agent0:                 episode reward: 1.6772,                 loss: nan
agent1:                 episode reward: -1.6772,                 loss: 0.2732
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6374s / 184.7771 s
agent0:                 episode reward: 1.5418,                 loss: nan
agent1:                 episode reward: -1.5418,                 loss: 0.2696
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6626s / 185.4396 s
agent0:                 episode reward: 1.3246,                 loss: nan
agent1:                 episode reward: -1.3246,                 loss: 0.2726
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6718s / 186.1115 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: 0.2707
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6418s / 186.7533 s
agent0:                 episode reward: 1.3138,                 loss: nan
agent1:                 episode reward: -1.3138,                 loss: 0.2382
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6427s / 187.3960 s
agent0:                 episode reward: 0.8856,                 loss: nan
agent1:                 episode reward: -0.8856,                 loss: 0.2129
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6465s / 188.0424 s
agent0:                 episode reward: 1.5216,                 loss: nan
agent1:                 episode reward: -1.5216,                 loss: 0.2108
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6426s / 188.6851 s
agent0:                 episode reward: 0.1896,                 loss: nan
agent1:                 episode reward: -0.1896,                 loss: 0.2099
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6526s / 189.3377 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.2101
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6388s / 189.9765 s
agent0:                 episode reward: 0.9943,                 loss: nan
agent1:                 episode reward: -0.9943,                 loss: 0.2096
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6452s / 190.6216 s
agent0:                 episode reward: 1.1100,                 loss: nan
agent1:                 episode reward: -1.1100,                 loss: 0.2097
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6794s / 191.3010 s
agent0:                 episode reward: 0.5435,                 loss: nan
agent1:                 episode reward: -0.5435,                 loss: 0.2089
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6467s / 191.9478 s
agent0:                 episode reward: 0.0997,                 loss: nan
agent1:                 episode reward: -0.0997,                 loss: 0.2098
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6706s / 192.6183 s
agent0:                 episode reward: 0.7881,                 loss: nan
agent1:                 episode reward: -0.7881,                 loss: 0.2103
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6451s / 193.2634 s
agent0:                 episode reward: -0.2533,                 loss: nan
agent1:                 episode reward: 0.2533,                 loss: 0.2424
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6842s / 193.9476 s
agent0:                 episode reward: 0.3532,                 loss: nan
agent1:                 episode reward: -0.3532,                 loss: 0.2485
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6579s / 194.6055 s
agent0:                 episode reward: 0.4964,                 loss: nan
agent1:                 episode reward: -0.4964,                 loss: 0.2486
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6761s / 195.2816 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.2444
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6520s / 195.9336 s
agent0:                 episode reward: 0.0439,                 loss: nan
agent1:                 episode reward: -0.0439,                 loss: 0.2444
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6555s / 196.5892 s
agent0:                 episode reward: -0.4903,                 loss: nan
agent1:                 episode reward: 0.4903,                 loss: 0.2449
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6529s / 197.2421 s
agent0:                 episode reward: 0.7214,                 loss: nan
agent1:                 episode reward: -0.7214,                 loss: 0.2499
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6436s / 197.8857 s
agent0:                 episode reward: 0.6442,                 loss: nan
agent1:                 episode reward: -0.6442,                 loss: 0.2455
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6685s / 198.5542 s
agent0:                 episode reward: 0.6997,                 loss: nan
agent1:                 episode reward: -0.6997,                 loss: 0.2461
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6517s / 199.2058 s
agent0:                 episode reward: 0.5411,                 loss: nan
agent1:                 episode reward: -0.5411,                 loss: 0.2476
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6474s / 199.8532 s
agent0:                 episode reward: 0.2576,                 loss: nan
agent1:                 episode reward: -0.2576,                 loss: 0.2802
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6559s / 200.5092 s
agent0:                 episode reward: -0.7469,                 loss: nan
agent1:                 episode reward: 0.7469,                 loss: 0.2872
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6633s / 201.1725 s
agent0:                 episode reward: -0.4306,                 loss: nan
agent1:                 episode reward: 0.4306,                 loss: 0.2863
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7137s / 201.8862 s
agent0:                 episode reward: 0.6432,                 loss: nan
agent1:                 episode reward: -0.6432,                 loss: 0.2841
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6729s / 202.5592 s
agent0:                 episode reward: -0.2649,                 loss: nan
agent1:                 episode reward: 0.2649,                 loss: 0.2841
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6645s / 203.2237 s
agent0:                 episode reward: 0.3903,                 loss: nan
agent1:                 episode reward: -0.3903,                 loss: 0.2840
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6656s / 203.8894 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: 0.2862
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6664s / 204.5558 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.2847
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6669s / 205.2227 s
agent0:                 episode reward: -0.8334,                 loss: nan
agent1:                 episode reward: 0.8334,                 loss: 0.2825
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6993s / 205.9220 s
agent0:                 episode reward: -0.7481,                 loss: nan
agent1:                 episode reward: 0.7481,                 loss: 0.2837
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6599s / 206.5819 s
agent0:                 episode reward: 0.2647,                 loss: nan
agent1:                 episode reward: -0.2647,                 loss: 0.2850
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6810s / 207.2629 s
agent0:                 episode reward: -0.0975,                 loss: nan
agent1:                 episode reward: 0.0975,                 loss: 0.2776
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6822s / 207.9451 s
agent0:                 episode reward: 0.6224,                 loss: nan
agent1:                 episode reward: -0.6224,                 loss: 0.2764
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6670s / 208.6121 s
agent0:                 episode reward: 0.3883,                 loss: nan
agent1:                 episode reward: -0.3883,                 loss: 0.2799
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6738s / 209.2859 s
agent0:                 episode reward: 0.6358,                 loss: nan
agent1:                 episode reward: -0.6358,                 loss: 0.2773
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6880s / 209.9739 s
agent0:                 episode reward: -1.5375,                 loss: nan
agent1:                 episode reward: 1.5375,                 loss: 0.2773
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6814s / 210.6553 s
agent0:                 episode reward: 1.1613,                 loss: nan
agent1:                 episode reward: -1.1613,                 loss: 0.2763
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6686s / 211.3239 s
agent0:                 episode reward: -0.6848,                 loss: nan
agent1:                 episode reward: 0.6848,                 loss: 0.2755
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7208s / 212.0447 s
agent0:                 episode reward: -0.4559,                 loss: nan
agent1:                 episode reward: 0.4559,                 loss: 0.2784
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6647s / 212.7093 s
agent0:                 episode reward: 0.6670,                 loss: nan
agent1:                 episode reward: -0.6670,                 loss: 0.2766
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6819s / 213.3912 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.2855
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6785s / 214.0697 s
agent0:                 episode reward: -0.3390,                 loss: nan
agent1:                 episode reward: 0.3390,                 loss: 0.2887
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6727s / 214.7424 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.2878
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6686s / 215.4110 s
agent0:                 episode reward: 0.6947,                 loss: nan
agent1:                 episode reward: -0.6947,                 loss: 0.2877
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6989s / 216.1099 s
agent0:                 episode reward: 0.3789,                 loss: nan
agent1:                 episode reward: -0.3789,                 loss: 0.2872
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6814s / 216.7914 s
agent0:                 episode reward: 0.5740,                 loss: nan
agent1:                 episode reward: -0.5740,                 loss: 0.2870
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6827s / 217.4740 s
agent0:                 episode reward: 1.2385,                 loss: nan
agent1:                 episode reward: -1.2385,                 loss: 0.2880
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6734s / 218.1474 s
agent0:                 episode reward: 0.8378,                 loss: nan
agent1:                 episode reward: -0.8378,                 loss: 0.2874
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6940s / 218.8414 s
agent0:                 episode reward: -0.0985,                 loss: nan
agent1:                 episode reward: 0.0985,                 loss: 0.2871
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6845s / 219.5259 s
agent0:                 episode reward: -0.3052,                 loss: nan
agent1:                 episode reward: 0.3052,                 loss: 0.2887
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6818s / 220.2077 s
agent0:                 episode reward: 0.7763,                 loss: nan
agent1:                 episode reward: -0.7763,                 loss: 0.3164
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6729s / 220.8805 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.3271
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6734s / 221.5540 s
agent0:                 episode reward: -0.3042,                 loss: nan
agent1:                 episode reward: 0.3042,                 loss: 0.3240
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7353s / 222.2892 s
agent0:                 episode reward: 0.1679,                 loss: nan
agent1:                 episode reward: -0.1679,                 loss: 0.3275
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7053s / 222.9945 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.3248
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6799s / 223.6744 s
agent0:                 episode reward: -0.0537,                 loss: nan
agent1:                 episode reward: 0.0537,                 loss: 0.3269
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6944s / 224.3688 s
agent0:                 episode reward: 0.0946,                 loss: nan
agent1:                 episode reward: -0.0946,                 loss: 0.3234
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6937s / 225.0626 s
agent0:                 episode reward: -0.2484,                 loss: nan
agent1:                 episode reward: 0.2484,                 loss: 0.3259
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6756s / 225.7382 s
agent0:                 episode reward: 0.5371,                 loss: nan
agent1:                 episode reward: -0.5371,                 loss: 0.3226
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6817s / 226.4199 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.3235
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6975s / 227.1174 s
agent0:                 episode reward: 1.2990,                 loss: nan
agent1:                 episode reward: -1.2990,                 loss: 0.3440
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6764s / 227.7938 s
agent0:                 episode reward: 1.2604,                 loss: nan
agent1:                 episode reward: -1.2604,                 loss: 0.3505
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6831s / 228.4769 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.3485
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6808s / 229.1577 s
agent0:                 episode reward: 0.3704,                 loss: nan
agent1:                 episode reward: -0.3704,                 loss: 0.3487
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6779s / 229.8356 s
agent0:                 episode reward: 0.6495,                 loss: nan
agent1:                 episode reward: -0.6495,                 loss: 0.3463
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6789s / 230.5144 s
agent0:                 episode reward: 0.5608,                 loss: nan
agent1:                 episode reward: -0.5608,                 loss: 0.3464
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6868s / 231.2013 s
agent0:                 episode reward: 0.4286,                 loss: nan
agent1:                 episode reward: -0.4286,                 loss: 0.3455
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6798s / 231.8811 s
agent0:                 episode reward: -0.2955,                 loss: nan
agent1:                 episode reward: 0.2955,                 loss: 0.3447
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7293s / 232.6104 s
agent0:                 episode reward: -0.8957,                 loss: nan
agent1:                 episode reward: 0.8957,                 loss: 0.3459
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6910s / 233.3014 s
agent0:                 episode reward: 1.4198,                 loss: nan
agent1:                 episode reward: -1.4198,                 loss: 0.3458
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 233.9863 s
agent0:                 episode reward: -0.3345,                 loss: nan
agent1:                 episode reward: 0.3345,                 loss: 0.3696
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7062s / 234.6926 s
agent0:                 episode reward: 0.3023,                 loss: nan
agent1:                 episode reward: -0.3023,                 loss: 0.3758
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7014s / 235.3939 s
agent0:                 episode reward: 0.2649,                 loss: nan
agent1:                 episode reward: -0.2649,                 loss: 0.3740
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6804s / 236.0743 s
agent0:                 episode reward: 0.3014,                 loss: nan
agent1:                 episode reward: -0.3014,                 loss: 0.3761
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6878s / 236.7621 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.3743
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6940s / 237.4561 s
agent0:                 episode reward: 0.5682,                 loss: nan
agent1:                 episode reward: -0.5682,                 loss: 0.3744
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6847s / 238.1408 s
agent0:                 episode reward: 0.2325,                 loss: nan
agent1:                 episode reward: -0.2325,                 loss: 0.3738
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6910s / 238.8318 s
agent0:                 episode reward: 0.4214,                 loss: nan
agent1:                 episode reward: -0.4214,                 loss: 0.3725
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6895s / 239.5213 s
agent0:                 episode reward: 1.0317,                 loss: nan
agent1:                 episode reward: -1.0317,                 loss: 0.3729
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6924s / 240.2137 s
agent0:                 episode reward: 0.2959,                 loss: nan
agent1:                 episode reward: -0.2959,                 loss: 0.3733
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6852s / 240.8988 s
agent0:                 episode reward: 0.8990,                 loss: nan
agent1:                 episode reward: -0.8990,                 loss: 0.3802
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6902s / 241.5890 s
agent0:                 episode reward: 1.6867,                 loss: nan
agent1:                 episode reward: -1.6867,                 loss: 0.3749
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6979s / 242.2869 s
agent0:                 episode reward: 1.6345,                 loss: nan
agent1:                 episode reward: -1.6345,                 loss: 0.3747
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7413s / 243.0282 s
agent0:                 episode reward: 0.6723,                 loss: nan
agent1:                 episode reward: -0.6723,                 loss: 0.3760
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7216s / 243.7497 s
agent0:                 episode reward: 0.1700,                 loss: nan
agent1:                 episode reward: -0.1700,                 loss: 0.3760
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6996s / 244.4493 s
agent0:                 episode reward: -0.2885,                 loss: nan
agent1:                 episode reward: 0.2885,                 loss: 0.3736
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6901s / 245.1394 s
agent0:                 episode reward: 0.7486,                 loss: nan
agent1:                 episode reward: -0.7486,                 loss: 0.3732
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6967s / 245.8360 s
agent0:                 episode reward: 0.3964,                 loss: nan
agent1:                 episode reward: -0.3964,                 loss: 0.3748
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6847s / 246.5207 s
agent0:                 episode reward: 0.3666,                 loss: nan
agent1:                 episode reward: -0.3666,                 loss: 0.3738
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6993s / 247.2201 s
agent0:                 episode reward: 0.8881,                 loss: nan
agent1:                 episode reward: -0.8881,                 loss: 0.3734
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6912s / 247.9112 s
agent0:                 episode reward: -0.0982,                 loss: nan
agent1:                 episode reward: 0.0982,                 loss: 0.3345
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6854s / 248.5966 s
agent0:                 episode reward: 1.2953,                 loss: nan
agent1:                 episode reward: -1.2953,                 loss: 0.3108
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7049s / 249.3015 s
agent0:                 episode reward: 0.9549,                 loss: nan
agent1:                 episode reward: -0.9549,                 loss: 0.3081
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6912s / 249.9927 s
agent0:                 episode reward: 0.9303,                 loss: nan
agent1:                 episode reward: -0.9303,                 loss: 0.3081
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6876s / 250.6803 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: 0.3058
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6935s / 251.3738 s
agent0:                 episode reward: -1.0991,                 loss: nan
agent1:                 episode reward: 1.0991,                 loss: 0.3069
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7115s / 252.0853 s
agent0:                 episode reward: -0.1206,                 loss: nan
agent1:                 episode reward: 0.1206,                 loss: 0.3063
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7379s / 252.8231 s
agent0:                 episode reward: -0.0961,                 loss: nan
agent1:                 episode reward: 0.0961,                 loss: 0.3040
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7009s / 253.5240 s
agent0:                 episode reward: -0.0972,                 loss: nan
agent1:                 episode reward: 0.0972,                 loss: 0.3038
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7002s / 254.2242 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.3040
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7093s / 254.9335 s
agent0:                 episode reward: -0.0392,                 loss: nan
agent1:                 episode reward: 0.0392,                 loss: 0.2902
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7171s / 255.6506 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.2830
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6951s / 256.3457 s
agent0:                 episode reward: 0.8155,                 loss: nan
agent1:                 episode reward: -0.8155,                 loss: 0.2814
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6914s / 257.0370 s
agent0:                 episode reward: -0.1015,                 loss: nan
agent1:                 episode reward: 0.1015,                 loss: 0.2775
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6993s / 257.7364 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.2790
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7058s / 258.4421 s
agent0:                 episode reward: 0.0649,                 loss: nan
agent1:                 episode reward: -0.0649,                 loss: 0.2782
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6921s / 259.1343 s
agent0:                 episode reward: -0.2312,                 loss: nan
agent1:                 episode reward: 0.2312,                 loss: 0.2789
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7062s / 259.8404 s
agent0:                 episode reward: 1.2178,                 loss: nan
agent1:                 episode reward: -1.2178,                 loss: 0.2784
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7231s / 260.5635 s
agent0:                 episode reward: 0.2917,                 loss: nan
agent1:                 episode reward: -0.2917,                 loss: 0.2786
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7002s / 261.2637 s
agent0:                 episode reward: 0.6822,                 loss: nan
agent1:                 episode reward: -0.6822,                 loss: 0.2780
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7006s / 261.9643 s
agent0:                 episode reward: -0.5193,                 loss: nan
agent1:                 episode reward: 0.5193,                 loss: 0.2792
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7072s / 262.6715 s
agent0:                 episode reward: -0.2163,                 loss: nan
agent1:                 episode reward: 0.2163,                 loss: 0.2773
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7495s / 263.4210 s
agent0:                 episode reward: 0.7790,                 loss: nan
agent1:                 episode reward: -0.7790,                 loss: 0.2805
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7050s / 264.1260 s
agent0:                 episode reward: -0.2238,                 loss: nan
agent1:                 episode reward: 0.2238,                 loss: 0.2775
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7128s / 264.8388 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.2779
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7068s / 265.5456 s
agent0:                 episode reward: -0.8274,                 loss: nan
agent1:                 episode reward: 0.8274,                 loss: 0.2788
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7050s / 266.2507 s
agent0:                 episode reward: -0.8708,                 loss: nan
agent1:                 episode reward: 0.8708,                 loss: 0.2780
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7105s / 266.9611 s
agent0:                 episode reward: 0.1690,                 loss: nan
agent1:                 episode reward: -0.1690,                 loss: 0.2781
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7072s / 267.6683 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: 0.2752
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7452s / 268.4136 s
agent0:                 episode reward: -0.4159,                 loss: nan
agent1:                 episode reward: 0.4159,                 loss: 0.2794
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7185s / 269.1321 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.2761
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7034s / 269.8355 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.2726
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7201s / 270.5556 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.2729
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7136s / 271.2692 s
agent0:                 episode reward: 0.8787,                 loss: nan
agent1:                 episode reward: -0.8787,                 loss: 0.2701
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7086s / 271.9778 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.2711
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7141s / 272.6919 s
agent0:                 episode reward: -0.4951,                 loss: nan
agent1:                 episode reward: 0.4951,                 loss: 0.2723
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7766s / 273.4685 s
agent0:                 episode reward: -0.5799,                 loss: nan
agent1:                 episode reward: 0.5799,                 loss: 0.2737
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7111s / 274.1796 s
agent0:                 episode reward: 0.0436,                 loss: nan
agent1:                 episode reward: -0.0436,                 loss: 0.2712
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7206s / 274.9002 s
agent0:                 episode reward: 0.0919,                 loss: nan
agent1:                 episode reward: -0.0919,                 loss: 0.2725
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7229s / 275.6231 s
agent0:                 episode reward: 0.5823,                 loss: nan
agent1:                 episode reward: -0.5823,                 loss: 0.2712
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7148s / 276.3380 s
agent0:                 episode reward: -0.5082,                 loss: nan
agent1:                 episode reward: 0.5082,                 loss: 0.2679
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7307s / 277.0687 s
agent0:                 episode reward: -0.3332,                 loss: nan
agent1:                 episode reward: 0.3332,                 loss: 0.2597
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7097s / 277.7784 s
agent0:                 episode reward: -0.2045,                 loss: nan
agent1:                 episode reward: 0.2045,                 loss: 0.2602
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7167s / 278.4952 s
agent0:                 episode reward: 0.9282,                 loss: nan
agent1:                 episode reward: -0.9282,                 loss: 0.2594
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7879s / 279.2831 s
agent0:                 episode reward: -1.0854,                 loss: nan
agent1:                 episode reward: 1.0854,                 loss: 0.2612
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7074s / 279.9905 s
agent0:                 episode reward: 0.7710,                 loss: nan
agent1:                 episode reward: -0.7710,                 loss: 0.2607
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7130s / 280.7035 s
agent0:                 episode reward: 0.5750,                 loss: nan
agent1:                 episode reward: -0.5750,                 loss: 0.2618
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7169s / 281.4204 s
agent0:                 episode reward: -0.7575,                 loss: nan
agent1:                 episode reward: 0.7575,                 loss: 0.2562
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7200s / 282.1405 s
agent0:                 episode reward: -1.0492,                 loss: nan
agent1:                 episode reward: 1.0492,                 loss: 0.2597
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7206s / 282.8610 s
agent0:                 episode reward: 1.2060,                 loss: nan
agent1:                 episode reward: -1.2060,                 loss: 0.2582
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7666s / 283.6276 s
agent0:                 episode reward: -0.3708,                 loss: nan
agent1:                 episode reward: 0.3708,                 loss: 0.2773
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7266s / 284.3542 s
agent0:                 episode reward: -0.0109,                 loss: nan
agent1:                 episode reward: 0.0109,                 loss: 0.2822
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7434s / 285.0976 s
agent0:                 episode reward: -0.1265,                 loss: nan
agent1:                 episode reward: 0.1265,                 loss: 0.2819
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7307s / 285.8283 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.2792
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7210s / 286.5493 s
agent0:                 episode reward: 0.3610,                 loss: nan
agent1:                 episode reward: -0.3610,                 loss: 0.2797
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7106s / 287.2599 s
agent0:                 episode reward: -0.0050,                 loss: nan
agent1:                 episode reward: 0.0050,                 loss: 0.2786
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7264s / 287.9863 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.2768
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7270s / 288.7133 s
agent0:                 episode reward: 0.1187,                 loss: nan
agent1:                 episode reward: -0.1187,                 loss: 0.2796
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7122s / 289.4254 s
agent0:                 episode reward: -1.3880,                 loss: nan
agent1:                 episode reward: 1.3880,                 loss: 0.2794
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 290.1741 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.2757
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7290s / 290.9030 s
agent0:                 episode reward: -0.1744,                 loss: nan
agent1:                 episode reward: 0.1744,                 loss: 0.3174
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7221s / 291.6252 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.3337
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7249s / 292.3500 s
agent0:                 episode reward: 0.4393,                 loss: nan
agent1:                 episode reward: -0.4393,                 loss: 0.3305
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7440s / 293.0940 s
agent0:                 episode reward: -0.5344,                 loss: nan
agent1:                 episode reward: 0.5344,                 loss: 0.3300
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7685s / 293.8626 s
agent0:                 episode reward: 0.9045,                 loss: nan
agent1:                 episode reward: -0.9045,                 loss: 0.3288
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7386s / 294.6011 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.3289
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7388s / 295.3399 s
agent0:                 episode reward: -0.0866,                 loss: nan
agent1:                 episode reward: 0.0866,                 loss: 0.3290
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7321s / 296.0720 s
agent0:                 episode reward: 0.7863,                 loss: nan
agent1:                 episode reward: -0.7863,                 loss: 0.3281
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7390s / 296.8110 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: 0.3289
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7559s / 297.5669 s
agent0:                 episode reward: 0.0114,                 loss: nan
agent1:                 episode reward: -0.0114,                 loss: 0.3273
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7357s / 298.3026 s
agent0:                 episode reward: -0.0139,                 loss: nan
agent1:                 episode reward: 0.0139,                 loss: 0.3686
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7356s / 299.0382 s
agent0:                 episode reward: 1.5403,                 loss: nan
agent1:                 episode reward: -1.5403,                 loss: 0.3799
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7296s / 299.7678 s
agent0:                 episode reward: 0.9492,                 loss: nan
agent1:                 episode reward: -0.9492,                 loss: 0.3781
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7614s / 300.5292 s
agent0:                 episode reward: 1.2632,                 loss: nan
agent1:                 episode reward: -1.2632,                 loss: 0.3783
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7302s / 301.2594 s
agent0:                 episode reward: 0.2896,                 loss: nan
agent1:                 episode reward: -0.2896,                 loss: 0.3801
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7443s / 302.0037 s
agent0:                 episode reward: 0.2009,                 loss: nan
agent1:                 episode reward: -0.2009,                 loss: 0.3794
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7483s / 302.7520 s
agent0:                 episode reward: -0.8904,                 loss: nan
agent1:                 episode reward: 0.8904,                 loss: 0.3779
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7413s / 303.4933 s
agent0:                 episode reward: 1.5117,                 loss: nan
agent1:                 episode reward: -1.5117,                 loss: 0.3792
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7951s / 304.2883 s
agent0:                 episode reward: 0.4798,                 loss: nan
agent1:                 episode reward: -0.4798,                 loss: 0.3776
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7367s / 305.0250 s
agent0:                 episode reward: -0.7034,                 loss: nan
agent1:                 episode reward: 0.7034,                 loss: 0.3779
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7498s / 305.7748 s
agent0:                 episode reward: 0.6864,                 loss: nan
agent1:                 episode reward: -0.6864,                 loss: 0.3567
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7430s / 306.5178 s
agent0:                 episode reward: 0.0518,                 loss: nan
agent1:                 episode reward: -0.0518,                 loss: 0.3349
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7383s / 307.2561 s
agent0:                 episode reward: -0.2053,                 loss: nan
agent1:                 episode reward: 0.2053,                 loss: 0.3341
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7394s / 307.9955 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: 0.3333
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7346s / 308.7301 s
agent0:                 episode reward: -0.7692,                 loss: nan
agent1:                 episode reward: 0.7692,                 loss: 0.3342
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7487s / 309.4788 s
agent0:                 episode reward: 1.2667,                 loss: nan
agent1:                 episode reward: -1.2667,                 loss: 0.3324
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7506s / 310.2294 s
agent0:                 episode reward: 0.9388,                 loss: nan
agent1:                 episode reward: -0.9388,                 loss: 0.3307
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7415s / 310.9709 s
agent0:                 episode reward: -0.1055,                 loss: nan
agent1:                 episode reward: 0.1055,                 loss: 0.3339
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7382s / 311.7091 s
agent0:                 episode reward: 0.2900,                 loss: nan
agent1:                 episode reward: -0.2900,                 loss: 0.3365
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7372s / 312.4463 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.3327
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7447s / 313.1911 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.2889
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7448s / 313.9359 s
agent0:                 episode reward: 1.7521,                 loss: nan
agent1:                 episode reward: -1.7521,                 loss: 0.2627
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7874s / 314.7233 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.2599
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7627s / 315.4860 s
agent0:                 episode reward: 0.6154,                 loss: nan
agent1:                 episode reward: -0.6154,                 loss: 0.2600
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7791s / 316.2651 s
agent0:                 episode reward: 0.3376,                 loss: nan
agent1:                 episode reward: -0.3376,                 loss: 0.2605
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7796s / 317.0447 s
agent0:                 episode reward: -0.7712,                 loss: nan
agent1:                 episode reward: 0.7712,                 loss: 0.2621
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7472s / 317.7919 s
agent0:                 episode reward: -1.0159,                 loss: nan
agent1:                 episode reward: 1.0159,                 loss: 0.2622
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7561s / 318.5480 s
agent0:                 episode reward: 0.3534,                 loss: nan
agent1:                 episode reward: -0.3534,                 loss: 0.2586
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7543s / 319.3023 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.2622
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7434s / 320.0457 s
agent0:                 episode reward: 1.0604,                 loss: nan
agent1:                 episode reward: -1.0604,                 loss: 0.2599
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7405s / 320.7862 s
agent0:                 episode reward: 0.3365,                 loss: nan
agent1:                 episode reward: -0.3365,                 loss: 0.2508
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 321.5390 s
agent0:                 episode reward: -0.6889,                 loss: nan
agent1:                 episode reward: 0.6889,                 loss: 0.2456
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7492s / 322.2882 s
agent0:                 episode reward: 0.6321,                 loss: nan
agent1:                 episode reward: -0.6321,                 loss: 0.2392
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7436s / 323.0318 s
agent0:                 episode reward: 0.4578,                 loss: nan
agent1:                 episode reward: -0.4578,                 loss: 0.2409
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7544s / 323.7862 s
agent0:                 episode reward: -0.4970,                 loss: nan
agent1:                 episode reward: 0.4970,                 loss: 0.2399
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7997s / 324.5858 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: 0.2391
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7474s / 325.3332 s
agent0:                 episode reward: 0.6781,                 loss: nan
agent1:                 episode reward: -0.6781,                 loss: 0.2379
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7564s / 326.0896 s
agent0:                 episode reward: 0.1545,                 loss: nan
agent1:                 episode reward: -0.1545,                 loss: 0.2381
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7673s / 326.8570 s
agent0:                 episode reward: 0.7119,                 loss: nan
agent1:                 episode reward: -0.7119,                 loss: 0.2374
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7650s / 327.6219 s
agent0:                 episode reward: 0.1512,                 loss: nan
agent1:                 episode reward: -0.1512,                 loss: 0.2383
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7547s / 328.3766 s
agent0:                 episode reward: 1.0355,                 loss: nan
agent1:                 episode reward: -1.0355,                 loss: 0.2523
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7490s / 329.1257 s
agent0:                 episode reward: 0.3466,                 loss: nan
agent1:                 episode reward: -0.3466,                 loss: 0.2521
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7620s / 329.8876 s
agent0:                 episode reward: 0.7290,                 loss: nan
agent1:                 episode reward: -0.7290,                 loss: 0.2525
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7652s / 330.6528 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.2526
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7489s / 331.4017 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.2511
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7568s / 332.1586 s
agent0:                 episode reward: 0.0853,                 loss: nan
agent1:                 episode reward: -0.0853,                 loss: 0.2503
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7587s / 332.9173 s
agent0:                 episode reward: 0.1110,                 loss: nan
agent1:                 episode reward: -0.1110,                 loss: 0.2519
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7624s / 333.6797 s
agent0:                 episode reward: -0.2285,                 loss: nan
agent1:                 episode reward: 0.2285,                 loss: 0.2511
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8122s / 334.4919 s
agent0:                 episode reward: -0.3040,                 loss: nan
agent1:                 episode reward: 0.3040,                 loss: 0.2507
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8137s / 335.3056 s
agent0:                 episode reward: -0.1328,                 loss: nan
agent1:                 episode reward: 0.1328,                 loss: 0.2529
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7935s / 336.0991 s
agent0:                 episode reward: 0.4862,                 loss: nan
agent1:                 episode reward: -0.4862,                 loss: 0.2658
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7820s / 336.8811 s
agent0:                 episode reward: 0.0864,                 loss: nan
agent1:                 episode reward: -0.0864,                 loss: 0.2662
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 337.6457 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.2639
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7668s / 338.4124 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.2661
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7702s / 339.1827 s
agent0:                 episode reward: -0.4160,                 loss: nan
agent1:                 episode reward: 0.4160,                 loss: 0.2659
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7721s / 339.9547 s
agent0:                 episode reward: 0.1710,                 loss: nan
agent1:                 episode reward: -0.1710,                 loss: 0.2641
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7676s / 340.7223 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.2668
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7669s / 341.4892 s
agent0:                 episode reward: 0.4230,                 loss: nan
agent1:                 episode reward: -0.4230,                 loss: 0.2656
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7668s / 342.2561 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.2652
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7872s / 343.0433 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: 0.2625
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8425s / 343.8858 s
agent0:                 episode reward: -0.0673,                 loss: nan
agent1:                 episode reward: 0.0673,                 loss: 0.2658
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 344.6609 s
agent0:                 episode reward: -0.3338,                 loss: nan
agent1:                 episode reward: 0.3338,                 loss: 0.2554
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8119s / 345.4728 s
agent0:                 episode reward: 0.3376,                 loss: nan
agent1:                 episode reward: -0.3376,                 loss: 0.2533
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7875s / 346.2603 s
agent0:                 episode reward: 0.1713,                 loss: nan
agent1:                 episode reward: -0.1713,                 loss: 0.2538
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7718s / 347.0321 s
agent0:                 episode reward: -0.6048,                 loss: nan
agent1:                 episode reward: 0.6048,                 loss: 0.2549
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7783s / 347.8104 s
agent0:                 episode reward: 0.4846,                 loss: nan
agent1:                 episode reward: -0.4846,                 loss: 0.2540
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7843s / 348.5947 s
agent0:                 episode reward: 0.7336,                 loss: nan
agent1:                 episode reward: -0.7336,                 loss: 0.2530
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7833s / 349.3780 s
agent0:                 episode reward: 0.2524,                 loss: nan
agent1:                 episode reward: -0.2524,                 loss: 0.2534
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7703s / 350.1482 s
agent0:                 episode reward: 0.5056,                 loss: nan
agent1:                 episode reward: -0.5056,                 loss: 0.2519
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7771s / 350.9253 s
agent0:                 episode reward: -0.4701,                 loss: nan
agent1:                 episode reward: 0.4701,                 loss: 0.2534
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7932s / 351.7185 s
agent0:                 episode reward: -0.7622,                 loss: nan
agent1:                 episode reward: 0.7622,                 loss: 0.2591
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7884s / 352.5069 s
agent0:                 episode reward: 0.1417,                 loss: nan
agent1:                 episode reward: -0.1417,                 loss: 0.2562
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7837s / 353.2906 s
agent0:                 episode reward: 0.3319,                 loss: nan
agent1:                 episode reward: -0.3319,                 loss: 0.2536
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7745s / 354.0651 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: 0.2530
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7767s / 354.8417 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.2520
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8374s / 355.6791 s
agent0:                 episode reward: 0.1682,                 loss: nan
agent1:                 episode reward: -0.1682,                 loss: 0.2506
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7877s / 356.4668 s
agent0:                 episode reward: 1.1625,                 loss: nan
agent1:                 episode reward: -1.1625,                 loss: 0.2503
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7852s / 357.2520 s
agent0:                 episode reward: 0.2931,                 loss: nan
agent1:                 episode reward: -0.2931,                 loss: 0.2500
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7952s / 358.0471 s
agent0:                 episode reward: 0.1549,                 loss: nan
agent1:                 episode reward: -0.1549,                 loss: 0.2489
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7725s / 358.8197 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.2520
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7937s / 359.6134 s
agent0:                 episode reward: 0.0523,                 loss: nan
agent1:                 episode reward: -0.0523,                 loss: 0.2889
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7741s / 360.3875 s
agent0:                 episode reward: 0.0450,                 loss: nan
agent1:                 episode reward: -0.0450,                 loss: 0.3021
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7835s / 361.1710 s
agent0:                 episode reward: 0.4911,                 loss: nan
agent1:                 episode reward: -0.4911,                 loss: 0.2989
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7819s / 361.9529 s
agent0:                 episode reward: 1.0173,                 loss: nan
agent1:                 episode reward: -1.0173,                 loss: 0.2971
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8184s / 362.7713 s
agent0:                 episode reward: -0.3484,                 loss: nan
agent1:                 episode reward: 0.3484,                 loss: 0.2976
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8095s / 363.5808 s
agent0:                 episode reward: 0.2618,                 loss: nan
agent1:                 episode reward: -0.2618,                 loss: 0.2978
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7848s / 364.3656 s
agent0:                 episode reward: -0.0857,                 loss: nan
agent1:                 episode reward: 0.0857,                 loss: 0.2978
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7817s / 365.1473 s
agent0:                 episode reward: 0.5274,                 loss: nan
agent1:                 episode reward: -0.5274,                 loss: 0.2973
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8469s / 365.9942 s
agent0:                 episode reward: 0.8042,                 loss: nan
agent1:                 episode reward: -0.8042,                 loss: 0.2957
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7832s / 366.7774 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.2951
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 367.5623 s
agent0:                 episode reward: -0.0316,                 loss: nan
agent1:                 episode reward: 0.0316,                 loss: 0.3432
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7957s / 368.3580 s
agent0:                 episode reward: -0.0463,                 loss: nan
agent1:                 episode reward: 0.0463,                 loss: 0.3530
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7798s / 369.1377 s
agent0:                 episode reward: 1.1509,                 loss: nan
agent1:                 episode reward: -1.1509,                 loss: 0.3519
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7890s / 369.9267 s
agent0:                 episode reward: -0.3722,                 loss: nan
agent1:                 episode reward: 0.3722,                 loss: 0.3516
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8056s / 370.7323 s
agent0:                 episode reward: 0.4832,                 loss: nan
agent1:                 episode reward: -0.4832,                 loss: 0.3496
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7833s / 371.5156 s
agent0:                 episode reward: 0.8056,                 loss: nan
agent1:                 episode reward: -0.8056,                 loss: 0.3511
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7813s / 372.2969 s
agent0:                 episode reward: 0.3149,                 loss: nan
agent1:                 episode reward: -0.3149,                 loss: 0.3508
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7833s / 373.0802 s
agent0:                 episode reward: -0.1138,                 loss: nan
agent1:                 episode reward: 0.1138,                 loss: 0.3501
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7865s / 373.8667 s
agent0:                 episode reward: -0.3370,                 loss: nan
agent1:                 episode reward: 0.3370,                 loss: 0.3521
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7846s / 374.6513 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.3517
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7845s / 375.4358 s
agent0:                 episode reward: 0.2690,                 loss: nan
agent1:                 episode reward: -0.2690,                 loss: 0.3281
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8610s / 376.2968 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: 0.3014
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7926s / 377.0894 s
agent0:                 episode reward: 0.8408,                 loss: nan
agent1:                 episode reward: -0.8408,                 loss: 0.3034
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7877s / 377.8771 s
agent0:                 episode reward: -0.1117,                 loss: nan
agent1:                 episode reward: 0.1117,                 loss: 0.2985
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7952s / 378.6723 s
agent0:                 episode reward: -0.5631,                 loss: nan
agent1:                 episode reward: 0.5631,                 loss: 0.3002
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8035s / 379.4758 s
agent0:                 episode reward: 0.5402,                 loss: nan
agent1:                 episode reward: -0.5402,                 loss: 0.3010
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7950s / 380.2708 s
agent0:                 episode reward: 0.5286,                 loss: nan
agent1:                 episode reward: -0.5286,                 loss: 0.3004
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7928s / 381.0636 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: 0.3001
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7934s / 381.8570 s
agent0:                 episode reward: -0.5622,                 loss: nan
agent1:                 episode reward: 0.5622,                 loss: 0.2991
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8284s / 382.6854 s
agent0:                 episode reward: 0.3645,                 loss: nan
agent1:                 episode reward: -0.3645,                 loss: 0.3021
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7939s / 383.4793 s
agent0:                 episode reward: -0.5615,                 loss: nan
agent1:                 episode reward: 0.5615,                 loss: 0.2492
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7906s / 384.2699 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.2175
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8181s / 385.0881 s
agent0:                 episode reward: -0.6300,                 loss: nan
agent1:                 episode reward: 0.6300,                 loss: 0.2131
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8341s / 385.9222 s
agent0:                 episode reward: -0.7337,                 loss: nan
agent1:                 episode reward: 0.7337,                 loss: 0.2108
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8104s / 386.7325 s
agent0:                 episode reward: 0.9122,                 loss: nan
agent1:                 episode reward: -0.9122,                 loss: 0.2120
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7982s / 387.5308 s
agent0:                 episode reward: -0.4246,                 loss: nan
agent1:                 episode reward: 0.4246,                 loss: 0.2131
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8148s / 388.3456 s
agent0:                 episode reward: 0.8467,                 loss: nan
agent1:                 episode reward: -0.8467,                 loss: 0.2103
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7986s / 389.1442 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.2099
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8026s / 389.9468 s
agent0:                 episode reward: -0.2502,                 loss: nan
agent1:                 episode reward: 0.2502,                 loss: 0.2122
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8563s / 390.8031 s
agent0:                 episode reward: -0.1074,                 loss: nan
agent1:                 episode reward: 0.1074,                 loss: 0.2129
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8031s / 391.6062 s
agent0:                 episode reward: 0.4572,                 loss: nan
agent1:                 episode reward: -0.4572,                 loss: 0.2247
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7910s / 392.3972 s
agent0:                 episode reward: 0.3041,                 loss: nan
agent1:                 episode reward: -0.3041,                 loss: 0.2243
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8224s / 393.2196 s
agent0:                 episode reward: -0.3575,                 loss: nan
agent1:                 episode reward: 0.3575,                 loss: 0.2231
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7995s / 394.0191 s
agent0:                 episode reward: 0.3456,                 loss: nan
agent1:                 episode reward: -0.3456,                 loss: 0.2224
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8006s / 394.8197 s
agent0:                 episode reward: -0.6521,                 loss: nan
agent1:                 episode reward: 0.6521,                 loss: 0.2198
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8025s / 395.6222 s
agent0:                 episode reward: 0.0729,                 loss: nan
agent1:                 episode reward: -0.0729,                 loss: 0.2209
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8786s / 396.5008 s
agent0:                 episode reward: 0.1459,                 loss: nan
agent1:                 episode reward: -0.1459,                 loss: 0.2204
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8125s / 397.3133 s
agent0:                 episode reward: 0.6272,                 loss: nan
agent1:                 episode reward: -0.6272,                 loss: 0.2192
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8073s / 398.1206 s
agent0:                 episode reward: 0.0570,                 loss: nan
agent1:                 episode reward: -0.0570,                 loss: 0.2227
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8053s / 398.9259 s
agent0:                 episode reward: -0.4124,                 loss: nan
agent1:                 episode reward: 0.4124,                 loss: 0.2204
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8085s / 399.7344 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.2492
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8143s / 400.5486 s
agent0:                 episode reward: -0.7252,                 loss: nan
agent1:                 episode reward: 0.7252,                 loss: 0.2566
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8527s / 401.4013 s
agent0:                 episode reward: 0.1516,                 loss: nan
agent1:                 episode reward: -0.1516,                 loss: 0.2553
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8103s / 402.2116 s
agent0:                 episode reward: -1.1705,                 loss: nan
agent1:                 episode reward: 1.1705,                 loss: 0.2512
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8003s / 403.0119 s
agent0:                 episode reward: -0.1662,                 loss: nan
agent1:                 episode reward: 0.1662,                 loss: 0.2541
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8180s / 403.8299 s
agent0:                 episode reward: 0.4895,                 loss: nan
agent1:                 episode reward: -0.4895,                 loss: 0.2519
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8056s / 404.6355 s
agent0:                 episode reward: -0.4462,                 loss: nan
agent1:                 episode reward: 0.4462,                 loss: 0.2536
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8512s / 405.4867 s
agent0:                 episode reward: -0.2237,                 loss: nan
agent1:                 episode reward: 0.2237,                 loss: 0.2529
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8347s / 406.3214 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: 0.2554
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 407.1862 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: 0.2514
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8748s / 408.0610 s
agent0:                 episode reward: -0.4672,                 loss: nan
agent1:                 episode reward: 0.4672,                 loss: 0.2688
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8169s / 408.8779 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: 0.2667
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8389s / 409.7167 s
agent0:                 episode reward: -0.1485,                 loss: nan
agent1:                 episode reward: 0.1485,                 loss: 0.2668
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8206s / 410.5373 s
agent0:                 episode reward: 0.2014,                 loss: nan
agent1:                 episode reward: -0.2014,                 loss: 0.2678
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8140s / 411.3513 s
agent0:                 episode reward: -0.5481,                 loss: nan
agent1:                 episode reward: 0.5481,                 loss: 0.2670
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8137s / 412.1650 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.2661
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8243s / 412.9893 s
agent0:                 episode reward: -0.0096,                 loss: nan
agent1:                 episode reward: 0.0096,                 loss: 0.2676
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8152s / 413.8044 s
agent0:                 episode reward: -0.0205,                 loss: nan
agent1:                 episode reward: 0.0205,                 loss: 0.2644
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8173s / 414.6217 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.2666
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8154s / 415.4371 s
agent0:                 episode reward: 0.1392,                 loss: nan
agent1:                 episode reward: -0.1392,                 loss: 0.2655
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8391s / 416.2761 s
agent0:                 episode reward: 0.0299,                 loss: nan
agent1:                 episode reward: -0.0299,                 loss: 0.2606
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8894s / 417.1655 s
agent0:                 episode reward: -0.1907,                 loss: nan
agent1:                 episode reward: 0.1907,                 loss: 0.2486
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8324s / 417.9980 s
agent0:                 episode reward: -0.4985,                 loss: nan
agent1:                 episode reward: 0.4985,                 loss: 0.2498
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8321s / 418.8300 s
agent0:                 episode reward: -1.1308,                 loss: nan
agent1:                 episode reward: 1.1308,                 loss: 0.2487
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8199s / 419.6499 s
agent0:                 episode reward: -0.3087,                 loss: nan
agent1:                 episode reward: 0.3087,                 loss: 0.2513
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8277s / 420.4776 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.2501
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8246s / 421.3022 s
agent0:                 episode reward: -0.0536,                 loss: nan
agent1:                 episode reward: 0.0536,                 loss: 0.2471
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8345s / 422.1367 s
agent0:                 episode reward: -0.3544,                 loss: nan
agent1:                 episode reward: 0.3544,                 loss: 0.2488
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8258s / 422.9625 s
agent0:                 episode reward: -0.8785,                 loss: nan
agent1:                 episode reward: 0.8785,                 loss: 0.2490
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8275s / 423.7900 s
agent0:                 episode reward: 0.1410,                 loss: nan
agent1:                 episode reward: -0.1410,                 loss: 0.2497
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8387s / 424.6286 s
agent0:                 episode reward: 0.2079,                 loss: nan
agent1:                 episode reward: -0.2079,                 loss: 0.2527
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8569s / 425.4855 s
agent0:                 episode reward: 0.0480,                 loss: nan
agent1:                 episode reward: -0.0480,                 loss: 0.2487
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8385s / 426.3239 s
agent0:                 episode reward: 0.1783,                 loss: nan
agent1:                 episode reward: -0.1783,                 loss: 0.2477
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8753s / 427.1992 s
agent0:                 episode reward: -0.3403,                 loss: nan
agent1:                 episode reward: 0.3403,                 loss: 0.2498
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8322s / 428.0315 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: 0.2475
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8287s / 428.8602 s
agent0:                 episode reward: -0.0560,                 loss: nan
agent1:                 episode reward: 0.0560,                 loss: 0.2493
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8310s / 429.6911 s
agent0:                 episode reward: -0.0585,                 loss: nan
agent1:                 episode reward: 0.0585,                 loss: 0.2482
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8334s / 430.5245 s
agent0:                 episode reward: -0.0620,                 loss: nan
agent1:                 episode reward: 0.0620,                 loss: 0.2495
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8400s / 431.3646 s
agent0:                 episode reward: 0.3264,                 loss: nan
agent1:                 episode reward: -0.3264,                 loss: 0.2483
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8322s / 432.1968 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.2485
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8295s / 433.0263 s
agent0:                 episode reward: -0.4054,                 loss: nan
agent1:                 episode reward: 0.4054,                 loss: 0.2675
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8448s / 433.8711 s
agent0:                 episode reward: 0.4796,                 loss: nan
agent1:                 episode reward: -0.4796,                 loss: 0.2732
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8564s / 434.7275 s
agent0:                 episode reward: 0.1069,                 loss: nan
agent1:                 episode reward: -0.1069,                 loss: 0.2694
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8347s / 435.5622 s
agent0:                 episode reward: 0.8399,                 loss: nan
agent1:                 episode reward: -0.8399,                 loss: 0.2698
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8329s / 436.3951 s
agent0:                 episode reward: -0.1048,                 loss: nan
agent1:                 episode reward: 0.1048,                 loss: 0.2707
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8996s / 437.2947 s
agent0:                 episode reward: 1.0224,                 loss: nan
agent1:                 episode reward: -1.0224,                 loss: 0.2707
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8353s / 438.1300 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.2698
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8272s / 438.9571 s
agent0:                 episode reward: 0.1568,                 loss: nan
agent1:                 episode reward: -0.1568,                 loss: 0.2687
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8445s / 439.8017 s
agent0:                 episode reward: -0.5367,                 loss: nan
agent1:                 episode reward: 0.5367,                 loss: 0.2669
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8363s / 440.6379 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.2709
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8345s / 441.4724 s
agent0:                 episode reward: -1.0800,                 loss: nan
agent1:                 episode reward: 1.0800,                 loss: 0.3141
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8369s / 442.3093 s
agent0:                 episode reward: 0.3619,                 loss: nan
agent1:                 episode reward: -0.3619,                 loss: 0.3206
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8581s / 443.1674 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.3244
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8447s / 444.0121 s
agent0:                 episode reward: -0.0880,                 loss: nan
agent1:                 episode reward: 0.0880,                 loss: 0.3237
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8374s / 444.8495 s
agent0:                 episode reward: 0.3753,                 loss: nan
agent1:                 episode reward: -0.3753,                 loss: 0.3207
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8490s / 445.6985 s
agent0:                 episode reward: 0.5136,                 loss: nan
agent1:                 episode reward: -0.5136,                 loss: 0.3231
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8846s / 446.5831 s
agent0:                 episode reward: 0.3911,                 loss: nan
agent1:                 episode reward: -0.3911,                 loss: 0.3199
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8888s / 447.4719 s
agent0:                 episode reward: 0.6648,                 loss: nan
agent1:                 episode reward: -0.6648,                 loss: 0.3211
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8413s / 448.3132 s
agent0:                 episode reward: 0.0519,                 loss: nan
agent1:                 episode reward: -0.0519,                 loss: 0.3207
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8599s / 449.1730 s
agent0:                 episode reward: 0.3219,                 loss: nan
agent1:                 episode reward: -0.3219,                 loss: 0.3205
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8473s / 450.0203 s
agent0:                 episode reward: 0.9247,                 loss: nan
agent1:                 episode reward: -0.9247,                 loss: 0.3389
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8561s / 450.8764 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: 0.3320
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8565s / 451.7329 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: 0.3338
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8578s / 452.5908 s
agent0:                 episode reward: -0.0376,                 loss: nan
agent1:                 episode reward: 0.0376,                 loss: 0.3301
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8536s / 453.4444 s
agent0:                 episode reward: -1.1531,                 loss: nan
agent1:                 episode reward: 1.1531,                 loss: 0.3307
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8542s / 454.2985 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.3312
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8497s / 455.1482 s
agent0:                 episode reward: 0.3381,                 loss: nan
agent1:                 episode reward: -0.3381,                 loss: 0.3291
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8556s / 456.0039 s
agent0:                 episode reward: -0.5456,                 loss: nan
agent1:                 episode reward: 0.5456,                 loss: 0.3301
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8507s / 456.8546 s
agent0:                 episode reward: -0.1948,                 loss: nan
agent1:                 episode reward: 0.1948,                 loss: 0.3327
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8999s / 457.7544 s
agent0:                 episode reward: -0.0481,                 loss: nan
agent1:                 episode reward: 0.0481,                 loss: 0.3327
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8542s / 458.6087 s
agent0:                 episode reward: -0.0789,                 loss: nan
agent1:                 episode reward: 0.0789,                 loss: 0.2869
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8653s / 459.4740 s
agent0:                 episode reward: -0.5478,                 loss: nan
agent1:                 episode reward: 0.5478,                 loss: 0.2479
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8714s / 460.3454 s
agent0:                 episode reward: 0.0663,                 loss: nan
agent1:                 episode reward: -0.0663,                 loss: 0.2459
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8638s / 461.2093 s
agent0:                 episode reward: -0.2900,                 loss: nan
agent1:                 episode reward: 0.2900,                 loss: 0.2467
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8619s / 462.0712 s
agent0:                 episode reward: 0.3049,                 loss: nan
agent1:                 episode reward: -0.3049,                 loss: 0.2458
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8876s / 462.9588 s
agent0:                 episode reward: -0.7794,                 loss: nan
agent1:                 episode reward: 0.7794,                 loss: 0.2441
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8606s / 463.8194 s
agent0:                 episode reward: -0.5463,                 loss: nan
agent1:                 episode reward: 0.5463,                 loss: 0.2449
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8642s / 464.6837 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.2440
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8500s / 465.5336 s
agent0:                 episode reward: 1.0518,                 loss: nan
agent1:                 episode reward: -1.0518,                 loss: 0.2413
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8568s / 466.3905 s
agent0:                 episode reward: 0.4586,                 loss: nan
agent1:                 episode reward: -0.4586,                 loss: 0.2451
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8850s / 467.2755 s
agent0:                 episode reward: -0.0170,                 loss: nan
agent1:                 episode reward: 0.0170,                 loss: 0.2264
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9156s / 468.1912 s
agent0:                 episode reward: -0.2343,                 loss: nan
agent1:                 episode reward: 0.2343,                 loss: 0.2123
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8659s / 469.0570 s
agent0:                 episode reward: 0.7910,                 loss: nan
agent1:                 episode reward: -0.7910,                 loss: 0.2125
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8719s / 469.9289 s
agent0:                 episode reward: 0.2692,                 loss: nan
agent1:                 episode reward: -0.2692,                 loss: 0.2129
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8702s / 470.7991 s
agent0:                 episode reward: 0.5724,                 loss: nan
agent1:                 episode reward: -0.5724,                 loss: 0.2119
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8667s / 471.6658 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.2095
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8755s / 472.5413 s
agent0:                 episode reward: -0.3598,                 loss: nan
agent1:                 episode reward: 0.3598,                 loss: 0.2121
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8785s / 473.4198 s
agent0:                 episode reward: -0.7064,                 loss: nan
agent1:                 episode reward: 0.7064,                 loss: 0.2102
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8714s / 474.2912 s
agent0:                 episode reward: 0.2922,                 loss: nan
agent1:                 episode reward: -0.2922,                 loss: 0.2101
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8692s / 475.1604 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.2107
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8940s / 476.0544 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: 0.2339
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8685s / 476.9229 s
agent0:                 episode reward: 0.2073,                 loss: nan
agent1:                 episode reward: -0.2073,                 loss: 0.2384
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8809s / 477.8038 s
agent0:                 episode reward: 1.2546,                 loss: nan
agent1:                 episode reward: -1.2546,                 loss: 0.2380
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9098s / 478.7136 s
agent0:                 episode reward: 0.3700,                 loss: nan
agent1:                 episode reward: -0.3700,                 loss: 0.2372
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8817s / 479.5952 s
agent0:                 episode reward: 0.2040,                 loss: nan
agent1:                 episode reward: -0.2040,                 loss: 0.2363
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8757s / 480.4709 s
agent0:                 episode reward: 0.5515,                 loss: nan
agent1:                 episode reward: -0.5515,                 loss: 0.2353
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8731s / 481.3441 s
agent0:                 episode reward: -0.5778,                 loss: nan
agent1:                 episode reward: 0.5778,                 loss: 0.2365
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8888s / 482.2328 s
agent0:                 episode reward: -0.2027,                 loss: nan
agent1:                 episode reward: 0.2027,                 loss: 0.2345
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8717s / 483.1046 s
agent0:                 episode reward: 0.2993,                 loss: nan
agent1:                 episode reward: -0.2993,                 loss: 0.2336
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8926s / 483.9971 s
agent0:                 episode reward: -0.6275,                 loss: nan
agent1:                 episode reward: 0.6275,                 loss: 0.2338
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8768s / 484.8740 s
agent0:                 episode reward: -0.6646,                 loss: nan
agent1:                 episode reward: 0.6646,                 loss: 0.2643
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8909s / 485.7649 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.2688
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8784s / 486.6432 s
agent0:                 episode reward: -0.1678,                 loss: nan
agent1:                 episode reward: 0.1678,                 loss: 0.2677
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8713s / 487.5146 s
agent0:                 episode reward: -0.7494,                 loss: nan
agent1:                 episode reward: 0.7494,                 loss: 0.2692
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9698s / 488.4844 s
agent0:                 episode reward: 0.2103,                 loss: nan
agent1:                 episode reward: -0.2103,                 loss: 0.2687
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8840s / 489.3685 s
agent0:                 episode reward: -1.2606,                 loss: nan
agent1:                 episode reward: 1.2606,                 loss: 0.2677
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8808s / 490.2492 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.2681
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9100s / 491.1592 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.2707
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9001s / 492.0593 s
agent0:                 episode reward: -0.7967,                 loss: nan
agent1:                 episode reward: 0.7967,                 loss: 0.2679
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9117s / 492.9710 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.2690
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8948s / 493.8658 s
agent0:                 episode reward: 0.4076,                 loss: nan
agent1:                 episode reward: -0.4076,                 loss: 0.2775
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9053s / 494.7711 s
agent0:                 episode reward: 0.3470,                 loss: nan
agent1:                 episode reward: -0.3470,                 loss: 0.2709
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8808s / 495.6519 s
agent0:                 episode reward: -0.1600,                 loss: nan
agent1:                 episode reward: 0.1600,                 loss: 0.2729
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8937s / 496.5456 s
agent0:                 episode reward: -0.3402,                 loss: nan
agent1:                 episode reward: 0.3402,                 loss: 0.2683
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8963s / 497.4420 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.2678
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9053s / 498.3472 s
agent0:                 episode reward: 1.2175,                 loss: nan
agent1:                 episode reward: -1.2175,                 loss: 0.2673
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9452s / 499.2924 s
agent0:                 episode reward: 0.3175,                 loss: nan
agent1:                 episode reward: -0.3175,                 loss: 0.2708
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9033s / 500.1957 s
agent0:                 episode reward: -0.4275,                 loss: nan
agent1:                 episode reward: 0.4275,                 loss: 0.2696
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9154s / 501.1111 s
agent0:                 episode reward: 0.1571,                 loss: nan
agent1:                 episode reward: -0.1571,                 loss: 0.2684
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8993s / 502.0104 s
agent0:                 episode reward: 0.5475,                 loss: nan
agent1:                 episode reward: -0.5475,                 loss: 0.2676
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8868s / 502.8972 s
agent0:                 episode reward: 0.7320,                 loss: nan
agent1:                 episode reward: -0.7320,                 loss: 0.2642
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9049s / 503.8021 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: 0.2547
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8916s / 504.6937 s
agent0:                 episode reward: -0.6379,                 loss: nan
agent1:                 episode reward: 0.6379,                 loss: 0.2547
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9430s / 505.6367 s
agent0:                 episode reward: -1.2322,                 loss: nan
agent1:                 episode reward: 1.2322,                 loss: 0.2553
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9018s / 506.5384 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.2540
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9263s / 507.4647 s
agent0:                 episode reward: -0.8825,                 loss: nan
agent1:                 episode reward: 0.8825,                 loss: 0.2558
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9016s / 508.3663 s
agent0:                 episode reward: -0.9436,                 loss: nan
agent1:                 episode reward: 0.9436,                 loss: 0.2522
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9578s / 509.3240 s
agent0:                 episode reward: 0.2793,                 loss: nan
agent1:                 episode reward: -0.2793,                 loss: 0.2529
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8961s / 510.2201 s
agent0:                 episode reward: -0.2505,                 loss: nan
agent1:                 episode reward: 0.2505,                 loss: 0.2534
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9411s / 511.1612 s
agent0:                 episode reward: -0.3445,                 loss: nan
agent1:                 episode reward: 0.3445,                 loss: 0.2551
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9010s / 512.0622 s
agent0:                 episode reward: 0.0857,                 loss: nan
agent1:                 episode reward: -0.0857,                 loss: 0.2831
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9065s / 512.9687 s
agent0:                 episode reward: -0.7312,                 loss: nan
agent1:                 episode reward: 0.7312,                 loss: 0.2885
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9030s / 513.8717 s
agent0:                 episode reward: -0.1147,                 loss: nan
agent1:                 episode reward: 0.1147,                 loss: 0.2907
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8980s / 514.7697 s
agent0:                 episode reward: 0.4607,                 loss: nan
agent1:                 episode reward: -0.4607,                 loss: 0.2883
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9094s / 515.6791 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.2895
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9051s / 516.5842 s
agent0:                 episode reward: -0.4484,                 loss: nan
agent1:                 episode reward: 0.4484,                 loss: 0.2876
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9117s / 517.4959 s
agent0:                 episode reward: -1.1658,                 loss: nan
agent1:                 episode reward: 1.1658,                 loss: 0.2899
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9177s / 518.4136 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.2873
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9641s / 519.3777 s
agent0:                 episode reward: -0.9947,                 loss: nan
agent1:                 episode reward: 0.9947,                 loss: 0.2876
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9120s / 520.2897 s
agent0:                 episode reward: -0.0423,                 loss: nan
agent1:                 episode reward: 0.0423,                 loss: 0.2879
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9072s / 521.1969 s
agent0:                 episode reward: -0.3929,                 loss: nan
agent1:                 episode reward: 0.3929,                 loss: 0.3339
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9357s / 522.1325 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.3484
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9099s / 523.0425 s
agent0:                 episode reward: 0.6607,                 loss: nan
agent1:                 episode reward: -0.6607,                 loss: 0.3500
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9149s / 523.9574 s
agent0:                 episode reward: 0.2113,                 loss: nan
agent1:                 episode reward: -0.2113,                 loss: 0.3480
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9447s / 524.9021 s
agent0:                 episode reward: -0.4597,                 loss: nan
agent1:                 episode reward: 0.4597,                 loss: 0.3483
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9266s / 525.8286 s
agent0:                 episode reward: -1.1325,                 loss: nan
agent1:                 episode reward: 1.1325,                 loss: 0.3443
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9136s / 526.7423 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.3498
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9284s / 527.6707 s
agent0:                 episode reward: -0.6889,                 loss: nan
agent1:                 episode reward: 0.6889,                 loss: 0.3463
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9292s / 528.6000 s
agent0:                 episode reward: 0.3142,                 loss: nan
agent1:                 episode reward: -0.3142,                 loss: 0.3490
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9604s / 529.5604 s
agent0:                 episode reward: 0.0003,                 loss: nan
agent1:                 episode reward: -0.0003,                 loss: 0.3482
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9170s / 530.4774 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.3698
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9199s / 531.3973 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.3667
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9460s / 532.3433 s
agent0:                 episode reward: -0.9889,                 loss: nan
agent1:                 episode reward: 0.9889,                 loss: 0.3673
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9218s / 533.2651 s
agent0:                 episode reward: -0.5603,                 loss: nan
agent1:                 episode reward: 0.5603,                 loss: 0.3672
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9358s / 534.2009 s
agent0:                 episode reward: -0.3056,                 loss: nan
agent1:                 episode reward: 0.3056,                 loss: 0.3684
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9074s / 535.1083 s
agent0:                 episode reward: -0.3083,                 loss: nan
agent1:                 episode reward: 0.3083,                 loss: 0.3668
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9233s / 536.0316 s
agent0:                 episode reward: -1.0013,                 loss: nan
agent1:                 episode reward: 1.0013,                 loss: 0.3650
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9250s / 536.9567 s
agent0:                 episode reward: -0.1686,                 loss: nan
agent1:                 episode reward: 0.1686,                 loss: 0.3680
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9186s / 537.8753 s
agent0:                 episode reward: -1.0719,                 loss: nan
agent1:                 episode reward: 1.0719,                 loss: 0.3655
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9253s / 538.8005 s
agent0:                 episode reward: -0.6653,                 loss: nan
agent1:                 episode reward: 0.6653,                 loss: 0.3683
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9789s / 539.7794 s
agent0:                 episode reward: 0.8471,                 loss: nan
agent1:                 episode reward: -0.8471,                 loss: 0.3134
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9256s / 540.7051 s
agent0:                 episode reward: 1.0535,                 loss: nan
agent1:                 episode reward: -1.0535,                 loss: 0.2801
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9131s / 541.6182 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.2799
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9499s / 542.5681 s
agent0:                 episode reward: 0.7818,                 loss: nan
agent1:                 episode reward: -0.7818,                 loss: 0.2788
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9299s / 543.4979 s
agent0:                 episode reward: -0.3560,                 loss: nan
agent1:                 episode reward: 0.3560,                 loss: 0.2785
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9625s / 544.4605 s
agent0:                 episode reward: -0.3598,                 loss: nan
agent1:                 episode reward: 0.3598,                 loss: 0.2781
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9311s / 545.3915 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.2776
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9353s / 546.3268 s
agent0:                 episode reward: 0.6938,                 loss: nan
agent1:                 episode reward: -0.6938,                 loss: 0.2765
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9333s / 547.2602 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.2774
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9271s / 548.1873 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.2783
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9407s / 549.1280 s
agent0:                 episode reward: -0.0804,                 loss: nan
agent1:                 episode reward: 0.0804,                 loss: 0.2501
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9619s / 550.0898 s
agent0:                 episode reward: -0.5821,                 loss: nan
agent1:                 episode reward: 0.5821,                 loss: 0.2337
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9462s / 551.0360 s
agent0:                 episode reward: -0.0857,                 loss: nan
agent1:                 episode reward: 0.0857,                 loss: 0.2315
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9347s / 551.9707 s
agent0:                 episode reward: -0.8725,                 loss: nan
agent1:                 episode reward: 0.8725,                 loss: 0.2315
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9453s / 552.9160 s
agent0:                 episode reward: 0.3712,                 loss: nan
agent1:                 episode reward: -0.3712,                 loss: 0.2313
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9350s / 553.8510 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.2290
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9444s / 554.7954 s
agent0:                 episode reward: -0.6769,                 loss: nan
agent1:                 episode reward: 0.6769,                 loss: 0.2319
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9316s / 555.7270 s
agent0:                 episode reward: 0.2615,                 loss: nan
agent1:                 episode reward: -0.2615,                 loss: 0.2281
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9440s / 556.6710 s
agent0:                 episode reward: -0.1844,                 loss: nan
agent1:                 episode reward: 0.1844,                 loss: 0.2296
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9375s / 557.6085 s
agent0:                 episode reward: 0.0999,                 loss: nan
agent1:                 episode reward: -0.0999,                 loss: 0.2286
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9525s / 558.5610 s
agent0:                 episode reward: -0.1993,                 loss: nan
agent1:                 episode reward: 0.1993,                 loss: 0.2336
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9628s / 559.5239 s
agent0:                 episode reward: 0.7655,                 loss: nan
agent1:                 episode reward: -0.7655,                 loss: 0.2310
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9787s / 560.5026 s
agent0:                 episode reward: -0.2254,                 loss: nan
agent1:                 episode reward: 0.2254,                 loss: 0.2298
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9679s / 561.4704 s
agent0:                 episode reward: 0.4302,                 loss: nan
agent1:                 episode reward: -0.4302,                 loss: 0.2307
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9359s / 562.4064 s
agent0:                 episode reward: 0.8189,                 loss: nan
agent1:                 episode reward: -0.8189,                 loss: 0.2284
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9557s / 563.3620 s
agent0:                 episode reward: -0.7203,                 loss: nan
agent1:                 episode reward: 0.7203,                 loss: 0.2286
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9548s / 564.3168 s
agent0:                 episode reward: -0.0378,                 loss: nan
agent1:                 episode reward: 0.0378,                 loss: 0.2264
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9508s / 565.2676 s
agent0:                 episode reward: 0.3780,                 loss: nan
agent1:                 episode reward: -0.3780,                 loss: 0.2267
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9451s / 566.2127 s
agent0:                 episode reward: -1.0173,                 loss: nan
agent1:                 episode reward: 1.0173,                 loss: 0.2271
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9648s / 567.1775 s
agent0:                 episode reward: 0.4382,                 loss: nan
agent1:                 episode reward: -0.4382,                 loss: 0.2305
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9501s / 568.1276 s
agent0:                 episode reward: -0.6186,                 loss: nan
agent1:                 episode reward: 0.6186,                 loss: 0.2526
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9516s / 569.0791 s
agent0:                 episode reward: -0.0291,                 loss: nan
agent1:                 episode reward: 0.0291,                 loss: 0.2601
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9851s / 570.0643 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.2591
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9953s / 571.0595 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.2610
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9538s / 572.0134 s
agent0:                 episode reward: -0.2222,                 loss: nan
agent1:                 episode reward: 0.2222,                 loss: 0.2598
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9631s / 572.9765 s
agent0:                 episode reward: -0.6593,                 loss: nan
agent1:                 episode reward: 0.6593,                 loss: 0.2594
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9648s / 573.9413 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.2585
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9449s / 574.8863 s
agent0:                 episode reward: -0.2238,                 loss: nan
agent1:                 episode reward: 0.2238,                 loss: 0.2602
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9985s / 575.8848 s
agent0:                 episode reward: -1.0996,                 loss: nan
agent1:                 episode reward: 1.0996,                 loss: 0.2576
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9505s / 576.8353 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.2576
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9544s / 577.7897 s
agent0:                 episode reward: 0.2529,                 loss: nan
agent1:                 episode reward: -0.2529,                 loss: 0.2744
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9589s / 578.7486 s
agent0:                 episode reward: 0.2094,                 loss: nan
agent1:                 episode reward: -0.2094,                 loss: 0.2655
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9912s / 579.7398 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.2680
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9985s / 580.7384 s
agent0:                 episode reward: 0.3538,                 loss: nan
agent1:                 episode reward: -0.3538,                 loss: 0.2660
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9530s / 581.6914 s
agent0:                 episode reward: 0.7410,                 loss: nan
agent1:                 episode reward: -0.7410,                 loss: 0.2662
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9731s / 582.6645 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.2669
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9754s / 583.6399 s
agent0:                 episode reward: 0.2238,                 loss: nan
agent1:                 episode reward: -0.2238,                 loss: 0.2658
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9697s / 584.6096 s
agent0:                 episode reward: -0.9429,                 loss: nan
agent1:                 episode reward: 0.9429,                 loss: 0.2683
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9853s / 585.5949 s
agent0:                 episode reward: 0.1469,                 loss: nan
agent1:                 episode reward: -0.1469,                 loss: 0.2655
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9581s / 586.5530 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: 0.2656
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9623s / 587.5153 s
agent0:                 episode reward: -0.0473,                 loss: nan
agent1:                 episode reward: 0.0473,                 loss: 0.2578
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9734s / 588.4887 s
agent0:                 episode reward: -0.5009,                 loss: nan
agent1:                 episode reward: 0.5009,                 loss: 0.2470
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9780s / 589.4666 s
agent0:                 episode reward: -0.8023,                 loss: nan
agent1:                 episode reward: 0.8023,                 loss: 0.2460
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9693s / 590.4359 s
agent0:                 episode reward: -0.2171,                 loss: nan
agent1:                 episode reward: 0.2171,                 loss: 0.2463
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0314s / 591.4673 s
agent0:                 episode reward: -0.6049,                 loss: nan
agent1:                 episode reward: 0.6049,                 loss: 0.2460
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9919s / 592.4592 s
agent0:                 episode reward: 0.0947,                 loss: nan
agent1:                 episode reward: -0.0947,                 loss: 0.2458
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9702s / 593.4294 s
agent0:                 episode reward: -0.1195,                 loss: nan
agent1:                 episode reward: 0.1195,                 loss: 0.2437
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9826s / 594.4121 s
agent0:                 episode reward: -0.0254,                 loss: nan
agent1:                 episode reward: 0.0254,                 loss: 0.2445
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9789s / 595.3909 s
agent0:                 episode reward: 0.3768,                 loss: nan
agent1:                 episode reward: -0.3768,                 loss: 0.2459
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9864s / 596.3774 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.2443
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9984s / 597.3758 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.2608
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9650s / 598.3408 s
agent0:                 episode reward: -0.9819,                 loss: nan
agent1:                 episode reward: 0.9819,                 loss: 0.2645
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9866s / 599.3274 s
agent0:                 episode reward: -0.4589,                 loss: nan
agent1:                 episode reward: 0.4589,                 loss: 0.2629
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0031s / 600.3304 s
agent0:                 episode reward: -0.7701,                 loss: nan
agent1:                 episode reward: 0.7701,                 loss: 0.2648
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0186s / 601.3490 s
agent0:                 episode reward: -0.0307,                 loss: nan
agent1:                 episode reward: 0.0307,                 loss: 0.2628
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9829s / 602.3319 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: 0.2643
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 603.3206 s
agent0:                 episode reward: 0.1452,                 loss: nan
agent1:                 episode reward: -0.1452,                 loss: 0.2628
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9870s / 604.3076 s
agent0:                 episode reward: -0.5367,                 loss: nan
agent1:                 episode reward: 0.5367,                 loss: 0.2631
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9977s / 605.3053 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.2613
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9937s / 606.2990 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.2653
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0015s / 607.3005 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.3043
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9885s / 608.2890 s
agent0:                 episode reward: -0.0416,                 loss: nan
agent1:                 episode reward: 0.0416,                 loss: 0.3146
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0116s / 609.3006 s
agent0:                 episode reward: 0.0687,                 loss: nan
agent1:                 episode reward: -0.0687,                 loss: 0.3154
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9862s / 610.2868 s
agent0:                 episode reward: -0.9987,                 loss: nan
agent1:                 episode reward: 0.9987,                 loss: 0.3153
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0188s / 611.3056 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.3144
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0137s / 612.3193 s
agent0:                 episode reward: 0.1894,                 loss: nan
agent1:                 episode reward: -0.1894,                 loss: 0.3146
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0319s / 613.3513 s
agent0:                 episode reward: 0.2042,                 loss: nan
agent1:                 episode reward: -0.2042,                 loss: 0.3125
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9860s / 614.3373 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.3155
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0170s / 615.3543 s
agent0:                 episode reward: 0.2045,                 loss: nan
agent1:                 episode reward: -0.2045,                 loss: 0.3132
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9956s / 616.3500 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: 0.3132
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0211s / 617.3711 s
agent0:                 episode reward: 0.0591,                 loss: nan
agent1:                 episode reward: -0.0591,                 loss: 0.3469
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0112s / 618.3823 s
agent0:                 episode reward: 0.3054,                 loss: nan
agent1:                 episode reward: -0.3054,                 loss: 0.3517
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0171s / 619.3995 s
agent0:                 episode reward: -0.1975,                 loss: nan
agent1:                 episode reward: 0.1975,                 loss: 0.3523
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0292s / 620.4287 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: 0.3512
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0047s / 621.4334 s
agent0:                 episode reward: -0.3191,                 loss: nan
agent1:                 episode reward: 0.3191,                 loss: 0.3512
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0441s / 622.4775 s
agent0:                 episode reward: 0.4481,                 loss: nan
agent1:                 episode reward: -0.4481,                 loss: 0.3502
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9946s / 623.4721 s
agent0:                 episode reward: -0.4577,                 loss: nan
agent1:                 episode reward: 0.4577,                 loss: 0.3511
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0085s / 624.4806 s
agent0:                 episode reward: -0.5728,                 loss: nan
agent1:                 episode reward: 0.5728,                 loss: 0.3504
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0216s / 625.5022 s
agent0:                 episode reward: -0.3421,                 loss: nan
agent1:                 episode reward: 0.3421,                 loss: 0.3495
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9954s / 626.4976 s
agent0:                 episode reward: 0.2138,                 loss: nan
agent1:                 episode reward: -0.2138,                 loss: 0.3511
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0044s / 627.5021 s
agent0:                 episode reward: 0.6772,                 loss: nan
agent1:                 episode reward: -0.6772,                 loss: 0.2998
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0321s / 628.5341 s
agent0:                 episode reward: 0.7479,                 loss: nan
agent1:                 episode reward: -0.7479,                 loss: 0.2644
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0246s / 629.5587 s
agent0:                 episode reward: -0.0069,                 loss: nan
agent1:                 episode reward: 0.0069,                 loss: 0.2649
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0496s / 630.6084 s
agent0:                 episode reward: -0.7863,                 loss: nan
agent1:                 episode reward: 0.7863,                 loss: 0.2643
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0165s / 631.6249 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.2634
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0445s / 632.6694 s
agent0:                 episode reward: 0.2819,                 loss: nan
agent1:                 episode reward: -0.2819,                 loss: 0.2628
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0529s / 633.7223 s
agent0:                 episode reward: -0.3382,                 loss: nan
agent1:                 episode reward: 0.3382,                 loss: 0.2608
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0071s / 634.7294 s
agent0:                 episode reward: -0.7975,                 loss: nan
agent1:                 episode reward: 0.7975,                 loss: 0.2644
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0067s / 635.7361 s
agent0:                 episode reward: -0.2151,                 loss: nan
agent1:                 episode reward: 0.2151,                 loss: 0.2624
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0770s / 636.8131 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.2619
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0029s / 637.8160 s
agent0:                 episode reward: -0.4000,                 loss: nan
agent1:                 episode reward: 0.4000,                 loss: 0.2245
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0068s / 638.8228 s
agent0:                 episode reward: 0.5972,                 loss: nan
agent1:                 episode reward: -0.5972,                 loss: 0.1974
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0616s / 639.8844 s
agent0:                 episode reward: 0.5529,                 loss: nan
agent1:                 episode reward: -0.5529,                 loss: 0.1955
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0185s / 640.9029 s
agent0:                 episode reward: 0.9749,                 loss: nan
agent1:                 episode reward: -0.9749,                 loss: 0.1935
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0348s / 641.9376 s
agent0:                 episode reward: -0.0710,                 loss: nan
agent1:                 episode reward: 0.0710,                 loss: 0.1938
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0754s / 643.0131 s
agent0:                 episode reward: -0.2500,                 loss: nan
agent1:                 episode reward: 0.2500,                 loss: 0.1925
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0622s / 644.0753 s
agent0:                 episode reward: 0.9885,                 loss: nan
agent1:                 episode reward: -0.9885,                 loss: 0.1932
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0409s / 645.1161 s
agent0:                 episode reward: 0.2868,                 loss: nan
agent1:                 episode reward: -0.2868,                 loss: 0.1934
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0355s / 646.1516 s
agent0:                 episode reward: -0.5349,                 loss: nan
agent1:                 episode reward: 0.5349,                 loss: 0.1943
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0213s / 647.1729 s
agent0:                 episode reward: -1.1206,                 loss: nan
agent1:                 episode reward: 1.1206,                 loss: 0.1909
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9974s / 648.1703 s
agent0:                 episode reward: 0.7532,                 loss: nan
agent1:                 episode reward: -0.7532,                 loss: 0.2115
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0364s / 649.2067 s
agent0:                 episode reward: 0.4127,                 loss: nan
agent1:                 episode reward: -0.4127,                 loss: 0.2109
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0590s / 650.2657 s
agent0:                 episode reward: 0.1467,                 loss: nan
agent1:                 episode reward: -0.1467,                 loss: 0.2127
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0365s / 651.3022 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.2095
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0889s / 652.3911 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.2090
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0708s / 653.4619 s
agent0:                 episode reward: 0.4974,                 loss: nan
agent1:                 episode reward: -0.4974,                 loss: 0.2075
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0240s / 654.4859 s
agent0:                 episode reward: 0.2799,                 loss: nan
agent1:                 episode reward: -0.2799,                 loss: 0.2122
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0275s / 655.5134 s
agent0:                 episode reward: 0.6544,                 loss: nan
agent1:                 episode reward: -0.6544,                 loss: 0.2097
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0206s / 656.5340 s
agent0:                 episode reward: 1.2125,                 loss: nan
agent1:                 episode reward: -1.2125,                 loss: 0.2096
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0152s / 657.5492 s
agent0:                 episode reward: -0.2609,                 loss: nan
agent1:                 episode reward: 0.2609,                 loss: 0.2116
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0221s / 658.5713 s
agent0:                 episode reward: 1.3767,                 loss: nan
agent1:                 episode reward: -1.3767,                 loss: 0.2300
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0306s / 659.6019 s
agent0:                 episode reward: -0.0493,                 loss: nan
agent1:                 episode reward: 0.0493,                 loss: 0.2338
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0116s / 660.6135 s
agent0:                 episode reward: -0.6349,                 loss: nan
agent1:                 episode reward: 0.6349,                 loss: 0.2352
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0037s / 661.6172 s
agent0:                 episode reward: -0.2459,                 loss: nan
agent1:                 episode reward: 0.2459,                 loss: 0.2314
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0649s / 662.6821 s
agent0:                 episode reward: -0.6302,                 loss: nan
agent1:                 episode reward: 0.6302,                 loss: 0.2331
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0919s / 663.7741 s
agent0:                 episode reward: -0.0136,                 loss: nan
agent1:                 episode reward: 0.0136,                 loss: 0.2301
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1419s / 664.9160 s
agent0:                 episode reward: 1.2621,                 loss: nan
agent1:                 episode reward: -1.2621,                 loss: 0.2344
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0408s / 665.9568 s
agent0:                 episode reward: 0.0151,                 loss: nan
agent1:                 episode reward: -0.0151,                 loss: 0.2325
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0760s / 667.0328 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: 0.2337
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1238s / 668.1566 s
agent0:                 episode reward: -0.6809,                 loss: nan
agent1:                 episode reward: 0.6809,                 loss: 0.2322
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1904s / 669.3470 s
agent0:                 episode reward: 0.1476,                 loss: nan
agent1:                 episode reward: -0.1476,                 loss: 0.2658
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1306s / 670.4776 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.2705
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1788s / 671.6565 s
agent0:                 episode reward: -0.9990,                 loss: nan
agent1:                 episode reward: 0.9990,                 loss: 0.2731
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1308s / 672.7873 s
agent0:                 episode reward: -0.2005,                 loss: nan
agent1:                 episode reward: 0.2005,                 loss: 0.2712
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0801s / 673.8674 s
agent0:                 episode reward: -1.0028,                 loss: nan
agent1:                 episode reward: 1.0028,                 loss: 0.2708
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0445s / 674.9119 s
agent0:                 episode reward: -0.0624,                 loss: nan
agent1:                 episode reward: 0.0624,                 loss: 0.2685
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0525s / 675.9645 s
agent0:                 episode reward: 0.5095,                 loss: nan
agent1:                 episode reward: -0.5095,                 loss: 0.2698
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0069s / 676.9714 s
agent0:                 episode reward: 0.5737,                 loss: nan
agent1:                 episode reward: -0.5737,                 loss: 0.2711
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0299s / 678.0013 s
agent0:                 episode reward: 0.0390,                 loss: nan
agent1:                 episode reward: -0.0390,                 loss: 0.2690
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0577s / 679.0589 s
agent0:                 episode reward: 0.5726,                 loss: nan
agent1:                 episode reward: -0.5726,                 loss: 0.2692
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0770s / 680.1359 s
agent0:                 episode reward: 0.7259,                 loss: nan
agent1:                 episode reward: -0.7259,                 loss: 0.2730
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 681.1904 s
agent0:                 episode reward: 0.2409,                 loss: nan
agent1:                 episode reward: -0.2409,                 loss: 0.2642
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 682.2448 s
agent0:                 episode reward: -0.6864,                 loss: nan
agent1:                 episode reward: 0.6864,                 loss: 0.2648
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0950s / 683.3398 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.2631
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0179s / 684.3577 s
agent0:                 episode reward: 0.5459,                 loss: nan
agent1:                 episode reward: -0.5459,                 loss: 0.2646
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 685.4385 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: 0.2663
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0368s / 686.4753 s
agent0:                 episode reward: 1.1146,                 loss: nan
agent1:                 episode reward: -1.1146,                 loss: 0.2639
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0631s / 687.5384 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.2646
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0346s / 688.5730 s
agent0:                 episode reward: 0.6719,                 loss: nan
agent1:                 episode reward: -0.6719,                 loss: 0.2651
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0238s / 689.5968 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.2644
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0224s / 690.6192 s
agent0:                 episode reward: -0.3285,                 loss: nan
agent1:                 episode reward: 0.3285,                 loss: 0.2648
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0857s / 691.7049 s
agent0:                 episode reward: 0.5980,                 loss: nan
agent1:                 episode reward: -0.5980,                 loss: 0.2613
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0469s / 692.7518 s
agent0:                 episode reward: -1.9067,                 loss: nan
agent1:                 episode reward: 1.9067,                 loss: 0.2593
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0889s / 693.8407 s
agent0:                 episode reward: 0.0198,                 loss: nan
agent1:                 episode reward: -0.0198,                 loss: 0.2582
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0697s / 694.9104 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: 0.2593
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0731s / 695.9836 s
agent0:                 episode reward: -0.4446,                 loss: nan
agent1:                 episode reward: 0.4446,                 loss: 0.2586
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0784s / 697.0620 s
agent0:                 episode reward: 0.1144,                 loss: nan
agent1:                 episode reward: -0.1144,                 loss: 0.2597
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0802s / 698.1422 s
agent0:                 episode reward: -0.9751,                 loss: nan
agent1:                 episode reward: 0.9751,                 loss: 0.2587
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0824s / 699.2245 s
agent0:                 episode reward: -0.5831,                 loss: nan
agent1:                 episode reward: 0.5831,                 loss: 0.2554
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0737s / 700.2982 s
agent0:                 episode reward: -0.5878,                 loss: nan
agent1:                 episode reward: 0.5878,                 loss: 0.2574
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0820s / 701.3802 s
agent0:                 episode reward: -0.5423,                 loss: nan
agent1:                 episode reward: 0.5423,                 loss: 0.2887
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0697s / 702.4499 s
agent0:                 episode reward: -0.7832,                 loss: nan
agent1:                 episode reward: 0.7832,                 loss: 0.2992
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1097s / 703.5596 s
agent0:                 episode reward: -1.0471,                 loss: nan
agent1:                 episode reward: 1.0471,                 loss: 0.2997
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1037s / 704.6633 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.2970
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0987s / 705.7620 s
agent0:                 episode reward: 1.0702,                 loss: nan
agent1:                 episode reward: -1.0702,                 loss: 0.2986
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0749s / 706.8370 s
agent0:                 episode reward: -0.0183,                 loss: nan
agent1:                 episode reward: 0.0183,                 loss: 0.2980
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0750s / 707.9120 s
agent0:                 episode reward: -0.0577,                 loss: nan
agent1:                 episode reward: 0.0577,                 loss: 0.2973
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0493s / 708.9613 s
agent0:                 episode reward: 0.8747,                 loss: nan
agent1:                 episode reward: -0.8747,                 loss: 0.2944
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0716s / 710.0328 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.2958
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0898s / 711.1226 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.2952
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0897s / 712.2123 s
agent0:                 episode reward: 0.1320,                 loss: nan
agent1:                 episode reward: -0.1320,                 loss: 0.3353
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0918s / 713.3041 s
agent0:                 episode reward: -0.1429,                 loss: nan
agent1:                 episode reward: 0.1429,                 loss: 0.3462
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1107s / 714.4149 s
agent0:                 episode reward: -0.0626,                 loss: nan
agent1:                 episode reward: 0.0626,                 loss: 0.3441
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1061s / 715.5210 s
agent0:                 episode reward: -0.5028,                 loss: nan
agent1:                 episode reward: 0.5028,                 loss: 0.3438
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0889s / 716.6099 s
agent0:                 episode reward: -0.2781,                 loss: nan
agent1:                 episode reward: 0.2781,                 loss: 0.3436
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0825s / 717.6924 s
agent0:                 episode reward: -0.7032,                 loss: nan
agent1:                 episode reward: 0.7032,                 loss: 0.3439
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0784s / 718.7708 s
agent0:                 episode reward: 0.7206,                 loss: nan
agent1:                 episode reward: -0.7206,                 loss: 0.3428
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0603s / 719.8311 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: 0.3437
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0832s / 720.9143 s
agent0:                 episode reward: -1.3553,                 loss: nan
agent1:                 episode reward: 1.3553,                 loss: 0.3421
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0843s / 721.9986 s
agent0:                 episode reward: 0.0345,                 loss: nan
agent1:                 episode reward: -0.0345,                 loss: 0.3436
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0716s / 723.0702 s
agent0:                 episode reward: -0.3722,                 loss: nan
agent1:                 episode reward: 0.3722,                 loss: 0.3304
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1271s / 724.1973 s
agent0:                 episode reward: -0.1953,                 loss: nan
agent1:                 episode reward: 0.1953,                 loss: 0.3142
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0930s / 725.2902 s
agent0:                 episode reward: 0.2866,                 loss: nan
agent1:                 episode reward: -0.2866,                 loss: 0.3146
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0766s / 726.3669 s
agent0:                 episode reward: 0.5161,                 loss: nan
agent1:                 episode reward: -0.5161,                 loss: 0.3114
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0972s / 727.4641 s
agent0:                 episode reward: 0.0642,                 loss: nan
agent1:                 episode reward: -0.0642,                 loss: 0.3157
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0825s / 728.5466 s
agent0:                 episode reward: -1.0700,                 loss: nan
agent1:                 episode reward: 1.0700,                 loss: 0.3159
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0768s / 729.6233 s
agent0:                 episode reward: 0.4530,                 loss: nan
agent1:                 episode reward: -0.4530,                 loss: 0.3140
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0944s / 730.7177 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.3159
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0883s / 731.8060 s
agent0:                 episode reward: 0.0097,                 loss: nan
agent1:                 episode reward: -0.0097,                 loss: 0.3157
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0924s / 732.8983 s
agent0:                 episode reward: 0.2191,                 loss: nan
agent1:                 episode reward: -0.2191,                 loss: 0.3129
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0911s / 733.9895 s
agent0:                 episode reward: 0.0061,                 loss: nan
agent1:                 episode reward: -0.0061,                 loss: 0.2534
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1191s / 735.1086 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.2143
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0863s / 736.1949 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.2124
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0774s / 737.2723 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.2159
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 738.3650 s
agent0:                 episode reward: 0.0996,                 loss: nan
agent1:                 episode reward: -0.0996,                 loss: 0.2161
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0733s / 739.4383 s
agent0:                 episode reward: -1.1180,                 loss: nan
agent1:                 episode reward: 1.1180,                 loss: 0.2141
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1005s / 740.5388 s
agent0:                 episode reward: -0.1713,                 loss: nan
agent1:                 episode reward: 0.1713,                 loss: 0.2143
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0977s / 741.6366 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: 1.1243,                 loss: nan
agent1:                 episode reward: -1.1243,                 loss: 0.2126
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1010s / 742.7375 s
agent0:                 episode reward: -0.3782,                 loss: nan
agent1:                 episode reward: 0.3782,                 loss: 0.2123
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0912s / 743.8288 s
agent0:                 episode reward: 0.6232,                 loss: nan
agent1:                 episode reward: -0.6232,                 loss: 0.2143
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1540s / 744.9828 s
agent0:                 episode reward: -0.0400,                 loss: nan
agent1:                 episode reward: 0.0400,                 loss: 0.2017
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0978s / 746.0805 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.1892
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0894s / 747.1700 s
agent0:                 episode reward: 0.3715,                 loss: nan
agent1:                 episode reward: -0.3715,                 loss: 0.1880
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1173s / 748.2873 s
agent0:                 episode reward: -0.8635,                 loss: nan
agent1:                 episode reward: 0.8635,                 loss: 0.1870
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1090s / 749.3963 s
agent0:                 episode reward: 1.3312,                 loss: nan
agent1:                 episode reward: -1.3312,                 loss: 0.1851
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 750.4890 s
agent0:                 episode reward: -0.3914,                 loss: nan
agent1:                 episode reward: 0.3914,                 loss: 0.1862
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1372s / 751.6262 s
agent0:                 episode reward: 0.2346,                 loss: nan
agent1:                 episode reward: -0.2346,                 loss: 0.1852
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1876s / 752.8138 s
agent0:                 episode reward: -0.0265,                 loss: nan
agent1:                 episode reward: 0.0265,                 loss: 0.1864
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0980s / 753.9118 s
agent0:                 episode reward: -0.3782,                 loss: nan
agent1:                 episode reward: 0.3782,                 loss: 0.1850
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1422s / 755.0541 s
agent0:                 episode reward: 0.9860,                 loss: nan
agent1:                 episode reward: -0.9860,                 loss: 0.1854
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1152s / 756.1693 s
agent0:                 episode reward: -0.8405,                 loss: nan
agent1:                 episode reward: 0.8405,                 loss: 0.2096
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1125s / 757.2818 s
agent0:                 episode reward: 0.8634,                 loss: nan
agent1:                 episode reward: -0.8634,                 loss: 0.2111
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1348s / 758.4166 s
agent0:                 episode reward: -0.2079,                 loss: nan
agent1:                 episode reward: 0.2079,                 loss: 0.2121
