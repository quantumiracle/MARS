Traceback (most recent call last):
  File "/home/zihan/research/MARS/general_train.py", line 1, in <module>
    from mars.utils.func import LoadYAML2Dict
  File "/home/zihan/research/MARS/mars/utils/func.py", line 7, in <module>
    from mars.rl.agents  import *
  File "/home/zihan/research/MARS/mars/rl/agents/__init__.py", line 1, in <module>
    from .dqn import DQN
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220328_0432/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220328_0432/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 6.2027s / 6.2027 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0063
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 199.5844s / 205.7871 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0069
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0072
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 203.4052s / 409.1923 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 206.2995s / 615.4918 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0141
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0140
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 210.5753s / 826.0672 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0139
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0140
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 212.6558s / 1038.7229 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0137
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 214.4636s / 1253.1865 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0138
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 220.7011s / 1473.8876 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0135
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0147
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 223.0545s / 1696.9421 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0143
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 226.0971s / 1923.0391 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0140
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 230.6883s / 2153.7274 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0139
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 231.1542s / 2384.8817 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0137
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0137
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 237.0567s / 2621.9383 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0134
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 241.9761s / 2863.9144 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0144
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0143
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 245.1248s / 3109.0392 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0139
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0144
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 248.9414s / 3357.9806 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0148
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 254.0271s / 3612.0077 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0144
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0144
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 256.9709s / 3868.9786 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0142
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0148
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2790s / 4127.2575 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0147
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0150
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 258.5672s / 4385.8247 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0149
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0153
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 257.8103s / 4643.6350 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0155
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0151
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0731s / 4903.7082 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0154
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0156
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7872s / 5164.4954 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0155
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.1360s / 5424.6313 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0152
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0155
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.6167s / 5684.2480 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0151
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0153
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.9527s / 5944.2007 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0152
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0149
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.5650s / 6203.7656 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0152
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0153
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.6147s / 6463.3803 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0151
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0150
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0197s / 6723.4000 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0147
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0152
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.7074s / 6983.1074 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0156
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0147
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1324s / 7244.2398 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0143
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.0677s / 7503.3075 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0146
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0147
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.4806s / 7762.7881 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0146
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0152
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8374s / 8021.6255 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0144
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0149
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7046s / 8282.3301 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0146
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0146
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.3385s / 8541.6686 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0145
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0146
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.0781s / 8802.7467 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0142
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0145
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3974s / 9066.1441 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0144
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.3962s / 9326.5403 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0141
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0138
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8717s / 9587.4120 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0134
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.3912s / 9848.8032 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0136
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3093s / 10111.1125 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.6316s / 10371.7441 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0145
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0568s / 10633.8008 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0139
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0135
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1021s / 10894.9029 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0137
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0136
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3095s / 11157.2125 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0136
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5838s / 11417.7963 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7529s / 11679.5492 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4667s / 11942.0159 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4336s / 12204.4495 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.8483s / 12466.2979 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.5973s / 12727.8951 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2732s / 12990.1683 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7276s / 13251.8960 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.5782s / 13514.4742 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0336s / 13777.5078 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.7769s / 14040.2847 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0894s / 14304.3741 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3144s / 14567.6885 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0596s / 14829.7481 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.1069s / 15091.8550 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1765s / 15356.0315 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0356s / 15619.0671 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.5011s / 15882.5682 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2903s / 16144.8585 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0861s / 16408.9446 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8732s / 16671.8178 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2295s / 16935.0473 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.9891s / 17199.0364 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 264.5819s / 17463.6183 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1083s / 17728.7266 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.5859s / 17993.3125 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.7498s / 18257.0623 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8110s / 18521.8734 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6169s / 18785.4903 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6104s / 19050.1007 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4596s / 19316.5604 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6630s / 19581.2233 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8438s / 19847.0672 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6064s / 20113.6736 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8171s / 20379.4906 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5472s / 20645.0379 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3728s / 20910.4107 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3362s / 21175.7469 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0129s / 21438.7598 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3421s / 21703.1018 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8358s / 21967.9377 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1056s / 22232.0433 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0949s / 22496.1382 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.1088s / 22759.2470 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5226s / 23025.7696 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1708s / 23290.9404 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3200s / 23555.2604 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8318s / 23820.0922 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.2283s / 24085.3204 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9315s / 24351.2519 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.4081s / 24615.6600 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3147s / 24878.9747 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0864s / 25144.0611 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9275s / 25411.9885 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8173s / 25679.8059 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7797s / 25982.5856 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 283.9650s / 26266.5506 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3011s / 26534.8517 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5140s / 26801.3658 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6178s / 27066.9836 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0499s / 27331.0335 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9025s / 27595.9360 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2541s / 27863.1900 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0138s / 28128.2038 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6608s / 28393.8647 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4647s / 28659.3294 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8081s / 28926.1375 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3109s / 29191.4484 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0100
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1868s / 29457.6352 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8806s / 29722.5158 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7846s / 29987.3004 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0610s / 30252.3613 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0095
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7642s / 30521.1255 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6227s / 30789.7483 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5112s / 31057.2595 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0093
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7771s / 31324.0365 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0093
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0439s / 31591.0805 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7328s / 31859.8133 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6110s / 32125.4243 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0094
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2930s / 32392.7173 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9264s / 32660.6437 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7057s / 32928.3494 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5779s / 33195.9274 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0100
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4986s / 33464.4260 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0094
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3228s / 33732.7488 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0094
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7381s / 34000.4869 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0094
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0092
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2955s / 34267.7825 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0092
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4032s / 34536.1856 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0097
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8526s / 34804.0382 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0095
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2380s / 35073.2762 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0096
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2493s / 35342.5255 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9111s / 35609.4366 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0095
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1670s / 35878.6035 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0093
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0098
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1756s / 36147.7791 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0094
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 276.8968s / 36424.6759 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0097
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8123s / 36725.4882 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0464s / 37026.5346 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0096
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2334s / 37327.7680 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0096
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.8382s / 37625.6062 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0096
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6542s / 37924.2604 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5096s / 38223.7700 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.9561s / 38522.7261 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 296.4039s / 38819.1300 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1019s / 39118.2319 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 297.7085s / 39415.9404 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6876s / 39714.6280 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.8144s / 40014.4424 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.6565s / 40314.0989 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2697s / 40614.3686 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 312.5433s / 40926.9119 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 305.1279s / 41232.0398 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5037s / 41533.5435 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1259s / 41832.6694 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.8131s / 42130.4825 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.4380s / 42428.9205 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6443s / 42729.5648 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0096s / 43030.5745 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 298.2034s / 43328.7778 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.3575s / 43627.1354 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8648s / 43926.0001 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2547s / 44225.2548 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.9680s / 44524.2228 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.0666s / 44823.2894 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.1304s / 45121.4199 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2083s / 45421.6282 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6600s / 45722.2882 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.0781s / 46022.3663 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0096
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7810s / 46325.1473 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2383s / 46626.3856 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7979s / 46926.1835 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4845s / 47226.6680 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7371s / 47528.4051 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5818s / 47828.9870 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8975s / 48129.8845 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9730s / 48431.8575 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7400s / 48732.5975 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5313s / 49034.1288 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4601s / 49334.5889 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7058s / 49635.2947 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0321s / 49937.3267 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1439s / 50238.4706 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0157s / 50540.4863 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 303.0250s / 50843.5113 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6001s / 51144.1114 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7370s / 51445.8485 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3709s / 51747.2193 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7776s / 52047.9970 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4516s / 52349.4485 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7071s / 52650.1556 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.3545s / 52953.5101 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4501s / 53253.9602 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9971s / 53554.9573 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0764s / 53856.0338 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 302.3295s / 54158.3633 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.2986s / 54461.6619 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4002s / 54763.0621 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 302.1093s / 55065.1714 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.2271s / 55367.3985 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.8815s / 55669.2800 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.1368s / 55972.4168 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3220s / 56273.7388 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8182s / 56572.5569 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1825s / 56873.7394 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 302.2266s / 57175.9660 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.6987s / 57479.6647 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 302.1732s / 57781.8378 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 303.4893s / 58085.3271 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7575s / 58388.0846 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0111
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 312.0291s / 58700.1138 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5394s / 59001.6531 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7043s / 59301.3575 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0100
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9074s / 59602.2649 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9659s / 59903.2308 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3777s / 60202.6085 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1147s / 60503.7232 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3820s / 60803.1052 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3914s / 61104.4965 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 297.6754s / 61402.1720 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2292s / 61701.4011 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 294.7411s / 61996.1423 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 297.9706s / 62294.1129 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.5271s / 62592.6400 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 298.7662s / 62891.4061 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2304s / 63191.6366 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.0988s / 63490.7354 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5641s / 63791.2995 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.2484s / 64089.5479 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 297.4018s / 64386.9497 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4040s / 64686.3537 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 297.6564s / 64984.0100 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8674s / 65282.8774 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 297.9310s / 65580.8084 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6463s / 65881.4546 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.5553s / 66179.0099 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2828s / 66478.2927 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7216s / 66778.0143 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.5650s / 67076.5794 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4209s / 67377.0002 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.0709s / 67675.0711 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1749s / 67976.2460 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5953s / 68275.8413 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7099s / 68576.5512 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8782s / 68877.4294 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.0117s / 69177.4411 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.4282s / 69475.8693 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7898s / 69775.6591 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.9764s / 70075.6356 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9663s / 70377.6018 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8520s / 70676.4538 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2852s / 70977.7390 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 297.7801s / 71275.5191 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2503s / 71574.7694 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3326s / 71874.1020 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.6889s / 72173.7909 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4797s / 72473.2706 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6139s / 72771.8845 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4304s / 73073.3149 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0096
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0404s / 73374.3553 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7802s / 73674.1356 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2256s / 73974.3612 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2810s / 74275.6422 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4708s / 74575.1130 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8379s / 74875.9509 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1279s / 75175.0788 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2981s / 75474.3769 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5748s / 75774.9517 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3414s / 76076.2931 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 303.6770s / 76379.9701 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6244s / 76708.5945 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0892s / 77010.6837 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 304.3855s / 77315.0693 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9745s / 77616.0437 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.9083s / 77915.9520 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9431s / 78217.8951 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2786s / 78518.1737 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7195s / 78819.8932 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5421s / 79119.4354 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5834s / 79452.0188 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 337.8216s / 79789.8404 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 340.8260s / 80130.6664 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 378.5303s / 80509.1966 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 385.8474s / 80895.0440 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1524s / 81283.1964 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.1826s / 81670.3790 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.1403s / 82059.5192 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 385.5517s / 82445.0709 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.4936s / 82831.5645 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3672s / 83220.9317 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 385.6551s / 83606.5868 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9384s / 83994.5252 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6002s / 84384.1254 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 388.8792s / 84773.0045 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 385.9655s / 85158.9700 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1568s / 85547.1268 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 385.8507s / 85932.9775 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.6194s / 86320.5969 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 387.8486s / 86708.4455 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0107
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6579s / 87098.1035 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5757s / 87487.6791 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7114s / 87875.3905 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2973s / 88262.6878 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.2428s / 88651.9306 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.7377s / 89040.6683 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4735s / 89428.1418 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.6494s / 89818.7911 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3486s / 90207.1398 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5284s / 90596.6682 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2971s / 90983.9653 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 391.0263s / 91374.9916 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3360s / 91763.3276 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4964s / 92150.8240 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.8033s / 92537.6273 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8871s / 92927.5144 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.6998s / 93318.2142 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.1117s / 93705.3259 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6547s / 94094.9805 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6702s / 94484.6508 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0439s / 94872.6946 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.8342s / 95263.5288 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 391.3835s / 95654.9123 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.7290s / 96044.6413 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.2504s / 96433.8917 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 393.8734s / 96827.7651 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.7180s / 97218.4831 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9343s / 97606.4173 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.3474s / 97996.7648 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.0196s / 98386.7844 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.2191s / 98775.0034 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.4465s / 99164.4500 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.4941s / 99554.9441 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.9326s / 99945.8767 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2420s / 100336.1187 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0105
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2425s / 100726.3612 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0123s / 101114.3735 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 392.1040s / 101506.4775 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0496s / 101894.5271 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.1467s / 102284.6737 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5490s / 102674.2227 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3099s / 103062.5327 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6622s / 103452.1949 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1427s / 103840.3376 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 383.8925s / 104224.2301 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 391.2517s / 104615.4818 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5628s / 105004.0446 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6680s / 105393.7125 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.1869s / 105783.8994 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9893s / 106171.8887 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 386.6683s / 106558.5570 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 386.2379s / 106944.7949 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.5649s / 107332.3598 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3374s / 107721.6972 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.7078s / 108111.4050 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5054s / 108500.9104 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.0338s / 108890.9442 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.4093s / 109279.3534 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.5201s / 109666.8735 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8659s / 110056.7394 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6316s / 110446.3710 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9875s / 110834.3585 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5870s / 111222.9455 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5481s / 111611.4936 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3751s / 112000.8687 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.1789s / 112390.0476 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5493s / 112778.5969 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5446s / 113167.1415 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9016s / 113555.0431 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 385.6295s / 113940.6725 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 385.7569s / 114326.4294 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2364s / 114713.6658 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7000s / 115101.3658 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2618s / 115488.6277 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.8181s / 115879.4457 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5616s / 116269.0074 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7286s / 116656.7359 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.6193s / 117045.3552 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0562s / 117433.4114 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.8893s / 117820.3006 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 386.3642s / 118206.6648 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2427s / 118596.9075 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 391.8008s / 118988.7083 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 391.2127s / 119379.9210 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5920s / 119769.5129 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4739s / 120156.9869 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.0962s / 120546.0831 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2644s / 120936.3475 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8902s / 121326.2377 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 388.9676s / 121715.2054 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0824s / 122103.2877 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8057s / 122493.0934 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.7422s / 122881.8355 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.1454s / 123271.9809 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 393.4426s / 123665.4235 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.9480s / 124055.3715 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.5280s / 124442.8996 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2090s / 124833.1086 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.1672s / 125222.2759 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.9044s / 125612.1802 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 393.2962s / 126005.4765 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 394.3243s / 126399.8008 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 392.9741s / 126792.7749 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 396.7279s / 127189.5028 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 394.0571s / 127583.5599 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 398.2498s / 127981.8097 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 395.5484s / 128377.3581 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 396.1881s / 128773.5462 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 394.9085s / 129168.4547 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 394.5069s / 129562.9616 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 394.1325s / 129957.0942 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 393.7281s / 130350.8223 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 396.1654s / 130746.9877 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 396.4198s / 131143.4075 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 395.0325s / 131538.4400 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 395.3362s / 131933.7762 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 397.2819s / 132331.0581 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 394.9074s / 132725.9656 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 396.3894s / 133122.3549 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 394.1357s / 133516.4907 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 395.6184s / 133912.1091 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 395.2980s / 134307.4072 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 383.2110s / 134690.6182 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 380.2311s / 135070.8493 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 384.3757s / 135455.2250 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 382.9132s / 135838.1382 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 381.5108s / 136219.6490 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 384.7054s / 136604.3544 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 383.6912s / 136988.0457 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 384.1110s / 137372.1567 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 382.6417s / 137754.7983 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 384.8354s / 138139.6338 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 381.7719s / 138521.4057 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 383.6218s / 138905.0275 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 383.8747s / 139288.9022 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 384.9447s / 139673.8470 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 384.2338s / 140058.0808 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 384.3627s / 140442.4435 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 383.7000s / 140826.1435 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 384.6447s / 141210.7882 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 384.5679s / 141595.3561 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 383.1126s / 141978.4687 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 384.4682s / 142362.9369 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 385.6853s / 142748.6222 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 383.4853s / 143132.1075 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 384.0838s / 143516.1913 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 383.7425s / 143899.9338 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 384.9214s / 144284.8552 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 382.8152s / 144667.6704 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 381.8232s / 145049.4936 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 382.6821s / 145432.1757 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 382.9429s / 145815.1186 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 383.6641s / 146198.7826 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 383.7794s / 146582.5620 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 381.0978s / 146963.6598 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 382.2467s / 147345.9065 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 381.1145s / 147727.0210 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 381.1229s / 148108.1439 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 382.4799s / 148490.6238 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 382.0802s / 148872.7039 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 380.2358s / 149252.9398 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 380.3500s / 149633.2897 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 381.3480s / 150014.6377 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 383.1507s / 150397.7884 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 381.6541s / 150779.4425 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 382.1182s / 151161.5607 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 383.1102s / 151544.6709 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 380.3905s / 151925.0614 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 382.3998s / 152307.4612 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 383.2725s / 152690.7337 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 378.1645s / 153068.8982 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.8502s / 153444.7484 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 373.8233s / 153818.5717 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.5317s / 154194.1034 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9541/50000 (19.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 378.6019s / 154572.7053 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9561/50000 (19.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.2332s / 154947.9385 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9581/50000 (19.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 377.1672s / 155325.1057 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9601/50000 (19.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 374.5873s / 155699.6930 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9621/50000 (19.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.2462s / 156074.9392 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9641/50000 (19.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 375.9048s / 156450.8440 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9661/50000 (19.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5098s / 156827.3538 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9681/50000 (19.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.3542s / 157203.7080 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9701/50000 (19.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 378.1931s / 157581.9010 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9721/50000 (19.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.3852s / 157958.2862 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9741/50000 (19.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6974s / 158334.9837 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9761/50000 (19.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.2129s / 158711.1966 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9781/50000 (19.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 378.0414s / 159089.2380 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9801/50000 (19.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 378.9522s / 159468.1902 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9821/50000 (19.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.3531s / 159845.5433 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9841/50000 (19.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 376.1865s / 160221.7298 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9861/50000 (19.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8064s / 160598.5361 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9881/50000 (19.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6393s / 160975.1755 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9901/50000 (19.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 378.0580s / 161353.2335 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9921/50000 (19.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 374.9001s / 161728.1336 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9941/50000 (19.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 374.9699s / 162103.1035 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9961/50000 (19.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 377.8223s / 162480.9259 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9981/50000 (19.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.7385s / 162857.6644 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10001/50000 (20.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 377.4522s / 163235.1166 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10021/50000 (20.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6218s / 163611.7384 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 10041/50000 (20.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.9329s / 164001.6713 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10061/50000 (20.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.3008s / 164376.9721 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10081/50000 (20.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.9081s / 164753.8802 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 10101/50000 (20.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 377.2854s / 165131.1656 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10121/50000 (20.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.1003s / 165507.2659 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10141/50000 (20.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 376.7754s / 165884.0413 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10161/50000 (20.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 378.6953s / 166262.7366 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10181/50000 (20.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7159s / 166638.4524 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 10201/50000 (20.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 375.5363s / 167013.9887 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10221/50000 (20.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.1264s / 167389.1150 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 10241/50000 (20.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 378.1132s / 167767.2282 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 10261/50000 (20.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 378.2737s / 168145.5019 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10281/50000 (20.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.8036s / 168521.3056 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10301/50000 (20.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 378.6883s / 168899.9939 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10321/50000 (20.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.6299s / 169275.6238 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10341/50000 (20.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 378.1479s / 169653.7717 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10361/50000 (20.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.3011s / 170029.0728 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10381/50000 (20.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.9741s / 170406.0469 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10401/50000 (20.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.2069s / 170782.2538 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 10421/50000 (20.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.6600s / 171159.9138 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10441/50000 (20.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.5679s / 171537.4817 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10461/50000 (20.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5519s / 171914.0336 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10481/50000 (20.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.4901s / 172289.5238 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10501/50000 (21.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 377.4197s / 172666.9435 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10521/50000 (21.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.6871s / 173042.6306 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10541/50000 (21.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.8128s / 173420.4435 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10561/50000 (21.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.4071s / 173796.8505 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 10581/50000 (21.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.4290s / 174172.2795 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10601/50000 (21.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.0209s / 174548.3004 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10621/50000 (21.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.5704s / 174925.8709 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10641/50000 (21.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6842s / 175302.5551 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10661/50000 (21.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7446s / 175678.2997 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0126
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 10681/50000 (21.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 378.0738s / 176056.3735 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10701/50000 (21.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.3105s / 176432.6840 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10721/50000 (21.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.6078s / 176810.2918 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10741/50000 (21.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5154s / 177186.8072 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10761/50000 (21.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 377.8846s / 177564.6917 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 10781/50000 (21.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 377.2957s / 177941.9874 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 10801/50000 (21.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.2856s / 178318.2731 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 10821/50000 (21.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8203s / 178695.0933 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10841/50000 (21.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.2001s / 179072.2934 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10861/50000 (21.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 377.3749s / 179449.6684 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10881/50000 (21.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 377.4790s / 179827.1474 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10901/50000 (21.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8012s / 180203.9485 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10921/50000 (21.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.7438s / 180581.6923 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10941/50000 (21.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.8931s / 180959.5854 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 10961/50000 (21.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 374.1274s / 181333.7128 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10981/50000 (21.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.6781s / 181709.3909 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11001/50000 (22.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8106s / 182086.2015 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11021/50000 (22.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.1771s / 182462.3786 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11041/50000 (22.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 374.9244s / 182837.3030 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11061/50000 (22.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 377.3405s / 183214.6435 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 11081/50000 (22.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.3174s / 183590.9609 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11101/50000 (22.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 375.2207s / 183966.1816 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11121/50000 (22.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8894s / 184343.0710 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11141/50000 (22.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 375.2946s / 184718.3656 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 11161/50000 (22.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.1299s / 185094.4955 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11181/50000 (22.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.8071s / 185471.3026 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11201/50000 (22.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.1741s / 185847.4767 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11221/50000 (22.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.4658s / 186223.9424 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11241/50000 (22.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 375.4951s / 186599.4376 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 11261/50000 (22.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.7619s / 186976.1995 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11281/50000 (22.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.3597s / 187351.5592 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11301/50000 (22.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6129s / 187728.1721 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 11321/50000 (22.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.1320s / 188103.3041 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11341/50000 (22.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 375.8855s / 188479.1897 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 11361/50000 (22.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 377.0361s / 188856.2258 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 11381/50000 (22.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.6054s / 189232.8312 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11401/50000 (22.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 375.5198s / 189608.3510 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 11421/50000 (22.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 374.8714s / 189983.2224 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11441/50000 (22.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 374.8784s / 190358.1008 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11461/50000 (22.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7689s / 190733.8697 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11481/50000 (22.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 373.6172s / 191107.4869 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11501/50000 (23.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 373.5838s / 191481.0707 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11521/50000 (23.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5189s / 191857.5896 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 11541/50000 (23.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.1653s / 192234.7549 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11561/50000 (23.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5739s / 192611.3288 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11581/50000 (23.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 375.0897s / 192986.4185 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11601/50000 (23.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.4908s / 193362.9093 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 11621/50000 (23.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.6627s / 193738.5719 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11641/50000 (23.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.3032s / 194115.8752 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 11661/50000 (23.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 374.4158s / 194490.2910 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11681/50000 (23.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.7801s / 194867.0711 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11701/50000 (23.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 375.8504s / 195242.9214 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11721/50000 (23.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 377.8098s / 195620.7312 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11741/50000 (23.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.2221s / 195997.9533 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11761/50000 (23.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 376.2747s / 196374.2280 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11781/50000 (23.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 377.3825s / 196751.6105 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11801/50000 (23.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 375.1372s / 197126.7477 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11821/50000 (23.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 376.9149s / 197503.6626 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 11841/50000 (23.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7900s / 197879.4525 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 11861/50000 (23.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.5915s / 198255.0441 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11881/50000 (23.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5947s / 198631.6388 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 11901/50000 (23.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 376.5801s / 199008.2189 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0133
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11921/50000 (23.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7398s / 199383.9586 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11941/50000 (23.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 377.0952s / 199761.0538 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11961/50000 (23.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 375.7569s / 200136.8107 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 11981/50000 (23.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 369.6135s / 200506.4242 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 12001/50000 (24.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 367.5836s / 200874.0078 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12021/50000 (24.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 370.5910s / 201244.5988 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12041/50000 (24.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 370.2877s / 201614.8865 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12061/50000 (24.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 369.8601s / 201984.7466 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12081/50000 (24.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 368.6327s / 202353.3793 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12101/50000 (24.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.6773s / 202724.0566 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12121/50000 (24.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 369.4744s / 203093.5310 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12141/50000 (24.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 368.3634s / 203461.8945 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12161/50000 (24.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 369.6775s / 203831.5720 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 12181/50000 (24.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.3435s / 204201.9155 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12201/50000 (24.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.9781s / 204572.8936 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 12221/50000 (24.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 369.5042s / 204942.3978 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12241/50000 (24.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 369.2516s / 205311.6494 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0124
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 12261/50000 (24.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 370.3784s / 205682.0278 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12281/50000 (24.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.3194s / 206052.3472 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12301/50000 (24.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 368.7173s / 206421.0645 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12321/50000 (24.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 370.7981s / 206791.8626 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12341/50000 (24.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.1171s / 207162.9797 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12361/50000 (24.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 369.8885s / 207532.8682 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12381/50000 (24.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.6550s / 207903.5232 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12401/50000 (24.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.6865s / 208274.2097 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12421/50000 (24.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.2004s / 208646.4101 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 12441/50000 (24.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.0608s / 209018.4710 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12461/50000 (24.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.0637s / 209390.5347 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12481/50000 (24.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.3737s / 209761.9084 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12501/50000 (25.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.5735s / 210133.4820 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12521/50000 (25.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 370.3794s / 210503.8613 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12541/50000 (25.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.6375s / 210875.4988 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12561/50000 (25.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.5138s / 211248.0127 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12581/50000 (25.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.3302s / 211618.3428 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12601/50000 (25.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.8274s / 211989.1702 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12621/50000 (25.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4456s / 212360.6157 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12641/50000 (25.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.0584s / 212731.6741 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12661/50000 (25.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.8445s / 213103.5186 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12681/50000 (25.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.2358s / 213473.7544 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12701/50000 (25.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.8276s / 213845.5820 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12721/50000 (25.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 373.0236s / 214218.6057 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 12741/50000 (25.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.0291s / 214589.6348 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12761/50000 (25.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 370.9853s / 214960.6200 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12781/50000 (25.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 370.5626s / 215331.1826 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12801/50000 (25.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.5187s / 215701.7013 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12821/50000 (25.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 370.9036s / 216072.6048 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12841/50000 (25.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7330s / 216444.3378 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12861/50000 (25.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.1426s / 216816.4804 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12881/50000 (25.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 373.5157s / 217189.9961 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12901/50000 (25.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.2864s / 217561.2825 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12921/50000 (25.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 373.6228s / 217934.9053 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12941/50000 (25.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.8850s / 218306.7903 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12961/50000 (25.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 370.7454s / 218677.5358 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 12981/50000 (25.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 372.6246s / 219050.1604 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13001/50000 (26.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9890s / 219422.1494 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13021/50000 (26.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.8727s / 219794.0220 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13041/50000 (26.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 370.8910s / 220164.9131 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13061/50000 (26.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.6449s / 220536.5580 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13081/50000 (26.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 372.5710s / 220909.1290 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 13101/50000 (26.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 372.2332s / 221281.3622 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 13121/50000 (26.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.8175s / 221654.1798 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13141/50000 (26.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.6363s / 222026.8160 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13161/50000 (26.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 373.4357s / 222400.2517 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13181/50000 (26.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9826s / 222772.2344 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13201/50000 (26.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 372.2771s / 223144.5114 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13221/50000 (26.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.6942s / 223516.2057 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13241/50000 (26.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.1388s / 223888.3445 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13261/50000 (26.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 370.7673s / 224259.1117 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13281/50000 (26.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7623s / 224630.8741 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13301/50000 (26.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.8648s / 225002.7388 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13321/50000 (26.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.6379s / 225375.3767 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13341/50000 (26.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 370.4221s / 225745.7987 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13361/50000 (26.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.2727s / 226117.0714 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13381/50000 (26.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4459s / 226488.5174 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13401/50000 (26.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.8688s / 226859.3862 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13421/50000 (26.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.5769s / 227231.9630 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13441/50000 (26.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.8726s / 227604.8357 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0118
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13461/50000 (26.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.4691s / 227977.3048 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 13481/50000 (26.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.6892s / 228348.9940 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13501/50000 (27.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7863s / 228720.7804 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13521/50000 (27.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.2882s / 229092.0685 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 13541/50000 (27.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 373.0760s / 229465.1446 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13561/50000 (27.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.7344s / 229837.8789 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13581/50000 (27.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 372.7583s / 230210.6372 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13601/50000 (27.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.5403s / 230581.1775 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13621/50000 (27.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.3760s / 230953.5535 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 13641/50000 (27.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.1508s / 231324.7044 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 13661/50000 (27.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 373.1732s / 231697.8775 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13681/50000 (27.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.5666s / 232069.4442 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0117
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13701/50000 (27.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 372.4807s / 232441.9249 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13721/50000 (27.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9144s / 232813.8392 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13741/50000 (27.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9270s / 233185.7663 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13761/50000 (27.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 373.5420s / 233559.3082 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13781/50000 (27.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 372.2376s / 233931.5458 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 13801/50000 (27.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4216s / 234302.9674 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13821/50000 (27.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 373.2808s / 234676.2482 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13841/50000 (27.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4805s / 235047.7287 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13861/50000 (27.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7866s / 235419.5153 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13881/50000 (27.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.6921s / 235791.2074 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13901/50000 (27.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.8698s / 236162.0771 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 13921/50000 (27.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.5021s / 236533.5792 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 13941/50000 (27.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 370.6408s / 236904.2201 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13961/50000 (27.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9609s / 237276.1810 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13981/50000 (27.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 369.6251s / 237645.8060 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14001/50000 (28.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 371.9527s / 238017.7587 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14021/50000 (28.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 372.4325s / 238390.1913 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 14041/50000 (28.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.0294s / 238762.2207 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 14061/50000 (28.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 371.3813s / 239133.6020 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0117
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14081/50000 (28.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4516s / 239505.0536 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14101/50000 (28.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.5201s / 239875.5737 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14121/50000 (28.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7344s / 240247.3081 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14141/50000 (28.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 372.1882s / 240619.4963 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 14161/50000 (28.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 372.0411s / 240991.5374 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14181/50000 (28.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 372.8205s / 241364.3579 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 14201/50000 (28.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 370.2686s / 241734.6265 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14221/50000 (28.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 371.4934s / 242106.1199 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 14241/50000 (28.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 371.7500s / 242477.8699 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan