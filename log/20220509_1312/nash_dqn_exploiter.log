pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 111
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fea37eb8050>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10100, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220509131207/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220509131207/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10100 (0.0099%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0414s / 1.0414 s
agent0:                 episode reward: 0.6276,                 loss: nan
agent1:                 episode reward: -0.6276,                 loss: nan
Episode: 11/10100 (0.1089%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0359s / 1.0773 s
agent0:                 episode reward: -0.7757,                 loss: nan
agent1:                 episode reward: 0.7757,                 loss: nan
Episode: 21/10100 (0.2079%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0295s / 1.1069 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: nan
Episode: 31/10100 (0.3069%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0304s / 1.1373 s
agent0:                 episode reward: 0.3738,                 loss: nan
agent1:                 episode reward: -0.3738,                 loss: nan
Episode: 41/10100 (0.4059%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0275s / 1.1648 s
agent0:                 episode reward: 0.1928,                 loss: nan
agent1:                 episode reward: -0.1928,                 loss: nan
Episode: 51/10100 (0.5050%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0339s / 1.1987 s
agent0:                 episode reward: 0.3187,                 loss: nan
agent1:                 episode reward: -0.3187,                 loss: nan
Episode: 61/10100 (0.6040%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0299s / 1.2286 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: nan
Episode: 71/10100 (0.7030%),                 avg. length: 9.0,                last time consumption/overall running time: 28.2707s / 29.4993 s
agent0:                 episode reward: 0.4260,                 loss: 0.3848
agent1:                 episode reward: -0.4260,                 loss: nan
Episode: 81/10100 (0.8020%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3154s / 69.8147 s
agent0:                 episode reward: 0.7979,                 loss: 0.3641
agent1:                 episode reward: -0.7979,                 loss: nan
Episode: 91/10100 (0.9010%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4190s / 110.2337 s
agent0:                 episode reward: -0.0207,                 loss: 0.3576
agent1:                 episode reward: 0.0207,                 loss: nan
Episode: 101/10100 (1.0000%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3098s / 150.5435 s
agent0:                 episode reward: 0.4292,                 loss: 0.3512
agent1:                 episode reward: -0.4292,                 loss: nan
Episode: 111/10100 (1.0990%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3603s / 190.9038 s
agent0:                 episode reward: 0.4837,                 loss: 0.3433
agent1:                 episode reward: -0.4837,                 loss: nan
Episode: 121/10100 (1.1980%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5029s / 231.4067 s
agent0:                 episode reward: 0.2531,                 loss: 0.3425
agent1:                 episode reward: -0.2531,                 loss: nan
Episode: 131/10100 (1.2970%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2662s / 271.6729 s
agent0:                 episode reward: 0.1459,                 loss: 0.3370
agent1:                 episode reward: -0.1459,                 loss: nan
Episode: 141/10100 (1.3960%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1594s / 311.8323 s
agent0:                 episode reward: -0.2530,                 loss: 0.3332
agent1:                 episode reward: 0.2530,                 loss: nan
Episode: 151/10100 (1.4950%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1145s / 351.9468 s
agent0:                 episode reward: -0.0758,                 loss: 0.3292
agent1:                 episode reward: 0.0758,                 loss: nan
Episode: 161/10100 (1.5941%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1090s / 392.0558 s
agent0:                 episode reward: -0.9724,                 loss: 0.3285
agent1:                 episode reward: 0.9724,                 loss: nan
Episode: 171/10100 (1.6931%),                 avg. length: 9.0,                last time consumption/overall running time: 39.9805s / 432.0363 s
agent0:                 episode reward: 0.8961,                 loss: 0.3238
agent1:                 episode reward: -0.8961,                 loss: nan
Episode: 181/10100 (1.7921%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0248s / 472.0611 s
agent0:                 episode reward: -1.1412,                 loss: 0.3206
agent1:                 episode reward: 1.1412,                 loss: nan
Episode: 191/10100 (1.8911%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0393s / 512.1004 s
agent0:                 episode reward: -0.4459,                 loss: 0.3203
agent1:                 episode reward: 0.4459,                 loss: nan
Episode: 201/10100 (1.9901%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1125s / 552.2129 s
agent0:                 episode reward: -0.5557,                 loss: 0.3185
agent1:                 episode reward: 0.5557,                 loss: nan
Episode: 211/10100 (2.0891%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0280s / 592.2409 s
agent0:                 episode reward: 0.2723,                 loss: 0.3177
agent1:                 episode reward: -0.2723,                 loss: nan
Episode: 221/10100 (2.1881%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2695s / 632.5104 s
agent0:                 episode reward: -0.0335,                 loss: 0.3158
agent1:                 episode reward: 0.0335,                 loss: nan
Episode: 231/10100 (2.2871%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0486s / 672.5590 s
agent0:                 episode reward: -0.1890,                 loss: 0.3165
agent1:                 episode reward: 0.1890,                 loss: nan
Episode: 241/10100 (2.3861%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0441s / 712.6032 s
agent0:                 episode reward: 1.2903,                 loss: 0.3164
agent1:                 episode reward: -1.2903,                 loss: nan
Episode: 251/10100 (2.4851%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0242s / 752.6273 s
agent0:                 episode reward: 0.4387,                 loss: 0.3130
agent1:                 episode reward: -0.4387,                 loss: nan
Episode: 261/10100 (2.5842%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1325s / 792.7598 s
agent0:                 episode reward: -0.0072,                 loss: 0.3126
agent1:                 episode reward: 0.0072,                 loss: nan
Episode: 271/10100 (2.6832%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2077s / 832.9675 s
agent0:                 episode reward: 0.1002,                 loss: 0.3142
agent1:                 episode reward: -0.1002,                 loss: nan
Episode: 281/10100 (2.7822%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2420s / 873.2096 s
agent0:                 episode reward: 0.7268,                 loss: 0.3146
agent1:                 episode reward: -0.7268,                 loss: nan
Episode: 291/10100 (2.8812%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2164s / 913.4260 s
agent0:                 episode reward: 0.5001,                 loss: 0.3134
agent1:                 episode reward: -0.5001,                 loss: nan
Episode: 301/10100 (2.9802%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2903s / 953.7163 s
agent0:                 episode reward: -0.2632,                 loss: 0.3109
agent1:                 episode reward: 0.2632,                 loss: nan
Episode: 311/10100 (3.0792%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2697s / 993.9860 s
agent0:                 episode reward: 0.0041,                 loss: 0.3108
agent1:                 episode reward: -0.0041,                 loss: nan
Episode: 321/10100 (3.1782%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2085s / 1034.1945 s
agent0:                 episode reward: 0.0163,                 loss: 0.3119
agent1:                 episode reward: -0.0163,                 loss: nan
Episode: 331/10100 (3.2772%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0970s / 1074.2914 s
agent0:                 episode reward: -0.6449,                 loss: 0.3117
agent1:                 episode reward: 0.6449,                 loss: nan
Episode: 341/10100 (3.3762%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2099s / 1114.5014 s
agent0:                 episode reward: -0.0868,                 loss: 0.3089
agent1:                 episode reward: 0.0868,                 loss: nan
Episode: 351/10100 (3.4752%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1211s / 1154.6225 s
agent0:                 episode reward: 0.0348,                 loss: 0.3113
agent1:                 episode reward: -0.0348,                 loss: nan
Episode: 361/10100 (3.5743%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0910s / 1194.7135 s
agent0:                 episode reward: 0.3584,                 loss: 0.3104
agent1:                 episode reward: -0.3584,                 loss: nan
Episode: 371/10100 (3.6733%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0820s / 1234.7955 s
agent0:                 episode reward: 0.8073,                 loss: 0.3085
agent1:                 episode reward: -0.8073,                 loss: nan
Episode: 381/10100 (3.7723%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0313s / 1274.8268 s
agent0:                 episode reward: 0.8982,                 loss: 0.3087
agent1:                 episode reward: -0.8982,                 loss: nan
Episode: 391/10100 (3.8713%),                 avg. length: 9.0,                last time consumption/overall running time: 39.9557s / 1314.7825 s
agent0:                 episode reward: 0.3203,                 loss: 0.3075
agent1:                 episode reward: -0.3203,                 loss: nan
Episode: 401/10100 (3.9703%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0170s / 1354.7996 s
agent0:                 episode reward: 1.1198,                 loss: 0.3068
agent1:                 episode reward: -1.1198,                 loss: nan
Episode: 411/10100 (4.0693%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0432s / 1394.8427 s
agent0:                 episode reward: -0.5366,                 loss: 0.3055
agent1:                 episode reward: 0.5366,                 loss: nan
Episode: 421/10100 (4.1683%),                 avg. length: 9.0,                last time consumption/overall running time: 39.9833s / 1434.8260 s
agent0:                 episode reward: -0.2945,                 loss: 0.3074
agent1:                 episode reward: 0.2945,                 loss: nan
Episode: 431/10100 (4.2673%),                 avg. length: 9.0,                last time consumption/overall running time: 39.9850s / 1474.8110 s
agent0:                 episode reward: -0.5638,                 loss: 0.3074
agent1:                 episode reward: 0.5638,                 loss: nan
Episode: 441/10100 (4.3663%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1359s / 1514.9469 s
agent0:                 episode reward: 0.6789,                 loss: 0.3104
agent1:                 episode reward: -0.6789,                 loss: nan
Episode: 451/10100 (4.4653%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1477s / 1555.0946 s
agent0:                 episode reward: 0.8979,                 loss: 0.3069
agent1:                 episode reward: -0.8979,                 loss: nan
Episode: 461/10100 (4.5644%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1483s / 1595.2428 s
agent0:                 episode reward: -0.0232,                 loss: 0.3081
agent1:                 episode reward: 0.0232,                 loss: nan
Episode: 471/10100 (4.6634%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1611s / 1635.4039 s
agent0:                 episode reward: -0.6929,                 loss: 0.3079
agent1:                 episode reward: 0.6929,                 loss: nan
Episode: 481/10100 (4.7624%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1638s / 1675.5677 s
agent0:                 episode reward: 0.2009,                 loss: 0.3060
agent1:                 episode reward: -0.2009,                 loss: nan
Episode: 491/10100 (4.8614%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1915s / 1715.7592 s
agent0:                 episode reward: -0.7510,                 loss: 0.3053
agent1:                 episode reward: 0.7510,                 loss: nan
Episode: 501/10100 (4.9604%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2446s / 1756.0038 s
agent0:                 episode reward: -0.3528,                 loss: 0.3036
agent1:                 episode reward: 0.3528,                 loss: nan
Episode: 511/10100 (5.0594%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2925s / 1796.2964 s
agent0:                 episode reward: -0.0507,                 loss: 0.3027
agent1:                 episode reward: 0.0507,                 loss: nan
Episode: 521/10100 (5.1584%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1533s / 1836.4497 s
agent0:                 episode reward: -0.7403,                 loss: 0.3060
agent1:                 episode reward: 0.7403,                 loss: nan
Episode: 531/10100 (5.2574%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1520s / 1876.6016 s
agent0:                 episode reward: -0.2673,                 loss: 0.3031
agent1:                 episode reward: 0.2673,                 loss: nan
Episode: 541/10100 (5.3564%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1774s / 1916.7790 s
agent0:                 episode reward: -0.0632,                 loss: 0.3036
agent1:                 episode reward: 0.0632,                 loss: nan
Episode: 551/10100 (5.4554%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1826s / 1956.9616 s
agent0:                 episode reward: 0.3212,                 loss: 0.3023
agent1:                 episode reward: -0.3212,                 loss: nan
Episode: 561/10100 (5.5545%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2271s / 1997.1888 s
agent0:                 episode reward: -1.2690,                 loss: 0.3060
agent1:                 episode reward: 1.2690,                 loss: nan
Episode: 571/10100 (5.6535%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1905s / 2037.3793 s
agent0:                 episode reward: 0.5008,                 loss: 0.3029
agent1:                 episode reward: -0.5008,                 loss: nan
Episode: 581/10100 (5.7525%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2615s / 2077.6408 s
agent0:                 episode reward: -0.3893,                 loss: 0.3042
agent1:                 episode reward: 0.3893,                 loss: nan
Episode: 591/10100 (5.8515%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2140s / 2117.8548 s
agent0:                 episode reward: -0.3648,                 loss: 0.3038
agent1:                 episode reward: 0.3648,                 loss: nan
Episode: 601/10100 (5.9505%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3089s / 2158.1637 s
agent0:                 episode reward: 0.1554,                 loss: 0.3035
agent1:                 episode reward: -0.1554,                 loss: nan
Episode: 611/10100 (6.0495%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3681s / 2198.5318 s
agent0:                 episode reward: 0.9961,                 loss: 0.3061
agent1:                 episode reward: -0.9961,                 loss: nan
Episode: 621/10100 (6.1485%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2298s / 2238.7616 s
agent0:                 episode reward: 0.0370,                 loss: 0.3036
agent1:                 episode reward: -0.0370,                 loss: nan
Episode: 631/10100 (6.2475%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2200s / 2278.9817 s
agent0:                 episode reward: 0.3245,                 loss: 0.3058
agent1:                 episode reward: -0.3245,                 loss: nan
Episode: 641/10100 (6.3465%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3193s / 2319.3010 s
agent0:                 episode reward: -0.1185,                 loss: 0.3065
agent1:                 episode reward: 0.1185,                 loss: nan
Episode: 651/10100 (6.4455%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2705s / 2359.5715 s
agent0:                 episode reward: -0.7544,                 loss: 0.3067
agent1:                 episode reward: 0.7544,                 loss: nan
Episode: 661/10100 (6.5446%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2508s / 2399.8223 s
agent0:                 episode reward: 0.6333,                 loss: 0.3063
agent1:                 episode reward: -0.6333,                 loss: nan
Episode: 671/10100 (6.6436%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1724s / 2439.9946 s
agent0:                 episode reward: 0.3405,                 loss: 0.3075
agent1:                 episode reward: -0.3405,                 loss: nan
Episode: 681/10100 (6.7426%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1989s / 2480.1936 s
agent0:                 episode reward: 0.5600,                 loss: 0.3069
agent1:                 episode reward: -0.5600,                 loss: nan
Episode: 691/10100 (6.8416%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2178s / 2520.4114 s
agent0:                 episode reward: 1.2148,                 loss: 0.3063
agent1:                 episode reward: -1.2148,                 loss: nan
Episode: 701/10100 (6.9406%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2306s / 2560.6419 s
agent0:                 episode reward: 0.7361,                 loss: 0.3056
agent1:                 episode reward: -0.7361,                 loss: nan
Episode: 711/10100 (7.0396%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2531s / 2600.8951 s
agent0:                 episode reward: -0.9411,                 loss: 0.3070
agent1:                 episode reward: 0.9411,                 loss: nan
Episode: 721/10100 (7.1386%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2151s / 2641.1101 s
agent0:                 episode reward: 0.1316,                 loss: 0.3071
agent1:                 episode reward: -0.1316,                 loss: nan
Episode: 731/10100 (7.2376%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1956s / 2681.3057 s
agent0:                 episode reward: -0.0623,                 loss: 0.3044
agent1:                 episode reward: 0.0623,                 loss: nan
Episode: 741/10100 (7.3366%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2050s / 2721.5107 s
agent0:                 episode reward: 0.4435,                 loss: 0.3041
agent1:                 episode reward: -0.4435,                 loss: nan
Episode: 751/10100 (7.4356%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1909s / 2761.7016 s
agent0:                 episode reward: 0.3207,                 loss: 0.3058
agent1:                 episode reward: -0.3207,                 loss: nan
Episode: 761/10100 (7.5347%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2061s / 2801.9077 s
agent0:                 episode reward: 0.2719,                 loss: 0.3010
agent1:                 episode reward: -0.2719,                 loss: nan
Episode: 771/10100 (7.6337%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2440s / 2842.1516 s
agent0:                 episode reward: -0.8537,                 loss: 0.3059
agent1:                 episode reward: 0.8537,                 loss: nan
Episode: 781/10100 (7.7327%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2348s / 2882.3864 s
agent0:                 episode reward: 0.2802,                 loss: 0.3072
agent1:                 episode reward: -0.2802,                 loss: nan
Episode: 791/10100 (7.8317%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2069s / 2922.5934 s
agent0:                 episode reward: -0.3072,                 loss: 0.3040
agent1:                 episode reward: 0.3072,                 loss: nan
Episode: 801/10100 (7.9307%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2266s / 2962.8199 s
agent0:                 episode reward: 0.6729,                 loss: 0.3048
agent1:                 episode reward: -0.6729,                 loss: nan
Episode: 811/10100 (8.0297%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2600s / 3003.0800 s
agent0:                 episode reward: -0.6382,                 loss: 0.3044
agent1:                 episode reward: 0.6382,                 loss: nan
Episode: 821/10100 (8.1287%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2278s / 3043.3077 s
agent0:                 episode reward: 0.7405,                 loss: 0.3064
agent1:                 episode reward: -0.7405,                 loss: nan
Episode: 831/10100 (8.2277%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2028s / 3083.5105 s
agent0:                 episode reward: -0.8923,                 loss: 0.3024
agent1:                 episode reward: 0.8923,                 loss: nan
Episode: 841/10100 (8.3267%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2271s / 3123.7376 s
agent0:                 episode reward: -0.7420,                 loss: 0.3034
agent1:                 episode reward: 0.7420,                 loss: nan
Episode: 851/10100 (8.4257%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1706s / 3163.9082 s
agent0:                 episode reward: 0.8643,                 loss: 0.3039
agent1:                 episode reward: -0.8643,                 loss: nan
Episode: 861/10100 (8.5248%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2235s / 3204.1318 s
agent0:                 episode reward: -0.7531,                 loss: 0.3059
agent1:                 episode reward: 0.7531,                 loss: nan
Episode: 871/10100 (8.6238%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1991s / 3244.3309 s
agent0:                 episode reward: 1.4096,                 loss: 0.3055
agent1:                 episode reward: -1.4096,                 loss: nan
Episode: 881/10100 (8.7228%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1223s / 3284.4532 s
agent0:                 episode reward: 0.0938,                 loss: 0.3025
agent1:                 episode reward: -0.0938,                 loss: nan
Episode: 891/10100 (8.8218%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1876s / 3324.6408 s
agent0:                 episode reward: -0.4647,                 loss: 0.3024
agent1:                 episode reward: 0.4647,                 loss: nan
Episode: 901/10100 (8.9208%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1968s / 3364.8377 s
agent0:                 episode reward: 0.3653,                 loss: 0.3027
agent1:                 episode reward: -0.3653,                 loss: nan
Episode: 911/10100 (9.0198%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2520s / 3405.0896 s
agent0:                 episode reward: -0.1863,                 loss: 0.3042
agent1:                 episode reward: 0.1863,                 loss: nan
Episode: 921/10100 (9.1188%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1690s / 3445.2587 s
agent0:                 episode reward: 0.3732,                 loss: 0.3040
agent1:                 episode reward: -0.3732,                 loss: nan
Episode: 931/10100 (9.2178%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2143s / 3485.4730 s
agent0:                 episode reward: 0.0987,                 loss: 0.3037
agent1:                 episode reward: -0.0987,                 loss: nan
Episode: 941/10100 (9.3168%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1365s / 3525.6095 s
agent0:                 episode reward: -0.1973,                 loss: 0.3012
agent1:                 episode reward: 0.1973,                 loss: nan
Episode: 951/10100 (9.4158%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1184s / 3565.7279 s
agent0:                 episode reward: 0.0058,                 loss: 0.3050
agent1:                 episode reward: -0.0058,                 loss: nan
Episode: 961/10100 (9.5149%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1586s / 3605.8865 s
agent0:                 episode reward: -0.0872,                 loss: 0.3026
agent1:                 episode reward: 0.0872,                 loss: nan
Episode: 971/10100 (9.6139%),                 avg. length: 9.0,                last time consumption/overall running time: 40.0845s / 3645.9710 s
agent0:                 episode reward: -0.7566,                 loss: 0.3043
agent1:                 episode reward: 0.7566,                 loss: nan
Episode: 981/10100 (9.7129%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1339s / 3686.1049 s
agent0:                 episode reward: 0.2357,                 loss: 0.3038
agent1:                 episode reward: -0.2357,                 loss: nan
Episode: 991/10100 (9.8119%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1367s / 3726.2415 s
agent0:                 episode reward: -0.5008,                 loss: 0.3036
agent1:                 episode reward: 0.5008,                 loss: nan
Episode: 1001/10100 (9.9109%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1749s / 3766.4164 s
agent0:                 episode reward: 0.3211,                 loss: 0.3039
agent1:                 episode reward: -0.3211,                 loss: nan
Episode: 1011/10100 (10.0099%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2625s / 3806.6789 s
agent0:                 episode reward: -0.0090,                 loss: 0.2986
agent1:                 episode reward: 0.0090,                 loss: nan
Episode: 1021/10100 (10.1089%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2746s / 3846.9535 s
agent0:                 episode reward: 0.5737,                 loss: 0.3035
agent1:                 episode reward: -0.5737,                 loss: nan
Episode: 1031/10100 (10.2079%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1783s / 3887.1319 s
agent0:                 episode reward: -0.2578,                 loss: 0.3026
agent1:                 episode reward: 0.2578,                 loss: nan
Episode: 1041/10100 (10.3069%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2320s / 3927.3639 s
agent0:                 episode reward: 0.4517,                 loss: 0.3005
agent1:                 episode reward: -0.4517,                 loss: nan
Episode: 1051/10100 (10.4059%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2272s / 3967.5911 s
agent0:                 episode reward: 0.0568,                 loss: 0.3017
agent1:                 episode reward: -0.0568,                 loss: nan
Episode: 1061/10100 (10.5050%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2140s / 4007.8051 s
agent0:                 episode reward: -0.2400,                 loss: 0.2998
agent1:                 episode reward: 0.2400,                 loss: nan
Episode: 1071/10100 (10.6040%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2275s / 4048.0326 s
agent0:                 episode reward: 1.0330,                 loss: 0.3017
agent1:                 episode reward: -1.0330,                 loss: nan
Episode: 1081/10100 (10.7030%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2759s / 4088.3085 s
agent0:                 episode reward: 0.8488,                 loss: 0.3027
agent1:                 episode reward: -0.8488,                 loss: nan
Episode: 1091/10100 (10.8020%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2110s / 4128.5194 s
agent0:                 episode reward: 0.3975,                 loss: 0.3005
agent1:                 episode reward: -0.3975,                 loss: nan
Episode: 1101/10100 (10.9010%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2551s / 4168.7745 s
agent0:                 episode reward: -0.0344,                 loss: 0.3010
agent1:                 episode reward: 0.0344,                 loss: nan
Episode: 1111/10100 (11.0000%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3852s / 4209.1597 s
agent0:                 episode reward: -0.0528,                 loss: 0.2986
agent1:                 episode reward: 0.0528,                 loss: nan
Episode: 1121/10100 (11.0990%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2362s / 4249.3959 s
agent0:                 episode reward: 0.1237,                 loss: 0.3005
agent1:                 episode reward: -0.1237,                 loss: nan
Episode: 1131/10100 (11.1980%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2438s / 4289.6397 s
agent0:                 episode reward: 0.4805,                 loss: 0.3000
agent1:                 episode reward: -0.4805,                 loss: nan
Episode: 1141/10100 (11.2970%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2712s / 4329.9109 s
agent0:                 episode reward: -0.0383,                 loss: 0.3006
agent1:                 episode reward: 0.0383,                 loss: nan
Episode: 1151/10100 (11.3960%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2206s / 4370.1315 s
agent0:                 episode reward: 0.2109,                 loss: 0.2974
agent1:                 episode reward: -0.2109,                 loss: nan
Episode: 1161/10100 (11.4950%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2386s / 4410.3701 s
agent0:                 episode reward: 0.4347,                 loss: 0.2972
agent1:                 episode reward: -0.4347,                 loss: nan
Episode: 1171/10100 (11.5941%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2094s / 4450.5795 s
agent0:                 episode reward: -0.8008,                 loss: 0.2993
agent1:                 episode reward: 0.8008,                 loss: nan
Episode: 1181/10100 (11.6931%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2667s / 4490.8462 s
agent0:                 episode reward: 0.1091,                 loss: 0.3017
agent1:                 episode reward: -0.1091,                 loss: nan
Episode: 1191/10100 (11.7921%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2148s / 4531.0609 s
agent0:                 episode reward: -0.3207,                 loss: 0.3008
agent1:                 episode reward: 0.3207,                 loss: nan
Episode: 1201/10100 (11.8911%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3828s / 4571.4438 s
agent0:                 episode reward: 0.3732,                 loss: 0.3010
agent1:                 episode reward: -0.3732,                 loss: nan
Episode: 1211/10100 (11.9901%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3341s / 4611.7779 s
agent0:                 episode reward: -0.4926,                 loss: 0.2995
agent1:                 episode reward: 0.4926,                 loss: nan
Episode: 1221/10100 (12.0891%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2379s / 4652.0158 s
agent0:                 episode reward: -0.3183,                 loss: 0.3018
agent1:                 episode reward: 0.3183,                 loss: nan
Episode: 1231/10100 (12.1881%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1886s / 4692.2045 s
agent0:                 episode reward: 0.3190,                 loss: 0.2994
agent1:                 episode reward: -0.3190,                 loss: nan
Episode: 1241/10100 (12.2871%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2825s / 4732.4870 s
agent0:                 episode reward: -0.0513,                 loss: 0.3002
agent1:                 episode reward: 0.0513,                 loss: nan
Episode: 1251/10100 (12.3861%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1633s / 4772.6503 s
agent0:                 episode reward: -1.2911,                 loss: 0.3009
agent1:                 episode reward: 1.2911,                 loss: nan
Episode: 1261/10100 (12.4851%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2683s / 4812.9186 s
agent0:                 episode reward: -0.8973,                 loss: 0.2996
agent1:                 episode reward: 0.8973,                 loss: nan
Episode: 1271/10100 (12.5842%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2772s / 4853.1958 s
agent0:                 episode reward: 0.0660,                 loss: 0.3013
agent1:                 episode reward: -0.0660,                 loss: nan
Episode: 1281/10100 (12.6832%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3688s / 4893.5646 s
agent0:                 episode reward: -0.3571,                 loss: 0.3013
agent1:                 episode reward: 0.3571,                 loss: nan
Episode: 1291/10100 (12.7822%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3120s / 4933.8767 s
agent0:                 episode reward: -0.0239,                 loss: 0.3006
agent1:                 episode reward: 0.0239,                 loss: nan
Episode: 1301/10100 (12.8812%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3304s / 4974.2071 s
agent0:                 episode reward: 0.0680,                 loss: 0.2997
agent1:                 episode reward: -0.0680,                 loss: nan
Episode: 1311/10100 (12.9802%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3072s / 5014.5142 s
agent0:                 episode reward: 0.4285,                 loss: 0.3018
agent1:                 episode reward: -0.4285,                 loss: nan
Episode: 1321/10100 (13.0792%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4733s / 5054.9875 s
agent0:                 episode reward: 0.1038,                 loss: 0.3022
agent1:                 episode reward: -0.1038,                 loss: nan
Episode: 1331/10100 (13.1782%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3738s / 5095.3613 s
agent0:                 episode reward: -0.6078,                 loss: 0.3014
agent1:                 episode reward: 0.6078,                 loss: nan
Episode: 1341/10100 (13.2772%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4342s / 5135.7955 s
agent0:                 episode reward: -0.5060,                 loss: 0.3012
agent1:                 episode reward: 0.5060,                 loss: nan
Episode: 1351/10100 (13.3762%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3158s / 5176.1113 s
agent0:                 episode reward: 0.6772,                 loss: 0.2992
agent1:                 episode reward: -0.6772,                 loss: nan
Episode: 1361/10100 (13.4752%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3508s / 5216.4621 s
agent0:                 episode reward: 0.3482,                 loss: 0.2992
agent1:                 episode reward: -0.3482,                 loss: nan
Episode: 1371/10100 (13.5743%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2568s / 5256.7189 s
agent0:                 episode reward: -0.5338,                 loss: 0.3006
agent1:                 episode reward: 0.5338,                 loss: nan
Episode: 1381/10100 (13.6733%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2871s / 5297.0060 s
agent0:                 episode reward: -0.4391,                 loss: 0.3009
agent1:                 episode reward: 0.4391,                 loss: nan
Episode: 1391/10100 (13.7723%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2721s / 5337.2781 s
agent0:                 episode reward: 0.3097,                 loss: 0.2991
agent1:                 episode reward: -0.3097,                 loss: nan
Episode: 1401/10100 (13.8713%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2507s / 5377.5288 s
agent0:                 episode reward: -0.1028,                 loss: 0.3023
agent1:                 episode reward: 0.1028,                 loss: nan
Episode: 1411/10100 (13.9703%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1996s / 5417.7285 s
agent0:                 episode reward: 1.1591,                 loss: 0.2986
agent1:                 episode reward: -1.1591,                 loss: nan
Episode: 1421/10100 (14.0693%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3432s / 5458.0717 s
agent0:                 episode reward: -0.9403,                 loss: 0.3008
agent1:                 episode reward: 0.9403,                 loss: nan
Episode: 1431/10100 (14.1683%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1487s / 5498.2204 s
agent0:                 episode reward: -0.4123,                 loss: 0.3027
agent1:                 episode reward: 0.4123,                 loss: nan
Episode: 1441/10100 (14.2673%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1852s / 5538.4056 s
agent0:                 episode reward: 0.7137,                 loss: 0.2981
agent1:                 episode reward: -0.7137,                 loss: nan
Episode: 1451/10100 (14.3663%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1598s / 5578.5654 s
agent0:                 episode reward: -0.1731,                 loss: 0.3002
agent1:                 episode reward: 0.1731,                 loss: nan
Episode: 1461/10100 (14.4653%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2222s / 5618.7877 s
agent0:                 episode reward: -0.0846,                 loss: 0.2992
agent1:                 episode reward: 0.0846,                 loss: nan
Episode: 1471/10100 (14.5644%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2368s / 5659.0245 s
agent0:                 episode reward: -0.7714,                 loss: 0.3027
agent1:                 episode reward: 0.7714,                 loss: nan
Episode: 1481/10100 (14.6634%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4248s / 5699.4493 s
agent0:                 episode reward: -0.4947,                 loss: 0.2987
agent1:                 episode reward: 0.4947,                 loss: nan
Episode: 1491/10100 (14.7624%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2406s / 5739.6899 s
agent0:                 episode reward: 0.1474,                 loss: 0.3007
agent1:                 episode reward: -0.1474,                 loss: nan
Episode: 1501/10100 (14.8614%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2745s / 5779.9644 s
agent0:                 episode reward: -0.3778,                 loss: 0.3005
agent1:                 episode reward: 0.3778,                 loss: nan
Episode: 1511/10100 (14.9604%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1852s / 5820.1495 s
agent0:                 episode reward: -0.5430,                 loss: 0.3014
agent1:                 episode reward: 0.5430,                 loss: nan
Episode: 1521/10100 (15.0594%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4001s / 5860.5496 s
agent0:                 episode reward: -0.2435,                 loss: 0.3001
agent1:                 episode reward: 0.2435,                 loss: nan
Episode: 1531/10100 (15.1584%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2558s / 5900.8054 s
agent0:                 episode reward: 0.2094,                 loss: 0.3016
agent1:                 episode reward: -0.2094,                 loss: nan
Episode: 1541/10100 (15.2574%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2891s / 5941.0945 s
agent0:                 episode reward: -0.5311,                 loss: 0.2994
agent1:                 episode reward: 0.5311,                 loss: nan
Episode: 1551/10100 (15.3564%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2715s / 5981.3660 s
agent0:                 episode reward: 0.1761,                 loss: 0.2994
agent1:                 episode reward: -0.1761,                 loss: nan
Episode: 1561/10100 (15.4554%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3302s / 6021.6962 s
agent0:                 episode reward: 0.0692,                 loss: 0.2989
agent1:                 episode reward: -0.0692,                 loss: nan
Episode: 1571/10100 (15.5545%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1957s / 6061.8919 s
agent0:                 episode reward: 0.0803,                 loss: 0.3007
agent1:                 episode reward: -0.0803,                 loss: nan
Episode: 1581/10100 (15.6535%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3159s / 6102.2078 s
agent0:                 episode reward: -0.6529,                 loss: 0.2985
agent1:                 episode reward: 0.6529,                 loss: nan
Episode: 1591/10100 (15.7525%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2661s / 6142.4739 s
agent0:                 episode reward: 0.0974,                 loss: 0.2971
agent1:                 episode reward: -0.0974,                 loss: nan
Episode: 1601/10100 (15.8515%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2980s / 6182.7719 s
agent0:                 episode reward: -0.2775,                 loss: 0.2993
agent1:                 episode reward: 0.2775,                 loss: nan
Episode: 1611/10100 (15.9505%),                 avg. length: 9.0,                last time consumption/overall running time: 40.1981s / 6222.9699 s
agent0:                 episode reward: 0.6200,                 loss: 0.2984
agent1:                 episode reward: -0.6200,                 loss: nan
Episode: 1621/10100 (16.0495%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2991s / 6263.2691 s
agent0:                 episode reward: -0.2902,                 loss: 0.2996
agent1:                 episode reward: 0.2902,                 loss: nan
Episode: 1631/10100 (16.1485%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2246s / 6303.4936 s
agent0:                 episode reward: -1.0673,                 loss: 0.2982
agent1:                 episode reward: 1.0673,                 loss: nan
Episode: 1641/10100 (16.2475%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2375s / 6343.7312 s
agent0:                 episode reward: 0.3272,                 loss: 0.2982
agent1:                 episode reward: -0.3272,                 loss: nan
Episode: 1651/10100 (16.3465%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2379s / 6383.9691 s
agent0:                 episode reward: 0.2270,                 loss: 0.2981
agent1:                 episode reward: -0.2270,                 loss: nan
Episode: 1661/10100 (16.4455%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2491s / 6424.2182 s
agent0:                 episode reward: -0.2001,                 loss: 0.2984
agent1:                 episode reward: 0.2001,                 loss: nan
Episode: 1671/10100 (16.5446%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2357s / 6464.4539 s
agent0:                 episode reward: 0.0625,                 loss: 0.2970
agent1:                 episode reward: -0.0625,                 loss: nan
Episode: 1681/10100 (16.6436%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2886s / 6504.7425 s
agent0:                 episode reward: -0.5883,                 loss: 0.2967
agent1:                 episode reward: 0.5883,                 loss: nan
Episode: 1691/10100 (16.7426%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2552s / 6544.9978 s
agent0:                 episode reward: -0.6038,                 loss: 0.2942
agent1:                 episode reward: 0.6038,                 loss: nan
Episode: 1701/10100 (16.8416%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2946s / 6585.2924 s
agent0:                 episode reward: -0.1805,                 loss: 0.2974
agent1:                 episode reward: 0.1805,                 loss: nan
Episode: 1711/10100 (16.9406%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3224s / 6625.6148 s
agent0:                 episode reward: -0.4410,                 loss: 0.2973
agent1:                 episode reward: 0.4410,                 loss: nan
Episode: 1721/10100 (17.0396%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3504s / 6665.9651 s
agent0:                 episode reward: 0.3443,                 loss: 0.2976
agent1:                 episode reward: -0.3443,                 loss: nan
Episode: 1731/10100 (17.1386%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3408s / 6706.3059 s
agent0:                 episode reward: 0.3064,                 loss: 0.2932
agent1:                 episode reward: -0.3064,                 loss: nan
Episode: 1741/10100 (17.2376%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3270s / 6746.6329 s
agent0:                 episode reward: -0.0506,                 loss: 0.2955
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 1751/10100 (17.3366%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3309s / 6786.9638 s
agent0:                 episode reward: -0.6726,                 loss: 0.2967
agent1:                 episode reward: 0.6726,                 loss: nan
Episode: 1761/10100 (17.4356%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2663s / 6827.2301 s
agent0:                 episode reward: 0.6756,                 loss: 0.2977
agent1:                 episode reward: -0.6756,                 loss: nan
Episode: 1771/10100 (17.5347%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3115s / 6867.5416 s
agent0:                 episode reward: 0.1788,                 loss: 0.2950
agent1:                 episode reward: -0.1788,                 loss: nan
Episode: 1781/10100 (17.6337%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3120s / 6907.8536 s
agent0:                 episode reward: 0.1736,                 loss: 0.2947
agent1:                 episode reward: -0.1736,                 loss: nan
Episode: 1791/10100 (17.7327%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2951s / 6948.1487 s
agent0:                 episode reward: 0.0842,                 loss: 0.2957
agent1:                 episode reward: -0.0842,                 loss: nan
Episode: 1801/10100 (17.8317%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2959s / 6988.4446 s
agent0:                 episode reward: -0.1141,                 loss: 0.2983
agent1:                 episode reward: 0.1141,                 loss: nan
Episode: 1811/10100 (17.9307%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2876s / 7028.7322 s
agent0:                 episode reward: 0.3995,                 loss: 0.2976
agent1:                 episode reward: -0.3995,                 loss: nan
Episode: 1821/10100 (18.0297%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2795s / 7069.0118 s
agent0:                 episode reward: 0.1638,                 loss: 0.2973
agent1:                 episode reward: -0.1638,                 loss: nan
Episode: 1831/10100 (18.1287%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4179s / 7109.4297 s
agent0:                 episode reward: -0.3836,                 loss: 0.2973
agent1:                 episode reward: 0.3836,                 loss: nan
Episode: 1841/10100 (18.2277%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3051s / 7149.7348 s
agent0:                 episode reward: 1.0023,                 loss: 0.2955
agent1:                 episode reward: -1.0023,                 loss: nan
Episode: 1851/10100 (18.3267%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2166s / 7189.9513 s
agent0:                 episode reward: 0.2038,                 loss: 0.2957
agent1:                 episode reward: -0.2038,                 loss: nan
Episode: 1861/10100 (18.4257%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3919s / 7230.3432 s
agent0:                 episode reward: -1.0363,                 loss: 0.2951
agent1:                 episode reward: 1.0363,                 loss: nan
Episode: 1871/10100 (18.5248%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3228s / 7270.6660 s
agent0:                 episode reward: -0.6163,                 loss: 0.2959
agent1:                 episode reward: 0.6163,                 loss: nan
Episode: 1881/10100 (18.6238%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3025s / 7310.9686 s
agent0:                 episode reward: -0.6425,                 loss: 0.2944
agent1:                 episode reward: 0.6425,                 loss: nan
Episode: 1891/10100 (18.7228%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2729s / 7351.2415 s
agent0:                 episode reward: 0.2689,                 loss: 0.2955
agent1:                 episode reward: -0.2689,                 loss: nan
Episode: 1901/10100 (18.8218%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3132s / 7391.5547 s
agent0:                 episode reward: -0.2215,                 loss: 0.2972
agent1:                 episode reward: 0.2215,                 loss: nan
Episode: 1911/10100 (18.9208%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2657s / 7431.8203 s
agent0:                 episode reward: 2.1803,                 loss: 0.2945
agent1:                 episode reward: -2.1803,                 loss: nan
Episode: 1921/10100 (19.0198%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3477s / 7472.1681 s
agent0:                 episode reward: -0.6310,                 loss: 0.2940
agent1:                 episode reward: 0.6310,                 loss: nan
Episode: 1931/10100 (19.1188%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4271s / 7512.5951 s
agent0:                 episode reward: 1.2639,                 loss: 0.2925
agent1:                 episode reward: -1.2639,                 loss: nan
Episode: 1941/10100 (19.2178%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3008s / 7552.8959 s
agent0:                 episode reward: 0.5195,                 loss: 0.2943
agent1:                 episode reward: -0.5195,                 loss: nan
Episode: 1951/10100 (19.3168%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2586s / 7593.1545 s
agent0:                 episode reward: -0.5586,                 loss: 0.2940
agent1:                 episode reward: 0.5586,                 loss: nan
Episode: 1961/10100 (19.4158%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2649s / 7633.4195 s
agent0:                 episode reward: 0.2230,                 loss: 0.2945
agent1:                 episode reward: -0.2230,                 loss: nan
Episode: 1971/10100 (19.5149%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2586s / 7673.6781 s
agent0:                 episode reward: -0.9024,                 loss: 0.2960
agent1:                 episode reward: 0.9024,                 loss: nan
Episode: 1981/10100 (19.6139%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3121s / 7713.9902 s
agent0:                 episode reward: -1.2971,                 loss: 0.2955
agent1:                 episode reward: 1.2971,                 loss: nan
Episode: 1991/10100 (19.7129%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3025s / 7754.2927 s
agent0:                 episode reward: 0.4784,                 loss: 0.2943
agent1:                 episode reward: -0.4784,                 loss: nan
Episode: 2001/10100 (19.8119%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2853s / 7794.5779 s
agent0:                 episode reward: 0.3566,                 loss: 0.2971
agent1:                 episode reward: -0.3566,                 loss: nan
Episode: 2011/10100 (19.9109%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3176s / 7834.8955 s
agent0:                 episode reward: 0.4364,                 loss: 0.2952
agent1:                 episode reward: -0.4364,                 loss: nan
Episode: 2021/10100 (20.0099%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3961s / 7875.2916 s
agent0:                 episode reward: -0.0185,                 loss: 0.2949
agent1:                 episode reward: 0.0185,                 loss: nan
Episode: 2031/10100 (20.1089%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5283s / 7915.8199 s
agent0:                 episode reward: -0.0388,                 loss: 0.2927
agent1:                 episode reward: 0.0388,                 loss: nan
Episode: 2041/10100 (20.2079%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4583s / 7956.2782 s
agent0:                 episode reward: -0.4839,                 loss: 0.2959
agent1:                 episode reward: 0.4839,                 loss: nan
Episode: 2051/10100 (20.3069%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2488s / 7996.5270 s
agent0:                 episode reward: -0.8767,                 loss: 0.2939
agent1:                 episode reward: 0.8767,                 loss: nan
Episode: 2061/10100 (20.4059%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2544s / 8036.7814 s
agent0:                 episode reward: 0.9280,                 loss: 0.2945
agent1:                 episode reward: -0.9280,                 loss: nan
Episode: 2071/10100 (20.5050%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2564s / 8077.0378 s
agent0:                 episode reward: 0.0096,                 loss: 0.2941
agent1:                 episode reward: -0.0096,                 loss: nan
Episode: 2081/10100 (20.6040%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2992s / 8117.3370 s
agent0:                 episode reward: 0.5222,                 loss: 0.2946
agent1:                 episode reward: -0.5222,                 loss: nan
Episode: 2091/10100 (20.7030%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2455s / 8157.5825 s
agent0:                 episode reward: 0.2759,                 loss: 0.2934
agent1:                 episode reward: -0.2759,                 loss: nan
Episode: 2101/10100 (20.8020%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3252s / 8197.9077 s
agent0:                 episode reward: 0.2276,                 loss: 0.2953
agent1:                 episode reward: -0.2276,                 loss: nan
Episode: 2111/10100 (20.9010%),                 avg. length: 9.0,                last time consumption/overall running time: 40.2774s / 8238.1851 s
agent0:                 episode reward: 0.9357,                 loss: 0.2931
agent1:                 episode reward: -0.9357,                 loss: nan
Episode: 2121/10100 (21.0000%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3061s / 8278.4912 s
agent0:                 episode reward: 1.0357,                 loss: 0.2943
agent1:                 episode reward: -1.0357,                 loss: nan