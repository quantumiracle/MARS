pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 288
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f5952058550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220429_0152/pettingzoo_tennis_v2_nfsp/8000_0
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220429_0152/pettingzoo_tennis_v2_nfsp/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152_exploit_first_2/pettingzoo_tennis_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152_exploit_first_2/pettingzoo_tennis_v2_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 7.6882s / 7.6882 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 22.3315s / 30.0197 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 48.8855s / 78.9053 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.1285
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.3466s / 170.2518 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0300
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.9955s / 262.2474 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0266
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.4033s / 354.6507 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0250
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.9920s / 447.6427 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0239
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.1729s / 540.8156 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0223
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.5576s / 634.3731 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0212
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.0763s / 728.4494 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0200
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.4306s / 822.8800 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0191
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.7990s / 917.6791 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0184
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.4324s / 1013.1115 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0174
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.8898s / 1109.0013 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0166
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.4379s / 1205.4392 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0158
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.3742s / 1301.8135 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0151
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.8758s / 1398.6892 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0143
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5349s / 1496.2241 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0138
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6027s / 1593.8268 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0137
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0597s / 1691.8865 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0136
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7104s / 1790.5968 s
first_0:                 episode reward: -2.6000,                 loss: nan
second_0:                 episode reward: 2.6000,                 loss: 0.0138
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6913s / 1888.2882 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0135
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0979s / 1986.3861 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0135
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9904s / 2084.3765 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0135
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8783s / 2182.2548 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0131
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4890s / 2280.7437 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0132
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.5926s / 2379.3364 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0135
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6474s / 2477.9838 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0131
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1540s / 2577.1378 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0131
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5166s / 2676.6544 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0128
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8655s / 2776.5199 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0135
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4293s / 2875.9492 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0129
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5484s / 2975.4976 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0128
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7312s / 3075.2288 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0126
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7060s / 3174.9348 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0125
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7991s / 3274.7339 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0126
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5384s / 3375.2724 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0129
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9753s / 3475.2477 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0123
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9091s / 3575.1568 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0126
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0465s / 3674.2033 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0129
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9720s / 3773.1753 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0127
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5735s / 3872.7489 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0124
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7597s / 3972.5085 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0121
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4028s / 4071.9113 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0124
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7470s / 4171.6584 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0127
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7952s / 4272.4535 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0121
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5335s / 4372.9870 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0120
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0903s / 4474.0773 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0124
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8932s / 4574.9705 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0125
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.6026s / 4676.5732 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0112
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9423s / 4777.5155 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0110
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9493s / 4878.4648 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0113
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1163s / 4979.5811 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0110
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0856s / 5080.6666 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0108
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2819s / 5180.9485 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0110
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2209s / 5281.1694 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0107
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1258s / 5381.2953 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0109
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0915s / 5481.3868 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0105
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4067s / 5581.7935 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0112
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8686s / 5681.6621 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0107
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1397s / 5781.8018 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0106
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7457s / 5882.5475 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0103
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6537s / 5983.2012 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0099
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6856s / 6083.8868 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0097
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8559s / 6184.7427 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0097
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2340s / 6284.9767 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0096
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5430s / 6385.5197 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0091
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8621s / 6486.3818 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0085
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3784s / 6586.7602 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0083
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2743s / 6687.0345 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0083
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4119s / 6787.4464 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0079
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3045s / 6887.7509 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0076
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2661s / 6988.0170 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0076
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4068s / 7088.4238 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0077
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8364s / 7188.2602 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0078
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9551s / 7288.2153 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0079
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4479s / 7388.6631 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0080
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5678s / 7489.2309 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0085
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5745s / 7589.8054 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0089
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7665s / 7690.5719 s
first_0:                 episode reward: -2.7000,                 loss: nan
second_0:                 episode reward: 2.7000,                 loss: 0.0090
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2658s / 7791.8376 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0091
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5933s / 7892.4309 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0094
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7722s / 7993.2031 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0096
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4408s / 8093.6439 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0098
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7055s / 8194.3494 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0096
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0840s / 8294.4334 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0098
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5445s / 8394.9779 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0102
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0503s / 8495.0282 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0098
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0547s / 8595.0829 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0096
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7393s / 8694.8222 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0096
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6727s / 8794.4950 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0100
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4078s / 8894.9027 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0098
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2570s / 8995.1597 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0100
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3118s / 9095.4714 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0101
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9593s / 9195.4307 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0099
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4526s / 9295.8833 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0099
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0900s / 9396.9733 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0097
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4798s / 9497.4530 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0101
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9430s / 9598.3960 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0095
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1289s / 9698.5249 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0094
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8485s / 9799.3734 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0091
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3782s / 9899.7516 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0088
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0005s / 10000.7521 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0090
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5741s / 10101.3263 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0089
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1213s / 10201.4475 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0086
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0737s / 10301.5212 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0083
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4609s / 10401.9821 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0081
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4953s / 10502.4774 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0082
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4418s / 10602.9192 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0080
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1061s / 10704.0253 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0083
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6559s / 10804.6812 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0078
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9587s / 10904.6398 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0081
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3297s / 11004.9695 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0075
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7648s / 11105.7343 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0076
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9573s / 11206.6915 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0076
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9384s / 11307.6300 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0077
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4720s / 11408.1020 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0075
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3984s / 11508.5005 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0073
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8355s / 11609.3360 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0071
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4199s / 11709.7558 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0069
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9728s / 11809.7287 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0068
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6355s / 11910.3642 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0067
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3881s / 12010.7523 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0069
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1882s / 12110.9405 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0069
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0456s / 12210.9861 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0070
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2207s / 12311.2068 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0071
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4241s / 12411.6309 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0075
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1578s / 12511.7887 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0075
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8921s / 12612.6808 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0077
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6557s / 12713.3365 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0080
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0886s / 12814.4250 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0084
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1104s / 12915.5354 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0086
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2479s / 13016.7833 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0089
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0687s / 13117.8520 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0088
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8714s / 13218.7234 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0091
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.4802s / 13320.2036 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0093
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7236s / 13420.9272 s
first_0:                 episode reward: -3.2500,                 loss: nan
second_0:                 episode reward: 3.2500,                 loss: 0.0097
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4624s / 13521.3896 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0097
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9506s / 13621.3402 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0098
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4880s / 13721.8281 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0100
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7909s / 13822.6191 s
first_0:                 episode reward: -2.5500,                 loss: nan
second_0:                 episode reward: 2.5500,                 loss: 0.0100
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4255s / 13923.0446 s
first_0:                 episode reward: -2.4500,                 loss: nan
second_0:                 episode reward: 2.4500,                 loss: 0.0104
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6466s / 14023.6911 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0104
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3222s / 14124.0133 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0103
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3522s / 14224.3656 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0106
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0550s / 14324.4205 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0109
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2443s / 14424.6648 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0112
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3230s / 14524.9878 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0113
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6420s / 14625.6298 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0113
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7729s / 14726.4028 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0117
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3789s / 14826.7816 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0116
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8808s / 14927.6625 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0117
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5586s / 15028.2210 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0120
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0605s / 15129.2815 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0120
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7561s / 15230.0376 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0120
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5966s / 15330.6342 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0122
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6800s / 15431.3142 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0122
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7362s / 15532.0504 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0125
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6939s / 15632.7443 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0124
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6595s / 15733.4038 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0123
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8012s / 15834.2049 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0126
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7486s / 15934.9536 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0128
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3993s / 16035.3529 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0130
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3729s / 16135.7258 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0129
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4090s / 16236.1348 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0128
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7039s / 16336.8387 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0130
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3540s / 16438.1927 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0135
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1323s / 16539.3250 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0143
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2128s / 16639.5378 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0140
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5576s / 16740.0954 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0137
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5515s / 16840.6469 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0137
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8405s / 16941.4874 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0134
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7665s / 17042.2539 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0129
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7414s / 17142.9952 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0128
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2896s / 17243.2848 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0124
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2671s / 17343.5519 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0123
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8399s / 17444.3919 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0119
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6066s / 17544.9985 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0117
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0739s / 17646.0724 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0113
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8145s / 17746.8868 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0110
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6081s / 17847.4950 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0109
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9475s / 17948.4425 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0110
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2847s / 18048.7272 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0108
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4848s / 18149.2120 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0109
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4720s / 18249.6839 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0106
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0748s / 18350.7587 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0110
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.4175s / 18452.1762 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0112
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2672s / 18553.4434 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0118
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0159s / 18654.4593 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0120
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7283s / 18755.1877 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0119
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2790s / 18856.4667 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0119
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.6913s / 18958.1580 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0121
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.4766s / 19059.6346 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0123
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0293s / 19160.6639 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0121
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3246s / 19261.9885 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0122
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1583s / 19363.1468 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0125
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8541s / 19464.0009 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0125
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9951s / 19564.9960 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0126
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7773s / 19665.7733 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0129
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1576s / 19766.9309 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0132
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3102s / 19867.2411 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0139
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8611s / 19968.1022 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0135
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5019s / 20068.6041 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0129
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5457s / 20169.1498 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0126
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6383s / 20269.7881 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0123
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0734s / 20370.8615 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0120
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1681s / 20472.0296 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0122
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1359s / 20573.1655 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0120
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2404s / 20674.4059 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0118
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.4517s / 20775.8576 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0116
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9419s / 20876.7995 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0115
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3858s / 20978.1853 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0117
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8750s / 21079.0603 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0116
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6229s / 21179.6832 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0116
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7982s / 21280.4813 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0115
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0706s / 21381.5519 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0116
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5878s / 21482.1397 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0122
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7072s / 21582.8469 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0119
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1633s / 21684.0103 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0118
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3366s / 21785.3468 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0116
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.4056s / 21886.7524 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0111
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3153s / 21988.0676 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0111
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.5001s / 22089.5678 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0108
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0051s / 22190.5729 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0104
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8863s / 22291.4592 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0102
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0094s / 22392.4686 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0100
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7413s / 22493.2099 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0101
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6024s / 22593.8122 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0101
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9397s / 22694.7520 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0103
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0071s / 22795.7590 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0105
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2500s / 22897.0090 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0104
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3514s / 22998.3605 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0103
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.2595s / 23099.6200 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0103
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1383s / 23200.7583 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0104
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.3054s / 23302.0637 s