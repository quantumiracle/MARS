pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220128_0331/pettingzoo_surround_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220128_0331/pettingzoo_surround_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1776.0,                last time consumption/overall running time: 21.1616s / 21.1616 s
env0_first_0:                 episode reward: -2.0000,                 loss: -0.0200
env0_second_0:                 episode reward: 2.0000,                 loss: -0.0270
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1595.25,                last time consumption/overall running time: 362.7793s / 383.9409 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0400
env0_second_0:                 episode reward: -0.5000,                 loss: -0.0407
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2224.5,                last time consumption/overall running time: 497.9442s / 881.8851 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0313
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0282
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2031.05,                last time consumption/overall running time: 455.7686s / 1337.6537 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.0235
env0_second_0:                 episode reward: 1.3500,                 loss: -0.0218
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2267.85,                last time consumption/overall running time: 505.3976s / 1843.0513 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0323
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0294
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2270.3,                last time consumption/overall running time: 508.0340s / 2351.0853 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0382
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0330
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2260.85,                last time consumption/overall running time: 507.7510s / 2858.8364 s
env0_first_0:                 episode reward: -2.2000,                 loss: -0.0442
env0_second_0:                 episode reward: 2.2000,                 loss: -0.0396
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2293.55,                last time consumption/overall running time: 515.1375s / 3373.9739 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0361
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0320
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2478.35,                last time consumption/overall running time: 555.8093s / 3929.7832 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.0560
env0_second_0:                 episode reward: 1.2500,                 loss: -0.0558
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2478.05,                last time consumption/overall running time: 555.2289s / 4485.0121 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0704
env0_second_0:                 episode reward: 0.9000,                 loss: -0.0712
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2443.4,                last time consumption/overall running time: 548.1654s / 5033.1775 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0611
env0_second_0:                 episode reward: -0.8000,                 loss: -0.0594
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2311.8,                last time consumption/overall running time: 516.4802s / 5549.6578 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0618
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0531
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 2435.5,                last time consumption/overall running time: 544.3415s / 6093.9993 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0682
env0_second_0:                 episode reward: 1.1500,                 loss: -0.0593
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2400.95,                last time consumption/overall running time: 536.7654s / 6630.7647 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0657
env0_second_0:                 episode reward: -0.4000,                 loss: -0.0561
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 2471.55,                last time consumption/overall running time: 553.0607s / 7183.8254 s
env0_first_0:                 episode reward: 2.2500,                 loss: -0.0716
env0_second_0:                 episode reward: -2.2500,                 loss: -0.0564
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2449.25,                last time consumption/overall running time: 546.4615s / 7730.2869 s
env0_first_0:                 episode reward: 3.6500,                 loss: -0.0549
env0_second_0:                 episode reward: -3.6500,                 loss: -0.0212
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2332.15,                last time consumption/overall running time: 522.0289s / 8252.3158 s
env0_first_0:                 episode reward: 4.1500,                 loss: -0.0727
env0_second_0:                 episode reward: -4.1500,                 loss: -0.0038
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 2350.35,                last time consumption/overall running time: 524.8628s / 8777.1786 s
env0_first_0:                 episode reward: 3.9000,                 loss: -0.0644
env0_second_0:                 episode reward: -3.9000,                 loss: -0.0071
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 2283.0,                last time consumption/overall running time: 512.0948s / 9289.2734 s
env0_first_0:                 episode reward: 5.0500,                 loss: -0.0709
env0_second_0:                 episode reward: -5.0500,                 loss: 0.0117
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 2330.8,                last time consumption/overall running time: 522.2736s / 9811.5470 s
env0_first_0:                 episode reward: 4.4500,                 loss: -0.0607
env0_second_0:                 episode reward: -4.4500,                 loss: -0.0194
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 2485.3,                last time consumption/overall running time: 556.1840s / 10367.7310 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.0765
env0_second_0:                 episode reward: -4.3000,                 loss: -0.0220
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 2503.6,                last time consumption/overall running time: 557.1206s / 10924.8516 s
env0_first_0:                 episode reward: 2.2500,                 loss: -0.0746
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0324
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 2204.35,                last time consumption/overall running time: 452.5511s / 11377.4027 s
env0_first_0:                 episode reward: 4.5500,                 loss: -0.0810
env0_second_0:                 episode reward: -4.5500,                 loss: -0.0172
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 2485.3,                last time consumption/overall running time: 504.7657s / 11882.1684 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.0501
env0_second_0:                 episode reward: -1.4500,                 loss: -0.0063
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 2722.55,                last time consumption/overall running time: 553.3664s / 12435.5349 s
env0_first_0:                 episode reward: -2.4500,                 loss: -0.0580
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0055
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 2409.15,                last time consumption/overall running time: 492.8406s / 12928.3755 s
env0_first_0:                 episode reward: 3.0500,                 loss: -0.0600
env0_second_0:                 episode reward: -3.0500,                 loss: -0.0295
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 2521.5,                last time consumption/overall running time: 513.6448s / 13442.0204 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.0596
env0_second_0:                 episode reward: -4.3000,                 loss: -0.0335
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 2475.0,                last time consumption/overall running time: 503.8628s / 13945.8831 s
env0_first_0:                 episode reward: 3.9000,                 loss: -0.0542
env0_second_0:                 episode reward: -3.9000,                 loss: 0.0194
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 2733.4,                last time consumption/overall running time: 557.0460s / 14502.9291 s
env0_first_0:                 episode reward: 3.8500,                 loss: -0.0415
env0_second_0:                 episode reward: -3.8500,                 loss: 0.0085
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 2668.55,                last time consumption/overall running time: 542.0400s / 15044.9691 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.0500
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0221
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 2807.55,                last time consumption/overall running time: 568.9660s / 15613.9351 s
env0_first_0:                 episode reward: 3.0500,                 loss: -0.0798
env0_second_0:                 episode reward: -3.0500,                 loss: -0.0037
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 2432.65,                last time consumption/overall running time: 495.3855s / 16109.3206 s
env0_first_0:                 episode reward: 4.4000,                 loss: -0.0681
env0_second_0:                 episode reward: -4.4000,                 loss: 0.0133
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2469.65,                last time consumption/overall running time: 502.7037s / 16612.0243 s
env0_first_0:                 episode reward: 5.2500,                 loss: -0.0581
env0_second_0:                 episode reward: -5.2500,                 loss: 0.0371
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 2381.1,                last time consumption/overall running time: 483.2246s / 17095.2489 s
env0_first_0:                 episode reward: 5.0500,                 loss: -0.0217
env0_second_0:                 episode reward: -5.0500,                 loss: 0.0811
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1412.1,                last time consumption/overall running time: 292.0459s / 17387.2948 s
env0_first_0:                 episode reward: 7.8500,                 loss: -0.0564
env0_second_0:                 episode reward: -7.8500,                 loss: -0.0094
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1897.45,                last time consumption/overall running time: 391.0413s / 17778.3362 s
env0_first_0:                 episode reward: 7.1000,                 loss: -0.0403
env0_second_0:                 episode reward: -7.1000,                 loss: 0.0368
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2148.75,                last time consumption/overall running time: 426.1720s / 18204.5082 s
env0_first_0:                 episode reward: 2.8500,                 loss: -0.0439
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0029
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2405.45,                last time consumption/overall running time: 443.2390s / 18647.7471 s
env0_first_0:                 episode reward: 6.1500,                 loss: -0.0651
env0_second_0:                 episode reward: -6.1500,                 loss: -0.0237
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2483.6,                last time consumption/overall running time: 455.9080s / 19103.6551 s
env0_first_0:                 episode reward: 5.8500,                 loss: -0.0520
env0_second_0:                 episode reward: -5.8500,                 loss: -0.0115
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2245.7,                last time consumption/overall running time: 416.3847s / 19520.0398 s
env0_first_0:                 episode reward: 6.6000,                 loss: -0.0706
env0_second_0:                 episode reward: -6.6000,                 loss: -0.0311
env1_first_0:                 episode reward: 6.0000,                 loss: nan
env1_second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2320.7,                last time consumption/overall running time: 426.8635s / 19946.9033 s
env0_first_0:                 episode reward: 4.9500,                 loss: -0.0705
env0_second_0:                 episode reward: -4.9500,                 loss: -0.0230
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2524.55,                last time consumption/overall running time: 468.2581s / 20415.1614 s
env0_first_0:                 episode reward: 4.0000,                 loss: -0.0720
env0_second_0:                 episode reward: -4.0000,                 loss: -0.0366
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2352.7,                last time consumption/overall running time: 434.3920s / 20849.5534 s
env0_first_0:                 episode reward: 5.8000,                 loss: -0.0752
env0_second_0:                 episode reward: -5.8000,                 loss: -0.0348
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2581.55,                last time consumption/overall running time: 476.0429s / 21325.5963 s
env0_first_0:                 episode reward: 4.5500,                 loss: -0.0646
env0_second_0:                 episode reward: -4.5500,                 loss: -0.0160
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2409.5,                last time consumption/overall running time: 444.7199s / 21770.3162 s
env0_first_0:                 episode reward: 6.0000,                 loss: -0.0747
env0_second_0:                 episode reward: -6.0000,                 loss: -0.0402
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2512.6,                last time consumption/overall running time: 463.5451s / 22233.8613 s
env0_first_0:                 episode reward: 5.8500,                 loss: -0.0619
env0_second_0:                 episode reward: -5.8500,                 loss: -0.0165
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2244.7,                last time consumption/overall running time: 417.1007s / 22650.9620 s
env0_first_0:                 episode reward: 5.8500,                 loss: -0.0632
env0_second_0:                 episode reward: -5.8500,                 loss: -0.0206
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2448.85,                last time consumption/overall running time: 453.0463s / 23104.0082 s
env0_first_0:                 episode reward: 5.8000,                 loss: -0.0669
env0_second_0:                 episode reward: -5.8000,                 loss: -0.0209
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2440.9,                last time consumption/overall running time: 451.8049s / 23555.8131 s
env0_first_0:                 episode reward: 6.0500,                 loss: -0.0709
env0_second_0:                 episode reward: -6.0500,                 loss: -0.0109
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2185.6,                last time consumption/overall running time: 402.9795s / 23958.7927 s
env0_first_0:                 episode reward: 5.8500,                 loss: -0.0550
env0_second_0:                 episode reward: -5.8500,                 loss: 0.0071
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2575.5,                last time consumption/overall running time: 473.5070s / 24432.2996 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0427
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2465.15,                last time consumption/overall running time: 455.0005s / 24887.3001 s
env0_first_0:                 episode reward: 4.4500,                 loss: -0.0634
env0_second_0:                 episode reward: -4.4500,                 loss: 0.0019
env1_first_0:                 episode reward: 5.6500,                 loss: nan
env1_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2304.25,                last time consumption/overall running time: 427.0209s / 25314.3211 s
env0_first_0:                 episode reward: 6.2000,                 loss: -0.0741
env0_second_0:                 episode reward: -6.2000,                 loss: -0.0213
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1945.65,                last time consumption/overall running time: 363.1638s / 25677.4849 s
env0_first_0:                 episode reward: 7.3000,                 loss: -0.0778
env0_second_0:                 episode reward: -7.3000,                 loss: -0.0400
env1_first_0:                 episode reward: 8.1000,                 loss: nan
env1_second_0:                 episode reward: -8.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2201.15,                last time consumption/overall running time: 406.1627s / 26083.6476 s
env0_first_0:                 episode reward: 7.7000,                 loss: -0.0825
env0_second_0:                 episode reward: -7.7000,                 loss: -0.0283
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1947.75,                last time consumption/overall running time: 362.1327s / 26445.7802 s
env0_first_0:                 episode reward: 8.4000,                 loss: -0.0977
env0_second_0:                 episode reward: -8.4000,                 loss: -0.0465
env1_first_0:                 episode reward: 7.8500,                 loss: nan
env1_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2100.45,                last time consumption/overall running time: 389.3179s / 26835.0981 s
env0_first_0:                 episode reward: 7.8500,                 loss: -0.0817
env0_second_0:                 episode reward: -7.8500,                 loss: -0.0355
env1_first_0:                 episode reward: 8.2500,                 loss: nan
env1_second_0:                 episode reward: -8.2500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2229.9,                last time consumption/overall running time: 413.7409s / 27248.8390 s
env0_first_0:                 episode reward: 7.6000,                 loss: -0.0762
env0_second_0:                 episode reward: -7.6000,                 loss: -0.0194
env1_first_0:                 episode reward: 7.6000,                 loss: nan
env1_second_0:                 episode reward: -7.6000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2244.15,                last time consumption/overall running time: 414.8664s / 27663.7054 s
env0_first_0:                 episode reward: 6.5500,                 loss: -0.0803
env0_second_0:                 episode reward: -6.5500,                 loss: -0.0297
env1_first_0:                 episode reward: 8.2000,                 loss: nan
env1_second_0:                 episode reward: -8.2000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2296.55,                last time consumption/overall running time: 422.7620s / 28086.4674 s
env0_first_0:                 episode reward: 8.3500,                 loss: -0.0711
env0_second_0:                 episode reward: -8.3500,                 loss: 0.0107
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2220.25,                last time consumption/overall running time: 409.5895s / 28496.0569 s
env0_first_0:                 episode reward: 8.3000,                 loss: -0.0441
env0_second_0:                 episode reward: -8.3000,                 loss: 0.0575
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2183.2,                last time consumption/overall running time: 401.8324s / 28897.8892 s
env0_first_0:                 episode reward: 8.3500,                 loss: -0.0666
env0_second_0:                 episode reward: -8.3500,                 loss: 0.0115
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2174.55,                last time consumption/overall running time: 401.4955s / 29299.3848 s
env0_first_0:                 episode reward: 6.5500,                 loss: -0.0668
env0_second_0:                 episode reward: -6.5500,                 loss: 0.0253
env1_first_0:                 episode reward: 7.4000,                 loss: nan
env1_second_0:                 episode reward: -7.4000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2018.75,                last time consumption/overall running time: 373.2582s / 29672.6430 s
env0_first_0:                 episode reward: 6.8000,                 loss: -0.0932
env0_second_0:                 episode reward: -6.8000,                 loss: 0.0566
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2301.55,                last time consumption/overall running time: 421.6883s / 30094.3313 s
env0_first_0:                 episode reward: 6.8000,                 loss: -0.0833
env0_second_0:                 episode reward: -6.8000,                 loss: 0.0066
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2235.9,                last time consumption/overall running time: 412.9580s / 30507.2893 s
env0_first_0:                 episode reward: 6.1000,                 loss: -0.0838
env0_second_0:                 episode reward: -6.1000,                 loss: 0.0612
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2195.4,                last time consumption/overall running time: 406.1162s / 30913.4054 s
env0_first_0:                 episode reward: 8.4000,                 loss: -0.0924
env0_second_0:                 episode reward: -8.4000,                 loss: -0.0167
env1_first_0:                 episode reward: 7.0000,                 loss: nan
env1_second_0:                 episode reward: -7.0000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2248.0,                last time consumption/overall running time: 413.5480s / 31326.9535 s
env0_first_0:                 episode reward: 8.1000,                 loss: -0.0757
env0_second_0:                 episode reward: -8.1000,                 loss: -0.0123
env1_first_0:                 episode reward: 6.6000,                 loss: nan
env1_second_0:                 episode reward: -6.6000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2179.1,                last time consumption/overall running time: 373.9469s / 31700.9004 s
env0_first_0:                 episode reward: 7.8500,                 loss: -0.1083
env0_second_0:                 episode reward: -7.8500,                 loss: -0.0246
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2343.2,                last time consumption/overall running time: 384.5799s / 32085.4803 s
env0_first_0:                 episode reward: 7.6000,                 loss: -0.0706
env0_second_0:                 episode reward: -7.6000,                 loss: 0.0175
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2238.6,                last time consumption/overall running time: 369.4497s / 32454.9299 s
env0_first_0:                 episode reward: 7.4500,                 loss: -0.0968
env0_second_0:                 episode reward: -7.4500,                 loss: -0.0182
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2507.45,                last time consumption/overall running time: 412.4357s / 32867.3656 s
env0_first_0:                 episode reward: 5.9500,                 loss: -0.0620
env0_second_0:                 episode reward: -5.9500,                 loss: 0.0596
env1_first_0:                 episode reward: 6.3500,                 loss: nan
env1_second_0:                 episode reward: -6.3500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2231.3,                last time consumption/overall running time: 373.6207s / 33240.9863 s
env0_first_0:                 episode reward: 6.3500,                 loss: -0.0661
env0_second_0:                 episode reward: -6.3500,                 loss: 0.0716
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1486.2,                last time consumption/overall running time: 250.7865s / 33491.7728 s
env0_first_0:                 episode reward: 5.8000,                 loss: -0.0581
env0_second_0:                 episode reward: -5.8000,                 loss: 0.0639
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2062.1,                last time consumption/overall running time: 338.0846s / 33829.8575 s
env0_first_0:                 episode reward: 6.7000,                 loss: -0.0756
env0_second_0:                 episode reward: -6.7000,                 loss: 0.0396
env1_first_0:                 episode reward: 6.3500,                 loss: nan
env1_second_0:                 episode reward: -6.3500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2218.5,                last time consumption/overall running time: 371.6407s / 34201.4981 s
env0_first_0:                 episode reward: 7.3500,                 loss: -0.0854
env0_second_0:                 episode reward: -7.3500,                 loss: 0.0225
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1907.9,                last time consumption/overall running time: 316.5774s / 34518.0756 s
env0_first_0:                 episode reward: 6.6500,                 loss: -0.0408
env0_second_0:                 episode reward: -6.6500,                 loss: 0.2320
env1_first_0:                 episode reward: 8.1500,                 loss: nan
env1_second_0:                 episode reward: -8.1500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1669.45,                last time consumption/overall running time: 278.1443s / 34796.2198 s
env0_first_0:                 episode reward: 6.4500,                 loss: -0.0333
env0_second_0:                 episode reward: -6.4500,                 loss: 0.0725
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2192.0,                last time consumption/overall running time: 363.5231s / 35159.7429 s
env0_first_0:                 episode reward: 6.3000,                 loss: -0.0225
env0_second_0:                 episode reward: -6.3000,                 loss: 0.1172
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2190.8,                last time consumption/overall running time: 359.0760s / 35518.8189 s
env0_first_0:                 episode reward: 7.4500,                 loss: -0.0582
env0_second_0:                 episode reward: -7.4500,                 loss: 0.1203
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2134.1,                last time consumption/overall running time: 350.5022s / 35869.3211 s
env0_first_0:                 episode reward: 6.5000,                 loss: -0.0168
env0_second_0:                 episode reward: -6.5000,                 loss: 0.1415
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1287.25,                last time consumption/overall running time: 214.3220s / 36083.6431 s
env0_first_0:                 episode reward: -7.4000,                 loss: -0.0141
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0785
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1604.45,                last time consumption/overall running time: 263.5801s / 36347.2232 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0012
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0470
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1603.2,                last time consumption/overall running time: 262.8248s / 36610.0480 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0540
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1680.5,                last time consumption/overall running time: 281.7169s / 36891.7649 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0035
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0363
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1666.85,                last time consumption/overall running time: 275.3029s / 37167.0677 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.0427
env0_second_0:                 episode reward: -4.3000,                 loss: -0.0129
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1683.2,                last time consumption/overall running time: 278.4457s / 37445.5135 s
env0_first_0:                 episode reward: 2.4000,                 loss: -0.0482
env0_second_0:                 episode reward: -2.4000,                 loss: -0.0279
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1778.45,                last time consumption/overall running time: 293.7870s / 37739.3004 s
env0_first_0:                 episode reward: 3.4000,                 loss: -0.0362
env0_second_0:                 episode reward: -3.4000,                 loss: -0.0023
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1939.25,                last time consumption/overall running time: 321.4052s / 38060.7057 s
env0_first_0:                 episode reward: 2.8000,                 loss: -0.0421
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0145
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2457.45,                last time consumption/overall running time: 407.3070s / 38468.0127 s
env0_first_0:                 episode reward: 4.8000,                 loss: -0.0593
env0_second_0:                 episode reward: -4.8000,                 loss: 0.1056
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2297.6,                last time consumption/overall running time: 381.5706s / 38849.5833 s
env0_first_0:                 episode reward: 7.0500,                 loss: -0.0704
env0_second_0:                 episode reward: -7.0500,                 loss: -0.0172
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2495.3,                last time consumption/overall running time: 410.9879s / 39260.5712 s
env0_first_0:                 episode reward: 5.9500,                 loss: -0.0625
env0_second_0:                 episode reward: -5.9500,                 loss: 0.0200
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2683.65,                last time consumption/overall running time: 437.9104s / 39698.4816 s
env0_first_0:                 episode reward: 5.2000,                 loss: -0.0855
env0_second_0:                 episode reward: -5.2000,                 loss: -0.0065
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2389.85,                last time consumption/overall running time: 394.7176s / 40093.1992 s
env0_first_0:                 episode reward: -1.6500,                 loss: -0.0723
env0_second_0:                 episode reward: 1.6500,                 loss: -0.0078
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 3101.45,                last time consumption/overall running time: 504.9520s / 40598.1512 s
env0_first_0:                 episode reward: 2.9000,                 loss: -0.0743
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0043
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2649.4,                last time consumption/overall running time: 434.8242s / 41032.9754 s
env0_first_0:                 episode reward: 6.3500,                 loss: -0.0832
env0_second_0:                 episode reward: -6.3500,                 loss: -0.0012
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2522.3,                last time consumption/overall running time: 416.2274s / 41449.2028 s
env0_first_0:                 episode reward: 6.4000,                 loss: -0.0800
env0_second_0:                 episode reward: -6.4000,                 loss: -0.0145
env1_first_0:                 episode reward: 7.0000,                 loss: nan
env1_second_0:                 episode reward: -7.0000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2580.75,                last time consumption/overall running time: 425.2505s / 41874.4532 s
env0_first_0:                 episode reward: 6.8000,                 loss: -0.0591
env0_second_0:                 episode reward: -6.8000,                 loss: 0.0236
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2374.35,                last time consumption/overall running time: 392.0479s / 42266.5011 s
env0_first_0:                 episode reward: 7.6000,                 loss: -0.0837
env0_second_0:                 episode reward: -7.6000,                 loss: 0.0649
env1_first_0:                 episode reward: 7.7500,                 loss: nan
env1_second_0:                 episode reward: -7.7500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2615.05,                last time consumption/overall running time: 431.7633s / 42698.2644 s
env0_first_0:                 episode reward: 6.7000,                 loss: -0.0706
env0_second_0:                 episode reward: -6.7000,                 loss: 0.0459
env1_first_0:                 episode reward: 6.1500,                 loss: nan
env1_second_0:                 episode reward: -6.1500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2638.65,                last time consumption/overall running time: 436.7237s / 43134.9881 s
env0_first_0:                 episode reward: 7.1000,                 loss: -0.0782
env0_second_0:                 episode reward: -7.1000,                 loss: 0.0157
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2469.75,                last time consumption/overall running time: 410.8043s / 43545.7923 s
env0_first_0:                 episode reward: 7.0000,                 loss: -0.0789
env0_second_0:                 episode reward: -7.0000,                 loss: 0.0030
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2680.2,                last time consumption/overall running time: 441.4080s / 43987.2003 s
env0_first_0:                 episode reward: 7.0000,                 loss: -0.0977
env0_second_0:                 episode reward: -7.0000,                 loss: -0.0223
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2800.8,                last time consumption/overall running time: 461.6046s / 44448.8049 s
env0_first_0:                 episode reward: 5.9000,                 loss: -0.0916
env0_second_0:                 episode reward: -5.9000,                 loss: -0.0217
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2619.85,                last time consumption/overall running time: 433.5479s / 44882.3528 s
env0_first_0:                 episode reward: 6.6000,                 loss: -0.1091
env0_second_0:                 episode reward: -6.6000,                 loss: -0.0493
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2670.5,                last time consumption/overall running time: 441.2594s / 45323.6121 s
env0_first_0:                 episode reward: 7.2500,                 loss: -0.0967
env0_second_0:                 episode reward: -7.2500,                 loss: -0.0092
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2586.6,                last time consumption/overall running time: 430.3864s / 45753.9986 s
env0_first_0:                 episode reward: 7.0000,                 loss: -0.0860
env0_second_0:                 episode reward: -7.0000,                 loss: 0.0028
env1_first_0:                 episode reward: 6.2000,                 loss: nan
env1_second_0:                 episode reward: -6.2000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2305.25,                last time consumption/overall running time: 380.3903s / 46134.3888 s
env0_first_0:                 episode reward: 8.2500,                 loss: -0.0911
env0_second_0:                 episode reward: -8.2500,                 loss: 0.0040
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2419.5,                last time consumption/overall running time: 399.9493s / 46534.3382 s
env0_first_0:                 episode reward: 7.8500,                 loss: -0.0740
env0_second_0:                 episode reward: -7.8500,                 loss: 0.0359
env1_first_0:                 episode reward: 5.9500,                 loss: nan
env1_second_0:                 episode reward: -5.9500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2313.65,                last time consumption/overall running time: 385.2861s / 46919.6243 s
env0_first_0:                 episode reward: 6.9000,                 loss: -0.0627
env0_second_0:                 episode reward: -6.9000,                 loss: 0.1053
env1_first_0:                 episode reward: 5.9000,                 loss: nan
env1_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2405.7,                last time consumption/overall running time: 396.2920s / 47315.9163 s
env0_first_0:                 episode reward: 8.6000,                 loss: -0.0929
env0_second_0:                 episode reward: -8.6000,                 loss: -0.0009
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2573.85,                last time consumption/overall running time: 421.5490s / 47737.4653 s
env0_first_0:                 episode reward: 7.2500,                 loss: -0.0950
env0_second_0:                 episode reward: -7.2500,                 loss: 0.0031
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2577.8,                last time consumption/overall running time: 423.1328s / 48160.5981 s
env0_first_0:                 episode reward: 6.5000,                 loss: -0.0929
env0_second_0:                 episode reward: -6.5000,                 loss: -0.0062
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2472.7,                last time consumption/overall running time: 410.8557s / 48571.4538 s
env0_first_0:                 episode reward: 7.0500,                 loss: -0.0904
env0_second_0:                 episode reward: -7.0500,                 loss: -0.0142
env1_first_0:                 episode reward: 6.1500,                 loss: nan
env1_second_0:                 episode reward: -6.1500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2588.8,                last time consumption/overall running time: 426.2783s / 48997.7321 s
env0_first_0:                 episode reward: 7.8500,                 loss: -0.0807
env0_second_0:                 episode reward: -7.8500,                 loss: 0.0080
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2763.1,                last time consumption/overall running time: 452.1369s / 49449.8690 s
env0_first_0:                 episode reward: 6.2500,                 loss: -0.0593
env0_second_0:                 episode reward: -6.2500,                 loss: 0.1083
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2818.4,                last time consumption/overall running time: 462.9552s / 49912.8242 s
env0_first_0:                 episode reward: 5.9500,                 loss: -0.0537
env0_second_0:                 episode reward: -5.9500,                 loss: 0.2342
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2351.5,                last time consumption/overall running time: 386.2987s / 50299.1228 s
env0_first_0:                 episode reward: 1.7500,                 loss: -0.0448
env0_second_0:                 episode reward: -1.7500,                 loss: 0.2179
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2609.7,                last time consumption/overall running time: 428.9791s / 50728.1020 s
env0_first_0:                 episode reward: 6.1500,                 loss: -0.0716
env0_second_0:                 episode reward: -6.1500,                 loss: 0.3655
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2645.15,                last time consumption/overall running time: 439.1794s / 51167.2813 s
env0_first_0:                 episode reward: 7.0500,                 loss: -0.0772
env0_second_0:                 episode reward: -7.0500,                 loss: 0.0861
env1_first_0:                 episode reward: 6.6000,                 loss: nan
env1_second_0:                 episode reward: -6.6000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2886.8,                last time consumption/overall running time: 470.3788s / 51637.6601 s
env0_first_0:                 episode reward: 6.1500,                 loss: -0.0564
env0_second_0:                 episode reward: -6.1500,                 loss: 0.0647
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2789.35,                last time consumption/overall running time: 457.4528s / 52095.1130 s
env0_first_0:                 episode reward: 4.9000,                 loss: -0.0723
env0_second_0:                 episode reward: -4.9000,                 loss: 0.0667
env1_first_0:                 episode reward: 6.1500,                 loss: nan
env1_second_0:                 episode reward: -6.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 3100.25,                last time consumption/overall running time: 504.5218s / 52599.6348 s
env0_first_0:                 episode reward: 5.3000,                 loss: -0.0644
env0_second_0:                 episode reward: -5.3000,                 loss: 0.0616
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2612.75,                last time consumption/overall running time: 428.7897s / 53028.4245 s
env0_first_0:                 episode reward: 6.0000,                 loss: -0.0649
env0_second_0:                 episode reward: -6.0000,                 loss: 0.1561
env1_first_0:                 episode reward: 5.4500,                 loss: nan
env1_second_0:                 episode reward: -5.4500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 3235.75,                last time consumption/overall running time: 530.9466s / 53559.3712 s
env0_first_0:                 episode reward: 2.7000,                 loss: -0.0819
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0389
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 3207.05,                last time consumption/overall running time: 521.3334s / 54080.7046 s
env0_first_0:                 episode reward: 2.5000,                 loss: -0.0892
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0891
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2540.85,                last time consumption/overall running time: 413.7244s / 54494.4290 s
env0_first_0:                 episode reward: 6.1000,                 loss: -0.0934
env0_second_0:                 episode reward: -6.1000,                 loss: 0.1273
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2854.9,                last time consumption/overall running time: 470.4839s / 54964.9129 s
env0_first_0:                 episode reward: 3.7000,                 loss: -0.0772
env0_second_0:                 episode reward: -3.7000,                 loss: 0.0536
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 3940.1,                last time consumption/overall running time: 641.4230s / 55606.3359 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.0749
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0901
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 3812.65,                last time consumption/overall running time: 618.8746s / 56225.2105 s
env0_first_0:                 episode reward: -3.2500,                 loss: -0.0746
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0667
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 3864.7,                last time consumption/overall running time: 626.2014s / 56851.4118 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0764
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1714
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 3605.55,                last time consumption/overall running time: 587.4401s / 57438.8519 s
env0_first_0:                 episode reward: -2.6000,                 loss: -0.0648
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0821
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 3973.25,                last time consumption/overall running time: 647.5983s / 58086.4502 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0782
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0829
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 3856.25,                last time consumption/overall running time: 631.7303s / 58718.1805 s
env0_first_0:                 episode reward: -4.2500,                 loss: -0.0654
env0_second_0:                 episode reward: 4.2500,                 loss: 0.1814
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 3837.2,                last time consumption/overall running time: 631.4605s / 59349.6410 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.0626
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3791
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 3939.45,                last time consumption/overall running time: 649.2393s / 59998.8803 s
env0_first_0:                 episode reward: -2.2000,                 loss: -0.0918
env0_second_0:                 episode reward: 2.2000,                 loss: 0.2400
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 3452.35,                last time consumption/overall running time: 566.6369s / 60565.5173 s
env0_first_0:                 episode reward: -4.6500,                 loss: -0.1171
env0_second_0:                 episode reward: 4.6500,                 loss: 0.2490
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 3767.45,                last time consumption/overall running time: 614.4268s / 61179.9441 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.0966
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1804
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 3651.3,                last time consumption/overall running time: 600.3292s / 61780.2732 s
env0_first_0:                 episode reward: -3.2500,                 loss: -0.0911
env0_second_0:                 episode reward: 3.2500,                 loss: 0.1534
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 3452.6,                last time consumption/overall running time: 564.7244s / 62344.9977 s
env0_first_0:                 episode reward: -4.6000,                 loss: -0.1063
env0_second_0:                 episode reward: 4.6000,                 loss: 0.1189
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 3562.85,                last time consumption/overall running time: 580.2473s / 62925.2449 s
env0_first_0:                 episode reward: -3.3500,                 loss: -0.0990
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2161
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 3582.0,                last time consumption/overall running time: 583.2616s / 63508.5066 s
env0_first_0:                 episode reward: -5.0000,                 loss: -0.0928
env0_second_0:                 episode reward: 5.0000,                 loss: 0.2373
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2499.2,                last time consumption/overall running time: 409.6672s / 63918.1738 s
env0_first_0:                 episode reward: 4.9500,                 loss: -0.0877
env0_second_0:                 episode reward: -4.9500,                 loss: 0.2135
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 3437.65,                last time consumption/overall running time: 557.6644s / 64475.8381 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0937
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1786
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 3826.15,                last time consumption/overall running time: 620.2572s / 65096.0953 s
env0_first_0:                 episode reward: -3.8000,                 loss: -0.0921
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2647
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 3357.05,                last time consumption/overall running time: 549.0578s / 65645.1531 s
env0_first_0:                 episode reward: -4.0500,                 loss: -0.0831
env0_second_0:                 episode reward: 4.0500,                 loss: 0.1463
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 3635.85,                last time consumption/overall running time: 594.1970s / 66239.3501 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0824
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2215
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 3613.45,                last time consumption/overall running time: 592.2720s / 66831.6221 s
env0_first_0:                 episode reward: -3.2000,                 loss: -0.0930
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2865
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 3385.4,                last time consumption/overall running time: 553.8063s / 67385.4284 s
env0_first_0:                 episode reward: -3.2500,                 loss: -0.1078
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2333
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 3264.55,                last time consumption/overall running time: 533.5314s / 67918.9597 s
env0_first_0:                 episode reward: -3.6000,                 loss: -0.0936
env0_second_0:                 episode reward: 3.6000,                 loss: 0.1674
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 3551.9,                last time consumption/overall running time: 581.1864s / 68500.1461 s
env0_first_0:                 episode reward: -4.6500,                 loss: -0.1191
env0_second_0:                 episode reward: 4.6500,                 loss: 0.1127
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 3599.95,                last time consumption/overall running time: 586.7324s / 69086.8785 s
env0_first_0:                 episode reward: -4.4000,                 loss: -0.1133
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0559
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 3285.85,                last time consumption/overall running time: 536.0208s / 69622.8994 s
env0_first_0:                 episode reward: -2.5500,                 loss: -0.1001
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0807
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 3694.1,                last time consumption/overall running time: 596.6768s / 70219.5762 s
env0_first_0:                 episode reward: -2.4000,                 loss: -0.1093
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0785
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 3932.8,                last time consumption/overall running time: 638.9411s / 70858.5173 s
env0_first_0:                 episode reward: -1.9000,                 loss: -0.1163
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0694
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 3596.1,                last time consumption/overall running time: 583.5831s / 71442.1004 s
env0_first_0:                 episode reward: -3.7000,                 loss: -0.1099
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0586
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 3641.0,                last time consumption/overall running time: 593.7874s / 72035.8878 s
env0_first_0:                 episode reward: -3.9500,                 loss: -0.1151
env0_second_0:                 episode reward: 3.9500,                 loss: 0.1125
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 3915.5,                last time consumption/overall running time: 633.9597s / 72669.8475 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.1020
env0_second_0:                 episode reward: -0.6000,                 loss: 0.1261
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 3882.5,                last time consumption/overall running time: 632.3192s / 73302.1667 s
env0_first_0:                 episode reward: -3.0500,                 loss: -0.0961
env0_second_0:                 episode reward: 3.0500,                 loss: 0.1806
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 3563.8,                last time consumption/overall running time: 579.6706s / 73881.8373 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.0831
env0_second_0:                 episode reward: 1.8000,                 loss: 0.1624
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 3600.75,                last time consumption/overall running time: 588.4752s / 74470.3125 s
env0_first_0:                 episode reward: -5.1000,                 loss: -0.0890
env0_second_0:                 episode reward: 5.1000,                 loss: 0.1336
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 4237.25,                last time consumption/overall running time: 683.9666s / 75154.2791 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0896
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2011
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 4521.75,                last time consumption/overall running time: 734.5818s / 75888.8609 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.0957
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0555
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 3697.7,                last time consumption/overall running time: 605.0612s / 76493.9221 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0908
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0880
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 3055.95,                last time consumption/overall running time: 503.7456s / 76997.6677 s
env0_first_0:                 episode reward: 2.9000,                 loss: -0.0843
env0_second_0:                 episode reward: -2.9000,                 loss: 0.1147
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 4324.45,                last time consumption/overall running time: 704.8352s / 77702.5029 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1030
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0489
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 4507.5,                last time consumption/overall running time: 734.0495s / 78436.5524 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0930
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0199
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 3930.25,                last time consumption/overall running time: 643.4445s / 79079.9968 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.1041
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1197
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 4225.4,                last time consumption/overall running time: 684.1589s / 79764.1557 s
env0_first_0:                 episode reward: 2.7000,                 loss: -0.1084
env0_second_0:                 episode reward: -2.7000,                 loss: 0.1158
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 3760.9,                last time consumption/overall running time: 611.7293s / 80375.8850 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0946
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2177
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 3787.55,                last time consumption/overall running time: 619.8931s / 80995.7782 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.0865
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4622
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 3342.65,                last time consumption/overall running time: 549.0967s / 81544.8749 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0814
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2788
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2750.7,                last time consumption/overall running time: 451.8141s / 81996.6890 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.0735
env0_second_0:                 episode reward: -4.3000,                 loss: 0.2429
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 3114.25,                last time consumption/overall running time: 506.8955s / 82503.5845 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.0624
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2923
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 3186.65,                last time consumption/overall running time: 522.1026s / 83025.6871 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0846
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2052
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2975.9,                last time consumption/overall running time: 491.7327s / 83517.4198 s
env0_first_0:                 episode reward: -2.9000,                 loss: -0.0786
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1272
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2566.15,                last time consumption/overall running time: 423.1921s / 83940.6119 s
env0_first_0:                 episode reward: -6.8000,                 loss: -0.1071
env0_second_0:                 episode reward: 6.8000,                 loss: 0.1542
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2768.15,                last time consumption/overall running time: 450.3256s / 84390.9375 s
env0_first_0:                 episode reward: 5.1500,                 loss: -0.0720
env0_second_0:                 episode reward: -5.1500,                 loss: 0.1694
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2755.75,                last time consumption/overall running time: 455.6076s / 84846.5451 s
env0_first_0:                 episode reward: 4.4000,                 loss: -0.0335
env0_second_0:                 episode reward: -4.4000,                 loss: 0.2878
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3022.8,                last time consumption/overall running time: 496.3960s / 85342.9411 s
env0_first_0:                 episode reward: 6.5000,                 loss: -0.0987
env0_second_0:                 episode reward: -6.5000,                 loss: 0.1979
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3319.8,                last time consumption/overall running time: 540.0489s / 85882.9901 s
env0_first_0:                 episode reward: 3.1000,                 loss: -0.0931
env0_second_0:                 episode reward: -3.1000,                 loss: 0.2808
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 3779.65,                last time consumption/overall running time: 616.0565s / 86499.0466 s
env0_first_0:                 episode reward: 2.8000,                 loss: -0.1108
env0_second_0:                 episode reward: -2.8000,                 loss: 0.2232
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 3800.95,                last time consumption/overall running time: 626.3140s / 87125.3606 s
env0_first_0:                 episode reward: 2.2000,                 loss: -0.1161
env0_second_0:                 episode reward: -2.2000,                 loss: 0.1332
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3952.95,                last time consumption/overall running time: 645.6309s / 87770.9915 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.0904
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1858
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2461.85,                last time consumption/overall running time: 405.7026s / 88176.6941 s
env0_first_0:                 episode reward: 5.0000,                 loss: -0.0856
env0_second_0:                 episode reward: -5.0000,                 loss: 0.2803
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1902.15,                last time consumption/overall running time: 312.7098s / 88489.4039 s
env0_first_0:                 episode reward: 2.0500,                 loss: -0.0925
env0_second_0:                 episode reward: -2.0500,                 loss: 0.2866
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1989.6,                last time consumption/overall running time: 322.8525s / 88812.2564 s
env0_first_0:                 episode reward: -1.9000,                 loss: -0.0410
env0_second_0:                 episode reward: 1.9000,                 loss: 0.1286
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1709.85,                last time consumption/overall running time: 282.6767s / 89094.9330 s
env0_first_0:                 episode reward: 2.3500,                 loss: -0.0450
env0_second_0:                 episode reward: -2.3500,                 loss: 0.1672
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1838.3,                last time consumption/overall running time: 306.6387s / 89401.5718 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0276
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1810
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2059.35,                last time consumption/overall running time: 339.6922s / 89741.2639 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.0451
env0_second_0:                 episode reward: -1.2500,                 loss: 0.1872
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2200.4,                last time consumption/overall running time: 367.9059s / 90109.1699 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.0279
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2970
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1888.2,                last time consumption/overall running time: 314.5839s / 90423.7537 s
env0_first_0:                 episode reward: -4.3000,                 loss: -0.0240
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2485
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1953.65,                last time consumption/overall running time: 324.7154s / 90748.4691 s
env0_first_0:                 episode reward: -6.5000,                 loss: -0.0340
env0_second_0:                 episode reward: 6.5000,                 loss: 0.5659
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2064.65,                last time consumption/overall running time: 342.3877s / 91090.8567 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0508
env0_second_0:                 episode reward: 3.3000,                 loss: 2.4422
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1887.55,                last time consumption/overall running time: 314.2435s / 91405.1002 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0245
env0_second_0:                 episode reward: 3.2500,                 loss: 1.5920
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1855.7,                last time consumption/overall running time: 308.8566s / 91713.9568 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0227
env0_second_0:                 episode reward: 1.3500,                 loss: 1.0208
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1419.0,                last time consumption/overall running time: 238.1403s / 91952.0971 s
env0_first_0:                 episode reward: 7.7500,                 loss: 0.0292
env0_second_0:                 episode reward: -7.7500,                 loss: 0.7692
env1_first_0:                 episode reward: 7.6500,                 loss: nan
env1_second_0:                 episode reward: -7.6500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1477.65,                last time consumption/overall running time: 249.2253s / 92201.3224 s
env0_first_0:                 episode reward: 4.6000,                 loss: -0.0411
env0_second_0:                 episode reward: -4.6000,                 loss: 0.1809
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1731.85,                last time consumption/overall running time: 287.3054s / 92488.6279 s
env0_first_0:                 episode reward: -9.1000,                 loss: -0.0901
env0_second_0:                 episode reward: 9.1000,                 loss: 0.1699
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1738.35,                last time consumption/overall running time: 289.7724s / 92778.4003 s
env0_first_0:                 episode reward: -7.7500,                 loss: -0.1071
env0_second_0:                 episode reward: 7.7500,                 loss: 0.2786
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2166.3,                last time consumption/overall running time: 356.6155s / 93135.0157 s
env0_first_0:                 episode reward: -5.8000,                 loss: -0.0776
env0_second_0:                 episode reward: 5.8000,                 loss: 0.2957
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 2232.65,                last time consumption/overall running time: 365.4342s / 93500.4499 s
env0_first_0:                 episode reward: -6.2000,                 loss: -0.0782
env0_second_0:                 episode reward: 6.2000,                 loss: 0.3178
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2364.35,                last time consumption/overall running time: 389.2157s / 93889.6657 s
env0_first_0:                 episode reward: -3.7000,                 loss: -0.0519
env0_second_0:                 episode reward: 3.7000,                 loss: 0.3580
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2556.25,                last time consumption/overall running time: 421.3090s / 94310.9747 s
env0_first_0:                 episode reward: -1.9000,                 loss: -0.0611
env0_second_0:                 episode reward: 1.9000,                 loss: 0.4327
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1978.65,                last time consumption/overall running time: 331.5691s / 94642.5437 s
env0_first_0:                 episode reward: -6.9000,                 loss: -0.0878
env0_second_0:                 episode reward: 6.9000,                 loss: 0.2137
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2008.15,                last time consumption/overall running time: 333.9473s / 94976.4911 s
env0_first_0:                 episode reward: -7.2000,                 loss: -0.0653
env0_second_0:                 episode reward: 7.2000,                 loss: 0.1200
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2450.25,                last time consumption/overall running time: 401.7581s / 95378.2492 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.0578
env0_second_0:                 episode reward: 1.8000,                 loss: 0.1022
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2475.9,                last time consumption/overall running time: 411.9679s / 95790.2171 s
env0_first_0:                 episode reward: -3.7000,                 loss: -0.0815
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0568
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2204.4,                last time consumption/overall running time: 362.0634s / 96152.2805 s
env0_first_0:                 episode reward: -6.8000,                 loss: -0.0944
env0_second_0:                 episode reward: 6.8000,                 loss: 0.1226
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 2063.8,                last time consumption/overall running time: 342.5571s / 96494.8376 s
env0_first_0:                 episode reward: -7.8000,                 loss: -0.0881
env0_second_0:                 episode reward: 7.8000,                 loss: 1.0359
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2175.85,                last time consumption/overall running time: 359.5597s / 96854.3972 s
env0_first_0:                 episode reward: -4.6500,                 loss: -0.0276
env0_second_0:                 episode reward: 4.6500,                 loss: 0.6223
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2722.85,                last time consumption/overall running time: 443.8228s / 97298.2200 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.0823
env0_second_0:                 episode reward: 1.7500,                 loss: 0.4527
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2189.0,                last time consumption/overall running time: 362.5033s / 97660.7233 s
env0_first_0:                 episode reward: 5.8500,                 loss: -0.0717
env0_second_0:                 episode reward: -5.8500,                 loss: 0.3525
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1930.95,                last time consumption/overall running time: 322.1350s / 97982.8583 s
env0_first_0:                 episode reward: 2.5000,                 loss: -0.0156
env0_second_0:                 episode reward: -2.5000,                 loss: 0.3836
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2616.35,                last time consumption/overall running time: 429.5940s / 98412.4523 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0407
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4630
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2405.9,                last time consumption/overall running time: 396.3794s / 98808.8317 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.0597
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4371
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2775.35,                last time consumption/overall running time: 459.9190s / 99268.7507 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0762
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3008
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2616.35,                last time consumption/overall running time: 432.1230s / 99700.8737 s
env0_first_0:                 episode reward: 2.1000,                 loss: -0.0797
env0_second_0:                 episode reward: -2.1000,                 loss: 0.1773
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2447.35,                last time consumption/overall running time: 399.7024s / 100100.5761 s
env0_first_0:                 episode reward: 7.1000,                 loss: -0.0804
env0_second_0:                 episode reward: -7.1000,                 loss: 0.2422
env1_first_0:                 episode reward: 7.7500,                 loss: nan
env1_second_0:                 episode reward: -7.7500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2480.9,                last time consumption/overall running time: 408.7292s / 100509.3054 s
env0_first_0:                 episode reward: 7.3500,                 loss: -0.0552
env0_second_0:                 episode reward: -7.3500,                 loss: 0.2986
env1_first_0:                 episode reward: 7.3000,                 loss: nan
env1_second_0:                 episode reward: -7.3000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2247.05,                last time consumption/overall running time: 370.3228s / 100879.6282 s
env0_first_0:                 episode reward: 6.1500,                 loss: -0.0465
env0_second_0:                 episode reward: -6.1500,                 loss: 0.2939
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1795.35,                last time consumption/overall running time: 301.8948s / 101181.5230 s
env0_first_0:                 episode reward: -1.4000,                 loss: -0.0100
env0_second_0:                 episode reward: 1.4000,                 loss: 0.3208
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1517.45,                last time consumption/overall running time: 254.9939s / 101436.5169 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0282
env0_second_0:                 episode reward: 4.3000,                 loss: 0.4224
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1755.3,                last time consumption/overall running time: 291.8895s / 101728.4064 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0193
env0_second_0:                 episode reward: 6.3000,                 loss: 0.5575
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2096.05,                last time consumption/overall running time: 349.8448s / 102078.2512 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 2.0000,                 loss: 0.4095
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1667.9,                last time consumption/overall running time: 277.2511s / 102355.5023 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.0290
env0_second_0:                 episode reward: -5.2000,                 loss: 0.3614
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1730.15,                last time consumption/overall running time: 290.2094s / 102645.7117 s
env0_first_0:                 episode reward: -5.1000,                 loss: -0.0357
env0_second_0:                 episode reward: 5.1000,                 loss: 0.3633
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1626.1,                last time consumption/overall running time: 274.1651s / 102919.8768 s
env0_first_0:                 episode reward: -7.1500,                 loss: -0.0559
env0_second_0:                 episode reward: 7.1500,                 loss: 0.2121
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1882.3,                last time consumption/overall running time: 314.6809s / 103234.5577 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0028
env0_second_0:                 episode reward: 1.6000,                 loss: 0.3561
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1845.1,                last time consumption/overall running time: 306.7382s / 103541.2959 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0675
env0_second_0:                 episode reward: -0.3500,                 loss: 0.6029
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1814.9,                last time consumption/overall running time: 304.6530s / 103845.9489 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0325
env0_second_0:                 episode reward: -0.6000,                 loss: 0.6848
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 2065.3,                last time consumption/overall running time: 338.8390s / 104184.7879 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0392
env0_second_0:                 episode reward: -3.9000,                 loss: 0.7073
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1792.35,                last time consumption/overall running time: 297.9991s / 104482.7871 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.0031
env0_second_0:                 episode reward: -5.8500,                 loss: 0.5486
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2033.95,                last time consumption/overall running time: 334.3514s / 104817.1384 s
env0_first_0:                 episode reward: 3.6500,                 loss: -0.0334
env0_second_0:                 episode reward: -3.6500,                 loss: 0.7440
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2642.5,                last time consumption/overall running time: 437.7453s / 105254.8837 s
env0_first_0:                 episode reward: -3.4000,                 loss: -0.0412
env0_second_0:                 episode reward: 3.4000,                 loss: 1.1811
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 2852.8,                last time consumption/overall running time: 465.0237s / 105719.9074 s
env0_first_0:                 episode reward: 3.0500,                 loss: -0.0573
env0_second_0:                 episode reward: -3.0500,                 loss: 0.2073
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 2309.55,                last time consumption/overall running time: 381.9062s / 106101.8135 s
env0_first_0:                 episode reward: 7.3500,                 loss: -0.0857
env0_second_0:                 episode reward: -7.3500,                 loss: 0.1853
env1_first_0:                 episode reward: 7.6000,                 loss: nan
env1_second_0:                 episode reward: -7.6000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 2090.75,                last time consumption/overall running time: 346.0213s / 106447.8349 s
env0_first_0:                 episode reward: 8.0500,                 loss: -0.0862
env0_second_0:                 episode reward: -8.0500,                 loss: 0.2152
env1_first_0:                 episode reward: 7.9500,                 loss: nan
env1_second_0:                 episode reward: -7.9500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 2246.5,                last time consumption/overall running time: 371.0235s / 106818.8584 s
env0_first_0:                 episode reward: 6.9000,                 loss: -0.0756
env0_second_0:                 episode reward: -6.9000,                 loss: 0.6132
env1_first_0:                 episode reward: 6.6500,                 loss: nan
env1_second_0:                 episode reward: -6.6500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2288.15,                last time consumption/overall running time: 378.4770s / 107197.3354 s
env0_first_0:                 episode reward: 9.1000,                 loss: -0.1079
env0_second_0:                 episode reward: -9.1000,                 loss: 0.2683
env1_first_0:                 episode reward: 8.6500,                 loss: nan
env1_second_0:                 episode reward: -8.6500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 2280.95,                last time consumption/overall running time: 380.0872s / 107577.4227 s
env0_first_0:                 episode reward: 9.0500,                 loss: -0.0981
env0_second_0:                 episode reward: -9.0500,                 loss: 0.2527
env1_first_0:                 episode reward: 9.0500,                 loss: nan
env1_second_0:                 episode reward: -9.0500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 2312.25,                last time consumption/overall running time: 385.7569s / 107963.1796 s
env0_first_0:                 episode reward: 8.9000,                 loss: -0.0852
env0_second_0:                 episode reward: -8.9000,                 loss: 0.2304
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2269.3,                last time consumption/overall running time: 373.1109s / 108336.2905 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.0066
env0_second_0:                 episode reward: -6.0500,                 loss: 0.7858
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 2468.45,                last time consumption/overall running time: 407.7557s / 108744.0463 s
env0_first_0:                 episode reward: 7.0000,                 loss: -0.0740
env0_second_0:                 episode reward: -7.0000,                 loss: 0.4188
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2399.55,                last time consumption/overall running time: 393.9179s / 109137.9641 s
env0_first_0:                 episode reward: 7.5500,                 loss: -0.0681
env0_second_0:                 episode reward: -7.5500,                 loss: 0.5722
env1_first_0:                 episode reward: 5.9500,                 loss: nan
env1_second_0:                 episode reward: -5.9500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 2435.55,                last time consumption/overall running time: 399.9156s / 109537.8797 s
env0_first_0:                 episode reward: 6.9500,                 loss: -0.0730
env0_second_0:                 episode reward: -6.9500,                 loss: 0.5430
env1_first_0:                 episode reward: 7.1500,                 loss: nan
env1_second_0:                 episode reward: -7.1500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 2409.95,                last time consumption/overall running time: 396.8082s / 109934.6879 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0322
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1595
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2255.0,                last time consumption/overall running time: 372.8033s / 110307.4913 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1709
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3782
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2435.1,                last time consumption/overall running time: 401.8542s / 110709.3454 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0150
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2750
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2623.0,                last time consumption/overall running time: 427.3530s / 111136.6984 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0034
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1047
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2436.45,                last time consumption/overall running time: 398.4117s / 111535.1101 s
env0_first_0:                 episode reward: -3.2000,                 loss: -0.0052
env0_second_0:                 episode reward: 3.2000,                 loss: 0.6376
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2230.75,                last time consumption/overall running time: 370.7168s / 111905.8269 s
env0_first_0:                 episode reward: -6.5000,                 loss: -0.0309
env0_second_0:                 episode reward: 6.5000,                 loss: 0.8067
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 2333.35,                last time consumption/overall running time: 385.2548s / 112291.0817 s
env0_first_0:                 episode reward: -5.4000,                 loss: -0.0286
env0_second_0:                 episode reward: 5.4000,                 loss: 2.5198
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2502.15,                last time consumption/overall running time: 411.8695s / 112702.9512 s
env0_first_0:                 episode reward: 4.3500,                 loss: -0.0829
env0_second_0:                 episode reward: -4.3500,                 loss: 1.9441
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2263.35,                last time consumption/overall running time: 370.6914s / 113073.6427 s
env0_first_0:                 episode reward: 7.3000,                 loss: -0.0524
env0_second_0:                 episode reward: -7.3000,                 loss: 0.8212
env1_first_0:                 episode reward: 7.0000,                 loss: nan
env1_second_0:                 episode reward: -7.0000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 2216.95,                last time consumption/overall running time: 364.8536s / 113438.4963 s
env0_first_0:                 episode reward: 6.9500,                 loss: -0.0665
env0_second_0:                 episode reward: -6.9500,                 loss: 0.6882
env1_first_0:                 episode reward: 7.8500,                 loss: nan
env1_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1918.95,                last time consumption/overall running time: 322.9084s / 113761.4047 s
env0_first_0:                 episode reward: 6.7500,                 loss: -0.0673
env0_second_0:                 episode reward: -6.7500,                 loss: 0.4402
env1_first_0:                 episode reward: 7.2500,                 loss: nan
env1_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2011.95,                last time consumption/overall running time: 337.2644s / 114098.6690 s
env0_first_0:                 episode reward: 6.5000,                 loss: -0.0217
env0_second_0:                 episode reward: -6.5000,                 loss: 0.5001
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2107.2,                last time consumption/overall running time: 346.3311s / 114445.0001 s
env0_first_0:                 episode reward: 8.5000,                 loss: -0.0983
env0_second_0:                 episode reward: -8.5000,                 loss: 1.1522
env1_first_0:                 episode reward: 8.0500,                 loss: nan
env1_second_0:                 episode reward: -8.0500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 2156.65,                last time consumption/overall running time: 352.6877s / 114797.6879 s
env0_first_0:                 episode reward: 8.7000,                 loss: -0.1019
env0_second_0:                 episode reward: -8.7000,                 loss: 0.4937
env1_first_0:                 episode reward: 7.8500,                 loss: nan
env1_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 2104.9,                last time consumption/overall running time: 346.9306s / 115144.6185 s
env0_first_0:                 episode reward: 8.7500,                 loss: -0.0418
env0_second_0:                 episode reward: -8.7500,                 loss: 1.1165
env1_first_0:                 episode reward: 7.9500,                 loss: nan
env1_second_0:                 episode reward: -7.9500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 2220.9,                last time consumption/overall running time: 368.1031s / 115512.7217 s
env0_first_0:                 episode reward: 8.3500,                 loss: -0.1154
env0_second_0:                 episode reward: -8.3500,                 loss: 0.3526
env1_first_0:                 episode reward: 8.9500,                 loss: nan
env1_second_0:                 episode reward: -8.9500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2251.2,                last time consumption/overall running time: 369.7686s / 115882.4903 s
env0_first_0:                 episode reward: 8.1000,                 loss: -0.0631
env0_second_0:                 episode reward: -8.1000,                 loss: 0.5030
env1_first_0:                 episode reward: 7.7500,                 loss: nan
env1_second_0:                 episode reward: -7.7500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 2213.85,                last time consumption/overall running time: 366.9711s / 116249.4615 s
env0_first_0:                 episode reward: 8.8000,                 loss: -0.0943
env0_second_0:                 episode reward: -8.8000,                 loss: 0.4196
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 2221.9,                last time consumption/overall running time: 366.8822s / 116616.3437 s
env0_first_0:                 episode reward: 8.4000,                 loss: -0.0700
env0_second_0:                 episode reward: -8.4000,                 loss: 0.5524
env1_first_0:                 episode reward: 8.3500,                 loss: nan
env1_second_0:                 episode reward: -8.3500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 2279.2,                last time consumption/overall running time: 374.4411s / 116990.7848 s
env0_first_0:                 episode reward: 8.4000,                 loss: -0.0768
env0_second_0:                 episode reward: -8.4000,                 loss: 0.5587
env1_first_0:                 episode reward: 8.8000,                 loss: nan
env1_second_0:                 episode reward: -8.8000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 2526.9,                last time consumption/overall running time: 410.7402s / 117401.5250 s
env0_first_0:                 episode reward: 7.4500,                 loss: -0.0436
env0_second_0:                 episode reward: -7.4500,                 loss: 0.4677
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 2231.25,                last time consumption/overall running time: 370.2544s / 117771.7794 s
env0_first_0:                 episode reward: 4.8000,                 loss: -0.0313
env0_second_0:                 episode reward: -4.8000,                 loss: 0.6200
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2427.9,                last time consumption/overall running time: 398.6632s / 118170.4425 s
env0_first_0:                 episode reward: 7.3000,                 loss: -0.0658
env0_second_0:                 episode reward: -7.3000,                 loss: 0.3536
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2687.25,                last time consumption/overall running time: 439.8235s / 118610.2661 s
env0_first_0:                 episode reward: 6.7500,                 loss: -0.0869
env0_second_0:                 episode reward: -6.7500,                 loss: 1.5754
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 2376.35,                last time consumption/overall running time: 392.6917s / 119002.9578 s
env0_first_0:                 episode reward: 8.7500,                 loss: -0.0730
env0_second_0:                 episode reward: -8.7500,                 loss: 0.5353
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 2081.5,                last time consumption/overall running time: 345.6043s / 119348.5621 s
env0_first_0:                 episode reward: 8.5000,                 loss: -0.1030
env0_second_0:                 episode reward: -8.5000,                 loss: 0.5701
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 2199.8,                last time consumption/overall running time: 362.9453s / 119711.5074 s
env0_first_0:                 episode reward: 7.9500,                 loss: -0.1045
env0_second_0:                 episode reward: -7.9500,                 loss: 0.8993
env1_first_0:                 episode reward: 6.6500,                 loss: nan
env1_second_0:                 episode reward: -6.6500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2262.2,                last time consumption/overall running time: 376.0465s / 120087.5540 s
env0_first_0:                 episode reward: 6.4000,                 loss: -0.0679
env0_second_0:                 episode reward: -6.4000,                 loss: 1.0473
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2273.8,                last time consumption/overall running time: 372.3019s / 120459.8559 s
env0_first_0:                 episode reward: 9.2500,                 loss: -0.1135
env0_second_0:                 episode reward: -9.2500,                 loss: 0.7669
env1_first_0:                 episode reward: 9.1500,                 loss: nan
env1_second_0:                 episode reward: -9.1500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2263.0,                last time consumption/overall running time: 374.7502s / 120834.6061 s
env0_first_0:                 episode reward: 8.7500,                 loss: -0.0919
env0_second_0:                 episode reward: -8.7500,                 loss: 0.7376
env1_first_0:                 episode reward: 9.1500,                 loss: nan
env1_second_0:                 episode reward: -9.1500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2138.2,                last time consumption/overall running time: 356.4553s / 121191.0614 s
env0_first_0:                 episode reward: 8.4500,                 loss: -0.0886
env0_second_0:                 episode reward: -8.4500,                 loss: 0.7571
env1_first_0:                 episode reward: 8.3000,                 loss: nan
env1_second_0:                 episode reward: -8.3000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 2370.65,                last time consumption/overall running time: 392.5095s / 121583.5709 s
env0_first_0:                 episode reward: 8.8500,                 loss: -0.0789
env0_second_0:                 episode reward: -8.8500,                 loss: 0.5809
env1_first_0:                 episode reward: 8.6500,                 loss: nan
env1_second_0:                 episode reward: -8.6500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 2051.7,                last time consumption/overall running time: 340.2277s / 121923.7986 s
env0_first_0:                 episode reward: 8.6000,                 loss: -0.0743
env0_second_0:                 episode reward: -8.6000,                 loss: 0.6172
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 2458.8,                last time consumption/overall running time: 404.5262s / 122328.3248 s
env0_first_0:                 episode reward: 4.5000,                 loss: -0.0422
env0_second_0:                 episode reward: -4.5000,                 loss: 0.4681
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2343.4,                last time consumption/overall running time: 384.9390s / 122713.2638 s
env0_first_0:                 episode reward: 8.0500,                 loss: -0.0948
env0_second_0:                 episode reward: -8.0500,                 loss: 0.5419
env1_first_0:                 episode reward: 7.0500,                 loss: nan
env1_second_0:                 episode reward: -7.0500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 2112.85,                last time consumption/overall running time: 352.9190s / 123066.1828 s
env0_first_0:                 episode reward: 9.0000,                 loss: -0.0864
env0_second_0:                 episode reward: -9.0000,                 loss: 0.5033
env1_first_0:                 episode reward: 7.8500,                 loss: nan
env1_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2228.0,                last time consumption/overall running time: 367.0200s / 123433.2028 s
env0_first_0:                 episode reward: 8.9500,                 loss: -0.1056
env0_second_0:                 episode reward: -8.9500,                 loss: 0.3268
env1_first_0:                 episode reward: 8.3000,                 loss: nan
env1_second_0:                 episode reward: -8.3000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2260.6,                last time consumption/overall running time: 367.7566s / 123800.9594 s
env0_first_0:                 episode reward: -2.1500,                 loss: -0.0557
env0_second_0:                 episode reward: 2.1500,                 loss: 0.1140
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1716.4,                last time consumption/overall running time: 283.7316s / 124084.6910 s
env0_first_0:                 episode reward: -7.2500,                 loss: -0.0660
env0_second_0:                 episode reward: 7.2500,                 loss: 0.2090
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 831.0,                last time consumption/overall running time: 141.0339s / 124225.7249 s
env0_first_0:                 episode reward: -9.3500,                 loss: -0.1146
env0_second_0:                 episode reward: 9.3500,                 loss: 0.3301
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 827.6,                last time consumption/overall running time: 140.4906s / 124366.2155 s
env0_first_0:                 episode reward: -9.5500,                 loss: -0.0831
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0928
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 827.2,                last time consumption/overall running time: 141.1254s / 124507.3409 s
env0_first_0:                 episode reward: -9.8000,                 loss: -0.0711
env0_second_0:                 episode reward: 9.8000,                 loss: -0.0006
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 827.0,                last time consumption/overall running time: 141.6129s / 124648.9538 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.0887
env0_second_0:                 episode reward: 9.6000,                 loss: -0.0262
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 831.2,                last time consumption/overall running time: 143.3974s / 124792.3512 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.0790
env0_second_0:                 episode reward: 9.6000,                 loss: -0.0215
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 827.2,                last time consumption/overall running time: 142.7537s / 124935.1049 s
env0_first_0:                 episode reward: -9.3500,                 loss: -0.0748
env0_second_0:                 episode reward: 9.3500,                 loss: -0.0747
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 831.0,                last time consumption/overall running time: 143.7709s / 125078.8758 s
env0_first_0:                 episode reward: -9.1500,                 loss: -0.0669
env0_second_0:                 episode reward: 9.1500,                 loss: 1.0340
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 827.0,                last time consumption/overall running time: 142.5169s / 125221.3927 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.0728
env0_second_0:                 episode reward: 9.6000,                 loss: 0.9930
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 827.0,                last time consumption/overall running time: 142.5456s / 125363.9383 s
env0_first_0:                 episode reward: -9.7500,                 loss: -0.0719
env0_second_0:                 episode reward: 9.7500,                 loss: 1.4234
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 831.4,                last time consumption/overall running time: 142.8646s / 125506.8029 s
env0_first_0:                 episode reward: -9.4000,                 loss: -0.0679
env0_second_0:                 episode reward: 9.4000,                 loss: 0.7304
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 827.0,                last time consumption/overall running time: 143.9847s / 125650.7876 s
env0_first_0:                 episode reward: -10.0000,                 loss: -0.1047
env0_second_0:                 episode reward: 10.0000,                 loss: 0.5369
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 830.6,                last time consumption/overall running time: 139.6037s / 125790.3913 s
env0_first_0:                 episode reward: -9.5500,                 loss: -0.1106
env0_second_0:                 episode reward: 9.5500,                 loss: 0.6834
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 827.0,                last time consumption/overall running time: 142.1645s / 125932.5558 s
env0_first_0:                 episode reward: -10.0000,                 loss: -0.1192
env0_second_0:                 episode reward: 10.0000,                 loss: 1.0018
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 830.6,                last time consumption/overall running time: 144.3584s / 126076.9143 s
env0_first_0:                 episode reward: -9.7000,                 loss: -0.1035
env0_second_0:                 episode reward: 9.7000,                 loss: 0.8944
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 827.4,                last time consumption/overall running time: 143.7927s / 126220.7070 s
env0_first_0:                 episode reward: -9.8000,                 loss: -0.1197
env0_second_0:                 episode reward: 9.8000,                 loss: 0.6803
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1906.55,                last time consumption/overall running time: 313.8131s / 126534.5201 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.0087
env0_second_0:                 episode reward: 1.3000,                 loss: 1.3164
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2285.9,                last time consumption/overall running time: 374.0659s / 126908.5860 s
env0_first_0:                 episode reward: 5.4000,                 loss: -0.0512
env0_second_0:                 episode reward: -5.4000,                 loss: 0.5993
env1_first_0:                 episode reward: 6.0000,                 loss: nan
env1_second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2114.2,                last time consumption/overall running time: 350.5148s / 127259.1008 s
env0_first_0:                 episode reward: 7.5500,                 loss: -0.0673
env0_second_0:                 episode reward: -7.5500,                 loss: 0.4346
env1_first_0:                 episode reward: 7.6500,                 loss: nan
env1_second_0:                 episode reward: -7.6500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1055.05,                last time consumption/overall running time: 178.3724s / 127437.4731 s
env0_first_0:                 episode reward: -8.8500,                 loss: -0.1264
env0_second_0:                 episode reward: 8.8500,                 loss: 0.3491
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 971.4,                last time consumption/overall running time: 166.3655s / 127603.8386 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.1382
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0974
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 921.3,                last time consumption/overall running time: 159.9977s / 127763.8363 s
env0_first_0:                 episode reward: -8.9500,                 loss: -0.1182
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0794
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 983.35,                last time consumption/overall running time: 168.8474s / 127932.6836 s
env0_first_0:                 episode reward: -8.0000,                 loss: -0.0872
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0647
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 937.85,                last time consumption/overall running time: 158.8043s / 128091.4880 s
env0_first_0:                 episode reward: -8.2000,                 loss: -0.1292
env0_second_0:                 episode reward: 8.2000,                 loss: -0.0334
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 948.6,                last time consumption/overall running time: 167.1325s / 128258.6204 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.1111
env0_second_0:                 episode reward: 8.7000,                 loss: -0.0079
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 932.55,                last time consumption/overall running time: 163.2122s / 128421.8326 s
env0_first_0:                 episode reward: -9.1000,                 loss: -0.1312
env0_second_0:                 episode reward: 9.1000,                 loss: -0.0820
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 920.8,                last time consumption/overall running time: 159.1517s / 128580.9843 s
env0_first_0:                 episode reward: -9.1000,                 loss: -0.1233
env0_second_0:                 episode reward: 9.1000,                 loss: -0.0552
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 913.25,                last time consumption/overall running time: 156.0684s / 128737.0527 s
env0_first_0:                 episode reward: -9.1500,                 loss: -0.1130
env0_second_0:                 episode reward: 9.1500,                 loss: -0.0622
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 910.15,                last time consumption/overall running time: 157.1710s / 128894.2237 s
env0_first_0:                 episode reward: -9.5000,                 loss: -0.1133
env0_second_0:                 episode reward: 9.5000,                 loss: -0.0466
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 958.2,                last time consumption/overall running time: 164.5790s / 129058.8027 s
env0_first_0:                 episode reward: -8.5500,                 loss: -0.0953
env0_second_0:                 episode reward: 8.5500,                 loss: -0.0664
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 911.1,                last time consumption/overall running time: 157.0071s / 129215.8098 s
env0_first_0:                 episode reward: -9.3000,                 loss: -0.1202
env0_second_0:                 episode reward: 9.3000,                 loss: -0.0888
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 912.8,                last time consumption/overall running time: 158.3376s / 129374.1474 s
env0_first_0:                 episode reward: -9.0000,                 loss: -0.1370
env0_second_0:                 episode reward: 9.0000,                 loss: -0.1182
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 913.25,                last time consumption/overall running time: 156.7886s / 129530.9360 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.1297
env0_second_0:                 episode reward: 8.7000,                 loss: -0.1089
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 925.95,                last time consumption/overall running time: 156.7163s / 129687.6523 s
env0_first_0:                 episode reward: -9.0500,                 loss: -0.1427
env0_second_0:                 episode reward: 9.0500,                 loss: -0.0904
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 954.55,                last time consumption/overall running time: 163.3765s / 129851.0288 s
env0_first_0:                 episode reward: -8.2500,                 loss: -0.1013
env0_second_0:                 episode reward: 8.2500,                 loss: -0.0305
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 909.8,                last time consumption/overall running time: 155.6797s / 130006.7085 s
env0_first_0:                 episode reward: -9.3500,                 loss: -0.1544
env0_second_0:                 episode reward: 9.3500,                 loss: -0.0844
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 909.1,                last time consumption/overall running time: 154.3018s / 130161.0103 s
env0_first_0:                 episode reward: -9.9500,                 loss: -0.1464
env0_second_0:                 episode reward: 9.9500,                 loss: -0.0196
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 913.4,                last time consumption/overall running time: 157.8687s / 130318.8789 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.1221
env0_second_0:                 episode reward: 8.7000,                 loss: -0.0023
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 940.0,                last time consumption/overall running time: 159.0610s / 130477.9399 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.1134
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0673
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 949.1,                last time consumption/overall running time: 162.4861s / 130640.4260 s
env0_first_0:                 episode reward: -8.6500,                 loss: -0.1086
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0276
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 949.45,                last time consumption/overall running time: 164.3212s / 130804.7472 s
env0_first_0:                 episode reward: -8.1000,                 loss: -0.1026
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0145
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 911.7,                last time consumption/overall running time: 157.5079s / 130962.2551 s
env0_first_0:                 episode reward: -9.2500,                 loss: -0.1291
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1929
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 914.05,                last time consumption/overall running time: 156.3265s / 131118.5816 s
env0_first_0:                 episode reward: -8.8500,                 loss: -0.0766
env0_second_0:                 episode reward: 8.8500,                 loss: -0.0128
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 917.2,                last time consumption/overall running time: 157.9074s / 131276.4890 s
env0_first_0:                 episode reward: -9.4000,                 loss: -0.0788
env0_second_0:                 episode reward: 9.4000,                 loss: -0.0203
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 911.75,                last time consumption/overall running time: 153.0520s / 131429.5410 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.0708
env0_second_0:                 episode reward: 9.6000,                 loss: -0.0589
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 907.8,                last time consumption/overall running time: 153.1821s / 131582.7231 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.0948
env0_second_0:                 episode reward: 9.6000,                 loss: -0.0239
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 907.0,                last time consumption/overall running time: 156.8109s / 131739.5340 s
env0_first_0:                 episode reward: -9.8000,                 loss: -0.1339
env0_second_0:                 episode reward: 9.8000,                 loss: -0.0646
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 907.0,                last time consumption/overall running time: 157.1697s / 131896.7037 s
env0_first_0:                 episode reward: -9.9500,                 loss: -0.1505
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0337
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 907.4,                last time consumption/overall running time: 155.5514s / 132052.2551 s
env0_first_0:                 episode reward: -9.6000,                 loss: -0.1614
env0_second_0:                 episode reward: 9.6000,                 loss: -0.1016
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 908.0,                last time consumption/overall running time: 154.0300s / 132206.2851 s
env0_first_0:                 episode reward: -9.6500,                 loss: -0.1540
env0_second_0:                 episode reward: 9.6500,                 loss: -0.1232
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 908.8,                last time consumption/overall running time: 153.4172s / 132359.7023 s
env0_first_0:                 episode reward: -9.5000,                 loss: -0.1734
env0_second_0:                 episode reward: 9.5000,                 loss: -0.0989
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 912.5,                last time consumption/overall running time: 153.7000s / 132513.4023 s
env0_first_0:                 episode reward: -9.0000,                 loss: -0.1496
env0_second_0:                 episode reward: 9.0000,                 loss: 0.2108
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 923.6,                last time consumption/overall running time: 158.7262s / 132672.1285 s
env0_first_0:                 episode reward: -9.1500,                 loss: -0.1298
env0_second_0:                 episode reward: 9.1500,                 loss: -0.0546
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 927.75,                last time consumption/overall running time: 157.9871s / 132830.1155 s
env0_first_0:                 episode reward: -9.4500,                 loss: -0.1378
env0_second_0:                 episode reward: 9.4500,                 loss: -0.0042
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1078.95,                last time consumption/overall running time: 183.0388s / 133013.1543 s
env0_first_0:                 episode reward: -8.2500,                 loss: -0.0240
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0871
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 936.4,                last time consumption/overall running time: 159.6435s / 133172.7978 s
env0_first_0:                 episode reward: -9.0500,                 loss: -0.1314
env0_second_0:                 episode reward: 9.0500,                 loss: -0.0954
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 923.35,                last time consumption/overall running time: 156.7091s / 133329.5069 s
env0_first_0:                 episode reward: -9.4000,                 loss: -0.1280
env0_second_0:                 episode reward: 9.4000,                 loss: 0.3391
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 928.8,                last time consumption/overall running time: 158.2983s / 133487.8052 s
env0_first_0:                 episode reward: -9.4000,                 loss: -0.1243
env0_second_0:                 episode reward: 9.4000,                 loss: 0.2007
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1023.7,                last time consumption/overall running time: 176.7510s / 133664.5562 s
env0_first_0:                 episode reward: -8.5000,                 loss: -0.0336
env0_second_0:                 episode reward: 8.5000,                 loss: 0.3269
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1129.4,                last time consumption/overall running time: 187.6778s / 133852.2340 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.9000,                 loss: 0.8612
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1560.4,                last time consumption/overall running time: 262.8242s / 134115.0582 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0393
env0_second_0:                 episode reward: 4.2000,                 loss: 1.2508
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1700.7,                last time consumption/overall running time: 283.9375s / 134398.9958 s
env0_first_0:                 episode reward: -4.8500,                 loss: -0.0301
env0_second_0:                 episode reward: 4.8500,                 loss: 1.1325
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 2052.65,                last time consumption/overall running time: 341.5225s / 134740.5183 s
env0_first_0:                 episode reward: -4.1000,                 loss: -0.0258
env0_second_0:                 episode reward: 4.1000,                 loss: 0.5486
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 2296.3,                last time consumption/overall running time: 373.7360s / 135114.2543 s
env0_first_0:                 episode reward: -4.5500,                 loss: -0.0415
env0_second_0:                 episode reward: 4.5500,                 loss: 0.4963
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 2195.65,                last time consumption/overall running time: 362.0693s / 135476.3236 s
env0_first_0:                 episode reward: -5.4500,                 loss: -0.0864
env0_second_0:                 episode reward: 5.4500,                 loss: 0.7162
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 2089.05,                last time consumption/overall running time: 345.1352s / 135821.4588 s
env0_first_0:                 episode reward: -6.6500,                 loss: -0.0860
env0_second_0:                 episode reward: 6.6500,                 loss: 0.7739
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2327.9,                last time consumption/overall running time: 383.8314s / 136205.2902 s
env0_first_0:                 episode reward: -4.0000,                 loss: -0.0653
env0_second_0:                 episode reward: 4.0000,                 loss: 0.4215
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 2178.4,                last time consumption/overall running time: 362.1503s / 136567.4405 s
env0_first_0:                 episode reward: -4.7000,                 loss: -0.0240
env0_second_0:                 episode reward: 4.7000,                 loss: 0.4927
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2445.1,                last time consumption/overall running time: 402.5457s / 136969.9862 s
env0_first_0:                 episode reward: -2.3000,                 loss: -0.0374
env0_second_0:                 episode reward: 2.3000,                 loss: 0.6070
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2533.25,                last time consumption/overall running time: 413.3095s / 137383.2958 s
env0_first_0:                 episode reward: -4.4500,                 loss: -0.0231
env0_second_0:                 episode reward: 4.4500,                 loss: 0.9955
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 2175.55,                last time consumption/overall running time: 359.1674s / 137742.4632 s
env0_first_0:                 episode reward: -5.5500,                 loss: -0.0433
env0_second_0:                 episode reward: 5.5500,                 loss: 0.6025
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 2336.8,                last time consumption/overall running time: 387.9619s / 138130.4251 s
env0_first_0:                 episode reward: -4.2500,                 loss: -0.0648
env0_second_0:                 episode reward: 4.2500,                 loss: 0.4743
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1795.35,                last time consumption/overall running time: 296.7482s / 138427.1733 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0221
env0_second_0:                 episode reward: -0.4500,                 loss: 0.7675
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1955.7,                last time consumption/overall running time: 321.8279s / 138749.0012 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0076
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4382
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1699.2,                last time consumption/overall running time: 279.6594s / 139028.6606 s
env0_first_0:                 episode reward: 5.0000,                 loss: -0.0223
env0_second_0:                 episode reward: -5.0000,                 loss: 0.3517
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1786.5,                last time consumption/overall running time: 293.9802s / 139322.6408 s
env0_first_0:                 episode reward: -3.3000,                 loss: -0.0297
env0_second_0:                 episode reward: 3.3000,                 loss: 0.1964
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1840.2,                last time consumption/overall running time: 306.6905s / 139629.3313 s
env0_first_0:                 episode reward: -2.5500,                 loss: -0.0551
env0_second_0:                 episode reward: 2.5500,                 loss: 0.3364
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2114.35,                last time consumption/overall running time: 351.4747s / 139980.8060 s
env0_first_0:                 episode reward: -2.1000,                 loss: -0.0611
env0_second_0:                 episode reward: 2.1000,                 loss: 0.2638
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 2064.95,                last time consumption/overall running time: 340.0716s / 140320.8776 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.0501
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2977
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1944.15,                last time consumption/overall running time: 322.2141s / 140643.0917 s
env0_first_0:                 episode reward: -7.4000,                 loss: -0.1040
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0395
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2145.85,                last time consumption/overall running time: 351.4548s / 140994.5465 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0345
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1613
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1974.3,                last time consumption/overall running time: 326.7368s / 141321.2833 s
env0_first_0:                 episode reward: 2.0500,                 loss: -0.0317
env0_second_0:                 episode reward: -2.0500,                 loss: 0.1551
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1775.4,                last time consumption/overall running time: 292.2010s / 141613.4843 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0894
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1389
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1314.65,                last time consumption/overall running time: 220.4669s / 141833.9512 s
env0_first_0:                 episode reward: 6.3500,                 loss: -0.0660
env0_second_0:                 episode reward: -6.3500,                 loss: 0.2745
env1_first_0:                 episode reward: 7.0500,                 loss: nan
env1_second_0:                 episode reward: -7.0500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1666.15,                last time consumption/overall running time: 275.2939s / 142109.2451 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0027
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2767
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1573.3,                last time consumption/overall running time: 259.4503s / 142368.6954 s
env0_first_0:                 episode reward: -7.3000,                 loss: -0.0872
env0_second_0:                 episode reward: 7.3000,                 loss: 0.2170
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1735.2,                last time consumption/overall running time: 285.9839s / 142654.6793 s
env0_first_0:                 episode reward: -6.8000,                 loss: -0.0906
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0261
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1703.4,                last time consumption/overall running time: 281.0545s / 142935.7339 s
env0_first_0:                 episode reward: -6.3000,                 loss: -0.0681
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0467
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1162.0,                last time consumption/overall running time: 196.2930s / 143132.0269 s
env0_first_0:                 episode reward: -9.0500,                 loss: -0.1058
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0847
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1539.95,                last time consumption/overall running time: 253.7608s / 143385.7876 s
env0_first_0:                 episode reward: -3.8500,                 loss: -0.0217
env0_second_0:                 episode reward: 3.8500,                 loss: 0.1391
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1717.65,                last time consumption/overall running time: 286.2726s / 143672.0602 s
env0_first_0:                 episode reward: -4.9500,                 loss: -0.0374
env0_second_0:                 episode reward: 4.9500,                 loss: 0.4903
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1264.4,                last time consumption/overall running time: 212.2438s / 143884.3040 s
env0_first_0:                 episode reward: -8.8000,                 loss: -0.0828
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0332
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1649.1,                last time consumption/overall running time: 275.4510s / 144159.7550 s
env0_first_0:                 episode reward: -7.9500,                 loss: -0.0475
env0_second_0:                 episode reward: 7.9500,                 loss: 0.3421
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1867.3,                last time consumption/overall running time: 309.3730s / 144469.1281 s
env0_first_0:                 episode reward: -7.0500,                 loss: -0.0243
env0_second_0:                 episode reward: 7.0500,                 loss: 0.3870
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1627.55,                last time consumption/overall running time: 270.3676s / 144739.4957 s
env0_first_0:                 episode reward: -8.9000,                 loss: -0.0647
env0_second_0:                 episode reward: 8.9000,                 loss: 0.7679
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1434.0,                last time consumption/overall running time: 238.4545s / 144977.9502 s
env0_first_0:                 episode reward: -8.4000,                 loss: -0.0338
env0_second_0:                 episode reward: 8.4000,                 loss: 0.4359
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1058.35,                last time consumption/overall running time: 184.2376s / 145162.1879 s
env0_first_0:                 episode reward: -9.1500,                 loss: -0.0976
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0370
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1206.5,                last time consumption/overall running time: 206.8704s / 145369.0582 s
env0_first_0:                 episode reward: -7.3500,                 loss: -0.0442
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0802
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1372.8,                last time consumption/overall running time: 231.2769s / 145600.3351 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0031
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3780
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1314.9,                last time consumption/overall running time: 221.8165s / 145822.1516 s
env0_first_0:                 episode reward: -7.0500,                 loss: -0.0811
env0_second_0:                 episode reward: 7.0500,                 loss: 0.1144
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1385.45,                last time consumption/overall running time: 234.1282s / 146056.2798 s
env0_first_0:                 episode reward: -7.9500,                 loss: -0.0542
env0_second_0:                 episode reward: 7.9500,                 loss: 0.1704
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1373.65,                last time consumption/overall running time: 230.2441s / 146286.5238 s
env0_first_0:                 episode reward: -8.5500,                 loss: -0.0665
env0_second_0:                 episode reward: 8.5500,                 loss: 0.1214
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1345.2,                last time consumption/overall running time: 224.8813s / 146511.4052 s
env0_first_0:                 episode reward: -8.4000,                 loss: -0.0701
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0490
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1427.0,                last time consumption/overall running time: 237.8843s / 146749.2895 s
env0_first_0:                 episode reward: -6.5500,                 loss: -0.0577
env0_second_0:                 episode reward: 6.5500,                 loss: 0.2053
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1651.45,                last time consumption/overall running time: 271.5659s / 147020.8554 s
env0_first_0:                 episode reward: -9.3500,                 loss: -0.0433
env0_second_0:                 episode reward: 9.3500,                 loss: 0.4427
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1628.05,                last time consumption/overall running time: 270.1298s / 147290.9852 s
env0_first_0:                 episode reward: -5.8500,                 loss: -0.0755
env0_second_0:                 episode reward: 5.8500,                 loss: 0.6378
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1378.45,                last time consumption/overall running time: 230.4635s / 147521.4487 s
env0_first_0:                 episode reward: -8.5000,                 loss: -0.1048
env0_second_0:                 episode reward: 8.5000,                 loss: 0.5888
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1350.95,                last time consumption/overall running time: 225.4728s / 147746.9215 s
env0_first_0:                 episode reward: -8.4000,                 loss: -0.1031
env0_second_0:                 episode reward: 8.4000,                 loss: 0.5599
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1298.9,                last time consumption/overall running time: 218.7295s / 147965.6510 s
env0_first_0:                 episode reward: -9.1500,                 loss: -0.1205
env0_second_0:                 episode reward: 9.1500,                 loss: 0.7942
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1246.55,                last time consumption/overall running time: 211.4955s / 148177.1465 s
env0_first_0:                 episode reward: -8.6500,                 loss: -0.1027
env0_second_0:                 episode reward: 8.6500,                 loss: 0.6402
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1347.9,                last time consumption/overall running time: 226.4501s / 148403.5966 s
env0_first_0:                 episode reward: -8.6500,                 loss: -0.0838
env0_second_0:                 episode reward: 8.6500,                 loss: 0.5279
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1445.2,                last time consumption/overall running time: 239.8898s / 148643.4864 s
env0_first_0:                 episode reward: -5.9000,                 loss: -0.0469
env0_second_0:                 episode reward: 5.9000,                 loss: 0.3165
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1351.1,                last time consumption/overall running time: 226.5413s / 148870.0277 s
env0_first_0:                 episode reward: -7.2000,                 loss: -0.0720
env0_second_0:                 episode reward: 7.2000,                 loss: 0.2559
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1475.0,                last time consumption/overall running time: 245.4294s / 149115.4571 s
env0_first_0:                 episode reward: -7.9500,                 loss: -0.0637
env0_second_0:                 episode reward: 7.9500,                 loss: 0.3844
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1662.75,                last time consumption/overall running time: 272.8936s / 149388.3507 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0141
env0_second_0:                 episode reward: 6.4500,                 loss: 0.8057
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1575.8,                last time consumption/overall running time: 262.5856s / 149650.9363 s
env0_first_0:                 episode reward: -8.2500,                 loss: -0.0679
env0_second_0:                 episode reward: 8.2500,                 loss: 0.7422
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1320.15,                last time consumption/overall running time: 222.0286s / 149872.9648 s
env0_first_0:                 episode reward: -8.1500,                 loss: -0.0826
env0_second_0:                 episode reward: 8.1500,                 loss: 0.4019
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1246.5,                last time consumption/overall running time: 209.6209s / 150082.5857 s
env0_first_0:                 episode reward: -6.6000,                 loss: -0.0616
env0_second_0:                 episode reward: 6.6000,                 loss: 0.6414
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1404.15,                last time consumption/overall running time: 233.1312s / 150315.7170 s
env0_first_0:                 episode reward: -8.4500,                 loss: -0.0507
env0_second_0:                 episode reward: 8.4500,                 loss: 0.4995
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1455.0,                last time consumption/overall running time: 241.6645s / 150557.3814 s
env0_first_0:                 episode reward: -7.2500,                 loss: -0.0742
env0_second_0:                 episode reward: 7.2500,                 loss: 0.5688
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1480.2,                last time consumption/overall running time: 245.2635s / 150802.6450 s
env0_first_0:                 episode reward: -7.3500,                 loss: -0.0286
env0_second_0:                 episode reward: 7.3500,                 loss: 0.3704
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1926.8,                last time consumption/overall running time: 316.4978s / 151119.1428 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0065
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2711
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1976.4,                last time consumption/overall running time: 326.1881s / 151445.3308 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0537
env0_second_0:                 episode reward: -1.4500,                 loss: 0.3673
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 2028.95,                last time consumption/overall running time: 334.6190s / 151779.9498 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0229
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2869
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 2043.9,                last time consumption/overall running time: 338.3601s / 152118.3100 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0400
env0_second_0:                 episode reward: 2.3500,                 loss: 0.3726
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 2217.35,                last time consumption/overall running time: 363.3411s / 152481.6511 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.6500,                 loss: 0.3534
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 2067.9,                last time consumption/overall running time: 343.0632s / 152824.7142 s
env0_first_0:                 episode reward: 1.9500,                 loss: -0.0038
env0_second_0:                 episode reward: -1.9500,                 loss: 0.2333
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 2324.0,                last time consumption/overall running time: 383.8584s / 153208.5727 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0088
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2267
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 2223.4,                last time consumption/overall running time: 368.6500s / 153577.2226 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.0126
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2542
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1917.6,                last time consumption/overall running time: 315.0737s / 153892.2963 s
env0_first_0:                 episode reward: -7.3000,                 loss: -0.0278
env0_second_0:                 episode reward: 7.3000,                 loss: 0.2288
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1777.75,                last time consumption/overall running time: 295.1290s / 154187.4253 s
env0_first_0:                 episode reward: -8.6500,                 loss: -0.0624
env0_second_0:                 episode reward: 8.6500,                 loss: 0.2066
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1711.95,                last time consumption/overall running time: 282.1885s / 154469.6139 s
env0_first_0:                 episode reward: -8.0500,                 loss: -0.0278
env0_second_0:                 episode reward: 8.0500,                 loss: 0.4417
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1814.7,                last time consumption/overall running time: 300.8623s / 154770.4761 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0324
env0_second_0:                 episode reward: 6.7500,                 loss: 0.5428
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1892.5,                last time consumption/overall running time: 311.3963s / 155081.8724 s
env0_first_0:                 episode reward: -8.0000,                 loss: -0.0657
env0_second_0:                 episode reward: 8.0000,                 loss: 0.1817
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1858.95,                last time consumption/overall running time: 308.5685s / 155390.4409 s
env0_first_0:                 episode reward: -7.9000,                 loss: -0.0696
env0_second_0:                 episode reward: 7.9000,                 loss: 1.1818
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1899.05,                last time consumption/overall running time: 316.5036s / 155706.9445 s
env0_first_0:                 episode reward: -8.3000,                 loss: -0.0468
env0_second_0:                 episode reward: 8.3000,                 loss: 0.1482
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 2038.95,                last time consumption/overall running time: 334.4135s / 156041.3580 s
env0_first_0:                 episode reward: -6.8000,                 loss: -0.0093
env0_second_0:                 episode reward: 6.8000,                 loss: 0.7437
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 2182.1,                last time consumption/overall running time: 360.7163s / 156402.0743 s
env0_first_0:                 episode reward: -2.1000,                 loss: -0.0126
env0_second_0:                 episode reward: 2.1000,                 loss: 0.5668
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 2373.8,                last time consumption/overall running time: 394.8665s / 156796.9409 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0207
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3297
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 2683.35,                last time consumption/overall running time: 440.4299s / 157237.3708 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.0297
env0_second_0:                 episode reward: 1.3500,                 loss: 0.4470
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 2268.35,                last time consumption/overall running time: 374.1830s / 157611.5538 s
env0_first_0:                 episode reward: -2.0000,                 loss: -0.0116
env0_second_0:                 episode reward: 2.0000,                 loss: 0.4256
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 2398.9,                last time consumption/overall running time: 402.4387s / 158013.9926 s
env0_first_0:                 episode reward: -4.4000,                 loss: -0.0298
env0_second_0:                 episode reward: 4.4000,                 loss: 0.3858
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1712.8,                last time consumption/overall running time: 288.5902s / 158302.5828 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0024
env0_second_0:                 episode reward: -0.5000,                 loss: 0.5638
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1759.0,                last time consumption/overall running time: 294.2968s / 158596.8796 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0399
env0_second_0:                 episode reward: 8.7000,                 loss: 0.4887
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1906.85,                last time consumption/overall running time: 315.2825s / 158912.1621 s
env0_first_0:                 episode reward: -8.2500,                 loss: -0.0353
env0_second_0:                 episode reward: 8.2500,                 loss: 0.6043
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1836.45,                last time consumption/overall running time: 306.6547s / 159218.8168 s
env0_first_0:                 episode reward: -7.2500,                 loss: -0.0486
env0_second_0:                 episode reward: 7.2500,                 loss: 0.2198
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1732.7,                last time consumption/overall running time: 290.1180s / 159508.9348 s
env0_first_0:                 episode reward: -7.0500,                 loss: -0.0531
env0_second_0:                 episode reward: 7.0500,                 loss: 0.3313
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1455.05,                last time consumption/overall running time: 246.6898s / 159755.6247 s
env0_first_0:                 episode reward: -7.1500,                 loss: -0.0167
env0_second_0:                 episode reward: 7.1500,                 loss: 0.1927
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1198.3,                last time consumption/overall running time: 203.8940s / 159959.5187 s
env0_first_0:                 episode reward: -8.9500,                 loss: -0.0465
env0_second_0:                 episode reward: 8.9500,                 loss: 0.4434
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1632.8,                last time consumption/overall running time: 273.4293s / 160232.9479 s
env0_first_0:                 episode reward: -7.2000,                 loss: -0.0210
env0_second_0:                 episode reward: 7.2000,                 loss: 0.2913
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1257.3,                last time consumption/overall running time: 212.2751s / 160445.2231 s
env0_first_0:                 episode reward: -8.5500,                 loss: -0.0609
env0_second_0:                 episode reward: 8.5500,                 loss: 0.2800
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1089.2,                last time consumption/overall running time: 183.5823s / 160628.8054 s
env0_first_0:                 episode reward: -8.8000,                 loss: -0.1045
env0_second_0:                 episode reward: 8.8000,                 loss: 0.5387
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1076.65,                last time consumption/overall running time: 184.0990s / 160812.9044 s
env0_first_0:                 episode reward: -8.7500,                 loss: -0.0942
env0_second_0:                 episode reward: 8.7500,                 loss: 0.1097
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1126.75,                last time consumption/overall running time: 190.9092s / 161003.8136 s
env0_first_0:                 episode reward: -8.6500,                 loss: -0.0775
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0591
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1196.9,                last time consumption/overall running time: 201.7257s / 161205.5393 s
env0_first_0:                 episode reward: -7.4000,                 loss: -0.0021
env0_second_0:                 episode reward: 7.4000,                 loss: 0.3701
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1114.1,                last time consumption/overall running time: 188.1937s / 161393.7330 s
env0_first_0:                 episode reward: -8.8000,                 loss: -0.0912
env0_second_0:                 episode reward: 8.8000,                 loss: 0.2563
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1651.9,                last time consumption/overall running time: 273.6073s / 161667.3403 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0118
env0_second_0:                 episode reward: 7.9000,                 loss: 0.9788
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1861.95,                last time consumption/overall running time: 304.8050s / 161972.1453 s
env0_first_0:                 episode reward: -7.2500,                 loss: -0.0502
env0_second_0:                 episode reward: 7.2500,                 loss: 0.9239
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1820.65,                last time consumption/overall running time: 300.4950s / 162272.6403 s
env0_first_0:                 episode reward: -8.1000,                 loss: -0.0588
env0_second_0:                 episode reward: 8.1000,                 loss: 0.7924
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1545.15,                last time consumption/overall running time: 258.3896s / 162531.0300 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0272
env0_second_0:                 episode reward: 8.3500,                 loss: 1.0549
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1715.85,                last time consumption/overall running time: 283.3297s / 162814.3597 s
env0_first_0:                 episode reward: -5.6000,                 loss: -0.0523
env0_second_0:                 episode reward: 5.6000,                 loss: 0.4173
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 2067.0,                last time consumption/overall running time: 343.0689s / 163157.4286 s
env0_first_0:                 episode reward: -5.0000,                 loss: -0.0469
env0_second_0:                 episode reward: 5.0000,                 loss: 0.2821
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1661.3,                last time consumption/overall running time: 275.1866s / 163432.6152 s
env0_first_0:                 episode reward: -2.8500,                 loss: -0.0413
env0_second_0:                 episode reward: 2.8500,                 loss: 0.4570
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1584.4,                last time consumption/overall running time: 262.4634s / 163695.0785 s
env0_first_0:                 episode reward: 5.3000,                 loss: -0.0426
env0_second_0:                 episode reward: -5.3000,                 loss: 0.4552
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1736.4,                last time consumption/overall running time: 287.0462s / 163982.1247 s
env0_first_0:                 episode reward: -7.3000,                 loss: -0.0835
env0_second_0:                 episode reward: 7.3000,                 loss: 0.2713
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 2022.95,                last time consumption/overall running time: 337.9930s / 164320.1177 s
env0_first_0:                 episode reward: -5.5500,                 loss: -0.0757
env0_second_0:                 episode reward: 5.5500,                 loss: 0.2326
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1823.05,                last time consumption/overall running time: 305.8052s / 164625.9228 s
env0_first_0:                 episode reward: -8.4500,                 loss: -0.0705
env0_second_0:                 episode reward: 8.4500,                 loss: 0.3260
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1726.0,                last time consumption/overall running time: 292.3473s / 164918.2701 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0110
env0_second_0:                 episode reward: -3.1500,                 loss: 0.5050
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1771.5,                last time consumption/overall running time: 295.9591s / 165214.2292 s
env0_first_0:                 episode reward: 8.8000,                 loss: -0.0910
env0_second_0:                 episode reward: -8.8000,                 loss: 0.3137
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1766.05,                last time consumption/overall running time: 296.9155s / 165511.1447 s
env0_first_0:                 episode reward: -4.0000,                 loss: -0.0143
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2712
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1908.35,                last time consumption/overall running time: 316.3733s / 165827.5180 s
env0_first_0:                 episode reward: -6.5000,                 loss: -0.0423
env0_second_0:                 episode reward: 6.5000,                 loss: 0.5983
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1663.7,                last time consumption/overall running time: 275.2956s / 166102.8136 s
env0_first_0:                 episode reward: -8.2000,                 loss: -0.1112
env0_second_0:                 episode reward: 8.2000,                 loss: 2.4230
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1804.4,                last time consumption/overall running time: 301.6907s / 166404.5043 s
env0_first_0:                 episode reward: -8.9500,                 loss: -0.1201
env0_second_0:                 episode reward: 8.9500,                 loss: 0.4947
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1820.15,                last time consumption/overall running time: 300.6320s / 166705.1363 s
env0_first_0:                 episode reward: -9.5000,                 loss: -0.1157
env0_second_0:                 episode reward: 9.5000,                 loss: 0.2707
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1921.9,                last time consumption/overall running time: 319.9368s / 167025.0731 s
env0_first_0:                 episode reward: -8.4500,                 loss: -0.0807
env0_second_0:                 episode reward: 8.4500,                 loss: 0.2774
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1611.15,                last time consumption/overall running time: 270.5699s / 167295.6429 s
env0_first_0:                 episode reward: -8.0500,                 loss: -0.0829
env0_second_0:                 episode reward: 8.0500,                 loss: 0.1958
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1716.35,                last time consumption/overall running time: 283.7794s / 167579.4224 s
env0_first_0:                 episode reward: -9.0000,                 loss: -0.1008
env0_second_0:                 episode reward: 9.0000,                 loss: 0.8953
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1518.9,                last time consumption/overall running time: 255.0468s / 167834.4692 s
env0_first_0:                 episode reward: -9.0500,                 loss: -0.0757
env0_second_0:                 episode reward: 9.0500,                 loss: 0.3774
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1262.95,                last time consumption/overall running time: 210.8120s / 168045.2812 s
env0_first_0:                 episode reward: -5.9500,                 loss: -0.0298
env0_second_0:                 episode reward: 5.9500,                 loss: 0.2740
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1352.15,                last time consumption/overall running time: 229.5148s / 168274.7960 s
env0_first_0:                 episode reward: -8.7000,                 loss: -0.0644
env0_second_0:                 episode reward: 8.7000,                 loss: 0.1146
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1778.3,                last time consumption/overall running time: 297.3930s / 168572.1890 s
env0_first_0:                 episode reward: -5.7500,                 loss: -0.0365
env0_second_0:                 episode reward: 5.7500,                 loss: 0.4012
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1730.2,                last time consumption/overall running time: 288.6351s / 168860.8241 s
env0_first_0:                 episode reward: -9.2500,                 loss: -0.1086
env0_second_0:                 episode reward: 9.2500,                 loss: 0.2498
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1587.4,                last time consumption/overall running time: 266.0476s / 169126.8717 s
env0_first_0:                 episode reward: -8.7500,                 loss: -0.0845
env0_second_0:                 episode reward: 8.7500,                 loss: 0.1578
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1617.55,                last time consumption/overall running time: 269.8943s / 169396.7660 s
env0_first_0:                 episode reward: -8.5500,                 loss: -0.1047
env0_second_0:                 episode reward: 8.5500,                 loss: 0.1430
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1977.6,                last time consumption/overall running time: 328.7774s / 169725.5434 s
env0_first_0:                 episode reward: -8.1500,                 loss: -0.1044
env0_second_0:                 episode reward: 8.1500,                 loss: 0.1463
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1341.75,                last time consumption/overall running time: 225.9802s / 169951.5236 s
env0_first_0:                 episode reward: -8.8500,                 loss: -0.1011
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0991
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1618.8,                last time consumption/overall running time: 271.6532s / 170223.1768 s
env0_first_0:                 episode reward: -8.5500,                 loss: -0.0818
env0_second_0:                 episode reward: 8.5500,                 loss: 0.5374
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 2437.9,                last time consumption/overall running time: 401.9394s / 170625.1162 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.0472
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2504
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1907.8,                last time consumption/overall running time: 313.7868s / 170938.9030 s
env0_first_0:                 episode reward: -8.3000,                 loss: -0.0964
env0_second_0:                 episode reward: 8.3000,                 loss: 0.1166
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1872.45,                last time consumption/overall running time: 310.4205s / 171249.3235 s
env0_first_0:                 episode reward: -2.1500,                 loss: -0.0580
env0_second_0:                 episode reward: 2.1500,                 loss: 0.2928
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 2338.25,                last time consumption/overall running time: 386.1011s / 171635.4246 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.0688
env0_second_0:                 episode reward: 3.0000,                 loss: 0.1649
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 2501.4,                last time consumption/overall running time: 414.6843s / 172050.1089 s
env0_first_0:                 episode reward: -2.8500,                 loss: -0.0597
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0851
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 2264.3,                last time consumption/overall running time: 373.3386s / 172423.4475 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0478
env0_second_0:                 episode reward: 2.0500,                 loss: 0.1982
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 2421.9,                last time consumption/overall running time: 398.9890s / 172822.4365 s
env0_first_0:                 episode reward: -1.8500,                 loss: -0.0240
env0_second_0:                 episode reward: 1.8500,                 loss: 0.2655
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 2270.75,                last time consumption/overall running time: 376.3549s / 173198.7914 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0075
env0_second_0:                 episode reward: 1.9000,                 loss: 0.2319
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 2422.9,                last time consumption/overall running time: 397.2171s / 173596.0085 s
env0_first_0:                 episode reward: -3.6500,                 loss: -0.0550
env0_second_0:                 episode reward: 3.6500,                 loss: 0.1444
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 2275.0,                last time consumption/overall running time: 371.7851s / 173967.7936 s
env0_first_0:                 episode reward: -2.5000,                 loss: -0.0348
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1340
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 2570.0,                last time consumption/overall running time: 422.2503s / 174390.0439 s
env0_first_0:                 episode reward: -3.8000,                 loss: -0.0624
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0183
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1843.1,                last time consumption/overall running time: 307.2590s / 174697.3029 s
env0_first_0:                 episode reward: -6.0500,                 loss: -0.0550
env0_second_0:                 episode reward: 6.0500,                 loss: 0.2329
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 2930.25,                last time consumption/overall running time: 480.6331s / 175177.9361 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.0487
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1438
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 2442.75,                last time consumption/overall running time: 403.4758s / 175581.4119 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0321
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1493
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1819.15,                last time consumption/overall running time: 304.3870s / 175885.7989 s
env0_first_0:                 episode reward: -5.2500,                 loss: -0.0242
env0_second_0:                 episode reward: 5.2500,                 loss: 0.2870
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 2480.85,                last time consumption/overall running time: 408.2809s / 176294.0798 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0098
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2384
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 2370.6,                last time consumption/overall running time: 390.5041s / 176684.5839 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0227
env0_second_0:                 episode reward: -0.9500,                 loss: 0.1748
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 2611.15,                last time consumption/overall running time: 429.8031s / 177114.3870 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0442
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1701
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 2490.5,                last time consumption/overall running time: 411.1672s / 177525.5542 s
env0_first_0:                 episode reward: -2.6500,                 loss: -0.0100
env0_second_0:                 episode reward: 2.6500,                 loss: 0.7641
env1_first_0:                 episode reward: -3.4000,                 loss: nanLoad surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 2697.4,                last time consumption/overall running time: 443.7437s / 177969.2980 s
env0_first_0:                 episode reward: -3.5000,                 loss: -0.0386
env0_second_0:                 episode reward: 3.5000,                 loss: 0.7004
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 2465.65,                last time consumption/overall running time: 408.0163s / 178377.3142 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0222
env0_second_0:                 episode reward: 0.3500,                 loss: 0.6482
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 2410.0,                last time consumption/overall running time: 396.5790s / 178773.8932 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0133
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4397
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 2373.45,                last time consumption/overall running time: 393.8254s / 179167.7186 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0049
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3887
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1761.8,                last time consumption/overall running time: 290.1512s / 179457.8699 s
env0_first_0:                 episode reward: 5.5500,                 loss: -0.0142
env0_second_0:                 episode reward: -5.5500,                 loss: 0.3138
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1615.35,                last time consumption/overall running time: 266.9505s / 179724.8204 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0079
env0_second_0:                 episode reward: 6.0500,                 loss: 0.4088
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1625.5,                last time consumption/overall running time: 270.0455s / 179994.8659 s
env0_first_0:                 episode reward: -4.4500,                 loss: -0.0454
env0_second_0:                 episode reward: 4.4500,                 loss: 0.2813
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1966.0,                last time consumption/overall running time: 325.6401s / 180320.5060 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0007
env0_second_0:                 episode reward: -1.9000,                 loss: 0.3395
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1770.8,                last time consumption/overall running time: 291.2218s / 180611.7278 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0258
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3276
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 2048.35,                last time consumption/overall running time: 337.8875s / 180949.6153 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0180
env0_second_0:                 episode reward: -2.4000,                 loss: 0.2432
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
