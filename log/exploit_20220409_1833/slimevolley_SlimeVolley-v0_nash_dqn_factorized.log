pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
random seed: 37
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f8895e46240>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220409_1833/slimevolley_SlimeVolley-v0_nash_dqn_factorized/50000_0
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQNFactorized', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220409_1833/slimevolley_SlimeVolley-v0_nash_dqn_factorized/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_factorized', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220409_1833_exploit/slimevolley_SlimeVolley-v0_nash_dqn_factorized. 
 Save logs to: /home/zihan/research/MARS/data/log/20220409_1833_exploit/slimevolley_SlimeVolley-v0_nash_dqn_factorized.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.9934s / 5.9934 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0050
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 112.1594s / 118.1528 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0041
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 112.6138s / 230.7666 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0185
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 113.7827s / 344.5493 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0428
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 115.8320s / 460.3813 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0748
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 116.5523s / 576.9336 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.1098
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 117.3812s / 694.3148 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.1414
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 118.7296s / 813.0443 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.1681
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 118.5423s / 931.5866 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.1831
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 120.2834s / 1051.8700 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.2030
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 120.6025s / 1172.4726 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.2455
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.5444s / 1296.0170 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.2872
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.0655s / 1419.0825 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.3312
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1634s / 1544.2459 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.3650
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8077s / 1670.0536 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.4015
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.0702s / 1796.1239 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.4135
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.8993s / 1924.0232 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.4279
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8588s / 2049.8820 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.4312
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.7249s / 2176.6069 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.4613
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1201s / 2301.7270 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.4802
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.9484s / 2428.6753 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.5024
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.2866s / 2552.9620 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.5170
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.3845s / 2680.3464 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.5275
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1491s / 2805.4955 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.5348
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.5472s / 2932.0427 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.5552
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4532s / 3060.4959 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.5798
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7811s / 3186.2770 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.5849
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.5208s / 3313.7979 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.5756
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7481s / 3439.5460 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.5774
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.0306s / 3567.5766 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.5775
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.2170s / 3694.7936 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.5935
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.3986s / 3821.1921 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.5664
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5091s / 3950.7012 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.5514
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.2998s / 4079.0010 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.5481
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.7109s / 4207.7119 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.5532
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8128s / 4336.5246 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.5506
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.4474s / 4462.9720 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.5557
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7789s / 4588.7509 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.5623
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.7769s / 4716.5278 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.5677
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.5419s / 4843.0697 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.5627
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4066s / 4971.4763 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.5647
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.6378s / 5101.1141 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.5610
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.9242s / 5229.0383 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.5533
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.2748s / 5354.3130 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.5702
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1299s / 5483.4430 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.5457
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.2436s / 5611.6866 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.5337
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.0423s / 5738.7288 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.5184
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.4657s / 5868.1945 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.5036
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5672s / 5997.7617 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.4765
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.0665s / 6127.8282 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.4373
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.9093s / 6256.7375 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.4152
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.6976s / 6384.4350 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.3952
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4725s / 6512.9075 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.3760
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.6274s / 6641.5349 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.3646
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.2294s / 6769.7643 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.3388
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.2454s / 6899.0097 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.3203
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.0327s / 7028.0424 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.3141
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.9164s / 7157.9589 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.3146
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4598s / 7286.4187 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.3044
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.2290s / 7414.6476 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.2801
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.9392s / 7544.5868 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.2712
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.2281s / 7672.8149 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.2775
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.0930s / 7800.9079 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.2912
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4650s / 7929.3729 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.2797
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.0949s / 8059.4678 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.2786
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.6829s / 8188.1507 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.2734
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.6913s / 8315.8420 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.2924
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.5132s / 8447.3553 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.2832
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5471s / 8576.9023 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.2731
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.4983s / 8705.4006 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.2542
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5594s / 8834.9600 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.2347
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.6411s / 8962.6011 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.2228
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.4428s / 9090.0439 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.1971
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.5345s / 9218.5784 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.1852
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8553s / 9347.4337 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.1618
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.2575s / 9476.6912 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.1426
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.6004s / 9606.2916 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.1203
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.0327s / 9736.3243 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.1065
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.0740s / 9867.3983 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0979
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8431s / 9996.2414 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0898
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.3439s / 10125.5853 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0861
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.7328s / 10255.3181 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0833
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.3341s / 10382.6522 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0806
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.3543s / 10511.0065 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0764
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.9616s / 10640.9682 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0734
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5663s / 10770.5345 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0733
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.2917s / 10900.8262 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0666
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1077s / 11029.9338 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0652
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.1765s / 11158.1104 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0631
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.5827s / 11286.6931 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0609
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.4025s / 11416.0956 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0596
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1033s / 11545.1989 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0570
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.7655s / 11675.9644 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0580
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.2251s / 11803.1895 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0562
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.6278s / 11932.8174 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0542
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.9735s / 12062.7909 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0521
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.9015s / 12191.6924 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0515
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.9604s / 12322.6528 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0496
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.5278s / 12451.1806 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0455
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.9584s / 12581.1389 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0430
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5438s / 12710.6827 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0438
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.5694s / 12841.2522 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0421
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.6707s / 12971.9229 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0411
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5608s / 13101.4837 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0448
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8614s / 13230.3451 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0436
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.7571s / 13360.1022 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0415
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.3370s / 13488.4392 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0392
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.0880s / 13616.5272 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0386
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.1626s / 13747.6898 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0352
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.2502s / 13876.9400 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0338
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.0942s / 14007.0342 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0353
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5142s / 14136.5484 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0362
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.3814s / 14266.9298 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0368
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8849s / 14395.8147 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0353
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.3413s / 14525.1560 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0333
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.9221s / 14654.0781 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0317
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1360s / 14783.2141 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0317
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.6099s / 14913.8240 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0311
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.4479s / 15043.2718 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0288
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.8172s / 15172.0890 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0270
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.3307s / 15301.4197 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0263
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.1487s / 15429.5683 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0253
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.1576s / 15556.7259 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0243
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1379s / 15685.8638 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0236
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.2224s / 15816.0862 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0253
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.1589s / 15945.2452 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0255
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.5035s / 16073.7486 s