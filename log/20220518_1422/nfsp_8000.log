pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fe6653b8e10>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/8000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_8000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_8000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7217s / 0.7217 s
agent0:                 episode reward: -1.0083,                 loss: nan
agent1:                 episode reward: 1.0083,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 0.9188 s
agent0:                 episode reward: -0.0052,                 loss: nan
agent1:                 episode reward: 0.0052,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 1.1177 s
agent0:                 episode reward: 0.0297,                 loss: nan
agent1:                 episode reward: -0.0297,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 1.3159 s
agent0:                 episode reward: -0.0361,                 loss: nan
agent1:                 episode reward: 0.0361,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 1.5131 s
agent0:                 episode reward: -0.0201,                 loss: nan
agent1:                 episode reward: 0.0201,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 1.7106 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 1.9099 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 2.1113 s
agent0:                 episode reward: -0.1118,                 loss: nan
agent1:                 episode reward: 0.1118,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 2.3071 s
agent0:                 episode reward: -0.0750,                 loss: nan
agent1:                 episode reward: 0.0750,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 2.5068 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 2.7081 s
agent0:                 episode reward: 0.0900,                 loss: nan
agent1:                 episode reward: -0.0900,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 2.9102 s
agent0:                 episode reward: -0.1185,                 loss: nan
agent1:                 episode reward: 0.1185,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 3.1102 s
agent0:                 episode reward: -0.0742,                 loss: nan
agent1:                 episode reward: 0.0742,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 3.3106 s
agent0:                 episode reward: -0.2098,                 loss: nan
agent1:                 episode reward: 0.2098,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 3.5081 s
agent0:                 episode reward: -0.0907,                 loss: nan
agent1:                 episode reward: 0.0907,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 3.7062 s
agent0:                 episode reward: 0.1224,                 loss: nan
agent1:                 episode reward: -0.1224,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 3.9033 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 4.1047 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 4.3027 s
agent0:                 episode reward: -0.0542,                 loss: nan
agent1:                 episode reward: 0.0542,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 4.5005 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 4.7013 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 4.8999 s
agent0:                 episode reward: -0.0333,                 loss: nan
agent1:                 episode reward: 0.0333,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 5.0930 s
agent0:                 episode reward: 0.2950,                 loss: nan
agent1:                 episode reward: -0.2950,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 5.2942 s
agent0:                 episode reward: -0.0868,                 loss: nan
agent1:                 episode reward: 0.0868,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 5.4876 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1894s / 5.6769 s
agent0:                 episode reward: -0.1331,                 loss: nan
agent1:                 episode reward: 0.1331,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 5.8713 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 6.0669 s
agent0:                 episode reward: 0.1759,                 loss: nan
agent1:                 episode reward: -0.1759,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1925s / 6.2594 s
agent0:                 episode reward: -0.0493,                 loss: nan
agent1:                 episode reward: 0.0493,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 6.4567 s
agent0:                 episode reward: -0.0776,                 loss: nan
agent1:                 episode reward: 0.0776,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 6.6546 s
agent0:                 episode reward: -0.3156,                 loss: nan
agent1:                 episode reward: 0.3156,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 6.8495 s
agent0:                 episode reward: 0.0027,                 loss: nan
agent1:                 episode reward: -0.0027,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 7.0444 s
agent0:                 episode reward: -0.4231,                 loss: nan
agent1:                 episode reward: 0.4231,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 7.2379 s
agent0:                 episode reward: -0.0557,                 loss: nan
agent1:                 episode reward: 0.0557,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 7.4332 s
agent0:                 episode reward: -0.0638,                 loss: nan
agent1:                 episode reward: 0.0638,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 7.6293 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 7.8235 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 8.0224 s
agent0:                 episode reward: -0.0333,                 loss: nan
agent1:                 episode reward: 0.0333,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 8.2203 s
agent0:                 episode reward: -0.0854,                 loss: nan
agent1:                 episode reward: 0.0854,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 8.4200 s
agent0:                 episode reward: -0.4512,                 loss: nan
agent1:                 episode reward: 0.4512,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 8.6131 s
agent0:                 episode reward: 0.1894,                 loss: nan
agent1:                 episode reward: -0.1894,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 8.8106 s
agent0:                 episode reward: -0.4999,                 loss: nan
agent1:                 episode reward: 0.4999,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 9.0094 s
agent0:                 episode reward: -0.1912,                 loss: nan
agent1:                 episode reward: 0.1912,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 9.2055 s
agent0:                 episode reward: -0.0456,                 loss: nan
agent1:                 episode reward: 0.0456,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 9.4033 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 9.6022 s
agent0:                 episode reward: -0.0056,                 loss: nan
agent1:                 episode reward: 0.0056,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 9.7970 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 9.9910 s
agent0:                 episode reward: -0.2959,                 loss: nan
agent1:                 episode reward: 0.2959,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.1899 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 10.3893 s
agent0:                 episode reward: -0.1437,                 loss: nan
agent1:                 episode reward: 0.1437,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 10.5907 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 10.7890 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 10.9875 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 11.1862 s
agent0:                 episode reward: 0.0091,                 loss: nan
agent1:                 episode reward: -0.0091,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 11.3781 s
agent0:                 episode reward: 0.3429,                 loss: nan
agent1:                 episode reward: -0.3429,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 11.5725 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 11.7673 s
agent0:                 episode reward: 0.0651,                 loss: nan
agent1:                 episode reward: -0.0651,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 11.9660 s
agent0:                 episode reward: -0.0457,                 loss: nan
agent1:                 episode reward: 0.0457,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 12.1622 s
agent0:                 episode reward: 0.2926,                 loss: nan
agent1:                 episode reward: -0.2926,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 12.3578 s
agent0:                 episode reward: -0.0602,                 loss: nan
agent1:                 episode reward: 0.0602,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 12.5546 s
agent0:                 episode reward: -0.1059,                 loss: nan
agent1:                 episode reward: 0.1059,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 12.7543 s
agent0:                 episode reward: -0.0668,                 loss: nan
agent1:                 episode reward: 0.0668,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 12.9449 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 13.1440 s
agent0:                 episode reward: -0.1864,                 loss: nan
agent1:                 episode reward: 0.1864,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 13.3386 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 13.5409 s
agent0:                 episode reward: -0.0653,                 loss: nan
agent1:                 episode reward: 0.0653,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 13.7399 s
agent0:                 episode reward: -0.1259,                 loss: nan
agent1:                 episode reward: 0.1259,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 13.9385 s
agent0:                 episode reward: -0.1639,                 loss: nan
agent1:                 episode reward: 0.1639,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 14.1326 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 14.3307 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 14.5251 s
agent0:                 episode reward: 0.3328,                 loss: nan
agent1:                 episode reward: -0.3328,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 14.7179 s
agent0:                 episode reward: -0.1750,                 loss: nan
agent1:                 episode reward: 0.1750,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 14.9180 s
agent0:                 episode reward: -0.0874,                 loss: nan
agent1:                 episode reward: 0.0874,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 15.1181 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 15.3179 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 15.5147 s
agent0:                 episode reward: 0.3223,                 loss: nan
agent1:                 episode reward: -0.3223,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 15.7114 s
agent0:                 episode reward: -0.0811,                 loss: nan
agent1:                 episode reward: 0.0811,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 15.9119 s
agent0:                 episode reward: -0.2225,                 loss: nan
agent1:                 episode reward: 0.2225,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 16.1102 s
agent0:                 episode reward: 0.0785,                 loss: nan
agent1:                 episode reward: -0.0785,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 16.3059 s
agent0:                 episode reward: 0.1801,                 loss: nan
agent1:                 episode reward: -0.1801,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 16.5042 s
agent0:                 episode reward: -0.0974,                 loss: nan
agent1:                 episode reward: 0.0974,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 16.7028 s
agent0:                 episode reward: -0.2618,                 loss: nan
agent1:                 episode reward: 0.2618,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 16.9038 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 17.1001 s
agent0:                 episode reward: 0.0278,                 loss: nan
agent1:                 episode reward: -0.0278,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 17.2969 s
agent0:                 episode reward: 0.0347,                 loss: nan
agent1:                 episode reward: -0.0347,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 17.4948 s
agent0:                 episode reward: -0.0916,                 loss: nan
agent1:                 episode reward: 0.0916,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 17.6968 s
agent0:                 episode reward: -0.0614,                 loss: nan
agent1:                 episode reward: 0.0614,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.8963 s
agent0:                 episode reward: 0.3383,                 loss: nan
agent1:                 episode reward: -0.3383,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 18.0960 s
agent0:                 episode reward: -0.0338,                 loss: nan
agent1:                 episode reward: 0.0338,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 18.2929 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 18.4919 s
agent0:                 episode reward: -0.3873,                 loss: nan
agent1:                 episode reward: 0.3873,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 18.6927 s
agent0:                 episode reward: -0.1138,                 loss: nan
agent1:                 episode reward: 0.1138,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 18.8939 s
agent0:                 episode reward: 0.0002,                 loss: nan
agent1:                 episode reward: -0.0002,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 19.0965 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 19.2987 s
agent0:                 episode reward: -0.0952,                 loss: nan
agent1:                 episode reward: 0.0952,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 19.4948 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 19.6909 s
agent0:                 episode reward: -0.2167,                 loss: nan
agent1:                 episode reward: 0.2167,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 19.8869 s
agent0:                 episode reward: -0.2229,                 loss: nan
agent1:                 episode reward: 0.2229,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 20.0827 s
agent0:                 episode reward: -0.0358,                 loss: nan
agent1:                 episode reward: 0.0358,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 20.2823 s
agent0:                 episode reward: -0.2386,                 loss: nan
agent1:                 episode reward: 0.2386,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 20.4800 s
agent0:                 episode reward: 0.0776,                 loss: nan
agent1:                 episode reward: -0.0776,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2043s / 20.6844 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 20.8801 s
agent0:                 episode reward: 0.2467,                 loss: nan
agent1:                 episode reward: -0.2467,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 21.0790 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 21.2768 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 21.4726 s
agent0:                 episode reward: -0.2988,                 loss: nan
agent1:                 episode reward: 0.2988,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 21.6668 s
agent0:                 episode reward: 0.4330,                 loss: nan
agent1:                 episode reward: -0.4330,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 21.8683 s
agent0:                 episode reward: -0.0359,                 loss: nan
agent1:                 episode reward: 0.0359,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 22.0660 s
agent0:                 episode reward: 0.1966,                 loss: nan
agent1:                 episode reward: -0.1966,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 22.2645 s
agent0:                 episode reward: 0.2613,                 loss: nan
agent1:                 episode reward: -0.2613,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 22.4645 s
agent0:                 episode reward: 0.3148,                 loss: nan
agent1:                 episode reward: -0.3148,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 22.6616 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 22.8608 s
agent0:                 episode reward: -0.0486,                 loss: nan
agent1:                 episode reward: 0.0486,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 23.0608 s
agent0:                 episode reward: -0.1425,                 loss: nan
agent1:                 episode reward: 0.1425,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 23.2602 s
agent0:                 episode reward: -0.4977,                 loss: nan
agent1:                 episode reward: 0.4977,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 23.4597 s
agent0:                 episode reward: 0.2349,                 loss: nan
agent1:                 episode reward: -0.2349,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 23.6619 s
agent0:                 episode reward: -0.2142,                 loss: nan
agent1:                 episode reward: 0.2142,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.8597 s
agent0:                 episode reward: 0.1005,                 loss: nan
agent1:                 episode reward: -0.1005,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 24.0554 s
agent0:                 episode reward: 0.1138,                 loss: nan
agent1:                 episode reward: -0.1138,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 24.2521 s
agent0:                 episode reward: 0.0037,                 loss: nan
agent1:                 episode reward: -0.0037,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 24.4510 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 24.6459 s
agent0:                 episode reward: 0.0819,                 loss: nan
agent1:                 episode reward: -0.0819,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 24.8439 s
agent0:                 episode reward: 0.4080,                 loss: nan
agent1:                 episode reward: -0.4080,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 25.0411 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 25.2375 s
agent0:                 episode reward: -0.0399,                 loss: nan
agent1:                 episode reward: 0.0399,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 25.4417 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 25.6351 s
agent0:                 episode reward: -0.2052,                 loss: nan
agent1:                 episode reward: 0.2052,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 25.8325 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 26.0304 s
agent0:                 episode reward: 0.0006,                 loss: nan
agent1:                 episode reward: -0.0006,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 26.2296 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1854s / 26.4150 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 26.6131 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 26.8126 s
agent0:                 episode reward: -0.1397,                 loss: nan
agent1:                 episode reward: 0.1397,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 27.0108 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 27.2095 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 27.4063 s
agent0:                 episode reward: -0.1091,                 loss: nan
agent1:                 episode reward: 0.1091,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1859s / 27.5921 s
agent0:                 episode reward: -0.0197,                 loss: nan
agent1:                 episode reward: 0.0197,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 27.7896 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2314s / 28.0210 s
agent0:                 episode reward: 0.2461,                 loss: nan
agent1:                 episode reward: -0.2461,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 28.2228 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 28.4205 s
agent0:                 episode reward: -0.2423,                 loss: nan
agent1:                 episode reward: 0.2423,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 28.6233 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 28.8270 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 29.0279 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 29.2330 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 29.4339 s
agent0:                 episode reward: 0.1163,                 loss: nan
agent1:                 episode reward: -0.1163,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 29.6362 s
agent0:                 episode reward: 0.2044,                 loss: nan
agent1:                 episode reward: -0.2044,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 29.8332 s
agent0:                 episode reward: 0.3775,                 loss: nan
agent1:                 episode reward: -0.3775,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 30.0353 s
agent0:                 episode reward: 0.2915,                 loss: nan
agent1:                 episode reward: -0.2915,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 30.2324 s
agent0:                 episode reward: 0.1634,                 loss: nan
agent1:                 episode reward: -0.1634,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 30.4342 s
agent0:                 episode reward: 0.0424,                 loss: nan
agent1:                 episode reward: -0.0424,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 30.6316 s
agent0:                 episode reward: -0.1657,                 loss: nan
agent1:                 episode reward: 0.1657,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 30.8345 s
agent0:                 episode reward: 0.2115,                 loss: nan
agent1:                 episode reward: -0.2115,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 31.0322 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 31.2303 s
agent0:                 episode reward: -0.1203,                 loss: nan
agent1:                 episode reward: 0.1203,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 31.4254 s
agent0:                 episode reward: -0.0785,                 loss: nan
agent1:                 episode reward: 0.0785,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 31.6255 s
agent0:                 episode reward: 0.0748,                 loss: nan
agent1:                 episode reward: -0.0748,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 31.8222 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 32.0246 s
agent0:                 episode reward: -0.0734,                 loss: nan
agent1:                 episode reward: 0.0734,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 32.2231 s
agent0:                 episode reward: 0.0873,                 loss: nan
agent1:                 episode reward: -0.0873,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 32.4190 s
agent0:                 episode reward: -0.3187,                 loss: nan
agent1:                 episode reward: 0.3187,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 32.6151 s
agent0:                 episode reward: -0.0138,                 loss: nan
agent1:                 episode reward: 0.0138,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 32.8117 s
agent0:                 episode reward: 0.1740,                 loss: nan
agent1:                 episode reward: -0.1740,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 33.0061 s
agent0:                 episode reward: 0.0530,                 loss: nan
agent1:                 episode reward: -0.0530,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1908s / 33.1968 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 33.3901 s
agent0:                 episode reward: -0.2377,                 loss: nan
agent1:                 episode reward: 0.2377,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 33.5805 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 33.9201 s
agent0:                 episode reward: 0.1861,                 loss: nan
agent1:                 episode reward: -0.1861,                 loss: 0.4481
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 34.5008 s
agent0:                 episode reward: -0.2754,                 loss: nan
agent1:                 episode reward: 0.2754,                 loss: 0.4249
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 35.0792 s
agent0:                 episode reward: -0.1499,                 loss: nan
agent1:                 episode reward: 0.1499,                 loss: 0.4078
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5740s / 35.6533 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: 0.3904
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5732s / 36.2265 s
agent0:                 episode reward: -0.2292,                 loss: nan
agent1:                 episode reward: 0.2292,                 loss: 0.3659
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 36.8056 s
agent0:                 episode reward: -0.7986,                 loss: nan
agent1:                 episode reward: 0.7986,                 loss: 0.3425
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5777s / 37.3833 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.3222
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 37.9666 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.3109
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 38.5509 s
agent0:                 episode reward: -0.6192,                 loss: nan
agent1:                 episode reward: 0.6192,                 loss: 0.3107
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 39.1372 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.3086
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 39.7186 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.3072
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 40.3038 s
agent0:                 episode reward: -0.8899,                 loss: nan
agent1:                 episode reward: 0.8899,                 loss: 0.3096
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5760s / 40.8798 s
agent0:                 episode reward: -0.6828,                 loss: nan
agent1:                 episode reward: 0.6828,                 loss: 0.3061
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5797s / 41.4595 s
agent0:                 episode reward: -0.5584,                 loss: nan
agent1:                 episode reward: 0.5584,                 loss: 0.3075
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 42.0385 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.3074
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 42.6188 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.3067
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5788s / 43.1976 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: 0.3024
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 43.7869 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.3084
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 44.3736 s
agent0:                 episode reward: -0.7197,                 loss: nan
agent1:                 episode reward: 0.7197,                 loss: 0.2721
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 44.9540 s
agent0:                 episode reward: -0.7888,                 loss: nan
agent1:                 episode reward: 0.7888,                 loss: 0.2691
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5786s / 45.5326 s
agent0:                 episode reward: -0.4551,                 loss: nan
agent1:                 episode reward: 0.4551,                 loss: 0.2663
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 46.1151 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.2667
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 46.7025 s
agent0:                 episode reward: -0.4420,                 loss: nan
agent1:                 episode reward: 0.4420,                 loss: 0.2676
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 47.2879 s
agent0:                 episode reward: -0.3218,                 loss: nan
agent1:                 episode reward: 0.3218,                 loss: 0.2650
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 47.8669 s
agent0:                 episode reward: -0.8259,                 loss: nan
agent1:                 episode reward: 0.8259,                 loss: 0.2651
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 48.4495 s
agent0:                 episode reward: -0.5276,                 loss: nan
agent1:                 episode reward: 0.5276,                 loss: 0.2627
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 49.0347 s
agent0:                 episode reward: -0.5719,                 loss: nan
agent1:                 episode reward: 0.5719,                 loss: 0.2645
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 49.6180 s
agent0:                 episode reward: -0.8835,                 loss: nan
agent1:                 episode reward: 0.8835,                 loss: 0.2623
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 50.1993 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.2637
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 50.7846 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.2682
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 51.3665 s
agent0:                 episode reward: -0.9905,                 loss: nan
agent1:                 episode reward: 0.9905,                 loss: 0.2625
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 51.9523 s
agent0:                 episode reward: -0.6205,                 loss: nan
agent1:                 episode reward: 0.6205,                 loss: 0.2642
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 52.5374 s
agent0:                 episode reward: -0.6399,                 loss: nan
agent1:                 episode reward: 0.6399,                 loss: 0.2616
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 53.1223 s
agent0:                 episode reward: -0.3894,                 loss: nan
agent1:                 episode reward: 0.3894,                 loss: 0.2675
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 53.7115 s
agent0:                 episode reward: -0.5518,                 loss: nan
agent1:                 episode reward: 0.5518,                 loss: 0.3366
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 54.3131 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.3279
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 54.9058 s
agent0:                 episode reward: -0.5646,                 loss: nan
agent1:                 episode reward: 0.5646,                 loss: 0.3287
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 55.4972 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.3273
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 56.0904 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.3279
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 56.6818 s
agent0:                 episode reward: -0.0676,                 loss: nan
agent1:                 episode reward: 0.0676,                 loss: 0.3329
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 57.2720 s
agent0:                 episode reward: -0.5333,                 loss: nan
agent1:                 episode reward: 0.5333,                 loss: 0.3270
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 57.8674 s
agent0:                 episode reward: -0.6944,                 loss: nan
agent1:                 episode reward: 0.6944,                 loss: 0.3258
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 58.4589 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.3318
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 59.0493 s
agent0:                 episode reward: -0.7183,                 loss: nan
agent1:                 episode reward: 0.7183,                 loss: 0.3310
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 59.6495 s
agent0:                 episode reward: -0.3078,                 loss: nan
agent1:                 episode reward: 0.3078,                 loss: 0.3307
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 60.2424 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.3327
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5781s / 60.8205 s
agent0:                 episode reward: -0.4322,                 loss: nan
agent1:                 episode reward: 0.4322,                 loss: 0.3297
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 61.4053 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.3299
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 61.9925 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.3276
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 62.5852 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.3288
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 63.1727 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.3364
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 63.7612 s
agent0:                 episode reward: -0.8926,                 loss: nan
agent1:                 episode reward: 0.8926,                 loss: 0.3403
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 64.3429 s
agent0:                 episode reward: -0.6571,                 loss: nan
agent1:                 episode reward: 0.6571,                 loss: 0.3359
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 64.9270 s
agent0:                 episode reward: -0.7275,                 loss: nan
agent1:                 episode reward: 0.7275,                 loss: 0.3331
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 65.5149 s
agent0:                 episode reward: -0.8673,                 loss: nan
agent1:                 episode reward: 0.8673,                 loss: 0.3346
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 66.1048 s
agent0:                 episode reward: -0.8923,                 loss: nan
agent1:                 episode reward: 0.8923,                 loss: 0.3343
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 66.6810 s
agent0:                 episode reward: -0.5676,                 loss: nan
agent1:                 episode reward: 0.5676,                 loss: 0.3362
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 67.2676 s
agent0:                 episode reward: -0.2045,                 loss: nan
agent1:                 episode reward: 0.2045,                 loss: 0.3352
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 67.8578 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.3346
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 68.4402 s
agent0:                 episode reward: -0.8615,                 loss: nan
agent1:                 episode reward: 0.8615,                 loss: 0.3334
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 69.0319 s
agent0:                 episode reward: -0.7861,                 loss: nan
agent1:                 episode reward: 0.7861,                 loss: 0.3325
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 69.6172 s
agent0:                 episode reward: -0.7416,                 loss: nan
agent1:                 episode reward: 0.7416,                 loss: 0.3313
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 70.2009 s
agent0:                 episode reward: -0.6424,                 loss: nan
agent1:                 episode reward: 0.6424,                 loss: 0.3298
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 70.7846 s
agent0:                 episode reward: -0.8527,                 loss: nan
agent1:                 episode reward: 0.8527,                 loss: 0.3305
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 71.3646 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.3323
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 71.9544 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3331
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 72.5364 s
agent0:                 episode reward: -0.7413,                 loss: nan
agent1:                 episode reward: 0.7413,                 loss: 0.3322
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 73.1245 s
agent0:                 episode reward: -0.9814,                 loss: nan
agent1:                 episode reward: 0.9814,                 loss: 0.3180
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 73.7082 s
agent0:                 episode reward: -0.6739,                 loss: nan
agent1:                 episode reward: 0.6739,                 loss: 0.2951
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 74.2926 s
agent0:                 episode reward: -0.7257,                 loss: nan
agent1:                 episode reward: 0.7257,                 loss: 0.2962
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 74.8866 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.2919
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 75.4717 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.2960
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 76.0557 s
agent0:                 episode reward: -0.8205,                 loss: nan
agent1:                 episode reward: 0.8205,                 loss: 0.2930
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 76.6436 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.2917
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 77.2319 s
agent0:                 episode reward: -0.6087,                 loss: nan
agent1:                 episode reward: 0.6087,                 loss: 0.2934
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 77.8197 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.2916
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 78.4134 s
agent0:                 episode reward: -0.7369,                 loss: nan
agent1:                 episode reward: 0.7369,                 loss: 0.2938
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 79.0059 s
agent0:                 episode reward: -0.6140,                 loss: nan
agent1:                 episode reward: 0.6140,                 loss: 0.2900
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 79.6009 s
agent0:                 episode reward: -0.7707,                 loss: nan
agent1:                 episode reward: 0.7707,                 loss: 0.2922
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 80.1961 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.2926
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 80.7931 s
agent0:                 episode reward: -0.4386,                 loss: nan
agent1:                 episode reward: 0.4386,                 loss: 0.2906
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 81.3955 s
agent0:                 episode reward: -0.5989,                 loss: nan
agent1:                 episode reward: 0.5989,                 loss: 0.2900
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 81.9968 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.2919
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 82.5919 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.2951
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 83.1812 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.3498
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 83.7704 s
agent0:                 episode reward: -0.7685,                 loss: nan
agent1:                 episode reward: 0.7685,                 loss: 0.3451
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 84.3624 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.3454
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 84.9553 s
agent0:                 episode reward: -0.6436,                 loss: nan
agent1:                 episode reward: 0.6436,                 loss: 0.3512
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 85.5462 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: 0.3495
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 86.1305 s
agent0:                 episode reward: -0.6912,                 loss: nan
agent1:                 episode reward: 0.6912,                 loss: 0.3486
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 86.7387 s
agent0:                 episode reward: -0.9449,                 loss: nan
agent1:                 episode reward: 0.9449,                 loss: 0.3460
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 87.3313 s
agent0:                 episode reward: -0.7142,                 loss: nan
agent1:                 episode reward: 0.7142,                 loss: 0.3440
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 87.9160 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.3462
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 88.5029 s
agent0:                 episode reward: -0.6173,                 loss: nan
agent1:                 episode reward: 0.6173,                 loss: 0.3479
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 89.0960 s
agent0:                 episode reward: -1.0283,                 loss: nan
agent1:                 episode reward: 1.0283,                 loss: 0.3477
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 89.6884 s
agent0:                 episode reward: -0.8887,                 loss: nan
agent1:                 episode reward: 0.8887,                 loss: 0.3469
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 90.2843 s
agent0:                 episode reward: -0.8731,                 loss: nan
agent1:                 episode reward: 0.8731,                 loss: 0.3475
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 90.8765 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.3471
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 91.4659 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.3454
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 92.0504 s
agent0:                 episode reward: -0.7773,                 loss: nan
agent1:                 episode reward: 0.7773,                 loss: 0.3451
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 92.6478 s
agent0:                 episode reward: -0.5944,                 loss: nan
agent1:                 episode reward: 0.5944,                 loss: 0.3472
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 93.2440 s
agent0:                 episode reward: -0.7094,                 loss: nan
agent1:                 episode reward: 0.7094,                 loss: 0.3361
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 93.8333 s
agent0:                 episode reward: -0.9791,                 loss: nan
agent1:                 episode reward: 0.9791,                 loss: 0.3354
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 94.4259 s
agent0:                 episode reward: -0.9887,                 loss: nan
agent1:                 episode reward: 0.9887,                 loss: 0.3338
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 95.0255 s
agent0:                 episode reward: -0.6136,                 loss: nan
agent1:                 episode reward: 0.6136,                 loss: 0.3308
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 95.6216 s
agent0:                 episode reward: -0.4975,                 loss: nan
agent1:                 episode reward: 0.4975,                 loss: 0.3325
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 96.2186 s
agent0:                 episode reward: -0.8105,                 loss: nan
agent1:                 episode reward: 0.8105,                 loss: 0.3294
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 96.8082 s
agent0:                 episode reward: -0.4545,                 loss: nan
agent1:                 episode reward: 0.4545,                 loss: 0.3309
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 97.4011 s
agent0:                 episode reward: -0.5572,                 loss: nan
agent1:                 episode reward: 0.5572,                 loss: 0.3307
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 98.0062 s
agent0:                 episode reward: -0.3292,                 loss: nan
agent1:                 episode reward: 0.3292,                 loss: 0.3316
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 98.6009 s
agent0:                 episode reward: -0.6134,                 loss: nan
agent1:                 episode reward: 0.6134,                 loss: 0.3327
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 99.1943 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.3329
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 99.7895 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.3292
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 100.3839 s
agent0:                 episode reward: -0.9814,                 loss: nan
agent1:                 episode reward: 0.9814,                 loss: 0.3293
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 100.9799 s
agent0:                 episode reward: -0.5776,                 loss: nan
agent1:                 episode reward: 0.5776,                 loss: 0.3309
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 101.5799 s
agent0:                 episode reward: -0.6195,                 loss: nan
agent1:                 episode reward: 0.6195,                 loss: 0.3305
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 102.1750 s
agent0:                 episode reward: -0.6544,                 loss: nan
agent1:                 episode reward: 0.6544,                 loss: 0.3284
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 102.7696 s
agent0:                 episode reward: -0.5872,                 loss: nan
agent1:                 episode reward: 0.5872,                 loss: 0.3150
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 103.3613 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.2996
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 103.9633 s
agent0:                 episode reward: -0.9009,                 loss: nan
agent1:                 episode reward: 0.9009,                 loss: 0.3002
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 104.5647 s
agent0:                 episode reward: -0.9226,                 loss: nan
agent1:                 episode reward: 0.9226,                 loss: 0.2973
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 105.1591 s
agent0:                 episode reward: -0.9682,                 loss: nan
agent1:                 episode reward: 0.9682,                 loss: 0.2956
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 105.7532 s
agent0:                 episode reward: -0.7862,                 loss: nan
agent1:                 episode reward: 0.7862,                 loss: 0.2940
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 106.3578 s
agent0:                 episode reward: -0.5523,                 loss: nan
agent1:                 episode reward: 0.5523,                 loss: 0.2967
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 106.9574 s
agent0:                 episode reward: -0.7810,                 loss: nan
agent1:                 episode reward: 0.7810,                 loss: 0.2970
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 107.5548 s
agent0:                 episode reward: -0.6133,                 loss: nan
agent1:                 episode reward: 0.6133,                 loss: 0.2977
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 108.1560 s
agent0:                 episode reward: -0.3975,                 loss: nan
agent1:                 episode reward: 0.3975,                 loss: 0.2960
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 108.7487 s
agent0:                 episode reward: -0.8012,                 loss: nan
agent1:                 episode reward: 0.8012,                 loss: 0.2976
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 109.3389 s
agent0:                 episode reward: -0.6147,                 loss: nan
agent1:                 episode reward: 0.6147,                 loss: 0.2983
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 109.9310 s
agent0:                 episode reward: -0.6451,                 loss: nan
agent1:                 episode reward: 0.6451,                 loss: 0.2926
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 110.5247 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.2969
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 111.1236 s
agent0:                 episode reward: -0.4406,                 loss: nan
agent1:                 episode reward: 0.4406,                 loss: 0.2951
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 111.7239 s
agent0:                 episode reward: -0.8901,                 loss: nan
agent1:                 episode reward: 0.8901,                 loss: 0.2945
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 112.3152 s
agent0:                 episode reward: -0.1835,                 loss: nan
agent1:                 episode reward: 0.1835,                 loss: 0.3038
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 112.9160 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.3641
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 113.5129 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.3537
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 114.1158 s
agent0:                 episode reward: -0.8345,                 loss: nan
agent1:                 episode reward: 0.8345,                 loss: 0.3530
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 114.7216 s
agent0:                 episode reward: -0.7209,                 loss: nan
agent1:                 episode reward: 0.7209,                 loss: 0.3581
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 115.3340 s
agent0:                 episode reward: -0.7040,                 loss: nan
agent1:                 episode reward: 0.7040,                 loss: 0.3534
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 115.9347 s
agent0:                 episode reward: -1.0183,                 loss: nan
agent1:                 episode reward: 1.0183,                 loss: 0.3540
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 116.5364 s
agent0:                 episode reward: -0.8450,                 loss: nan
agent1:                 episode reward: 0.8450,                 loss: 0.3557
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 117.1365 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.3532
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 117.7394 s
agent0:                 episode reward: -1.1207,                 loss: nan
agent1:                 episode reward: 1.1207,                 loss: 0.3540
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 118.3448 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.3555
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 118.9479 s
agent0:                 episode reward: -0.5435,                 loss: nan
agent1:                 episode reward: 0.5435,                 loss: 0.3544
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 119.5511 s
agent0:                 episode reward: -0.8741,                 loss: nan
agent1:                 episode reward: 0.8741,                 loss: 0.3540
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 120.1515 s
agent0:                 episode reward: -0.9309,                 loss: nan
agent1:                 episode reward: 0.9309,                 loss: 0.3521
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 120.7465 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.3510
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 121.3508 s
agent0:                 episode reward: -0.9299,                 loss: nan
agent1:                 episode reward: 0.9299,                 loss: 0.3537
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 121.9520 s
agent0:                 episode reward: -0.2223,                 loss: nan
agent1:                 episode reward: 0.2223,                 loss: 0.3518
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 122.5590 s
agent0:                 episode reward: -0.5530,                 loss: nan
agent1:                 episode reward: 0.5530,                 loss: 0.3451
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6100s / 123.1690 s
agent0:                 episode reward: -0.5203,                 loss: nan
agent1:                 episode reward: 0.5203,                 loss: 0.3291
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 123.7757 s
agent0:                 episode reward: -0.9853,                 loss: nan
agent1:                 episode reward: 0.9853,                 loss: 0.3278
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 124.3748 s
agent0:                 episode reward: -0.4566,                 loss: nan
agent1:                 episode reward: 0.4566,                 loss: 0.3269
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 124.9723 s
agent0:                 episode reward: -0.5911,                 loss: nan
agent1:                 episode reward: 0.5911,                 loss: 0.3242
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 125.5697 s
agent0:                 episode reward: -0.6621,                 loss: nan
agent1:                 episode reward: 0.6621,                 loss: 0.3233
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 126.1742 s
agent0:                 episode reward: -0.8790,                 loss: nan
agent1:                 episode reward: 0.8790,                 loss: 0.3287
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 126.7761 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.3257
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 127.3774 s
agent0:                 episode reward: -0.4446,                 loss: nan
agent1:                 episode reward: 0.4446,                 loss: 0.3245
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 127.9746 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.3245
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 128.5777 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.3252
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 129.1732 s
agent0:                 episode reward: -0.6771,                 loss: nan
agent1:                 episode reward: 0.6771,                 loss: 0.3242
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 129.7717 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.3248
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 130.3671 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.3232
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 130.9681 s
agent0:                 episode reward: -0.6820,                 loss: nan
agent1:                 episode reward: 0.6820,                 loss: 0.3238
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 131.5766 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3248
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 132.1745 s
agent0:                 episode reward: -0.6968,                 loss: nan
agent1:                 episode reward: 0.6968,                 loss: 0.3265
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 132.7808 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.3185
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 133.3832 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.3039
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 133.9842 s
agent0:                 episode reward: -0.6150,                 loss: nan
agent1:                 episode reward: 0.6150,                 loss: 0.3021
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 134.5886 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.3059
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 135.1954 s
agent0:                 episode reward: -0.7363,                 loss: nan
agent1:                 episode reward: 0.7363,                 loss: 0.3049
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 135.7995 s
agent0:                 episode reward: -0.6550,                 loss: nan
agent1:                 episode reward: 0.6550,                 loss: 0.3052
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 136.3963 s
agent0:                 episode reward: -0.5422,                 loss: nan
agent1:                 episode reward: 0.5422,                 loss: 0.3074
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 136.9941 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.3055
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 137.5963 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.3044
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 138.1963 s
agent0:                 episode reward: -0.7928,                 loss: nan
agent1:                 episode reward: 0.7928,                 loss: 0.3017
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 138.7958 s
agent0:                 episode reward: -0.7025,                 loss: nan
agent1:                 episode reward: 0.7025,                 loss: 0.3052
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 139.3984 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.3045
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 140.0032 s
agent0:                 episode reward: -0.8787,                 loss: nan
agent1:                 episode reward: 0.8787,                 loss: 0.2996
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 140.6083 s
agent0:                 episode reward: -0.8392,                 loss: nan
agent1:                 episode reward: 0.8392,                 loss: 0.3040
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 141.2121 s
agent0:                 episode reward: -0.6706,                 loss: nan
agent1:                 episode reward: 0.6706,                 loss: 0.3047
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 141.8243 s
agent0:                 episode reward: -0.8172,                 loss: nan
agent1:                 episode reward: 0.8172,                 loss: 0.3043
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 142.4296 s
agent0:                 episode reward: -0.9929,                 loss: nan
agent1:                 episode reward: 0.9929,                 loss: 0.3077
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 143.0356 s
agent0:                 episode reward: -0.3160,                 loss: nan
agent1:                 episode reward: 0.3160,                 loss: 0.3636
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 143.6398 s
agent0:                 episode reward: -1.0777,                 loss: nan
agent1:                 episode reward: 1.0777,                 loss: 0.3551
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 144.2430 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.3547
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 144.8500 s
agent0:                 episode reward: -0.6920,                 loss: nan
agent1:                 episode reward: 0.6920,                 loss: 0.3540
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 145.4505 s
agent0:                 episode reward: -0.6919,                 loss: nan
agent1:                 episode reward: 0.6919,                 loss: 0.3557
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 146.0575 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: 0.3544
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 146.6588 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.3564
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 147.2666 s
agent0:                 episode reward: -0.5059,                 loss: nan
agent1:                 episode reward: 0.5059,                 loss: 0.3533
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 147.8753 s
agent0:                 episode reward: -0.8022,                 loss: nan
agent1:                 episode reward: 0.8022,                 loss: 0.3556
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 148.4803 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.3523
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 149.0860 s
agent0:                 episode reward: -1.0449,                 loss: nan
agent1:                 episode reward: 1.0449,                 loss: 0.3538
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 149.6910 s
agent0:                 episode reward: -1.2528,                 loss: nan
agent1:                 episode reward: 1.2528,                 loss: 0.3550
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 150.2974 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.3567
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 150.9104 s
agent0:                 episode reward: -0.5816,                 loss: nan
agent1:                 episode reward: 0.5816,                 loss: 0.3540
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 151.5125 s
agent0:                 episode reward: -0.9459,                 loss: nan
agent1:                 episode reward: 0.9459,                 loss: 0.3533
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 152.1156 s
agent0:                 episode reward: -0.6753,                 loss: nan
agent1:                 episode reward: 0.6753,                 loss: 0.3505
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 152.7129 s
agent0:                 episode reward: -0.5122,                 loss: nan
agent1:                 episode reward: 0.5122,                 loss: 0.3474
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 153.3181 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.3280
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 153.9255 s
agent0:                 episode reward: -0.9358,                 loss: nan
agent1:                 episode reward: 0.9358,                 loss: 0.3297
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 154.5283 s
agent0:                 episode reward: -0.8378,                 loss: nan
agent1:                 episode reward: 0.8378,                 loss: 0.3289
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 155.1320 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.3247
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 155.7430 s
agent0:                 episode reward: -0.8940,                 loss: nan
agent1:                 episode reward: 0.8940,                 loss: 0.3296
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 156.3435 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.3261
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 156.9487 s
agent0:                 episode reward: -0.5197,                 loss: nan
agent1:                 episode reward: 0.5197,                 loss: 0.3273
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 157.5472 s
agent0:                 episode reward: -0.6587,                 loss: nan
agent1:                 episode reward: 0.6587,                 loss: 0.3253
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 158.1463 s
agent0:                 episode reward: -0.9238,                 loss: nan
agent1:                 episode reward: 0.9238,                 loss: 0.3262
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 158.7500 s
agent0:                 episode reward: -0.8584,                 loss: nan
agent1:                 episode reward: 0.8584,                 loss: 0.3258
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 159.3631 s
agent0:                 episode reward: -0.8971,                 loss: nan
agent1:                 episode reward: 0.8971,                 loss: 0.3266
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 159.9680 s
agent0:                 episode reward: -0.4549,                 loss: nan
agent1:                 episode reward: 0.4549,                 loss: 0.3262
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 160.5702 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3238
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 161.1831 s
agent0:                 episode reward: -0.5371,                 loss: nan
agent1:                 episode reward: 0.5371,                 loss: 0.3262
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 161.7852 s
agent0:                 episode reward: -1.0526,                 loss: nan
agent1:                 episode reward: 1.0526,                 loss: 0.3263
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 162.3974 s
agent0:                 episode reward: -0.7494,                 loss: nan
agent1:                 episode reward: 0.7494,                 loss: 0.3292
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 162.9974 s
agent0:                 episode reward: -0.7582,                 loss: nan
agent1:                 episode reward: 0.7582,                 loss: 0.3242
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 163.6035 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.3200
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 164.2075 s
agent0:                 episode reward: -0.7630,                 loss: nan
agent1:                 episode reward: 0.7630,                 loss: 0.3206
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 164.8063 s
agent0:                 episode reward: -0.6097,                 loss: nan
agent1:                 episode reward: 0.6097,                 loss: 0.3206
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 165.4128 s
agent0:                 episode reward: -0.7239,                 loss: nan
agent1:                 episode reward: 0.7239,                 loss: 0.3192
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 166.0240 s
agent0:                 episode reward: -0.9199,                 loss: nan
agent1:                 episode reward: 0.9199,                 loss: 0.3192
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 166.6353 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.3223
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 167.2430 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: 0.3205
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 167.8515 s
agent0:                 episode reward: -0.5779,                 loss: nan
agent1:                 episode reward: 0.5779,                 loss: 0.3196
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 168.4548 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: 0.3196
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6098s / 169.0647 s
agent0:                 episode reward: -0.1883,                 loss: nan
agent1:                 episode reward: 0.1883,                 loss: 0.3214
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 169.6726 s
agent0:                 episode reward: -0.5740,                 loss: nan
agent1:                 episode reward: 0.5740,                 loss: 0.3207
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6073s / 170.2799 s
agent0:                 episode reward: -1.0262,                 loss: nan
agent1:                 episode reward: 1.0262,                 loss: 0.3172
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 170.8901 s
agent0:                 episode reward: -0.7693,                 loss: nan
agent1:                 episode reward: 0.7693,                 loss: 0.3195
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 171.5006 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.3197
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 172.1042 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.3187
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 172.7130 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.3220
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 173.3280 s
agent0:                 episode reward: -0.8861,                 loss: nan
agent1:                 episode reward: 0.8861,                 loss: 0.3488
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 173.9362 s
agent0:                 episode reward: -0.4721,                 loss: nan
agent1:                 episode reward: 0.4721,                 loss: 0.3479
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 174.5425 s
agent0:                 episode reward: -0.8134,                 loss: nan
agent1:                 episode reward: 0.8134,                 loss: 0.3473
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6118s / 175.1544 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.3492
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6175s / 175.7718 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3484
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6141s / 176.3859 s
agent0:                 episode reward: -0.7038,                 loss: nan
agent1:                 episode reward: 0.7038,                 loss: 0.3485
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6120s / 176.9979 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.3486
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 177.6032 s
agent0:                 episode reward: -0.8873,                 loss: nan
agent1:                 episode reward: 0.8873,                 loss: 0.3477
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 178.2095 s
