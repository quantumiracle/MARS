pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f17218c5cf8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/0_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/0_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_0/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_0/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.3980s / 7.3980 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3638s / 7.7618 s
agent0:                 episode reward: -0.2491,                 loss: nan
agent1:                 episode reward: 0.2491,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3979s / 8.1597 s
agent0:                 episode reward: -0.6411,                 loss: nan
agent1:                 episode reward: 0.6411,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4031s / 8.5628 s
agent0:                 episode reward: 0.1064,                 loss: nan
agent1:                 episode reward: -0.1064,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3963s / 8.9590 s
agent0:                 episode reward: -0.5237,                 loss: nan
agent1:                 episode reward: 0.5237,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 9.3533 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4008s / 9.7541 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3952s / 10.1493 s
agent0:                 episode reward: -1.0393,                 loss: nan
agent1:                 episode reward: 1.0393,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3994s / 10.5487 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4050s / 10.9537 s
agent0:                 episode reward: -0.8843,                 loss: nan
agent1:                 episode reward: 0.8843,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4026s / 11.3563 s
agent0:                 episode reward: -0.7860,                 loss: nan
agent1:                 episode reward: 0.7860,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 11.7520 s
agent0:                 episode reward: -0.0927,                 loss: nan
agent1:                 episode reward: 0.0927,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4002s / 12.1522 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 12.5438 s
agent0:                 episode reward: -0.6598,                 loss: nan
agent1:                 episode reward: 0.6598,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3889s / 12.9328 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3886s / 13.3214 s
agent0:                 episode reward: -0.7595,                 loss: nan
agent1:                 episode reward: 0.7595,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3921s / 13.7135 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3904s / 14.1039 s
agent0:                 episode reward: 0.0679,                 loss: nan
agent1:                 episode reward: -0.0679,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3929s / 14.4968 s
agent0:                 episode reward: -0.6441,                 loss: nan
agent1:                 episode reward: 0.6441,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 14.8929 s
agent0:                 episode reward: -0.0315,                 loss: nan
agent1:                 episode reward: 0.0315,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 15.2862 s
agent0:                 episode reward: -0.5724,                 loss: nan
agent1:                 episode reward: 0.5724,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3968s / 15.6830 s
agent0:                 episode reward: -0.3020,                 loss: nan
agent1:                 episode reward: 0.3020,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 16.0788 s
agent0:                 episode reward: -0.2758,                 loss: nan
agent1:                 episode reward: 0.2758,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3954s / 16.4742 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3872s / 16.8613 s
agent0:                 episode reward: 0.0816,                 loss: nan
agent1:                 episode reward: -0.0816,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3972s / 17.2585 s
agent0:                 episode reward: -0.8992,                 loss: nan
agent1:                 episode reward: 0.8992,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 17.6512 s
agent0:                 episode reward: -0.7679,                 loss: nan
agent1:                 episode reward: 0.7679,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3937s / 18.0449 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3975s / 18.4424 s
agent0:                 episode reward: -0.4902,                 loss: nan
agent1:                 episode reward: 0.4902,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 18.8353 s
agent0:                 episode reward: -0.0595,                 loss: nan
agent1:                 episode reward: 0.0595,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3901s / 19.2253 s
agent0:                 episode reward: -0.8920,                 loss: nan
agent1:                 episode reward: 0.8920,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3893s / 19.6146 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3919s / 20.0065 s
agent0:                 episode reward: -0.4147,                 loss: nan
agent1:                 episode reward: 0.4147,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3941s / 20.4006 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3910s / 20.7916 s
agent0:                 episode reward: -0.2782,                 loss: nan
agent1:                 episode reward: 0.2782,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 21.1878 s
agent0:                 episode reward: -0.7354,                 loss: nan
agent1:                 episode reward: 0.7354,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 21.5794 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 21.9727 s
agent0:                 episode reward: -0.1776,                 loss: nan
agent1:                 episode reward: 0.1776,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 22.3676 s
agent0:                 episode reward: -0.3395,                 loss: nan
agent1:                 episode reward: 0.3395,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3968s / 22.7644 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3889s / 23.1533 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 23.5479 s
agent0:                 episode reward: -0.0724,                 loss: nan
agent1:                 episode reward: 0.0724,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3921s / 23.9400 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3905s / 24.3305 s
agent0:                 episode reward: -0.6800,                 loss: nan
agent1:                 episode reward: 0.6800,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 24.7235 s
agent0:                 episode reward: -1.0412,                 loss: nan
agent1:                 episode reward: 1.0412,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3905s / 25.1139 s
agent0:                 episode reward: -0.6131,                 loss: nan
agent1:                 episode reward: 0.6131,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4003s / 25.5143 s
agent0:                 episode reward: -0.1397,                 loss: nan
agent1:                 episode reward: 0.1397,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 25.9050 s
agent0:                 episode reward: -0.7879,                 loss: nan
agent1:                 episode reward: 0.7879,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3948s / 26.2998 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3979s / 26.6977 s
agent0:                 episode reward: -0.1341,                 loss: nan
agent1:                 episode reward: 0.1341,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3932s / 27.0909 s
agent0:                 episode reward: -0.5802,                 loss: nan
agent1:                 episode reward: 0.5802,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3860s / 27.4769 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3918s / 27.8687 s
agent0:                 episode reward: -0.2365,                 loss: nan
agent1:                 episode reward: 0.2365,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3904s / 28.2591 s
agent0:                 episode reward: -0.9522,                 loss: nan
agent1:                 episode reward: 0.9522,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 28.6552 s
agent0:                 episode reward: -0.1472,                 loss: nan
agent1:                 episode reward: 0.1472,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3876s / 29.0427 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3917s / 29.4344 s
agent0:                 episode reward: -0.1903,                 loss: nan
agent1:                 episode reward: 0.1903,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3908s / 29.8253 s
agent0:                 episode reward: -0.6160,                 loss: nan
agent1:                 episode reward: 0.6160,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3863s / 30.2115 s
agent0:                 episode reward: -1.0625,                 loss: nan
agent1:                 episode reward: 1.0625,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3978s / 30.6093 s
agent0:                 episode reward: -0.7012,                 loss: nan
agent1:                 episode reward: 0.7012,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 31.0028 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3902s / 31.3930 s
agent0:                 episode reward: -0.2662,                 loss: nan
agent1:                 episode reward: 0.2662,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3922s / 31.7852 s
agent0:                 episode reward: -1.0415,                 loss: nan
agent1:                 episode reward: 1.0415,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3918s / 32.1770 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3929s / 32.5698 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3911s / 32.9610 s
agent0:                 episode reward: 0.1374,                 loss: nan
agent1:                 episode reward: -0.1374,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 33.3552 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3966s / 33.7518 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3868s / 34.1387 s
agent0:                 episode reward: -1.0950,                 loss: nan
agent1:                 episode reward: 1.0950,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3925s / 34.5311 s
agent0:                 episode reward: -0.5950,                 loss: nan
agent1:                 episode reward: 0.5950,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 34.9244 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3884s / 35.3128 s
agent0:                 episode reward: 0.1000,                 loss: nan
agent1:                 episode reward: -0.1000,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 35.7084 s
agent0:                 episode reward: -0.1006,                 loss: nan
agent1:                 episode reward: 0.1006,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3865s / 36.0949 s
agent0:                 episode reward: -0.5474,                 loss: nan
agent1:                 episode reward: 0.5474,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 36.4865 s
agent0:                 episode reward: -0.3449,                 loss: nan
agent1:                 episode reward: 0.3449,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3886s / 36.8751 s
agent0:                 episode reward: 0.1187,                 loss: nan
agent1:                 episode reward: -0.1187,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4083s / 37.2834 s
agent0:                 episode reward: -0.1345,                 loss: nan
agent1:                 episode reward: 0.1345,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3619s / 37.6453 s
agent0:                 episode reward: -0.4381,                 loss: nan
agent1:                 episode reward: 0.4381,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 38.0391 s
agent0:                 episode reward: -0.7271,                 loss: nan
agent1:                 episode reward: 0.7271,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3889s / 38.4279 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3898s / 38.8178 s
agent0:                 episode reward: -1.1956,                 loss: nan
agent1:                 episode reward: 1.1956,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3913s / 39.2091 s
agent0:                 episode reward: 0.0677,                 loss: nan
agent1:                 episode reward: -0.0677,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3969s / 39.6060 s
agent0:                 episode reward: -0.8905,                 loss: nan
agent1:                 episode reward: 0.8905,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3857s / 39.9917 s
agent0:                 episode reward: -0.4234,                 loss: nan
agent1:                 episode reward: 0.4234,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.2059s / 42.1976 s
agent0:                 episode reward: -0.2127,                 loss: nan
agent1:                 episode reward: 0.2127,                 loss: 0.4742
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1432s / 43.3408 s
agent0:                 episode reward: 0.3122,                 loss: nan
agent1:                 episode reward: -0.3122,                 loss: 0.4050
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1476s / 44.4884 s
agent0:                 episode reward: -0.4899,                 loss: nan
agent1:                 episode reward: 0.4899,                 loss: 0.3869
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1444s / 45.6328 s
agent0:                 episode reward: -0.3240,                 loss: nan
agent1:                 episode reward: 0.3240,                 loss: 0.3739
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1447s / 46.7775 s
agent0:                 episode reward: -0.3542,                 loss: nan
agent1:                 episode reward: 0.3542,                 loss: 0.3577
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1405s / 47.9180 s
agent0:                 episode reward: -0.6398,                 loss: nan
agent1:                 episode reward: 0.6398,                 loss: 0.3323
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1430s / 49.0609 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.3078
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1471s / 50.2080 s
agent0:                 episode reward: -0.8705,                 loss: nan
agent1:                 episode reward: 0.8705,                 loss: 0.2842
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1527s / 51.3607 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: 0.3234
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1498s / 52.5104 s
agent0:                 episode reward: -0.4782,                 loss: nan
agent1:                 episode reward: 0.4782,                 loss: 0.3860
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1455s / 53.6560 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3871
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1399s / 54.7959 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.3851
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1450s / 55.9409 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.3844
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1473s / 57.0882 s
agent0:                 episode reward: -0.7963,                 loss: nan
agent1:                 episode reward: 0.7963,                 loss: 0.3844
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1519s / 58.2401 s
agent0:                 episode reward: -0.0215,                 loss: nan
agent1:                 episode reward: 0.0215,                 loss: 0.3844
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1455s / 59.3857 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.3829
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1402s / 60.5258 s
agent0:                 episode reward: -0.1255,                 loss: nan
agent1:                 episode reward: 0.1255,                 loss: 0.3866
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1658s / 61.6916 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.4312
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1653s / 62.8569 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.4211
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1602s / 64.0171 s
agent0:                 episode reward: -0.4579,                 loss: nan