pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 1154.0,                last time consumption/overall running time: 24.8396s / 24.8396 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0104
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0090
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1416.3,                last time consumption/overall running time: 784.9027s / 809.7423 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0096
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0098
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1402.2,                last time consumption/overall running time: 1006.7777s / 1816.5200 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0093
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0094
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1256.4,                last time consumption/overall running time: 988.7330s / 2805.2531 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0090
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0088
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1277.05,                last time consumption/overall running time: 1027.5652s / 3832.8183 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0086
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0086
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1166.35,                last time consumption/overall running time: 950.5477s / 4783.3660 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0086
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0086
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1246.0,                last time consumption/overall running time: 1022.8474s / 5806.2134 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0084
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0080
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1259.3,                last time consumption/overall running time: 1027.1395s / 6833.3529 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0078
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0076
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1154.25,                last time consumption/overall running time: 956.1678s / 7789.5208 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0075
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0072
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1118.2,                last time consumption/overall running time: 920.6446s / 8710.1654 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0071
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0074
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1183.05,                last time consumption/overall running time: 975.5471s / 9685.7125 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0065
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0069
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1209.7,                last time consumption/overall running time: 997.2980s / 10683.0105 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0065
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0069
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1213.6,                last time consumption/overall running time: 1004.8317s / 11687.8422 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0060
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0065
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1186.0,                last time consumption/overall running time: 978.5871s / 12666.4293 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0061
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0064
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1130.9,                last time consumption/overall running time: 936.8137s / 13603.2430 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0061
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0062
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1161.15,                last time consumption/overall running time: 963.7537s / 14566.9967 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0058
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1135.0,                last time consumption/overall running time: 934.4410s / 15501.4377 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0057
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1137.55,                last time consumption/overall running time: 938.7906s / 16440.2282 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0055
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0055
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1221.0,                last time consumption/overall running time: 1004.1586s / 17444.3869 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0055
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0057
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1262.7,                last time consumption/overall running time: 1042.7526s / 18487.1395 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0060
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0063
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1209.15,                last time consumption/overall running time: 1000.3716s / 19487.5112 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0065
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1245.35,                last time consumption/overall running time: 1027.3863s / 20514.8974 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0065
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0070
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1145.8,                last time consumption/overall running time: 943.9356s / 21458.8330 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0064
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0063
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1112.3,                last time consumption/overall running time: 913.8849s / 22372.7180 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0056
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0057
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1117.8,                last time consumption/overall running time: 925.9622s / 23298.6802 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0047
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0046
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1126.0,                last time consumption/overall running time: 925.7080s / 24224.3882 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0036
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1150.65,                last time consumption/overall running time: 947.7898s / 25172.1779 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0036
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1118.95,                last time consumption/overall running time: 925.5741s / 26097.7520 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0039
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1132.15,                last time consumption/overall running time: 935.2324s / 27032.9844 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0038
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1151.3,                last time consumption/overall running time: 952.3268s / 27985.3112 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0036
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1130.45,                last time consumption/overall running time: 931.8712s / 28917.1824 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1198.65,                last time consumption/overall running time: 990.8139s / 29907.9963 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1135.65,                last time consumption/overall running time: 937.9558s / 30845.9521 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0038
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1160.55,                last time consumption/overall running time: 959.5144s / 31805.4665 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0042
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1211.9,                last time consumption/overall running time: 999.4197s / 32804.8862 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0043
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1248.95,                last time consumption/overall running time: 1027.1645s / 33832.0507 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0045
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0043
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1159.45,                last time consumption/overall running time: 957.1769s / 34789.2276 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0043
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1164.8,                last time consumption/overall running time: 957.7798s / 35747.0075 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1155.35,                last time consumption/overall running time: 954.1275s / 36701.1350 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0047
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0047
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1147.1,                last time consumption/overall running time: 1019.2518s / 37720.3868 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1162.95,                last time consumption/overall running time: 1121.1189s / 38841.5057 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1190.4,                last time consumption/overall running time: 1141.3877s / 39982.8934 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0045
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1159.2,                last time consumption/overall running time: 1109.0813s / 41091.9747 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0045
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1260.7,                last time consumption/overall running time: 1205.8585s / 42297.8332 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0050
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1223.25,                last time consumption/overall running time: 1168.1742s / 43466.0074 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0052
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1201.15,                last time consumption/overall running time: 1145.3819s / 44611.3893 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0050
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0050
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1214.15,                last time consumption/overall running time: 1157.3492s / 45768.7385 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0050
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1298.9,                last time consumption/overall running time: 1237.4576s / 47006.1961 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1301.65,                last time consumption/overall running time: 1244.0317s / 48250.2278 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1232.85,                last time consumption/overall running time: 1173.9533s / 49424.1811 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1213.9,                last time consumption/overall running time: 1151.2682s / 50575.4494 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0047
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0046
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1201.45,                last time consumption/overall running time: 1140.8296s / 51716.2789 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0046
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1230.4,                last time consumption/overall running time: 1175.9577s / 52892.2367 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0045
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1225.1,                last time consumption/overall running time: 1166.8994s / 54059.1360 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0045
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1180.5,                last time consumption/overall running time: 1121.3372s / 55180.4732 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0046
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0048
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1165.4,                last time consumption/overall running time: 1108.9834s / 56289.4566 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1255.9,                last time consumption/overall running time: 1198.7281s / 57488.1848 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1245.9,                last time consumption/overall running time: 1185.1855s / 58673.3703 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1223.5,                last time consumption/overall running time: 1169.5841s / 59842.9545 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0044
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1199.2,                last time consumption/overall running time: 1143.7957s / 60986.7501 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0043
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1223.35,                last time consumption/overall running time: 1161.6751s / 62148.4252 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0039
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1239.65,                last time consumption/overall running time: 1181.5074s / 63329.9326 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0037
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1163.85,                last time consumption/overall running time: 1111.1979s / 64441.1305 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0036
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1198.05,                last time consumption/overall running time: 1149.1038s / 65590.2343 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0033
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0033
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1226.75,                last time consumption/overall running time: 1184.0234s / 66774.2576 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0036
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0036
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1197.45,                last time consumption/overall running time: 1141.7439s / 67916.0015 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1230.05,                last time consumption/overall running time: 1168.4031s / 69084.4046 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0040
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1214.95,                last time consumption/overall running time: 1149.4638s / 70233.8684 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0040
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1193.6,                last time consumption/overall running time: 1134.2863s / 71368.1548 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0040
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1168.85,                last time consumption/overall running time: 1111.6378s / 72479.7926 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0041
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1207.7,                last time consumption/overall running time: 1140.8573s / 73620.6499 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0036
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0040
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1228.7,                last time consumption/overall running time: 1161.7552s / 74782.4051 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1217.25,                last time consumption/overall running time: 1154.7263s / 75937.1314 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0039
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1228.55,                last time consumption/overall running time: 1163.0024s / 77100.1338 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0039
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1250.95,                last time consumption/overall running time: 1185.4857s / 78285.6194 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0040
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1223.65,                last time consumption/overall running time: 1159.5242s / 79445.1436 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1243.9,                last time consumption/overall running time: 1178.6392s / 80623.7828 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1173.55,                last time consumption/overall running time: 1114.3345s / 81738.1173 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1286.3,                last time consumption/overall running time: 1215.3383s / 82953.4556 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0043
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1243.0,                last time consumption/overall running time: 1178.8471s / 84132.3028 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0043
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1278.6,                last time consumption/overall running time: 1212.5938s / 85344.8966 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0045
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1260.6,                last time consumption/overall running time: 1195.7088s / 86540.6053 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0043
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0042
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1251.55,                last time consumption/overall running time: 1183.5612s / 87724.1666 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0040
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1274.1,                last time consumption/overall running time: 1203.5951s / 88927.7617 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0041
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1267.35,                last time consumption/overall running time: 1198.7178s / 90126.4795 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0043
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0043
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1246.25,                last time consumption/overall running time: 1176.1622s / 91302.6417 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1242.3,                last time consumption/overall running time: 1172.6494s / 92475.2911 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0039
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1270.2,                last time consumption/overall running time: 1196.5753s / 93671.8664 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0040
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1260.55,                last time consumption/overall running time: 1187.4547s / 94859.3212 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0041
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1255.45,                last time consumption/overall running time: 1176.0920s / 96035.4131 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0046
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1258.85,                last time consumption/overall running time: 1180.3030s / 97215.7161 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0037
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1350.5,                last time consumption/overall running time: 1251.6603s / 98467.3764 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1270.15,                last time consumption/overall running time: 1180.7550s / 99648.1314 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0048
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1271.65,                last time consumption/overall running time: 1180.9995s / 100829.1309 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0039
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1360.15,                last time consumption/overall running time: 1269.4547s / 102098.5855 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0041
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1344.4,                last time consumption/overall running time: 1247.4653s / 103346.0508 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0042
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1326.1,                last time consumption/overall running time: 1236.3329s / 104582.3837 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0042
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1343.6,                last time consumption/overall running time: 1249.4594s / 105831.8430 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1448.95,                last time consumption/overall running time: 1353.7514s / 107185.5945 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0049
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1268.65,                last time consumption/overall running time: 1183.4948s / 108369.0892 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0047
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1282.7,                last time consumption/overall running time: 1186.5283s / 109555.6175 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1372.3,                last time consumption/overall running time: 1270.6117s / 110826.2292 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0041
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1427.55,                last time consumption/overall running time: 1327.3810s / 112153.6102 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1388.7,                last time consumption/overall running time: 1294.9553s / 113448.5654 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1364.85,                last time consumption/overall running time: 1272.8011s / 114721.3665 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0045
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1380.9,                last time consumption/overall running time: 1286.4107s / 116007.7772 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1320.6,                last time consumption/overall running time: 1233.4558s / 117241.2331 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1296.3,                last time consumption/overall running time: 1205.7004s / 118446.9334 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1428.6,                last time consumption/overall running time: 1337.7980s / 119784.7314 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0045
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1390.55,                last time consumption/overall running time: 1307.6520s / 121092.3833 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0047
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1337.75,                last time consumption/overall running time: 1244.7203s / 122337.1036 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0050
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1341.15,                last time consumption/overall running time: 1257.9384s / 123595.0420 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0044
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1330.35,                last time consumption/overall running time: 1238.0646s / 124833.1066 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0047
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1317.05,                last time consumption/overall running time: 1223.6553s / 126056.7619 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1353.25,                last time consumption/overall running time: 1260.8388s / 127317.6007 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0042
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1353.4,                last time consumption/overall running time: 1261.6988s / 128579.2996 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1352.15,                last time consumption/overall running time: 1260.3243s / 129839.6239 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1332.45,                last time consumption/overall running time: 1235.4565s / 131075.0804 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0044
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0041
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1267.65,                last time consumption/overall running time: 1179.2542s / 132254.3346 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0047
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1318.9,                last time consumption/overall running time: 1229.3418s / 133483.6764 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0046
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1261.65,                last time consumption/overall running time: 1175.7682s / 134659.4446 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0043
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1377.6,                last time consumption/overall running time: 1284.4559s / 135943.9006 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0042
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1351.95,                last time consumption/overall running time: 1269.0498s / 137212.9503 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0044
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1374.5,                last time consumption/overall running time: 1290.3801s / 138503.3304 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0046
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1272.0,                last time consumption/overall running time: 1194.5022s / 139697.8326 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0049
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1235.0,                last time consumption/overall running time: 1156.1801s / 140854.0127 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1285.65,                last time consumption/overall running time: 1199.8525s / 142053.8653 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0042
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1324.45,                last time consumption/overall running time: 1235.7422s / 143289.6074 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1261.25,                last time consumption/overall running time: 1168.8212s / 144458.4286 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1326.95,                last time consumption/overall running time: 1222.7536s / 145681.1821 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1228.95,                last time consumption/overall running time: 1131.1524s / 146812.3345 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1314.3,                last time consumption/overall running time: 1205.5978s / 148017.9323 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0040
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1347.05,                last time consumption/overall running time: 1236.4781s / 149254.4104 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1381.85,                last time consumption/overall running time: 1263.8626s / 150518.2730 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0043
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1325.7,                last time consumption/overall running time: 1209.8859s / 151728.1589 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0043
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0043
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1407.95,                last time consumption/overall running time: 1284.4120s / 153012.5709 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1364.85,                last time consumption/overall running time: 1251.9554s / 154264.5264 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1332.35,                last time consumption/overall running time: 1209.4476s / 155473.9740 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0041
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1279.45,                last time consumption/overall running time: 1164.8954s / 156638.8694 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0042
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1291.95,                last time consumption/overall running time: 1182.5044s / 157821.3738 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0036
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0039
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1370.7,                last time consumption/overall running time: 1253.3301s / 159074.7038 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0035
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0039
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1279.55,                last time consumption/overall running time: 1168.0340s / 160242.7378 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0035
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0037
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1244.45,                last time consumption/overall running time: 1130.2565s / 161372.9943 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0032
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0036
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1268.5,                last time consumption/overall running time: 1142.0684s / 162515.0627 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0035
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0039
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1420.15,                last time consumption/overall running time: 1287.8038s / 163802.8666 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1337.05,                last time consumption/overall running time: 1209.7273s / 165012.5939 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0046
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1298.75,                last time consumption/overall running time: 1172.1989s / 166184.7928 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1347.6,                last time consumption/overall running time: 1221.5741s / 167406.3669 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0047
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1386.6,                last time consumption/overall running time: 1245.9621s / 168652.3290 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1314.15,                last time consumption/overall running time: 1182.4688s / 169834.7978 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0048
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1399.35,                last time consumption/overall running time: 1264.3715s / 171099.1692 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0049
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0045
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1300.85,                last time consumption/overall running time: 1170.3350s / 172269.5042 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1368.85,                last time consumption/overall running time: 1233.5008s / 173503.0050 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1337.3,                last time consumption/overall running time: 1206.9971s / 174710.0021 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0049
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0044
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1476.65,                last time consumption/overall running time: 1340.7030s / 176050.7051 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0049
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1407.35,                last time consumption/overall running time: 1263.7005s / 177314.4055 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1393.0,                last time consumption/overall running time: 1247.9564s / 178562.3619 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1386.75,                last time consumption/overall running time: 1238.4987s / 179800.8606 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1394.35,                last time consumption/overall running time: 1246.2661s / 181047.1267 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0055
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1305.3,                last time consumption/overall running time: 1178.6809s / 182225.8075 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0051
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1275.6,                last time consumption/overall running time: 1147.5851s / 183373.3927 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0045
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1460.0,                last time consumption/overall running time: 1310.3124s / 184683.7051 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1432.8,                last time consumption/overall running time: 1279.6154s / 185963.3205 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0053
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1362.9,                last time consumption/overall running time: 1212.4975s / 187175.8180 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0049
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0049
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1385.1,                last time consumption/overall running time: 1240.6796s / 188416.4976 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0050
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1348.5,                last time consumption/overall running time: 1203.8747s / 189620.3722 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1317.8,                last time consumption/overall running time: 1165.5929s / 190785.9651 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0044
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1424.15,                last time consumption/overall running time: 1252.0038s / 192037.9690 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0043
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1316.3,                last time consumption/overall running time: 1159.7676s / 193197.7365 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0046
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1493.9,                last time consumption/overall running time: 1309.9691s / 194507.7057 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0043
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1373.75,                last time consumption/overall running time: 1204.8771s / 195712.5827 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0045
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0046
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1393.2,                last time consumption/overall running time: 1218.2665s / 196930.8492 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1334.2,                last time consumption/overall running time: 1159.2403s / 198090.0895 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0043
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0044
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1239.0,                last time consumption/overall running time: 1074.2791s / 199164.3686 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0040
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1312.4,                last time consumption/overall running time: 1127.7320s / 200292.1006 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0040
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1380.1,                last time consumption/overall running time: 1173.5879s / 201465.6884 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0042
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1310.85,                last time consumption/overall running time: 1113.8253s / 202579.5137 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1384.65,                last time consumption/overall running time: 1181.5172s / 203761.0309 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0045
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0045
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1310.0,                last time consumption/overall running time: 1114.4549s / 204875.4859 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1240.5,                last time consumption/overall running time: 1059.2126s / 205934.6984 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0044
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1294.25,                last time consumption/overall running time: 1101.2376s / 207035.9360 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0043
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1240.15,                last time consumption/overall running time: 1061.8777s / 208097.8137 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0041
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1491.95,                last time consumption/overall running time: 1275.5960s / 209373.4098 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0044
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1331.5,                last time consumption/overall running time: 1140.8392s / 210514.2490 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1337.0,                last time consumption/overall running time: 1142.6341s / 211656.8831 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0045
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0046
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1368.1,                last time consumption/overall running time: 1171.2402s / 212828.1233 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0043
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0045
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1381.3,                last time consumption/overall running time: 1184.3569s / 214012.4802 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1474.95,                last time consumption/overall running time: 1247.0863s / 215259.5666 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1354.8,                last time consumption/overall running time: 1145.8618s / 216405.4283 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1411.6,                last time consumption/overall running time: 1190.0292s / 217595.4576 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1419.7,                last time consumption/overall running time: 1197.6886s / 218793.1461 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1442.05,                last time consumption/overall running time: 1217.5781s / 220010.7242 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1485.45,                last time consumption/overall running time: 1247.6830s / 221258.4072 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0050
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1473.35,                last time consumption/overall running time: 1241.7496s / 222500.1568 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1420.3,                last time consumption/overall running time: 1203.8980s / 223704.0548 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0046
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1451.15,                last time consumption/overall running time: 1219.6028s / 224923.6576 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1449.55,                last time consumption/overall running time: 1221.6980s / 226145.3556 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0049
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0048
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1387.35,                last time consumption/overall running time: 1161.4136s / 227306.7692 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0054
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1348.15,                last time consumption/overall running time: 1122.6503s / 228429.4195 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0047
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1441.7,                last time consumption/overall running time: 1194.2218s / 229623.6413 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1398.25,                last time consumption/overall running time: 1153.1405s / 230776.7818 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1406.35,                last time consumption/overall running time: 1167.7052s / 231944.4870 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0046
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1397.35,                last time consumption/overall running time: 1152.2854s / 233096.7724 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0050
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0047
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1389.6,                last time consumption/overall running time: 1148.9142s / 234245.6866 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1376.1,                last time consumption/overall running time: 1146.8511s / 235392.5377 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0050
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1454.55,                last time consumption/overall running time: 1205.3053s / 236597.8430 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1377.25,                last time consumption/overall running time: 1139.0894s / 237736.9323 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1381.6,                last time consumption/overall running time: 1140.0020s / 238876.9343 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1367.2,                last time consumption/overall running time: 1132.2051s / 240009.1394 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0042
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1472.15,                last time consumption/overall running time: 1219.0088s / 241228.1481 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1373.95,                last time consumption/overall running time: 1137.5320s / 242365.6802 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1404.2,                last time consumption/overall running time: 1168.0900s / 243533.7702 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1495.0,                last time consumption/overall running time: 1233.4907s / 244767.2609 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0044
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1443.8,                last time consumption/overall running time: 1192.7253s / 245959.9863 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1434.45,                last time consumption/overall running time: 1187.5015s / 247147.4878 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0048
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0044
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1344.15,                last time consumption/overall running time: 1106.7155s / 248254.2033 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0045
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0041
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1445.2,                last time consumption/overall running time: 1194.8253s / 249449.0286 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0042
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1502.8,                last time consumption/overall running time: 1243.4940s / 250692.5226 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0045
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0041
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1566.3,                last time consumption/overall running time: 1290.9956s / 251983.5182 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0041
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1541.45,                last time consumption/overall running time: 1264.9783s / 253248.4965 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0047
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1466.85,                last time consumption/overall running time: 1196.5445s / 254445.0410 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1386.9,                last time consumption/overall running time: 1137.1286s / 255582.1696 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0049
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1368.4,                last time consumption/overall running time: 1127.5924s / 256709.7620 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0043
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1375.1,                last time consumption/overall running time: 1124.4242s / 257834.1862 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0044
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0041
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1527.25,                last time consumption/overall running time: 1241.5825s / 259075.7687 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0044
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1338.9,                last time consumption/overall running time: 1091.3410s / 260167.1097 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0050
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0046
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1416.7,                last time consumption/overall running time: 1148.5870s / 261315.6966 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1403.8,                last time consumption/overall running time: 1140.6856s / 262456.3822 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0045
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1395.45,                last time consumption/overall running time: 1126.9051s / 263583.2873 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1424.15,                last time consumption/overall running time: 1145.6024s / 264728.8897 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1410.75,                last time consumption/overall running time: 1138.1148s / 265867.0045 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0050
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1348.8,                last time consumption/overall running time: 1091.9515s / 266958.9560 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0046
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1502.85,                last time consumption/overall running time: 1224.2128s / 268183.1688 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1457.9,                last time consumption/overall running time: 1188.0224s / 269371.1912 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1366.25,                last time consumption/overall running time: 1109.4442s / 270480.6354 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1381.2,                last time consumption/overall running time: 1124.2479s / 271604.8832 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0050
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0048
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1378.55,                last time consumption/overall running time: 1116.3240s / 272721.2072 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0050
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1346.6,                last time consumption/overall running time: 1079.5024s / 273800.7096 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0050
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0050
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1432.2,                last time consumption/overall running time: 1159.7488s / 274960.4584 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0048
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1457.65,                last time consumption/overall running time: 1180.5808s / 276141.0392 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1411.75,                last time consumption/overall running time: 1148.8030s / 277289.8421 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0046
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0048
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1410.75,                last time consumption/overall running time: 1141.0139s / 278430.8561 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0050
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1444.55,                last time consumption/overall running time: 1170.8578s / 279601.7139 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0048
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1510.25,                last time consumption/overall running time: 1220.1599s / 280821.8738 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0051
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0050
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1611.85,                last time consumption/overall running time: 1294.1618s / 282116.0356 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0054
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0054
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1432.25,                last time consumption/overall running time: 1141.4050s / 283257.4406 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0053
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1405.65,                last time consumption/overall running time: 1123.8113s / 284381.2518 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0051
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1463.8,                last time consumption/overall running time: 1181.7333s / 285562.9851 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0046
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1525.95,                last time consumption/overall running time: 1226.5419s / 286789.5270 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0047
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1407.2,                last time consumption/overall running time: 1127.6902s / 287917.2172 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1423.9,                last time consumption/overall running time: 1137.9442s / 289055.1615 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0051
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1482.1,                last time consumption/overall running time: 1185.2936s / 290240.4550 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1526.55,                last time consumption/overall running time: 1224.3455s / 291464.8005 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0047
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0049
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1387.5,                last time consumption/overall running time: 1105.2616s / 292570.0621 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0050
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1433.25,                last time consumption/overall running time: 1139.9311s / 293709.9932 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1489.35,                last time consumption/overall running time: 1163.2742s / 294873.2674 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0048
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1413.05,                last time consumption/overall running time: 1105.7638s / 295979.0312 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0049
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1445.1,                last time consumption/overall running time: 1134.9940s / 297114.0253 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0047
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1476.5,                last time consumption/overall running time: 1156.8856s / 298270.9109 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0049
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1523.5,                last time consumption/overall running time: 1183.4960s / 299454.4068 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0053
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0051
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1445.85,                last time consumption/overall running time: 1127.6345s / 300582.0414 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0050
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1499.8,                last time consumption/overall running time: 1165.7659s / 301747.8072 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0053
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0051
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1500.2,                last time consumption/overall running time: 1154.3921s / 302902.1994 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0053
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0050
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1491.95,                last time consumption/overall running time: 1151.0236s / 304053.2230 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0051
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1402.4,                last time consumption/overall running time: 1088.2326s / 305141.4556 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0049
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1361.45,                last time consumption/overall running time: 1043.2057s / 306184.6613 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1388.55,                last time consumption/overall running time: 1070.1525s / 307254.8137 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0047
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1489.5,                last time consumption/overall running time: 1139.5155s / 308394.3293 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0048
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1427.6,                last time consumption/overall running time: 1091.6569s / 309485.9861 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1570.95,                last time consumption/overall running time: 1186.6566s / 310672.6428 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1521.0,                last time consumption/overall running time: 1166.1574s / 311838.8002 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0058
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0054
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1550.45,                last time consumption/overall running time: 1173.7367s / 313012.5369 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0055
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0051
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1431.7,                last time consumption/overall running time: 1078.1633s / 314090.7002 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0056
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1515.95,                last time consumption/overall running time: 1146.8887s / 315237.5889 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1514.1,                last time consumption/overall running time: 1128.7312s / 316366.3202 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0053
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1445.5,                last time consumption/overall running time: 1078.2873s / 317444.6075 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0052
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1519.4,                last time consumption/overall running time: 1121.4500s / 318566.0575 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0052
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1570.85,                last time consumption/overall running time: 1161.2909s / 319727.3484 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0049
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1537.65,                last time consumption/overall running time: 1139.8967s / 320867.2450 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0058
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0054
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1601.55,                last time consumption/overall running time: 1177.6513s / 322044.8963 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0060
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0057
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1501.85,                last time consumption/overall running time: 1109.0045s / 323153.9008 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0052
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0053
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1571.8,                last time consumption/overall running time: 1150.8227s / 324304.7235 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1567.1,                last time consumption/overall running time: 1147.5583s / 325452.2818 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0050
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1580.3,                last time consumption/overall running time: 1150.5836s / 326602.8654 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0054
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0051
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1570.1,                last time consumption/overall running time: 1140.2725s / 327743.1379 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0052
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1561.55,                last time consumption/overall running time: 1138.1187s / 328881.2566 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1610.2,                last time consumption/overall running time: 1177.0782s / 330058.3348 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0053
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0053
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1537.7,                last time consumption/overall running time: 1122.6264s / 331180.9612 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1513.9,                last time consumption/overall running time: 1104.0159s / 332284.9770 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0050
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1560.65,                last time consumption/overall running time: 1141.8142s / 333426.7912 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0052
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1560.95,                last time consumption/overall running time: 1122.8051s / 334549.5963 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1656.65,                last time consumption/overall running time: 1191.9187s / 335741.5150 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0049
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1517.9,                last time consumption/overall running time: 1099.6129s / 336841.1279 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0049
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0051
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1543.65,                last time consumption/overall running time: 1107.2885s / 337948.4164 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0049
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0051
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1653.7,                last time consumption/overall running time: 1190.8816s / 339139.2980 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0049
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0048
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1633.0,                last time consumption/overall running time: 1157.2759s / 340296.5739 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0049
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1561.35,                last time consumption/overall running time: 1108.0832s / 341404.6571 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1662.35,                last time consumption/overall running time: 1180.7093s / 342585.3664 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0046
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1592.55,                last time consumption/overall running time: 1135.3982s / 343720.7646 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0050
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0050
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1720.75,                last time consumption/overall running time: 1227.2628s / 344948.0274 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0053
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1678.6,                last time consumption/overall running time: 1188.7901s / 346136.8175 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1580.5,                last time consumption/overall running time: 1115.0768s / 347251.8943 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0051
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1576.25,                last time consumption/overall running time: 1112.8769s / 348364.7713 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1629.55,                last time consumption/overall running time: 1150.9116s / 349515.6829 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0050
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1583.55,                last time consumption/overall running time: 1121.5797s / 350637.2625 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0052
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0045
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1510.45,                last time consumption/overall running time: 1063.2748s / 351700.5374 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0049
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1640.45,                last time consumption/overall running time: 1146.5075s / 352847.0449 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0049
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1584.45,                last time consumption/overall running time: 1112.3999s / 353959.4447 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0045
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1580.75,                last time consumption/overall running time: 1117.1602s / 355076.6049 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0049
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1618.9,                last time consumption/overall running time: 1150.4487s / 356227.0536 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1572.4,                last time consumption/overall running time: 1106.2713s / 357333.3249 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0050
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1581.5,                last time consumption/overall running time: 1105.5513s / 358438.8762 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0047
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1592.65,                last time consumption/overall running time: 1116.8171s / 359555.6932 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0048
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1582.85,                last time consumption/overall running time: 1113.9013s / 360669.5945 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0049
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1531.05,                last time consumption/overall running time: 1072.9187s / 361742.5132 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0051
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1442.3,                last time consumption/overall running time: 1017.9382s / 362760.4514 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1649.05,                last time consumption/overall running time: 1152.2587s / 363912.7101 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0046
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1614.75,                last time consumption/overall running time: 1119.5613s / 365032.2713 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0047
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1758.05,                last time consumption/overall running time: 1221.1020s / 366253.3734 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0049
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1579.95,                last time consumption/overall running time: 1092.4577s / 367345.8311 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.0500,                 loss: 0.0049
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1500.8,                last time consumption/overall running time: 1038.6666s / 368384.4976 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1628.6,                last time consumption/overall running time: 1119.7463s / 369504.2439 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0050
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1726.1,                last time consumption/overall running time: 1192.1826s / 370696.4265 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0055
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0053
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1772.9,                last time consumption/overall running time: 1226.3516s / 371922.7781 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0049
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1771.3,                last time consumption/overall running time: 1214.4681s / 373137.2462 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0050
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1720.05,                last time consumption/overall running time: 1169.0822s / 374306.3283 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0049
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0048
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1624.15,                last time consumption/overall running time: 1096.3337s / 375402.6620 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1678.4,                last time consumption/overall running time: 1141.3690s / 376544.0310 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0050
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1826.75,                last time consumption/overall running time: 1242.9253s / 377786.9563 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0051
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1685.8,                last time consumption/overall running time: 1153.4391s / 378940.3954 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0052
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1689.85,                last time consumption/overall running time: 1153.1135s / 380093.5089 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0051
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1602.3,                last time consumption/overall running time: 1090.5030s / 381184.0119 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0049
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1533.0,                last time consumption/overall running time: 1055.6435s / 382239.6554 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0048
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1766.15,                last time consumption/overall running time: 1203.1780s / 383442.8334 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0048
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1800.35,                last time consumption/overall running time: 1241.3674s / 384684.2008 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0052
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1830.7,                last time consumption/overall running time: 1370.6931s / 386054.8939 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0051
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1840.8,                last time consumption/overall running time: 1434.6393s / 387489.5332 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0048
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1807.75,                last time consumption/overall running time: 1404.8904s / 388894.4236 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0050
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1821.6,                last time consumption/overall running time: 1431.9181s / 390326.3417 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0050
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1752.65,                last time consumption/overall running time: 1363.3125s / 391689.6542 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0051
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 1662.65,                last time consumption/overall running time: 1299.8543s / 392989.5084 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0054
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0052
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1712.7,                last time consumption/overall running time: 1328.7064s / 394318.2149 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0054
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1612.55,                last time consumption/overall running time: 1250.8356s / 395569.0505 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1578.0,                last time consumption/overall running time: 1227.3554s / 396796.4059 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0054
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0050
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1728.35,                last time consumption/overall running time: 1331.0254s / 398127.4313 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0055
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0051
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1825.4,                last time consumption/overall running time: 1406.1738s / 399533.6051 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0056
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1636.65,                last time consumption/overall running time: 1267.6815s / 400801.2865 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0054
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1623.85,                last time consumption/overall running time: 1251.9234s / 402053.2100 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0055
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1779.15,                last time consumption/overall running time: 1360.8187s / 403414.0287 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0048
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1757.5,                last time consumption/overall running time: 1339.5812s / 404753.6099 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0051
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1643.45,                last time consumption/overall running time: 1255.2375s / 406008.8474 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1725.9,                last time consumption/overall running time: 1320.1969s / 407329.0443 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0051
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1743.15,                last time consumption/overall running time: 1330.6818s / 408659.7261 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0055
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0050
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1925.7,                last time consumption/overall running time: 1464.7816s / 410124.5077 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0052
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1799.05,                last time consumption/overall running time: 1359.3463s / 411483.8540 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0054
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1824.7,                last time consumption/overall running time: 1375.8156s / 412859.6696 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0052
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1793.15,                last time consumption/overall running time: 1358.7142s / 414218.3837 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0055
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0051
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1705.4,                last time consumption/overall running time: 1290.2561s / 415508.6399 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0059
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1899.25,                last time consumption/overall running time: 1439.7498s / 416948.3897 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0054
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0052
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1799.2,                last time consumption/overall running time: 1366.6496s / 418315.0393 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0051
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1764.7,                last time consumption/overall running time: 1329.6326s / 419644.6719 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0055
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0054
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1642.35,                last time consumption/overall running time: 1236.2377s / 420880.9096 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0056
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1706.3,                last time consumption/overall running time: 1282.1292s / 422163.0388 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0055
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0053
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1678.3,                last time consumption/overall running time: 1245.2510s / 423408.2898 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0054
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1557.5,                last time consumption/overall running time: 1171.0443s / 424579.3340 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0054
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1647.8,                last time consumption/overall running time: 1238.3751s / 425817.7092 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0052
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1547.6,                last time consumption/overall running time: 1157.3395s / 426975.0487 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1662.05,                last time consumption/overall running time: 1248.5792s / 428223.6279 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0054
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0052
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1713.5,                last time consumption/overall running time: 1283.8448s / 429507.4727 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0054
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1668.35,                last time consumption/overall running time: 1238.8437s / 430746.3164 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0055
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0051
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1667.65,                last time consumption/overall running time: 1254.0629s / 432000.3793 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0054
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0053
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1657.4,                last time consumption/overall running time: 1229.1168s / 433229.4961 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1651.35,                last time consumption/overall running time: 1223.6485s / 434453.1446 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0050
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1433.75,                last time consumption/overall running time: 1074.1329s / 435527.2775 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1553.15,                last time consumption/overall running time: 1160.6683s / 436687.9458 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0048
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0048
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1577.25,                last time consumption/overall running time: 1159.4214s / 437847.3673 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0048
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1607.3,                last time consumption/overall running time: 1179.9098s / 439027.2770 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0048
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1471.6,                last time consumption/overall running time: 1089.0418s / 440116.3188 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0048
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0046
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1483.95,                last time consumption/overall running time: 1099.4470s / 441215.7658 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.0500,                 loss: 0.0046
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1563.7,                last time consumption/overall running time: 1146.0615s / 442361.8272 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0049
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0050
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1600.15,                last time consumption/overall running time: 1179.1774s / 443541.0046 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0046
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1654.25,                last time consumption/overall running time: 1210.8576s / 444751.8622 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0051
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0049
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1558.4,                last time consumption/overall running time: 1126.2063s / 445878.0686 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.0055
env0_second_0:                 episode reward: 5.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1822.75,                last time consumption/overall running time: 1302.4400s / 447180.5086 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0052
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1705.75,                last time consumption/overall running time: 1195.7958s / 448376.3043 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0057
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1623.6,                last time consumption/overall running time: 1119.6053s / 449495.9096 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0056
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0053
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1859.1,                last time consumption/overall running time: 1291.1076s / 450787.0172 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0053
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1787.05,                last time consumption/overall running time: 1241.0890s / 452028.1062 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0055
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0050
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1890.55,                last time consumption/overall running time: 1312.7144s / 453340.8206 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0055
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0049
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1754.8,                last time consumption/overall running time: 1206.7595s / 454547.5801 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0053
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1689.95,                last time consumption/overall running time: 1133.2425s / 455680.8226 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0055
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0052
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1665.5,                last time consumption/overall running time: 1105.7422s / 456786.5648 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0053
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1731.45,                last time consumption/overall running time: 1146.6302s / 457933.1949 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0054
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0052
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1555.45,                last time consumption/overall running time: 1028.6674s / 458961.8623 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0053
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0052
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1583.25,                last time consumption/overall running time: 1054.4567s / 460016.3190 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0050
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1704.85,                last time consumption/overall running time: 1129.7432s / 461146.0621 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0048
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1597.25,                last time consumption/overall running time: 1056.4281s / 462202.4902 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0049
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0051
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1727.3,                last time consumption/overall running time: 1139.1914s / 463341.6816 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0050
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1719.9,                last time consumption/overall running time: 1144.6524s / 464486.3340 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0050
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0048
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1942.7,                last time consumption/overall running time: 1279.7894s / 465766.1235 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0050
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0049
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1817.25,                last time consumption/overall running time: 1298.0906s / 467064.2141 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1758.55,                last time consumption/overall running time: 1332.4305s / 468396.6446 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1722.65,                last time consumption/overall running time: 1302.1724s / 469698.8170 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.0054
env0_second_0:                 episode reward: 5.6000,                 loss: 0.0053
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1634.1,                last time consumption/overall running time: 1237.8501s / 470936.6671 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1648.8,                last time consumption/overall running time: 1254.8985s / 472191.5656 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0049
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0051
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1826.35,                last time consumption/overall running time: 1377.6597s / 473569.2252 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0052
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1781.35,                last time consumption/overall running time: 1362.1196s / 474931.3449 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0051
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1713.9,                last time consumption/overall running time: 1294.9477s / 476226.2926 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0049
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1679.6,                last time consumption/overall running time: 1262.9328s / 477489.2254 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0048
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0047
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1819.7,                last time consumption/overall running time: 1375.2342s / 478864.4596 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0051
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1894.5,                last time consumption/overall running time: 1432.5189s / 480296.9785 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0055
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0054
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1729.9,                last time consumption/overall running time: 1313.5498s / 481610.5283 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0053
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1683.35,                last time consumption/overall running time: 1263.9232s / 482874.4515 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0050
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1796.9,                last time consumption/overall running time: 1365.0690s / 484239.5205 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1758.5,                last time consumption/overall running time: 1338.0310s / 485577.5515 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0050
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1618.75,                last time consumption/overall running time: 1225.5538s / 486803.1053 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0056
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0055
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1664.1,                last time consumption/overall running time: 1256.1091s / 488059.2144 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0056
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1851.8,                last time consumption/overall running time: 1405.9202s / 489465.1346 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0056
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1872.4,                last time consumption/overall running time: 1432.7260s / 490897.8606 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0054
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1786.45,                last time consumption/overall running time: 1344.4129s / 492242.2735 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0055
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0057
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1881.4,                last time consumption/overall running time: 1421.7080s / 493663.9815 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0055
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0057
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1809.25,                last time consumption/overall running time: 1368.7571s / 495032.7386 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0055
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0057
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1815.25,                last time consumption/overall running time: 1371.8688s / 496404.6074 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0057
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1703.8,                last time consumption/overall running time: 1264.2243s / 497668.8318 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0053
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0056
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1733.3,                last time consumption/overall running time: 1304.2996s / 498973.1314 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0054
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0057
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1701.3,                last time consumption/overall running time: 1293.5279s / 500266.6594 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1685.7,                last time consumption/overall running time: 1266.5955s / 501533.2549 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0056
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0058
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1811.1,                last time consumption/overall running time: 1372.4705s / 502905.7254 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1904.5,                last time consumption/overall running time: 1441.9800s / 504347.7054 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0056
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1945.6,                last time consumption/overall running time: 1468.1964s / 505815.9019 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0055
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1829.8,                last time consumption/overall running time: 1375.7553s / 507191.6572 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0053
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1916.4,                last time consumption/overall running time: 1434.7274s / 508626.3846 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0057
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0056
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1831.8,                last time consumption/overall running time: 1841.8720s / 510468.2566 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0055
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0054
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1947.15,                last time consumption/overall running time: 1963.1721s / 512431.4287 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0054
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1842.9,                last time consumption/overall running time: 1861.7570s / 514293.1857 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0060
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1793.45,                last time consumption/overall running time: 1794.0490s / 516087.2347 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0057
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1897.5,                last time consumption/overall running time: 1895.1097s / 517982.3445 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0055
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0058
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1871.55,                last time consumption/overall running time: 1857.2863s / 519839.6308 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0058
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0058
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1950.35,                last time consumption/overall running time: 1926.5256s / 521766.1564 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0056
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0058
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1794.7,                last time consumption/overall running time: 1768.7832s / 523534.9396 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0058
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1930.65,                last time consumption/overall running time: 1905.2479s / 525440.1875 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0057
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1864.15,                last time consumption/overall running time: 1836.2000s / 527276.3874 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0056
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0057
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1909.05,                last time consumption/overall running time: 1858.9632s / 529135.3506 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0056
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1840.85,                last time consumption/overall running time: 1806.4614s / 530941.8120 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0058
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1774.45,                last time consumption/overall running time: 1729.4888s / 532671.3008 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0053
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0057
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1815.85,                last time consumption/overall running time: 1769.4394s / 534440.7402 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0053
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1956.6,                last time consumption/overall running time: 1906.9859s / 536347.7261 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0054
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0060
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1946.1,                last time consumption/overall running time: 1879.6006s / 538227.3267 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0055
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 2012.75,                last time consumption/overall running time: 1952.3099s / 540179.6366 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0057
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1929.75,                last time consumption/overall running time: 1850.9547s / 542030.5912 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0056
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1961.55,                last time consumption/overall running time: 1889.3372s / 543919.9284 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0057
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1903.0,                last time consumption/overall running time: 1826.1063s / 545746.0347 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0054
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0057
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1966.2,                last time consumption/overall running time: 1873.4356s / 547619.4703 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1931.8,                last time consumption/overall running time: 1847.3554s / 549466.8257 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0060
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1950.55,                last time consumption/overall running time: 1872.9469s / 551339.7726 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0060
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1915.45,                last time consumption/overall running time: 1841.2699s / 553181.0426 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0054
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1959.1,                last time consumption/overall running time: 1862.2247s / 555043.2672 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0054
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1969.7,                last time consumption/overall running time: 1888.2406s / 556931.5079 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0052
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1932.6,                last time consumption/overall running time: 1839.2031s / 558770.7110 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 2051.25,                last time consumption/overall running time: 1902.0414s / 560672.7524 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0056
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 2020.35,                last time consumption/overall running time: 1880.9932s / 562553.7456 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0055
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1965.9,                last time consumption/overall running time: 1815.5999s / 564369.3456 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0058
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1959.55,                last time consumption/overall running time: 1796.7502s / 566166.0957 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0053
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0055
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1896.3,                last time consumption/overall running time: 1761.8104s / 567927.9061 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0056
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0058
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1825.9,                last time consumption/overall running time: 1689.6563s / 569617.5624 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1868.7,                last time consumption/overall running time: 1729.1486s / 571346.7110 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0057
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1821.9,                last time consumption/overall running time: 1679.6416s / 573026.3527 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0060
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 2023.85,                last time consumption/overall running time: 1862.0109s / 574888.3635 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 2040.9,                last time consumption/overall running time: 1871.5491s / 576759.9126 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1862.55,                last time consumption/overall running time: 1708.0289s / 578467.9415 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0056
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0055
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1926.05,                last time consumption/overall running time: 1760.4900s / 580228.4316 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0057
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1911.7,                last time consumption/overall running time: 1740.9827s / 581969.4143 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0056
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1848.5,                last time consumption/overall running time: 1678.6807s / 583648.0950 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0051
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1930.95,                last time consumption/overall running time: 1722.0955s / 585370.1904 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0059
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1979.65,                last time consumption/overall running time: 1746.3337s / 587116.5241 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1982.7,                last time consumption/overall running time: 1756.3945s / 588872.9186 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0056
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0056
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1830.75,                last time consumption/overall running time: 1607.4604s / 590480.3790 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0052
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0052
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1953.05,                last time consumption/overall running time: 1717.8908s / 592198.2698 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0052
env0_second_0:                 episode reward: -2.4000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 2007.25,                last time consumption/overall running time: 1778.8548s / 593977.1246 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0054
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1939.1,                last time consumption/overall running time: 1707.2455s / 595684.3701 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0057
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0054
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1986.6,                last time consumption/overall running time: 1735.3915s / 597419.7616 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0055
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0055
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1988.9,                last time consumption/overall running time: 1742.0053s / 599161.7669 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0057
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1981.45,                last time consumption/overall running time: 1736.4316s / 600898.1985 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0054
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1888.85,                last time consumption/overall running time: 1636.9493s / 602535.1478 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 2081.8,                last time consumption/overall running time: 1807.8895s / 604343.0373 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0057
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 2047.8,                last time consumption/overall running time: 1783.6023s / 606126.6395 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0054
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1983.9,                last time consumption/overall running time: 1712.8862s / 607839.5258 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0051
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0052
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1915.15,                last time consumption/overall running time: 1655.6720s / 609495.1978 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0052
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0053
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 2073.4,                last time consumption/overall running time: 1806.4522s / 611301.6499 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0056Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py:174: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.LongTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1918.85,                last time consumption/overall running time: 1659.9736s / 612961.6235 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 2055.85,                last time consumption/overall running time: 1773.0045s / 614734.6281 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0055
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 2166.2,                last time consumption/overall running time: 1855.0165s / 616589.6445 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0054
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 2062.65,                last time consumption/overall running time: 1739.0855s / 618328.7300 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1900.5,                last time consumption/overall running time: 1578.6119s / 619907.3419 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1967.3,                last time consumption/overall running time: 1651.0684s / 621558.4103 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 2073.1,                last time consumption/overall running time: 1712.2359s / 623270.6461 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0050
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0053
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1988.25,                last time consumption/overall running time: 1629.7863s / 624900.4324 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0050
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0049
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1984.75,                last time consumption/overall running time: 1637.6722s / 626538.1047 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0051
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0051
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 2122.15,                last time consumption/overall running time: 1779.1852s / 628317.2899 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0052
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0051
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1964.05,                last time consumption/overall running time: 1614.9607s / 629932.2506 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0050
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0050
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
