pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fdd78226fd0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.024 0.024 0.024 ... 0.024 0.024 0.024]
 [0.024 0.024 0.024 ... 0.024 0.024 0.024]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '26681' '26940' '28709']
 ['193' '5289' '7712' ... '26747' '26990' '28804']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_30000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_30000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_30000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6640s / 6.6640 s
agent0:                 episode reward: 1.1516,                 loss: nan
agent1:                 episode reward: -1.1516,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7560s / 13.4200 s
agent0:                 episode reward: -0.0878,                 loss: nan
agent1:                 episode reward: 0.0878,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6268s / 20.0468 s
agent0:                 episode reward: 0.1293,                 loss: nan
agent1:                 episode reward: -0.1293,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.2080s / 26.2548 s
agent0:                 episode reward: -0.1288,                 loss: nan
agent1:                 episode reward: 0.1288,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.5565s / 33.8113 s
agent0:                 episode reward: 0.2587,                 loss: nan
agent1:                 episode reward: -0.2587,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.4376s / 41.2489 s
agent0:                 episode reward: -0.0058,                 loss: nan
agent1:                 episode reward: 0.0058,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.8436s / 49.0925 s
agent0:                 episode reward: 0.5592,                 loss: nan
agent1:                 episode reward: -0.5592,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6359s / 55.7285 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.9971s / 62.7256 s
agent0:                 episode reward: 0.0217,                 loss: nan
agent1:                 episode reward: -0.0217,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.9675s / 69.6930 s
agent0:                 episode reward: 0.1903,                 loss: nan
agent1:                 episode reward: -0.1903,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.9691s / 76.6621 s
agent0:                 episode reward: 0.1722,                 loss: nan
agent1:                 episode reward: -0.1722,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.9655s / 175.6276 s
agent0:                 episode reward: 0.1348,                 loss: nan
agent1:                 episode reward: -0.1348,                 loss: 0.2027
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7733s / 413.4009 s
agent0:                 episode reward: 0.1475,                 loss: nan
agent1:                 episode reward: -0.1475,                 loss: 0.1829
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8171s / 661.2179 s
agent0:                 episode reward: 0.2144,                 loss: nan
agent1:                 episode reward: -0.2144,                 loss: 0.1710
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9272s / 904.1451 s
agent0:                 episode reward: -0.4600,                 loss: nan
agent1:                 episode reward: 0.4600,                 loss: 0.1620
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3759s / 1145.5210 s
agent0:                 episode reward: -0.0734,                 loss: nan
agent1:                 episode reward: 0.0734,                 loss: 0.1550
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6335s / 1392.1545 s
agent0:                 episode reward: -0.0787,                 loss: nan
agent1:                 episode reward: 0.0787,                 loss: 0.1514
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7141s / 1634.8686 s
agent0:                 episode reward: -0.0232,                 loss: nan
agent1:                 episode reward: 0.0232,                 loss: 0.1480
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6538s / 1879.5224 s
agent0:                 episode reward: 0.0517,                 loss: nan
agent1:                 episode reward: -0.0517,                 loss: 0.1452
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0960s / 2119.6184 s
agent0:                 episode reward: 0.1883,                 loss: nan
agent1:                 episode reward: -0.1883,                 loss: 0.1430
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1064s / 2357.7248 s
agent0:                 episode reward: 0.0620,                 loss: nan
agent1:                 episode reward: -0.0620,                 loss: 0.1406
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4106s / 2600.1354 s
agent0:                 episode reward: 0.2825,                 loss: nan
agent1:                 episode reward: -0.2825,                 loss: 0.1385
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3063s / 2842.4417 s
agent0:                 episode reward: 0.0469,                 loss: nan
agent1:                 episode reward: -0.0469,                 loss: 0.1381
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6681s / 3095.1098 s
agent0:                 episode reward: -0.1149,                 loss: nan
agent1:                 episode reward: 0.1149,                 loss: 0.1363
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7158s / 3338.8256 s
agent0:                 episode reward: 0.1235,                 loss: nan
agent1:                 episode reward: -0.1235,                 loss: 0.1359
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1630s / 3584.9886 s
agent0:                 episode reward: 0.3870,                 loss: nan
agent1:                 episode reward: -0.3870,                 loss: 0.1355
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4812s / 3834.4698 s
agent0:                 episode reward: -0.4256,                 loss: nan
agent1:                 episode reward: 0.4256,                 loss: 0.1337
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9242s / 4076.3940 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1354
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5842s / 4328.9782 s
agent0:                 episode reward: 0.6830,                 loss: nan
agent1:                 episode reward: -0.6830,                 loss: 0.1388
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5227s / 4576.5009 s
agent0:                 episode reward: -0.2079,                 loss: nan
agent1:                 episode reward: 0.2079,                 loss: 0.1321
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3052s / 4820.8061 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.1324
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3466s / 5059.1527 s
agent0:                 episode reward: -0.1370,                 loss: nan
agent1:                 episode reward: 0.1370,                 loss: 0.1327
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7210s / 5303.8736 s
agent0:                 episode reward: 0.4355,                 loss: nan
agent1:                 episode reward: -0.4355,                 loss: 0.1328
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8133s / 5550.6869 s
agent0:                 episode reward: 0.0756,                 loss: nan
agent1:                 episode reward: -0.0756,                 loss: 0.1329
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5599s / 5803.2469 s
agent0:                 episode reward: -0.0931,                 loss: nan
agent1:                 episode reward: 0.0931,                 loss: 0.1323
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6355s / 6051.8824 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.1329
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8106s / 6304.6929 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: 0.1309
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2690s / 6546.9619 s
agent0:                 episode reward: -0.0068,                 loss: nan
agent1:                 episode reward: 0.0068,                 loss: 0.1310
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7926s / 6799.7545 s
agent0:                 episode reward: 0.2441,                 loss: nan
agent1:                 episode reward: -0.2441,                 loss: 0.1299
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1158s / 7048.8703 s
agent0:                 episode reward: 0.2532,                 loss: nan
agent1:                 episode reward: -0.2532,                 loss: 0.1306
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9076s / 7298.7779 s
agent0:                 episode reward: -0.0983,                 loss: nan
agent1:                 episode reward: 0.0983,                 loss: 0.1305
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8985s / 7537.6764 s
agent0:                 episode reward: 0.1418,                 loss: nan
agent1:                 episode reward: -0.1418,                 loss: 0.1301
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3853s / 7783.0617 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1283
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1648s / 8037.2265 s
agent0:                 episode reward: 0.1065,                 loss: nan
agent1:                 episode reward: -0.1065,                 loss: 0.1286
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0705s / 8287.2969 s
agent0:                 episode reward: 0.1321,                 loss: nan
agent1:                 episode reward: -0.1321,                 loss: 0.1275
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2925s / 8537.5895 s
agent0:                 episode reward: -0.1320,                 loss: nan
agent1:                 episode reward: 0.1320,                 loss: 0.1283
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6925s / 8788.2820 s
agent0:                 episode reward: -0.0303,                 loss: nan
agent1:                 episode reward: 0.0303,                 loss: 0.1283
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0151s / 9037.2971 s
agent0:                 episode reward: 0.2344,                 loss: nan
agent1:                 episode reward: -0.2344,                 loss: 0.1271
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7059s / 9285.0030 s
agent0:                 episode reward: 0.5768,                 loss: nan
agent1:                 episode reward: -0.5768,                 loss: 0.1272
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4537s / 9535.4567 s
agent0:                 episode reward: 0.5016,                 loss: nan
agent1:                 episode reward: -0.5016,                 loss: 0.1280
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5748s / 9781.0316 s
agent0:                 episode reward: 0.6355,                 loss: nan
agent1:                 episode reward: -0.6355,                 loss: 0.1281
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5658s / 10027.5974 s
agent0:                 episode reward: 0.0379,                 loss: nan
agent1:                 episode reward: -0.0379,                 loss: 0.1283
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1188s / 10264.7162 s
agent0:                 episode reward: 0.1995,                 loss: nan
agent1:                 episode reward: -0.1995,                 loss: 0.1262
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0209s / 10513.7370 s
agent0:                 episode reward: -0.0638,                 loss: nan
agent1:                 episode reward: 0.0638,                 loss: 0.1275
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9682s / 10763.7052 s
agent0:                 episode reward: 0.1487,                 loss: nan
agent1:                 episode reward: -0.1487,                 loss: 0.1258
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4920s / 11001.1972 s
agent0:                 episode reward: -0.0061,                 loss: nan
agent1:                 episode reward: 0.0061,                 loss: 0.1269
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8669s / 11254.0642 s
agent0:                 episode reward: -0.2047,                 loss: nan
agent1:                 episode reward: 0.2047,                 loss: 0.1262
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0248s / 11499.0890 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.1260
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9789s / 11749.0679 s
agent0:                 episode reward: -0.1740,                 loss: nan
agent1:                 episode reward: 0.1740,                 loss: 0.1273
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6448s / 11996.7126 s
agent0:                 episode reward: 0.0432,                 loss: nan
agent1:                 episode reward: -0.0432,                 loss: 0.1270
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1223s / 12243.8349 s
agent0:                 episode reward: -0.6857,                 loss: nan
agent1:                 episode reward: 0.6857,                 loss: 0.1266
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8518s / 12494.6867 s
agent0:                 episode reward: -0.1070,                 loss: nan
agent1:                 episode reward: 0.1070,                 loss: 0.1272
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5005s / 12744.1872 s
agent0:                 episode reward: -0.1170,                 loss: nan
agent1:                 episode reward: 0.1170,                 loss: 0.1268
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.9774s / 12981.1645 s
agent0:                 episode reward: -0.0119,                 loss: nan
agent1:                 episode reward: 0.0119,                 loss: 0.1258
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4097s / 13226.5743 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1272
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4425s / 13472.0168 s
agent0:                 episode reward: 0.0830,                 loss: nan
agent1:                 episode reward: -0.0830,                 loss: 0.1269
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4050s / 13722.4218 s
agent0:                 episode reward: 0.4790,                 loss: nan
agent1:                 episode reward: -0.4790,                 loss: 0.1256
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7815s / 13972.2033 s
agent0:                 episode reward: -0.3892,                 loss: nan
agent1:                 episode reward: 0.3892,                 loss: 0.1273
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6121s / 14222.8154 s
agent0:                 episode reward: 0.0908,                 loss: nan
agent1:                 episode reward: -0.0908,                 loss: 0.1270
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0259s / 14465.8412 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.1250
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0650s / 14716.9063 s
agent0:                 episode reward: 0.0380,                 loss: nan
agent1:                 episode reward: -0.0380,                 loss: 0.1257
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7548s / 14962.6610 s
agent0:                 episode reward: -0.0754,                 loss: nan
agent1:                 episode reward: 0.0754,                 loss: 0.1256
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0276s / 15213.6886 s
agent0:                 episode reward: 0.2840,                 loss: nan
agent1:                 episode reward: -0.2840,                 loss: 0.1235
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8779s / 15461.5665 s
agent0:                 episode reward: 0.4050,                 loss: nan
agent1:                 episode reward: -0.4050,                 loss: 0.1230
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0689s / 15702.6354 s
agent0:                 episode reward: -0.1310,                 loss: nan
agent1:                 episode reward: 0.1310,                 loss: 0.1248
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0237s / 15954.6590 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.1227
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6167s / 16208.2757 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: 0.1234
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7814s / 16457.0572 s
agent0:                 episode reward: -0.0645,                 loss: nan
agent1:                 episode reward: 0.0645,                 loss: 0.1230
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2478s / 16702.3050 s
agent0:                 episode reward: 0.3024,                 loss: nan
agent1:                 episode reward: -0.3024,                 loss: 0.1251
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1194s / 16943.4244 s
agent0:                 episode reward: 0.1807,                 loss: nan
agent1:                 episode reward: -0.1807,                 loss: 0.1244
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1081s / 17192.5325 s
agent0:                 episode reward: 0.2927,                 loss: nan
agent1:                 episode reward: -0.2927,                 loss: 0.1252
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9730s / 17439.5055 s
agent0:                 episode reward: -0.0848,                 loss: nan
agent1:                 episode reward: 0.0848,                 loss: 0.1244
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9586s / 17690.4641 s
agent0:                 episode reward: 0.1462,                 loss: nan
agent1:                 episode reward: -0.1462,                 loss: 0.1246
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8505s / 17933.3146 s
agent0:                 episode reward: -0.4583,                 loss: nan
agent1:                 episode reward: 0.4583,                 loss: 0.1250
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1337s / 18183.4483 s
agent0:                 episode reward: -0.0914,                 loss: nan
agent1:                 episode reward: 0.0914,                 loss: 0.1240
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1244s / 18429.5727 s
agent0:                 episode reward: 0.3792,                 loss: nan
agent1:                 episode reward: -0.3792,                 loss: 0.1237
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5087s / 18672.0813 s
agent0:                 episode reward: -0.2057,                 loss: nan
agent1:                 episode reward: 0.2057,                 loss: 0.1230
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9732s / 18912.0545 s
agent0:                 episode reward: 0.4125,                 loss: nan
agent1:                 episode reward: -0.4125,                 loss: 0.1231
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5439s / 19161.5985 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1248
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7166s / 19407.3151 s
agent0:                 episode reward: 0.2023,                 loss: nan
agent1:                 episode reward: -0.2023,                 loss: 0.1242
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8772s / 19655.1922 s
agent0:                 episode reward: -0.0699,                 loss: nan
agent1:                 episode reward: 0.0699,                 loss: 0.1234
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1369s / 19899.3291 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.1227
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8399s / 20149.1691 s
agent0:                 episode reward: -0.0569,                 loss: nan
agent1:                 episode reward: 0.0569,                 loss: 0.1227
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1450s / 20392.3140 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.1227
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3900s / 20637.7040 s
agent0:                 episode reward: -0.3403,                 loss: nan
agent1:                 episode reward: 0.3403,                 loss: 0.1221
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7596s / 20888.4637 s
agent0:                 episode reward: 0.1878,                 loss: nan
agent1:                 episode reward: -0.1878,                 loss: 0.1255
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.6887s / 21126.1523 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.1256
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6830s / 21382.8353 s
agent0:                 episode reward: -0.0585,                 loss: nan
agent1:                 episode reward: 0.0585,                 loss: 0.1239
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1042s / 21619.9395 s
agent0:                 episode reward: -0.0549,                 loss: nan
agent1:                 episode reward: 0.0549,                 loss: 0.1252
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5294s / 21869.4689 s
agent0:                 episode reward: -0.0165,                 loss: nan
agent1:                 episode reward: 0.0165,                 loss: 0.1239
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6224s / 22113.0913 s
agent0:                 episode reward: -0.5424,                 loss: nan
agent1:                 episode reward: 0.5424,                 loss: 0.1248
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1415s / 22356.2327 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1239
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2523s / 22606.4850 s
agent0:                 episode reward: 0.2482,                 loss: nan
agent1:                 episode reward: -0.2482,                 loss: 0.1249
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2658s / 22852.7508 s
agent0:                 episode reward: -0.3200,                 loss: nan
agent1:                 episode reward: 0.3200,                 loss: 0.1242
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3682s / 23098.1189 s
agent0:                 episode reward: -0.5688,                 loss: nan
agent1:                 episode reward: 0.5688,                 loss: 0.1241
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9815s / 23347.1004 s
agent0:                 episode reward: 0.3943,                 loss: nan
agent1:                 episode reward: -0.3943,                 loss: 0.1241
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8058s / 23597.9063 s
agent0:                 episode reward: 0.5459,                 loss: nan
agent1:                 episode reward: -0.5459,                 loss: 0.1251
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2745s / 23842.1808 s
agent0:                 episode reward: 0.1319,                 loss: nan
agent1:                 episode reward: -0.1319,                 loss: 0.1253
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1048s / 24084.2855 s
agent0:                 episode reward: -0.0098,                 loss: nan
agent1:                 episode reward: 0.0098,                 loss: 0.1243
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3317s / 24335.6172 s
agent0:                 episode reward: -0.1200,                 loss: nan
agent1:                 episode reward: 0.1200,                 loss: 0.1257
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0439s / 24588.6611 s
agent0:                 episode reward: -0.0201,                 loss: nan
agent1:                 episode reward: 0.0201,                 loss: 0.1242
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2846s / 24832.9457 s
agent0:                 episode reward: -0.2499,                 loss: nan
agent1:                 episode reward: 0.2499,                 loss: 0.1256
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7960s / 25073.7417 s
agent0:                 episode reward: -0.1939,                 loss: nan
agent1:                 episode reward: 0.1939,                 loss: 0.1273
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9670s / 25313.7087 s
agent0:                 episode reward: 0.1422,                 loss: nan
agent1:                 episode reward: -0.1422,                 loss: 0.1261
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8684s / 25561.5771 s
agent0:                 episode reward: 0.0764,                 loss: nan
agent1:                 episode reward: -0.0764,                 loss: 0.1266
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1779s / 25805.7550 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: 0.1248
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0622s / 26054.8173 s
agent0:                 episode reward: -0.5604,                 loss: nan
agent1:                 episode reward: 0.5604,                 loss: 0.1270
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4668s / 26305.2841 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1266
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5083s / 26550.7923 s
agent0:                 episode reward: 0.1842,                 loss: nan
agent1:                 episode reward: -0.1842,                 loss: 0.1260
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0771s / 26793.8695 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.1259
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7636s / 27041.6331 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: 0.1265
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7313s / 27289.3644 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1260
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6591s / 27533.0235 s
agent0:                 episode reward: -0.2389,                 loss: nan
agent1:                 episode reward: 0.2389,                 loss: 0.1253
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6499s / 27778.6734 s
agent0:                 episode reward: -0.1328,                 loss: nan
agent1:                 episode reward: 0.1328,                 loss: 0.1251
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5777s / 28026.2511 s
agent0:                 episode reward: 0.0835,                 loss: nan
agent1:                 episode reward: -0.0835,                 loss: 0.1254
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9319s / 28273.1829 s
agent0:                 episode reward: -0.0486,                 loss: nan
agent1:                 episode reward: 0.0486,                 loss: 0.1257
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2155s / 28520.3985 s
agent0:                 episode reward: -0.0254,                 loss: nan
agent1:                 episode reward: 0.0254,                 loss: 0.1263
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8296s / 28764.2280 s
agent0:                 episode reward: -0.1260,                 loss: nan
agent1:                 episode reward: 0.1260,                 loss: 0.1259
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7384s / 29016.9664 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: 0.1268
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2065s / 29259.1730 s
agent0:                 episode reward: -0.0267,                 loss: nan
agent1:                 episode reward: 0.0267,                 loss: 0.1281
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4087s / 29508.5817 s
agent0:                 episode reward: -0.1218,                 loss: nan
agent1:                 episode reward: 0.1218,                 loss: 0.1277
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5536s / 29753.1353 s
agent0:                 episode reward: 0.3820,                 loss: nan
agent1:                 episode reward: -0.3820,                 loss: 0.1287
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1871s / 30000.3224 s
agent0:                 episode reward: 0.0899,                 loss: nan
agent1:                 episode reward: -0.0899,                 loss: 0.1271
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8738s / 30249.1962 s
agent0:                 episode reward: -0.2742,                 loss: nan
agent1:                 episode reward: 0.2742,                 loss: 0.1276
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1964s / 30504.3926 s
agent0:                 episode reward: 0.0278,                 loss: nan
agent1:                 episode reward: -0.0278,                 loss: 0.1280
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3826s / 30760.7752 s
agent0:                 episode reward: -0.0018,                 loss: nan
agent1:                 episode reward: 0.0018,                 loss: 0.1266
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4919s / 31010.2671 s
agent0:                 episode reward: -0.1873,                 loss: nan
agent1:                 episode reward: 0.1873,                 loss: 0.1281
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 260.3272s / 31270.5943 s
agent0:                 episode reward: -0.2589,                 loss: nan
agent1:                 episode reward: 0.2589,                 loss: 0.1276
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4914s / 31513.0857 s
agent0:                 episode reward: 0.3231,                 loss: nan
agent1:                 episode reward: -0.3231,                 loss: 0.1284
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2342s / 31765.3199 s
agent0:                 episode reward: 0.1332,                 loss: nan
agent1:                 episode reward: -0.1332,                 loss: 0.1278
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0357s / 32019.3556 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.1283
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4249s / 32267.7805 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: 0.1278
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8705s / 32511.6511 s
agent0:                 episode reward: -0.0699,                 loss: nan
agent1:                 episode reward: 0.0699,                 loss: 0.1271
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6430s / 32761.2941 s
agent0:                 episode reward: 0.0212,                 loss: nan
agent1:                 episode reward: -0.0212,                 loss: 0.1273
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2379s / 33012.5320 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.1281
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1194s / 33260.6514 s
agent0:                 episode reward: -0.5458,                 loss: nan
agent1:                 episode reward: 0.5458,                 loss: 0.1282
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2515s / 33504.9029 s
agent0:                 episode reward: -0.3442,                 loss: nan
agent1:                 episode reward: 0.3442,                 loss: 0.1298
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5197s / 33762.4226 s
agent0:                 episode reward: -0.2403,                 loss: nan
agent1:                 episode reward: 0.2403,                 loss: 0.1301
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7131s / 34010.1356 s
agent0:                 episode reward: -0.0308,                 loss: nan
agent1:                 episode reward: 0.0308,                 loss: 0.1298
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3143s / 34264.4500 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: 0.1280
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0292s / 34509.4792 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: 0.1284
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1194s / 34750.5985 s
agent0:                 episode reward: -0.4181,                 loss: nan
agent1:                 episode reward: 0.4181,                 loss: 0.1291
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8410s / 34997.4395 s
agent0:                 episode reward: -0.2306,                 loss: nan
agent1:                 episode reward: 0.2306,                 loss: 0.1292
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6497s / 35239.0892 s
agent0:                 episode reward: -0.3749,                 loss: nan
agent1:                 episode reward: 0.3749,                 loss: 0.1282
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1880s / 35485.2772 s
agent0:                 episode reward: -0.3197,                 loss: nan
agent1:                 episode reward: 0.3197,                 loss: 0.1281
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4127s / 35733.6899 s
agent0:                 episode reward: 0.2468,                 loss: nan
agent1:                 episode reward: -0.2468,                 loss: 0.1290
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.2282s / 35992.9181 s
agent0:                 episode reward: -0.1201,                 loss: nan
agent1:                 episode reward: 0.1201,                 loss: 0.1287
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2758s / 36241.1939 s
agent0:                 episode reward: -0.4379,                 loss: nan
agent1:                 episode reward: 0.4379,                 loss: 0.1274
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2048s / 36492.3987 s
agent0:                 episode reward: 0.0371,                 loss: nan
agent1:                 episode reward: -0.0371,                 loss: 0.1277
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6350s / 36747.0336 s
agent0:                 episode reward: -0.1632,                 loss: nan
agent1:                 episode reward: 0.1632,                 loss: 0.1269
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8425s / 36987.8761 s
agent0:                 episode reward: -0.0789,                 loss: nan
agent1:                 episode reward: 0.0789,                 loss: 0.1300
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2442s / 37226.1203 s
agent0:                 episode reward: -0.2985,                 loss: nan
agent1:                 episode reward: 0.2985,                 loss: 0.1273
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5800s / 37473.7003 s
agent0:                 episode reward: 0.1650,                 loss: nan
agent1:                 episode reward: -0.1650,                 loss: 0.1275
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7740s / 37725.4744 s
agent0:                 episode reward: -0.2429,                 loss: nan
agent1:                 episode reward: 0.2429,                 loss: 0.1265
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2428s / 37970.7171 s
agent0:                 episode reward: -0.0723,                 loss: nan
agent1:                 episode reward: 0.0723,                 loss: 0.1254
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0089s / 38213.7260 s
agent0:                 episode reward: -0.1287,                 loss: nan
agent1:                 episode reward: 0.1287,                 loss: 0.1261
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1627s / 38467.8887 s
agent0:                 episode reward: -0.0522,                 loss: nan
agent1:                 episode reward: 0.0522,                 loss: 0.1275
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2954s / 38710.1841 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1276
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0379s / 38961.2220 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1265
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8068s / 39202.0288 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.1259
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5327s / 39452.5615 s
agent0:                 episode reward: -0.1552,                 loss: nan
agent1:                 episode reward: 0.1552,                 loss: 0.1249
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5745s / 39701.1360 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: 0.1262
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4659s / 39946.6019 s
agent0:                 episode reward: -0.3043,                 loss: nan
agent1:                 episode reward: 0.3043,                 loss: 0.1267
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4708s / 40184.0727 s
agent0:                 episode reward: -0.5199,                 loss: nan
agent1:                 episode reward: 0.5199,                 loss: 0.1266
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0917s / 40432.1645 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1259
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5668s / 40682.7313 s
agent0:                 episode reward: -0.6166,                 loss: nan
agent1:                 episode reward: 0.6166,                 loss: 0.1267
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9386s / 40923.6699 s
agent0:                 episode reward: -0.0903,                 loss: nan
agent1:                 episode reward: 0.0903,                 loss: 0.1258
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.9934s / 41180.6634 s
agent0:                 episode reward: 0.1793,                 loss: nan
agent1:                 episode reward: -0.1793,                 loss: 0.1259
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3327s / 41426.9961 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: 0.1270
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7262s / 41676.7222 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.1255
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3484s / 41926.0706 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1260
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1285s / 42180.1991 s
agent0:                 episode reward: -0.3309,                 loss: nan
agent1:                 episode reward: 0.3309,                 loss: 0.1266
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8460s / 42425.0452 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.1261
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8638s / 42670.9090 s
agent0:                 episode reward: 0.2290,                 loss: nan
agent1:                 episode reward: -0.2290,                 loss: 0.1251
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5030s / 42923.4120 s
agent0:                 episode reward: -0.0645,                 loss: nan
agent1:                 episode reward: 0.0645,                 loss: 0.1256
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1340s / 43169.5459 s
agent0:                 episode reward: -0.5664,                 loss: nan
agent1:                 episode reward: 0.5664,                 loss: 0.1264
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5168s / 43418.0628 s
agent0:                 episode reward: -0.3028,                 loss: nan
agent1:                 episode reward: 0.3028,                 loss: 0.1268
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3108s / 43660.3736 s
agent0:                 episode reward: 0.0954,                 loss: nan
agent1:                 episode reward: -0.0954,                 loss: 0.1256
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0890s / 43910.4626 s
agent0:                 episode reward: -0.2882,                 loss: nan
agent1:                 episode reward: 0.2882,                 loss: 0.1264
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5386s / 44155.0012 s
agent0:                 episode reward: -0.0561,                 loss: nan
agent1:                 episode reward: 0.0561,                 loss: 0.1265
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3675s / 44401.3687 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.1261
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2314s / 44653.6001 s
agent0:                 episode reward: -0.2094,                 loss: nan
agent1:                 episode reward: 0.2094,                 loss: 0.1258
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1454s / 44901.7455 s
agent0:                 episode reward: 0.0957,                 loss: nan
agent1:                 episode reward: -0.0957,                 loss: 0.1256
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0169s / 45149.7624 s
agent0:                 episode reward: -0.0996,                 loss: nan
agent1:                 episode reward: 0.0996,                 loss: 0.1254
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8406s / 45394.6030 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.1264
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5992s / 45639.2022 s
agent0:                 episode reward: -0.0991,                 loss: nan
agent1:                 episode reward: 0.0991,                 loss: 0.1253
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8153s / 45881.0174 s
agent0:                 episode reward: -0.4168,                 loss: nan
agent1:                 episode reward: 0.4168,                 loss: 0.1238
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4806s / 46131.4980 s
agent0:                 episode reward: -0.0051,                 loss: nan
agent1:                 episode reward: 0.0051,                 loss: 0.1257
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0232s / 46387.5212 s
agent0:                 episode reward: -0.3461,                 loss: nan
agent1:                 episode reward: 0.3461,                 loss: 0.1256
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1086s / 46631.6299 s
agent0:                 episode reward: 0.2098,                 loss: nan
agent1:                 episode reward: -0.2098,                 loss: 0.1248
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5170s / 46885.1469 s
agent0:                 episode reward: -0.0279,                 loss: nan
agent1:                 episode reward: 0.0279,                 loss: 0.1233
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3589s / 47134.5058 s
agent0:                 episode reward: -0.3398,                 loss: nan
agent1:                 episode reward: 0.3398,                 loss: 0.1251
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9596s / 47384.4654 s
agent0:                 episode reward: -0.0150,                 loss: nan
agent1:                 episode reward: 0.0150,                 loss: 0.1253
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6140s / 47633.0795 s
agent0:                 episode reward: -0.0251,                 loss: nan
agent1:                 episode reward: 0.0251,                 loss: 0.1252
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1108s / 47882.1903 s
agent0:                 episode reward: -0.1916,                 loss: nan
agent1:                 episode reward: 0.1916,                 loss: 0.1230
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8357s / 48133.0260 s
agent0:                 episode reward: -0.1393,                 loss: nan
agent1:                 episode reward: 0.1393,                 loss: 0.1230
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1418s / 48377.1678 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: 0.1250
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6321s / 48633.7999 s
agent0:                 episode reward: -0.4952,                 loss: nan
agent1:                 episode reward: 0.4952,                 loss: 0.1231
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.6508s / 48892.4507 s
agent0:                 episode reward: -0.2798,                 loss: nan
agent1:                 episode reward: 0.2798,                 loss: 0.1228
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8602s / 49143.3109 s
agent0:                 episode reward: -0.3356,                 loss: nan
agent1:                 episode reward: 0.3356,                 loss: 0.1237
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8562s / 49387.1672 s
agent0:                 episode reward: -0.0353,                 loss: nan
agent1:                 episode reward: 0.0353,                 loss: 0.1233
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1729s / 49640.3400 s
agent0:                 episode reward: -0.3853,                 loss: nan
agent1:                 episode reward: 0.3853,                 loss: 0.1225
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7111s / 49893.0512 s
agent0:                 episode reward: -0.3113,                 loss: nan
agent1:                 episode reward: 0.3113,                 loss: 0.1230
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5101s / 50141.5613 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.1236
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1578s / 50387.7191 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.1235
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7976s / 50643.5167 s
agent0:                 episode reward: -0.0037,                 loss: nan
agent1:                 episode reward: 0.0037,                 loss: 0.1228
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4250s / 50889.9417 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1221
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8302s / 51134.7719 s
agent0:                 episode reward: -0.1754,                 loss: nan
agent1:                 episode reward: 0.1754,                 loss: 0.1224
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4159s / 51379.1878 s
agent0:                 episode reward: -0.1482,                 loss: nan
agent1:                 episode reward: 0.1482,                 loss: 0.1238
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9028s / 51627.0906 s
agent0:                 episode reward: -0.2017,                 loss: nan
agent1:                 episode reward: 0.2017,                 loss: 0.1234
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5707s / 51881.6614 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: 0.1241
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6097s / 52127.2711 s
agent0:                 episode reward: 0.0360,                 loss: nan
agent1:                 episode reward: -0.0360,                 loss: 0.1246
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6232s / 52367.8943 s
agent0:                 episode reward: -0.2658,                 loss: nan
agent1:                 episode reward: 0.2658,                 loss: 0.1230
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9504s / 52617.8447 s
agent0:                 episode reward: -0.1558,                 loss: nan
agent1:                 episode reward: 0.1558,                 loss: 0.1238
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3403s / 52867.1850 s
agent0:                 episode reward: -0.2843,                 loss: nan
agent1:                 episode reward: 0.2843,                 loss: 0.1243
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1188s / 53117.3037 s
agent0:                 episode reward: -0.1613,                 loss: nan
agent1:                 episode reward: 0.1613,                 loss: 0.1224
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5305s / 53360.8342 s
agent0:                 episode reward: 0.2065,                 loss: nan
agent1:                 episode reward: -0.2065,                 loss: 0.1209
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8000s / 53603.6342 s
agent0:                 episode reward: -0.3386,                 loss: nan
agent1:                 episode reward: 0.3386,                 loss: 0.1221
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8716s / 53854.5058 s
agent0:                 episode reward: -0.1346,                 loss: nan
agent1:                 episode reward: 0.1346,                 loss: 0.1262
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3759s / 54098.8817 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: 0.1250
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5158s / 54353.3975 s
agent0:                 episode reward: -0.0462,                 loss: nan
agent1:                 episode reward: 0.0462,                 loss: 0.1256
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5996s / 54606.9970 s
agent0:                 episode reward: -0.2534,                 loss: nan
agent1:                 episode reward: 0.2534,                 loss: 0.1247
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0323s / 54851.0293 s
agent0:                 episode reward: 0.0842,                 loss: nan
agent1:                 episode reward: -0.0842,                 loss: 0.1236
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0850s / 55096.1143 s
agent0:                 episode reward: -0.2267,                 loss: nan
agent1:                 episode reward: 0.2267,                 loss: 0.1230
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3771s / 55340.4913 s
agent0:                 episode reward: -0.2190,                 loss: nan
agent1:                 episode reward: 0.2190,                 loss: 0.1254
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7092s / 55584.2005 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.1238
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2705s / 55830.4710 s
agent0:                 episode reward: -0.2572,                 loss: nan
agent1:                 episode reward: 0.2572,                 loss: 0.1226
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9104s / 56073.3814 s
agent0:                 episode reward: -0.0326,                 loss: nan
agent1:                 episode reward: 0.0326,                 loss: 0.1232
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4849s / 56322.8663 s
agent0:                 episode reward: -0.3227,                 loss: nan
agent1:                 episode reward: 0.3227,                 loss: 0.1228
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9718s / 56574.8381 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.1237
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7799s / 56811.6180 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.1229
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0187s / 57062.6367 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1239
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2834s / 57299.9201 s
agent0:                 episode reward: -0.3668,                 loss: nan
agent1:                 episode reward: 0.3668,                 loss: 0.1244
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8675s / 57550.7876 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.1227
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2768s / 57792.0643 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.1242
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5472s / 58040.6115 s
agent0:                 episode reward: 0.1631,                 loss: nan
agent1:                 episode reward: -0.1631,                 loss: 0.1241
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8998s / 58287.5113 s
agent0:                 episode reward: -0.2340,                 loss: nan
agent1:                 episode reward: 0.2340,                 loss: 0.1215
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9572s / 58531.4684 s
agent0:                 episode reward: -0.2956,                 loss: nan
agent1:                 episode reward: 0.2956,                 loss: 0.1242
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5199s / 58782.9884 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: 0.1224
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1250s / 59025.1133 s
agent0:                 episode reward: 0.1395,                 loss: nan
agent1:                 episode reward: -0.1395,                 loss: 0.1237
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7801s / 59279.8934 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.1215
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7414s / 59522.6348 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.1228
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1612s / 59775.7960 s
agent0:                 episode reward: -0.0149,                 loss: nan
agent1:                 episode reward: 0.0149,                 loss: 0.1227
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1624s / 60021.9583 s
agent0:                 episode reward: 0.1055,                 loss: nan
agent1:                 episode reward: -0.1055,                 loss: 0.1236
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0879s / 60268.0462 s
agent0:                 episode reward: -0.3322,                 loss: nan
agent1:                 episode reward: 0.3322,                 loss: 0.1219
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1828s / 60513.2291 s
agent0:                 episode reward: -0.1894,                 loss: nan
agent1:                 episode reward: 0.1894,                 loss: 0.1228
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0734s / 60765.3024 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.1212
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7377s / 61005.0401 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.1208
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9765s / 61249.0166 s
agent0:                 episode reward: 0.0143,                 loss: nan
agent1:                 episode reward: -0.0143,                 loss: 0.1214
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2925s / 61496.3091 s
agent0:                 episode reward: -0.1723,                 loss: nan
agent1:                 episode reward: 0.1723,                 loss: 0.1237
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6109s / 61736.9200 s
agent0:                 episode reward: 0.0302,                 loss: nan
agent1:                 episode reward: -0.0302,                 loss: 0.1216
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3625s / 61989.2825 s
agent0:                 episode reward: -0.2229,                 loss: nan
agent1:                 episode reward: 0.2229,                 loss: 0.1213
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6004s / 62241.8829 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.1231
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3210s / 62495.2039 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1231
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0885s / 62739.2924 s
agent0:                 episode reward: -0.3592,                 loss: nan
agent1:                 episode reward: 0.3592,                 loss: 0.1224
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5633s / 62989.8557 s
agent0:                 episode reward: -0.3170,                 loss: nan
agent1:                 episode reward: 0.3170,                 loss: 0.1242
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7571s / 63233.6128 s
agent0:                 episode reward: -0.1379,                 loss: nan
agent1:                 episode reward: 0.1379,                 loss: 0.1245
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8405s / 63484.4533 s
agent0:                 episode reward: -0.6860,                 loss: nan
agent1:                 episode reward: 0.6860,                 loss: 0.1230
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2479s / 63726.7012 s
agent0:                 episode reward: -0.4770,                 loss: nan
agent1:                 episode reward: 0.4770,                 loss: 0.1229
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0737s / 63980.7749 s
agent0:                 episode reward: -0.1575,                 loss: nan
agent1:                 episode reward: 0.1575,                 loss: 0.1218
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2730s / 64221.0480 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.1231
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1070s / 64479.1550 s
agent0:                 episode reward: -0.2761,                 loss: nan
agent1:                 episode reward: 0.2761,                 loss: 0.1231
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1025s / 64725.2575 s
agent0:                 episode reward: 0.0199,                 loss: nan
agent1:                 episode reward: -0.0199,                 loss: 0.1235
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2661s / 64972.5235 s
agent0:                 episode reward: -0.0861,                 loss: nan
agent1:                 episode reward: 0.0861,                 loss: 0.1232
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9686s / 65213.4922 s
agent0:                 episode reward: -0.4367,                 loss: nan
agent1:                 episode reward: 0.4367,                 loss: 0.1225
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6620s / 65463.1542 s
agent0:                 episode reward: -0.1661,                 loss: nan
agent1:                 episode reward: 0.1661,                 loss: 0.1225
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5314s / 65712.6856 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.1226
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9254s / 65956.6110 s
agent0:                 episode reward: 0.3493,                 loss: nan
agent1:                 episode reward: -0.3493,                 loss: 0.1233
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9542s / 66203.5652 s
agent0:                 episode reward: 0.1395,                 loss: nan
agent1:                 episode reward: -0.1395,                 loss: 0.1223
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5182s / 66451.0835 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1219
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5787s / 66706.6622 s
agent0:                 episode reward: -0.6086,                 loss: nan
agent1:                 episode reward: 0.6086,                 loss: 0.1209
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 261.6714s / 66968.3336 s
agent0:                 episode reward: -0.1756,                 loss: nan
agent1:                 episode reward: 0.1756,                 loss: 0.1202
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.5029s / 67224.8365 s
agent0:                 episode reward: -0.2576,                 loss: nan
agent1:                 episode reward: 0.2576,                 loss: 0.1214
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8507s / 67473.6873 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.1223
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4940s / 67720.1812 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1201
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8070s / 67972.9882 s
agent0:                 episode reward: -0.4373,                 loss: nan
agent1:                 episode reward: 0.4373,                 loss: 0.1223
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1488s / 68218.1370 s
agent0:                 episode reward: -0.5652,                 loss: nan
agent1:                 episode reward: 0.5652,                 loss: 0.1208
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1886s / 68473.3256 s
agent0:                 episode reward: -0.3455,                 loss: nan
agent1:                 episode reward: 0.3455,                 loss: 0.1213
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5076s / 68721.8333 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1205
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7967s / 68971.6300 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1203
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2767s / 69219.9067 s
agent0:                 episode reward: -0.1911,                 loss: nan
agent1:                 episode reward: 0.1911,                 loss: 0.1218
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5844s / 69463.4911 s
agent0:                 episode reward: -0.6060,                 loss: nan
agent1:                 episode reward: 0.6060,                 loss: 0.1206
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1500s / 69721.6411 s
agent0:                 episode reward: -0.2818,                 loss: nan
agent1:                 episode reward: 0.2818,                 loss: 0.1213
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5702s / 69976.2113 s
agent0:                 episode reward: -0.5770,                 loss: nan
agent1:                 episode reward: 0.5770,                 loss: 0.1199
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3722s / 70227.5834 s
agent0:                 episode reward: 0.2091,                 loss: nan
agent1:                 episode reward: -0.2091,                 loss: 0.1206
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3194s / 70482.9028 s
agent0:                 episode reward: -0.2060,                 loss: nan
agent1:                 episode reward: 0.2060,                 loss: 0.1190
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2564s / 70736.1592 s
agent0:                 episode reward: -0.3843,                 loss: nan
agent1:                 episode reward: 0.3843,                 loss: 0.1194
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0957s / 70979.2548 s
agent0:                 episode reward: -0.4682,                 loss: nan
agent1:                 episode reward: 0.4682,                 loss: 0.1193
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.3375s / 71237.5923 s
agent0:                 episode reward: 0.0273,                 loss: nan
agent1:                 episode reward: -0.0273,                 loss: 0.1201
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3751s / 71480.9674 s
agent0:                 episode reward: 0.1678,                 loss: nan
agent1:                 episode reward: -0.1678,                 loss: 0.1218
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3948s / 71731.3622 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.1203
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0517s / 71983.4139 s
agent0:                 episode reward: -0.2239,                 loss: nan
agent1:                 episode reward: 0.2239,                 loss: 0.1203
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7393s / 72226.1532 s
agent0:                 episode reward: 0.0294,                 loss: nan
agent1:                 episode reward: -0.0294,                 loss: 0.1176
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6658s / 72470.8191 s
agent0:                 episode reward: -0.1767,                 loss: nan
agent1:                 episode reward: 0.1767,                 loss: 0.1191
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6811s / 72715.5002 s
agent0:                 episode reward: -0.2214,                 loss: nan
agent1:                 episode reward: 0.2214,                 loss: 0.1182
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6520s / 72967.1521 s
agent0:                 episode reward: -0.2032,                 loss: nan
agent1:                 episode reward: 0.2032,                 loss: 0.1206
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4731s / 73220.6252 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.1209
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9893s / 73471.6145 s
agent0:                 episode reward: -0.0994,                 loss: nan
agent1:                 episode reward: 0.0994,                 loss: 0.1202
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6585s / 73723.2730 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.1192
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8022s / 73971.0752 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.1199
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1993s / 74223.2744 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.1202
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0746s / 74469.3490 s
agent0:                 episode reward: -0.0658,                 loss: nan
agent1:                 episode reward: 0.0658,                 loss: 0.1184
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4596s / 74710.8086 s
agent0:                 episode reward: -0.5789,                 loss: nan
agent1:                 episode reward: 0.5789,                 loss: 0.1203
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9724s / 74962.7809 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.1232
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1753s / 75213.9562 s
agent0:                 episode reward: -0.0348,                 loss: nan
agent1:                 episode reward: 0.0348,                 loss: 0.1215
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7091s / 75464.6654 s
agent0:                 episode reward: -0.7234,                 loss: nan
agent1:                 episode reward: 0.7234,                 loss: 0.1213
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7894s / 75716.4548 s
agent0:                 episode reward: 0.1341,                 loss: nan
agent1:                 episode reward: -0.1341,                 loss: 0.1197
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7588s / 75956.2136 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.1215
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8960s / 76209.1096 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.1201
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8558s / 76460.9654 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.1208
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6518s / 76710.6172 s
agent0:                 episode reward: 0.1122,                 loss: nan
agent1:                 episode reward: -0.1122,                 loss: 0.1194
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3548s / 76958.9720 s
agent0:                 episode reward: -0.2702,                 loss: nan
agent1:                 episode reward: 0.2702,                 loss: 0.1213
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1359s / 77205.1079 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.1212
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.6765s / 77464.7844 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.1205
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5213s / 77703.3056 s
agent0:                 episode reward: -0.1416,                 loss: nan
agent1:                 episode reward: 0.1416,                 loss: 0.1208
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9209s / 77949.2266 s
agent0:                 episode reward: -0.6161,                 loss: nan
agent1:                 episode reward: 0.6161,                 loss: 0.1208
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1146s / 78205.3411 s
agent0:                 episode reward: 0.1824,                 loss: nan
agent1:                 episode reward: -0.1824,                 loss: 0.1199
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3152s / 78454.6564 s
agent0:                 episode reward: -0.2219,                 loss: nan
agent1:                 episode reward: 0.2219,                 loss: 0.1208
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3794s / 78702.0358 s
agent0:                 episode reward: -0.1742,                 loss: nan
agent1:                 episode reward: 0.1742,                 loss: 0.1218
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7733s / 78954.8091 s
agent0:                 episode reward: -0.2570,                 loss: nan
agent1:                 episode reward: 0.2570,                 loss: 0.1207
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6904s / 79208.4995 s
agent0:                 episode reward: -0.2860,                 loss: nan
agent1:                 episode reward: 0.2860,                 loss: 0.1215
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3869s / 79451.8864 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.1196
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8781s / 79706.7645 s
agent0:                 episode reward: -0.8424,                 loss: nan
agent1:                 episode reward: 0.8424,                 loss: 0.1198
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5206s / 79961.2851 s
agent0:                 episode reward: -0.2348,                 loss: nan
agent1:                 episode reward: 0.2348,                 loss: 0.1206
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7599s / 80211.0450 s
agent0:                 episode reward: -0.2171,                 loss: nan
agent1:                 episode reward: 0.2171,                 loss: 0.1209
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8118s / 80457.8568 s
agent0:                 episode reward: 0.0579,                 loss: nan
agent1:                 episode reward: -0.0579,                 loss: 0.1206
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8023s / 80706.6591 s
agent0:                 episode reward: -0.3293,                 loss: nan
agent1:                 episode reward: 0.3293,                 loss: 0.1194
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1390s / 80952.7981 s
agent0:                 episode reward: -0.5931,                 loss: nan
agent1:                 episode reward: 0.5931,                 loss: 0.1196
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.4621s / 81209.2602 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.1206
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3118s / 81455.5720 s
agent0:                 episode reward: -0.2489,                 loss: nan
agent1:                 episode reward: 0.2489,                 loss: 0.1201
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6078s / 81702.1798 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.1181
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6944s / 81952.8742 s
agent0:                 episode reward: 0.1382,                 loss: nan
agent1:                 episode reward: -0.1382,                 loss: 0.1193
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3682s / 82200.2424 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.1197
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3744s / 82448.6169 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1190
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3725s / 82701.9894 s
agent0:                 episode reward: -0.3872,                 loss: nan
agent1:                 episode reward: 0.3872,                 loss: 0.1192
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1213s / 82948.1107 s
agent0:                 episode reward: 0.0252,                 loss: nan
agent1:                 episode reward: -0.0252,                 loss: 0.1205
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1721s / 83189.2828 s
agent0:                 episode reward: -0.1230,                 loss: nan
agent1:                 episode reward: 0.1230,                 loss: 0.1182
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0157s / 83444.2985 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.1199
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7864s / 83694.0849 s
agent0:                 episode reward: -0.8662,                 loss: nan
agent1:                 episode reward: 0.8662,                 loss: 0.1196
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1899s / 83947.2748 s
agent0:                 episode reward: -0.0408,                 loss: nan
agent1:                 episode reward: 0.0408,                 loss: 0.1203
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9704s / 84193.2453 s
agent0:                 episode reward: -0.5575,                 loss: nan
agent1:                 episode reward: 0.5575,                 loss: 0.1196
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5258s / 84445.7710 s
agent0:                 episode reward: -0.2395,                 loss: nan
agent1:                 episode reward: 0.2395,                 loss: 0.1204
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1218s / 84692.8929 s
agent0:                 episode reward: -0.0420,                 loss: nan
agent1:                 episode reward: 0.0420,                 loss: 0.1206
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6235s / 84938.5164 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: 0.1184
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.9320s / 85196.4484 s
agent0:                 episode reward: -0.4894,                 loss: nan
agent1:                 episode reward: 0.4894,                 loss: 0.1179
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0218s / 85440.4702 s
agent0:                 episode reward: -0.4006,                 loss: nan
agent1:                 episode reward: 0.4006,                 loss: 0.1188
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8795s / 85688.3498 s
agent0:                 episode reward: -0.3114,                 loss: nan
agent1:                 episode reward: 0.3114,                 loss: 0.1195
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2982s / 85942.6480 s
agent0:                 episode reward: -0.5626,                 loss: nan
agent1:                 episode reward: 0.5626,                 loss: 0.1194
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2641s / 86189.9121 s
agent0:                 episode reward: -0.2954,                 loss: nan
agent1:                 episode reward: 0.2954,                 loss: 0.1192
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7701s / 86440.6822 s
agent0:                 episode reward: -0.1280,                 loss: nan
agent1:                 episode reward: 0.1280,                 loss: 0.1194
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7160s / 86684.3981 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.1171
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3773s / 86938.7755 s
agent0:                 episode reward: -0.0651,                 loss: nan
agent1:                 episode reward: 0.0651,                 loss: 0.1175
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9761s / 87183.7516 s
agent0:                 episode reward: -0.4644,                 loss: nan
agent1:                 episode reward: 0.4644,                 loss: 0.1174
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.6899s / 87441.4415 s
agent0:                 episode reward: -0.4060,                 loss: nan
agent1:                 episode reward: 0.4060,                 loss: 0.1176
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2809s / 87691.7223 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1172
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6031s / 87943.3254 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.1171
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1950s / 88197.5204 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.1170
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4856s / 88443.0060 s
agent0:                 episode reward: -0.2615,                 loss: nan
agent1:                 episode reward: 0.2615,                 loss: 0.1179
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7888s / 88692.7948 s
agent0:                 episode reward: -0.1619,                 loss: nan
agent1:                 episode reward: 0.1619,                 loss: 0.1180
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2610s / 88938.0558 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.1154
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2286s / 89192.2844 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.1162
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5027s / 89441.7871 s
agent0:                 episode reward: -0.6006,                 loss: nan
agent1:                 episode reward: 0.6006,                 loss: 0.1178
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6378s / 89685.4249 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1170
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5142s / 89935.9391 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.1177
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6071s / 90186.5462 s