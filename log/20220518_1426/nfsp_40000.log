pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fbcde837c18>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_40000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_40000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6813s / 0.6813 s
agent0:                 episode reward: -0.5509,                 loss: nan
agent1:                 episode reward: 0.5509,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 0.8829 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 1.0829 s
agent0:                 episode reward: 0.1313,                 loss: nan
agent1:                 episode reward: -0.1313,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 1.2808 s
agent0:                 episode reward: -0.2285,                 loss: nan
agent1:                 episode reward: 0.2285,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 1.4844 s
agent0:                 episode reward: 0.5027,                 loss: nan
agent1:                 episode reward: -0.5027,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 1.6803 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 1.8818 s
agent0:                 episode reward: 0.0295,                 loss: nan
agent1:                 episode reward: -0.0295,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 2.0775 s
agent0:                 episode reward: 0.0547,                 loss: nan
agent1:                 episode reward: -0.0547,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 2.2727 s
agent0:                 episode reward: 0.4032,                 loss: nan
agent1:                 episode reward: -0.4032,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 2.4674 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 2.6656 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 2.8611 s
agent0:                 episode reward: 0.0827,                 loss: nan
agent1:                 episode reward: -0.0827,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 3.0542 s
agent0:                 episode reward: 0.2480,                 loss: nan
agent1:                 episode reward: -0.2480,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 3.2500 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 3.4521 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 3.6463 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 3.8429 s
agent0:                 episode reward: 0.4634,                 loss: nan
agent1:                 episode reward: -0.4634,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 4.0411 s
agent0:                 episode reward: 0.1514,                 loss: nan
agent1:                 episode reward: -0.1514,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 4.2483 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 4.4466 s
agent0:                 episode reward: -0.0611,                 loss: nan
agent1:                 episode reward: 0.0611,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 4.6460 s
agent0:                 episode reward: 0.2334,                 loss: nan
agent1:                 episode reward: -0.2334,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 4.8445 s
agent0:                 episode reward: -0.0747,                 loss: nan
agent1:                 episode reward: 0.0747,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 5.0436 s
agent0:                 episode reward: 0.2098,                 loss: nan
agent1:                 episode reward: -0.2098,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.2408 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 5.4377 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 5.6356 s
agent0:                 episode reward: -0.1458,                 loss: nan
agent1:                 episode reward: 0.1458,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 5.8369 s
agent0:                 episode reward: 0.1808,                 loss: nan
agent1:                 episode reward: -0.1808,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.0368 s
agent0:                 episode reward: 0.3930,                 loss: nan
agent1:                 episode reward: -0.3930,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 6.2337 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 6.4282 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 6.6250 s
agent0:                 episode reward: -0.1159,                 loss: nan
agent1:                 episode reward: 0.1159,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 6.8243 s
agent0:                 episode reward: 0.1167,                 loss: nan
agent1:                 episode reward: -0.1167,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 7.0215 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 7.2190 s
agent0:                 episode reward: 0.0874,                 loss: nan
agent1:                 episode reward: -0.0874,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 7.4186 s
agent0:                 episode reward: 0.1234,                 loss: nan
agent1:                 episode reward: -0.1234,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 7.6179 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 7.8169 s
agent0:                 episode reward: -0.1647,                 loss: nan
agent1:                 episode reward: 0.1647,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 8.0128 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 8.2134 s
agent0:                 episode reward: -0.0330,                 loss: nan
agent1:                 episode reward: 0.0330,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 8.4161 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 8.6116 s
agent0:                 episode reward: -0.0410,                 loss: nan
agent1:                 episode reward: 0.0410,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 8.8092 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 9.0074 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 9.2047 s
agent0:                 episode reward: -0.1801,                 loss: nan
agent1:                 episode reward: 0.1801,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 9.3982 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 9.5919 s
agent0:                 episode reward: 0.2833,                 loss: nan
agent1:                 episode reward: -0.2833,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 9.7946 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 9.9963 s
agent0:                 episode reward: -0.2551,                 loss: nan
agent1:                 episode reward: 0.2551,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.1932 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 10.3955 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 10.5942 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.7932 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 10.9895 s
agent0:                 episode reward: 0.0909,                 loss: nan
agent1:                 episode reward: -0.0909,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 11.1901 s
agent0:                 episode reward: 0.0915,                 loss: nan
agent1:                 episode reward: -0.0915,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1925s / 11.3827 s
agent0:                 episode reward: 0.5043,                 loss: nan
agent1:                 episode reward: -0.5043,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 11.5800 s
agent0:                 episode reward: -0.1399,                 loss: nan
agent1:                 episode reward: 0.1399,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 11.7774 s
agent0:                 episode reward: 0.0401,                 loss: nan
agent1:                 episode reward: -0.0401,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 11.9792 s
agent0:                 episode reward: -0.1725,                 loss: nan
agent1:                 episode reward: 0.1725,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 12.1751 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 12.3763 s
agent0:                 episode reward: -0.2632,                 loss: nan
agent1:                 episode reward: 0.2632,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 12.5756 s
agent0:                 episode reward: -0.1568,                 loss: nan
agent1:                 episode reward: 0.1568,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 12.7763 s
agent0:                 episode reward: 0.0610,                 loss: nan
agent1:                 episode reward: -0.0610,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 12.9758 s
agent0:                 episode reward: 0.3492,                 loss: nan
agent1:                 episode reward: -0.3492,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 13.1776 s
agent0:                 episode reward: 0.1721,                 loss: nan
agent1:                 episode reward: -0.1721,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 13.3741 s
agent0:                 episode reward: 0.0404,                 loss: nan
agent1:                 episode reward: -0.0404,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 13.5710 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 13.7725 s
agent0:                 episode reward: 0.0702,                 loss: nan
agent1:                 episode reward: -0.0702,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 13.9683 s
agent0:                 episode reward: 0.1497,                 loss: nan
agent1:                 episode reward: -0.1497,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 14.1665 s
agent0:                 episode reward: -0.1342,                 loss: nan
agent1:                 episode reward: 0.1342,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1913s / 14.3578 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 14.5579 s
agent0:                 episode reward: 0.3152,                 loss: nan
agent1:                 episode reward: -0.3152,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 14.7534 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 14.9578 s
agent0:                 episode reward: 0.3382,                 loss: nan
agent1:                 episode reward: -0.3382,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 15.1568 s
agent0:                 episode reward: 0.3127,                 loss: nan
agent1:                 episode reward: -0.3127,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 15.3496 s
agent0:                 episode reward: 0.1070,                 loss: nan
agent1:                 episode reward: -0.1070,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 15.5451 s
agent0:                 episode reward: -0.4020,                 loss: nan
agent1:                 episode reward: 0.4020,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 15.7442 s
agent0:                 episode reward: 0.5803,                 loss: nan
agent1:                 episode reward: -0.5803,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 15.9455 s
agent0:                 episode reward: 0.0469,                 loss: nan
agent1:                 episode reward: -0.0469,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 16.1448 s
agent0:                 episode reward: 0.1480,                 loss: nan
agent1:                 episode reward: -0.1480,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 16.3368 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 16.5367 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 16.7348 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 16.9361 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 17.1330 s
agent0:                 episode reward: 0.1628,                 loss: nan
agent1:                 episode reward: -0.1628,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 17.3249 s
agent0:                 episode reward: -0.0941,                 loss: nan
agent1:                 episode reward: 0.0941,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 17.5263 s
agent0:                 episode reward: 0.1204,                 loss: nan
agent1:                 episode reward: -0.1204,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 17.7182 s
agent0:                 episode reward: 0.1079,                 loss: nan
agent1:                 episode reward: -0.1079,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.9177 s
agent0:                 episode reward: -0.0438,                 loss: nan
agent1:                 episode reward: 0.0438,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 18.1161 s
agent0:                 episode reward: 0.1079,                 loss: nan
agent1:                 episode reward: -0.1079,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 18.3181 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 18.5151 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 18.7110 s
agent0:                 episode reward: 0.3773,                 loss: nan
agent1:                 episode reward: -0.3773,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 18.9094 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 19.1119 s
agent0:                 episode reward: 0.1154,                 loss: nan
agent1:                 episode reward: -0.1154,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 19.3129 s
agent0:                 episode reward: 0.2407,                 loss: nan
agent1:                 episode reward: -0.2407,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 19.5148 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 19.7139 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 19.9101 s
agent0:                 episode reward: -0.4167,                 loss: nan
agent1:                 episode reward: 0.4167,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1930s / 20.1031 s
agent0:                 episode reward: -0.4392,                 loss: nan
agent1:                 episode reward: 0.4392,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 20.3012 s
agent0:                 episode reward: -0.1956,                 loss: nan
agent1:                 episode reward: 0.1956,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 20.5010 s
agent0:                 episode reward: -0.2180,                 loss: nan
agent1:                 episode reward: 0.2180,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 20.7042 s
agent0:                 episode reward: 0.1674,                 loss: nan
agent1:                 episode reward: -0.1674,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 20.9013 s
agent0:                 episode reward: 0.3412,                 loss: nan
agent1:                 episode reward: -0.3412,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 21.1006 s
agent0:                 episode reward: 0.2018,                 loss: nan
agent1:                 episode reward: -0.2018,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 21.3031 s
agent0:                 episode reward: 0.2625,                 loss: nan
agent1:                 episode reward: -0.2625,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 21.5055 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 21.7019 s
agent0:                 episode reward: 0.2015,                 loss: nan
agent1:                 episode reward: -0.2015,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 21.9029 s
agent0:                 episode reward: 0.2241,                 loss: nan
agent1:                 episode reward: -0.2241,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 22.1020 s
agent0:                 episode reward: 0.2629,                 loss: nan
agent1:                 episode reward: -0.2629,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 22.3032 s
agent0:                 episode reward: 0.2315,                 loss: nan
agent1:                 episode reward: -0.2315,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 22.5038 s
agent0:                 episode reward: -0.1953,                 loss: nan
agent1:                 episode reward: 0.1953,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 22.6986 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 22.9010 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 23.0957 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 23.2953 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 23.4939 s
agent0:                 episode reward: 0.2868,                 loss: nan
agent1:                 episode reward: -0.2868,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 23.6906 s
agent0:                 episode reward: 0.1137,                 loss: nan
agent1:                 episode reward: -0.1137,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 23.8899 s
agent0:                 episode reward: -0.0324,                 loss: nan
agent1:                 episode reward: 0.0324,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 24.0924 s
agent0:                 episode reward: -0.0632,                 loss: nan
agent1:                 episode reward: 0.0632,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 24.2906 s
agent0:                 episode reward: -0.1509,                 loss: nan
agent1:                 episode reward: 0.1509,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 24.4853 s
agent0:                 episode reward: 0.1284,                 loss: nan
agent1:                 episode reward: -0.1284,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 24.6845 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 24.8815 s
agent0:                 episode reward: -0.0977,                 loss: nan
agent1:                 episode reward: 0.0977,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 25.0831 s
agent0:                 episode reward: 0.1122,                 loss: nan
agent1:                 episode reward: -0.1122,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 25.2791 s
agent0:                 episode reward: 0.0217,                 loss: nan
agent1:                 episode reward: -0.0217,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 25.4805 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 25.6795 s
agent0:                 episode reward: 0.0342,                 loss: nan
agent1:                 episode reward: -0.0342,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 25.8750 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 26.0788 s
agent0:                 episode reward: 0.0823,                 loss: nan
agent1:                 episode reward: -0.0823,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 26.2707 s
agent0:                 episode reward: 0.4456,                 loss: nan
agent1:                 episode reward: -0.4456,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1901s / 26.4608 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 26.6558 s
agent0:                 episode reward: 0.0202,                 loss: nan
agent1:                 episode reward: -0.0202,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 26.8525 s
agent0:                 episode reward: 0.1009,                 loss: nan
agent1:                 episode reward: -0.1009,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 27.0383 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 27.2378 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 27.4380 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 27.6368 s
agent0:                 episode reward: -0.0719,                 loss: nan
agent1:                 episode reward: 0.0719,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 27.8355 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2297s / 28.0651 s
agent0:                 episode reward: 0.0429,                 loss: nan
agent1:                 episode reward: -0.0429,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 28.2628 s
agent0:                 episode reward: 0.0192,                 loss: nan
agent1:                 episode reward: -0.0192,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 28.4589 s
agent0:                 episode reward: -0.2786,                 loss: nan
agent1:                 episode reward: 0.2786,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 28.6565 s
agent0:                 episode reward: 0.1962,                 loss: nan
agent1:                 episode reward: -0.1962,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 28.8504 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 29.0475 s
agent0:                 episode reward: 0.2524,                 loss: nan
agent1:                 episode reward: -0.2524,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 29.2451 s
agent0:                 episode reward: 0.0898,                 loss: nan
agent1:                 episode reward: -0.0898,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 29.4388 s
agent0:                 episode reward: -0.1120,                 loss: nan
agent1:                 episode reward: 0.1120,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 29.6340 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 29.8292 s
agent0:                 episode reward: -0.2036,                 loss: nan
agent1:                 episode reward: 0.2036,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 30.0254 s
agent0:                 episode reward: 0.0325,                 loss: nan
agent1:                 episode reward: -0.0325,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 30.2241 s
agent0:                 episode reward: 0.3478,                 loss: nan
agent1:                 episode reward: -0.3478,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 30.4206 s
agent0:                 episode reward: 0.5867,                 loss: nan
agent1:                 episode reward: -0.5867,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 30.6201 s
agent0:                 episode reward: 0.2482,                 loss: nan
agent1:                 episode reward: -0.2482,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 30.8171 s
agent0:                 episode reward: 0.2547,                 loss: nan
agent1:                 episode reward: -0.2547,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 31.0130 s
agent0:                 episode reward: 0.1596,                 loss: nan
agent1:                 episode reward: -0.1596,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 31.2079 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 31.4052 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 31.6043 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 31.8037 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 32.0014 s
agent0:                 episode reward: 0.2818,                 loss: nan
agent1:                 episode reward: -0.2818,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 32.2036 s
agent0:                 episode reward: 0.4341,                 loss: nan
agent1:                 episode reward: -0.4341,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.4023 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 32.6035 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 32.8024 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 33.0036 s
agent0:                 episode reward: 0.4211,                 loss: nan
agent1:                 episode reward: -0.4211,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 33.1992 s
agent0:                 episode reward: -0.1040,                 loss: nan
agent1:                 episode reward: 0.1040,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 33.3990 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 33.5955 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 33.9445 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.4568
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5764s / 34.5209 s
agent0:                 episode reward: 0.3165,                 loss: nan
agent1:                 episode reward: -0.3165,                 loss: 0.4479
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5768s / 35.0977 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.4369
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 35.6770 s
agent0:                 episode reward: -0.1955,                 loss: nan
agent1:                 episode reward: 0.1955,                 loss: 0.4227
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5698s / 36.2469 s
agent0:                 episode reward: -0.2618,                 loss: nan
agent1:                 episode reward: 0.2618,                 loss: 0.4029
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5751s / 36.8219 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.3882
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5772s / 37.3991 s
agent0:                 episode reward: -0.2110,                 loss: nan
agent1:                 episode reward: 0.2110,                 loss: 0.3737
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5674s / 37.9665 s
agent0:                 episode reward: -0.2827,                 loss: nan
agent1:                 episode reward: 0.2827,                 loss: 0.3672
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 38.5469 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.3670
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5734s / 39.1202 s
agent0:                 episode reward: -0.2396,                 loss: nan
agent1:                 episode reward: 0.2396,                 loss: 0.3680
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 39.6992 s
agent0:                 episode reward: -0.1629,                 loss: nan
agent1:                 episode reward: 0.1629,                 loss: 0.3678
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 40.2850 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.3671
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 40.8672 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.3640
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 41.4484 s
agent0:                 episode reward: -0.0256,                 loss: nan
agent1:                 episode reward: 0.0256,                 loss: 0.3629
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5754s / 42.0239 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.3661
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 42.6083 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.3677
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 43.1953 s
agent0:                 episode reward: 0.0946,                 loss: nan
agent1:                 episode reward: -0.0946,                 loss: 0.3642
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 43.7788 s
agent0:                 episode reward: -0.4266,                 loss: nan
agent1:                 episode reward: 0.4266,                 loss: 0.3585
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5782s / 44.3570 s
agent0:                 episode reward: -0.3763,                 loss: nan
agent1:                 episode reward: 0.3763,                 loss: 0.3485
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5776s / 44.9346 s
agent0:                 episode reward: -0.6363,                 loss: nan
agent1:                 episode reward: 0.6363,                 loss: 0.3469
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 45.5214 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.3407
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 46.1037 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: 0.3433
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 46.6830 s
agent0:                 episode reward: -0.2759,                 loss: nan
agent1:                 episode reward: 0.2759,                 loss: 0.3458
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 47.2638 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.3470
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 47.8459 s
agent0:                 episode reward: -0.1396,                 loss: nan
agent1:                 episode reward: 0.1396,                 loss: 0.3392
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 48.4272 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.3413
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5769s / 49.0041 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.3372
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 49.5874 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: 0.3361
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 50.1695 s
agent0:                 episode reward: -0.5212,                 loss: nan
agent1:                 episode reward: 0.5212,                 loss: 0.3388
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 50.7537 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.3384
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5769s / 51.3306 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.3373
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5770s / 51.9077 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.3395
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5774s / 52.4851 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.3357
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5771s / 53.0622 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.3371
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 53.6494 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.3552
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5797s / 54.2291 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.3497
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 54.8081 s
agent0:                 episode reward: -0.1071,                 loss: nan
agent1:                 episode reward: 0.1071,                 loss: 0.3512
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 55.3949 s
agent0:                 episode reward: -0.7529,                 loss: nan
agent1:                 episode reward: 0.7529,                 loss: 0.3513
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 55.9840 s
agent0:                 episode reward: -0.7548,                 loss: nan
agent1:                 episode reward: 0.7548,                 loss: 0.3515
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 56.5709 s
agent0:                 episode reward: -0.0846,                 loss: nan
agent1:                 episode reward: 0.0846,                 loss: 0.3541
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 57.1509 s
agent0:                 episode reward: -0.1699,                 loss: nan
agent1:                 episode reward: 0.1699,                 loss: 0.3537
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 57.7300 s
agent0:                 episode reward: -0.6984,                 loss: nan
agent1:                 episode reward: 0.6984,                 loss: 0.3497
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5807s / 58.3107 s
agent0:                 episode reward: -0.0826,                 loss: nan
agent1:                 episode reward: 0.0826,                 loss: 0.3516
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 58.8970 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.3513
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 59.4849 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.3512
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 60.0831 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.3522
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6148s / 60.6979 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.3495
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 61.2899 s
agent0:                 episode reward: -0.2371,                 loss: nan
agent1:                 episode reward: 0.2371,                 loss: 0.3483
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 61.8842 s
agent0:                 episode reward: 0.1431,                 loss: nan
agent1:                 episode reward: -0.1431,                 loss: 0.3524
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 62.4754 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: 0.3501
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 63.0697 s
agent0:                 episode reward: -0.0712,                 loss: nan
agent1:                 episode reward: 0.0712,                 loss: 0.3472
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 63.6614 s
agent0:                 episode reward: -0.5194,                 loss: nan
agent1:                 episode reward: 0.5194,                 loss: 0.3412
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 64.2520 s
agent0:                 episode reward: -0.5803,                 loss: nan
agent1:                 episode reward: 0.5803,                 loss: 0.3380
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 64.8345 s
agent0:                 episode reward: -0.5069,                 loss: nan
agent1:                 episode reward: 0.5069,                 loss: 0.3361
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 65.4256 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.3366
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 66.0197 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.3389
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 66.6117 s
agent0:                 episode reward: -0.1487,                 loss: nan
agent1:                 episode reward: 0.1487,                 loss: 0.3380
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 67.2070 s
agent0:                 episode reward: -0.2730,                 loss: nan
agent1:                 episode reward: 0.2730,                 loss: 0.3370
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 67.8023 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.3400
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 68.3965 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3371
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 68.9893 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.3408
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 69.5777 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3399
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 70.1643 s
agent0:                 episode reward: -0.1559,                 loss: nan
agent1:                 episode reward: 0.1559,                 loss: 0.3368
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 70.7502 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3334
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 71.3425 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.3378
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 71.9311 s
agent0:                 episode reward: -0.4394,                 loss: nan
agent1:                 episode reward: 0.4394,                 loss: 0.3391
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 72.5209 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.3358
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 73.1094 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.3429
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 73.7075 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.3403
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 74.3045 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.3404
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 74.8963 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.3382
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 75.4796 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: 0.3396
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 76.0679 s
agent0:                 episode reward: -0.5362,                 loss: nan
agent1:                 episode reward: 0.5362,                 loss: 0.3398
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 76.6572 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.3373
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 77.2426 s
agent0:                 episode reward: -0.2364,                 loss: nan
agent1:                 episode reward: 0.2364,                 loss: 0.3355
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 77.8333 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.3363
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 78.4199 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.3408
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 79.0172 s
agent0:                 episode reward: -0.3452,                 loss: nan
agent1:                 episode reward: 0.3452,                 loss: 0.3389
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 79.6098 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.3393
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 80.1936 s
agent0:                 episode reward: -0.2506,                 loss: nan
agent1:                 episode reward: 0.2506,                 loss: 0.3367
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 80.7859 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.3377
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 81.3707 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: 0.3394
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 81.9611 s
agent0:                 episode reward: -0.2513,                 loss: nan
agent1:                 episode reward: 0.2513,                 loss: 0.3406
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 82.5516 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.3410
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 83.1435 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.3481
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 83.7329 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.3523
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 84.3297 s
agent0:                 episode reward: -0.2073,                 loss: nan
agent1:                 episode reward: 0.2073,                 loss: 0.3494
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 84.9260 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.3506
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 85.5238 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.3493
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 86.1191 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3519
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 86.7181 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3504
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 87.3099 s
agent0:                 episode reward: -0.3850,                 loss: nan
agent1:                 episode reward: 0.3850,                 loss: 0.3491
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 87.9020 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.3492
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 88.4898 s
agent0:                 episode reward: -0.5255,                 loss: nan
agent1:                 episode reward: 0.5255,                 loss: 0.3532
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 89.0839 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.3505
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 89.6755 s
agent0:                 episode reward: -0.5737,                 loss: nan
agent1:                 episode reward: 0.5737,                 loss: 0.3511
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 90.2625 s
agent0:                 episode reward: -0.3876,                 loss: nan
agent1:                 episode reward: 0.3876,                 loss: 0.3478
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 90.8545 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.3503
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 91.4507 s
agent0:                 episode reward: -0.4057,                 loss: nan
agent1:                 episode reward: 0.4057,                 loss: 0.3505
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 92.0492 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3492
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 92.6484 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.3470
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 93.2450 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.3424
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 93.8367 s
agent0:                 episode reward: -0.2971,                 loss: nan
agent1:                 episode reward: 0.2971,                 loss: 0.3440
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 94.4318 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3408
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 95.0308 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3410
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 95.6181 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3423
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 96.2103 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: 0.3365
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 96.8028 s
agent0:                 episode reward: -0.1411,                 loss: nan
agent1:                 episode reward: 0.1411,                 loss: 0.3426
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 97.3993 s
agent0:                 episode reward: -0.3594,                 loss: nan
agent1:                 episode reward: 0.3594,                 loss: 0.3390
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 97.9910 s
agent0:                 episode reward: -0.3790,                 loss: nan
agent1:                 episode reward: 0.3790,                 loss: 0.3421
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 98.5862 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.3397
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 99.1772 s
agent0:                 episode reward: -0.1533,                 loss: nan
agent1:                 episode reward: 0.1533,                 loss: 0.3403
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 99.7688 s
agent0:                 episode reward: -0.0536,                 loss: nan
agent1:                 episode reward: 0.0536,                 loss: 0.3393
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 100.3632 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.3399
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 100.9516 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.3404
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 101.5354 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.3416
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 102.1273 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: 0.3439
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 102.7227 s
agent0:                 episode reward: -0.3603,                 loss: nan
agent1:                 episode reward: 0.3603,                 loss: 0.3464
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 103.3125 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: 0.3500
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 103.9098 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.3486
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 104.4975 s
agent0:                 episode reward: -0.2648,                 loss: nan
agent1:                 episode reward: 0.2648,                 loss: 0.3490
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 105.0989 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.3479
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 105.6963 s
agent0:                 episode reward: -0.0520,                 loss: nan
agent1:                 episode reward: 0.0520,                 loss: 0.3492
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 106.2940 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.3503
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 106.8951 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.3478
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 107.4900 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: 0.3510
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 108.0922 s
agent0:                 episode reward: 0.0961,                 loss: nan
agent1:                 episode reward: -0.0961,                 loss: 0.3461
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 108.6874 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3496
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 109.2883 s
agent0:                 episode reward: -0.1982,                 loss: nan
agent1:                 episode reward: 0.1982,                 loss: 0.3485
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 109.8819 s
agent0:                 episode reward: -0.0920,                 loss: nan
agent1:                 episode reward: 0.0920,                 loss: 0.3478
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 110.4822 s
agent0:                 episode reward: -0.4556,                 loss: nan
agent1:                 episode reward: 0.4556,                 loss: 0.3510
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 111.0776 s
agent0:                 episode reward: -0.3178,                 loss: nan
agent1:                 episode reward: 0.3178,                 loss: 0.3498
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 111.6686 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.3486
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 112.2699 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.3502
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 112.8768 s
agent0:                 episode reward: -0.1947,                 loss: nan
agent1:                 episode reward: 0.1947,                 loss: 0.3436
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 113.4711 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3435
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 114.0732 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.3447
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 114.6817 s
agent0:                 episode reward: -0.4884,                 loss: nan
agent1:                 episode reward: 0.4884,                 loss: 0.3427
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 115.2746 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.3452
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 115.8735 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.3439
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 116.4651 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.3435
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 117.0488 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3459
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 117.6371 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.3469
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 118.2353 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.3443
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 118.8266 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.3432
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 119.4217 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.3418
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 120.0230 s
agent0:                 episode reward: -0.5129,                 loss: nan
agent1:                 episode reward: 0.5129,                 loss: 0.3456
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 120.6136 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3427
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 121.2110 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.3443
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 121.8119 s
agent0:                 episode reward: -0.1427,                 loss: nan
agent1:                 episode reward: 0.1427,                 loss: 0.3445
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 122.4073 s
agent0:                 episode reward: -0.2052,                 loss: nan
agent1:                 episode reward: 0.2052,                 loss: 0.3442
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 123.0045 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.3484
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 123.6089 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.3476
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 124.2121 s
agent0:                 episode reward: 0.1569,                 loss: nan
agent1:                 episode reward: -0.1569,                 loss: 0.3503
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 124.8133 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3485
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 125.4172 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.3482
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 126.0166 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.3494
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 126.6132 s
agent0:                 episode reward: -0.0939,                 loss: nan
agent1:                 episode reward: 0.0939,                 loss: 0.3486
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 127.2027 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.3463
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 127.8013 s
agent0:                 episode reward: 0.0256,                 loss: nan
agent1:                 episode reward: -0.0256,                 loss: 0.3480
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 128.4003 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.3477
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 128.9990 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.3500
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 129.6032 s
agent0:                 episode reward: -0.3730,                 loss: nan
agent1:                 episode reward: 0.3730,                 loss: 0.3501
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 130.2083 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3486
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 130.8096 s
agent0:                 episode reward: -0.7914,                 loss: nan
agent1:                 episode reward: 0.7914,                 loss: 0.3468
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 131.4104 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3461
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 132.0017 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.3474
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 132.6028 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.3429
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 133.2065 s
agent0:                 episode reward: -0.1009,                 loss: nan
agent1:                 episode reward: 0.1009,                 loss: 0.3482
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 133.8079 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.3480
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6059s / 134.4139 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.3460
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 135.0178 s
agent0:                 episode reward: -0.3554,                 loss: nan
agent1:                 episode reward: 0.3554,                 loss: 0.3456
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 135.6142 s
agent0:                 episode reward: -0.2805,                 loss: nan
agent1:                 episode reward: 0.2805,                 loss: 0.3437
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 136.2129 s
agent0:                 episode reward: -0.3953,                 loss: nan
agent1:                 episode reward: 0.3953,                 loss: 0.3460
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 136.8065 s
agent0:                 episode reward: -0.7311,                 loss: nan
agent1:                 episode reward: 0.7311,                 loss: 0.3474
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 137.4015 s
agent0:                 episode reward: -0.2114,                 loss: nan
agent1:                 episode reward: 0.2114,                 loss: 0.3468
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 137.9998 s
agent0:                 episode reward: -0.1721,                 loss: nan
agent1:                 episode reward: 0.1721,                 loss: 0.3453
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 138.5972 s
agent0:                 episode reward: -0.3842,                 loss: nan
agent1:                 episode reward: 0.3842,                 loss: 0.3473
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 139.2005 s
agent0:                 episode reward: -0.1536,                 loss: nan
agent1:                 episode reward: 0.1536,                 loss: 0.3454
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 139.8050 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.3468
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 140.4000 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.3476
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 140.9966 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3491
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 141.5973 s
agent0:                 episode reward: -0.0625,                 loss: nan
agent1:                 episode reward: 0.0625,                 loss: 0.3455
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 142.1961 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3474
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 142.8002 s
agent0:                 episode reward: -0.3392,                 loss: nan
agent1:                 episode reward: 0.3392,                 loss: 0.3499
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 143.3967 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.3481
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 143.9925 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3491
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 144.5853 s
agent0:                 episode reward: -0.5425,                 loss: nan
agent1:                 episode reward: 0.5425,                 loss: 0.3455
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 145.1836 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.3483
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 145.7704 s
agent0:                 episode reward: -0.1691,                 loss: nan
agent1:                 episode reward: 0.1691,                 loss: 0.3484
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 146.3667 s
agent0:                 episode reward: -0.0912,                 loss: nan
agent1:                 episode reward: 0.0912,                 loss: 0.3495
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 146.9676 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.3470
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 147.5667 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.3505
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 148.1597 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.3464
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 148.7578 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.3505
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6094s / 149.3672 s
agent0:                 episode reward: -0.4729,                 loss: nan
agent1:                 episode reward: 0.4729,                 loss: 0.3482
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 149.9688 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.3476
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 150.5613 s
agent0:                 episode reward: -0.2289,                 loss: nan
agent1:                 episode reward: 0.2289,                 loss: 0.3508
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 151.1488 s
agent0:                 episode reward: -0.9128,                 loss: nan
agent1:                 episode reward: 0.9128,                 loss: 0.3464
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 151.7440 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.3468
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 152.3302 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.3495
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 152.9184 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.3512
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 153.5196 s
agent0:                 episode reward: -0.7164,                 loss: nan
agent1:                 episode reward: 0.7164,                 loss: 0.3492
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 154.1156 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.3498
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 154.7004 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.3500
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 155.3030 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3486
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 155.8997 s
agent0:                 episode reward: -0.0825,                 loss: nan
agent1:                 episode reward: 0.0825,                 loss: 0.3492
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 156.4964 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.3504
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 157.1060 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.3443
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 157.6982 s
agent0:                 episode reward: -0.6917,                 loss: nan
agent1:                 episode reward: 0.6917,                 loss: 0.3487
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 158.3007 s
agent0:                 episode reward: -0.2342,                 loss: nan
agent1:                 episode reward: 0.2342,                 loss: 0.3502
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 158.8959 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.3476
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 159.4987 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.3500
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 160.1008 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.3511
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 160.7115 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.3484