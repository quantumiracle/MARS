2022-05-11 12:13:04.506169: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:13:04.506246: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:13:04.506252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f6ee37fa518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510124814/mdp_arbitrary_mdp_selfplay2/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510124814/mdp_arbitrary_mdp_selfplay2/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510124814_exploit_40000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510124814_exploit_40000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8242s / 0.8242 s
agent0:                 episode reward: 0.6188,                 loss: nan
agent1:                 episode reward: -0.6188,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0665s / 0.8907 s
agent0:                 episode reward: 1.9567,                 loss: nan
agent1:                 episode reward: -1.9567,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0819s / 0.9726 s
agent0:                 episode reward: 2.2029,                 loss: nan
agent1:                 episode reward: -2.2029,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0908s / 1.0635 s
agent0:                 episode reward: 1.6805,                 loss: nan
agent1:                 episode reward: -1.6805,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6426s / 1.7060 s
agent0:                 episode reward: 1.4319,                 loss: nan
agent1:                 episode reward: -1.4319,                 loss: 0.4092
Episode: 101/30000 (0.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7409s / 2.4469 s
agent0:                 episode reward: 0.8782,                 loss: nan
agent1:                 episode reward: -0.8782,                 loss: 0.3812
Episode: 121/30000 (0.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7978s / 3.2447 s
agent0:                 episode reward: 1.8365,                 loss: nan
agent1:                 episode reward: -1.8365,                 loss: 0.3751
Episode: 141/30000 (0.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7647s / 4.0094 s
agent0:                 episode reward: 1.6231,                 loss: nan
agent1:                 episode reward: -1.6231,                 loss: 0.3758
Episode: 161/30000 (0.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7718s / 4.7813 s
agent0:                 episode reward: 1.8608,                 loss: nan
agent1:                 episode reward: -1.8608,                 loss: 0.3758
Episode: 181/30000 (0.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7662s / 5.5475 s
agent0:                 episode reward: 0.4409,                 loss: nan
agent1:                 episode reward: -0.4409,                 loss: 0.3781
Episode: 201/30000 (0.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7819s / 6.3294 s
agent0:                 episode reward: 1.2576,                 loss: nan
agent1:                 episode reward: -1.2576,                 loss: 0.3751
Episode: 221/30000 (0.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7611s / 7.0906 s
agent0:                 episode reward: 1.5961,                 loss: nan
agent1:                 episode reward: -1.5961,                 loss: 0.3720
Episode: 241/30000 (0.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7851s / 7.8756 s
agent0:                 episode reward: 1.4182,                 loss: nan
agent1:                 episode reward: -1.4182,                 loss: 0.3721
Episode: 261/30000 (0.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7870s / 8.6627 s
agent0:                 episode reward: 0.9225,                 loss: nan
agent1:                 episode reward: -0.9225,                 loss: 0.3693
Episode: 281/30000 (0.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7858s / 9.4485 s
agent0:                 episode reward: 0.4306,                 loss: nan
agent1:                 episode reward: -0.4306,                 loss: 0.3665
Episode: 301/30000 (1.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 10.2265 s
agent0:                 episode reward: 0.6078,                 loss: nan
agent1:                 episode reward: -0.6078,                 loss: 0.3633
Episode: 321/30000 (1.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7838s / 11.0103 s
agent0:                 episode reward: 0.2748,                 loss: nan
agent1:                 episode reward: -0.2748,                 loss: 0.3599
Episode: 341/30000 (1.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8067s / 11.8170 s
agent0:                 episode reward: 1.9138,                 loss: nan
agent1:                 episode reward: -1.9138,                 loss: 0.3610
Episode: 361/30000 (1.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7939s / 12.6109 s
agent0:                 episode reward: 0.8997,                 loss: nan
agent1:                 episode reward: -0.8997,                 loss: 0.3619
Episode: 381/30000 (1.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8391s / 13.4500 s
agent0:                 episode reward: 1.0240,                 loss: nan
agent1:                 episode reward: -1.0240,                 loss: 0.3482
Episode: 401/30000 (1.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8142s / 14.2642 s
agent0:                 episode reward: 0.7063,                 loss: nan
agent1:                 episode reward: -0.7063,                 loss: 0.3420
Episode: 421/30000 (1.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8146s / 15.0788 s
agent0:                 episode reward: 1.6403,                 loss: nan
agent1:                 episode reward: -1.6403,                 loss: 0.3398
Episode: 441/30000 (1.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8001s / 15.8790 s
agent0:                 episode reward: 0.2638,                 loss: nan
agent1:                 episode reward: -0.2638,                 loss: 0.3375
Episode: 461/30000 (1.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8377s / 16.7167 s
agent0:                 episode reward: 0.3133,                 loss: nan
agent1:                 episode reward: -0.3133,                 loss: 0.3358
Episode: 481/30000 (1.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8310s / 17.5476 s
agent0:                 episode reward: 0.9204,                 loss: nan
agent1:                 episode reward: -0.9204,                 loss: 0.3050
Episode: 501/30000 (1.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8314s / 18.3791 s
agent0:                 episode reward: 0.4614,                 loss: nan
agent1:                 episode reward: -0.4614,                 loss: 0.2918
Episode: 521/30000 (1.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8178s / 19.1969 s
agent0:                 episode reward: 0.2534,                 loss: nan
agent1:                 episode reward: -0.2534,                 loss: 0.2880
Episode: 541/30000 (1.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8227s / 20.0196 s
agent0:                 episode reward: 1.0264,                 loss: nan
agent1:                 episode reward: -1.0264,                 loss: 0.2855
Episode: 561/30000 (1.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8283s / 20.8479 s
agent0:                 episode reward: 0.4930,                 loss: nan
agent1:                 episode reward: -0.4930,                 loss: 0.2820
Episode: 581/30000 (1.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8430s / 21.6909 s
agent0:                 episode reward: 0.4561,                 loss: nan
agent1:                 episode reward: -0.4561,                 loss: 0.2359
Episode: 601/30000 (2.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8385s / 22.5294 s
agent0:                 episode reward: 0.2559,                 loss: nan
agent1:                 episode reward: -0.2559,                 loss: 0.2173
Episode: 621/30000 (2.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8225s / 23.3519 s
agent0:                 episode reward: 1.0840,                 loss: nan
agent1:                 episode reward: -1.0840,                 loss: 0.2095
Episode: 641/30000 (2.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9115s / 24.2634 s
agent0:                 episode reward: 1.9291,                 loss: nan
agent1:                 episode reward: -1.9291,                 loss: 0.2069
Episode: 661/30000 (2.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8744s / 25.1378 s
agent0:                 episode reward: 0.7583,                 loss: nan
agent1:                 episode reward: -0.7583,                 loss: 0.2025
Episode: 681/30000 (2.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8525s / 25.9903 s
agent0:                 episode reward: 1.1411,                 loss: nan
agent1:                 episode reward: -1.1411,                 loss: 0.1919
Episode: 701/30000 (2.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8626s / 26.8528 s
agent0:                 episode reward: 0.6679,                 loss: nan
agent1:                 episode reward: -0.6679,                 loss: 0.1869
Episode: 721/30000 (2.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8633s / 27.7161 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: 0.1841
Episode: 741/30000 (2.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8469s / 28.5630 s
agent0:                 episode reward: 0.7078,                 loss: nan
agent1:                 episode reward: -0.7078,                 loss: 0.1846
Episode: 761/30000 (2.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8581s / 29.4211 s
agent0:                 episode reward: 0.3930,                 loss: nan
agent1:                 episode reward: -0.3930,                 loss: 0.1859
Episode: 781/30000 (2.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8757s / 30.2968 s
agent0:                 episode reward: 0.7784,                 loss: nan
agent1:                 episode reward: -0.7784,                 loss: 0.1988
Episode: 801/30000 (2.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8611s / 31.1579 s
agent0:                 episode reward: 0.6224,                 loss: nan
agent1:                 episode reward: -0.6224,                 loss: 0.2001
Episode: 821/30000 (2.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8893s / 32.0472 s
agent0:                 episode reward: 0.6046,                 loss: nan
agent1:                 episode reward: -0.6046,                 loss: 0.1982
Episode: 841/30000 (2.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9148s / 32.9621 s
agent0:                 episode reward: 0.6526,                 loss: nan
agent1:                 episode reward: -0.6526,                 loss: 0.1980
Episode: 861/30000 (2.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8759s / 33.8380 s
agent0:                 episode reward: 0.7196,                 loss: nan
agent1:                 episode reward: -0.7196,                 loss: 0.1978
Episode: 881/30000 (2.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9357s / 34.7737 s
agent0:                 episode reward: -0.2057,                 loss: nan
agent1:                 episode reward: 0.2057,                 loss: 0.2304
Episode: 901/30000 (3.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8725s / 35.6462 s
agent0:                 episode reward: 0.4339,                 loss: nan
agent1:                 episode reward: -0.4339,                 loss: 0.2330
Episode: 921/30000 (3.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8710s / 36.5173 s
agent0:                 episode reward: 0.6141,                 loss: nan
agent1:                 episode reward: -0.6141,                 loss: 0.2324
Episode: 941/30000 (3.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8878s / 37.4050 s
agent0:                 episode reward: 0.3427,                 loss: nan
agent1:                 episode reward: -0.3427,                 loss: 0.2305
Episode: 961/30000 (3.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8836s / 38.2886 s
agent0:                 episode reward: 0.7988,                 loss: nan
agent1:                 episode reward: -0.7988,                 loss: 0.2288
Episode: 981/30000 (3.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8870s / 39.1756 s
agent0:                 episode reward: 0.4120,                 loss: nan
agent1:                 episode reward: -0.4120,                 loss: 0.2668
Episode: 1001/30000 (3.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8840s / 40.0597 s
agent0:                 episode reward: 0.5179,                 loss: nan
agent1:                 episode reward: -0.5179,                 loss: 0.2685
Episode: 1021/30000 (3.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9076s / 40.9673 s
agent0:                 episode reward: 0.0076,                 loss: nan
agent1:                 episode reward: -0.0076,                 loss: 0.2646
Episode: 1041/30000 (3.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9536s / 41.9209 s
agent0:                 episode reward: 0.8143,                 loss: nan
agent1:                 episode reward: -0.8143,                 loss: 0.2640
Episode: 1061/30000 (3.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9029s / 42.8238 s
agent0:                 episode reward: 0.1970,                 loss: nan
agent1:                 episode reward: -0.1970,                 loss: 0.2622
Episode: 1081/30000 (3.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9018s / 43.7256 s
agent0:                 episode reward: 1.2113,                 loss: nan
agent1:                 episode reward: -1.2113,                 loss: 0.2740
Episode: 1101/30000 (3.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9504s / 44.6760 s
agent0:                 episode reward: 0.5052,                 loss: nan
agent1:                 episode reward: -0.5052,                 loss: 0.2723
Episode: 1121/30000 (3.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9445s / 45.6205 s
agent0:                 episode reward: 0.1714,                 loss: nan
agent1:                 episode reward: -0.1714,                 loss: 0.2666
Episode: 1141/30000 (3.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9119s / 46.5323 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: 0.2649
Episode: 1161/30000 (3.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9035s / 47.4359 s
agent0:                 episode reward: 0.2409,                 loss: nan
agent1:                 episode reward: -0.2409,                 loss: 0.2599
Episode: 1181/30000 (3.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9235s / 48.3593 s
agent0:                 episode reward: 0.8129,                 loss: nan
agent1:                 episode reward: -0.8129,                 loss: 0.2600
Episode: 1201/30000 (4.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9336s / 49.2930 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.2536
Episode: 1221/30000 (4.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9232s / 50.2161 s
agent0:                 episode reward: 0.1051,                 loss: nan
agent1:                 episode reward: -0.1051,                 loss: 0.2483
Episode: 1241/30000 (4.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9404s / 51.1566 s
agent0:                 episode reward: 0.2423,                 loss: nan
agent1:                 episode reward: -0.2423,                 loss: 0.2457
Episode: 1261/30000 (4.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9447s / 52.1013 s
agent0:                 episode reward: 0.3848,                 loss: nan
agent1:                 episode reward: -0.3848,                 loss: 0.2425
Episode: 1281/30000 (4.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9433s / 53.0446 s
agent0:                 episode reward: 0.4251,                 loss: nan
agent1:                 episode reward: -0.4251,                 loss: 0.2500
Episode: 1301/30000 (4.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9401s / 53.9847 s
agent0:                 episode reward: 0.0892,                 loss: nan
agent1:                 episode reward: -0.0892,                 loss: 0.2493
Episode: 1321/30000 (4.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0136s / 54.9983 s
agent0:                 episode reward: -0.5207,                 loss: nan
agent1:                 episode reward: 0.5207,                 loss: 0.2471
Episode: 1341/30000 (4.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9425s / 55.9408 s
agent0:                 episode reward: 0.2065,                 loss: nan
agent1:                 episode reward: -0.2065,                 loss: 0.2462
Episode: 1361/30000 (4.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9459s / 56.8867 s
agent0:                 episode reward: -0.7255,                 loss: nan
agent1:                 episode reward: 0.7255,                 loss: 0.2454
Episode: 1381/30000 (4.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9815s / 57.8682 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.2735
Episode: 1401/30000 (4.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9471s / 58.8153 s
agent0:                 episode reward: 0.5592,                 loss: nan
agent1:                 episode reward: -0.5592,                 loss: 0.2742
Episode: 1421/30000 (4.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9653s / 59.7806 s
agent0:                 episode reward: -0.0311,                 loss: nan
agent1:                 episode reward: 0.0311,                 loss: 0.2723
Episode: 1441/30000 (4.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9576s / 60.7382 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.2715
Episode: 1461/30000 (4.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9554s / 61.6936 s
agent0:                 episode reward: 0.6232,                 loss: nan
agent1:                 episode reward: -0.6232,                 loss: 0.2701
Episode: 1481/30000 (4.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9721s / 62.6657 s
agent0:                 episode reward: 0.0741,                 loss: nan
agent1:                 episode reward: -0.0741,                 loss: 0.2892
Episode: 1501/30000 (5.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9831s / 63.6488 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: 0.2867
Episode: 1521/30000 (5.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0390s / 64.6878 s
agent0:                 episode reward: -0.6098,                 loss: nan
agent1:                 episode reward: 0.6098,                 loss: 0.2853
Episode: 1541/30000 (5.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9635s / 65.6513 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.2829
Episode: 1561/30000 (5.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0324s / 66.6837 s
agent0:                 episode reward: -0.6752,                 loss: nan
agent1:                 episode reward: 0.6752,                 loss: 0.2844
Episode: 1581/30000 (5.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9770s / 67.6607 s
agent0:                 episode reward: -0.4241,                 loss: nan
agent1:                 episode reward: 0.4241,                 loss: 0.2297
Episode: 1601/30000 (5.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9792s / 68.6399 s
agent0:                 episode reward: 0.3110,                 loss: nan
agent1:                 episode reward: -0.3110,                 loss: 0.2113
Episode: 1621/30000 (5.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9917s / 69.6316 s
agent0:                 episode reward: -0.2458,                 loss: nan
agent1:                 episode reward: 0.2458,                 loss: 0.2108
Episode: 1641/30000 (5.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9697s / 70.6013 s
agent0:                 episode reward: -0.3084,                 loss: nan
agent1:                 episode reward: 0.3084,                 loss: 0.2072
Episode: 1661/30000 (5.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9593s / 71.5606 s
agent0:                 episode reward: 0.7504,                 loss: nan
agent1:                 episode reward: -0.7504,                 loss: 0.2061
Episode: 1681/30000 (5.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9995s / 72.5600 s
agent0:                 episode reward: 0.0575,                 loss: nan
agent1:                 episode reward: -0.0575,                 loss: 0.1611
Episode: 1701/30000 (5.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9761s / 73.5361 s
agent0:                 episode reward: 0.0137,                 loss: nan
agent1:                 episode reward: -0.0137,                 loss: 0.1467
Episode: 1721/30000 (5.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9783s / 74.5144 s
agent0:                 episode reward: 0.0214,                 loss: nan
agent1:                 episode reward: -0.0214,                 loss: 0.1431
Episode: 1741/30000 (5.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0580s / 75.5725 s
agent0:                 episode reward: 0.2313,                 loss: nan
agent1:                 episode reward: -0.2313,                 loss: 0.1442
Episode: 1761/30000 (5.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9755s / 76.5479 s
agent0:                 episode reward: -0.1411,                 loss: nan
agent1:                 episode reward: 0.1411,                 loss: 0.1434
Episode: 1781/30000 (5.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9862s / 77.5342 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.1411
Episode: 1801/30000 (6.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0028s / 78.5370 s
agent0:                 episode reward: 0.0575,                 loss: nan
agent1:                 episode reward: -0.0575,                 loss: 0.1362
Episode: 1821/30000 (6.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9906s / 79.5276 s
agent0:                 episode reward: 0.0087,                 loss: nan
agent1:                 episode reward: -0.0087,                 loss: 0.1347
Episode: 1841/30000 (6.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9979s / 80.5255 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.1341
Episode: 1861/30000 (6.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0042s / 81.5297 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.1360
Episode: 1881/30000 (6.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0203s / 82.5500 s
agent0:                 episode reward: -0.1345,                 loss: nan
agent1:                 episode reward: 0.1345,                 loss: 0.1565
Episode: 1901/30000 (6.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0002s / 83.5502 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: 0.1569
Episode: 1921/30000 (6.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0069s / 84.5571 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: 0.1566
Episode: 1941/30000 (6.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0468s / 85.6039 s
agent0:                 episode reward: 0.1429,                 loss: nan
agent1:                 episode reward: -0.1429,                 loss: 0.1557
Episode: 1961/30000 (6.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0178s / 86.6217 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.1531
Episode: 1981/30000 (6.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0371s / 87.6589 s
agent0:                 episode reward: 0.5191,                 loss: nan
agent1:                 episode reward: -0.5191,                 loss: 0.1977
Episode: 2001/30000 (6.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0067s / 88.6656 s
agent0:                 episode reward: 0.6226,                 loss: nan
agent1:                 episode reward: -0.6226,                 loss: 0.2007
Episode: 2021/30000 (6.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0229s / 89.6885 s
agent0:                 episode reward: -0.6473,                 loss: nan
agent1:                 episode reward: 0.6473,                 loss: 0.2005
Episode: 2041/30000 (6.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0370s / 90.7254 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.2005
Episode: 2061/30000 (6.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0268s / 91.7523 s
agent0:                 episode reward: -0.1244,                 loss: nan
agent1:                 episode reward: 0.1244,                 loss: 0.1981
Episode: 2081/30000 (6.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0449s / 92.7972 s
agent0:                 episode reward: 0.1336,                 loss: nan
agent1:                 episode reward: -0.1336,                 loss: 0.2468
Episode: 2101/30000 (7.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0500s / 93.8472 s
agent0:                 episode reward: 0.1050,                 loss: nan
agent1:                 episode reward: -0.1050,                 loss: 0.2509
Episode: 2121/30000 (7.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0369s / 94.8841 s
agent0:                 episode reward: -0.0168,                 loss: nan
agent1:                 episode reward: 0.0168,                 loss: 0.2501
Episode: 2141/30000 (7.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0555s / 95.9395 s
agent0:                 episode reward: -0.1747,                 loss: nan
agent1:                 episode reward: 0.1747,                 loss: 0.2466
Episode: 2161/30000 (7.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0304s / 96.9699 s
agent0:                 episode reward: -0.2774,                 loss: nan
agent1:                 episode reward: 0.2774,                 loss: 0.2463
Episode: 2181/30000 (7.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9981s / 97.9680 s
agent0:                 episode reward: -0.0509,                 loss: nan
agent1:                 episode reward: 0.0509,                 loss: 0.2772
Episode: 2201/30000 (7.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0020s / 98.9701 s
agent0:                 episode reward: -0.9107,                 loss: nan
agent1:                 episode reward: 0.9107,                 loss: 0.2799
Episode: 2221/30000 (7.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0563s / 100.0264 s
agent0:                 episode reward: -0.8052,                 loss: nan
agent1:                 episode reward: 0.8052,                 loss: 0.2787
Episode: 2241/30000 (7.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0011s / 101.0275 s
agent0:                 episode reward: 0.0011,                 loss: nan
agent1:                 episode reward: -0.0011,                 loss: 0.2768
Episode: 2261/30000 (7.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9926s / 102.0201 s
agent0:                 episode reward: -0.7192,                 loss: nan
agent1:                 episode reward: 0.7192,                 loss: 0.2752
Episode: 2281/30000 (7.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0369s / 103.0570 s
agent0:                 episode reward: -0.4307,                 loss: nan
agent1:                 episode reward: 0.4307,                 loss: 0.2974
Episode: 2301/30000 (7.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0142s / 104.0712 s
agent0:                 episode reward: -0.8323,                 loss: nan
agent1:                 episode reward: 0.8323,                 loss: 0.2978
Episode: 2321/30000 (7.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9914s / 105.0626 s
agent0:                 episode reward: -0.4965,                 loss: nan
agent1:                 episode reward: 0.4965,                 loss: 0.2977
Episode: 2341/30000 (7.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0509s / 106.1135 s
agent0:                 episode reward: -0.9415,                 loss: nan
agent1:                 episode reward: 0.9415,                 loss: 0.2961
Episode: 2361/30000 (7.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0207s / 107.1342 s
agent0:                 episode reward: -1.4425,                 loss: nan
agent1:                 episode reward: 1.4425,                 loss: 0.2939
Episode: 2381/30000 (7.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0628s / 108.1970 s
agent0:                 episode reward: -0.8107,                 loss: nan
agent1:                 episode reward: 0.8107,                 loss: 0.3262
Episode: 2401/30000 (8.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0506s / 109.2476 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.3292
Episode: 2421/30000 (8.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0446s / 110.2922 s
agent0:                 episode reward: -0.3906,                 loss: nan
agent1:                 episode reward: 0.3906,                 loss: 0.3284
Episode: 2441/30000 (8.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0518s / 111.3440 s
agent0:                 episode reward: -0.4810,                 loss: nan
agent1:                 episode reward: 0.4810,                 loss: 0.3266
Episode: 2461/30000 (8.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0747s / 112.4186 s
agent0:                 episode reward: -0.4245,                 loss: nan
agent1:                 episode reward: 0.4245,                 loss: 0.3279
Episode: 2481/30000 (8.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0527s / 113.4713 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.3203
Episode: 2501/30000 (8.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0635s / 114.5348 s
agent0:                 episode reward: -0.3059,                 loss: nan
agent1:                 episode reward: 0.3059,                 loss: 0.3145
Episode: 2521/30000 (8.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0706s / 115.6054 s
agent0:                 episode reward: -0.9096,                 loss: nan
agent1:                 episode reward: 0.9096,                 loss: 0.3140
Episode: 2541/30000 (8.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0900s / 116.6954 s
agent0:                 episode reward: -0.6879,                 loss: nan
agent1:                 episode reward: 0.6879,                 loss: 0.3135
Episode: 2561/30000 (8.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0637s / 117.7591 s
agent0:                 episode reward: -0.6162,                 loss: nan
agent1:                 episode reward: 0.6162,                 loss: 0.3130
Episode: 2581/30000 (8.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0530s / 118.8120 s
agent0:                 episode reward: -1.2945,                 loss: nan
agent1:                 episode reward: 1.2945,                 loss: 0.2600
Episode: 2601/30000 (8.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0588s / 119.8709 s
agent0:                 episode reward: -0.2403,                 loss: nan
agent1:                 episode reward: 0.2403,                 loss: 0.2482
Episode: 2621/30000 (8.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0769s / 120.9477 s
agent0:                 episode reward: -1.1907,                 loss: nan
agent1:                 episode reward: 1.1907,                 loss: 0.2457
Episode: 2641/30000 (8.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0819s / 122.0296 s
agent0:                 episode reward: -0.8495,                 loss: nan
agent1:                 episode reward: 0.8495,                 loss: 0.2455
Episode: 2661/30000 (8.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0600s / 123.0896 s
agent0:                 episode reward: -1.0133,                 loss: nan
agent1:                 episode reward: 1.0133,                 loss: 0.2405
Episode: 2681/30000 (8.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1068s / 124.1964 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1821
Episode: 2701/30000 (9.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0819s / 125.2783 s
agent0:                 episode reward: -1.0534,                 loss: nan
agent1:                 episode reward: 1.0534,                 loss: 0.1683
Episode: 2721/30000 (9.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1629s / 126.4412 s
agent0:                 episode reward: -0.5349,                 loss: nan
agent1:                 episode reward: 0.5349,                 loss: 0.1673
Episode: 2741/30000 (9.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0904s / 127.5316 s
agent0:                 episode reward: -1.0407,                 loss: nan
agent1:                 episode reward: 1.0407,                 loss: 0.1686
Episode: 2761/30000 (9.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0867s / 128.6183 s
agent0:                 episode reward: -0.4784,                 loss: nan
agent1:                 episode reward: 0.4784,                 loss: 0.1685
Episode: 2781/30000 (9.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0873s / 129.7056 s
agent0:                 episode reward: -0.8839,                 loss: nan
agent1:                 episode reward: 0.8839,                 loss: 0.1593
Episode: 2801/30000 (9.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0965s / 130.8022 s
agent0:                 episode reward: -1.0766,                 loss: nan
agent1:                 episode reward: 1.0766,                 loss: 0.1563
Episode: 2821/30000 (9.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0832s / 131.8854 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.1578
Episode: 2841/30000 (9.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1261s / 133.0114 s
agent0:                 episode reward: -0.9344,                 loss: nan
agent1:                 episode reward: 0.9344,                 loss: 0.1545
Episode: 2861/30000 (9.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0972s / 134.1086 s
agent0:                 episode reward: -0.9620,                 loss: nan
agent1:                 episode reward: 0.9620,                 loss: 0.1573
Episode: 2881/30000 (9.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1029s / 135.2116 s
agent0:                 episode reward: -0.8395,                 loss: nan
agent1:                 episode reward: 0.8395,                 loss: 0.1585
Episode: 2901/30000 (9.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1685s / 136.3801 s
agent0:                 episode reward: -1.2697,                 loss: nan
agent1:                 episode reward: 1.2697,                 loss: 0.1579
Episode: 2921/30000 (9.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1270s / 137.5070 s
agent0:                 episode reward: -0.6087,                 loss: nan
agent1:                 episode reward: 0.6087,                 loss: 0.1577
Episode: 2941/30000 (9.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1035s / 138.6105 s
agent0:                 episode reward: -1.2029,                 loss: nan
agent1:                 episode reward: 1.2029,                 loss: 0.1571
Episode: 2961/30000 (9.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1068s / 139.7173 s
agent0:                 episode reward: -0.2582,                 loss: nan
agent1:                 episode reward: 0.2582,                 loss: 0.1580
Episode: 2981/30000 (9.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1341s / 140.8513 s
agent0:                 episode reward: -0.7800,                 loss: nan
agent1:                 episode reward: 0.7800,                 loss: 0.1729
Episode: 3001/30000 (10.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1128s / 141.9641 s
agent0:                 episode reward: -0.7873,                 loss: nan
agent1:                 episode reward: 0.7873,                 loss: 0.1754
Episode: 3021/30000 (10.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1035s / 143.0676 s
agent0:                 episode reward: -0.4076,                 loss: nan
agent1:                 episode reward: 0.4076,                 loss: 0.1760
Episode: 3041/30000 (10.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1181s / 144.1857 s
agent0:                 episode reward: -0.4051,                 loss: nan
agent1:                 episode reward: 0.4051,                 loss: 0.1752
Episode: 3061/30000 (10.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1302s / 145.3159 s
agent0:                 episode reward: -0.6075,                 loss: nan
agent1:                 episode reward: 0.6075,                 loss: 0.1748
Episode: 3081/30000 (10.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1141s / 146.4301 s
agent0:                 episode reward: -0.5938,                 loss: nan
agent1:                 episode reward: 0.5938,                 loss: 0.2098
Episode: 3101/30000 (10.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1755s / 147.6056 s
agent0:                 episode reward: -0.9377,                 loss: nan
agent1:                 episode reward: 0.9377,                 loss: 0.2137
Episode: 3121/30000 (10.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1311s / 148.7367 s
agent0:                 episode reward: -1.1047,                 loss: nan
agent1:                 episode reward: 1.1047,                 loss: 0.2138
Episode: 3141/30000 (10.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1250s / 149.8617 s
agent0:                 episode reward: -1.3021,                 loss: nan
agent1:                 episode reward: 1.3021,                 loss: 0.2133
Episode: 3161/30000 (10.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1326s / 150.9943 s
agent0:                 episode reward: -1.5817,                 loss: nan
agent1:                 episode reward: 1.5817,                 loss: 0.2118
Episode: 3181/30000 (10.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1216s / 152.1159 s
agent0:                 episode reward: -0.8429,                 loss: nan
agent1:                 episode reward: 0.8429,                 loss: 0.2403
Episode: 3201/30000 (10.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1180s / 153.2339 s
agent0:                 episode reward: -0.2659,                 loss: nan
agent1:                 episode reward: 0.2659,                 loss: 0.2450
Episode: 3221/30000 (10.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1381s / 154.3720 s
agent0:                 episode reward: -1.2643,                 loss: nan
agent1:                 episode reward: 1.2643,                 loss: 0.2420
Episode: 3241/30000 (10.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1197s / 155.4917 s
agent0:                 episode reward: -0.7909,                 loss: nan
agent1:                 episode reward: 0.7909,                 loss: 0.2396
Episode: 3261/30000 (10.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1445s / 156.6362 s
agent0:                 episode reward: -0.8429,                 loss: nan
agent1:                 episode reward: 0.8429,                 loss: 0.2414
Episode: 3281/30000 (10.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2675s / 157.9037 s
agent0:                 episode reward: -0.3525,                 loss: nan
agent1:                 episode reward: 0.3525,                 loss: 0.2855
Episode: 3301/30000 (11.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1225s / 159.0262 s
agent0:                 episode reward: -0.8718,                 loss: nan
agent1:                 episode reward: 0.8718,                 loss: 0.2892
Episode: 3321/30000 (11.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1455s / 160.1717 s
agent0:                 episode reward: -1.0558,                 loss: nan
agent1:                 episode reward: 1.0558,                 loss: 0.2936
Episode: 3341/30000 (11.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1389s / 161.3106 s
agent0:                 episode reward: -0.7445,                 loss: nan
agent1:                 episode reward: 0.7445,                 loss: 0.2870
Episode: 3361/30000 (11.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1353s / 162.4459 s
agent0:                 episode reward: -0.7814,                 loss: nan
agent1:                 episode reward: 0.7814,                 loss: 0.2918
Episode: 3381/30000 (11.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1685s / 163.6143 s
agent0:                 episode reward: -1.1785,                 loss: nan
agent1:                 episode reward: 1.1785,                 loss: 0.3068
Episode: 3401/30000 (11.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1462s / 164.7605 s
agent0:                 episode reward: -0.6985,                 loss: nan
agent1:                 episode reward: 0.6985,                 loss: 0.3028
Episode: 3421/30000 (11.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1850s / 165.9455 s
agent0:                 episode reward: -1.0063,                 loss: nan
agent1:                 episode reward: 1.0063,                 loss: 0.3029
Episode: 3441/30000 (11.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1459s / 167.0914 s
agent0:                 episode reward: -0.3947,                 loss: nan
agent1:                 episode reward: 0.3947,                 loss: 0.3038
Episode: 3461/30000 (11.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1983s / 168.2897 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.3031
Episode: 3481/30000 (11.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1659s / 169.4556 s
agent0:                 episode reward: -1.3525,                 loss: nan
agent1:                 episode reward: 1.3525,                 loss: 0.2633
Episode: 3501/30000 (11.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1621s / 170.6177 s
agent0:                 episode reward: -0.9088,                 loss: nan
agent1:                 episode reward: 0.9088,                 loss: 0.2532
Episode: 3521/30000 (11.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1723s / 171.7900 s
agent0:                 episode reward: -1.0943,                 loss: nan
agent1:                 episode reward: 1.0943,                 loss: 0.2532
Episode: 3541/30000 (11.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1639s / 172.9539 s
agent0:                 episode reward: -0.7705,                 loss: nan
agent1:                 episode reward: 0.7705,                 loss: 0.2535
Episode: 3561/30000 (11.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1865s / 174.1404 s
agent0:                 episode reward: -1.0137,                 loss: nan
agent1:                 episode reward: 1.0137,                 loss: 0.2524
Episode: 3581/30000 (11.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2010s / 175.3414 s
agent0:                 episode reward: -0.5397,                 loss: nan
agent1:                 episode reward: 0.5397,                 loss: 0.2322
Episode: 3601/30000 (12.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1669s / 176.5083 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.2251
Episode: 3621/30000 (12.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2196s / 177.7278 s
agent0:                 episode reward: -0.8467,                 loss: nan
agent1:                 episode reward: 0.8467,                 loss: 0.2261
Episode: 3641/30000 (12.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1713s / 178.8991 s
agent0:                 episode reward: -0.9073,                 loss: nan
agent1:                 episode reward: 0.9073,                 loss: 0.2275
Episode: 3661/30000 (12.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1614s / 180.0605 s
agent0:                 episode reward: -1.2352,                 loss: nan
agent1:                 episode reward: 1.2352,                 loss: 0.2249
Episode: 3681/30000 (12.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1655s / 181.2260 s
agent0:                 episode reward: -1.1165,                 loss: nan
agent1:                 episode reward: 1.1165,                 loss: 0.2025
Episode: 3701/30000 (12.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1856s / 182.4115 s
agent0:                 episode reward: -0.9874,                 loss: nan
agent1:                 episode reward: 0.9874,                 loss: 0.2005
Episode: 3721/30000 (12.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1829s / 183.5944 s
agent0:                 episode reward: -0.6272,                 loss: nan
agent1:                 episode reward: 0.6272,                 loss: 0.1990
Episode: 3741/30000 (12.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1862s / 184.7806 s
agent0:                 episode reward: -0.7974,                 loss: nan
agent1:                 episode reward: 0.7974,                 loss: 0.2007
Episode: 3761/30000 (12.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1751s / 185.9557 s
agent0:                 episode reward: -1.1888,                 loss: nan
agent1:                 episode reward: 1.1888,                 loss: 0.1981
Episode: 3781/30000 (12.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1975s / 187.1532 s
agent0:                 episode reward: -1.1333,                 loss: nan
agent1:                 episode reward: 1.1333,                 loss: 0.1783
Episode: 3801/30000 (12.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2342s / 188.3874 s
agent0:                 episode reward: -1.3277,                 loss: nan
agent1:                 episode reward: 1.3277,                 loss: 0.1710
Episode: 3821/30000 (12.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1974s / 189.5848 s
agent0:                 episode reward: -1.0426,                 loss: nan
agent1:                 episode reward: 1.0426,                 loss: 0.1703
Episode: 3841/30000 (12.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2256s / 190.8104 s
agent0:                 episode reward: -1.0993,                 loss: nan
agent1:                 episode reward: 1.0993,                 loss: 0.1706
Episode: 3861/30000 (12.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1987s / 192.0091 s
agent0:                 episode reward: -1.0855,                 loss: nan
agent1:                 episode reward: 1.0855,                 loss: 0.1703
Episode: 3881/30000 (12.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2189s / 193.2280 s
agent0:                 episode reward: -1.1619,                 loss: nan
agent1:                 episode reward: 1.1619,                 loss: 0.2203
Episode: 3901/30000 (13.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2020s / 194.4300 s
agent0:                 episode reward: -1.2673,                 loss: nan
agent1:                 episode reward: 1.2673,                 loss: 0.2275
Episode: 3921/30000 (13.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2159s / 195.6459 s
agent0:                 episode reward: -1.3042,                 loss: nan
agent1:                 episode reward: 1.3042,                 loss: 0.2244
Episode: 3941/30000 (13.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2334s / 196.8794 s
agent0:                 episode reward: -0.4424,                 loss: nan
agent1:                 episode reward: 0.4424,                 loss: 0.2258
Episode: 3961/30000 (13.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2613s / 198.1407 s
agent0:                 episode reward: -0.6821,                 loss: nan
agent1:                 episode reward: 0.6821,                 loss: 0.2260
Episode: 3981/30000 (13.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2578s / 199.3985 s
agent0:                 episode reward: -1.0069,                 loss: nan
agent1:                 episode reward: 1.0069,                 loss: 0.2185
Episode: 4001/30000 (13.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2043s / 200.6029 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.2175
Episode: 4021/30000 (13.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2250s / 201.8279 s
agent0:                 episode reward: -1.4576,                 loss: nan
agent1:                 episode reward: 1.4576,                 loss: 0.2168
Episode: 4041/30000 (13.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2102s / 203.0381 s
agent0:                 episode reward: -1.1957,                 loss: nan
agent1:                 episode reward: 1.1957,                 loss: 0.2168
Episode: 4061/30000 (13.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2280s / 204.2661 s
agent0:                 episode reward: -1.2313,                 loss: nan
agent1:                 episode reward: 1.2313,                 loss: 0.2176
Episode: 4081/30000 (13.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2264s / 205.4925 s
agent0:                 episode reward: -1.4938,                 loss: nan
agent1:                 episode reward: 1.4938,                 loss: 0.2040
Episode: 4101/30000 (13.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2246s / 206.7171 s
agent0:                 episode reward: -1.2127,                 loss: nan
agent1:                 episode reward: 1.2127,                 loss: 0.2025
Episode: 4121/30000 (13.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2484s / 207.9656 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.2016
Episode: 4141/30000 (13.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2691s / 209.2347 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.1998
Episode: 4161/30000 (13.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2393s / 210.4739 s
agent0:                 episode reward: -1.9758,                 loss: nan
agent1:                 episode reward: 1.9758,                 loss: 0.2014
Episode: 4181/30000 (13.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2429s / 211.7168 s
agent0:                 episode reward: -1.6371,                 loss: nan
agent1:                 episode reward: 1.6371,                 loss: 0.2190
Episode: 4201/30000 (14.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2357s / 212.9525 s
agent0:                 episode reward: -0.8147,                 loss: nan
agent1:                 episode reward: 0.8147,                 loss: 0.2220
Episode: 4221/30000 (14.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2692s / 214.2217 s
agent0:                 episode reward: -0.7609,                 loss: nan
agent1:                 episode reward: 0.7609,                 loss: 0.2224
Episode: 4241/30000 (14.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2565s / 215.4782 s
agent0:                 episode reward: -0.7685,                 loss: nan
agent1:                 episode reward: 0.7685,                 loss: 0.2198
Episode: 4261/30000 (14.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2428s / 216.7210 s
agent0:                 episode reward: -1.1660,                 loss: nan
agent1:                 episode reward: 1.1660,                 loss: 0.2207
Episode: 4281/30000 (14.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2436s / 217.9646 s
agent0:                 episode reward: -0.7832,                 loss: nan
agent1:                 episode reward: 0.7832,                 loss: 0.2479
Episode: 4301/30000 (14.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2990s / 219.2636 s
agent0:                 episode reward: -0.8458,                 loss: nan
agent1:                 episode reward: 0.8458,                 loss: 0.2516
Episode: 4321/30000 (14.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2488s / 220.5124 s
agent0:                 episode reward: -0.9747,                 loss: nan
agent1:                 episode reward: 0.9747,                 loss: 0.2513
Episode: 4341/30000 (14.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2506s / 221.7631 s
agent0:                 episode reward: -1.1324,                 loss: nan
agent1:                 episode reward: 1.1324,                 loss: 0.2533
Episode: 4361/30000 (14.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2601s / 223.0232 s
agent0:                 episode reward: -1.4851,                 loss: nan
agent1:                 episode reward: 1.4851,                 loss: 0.2519
Episode: 4381/30000 (14.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3121s / 224.3353 s
agent0:                 episode reward: -1.2818,                 loss: nan
agent1:                 episode reward: 1.2818,                 loss: 0.2872
Episode: 4401/30000 (14.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2869s / 225.6222 s
agent0:                 episode reward: -0.7158,                 loss: nan
agent1:                 episode reward: 0.7158,                 loss: 0.2921
Episode: 4421/30000 (14.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2545s / 226.8768 s
agent0:                 episode reward: -0.7081,                 loss: nan
agent1:                 episode reward: 0.7081,                 loss: 0.2902
Episode: 4441/30000 (14.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2653s / 228.1420 s
agent0:                 episode reward: -1.3772,                 loss: nan
agent1:                 episode reward: 1.3772,                 loss: 0.2903
Episode: 4461/30000 (14.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3204s / 229.4624 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.2923
Episode: 4481/30000 (14.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2606s / 230.7230 s
agent0:                 episode reward: -0.9885,                 loss: nan
agent1:                 episode reward: 0.9885,                 loss: 0.2744
Episode: 4501/30000 (15.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2831s / 232.0061 s
agent0:                 episode reward: -1.3657,                 loss: nan
agent1:                 episode reward: 1.3657,                 loss: 0.2707
Episode: 4521/30000 (15.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2672s / 233.2733 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.2712
Episode: 4541/30000 (15.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2915s / 234.5648 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.2734
Episode: 4561/30000 (15.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2765s / 235.8413 s
agent0:                 episode reward: -1.2368,                 loss: nan
agent1:                 episode reward: 1.2368,                 loss: 0.2717
Episode: 4581/30000 (15.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2714s / 237.1128 s
agent0:                 episode reward: -1.1898,                 loss: nan
agent1:                 episode reward: 1.1898,                 loss: 0.2435
Episode: 4601/30000 (15.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2843s / 238.3971 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.2378
Episode: 4621/30000 (15.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3244s / 239.7215 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.2389
Episode: 4641/30000 (15.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3064s / 241.0279 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.2379
Episode: 4661/30000 (15.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2839s / 242.3118 s
agent0:                 episode reward: -1.2357,                 loss: nan
agent1:                 episode reward: 1.2357,                 loss: 0.2369
Episode: 4681/30000 (15.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2940s / 243.6057 s
agent0:                 episode reward: -1.2425,                 loss: nan
agent1:                 episode reward: 1.2425,                 loss: 0.1984
Episode: 4701/30000 (15.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2952s / 244.9010 s
agent0:                 episode reward: -1.3373,                 loss: nan
agent1:                 episode reward: 1.3373,                 loss: 0.1888
Episode: 4721/30000 (15.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2974s / 246.1984 s
agent0:                 episode reward: -1.3966,                 loss: nan
agent1:                 episode reward: 1.3966,                 loss: 0.1882
Episode: 4741/30000 (15.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2977s / 247.4960 s
agent0:                 episode reward: -0.9732,                 loss: nan
agent1:                 episode reward: 0.9732,                 loss: 0.1874
Episode: 4761/30000 (15.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3097s / 248.8057 s
agent0:                 episode reward: -0.8031,                 loss: nan
agent1:                 episode reward: 0.8031,                 loss: 0.1873
Episode: 4781/30000 (15.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3582s / 250.1639 s
agent0:                 episode reward: -1.0386,                 loss: nan
agent1:                 episode reward: 1.0386,                 loss: 0.1607
Episode: 4801/30000 (16.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2949s / 251.4587 s
agent0:                 episode reward: -1.3549,                 loss: nan
agent1:                 episode reward: 1.3549,                 loss: 0.1545
Episode: 4821/30000 (16.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3158s / 252.7745 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.1539
Episode: 4841/30000 (16.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3039s / 254.0784 s
agent0:                 episode reward: -1.0435,                 loss: nan
agent1:                 episode reward: 1.0435,                 loss: 0.1560
Episode: 4861/30000 (16.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3135s / 255.3919 s
agent0:                 episode reward: -1.1138,                 loss: nan
agent1:                 episode reward: 1.1138,                 loss: 0.1546
Episode: 4881/30000 (16.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3331s / 256.7250 s
agent0:                 episode reward: -1.5836,                 loss: nan
agent1:                 episode reward: 1.5836,                 loss: 0.1601
Episode: 4901/30000 (16.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3417s / 258.0668 s
agent0:                 episode reward: -1.3063,                 loss: nan
agent1:                 episode reward: 1.3063,                 loss: 0.1603
Episode: 4921/30000 (16.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3541s / 259.4209 s
agent0:                 episode reward: -1.2755,                 loss: nan
agent1:                 episode reward: 1.2755,                 loss: 0.1598
Episode: 4941/30000 (16.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3192s / 260.7401 s
agent0:                 episode reward: -1.6626,                 loss: nan
agent1:                 episode reward: 1.6626,                 loss: 0.1599
Episode: 4961/30000 (16.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3167s / 262.0568 s
agent0:                 episode reward: -1.3821,                 loss: nan
agent1:                 episode reward: 1.3821,                 loss: 0.1584
Episode: 4981/30000 (16.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3230s / 263.3798 s
agent0:                 episode reward: -1.4997,                 loss: nan
agent1:                 episode reward: 1.4997,                 loss: 0.1569
Episode: 5001/30000 (16.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3181s / 264.6979 s
agent0:                 episode reward: -1.5151,                 loss: nan
agent1:                 episode reward: 1.5151,                 loss: 0.1532
Episode: 5021/30000 (16.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3458s / 266.0437 s
agent0:                 episode reward: -1.7382,                 loss: nan
agent1:                 episode reward: 1.7382,                 loss: 0.1549
Episode: 5041/30000 (16.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3256s / 267.3693 s
agent0:                 episode reward: -1.2626,                 loss: nan
agent1:                 episode reward: 1.2626,                 loss: 0.1541
Episode: 5061/30000 (16.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3310s / 268.7003 s
agent0:                 episode reward: -0.8542,                 loss: nan
agent1:                 episode reward: 0.8542,                 loss: 0.1526
Episode: 5081/30000 (16.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3688s / 270.0691 s
agent0:                 episode reward: -1.3874,                 loss: nan
agent1:                 episode reward: 1.3874,                 loss: 0.1785
Episode: 5101/30000 (17.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3387s / 271.4077 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.1774
Episode: 5121/30000 (17.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3304s / 272.7382 s
agent0:                 episode reward: -1.7310,                 loss: nan
agent1:                 episode reward: 1.7310,                 loss: 0.1787
Episode: 5141/30000 (17.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3524s / 274.0906 s
agent0:                 episode reward: -1.4855,                 loss: nan
agent1:                 episode reward: 1.4855,                 loss: 0.1798
Episode: 5161/30000 (17.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3479s / 275.4385 s
agent0:                 episode reward: -1.1235,                 loss: nan
agent1:                 episode reward: 1.1235,                 loss: 0.1795
Episode: 5181/30000 (17.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3484s / 276.7869 s
agent0:                 episode reward: -1.3925,                 loss: nan
agent1:                 episode reward: 1.3925,                 loss: 0.2439
Episode: 5201/30000 (17.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3479s / 278.1348 s
agent0:                 episode reward: -1.1962,                 loss: nan
agent1:                 episode reward: 1.1962,                 loss: 0.2518
Episode: 5221/30000 (17.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3477s / 279.4825 s
agent0:                 episode reward: -2.2055,                 loss: nan
agent1:                 episode reward: 2.2055,                 loss: 0.2513
Episode: 5241/30000 (17.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3879s / 280.8704 s
agent0:                 episode reward: -1.4668,                 loss: nan
agent1:                 episode reward: 1.4668,                 loss: 0.2513
Episode: 5261/30000 (17.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3755s / 282.2459 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.2529
Episode: 5281/30000 (17.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3522s / 283.5981 s
agent0:                 episode reward: -1.3720,                 loss: nan
agent1:                 episode reward: 1.3720,                 loss: 0.2837
Episode: 5301/30000 (17.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3478s / 284.9459 s
agent0:                 episode reward: -1.6378,                 loss: nan
agent1:                 episode reward: 1.6378,                 loss: 0.2861
Episode: 5321/30000 (17.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3600s / 286.3060 s
agent0:                 episode reward: -0.8540,                 loss: nan
agent1:                 episode reward: 0.8540,                 loss: 0.2881
Episode: 5341/30000 (17.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3500s / 287.6559 s
agent0:                 episode reward: -1.6569,                 loss: nan
agent1:                 episode reward: 1.6569,                 loss: 0.2881
Episode: 5361/30000 (17.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3714s / 289.0273 s
agent0:                 episode reward: -1.1245,                 loss: nan
agent1:                 episode reward: 1.1245,                 loss: 0.2882
Episode: 5381/30000 (17.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4157s / 290.4430 s
agent0:                 episode reward: -1.6034,                 loss: nan
agent1:                 episode reward: 1.6034,                 loss: 0.2894
Episode: 5401/30000 (18.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3961s / 291.8391 s
agent0:                 episode reward: -1.5976,                 loss: nan
agent1:                 episode reward: 1.5976,                 loss: 0.2861
Episode: 5421/30000 (18.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3645s / 293.2036 s
agent0:                 episode reward: -1.6394,                 loss: nan
agent1:                 episode reward: 1.6394,                 loss: 0.2848
Episode: 5441/30000 (18.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3597s / 294.5633 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.2852
Episode: 5461/30000 (18.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3815s / 295.9448 s
agent0:                 episode reward: -0.9058,                 loss: nan
agent1:                 episode reward: 0.9058,                 loss: 0.2870
Episode: 5481/30000 (18.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3634s / 297.3081 s
agent0:                 episode reward: -1.1432,                 loss: nan
agent1:                 episode reward: 1.1432,                 loss: 0.2137
Episode: 5501/30000 (18.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4234s / 298.7315 s
agent0:                 episode reward: -1.8553,                 loss: nan
agent1:                 episode reward: 1.8553,                 loss: 0.1995
Episode: 5521/30000 (18.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3828s / 300.1144 s
agent0:                 episode reward: -1.6988,                 loss: nan
agent1:                 episode reward: 1.6988,                 loss: 0.1971
Episode: 5541/30000 (18.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4244s / 301.5388 s
agent0:                 episode reward: -1.0930,                 loss: nan
agent1:                 episode reward: 1.0930,                 loss: 0.1984
Episode: 5561/30000 (18.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3858s / 302.9245 s
agent0:                 episode reward: -0.8638,                 loss: nan
agent1:                 episode reward: 0.8638,                 loss: 0.1968
Episode: 5581/30000 (18.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3934s / 304.3180 s
agent0:                 episode reward: -1.2650,                 loss: nan
agent1:                 episode reward: 1.2650,                 loss: 0.1396
Episode: 5601/30000 (18.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3950s / 305.7130 s
agent0:                 episode reward: -1.2587,                 loss: nan
agent1:                 episode reward: 1.2587,                 loss: 0.1248
Episode: 5621/30000 (18.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4214s / 307.1344 s
agent0:                 episode reward: -1.6027,                 loss: nan
agent1:                 episode reward: 1.6027,                 loss: 0.1239
Episode: 5641/30000 (18.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3854s / 308.5197 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.1234
Episode: 5661/30000 (18.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3843s / 309.9040 s
agent0:                 episode reward: -0.8713,                 loss: nan
agent1:                 episode reward: 0.8713,                 loss: 0.1228
Episode: 5681/30000 (18.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4363s / 311.3402 s
agent0:                 episode reward: -1.0156,                 loss: nan
agent1:                 episode reward: 1.0156,                 loss: 0.1284
Episode: 5701/30000 (19.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3914s / 312.7316 s
agent0:                 episode reward: -1.5253,                 loss: nan
agent1:                 episode reward: 1.5253,                 loss: 0.1271
Episode: 5721/30000 (19.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3971s / 314.1287 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.1290
Episode: 5741/30000 (19.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4163s / 315.5450 s
agent0:                 episode reward: -0.8937,                 loss: nan
agent1:                 episode reward: 0.8937,                 loss: 0.1287
Episode: 5761/30000 (19.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4051s / 316.9501 s
agent0:                 episode reward: -1.3671,                 loss: nan
agent1:                 episode reward: 1.3671,                 loss: 0.1278
Episode: 5781/30000 (19.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4003s / 318.3504 s
agent0:                 episode reward: -1.2227,                 loss: nan
agent1:                 episode reward: 1.2227,                 loss: 0.1404
Episode: 5801/30000 (19.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4146s / 319.7650 s
agent0:                 episode reward: -1.3943,                 loss: nan
agent1:                 episode reward: 1.3943,                 loss: 0.1414
Episode: 5821/30000 (19.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4426s / 321.2076 s
agent0:                 episode reward: -1.2163,                 loss: nan
agent1:                 episode reward: 1.2163,                 loss: 0.1408
Episode: 5841/30000 (19.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4085s / 322.6160 s
agent0:                 episode reward: -0.9810,                 loss: nan
agent1:                 episode reward: 0.9810,                 loss: 0.1406
Episode: 5861/30000 (19.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4242s / 324.0402 s
agent0:                 episode reward: -1.0315,                 loss: nan
agent1:                 episode reward: 1.0315,                 loss: 0.1402
Episode: 5881/30000 (19.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4199s / 325.4602 s
agent0:                 episode reward: -1.6408,                 loss: nan
agent1:                 episode reward: 1.6408,                 loss: 0.1664
Episode: 5901/30000 (19.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4089s / 326.8690 s
agent0:                 episode reward: -0.9476,                 loss: nan
agent1:                 episode reward: 0.9476,                 loss: 0.1676
Episode: 5921/30000 (19.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4156s / 328.2847 s
agent0:                 episode reward: -0.9987,                 loss: nan
agent1:                 episode reward: 0.9987,                 loss: 0.1688
Episode: 5941/30000 (19.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4144s / 329.6990 s
agent0:                 episode reward: -1.5045,                 loss: nan
agent1:                 episode reward: 1.5045,                 loss: 0.1668
Episode: 5961/30000 (19.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4752s / 331.1742 s
agent0:                 episode reward: -0.9704,                 loss: nan
agent1:                 episode reward: 0.9704,                 loss: 0.1679
Episode: 5981/30000 (19.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4150s / 332.5892 s
agent0:                 episode reward: -0.5085,                 loss: nan
agent1:                 episode reward: 0.5085,                 loss: 0.1875
Episode: 6001/30000 (20.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4145s / 334.0037 s
agent0:                 episode reward: -2.0271,                 loss: nan
agent1:                 episode reward: 2.0271,                 loss: 0.1903
Episode: 6021/30000 (20.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4198s / 335.4235 s
agent0:                 episode reward: -1.0789,                 loss: nan
agent1:                 episode reward: 1.0789,                 loss: 0.1913
Episode: 6041/30000 (20.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4431s / 336.8666 s
agent0:                 episode reward: -0.8015,                 loss: nan
agent1:                 episode reward: 0.8015,                 loss: 0.1925
Episode: 6061/30000 (20.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4349s / 338.3015 s
agent0:                 episode reward: -1.1336,                 loss: nan
agent1:                 episode reward: 1.1336,                 loss: 0.1898
Episode: 6081/30000 (20.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4394s / 339.7410 s
agent0:                 episode reward: -0.9193,                 loss: nan
agent1:                 episode reward: 0.9193,                 loss: 0.1907
Episode: 6101/30000 (20.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4607s / 341.2017 s
agent0:                 episode reward: -0.4604,                 loss: nan
agent1:                 episode reward: 0.4604,                 loss: 0.1896
Episode: 6121/30000 (20.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4991s / 342.7008 s
agent0:                 episode reward: -0.9361,                 loss: nan
agent1:                 episode reward: 0.9361,                 loss: 0.1890
Episode: 6141/30000 (20.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4627s / 344.1635 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.1891
Episode: 6161/30000 (20.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4765s / 345.6400 s
agent0:                 episode reward: -0.7702,                 loss: nan
agent1:                 episode reward: 0.7702,                 loss: 0.1900
Episode: 6181/30000 (20.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4703s / 347.1103 s
agent0:                 episode reward: -1.8452,                 loss: nan
agent1:                 episode reward: 1.8452,                 loss: 0.2419
Episode: 6201/30000 (20.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4817s / 348.5920 s
agent0:                 episode reward: -1.5103,                 loss: nan
agent1:                 episode reward: 1.5103,                 loss: 0.2493
Episode: 6221/30000 (20.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4469s / 350.0389 s
agent0:                 episode reward: -1.6115,                 loss: nan
agent1:                 episode reward: 1.6115,                 loss: 0.2474
Episode: 6241/30000 (20.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4781s / 351.5169 s
agent0:                 episode reward: -1.3523,                 loss: nan
agent1:                 episode reward: 1.3523,                 loss: 0.2485
Episode: 6261/30000 (20.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4987s / 353.0156 s
agent0:                 episode reward: -1.1399,                 loss: nan
agent1:                 episode reward: 1.1399,                 loss: 0.2477
Episode: 6281/30000 (20.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4444s / 354.4600 s
agent0:                 episode reward: -0.6917,                 loss: nan
agent1:                 episode reward: 0.6917,                 loss: 0.2580
Episode: 6301/30000 (21.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5248s / 355.9848 s
agent0:                 episode reward: -1.5333,                 loss: nan
agent1:                 episode reward: 1.5333,                 loss: 0.2595
Episode: 6321/30000 (21.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4571s / 357.4419 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.2588
Episode: 6341/30000 (21.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4588s / 358.9007 s
agent0:                 episode reward: -1.4336,                 loss: nan
agent1:                 episode reward: 1.4336,                 loss: 0.2602
Episode: 6361/30000 (21.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4661s / 360.3669 s
agent0:                 episode reward: -1.3495,                 loss: nan
agent1:                 episode reward: 1.3495,                 loss: 0.2591
Episode: 6381/30000 (21.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5345s / 361.9014 s
agent0:                 episode reward: -1.6615,                 loss: nan
agent1:                 episode reward: 1.6615,                 loss: 0.2338
Episode: 6401/30000 (21.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4612s / 363.3626 s
agent0:                 episode reward: -1.2439,                 loss: nan
agent1:                 episode reward: 1.2439,                 loss: 0.2288
Episode: 6421/30000 (21.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4969s / 364.8595 s
agent0:                 episode reward: -1.8028,                 loss: nan
agent1:                 episode reward: 1.8028,                 loss: 0.2302
Episode: 6441/30000 (21.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4760s / 366.3354 s
agent0:                 episode reward: -1.3444,                 loss: nan
agent1:                 episode reward: 1.3444,                 loss: 0.2274
Episode: 6461/30000 (21.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4844s / 367.8199 s
agent0:                 episode reward: -0.6421,                 loss: nan
agent1:                 episode reward: 0.6421,                 loss: 0.2289
Episode: 6481/30000 (21.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4672s / 369.2871 s
agent0:                 episode reward: -0.8765,                 loss: nan
agent1:                 episode reward: 0.8765,                 loss: 0.1946
Episode: 6501/30000 (21.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4844s / 370.7715 s
agent0:                 episode reward: -1.0878,                 loss: nan
agent1:                 episode reward: 1.0878,                 loss: 0.1853
Episode: 6521/30000 (21.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5278s / 372.2993 s
agent0:                 episode reward: -1.5758,                 loss: nan
agent1:                 episode reward: 1.5758,                 loss: 0.1865
Episode: 6541/30000 (21.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5653s / 373.8646 s
agent0:                 episode reward: -0.9939,                 loss: nan
agent1:                 episode reward: 0.9939,                 loss: 0.1853
Episode: 6561/30000 (21.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4886s / 375.3532 s
agent0:                 episode reward: -0.9076,                 loss: nan
agent1:                 episode reward: 0.9076,                 loss: 0.1856
Episode: 6581/30000 (21.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5242s / 376.8774 s
agent0:                 episode reward: -1.4265,                 loss: nan
agent1:                 episode reward: 1.4265,                 loss: 0.1759
Episode: 6601/30000 (22.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4930s / 378.3703 s
agent0:                 episode reward: -1.8542,                 loss: nan
agent1:                 episode reward: 1.8542,                 loss: 0.1717
Episode: 6621/30000 (22.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5026s / 379.8729 s
agent0:                 episode reward: -1.3342,                 loss: nan
agent1:                 episode reward: 1.3342,                 loss: 0.1722
Episode: 6641/30000 (22.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5213s / 381.3942 s
agent0:                 episode reward: -1.4617,                 loss: nan
agent1:                 episode reward: 1.4617,                 loss: 0.1742
Episode: 6661/30000 (22.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5652s / 382.9594 s
agent0:                 episode reward: -1.4226,                 loss: nan
agent1:                 episode reward: 1.4226,                 loss: 0.1727
Episode: 6681/30000 (22.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4992s / 384.4586 s
agent0:                 episode reward: -1.8787,                 loss: nan
agent1:                 episode reward: 1.8787,                 loss: 0.1683
Episode: 6701/30000 (22.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5409s / 385.9996 s
agent0:                 episode reward: -1.2253,                 loss: nan
agent1:                 episode reward: 1.2253,                 loss: 0.1642
Episode: 6721/30000 (22.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5113s / 387.5109 s
agent0:                 episode reward: -1.5348,                 loss: nan
agent1:                 episode reward: 1.5348,                 loss: 0.1629
Episode: 6741/30000 (22.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5092s / 389.0200 s
agent0:                 episode reward: -0.2360,                 loss: nan
agent1:                 episode reward: 0.2360,                 loss: 0.1647
Episode: 6761/30000 (22.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5323s / 390.5523 s
agent0:                 episode reward: -1.5165,                 loss: nan
agent1:                 episode reward: 1.5165,                 loss: 0.1643
Episode: 6781/30000 (22.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5293s / 392.0816 s
agent0:                 episode reward: -1.3184,                 loss: nan
agent1:                 episode reward: 1.3184,                 loss: 0.2090
Episode: 6801/30000 (22.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6268s / 393.7083 s
agent0:                 episode reward: -1.2455,                 loss: nan
agent1:                 episode reward: 1.2455,                 loss: 0.2124
Episode: 6821/30000 (22.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5319s / 395.2403 s
agent0:                 episode reward: -1.0017,                 loss: nan
agent1:                 episode reward: 1.0017,                 loss: 0.2140
Episode: 6841/30000 (22.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5476s / 396.7879 s
agent0:                 episode reward: -1.1441,                 loss: nan
agent1:                 episode reward: 1.1441,                 loss: 0.2138
Episode: 6861/30000 (22.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5351s / 398.3230 s
agent0:                 episode reward: -1.5839,                 loss: nan
agent1:                 episode reward: 1.5839,                 loss: 0.2127
Episode: 6881/30000 (22.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5333s / 399.8563 s
agent0:                 episode reward: -1.3877,                 loss: nan
agent1:                 episode reward: 1.3877,                 loss: 0.1868
Episode: 6901/30000 (23.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5238s / 401.3801 s
agent0:                 episode reward: -1.5074,                 loss: nan
agent1:                 episode reward: 1.5074,                 loss: 0.1852
Episode: 6921/30000 (23.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6038s / 402.9839 s
agent0:                 episode reward: -1.4402,                 loss: nan
agent1:                 episode reward: 1.4402,                 loss: 0.1834
Episode: 6941/30000 (23.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5570s / 404.5409 s
agent0:                 episode reward: -1.6701,                 loss: nan
agent1:                 episode reward: 1.6701,                 loss: 0.1839
Episode: 6961/30000 (23.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5691s / 406.1100 s
agent0:                 episode reward: -0.8554,                 loss: nan
agent1:                 episode reward: 0.8554,                 loss: 0.1836
Episode: 6981/30000 (23.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5448s / 407.6548 s
agent0:                 episode reward: -1.6329,                 loss: nan
agent1:                 episode reward: 1.6329,                 loss: 0.1973
Episode: 7001/30000 (23.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5444s / 409.1992 s
agent0:                 episode reward: -0.9793,                 loss: nan
agent1:                 episode reward: 0.9793,                 loss: 0.1969
Episode: 7021/30000 (23.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5434s / 410.7426 s
agent0:                 episode reward: -1.0602,                 loss: nan
agent1:                 episode reward: 1.0602,                 loss: 0.1977
Episode: 7041/30000 (23.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5602s / 412.3028 s
agent0:                 episode reward: -0.8864,                 loss: nan
agent1:                 episode reward: 0.8864,                 loss: 0.1992
Episode: 7061/30000 (23.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5977s / 413.9005 s
agent0:                 episode reward: -1.5838,                 loss: nan
agent1:                 episode reward: 1.5838,                 loss: 0.1973
Episode: 7081/30000 (23.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5646s / 415.4651 s
agent0:                 episode reward: -1.1385,                 loss: nan
agent1:                 episode reward: 1.1385,                 loss: 0.2071
Episode: 7101/30000 (23.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5511s / 417.0162 s
agent0:                 episode reward: -1.3020,                 loss: nan
agent1:                 episode reward: 1.3020,                 loss: 0.2066
Episode: 7121/30000 (23.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5994s / 418.6156 s
agent0:                 episode reward: -1.3989,                 loss: nan
agent1:                 episode reward: 1.3989,                 loss: 0.2076
Episode: 7141/30000 (23.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5566s / 420.1722 s
agent0:                 episode reward: -1.3863,                 loss: nan
agent1:                 episode reward: 1.3863,                 loss: 0.2070
Episode: 7161/30000 (23.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5716s / 421.7438 s
agent0:                 episode reward: -1.2054,                 loss: nan
agent1:                 episode reward: 1.2054,                 loss: 0.2079
Episode: 7181/30000 (23.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6076s / 423.3514 s
agent0:                 episode reward: -1.2312,                 loss: nan
agent1:                 episode reward: 1.2312,                 loss: 0.1997
Episode: 7201/30000 (24.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5746s / 424.9261 s
agent0:                 episode reward: -0.7191,                 loss: nan
agent1:                 episode reward: 0.7191,                 loss: 0.1990
Episode: 7221/30000 (24.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5575s / 426.4835 s
agent0:                 episode reward: -1.0514,                 loss: nan
agent1:                 episode reward: 1.0514,                 loss: 0.1999
Episode: 7241/30000 (24.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6010s / 428.0845 s
agent0:                 episode reward: -1.3371,                 loss: nan
agent1:                 episode reward: 1.3371,                 loss: 0.2003
Episode: 7261/30000 (24.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5600s / 429.6445 s
agent0:                 episode reward: -1.4551,                 loss: nan
agent1:                 episode reward: 1.4551,                 loss: 0.1993
Episode: 7281/30000 (24.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6072s / 431.2517 s
agent0:                 episode reward: -0.8695,                 loss: nan
agent1:                 episode reward: 0.8695,                 loss: 0.2290
Episode: 7301/30000 (24.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5823s / 432.8340 s
agent0:                 episode reward: -1.0354,                 loss: nan
agent1:                 episode reward: 1.0354,                 loss: 0.2332
Episode: 7321/30000 (24.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6269s / 434.4609 s
agent0:                 episode reward: -1.0887,                 loss: nan
agent1:                 episode reward: 1.0887,                 loss: 0.2321
Episode: 7341/30000 (24.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6025s / 436.0634 s
agent0:                 episode reward: -1.8356,                 loss: nan
agent1:                 episode reward: 1.8356,                 loss: 0.2329
Episode: 7361/30000 (24.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5958s / 437.6592 s
agent0:                 episode reward: -1.1499,                 loss: nan
agent1:                 episode reward: 1.1499,                 loss: 0.2313
Episode: 7381/30000 (24.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6181s / 439.2773 s
agent0:                 episode reward: -0.7388,                 loss: nan
agent1:                 episode reward: 0.7388,                 loss: 0.2163
Episode: 7401/30000 (24.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5885s / 440.8658 s
agent0:                 episode reward: -1.6333,                 loss: nan
agent1:                 episode reward: 1.6333,                 loss: 0.2136
Episode: 7421/30000 (24.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6003s / 442.4661 s
agent0:                 episode reward: -2.2220,                 loss: nan
agent1:                 episode reward: 2.2220,                 loss: 0.2131
Episode: 7441/30000 (24.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6508s / 444.1169 s
agent0:                 episode reward: -0.9512,                 loss: nan
agent1:                 episode reward: 0.9512,                 loss: 0.2125
Episode: 7461/30000 (24.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6335s / 445.7504 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.2110
Episode: 7481/30000 (24.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6165s / 447.3669 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.1929
Episode: 7501/30000 (25.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5882s / 448.9551 s
agent0:                 episode reward: -1.0552,                 loss: nan
agent1:                 episode reward: 1.0552,                 loss: 0.1894
Episode: 7521/30000 (25.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6252s / 450.5802 s
agent0:                 episode reward: -0.9830,                 loss: nan
agent1:                 episode reward: 0.9830,                 loss: 0.1913
Episode: 7541/30000 (25.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6211s / 452.2013 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.1897
Episode: 7561/30000 (25.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6134s / 453.8148 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.1897
Episode: 7581/30000 (25.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6561s / 455.4709 s
agent0:                 episode reward: -1.1954,                 loss: nan
agent1:                 episode reward: 1.1954,                 loss: 0.1980
Episode: 7601/30000 (25.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6782s / 457.1491 s
agent0:                 episode reward: -1.2635,                 loss: nan
agent1:                 episode reward: 1.2635,                 loss: 0.1977
Episode: 7621/30000 (25.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6346s / 458.7837 s
agent0:                 episode reward: -1.3572,                 loss: nan
agent1:                 episode reward: 1.3572,                 loss: 0.1984
Episode: 7641/30000 (25.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6340s / 460.4177 s
agent0:                 episode reward: -1.4747,                 loss: nan
agent1:                 episode reward: 1.4747,                 loss: 0.1963
Episode: 7661/30000 (25.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6357s / 462.0534 s
agent0:                 episode reward: -1.3491,                 loss: nan
agent1:                 episode reward: 1.3491,                 loss: 0.1971
Episode: 7681/30000 (25.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6445s / 463.6979 s
agent0:                 episode reward: -1.6294,                 loss: nan
agent1:                 episode reward: 1.6294,                 loss: 0.1772
Episode: 7701/30000 (25.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7376s / 465.4355 s
agent0:                 episode reward: -0.9175,                 loss: nan
agent1:                 episode reward: 0.9175,                 loss: 0.1721
Episode: 7721/30000 (25.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7098s / 467.1453 s
agent0:                 episode reward: -1.4272,                 loss: nan
agent1:                 episode reward: 1.4272,                 loss: 0.1746
Episode: 7741/30000 (25.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6781s / 468.8234 s
agent0:                 episode reward: -1.0262,                 loss: nan
agent1:                 episode reward: 1.0262,                 loss: 0.1731
Episode: 7761/30000 (25.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6417s / 470.4651 s
agent0:                 episode reward: -1.0934,                 loss: nan
agent1:                 episode reward: 1.0934,                 loss: 0.1722
Episode: 7781/30000 (25.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6587s / 472.1238 s
agent0:                 episode reward: -0.9114,                 loss: nan
agent1:                 episode reward: 0.9114,                 loss: 0.1997
Episode: 7801/30000 (26.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7083s / 473.8321 s
agent0:                 episode reward: -0.9505,                 loss: nan
agent1:                 episode reward: 0.9505,                 loss: 0.2036
Episode: 7821/30000 (26.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7169s / 475.5491 s
agent0:                 episode reward: -0.8801,                 loss: nan
agent1:                 episode reward: 0.8801,                 loss: 0.2031
Episode: 7841/30000 (26.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6464s / 477.1955 s
agent0:                 episode reward: -1.4091,                 loss: nan
agent1:                 episode reward: 1.4091,                 loss: 0.2048
Episode: 7861/30000 (26.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6740s / 478.8695 s
agent0:                 episode reward: -1.7729,                 loss: nan
agent1:                 episode reward: 1.7729,                 loss: 0.2023
Episode: 7881/30000 (26.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6874s / 480.5569 s
agent0:                 episode reward: -1.6699,                 loss: nan
agent1:                 episode reward: 1.6699,                 loss: 0.2035
Episode: 7901/30000 (26.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6590s / 482.2159 s
agent0:                 episode reward: -1.6496,                 loss: nan
agent1:                 episode reward: 1.6496,                 loss: 0.2026
Episode: 7921/30000 (26.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7039s / 483.9198 s
agent0:                 episode reward: -1.7039,                 loss: nan
agent1:                 episode reward: 1.7039,                 loss: 0.2023
Episode: 7941/30000 (26.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7380s / 485.6578 s
agent0:                 episode reward: -0.9635,                 loss: nan
agent1:                 episode reward: 0.9635,                 loss: 0.2028
Episode: 7961/30000 (26.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6845s / 487.3423 s
agent0:                 episode reward: -1.1938,                 loss: nan
agent1:                 episode reward: 1.1938,                 loss: 0.2017
Episode: 7981/30000 (26.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6895s / 489.0318 s
agent0:                 episode reward: -1.5436,                 loss: nan
agent1:                 episode reward: 1.5436,                 loss: 0.2021
Episode: 8001/30000 (26.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6727s / 490.7045 s
agent0:                 episode reward: -1.7111,                 loss: nan
agent1:                 episode reward: 1.7111,                 loss: 0.2007
Episode: 8021/30000 (26.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6847s / 492.3892 s
agent0:                 episode reward: -1.0687,                 loss: nan
agent1:                 episode reward: 1.0687,                 loss: 0.2009
Episode: 8041/30000 (26.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7006s / 494.0898 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.2010
Episode: 8061/30000 (26.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7446s / 495.8344 s
agent0:                 episode reward: -0.7680,                 loss: nan
agent1:                 episode reward: 0.7680,                 loss: 0.2020
Episode: 8081/30000 (26.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6978s / 497.5322 s
agent0:                 episode reward: -0.9519,                 loss: nan
agent1:                 episode reward: 0.9519,                 loss: 0.2211
Episode: 8101/30000 (27.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7128s / 499.2450 s
agent0:                 episode reward: -1.6105,                 loss: nan
agent1:                 episode reward: 1.6105,                 loss: 0.2222
Episode: 8121/30000 (27.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6891s / 500.9341 s
agent0:                 episode reward: -1.5751,                 loss: nan
agent1:                 episode reward: 1.5751,                 loss: 0.2214
Episode: 8141/30000 (27.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7007s / 502.6348 s
agent0:                 episode reward: -0.9816,                 loss: nan
agent1:                 episode reward: 0.9816,                 loss: 0.2239
Episode: 8161/30000 (27.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7324s / 504.3672 s
agent0:                 episode reward: -0.9847,                 loss: nan
agent1:                 episode reward: 0.9847,                 loss: 0.2214
Episode: 8181/30000 (27.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7487s / 506.1159 s
agent0:                 episode reward: -1.2948,                 loss: nan
agent1:                 episode reward: 1.2948,                 loss: 0.2005
Episode: 8201/30000 (27.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7115s / 507.8274 s
agent0:                 episode reward: -1.0069,                 loss: nan
agent1:                 episode reward: 1.0069,                 loss: 0.1945
Episode: 8221/30000 (27.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7065s / 509.5339 s
agent0:                 episode reward: -1.3104,                 loss: nan
agent1:                 episode reward: 1.3104,                 loss: 0.1986
Episode: 8241/30000 (27.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7444s / 511.2783 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.1957
Episode: 8261/30000 (27.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7285s / 513.0068 s
agent0:                 episode reward: -1.0222,                 loss: nan
agent1:                 episode reward: 1.0222,                 loss: 0.1947
Episode: 8281/30000 (27.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7356s / 514.7425 s
agent0:                 episode reward: -1.3454,                 loss: nan
agent1:                 episode reward: 1.3454,                 loss: 0.1558
Episode: 8301/30000 (27.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7822s / 516.5247 s
agent0:                 episode reward: -1.3391,                 loss: nan
agent1:                 episode reward: 1.3391,                 loss: 0.1491
Episode: 8321/30000 (27.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7312s / 518.2559 s
agent0:                 episode reward: -1.7100,                 loss: nan
agent1:                 episode reward: 1.7100,                 loss: 0.1485
Episode: 8341/30000 (27.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7347s / 519.9906 s
agent0:                 episode reward: -1.0811,                 loss: nan
agent1:                 episode reward: 1.0811,                 loss: 0.1483
Episode: 8361/30000 (27.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7220s / 521.7126 s
agent0:                 episode reward: -1.2265,                 loss: nan
agent1:                 episode reward: 1.2265,                 loss: 0.1470
Episode: 8381/30000 (27.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7605s / 523.4731 s
agent0:                 episode reward: -0.6743,                 loss: nan
agent1:                 episode reward: 0.6743,                 loss: 0.1570
Episode: 8401/30000 (28.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7433s / 525.2163 s
agent0:                 episode reward: -1.2196,                 loss: nan
agent1:                 episode reward: 1.2196,                 loss: 0.1553
Episode: 8421/30000 (28.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7822s / 526.9985 s
agent0:                 episode reward: -0.5398,                 loss: nan
agent1:                 episode reward: 0.5398,                 loss: 0.1566
Episode: 8441/30000 (28.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7742s / 528.7727 s
agent0:                 episode reward: -1.6692,                 loss: nan
agent1:                 episode reward: 1.6692,                 loss: 0.1548
Episode: 8461/30000 (28.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7708s / 530.5435 s
agent0:                 episode reward: -1.2856,                 loss: nan
agent1:                 episode reward: 1.2856,                 loss: 0.1562
Episode: 8481/30000 (28.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7747s / 532.3182 s
agent0:                 episode reward: -1.0240,                 loss: nan
agent1:                 episode reward: 1.0240,                 loss: 0.1662
Episode: 8501/30000 (28.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7385s / 534.0567 s
agent0:                 episode reward: -1.5144,                 loss: nan
agent1:                 episode reward: 1.5144,                 loss: 0.1672
Episode: 8521/30000 (28.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7793s / 535.8360 s
agent0:                 episode reward: -1.5977,                 loss: nan
agent1:                 episode reward: 1.5977,                 loss: 0.1669
Episode: 8541/30000 (28.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8035s / 537.6395 s
agent0:                 episode reward: -1.1676,                 loss: nan
agent1:                 episode reward: 1.1676,                 loss: 0.1662
Episode: 8561/30000 (28.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8094s / 539.4489 s
agent0:                 episode reward: -1.4977,                 loss: nan
agent1:                 episode reward: 1.4977,                 loss: 0.1662
Episode: 8581/30000 (28.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8324s / 541.2813 s
agent0:                 episode reward: -1.7845,                 loss: nan
agent1:                 episode reward: 1.7845,                 loss: 0.1932
Episode: 8601/30000 (28.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7656s / 543.0469 s
agent0:                 episode reward: -1.1908,                 loss: nan
agent1:                 episode reward: 1.1908,                 loss: 0.1969
Episode: 8621/30000 (28.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7842s / 544.8311 s
agent0:                 episode reward: -1.0377,                 loss: nan
agent1:                 episode reward: 1.0377,                 loss: 0.1947
Episode: 8641/30000 (28.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8572s / 546.6883 s
agent0:                 episode reward: -1.5505,                 loss: nan
agent1:                 episode reward: 1.5505,                 loss: 0.1961
Episode: 8661/30000 (28.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7950s / 548.4834 s
agent0:                 episode reward: -1.6655,                 loss: nan
agent1:                 episode reward: 1.6655,                 loss: 0.1947
Episode: 8681/30000 (28.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7885s / 550.2718 s
agent0:                 episode reward: -0.7497,                 loss: nan
agent1:                 episode reward: 0.7497,                 loss: 0.2400
Episode: 8701/30000 (29.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7847s / 552.0565 s
agent0:                 episode reward: -1.4519,                 loss: nan
agent1:                 episode reward: 1.4519,                 loss: 0.2440
Episode: 8721/30000 (29.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8092s / 553.8657 s
agent0:                 episode reward: -1.7066,                 loss: nan
agent1:                 episode reward: 1.7066,                 loss: 0.2432
Episode: 8741/30000 (29.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8247s / 555.6903 s
agent0:                 episode reward: -1.3510,                 loss: nan
agent1:                 episode reward: 1.3510,                 loss: 0.2429
Episode: 8761/30000 (29.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8837s / 557.5741 s
agent0:                 episode reward: -1.1864,                 loss: nan
agent1:                 episode reward: 1.1864,                 loss: 0.2411
Episode: 8781/30000 (29.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8325s / 559.4066 s
agent0:                 episode reward: -1.5025,                 loss: nan
agent1:                 episode reward: 1.5025,                 loss: 0.2775
Episode: 8801/30000 (29.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8666s / 561.2731 s
agent0:                 episode reward: -1.6069,                 loss: nan
agent1:                 episode reward: 1.6069,                 loss: 0.2807
Episode: 8821/30000 (29.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8183s / 563.0914 s
agent0:                 episode reward: -1.1320,                 loss: nan
agent1:                 episode reward: 1.1320,                 loss: 0.2788
Episode: 8841/30000 (29.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8468s / 564.9382 s
agent0:                 episode reward: -1.6010,                 loss: nan
agent1:                 episode reward: 1.6010,                 loss: 0.2781
Episode: 8861/30000 (29.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8962s / 566.8344 s
agent0:                 episode reward: -1.4594,                 loss: nan
agent1:                 episode reward: 1.4594,                 loss: 0.2797
Episode: 8881/30000 (29.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8642s / 568.6986 s
agent0:                 episode reward: -1.0502,                 loss: nan
agent1:                 episode reward: 1.0502,                 loss: 0.2955
Episode: 8901/30000 (29.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8820s / 570.5806 s
agent0:                 episode reward: -1.5412,                 loss: nan
agent1:                 episode reward: 1.5412,                 loss: 0.2912
Episode: 8921/30000 (29.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8561s / 572.4367 s
agent0:                 episode reward: -1.2288,                 loss: nan
agent1:                 episode reward: 1.2288,                 loss: 0.2877
Episode: 8941/30000 (29.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8564s / 574.2932 s
agent0:                 episode reward: -0.9427,                 loss: nan
agent1:                 episode reward: 0.9427,                 loss: 0.2901
Episode: 8961/30000 (29.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8541s / 576.1473 s
agent0:                 episode reward: -1.3875,                 loss: nan
agent1:                 episode reward: 1.3875,                 loss: 0.2886
Episode: 8981/30000 (29.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8921s / 578.0394 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: 0.2174
Episode: 9001/30000 (30.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8779s / 579.9173 s
agent0:                 episode reward: -1.3377,                 loss: nan
agent1:                 episode reward: 1.3377,                 loss: 0.1928
Episode: 9021/30000 (30.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8510s / 581.7683 s
agent0:                 episode reward: -1.6684,                 loss: nan
agent1:                 episode reward: 1.6684,                 loss: 0.1928
Episode: 9041/30000 (30.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8675s / 583.6358 s
agent0:                 episode reward: -1.3353,                 loss: nan
agent1:                 episode reward: 1.3353,                 loss: 0.1933
Episode: 9061/30000 (30.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8488s / 585.4846 s
agent0:                 episode reward: -0.9515,                 loss: nan
agent1:                 episode reward: 0.9515,                 loss: 0.1906
Episode: 9081/30000 (30.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9027s / 587.3874 s
agent0:                 episode reward: -1.0701,                 loss: nan
agent1:                 episode reward: 1.0701,                 loss: 0.1341
Episode: 9101/30000 (30.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9258s / 589.3132 s
agent0:                 episode reward: -1.2270,                 loss: nan
agent1:                 episode reward: 1.2270,                 loss: 0.1104
Episode: 9121/30000 (30.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8740s / 591.1872 s
agent0:                 episode reward: -1.2776,                 loss: nan
agent1:                 episode reward: 1.2776,                 loss: 0.1113
Episode: 9141/30000 (30.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8753s / 593.0624 s
agent0:                 episode reward: -0.8756,                 loss: nan
agent1:                 episode reward: 0.8756,                 loss: 0.1111
Episode: 9161/30000 (30.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8833s / 594.9457 s
agent0:                 episode reward: -1.5154,                 loss: nan
agent1:                 episode reward: 1.5154,                 loss: 0.1110
Episode: 9181/30000 (30.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9236s / 596.8693 s
agent0:                 episode reward: -0.4989,                 loss: nan
agent1:                 episode reward: 0.4989,                 loss: 0.1166
Episode: 9201/30000 (30.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9206s / 598.7899 s
agent0:                 episode reward: -1.7204,                 loss: nan
agent1:                 episode reward: 1.7204,                 loss: 0.1111
Episode: 9221/30000 (30.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8941s / 600.6840 s
agent0:                 episode reward: -2.0188,                 loss: nan
agent1:                 episode reward: 2.0188,                 loss: 0.1111
Episode: 9241/30000 (30.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8965s / 602.5805 s
agent0:                 episode reward: -1.3350,                 loss: nan
agent1:                 episode reward: 1.3350,                 loss: 0.1113
Episode: 9261/30000 (30.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8863s / 604.4668 s
agent0:                 episode reward: -1.6553,                 loss: nan
agent1:                 episode reward: 1.6553,                 loss: 0.1117
Episode: 9281/30000 (30.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9210s / 606.3878 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: 0.1081
Episode: 9301/30000 (31.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9482s / 608.3359 s
agent0:                 episode reward: -1.4956,                 loss: nan
agent1:                 episode reward: 1.4956,                 loss: 0.1026
Episode: 9321/30000 (31.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9257s / 610.2616 s
agent0:                 episode reward: -1.5536,                 loss: nan
agent1:                 episode reward: 1.5536,                 loss: 0.1024
Episode: 9341/30000 (31.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9173s / 612.1789 s
agent0:                 episode reward: -1.2806,                 loss: nan
agent1:                 episode reward: 1.2806,                 loss: 0.1023
Episode: 9361/30000 (31.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9329s / 614.1118 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.1030
Episode: 9381/30000 (31.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9095s / 616.0213 s
agent0:                 episode reward: -1.0800,                 loss: nan
agent1:                 episode reward: 1.0800,                 loss: 0.1307
Episode: 9401/30000 (31.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9634s / 617.9847 s
agent0:                 episode reward: -1.2637,                 loss: nan
agent1:                 episode reward: 1.2637,                 loss: 0.1341
Episode: 9421/30000 (31.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9086s / 619.8933 s
agent0:                 episode reward: -2.0329,                 loss: nan
agent1:                 episode reward: 2.0329,                 loss: 0.1353
Episode: 9441/30000 (31.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9144s / 621.8076 s
agent0:                 episode reward: -1.5914,                 loss: nan
agent1:                 episode reward: 1.5914,                 loss: 0.1336
Episode: 9461/30000 (31.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9228s / 623.7304 s
agent0:                 episode reward: -1.3628,                 loss: nan
agent1:                 episode reward: 1.3628,                 loss: 0.1348
Episode: 9481/30000 (31.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9157s / 625.6462 s
agent0:                 episode reward: -1.4331,                 loss: nan
agent1:                 episode reward: 1.4331,                 loss: 0.1762
Episode: 9501/30000 (31.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9261s / 627.5722 s
agent0:                 episode reward: -1.7360,                 loss: nan
agent1:                 episode reward: 1.7360,                 loss: 0.1811
Episode: 9521/30000 (31.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9921s / 629.5643 s
agent0:                 episode reward: -1.5254,                 loss: nan
agent1:                 episode reward: 1.5254,                 loss: 0.1817
Episode: 9541/30000 (31.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9664s / 631.5307 s
agent0:                 episode reward: -1.3348,                 loss: nan
agent1:                 episode reward: 1.3348,                 loss: 0.1789
Episode: 9561/30000 (31.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9401s / 633.4708 s
agent0:                 episode reward: -1.3782,                 loss: nan
agent1:                 episode reward: 1.3782,                 loss: 0.1788
Episode: 9581/30000 (31.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9528s / 635.4236 s
agent0:                 episode reward: -1.4997,                 loss: nan
agent1:                 episode reward: 1.4997,                 loss: 0.2134
Episode: 9601/30000 (32.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9503s / 637.3739 s
agent0:                 episode reward: -1.3553,                 loss: nan
agent1:                 episode reward: 1.3553,                 loss: 0.2185
Episode: 9621/30000 (32.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0147s / 639.3887 s
agent0:                 episode reward: -1.1418,                 loss: nan
agent1:                 episode reward: 1.1418,                 loss: 0.2164
Episode: 9641/30000 (32.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9715s / 641.3601 s
agent0:                 episode reward: -1.0168,                 loss: nan
agent1:                 episode reward: 1.0168,                 loss: 0.2175
Episode: 9661/30000 (32.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9480s / 643.3081 s
agent0:                 episode reward: -0.6267,                 loss: nan
agent1:                 episode reward: 0.6267,                 loss: 0.2152
Episode: 9681/30000 (32.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9883s / 645.2964 s
agent0:                 episode reward: -1.0325,                 loss: nan
agent1:                 episode reward: 1.0325,                 loss: 0.2555
Episode: 9701/30000 (32.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9814s / 647.2779 s
agent0:                 episode reward: -1.2451,                 loss: nan
agent1:                 episode reward: 1.2451,                 loss: 0.2593
Episode: 9721/30000 (32.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0578s / 649.3356 s
agent0:                 episode reward: -0.7939,                 loss: nan
agent1:                 episode reward: 0.7939,                 loss: 0.2579
Episode: 9741/30000 (32.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9706s / 651.3062 s
agent0:                 episode reward: -1.1743,                 loss: nan
agent1:                 episode reward: 1.1743,                 loss: 0.2594
Episode: 9761/30000 (32.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9371s / 653.2433 s
agent0:                 episode reward: -1.7883,                 loss: nan
agent1:                 episode reward: 1.7883,                 loss: 0.2582
Episode: 9781/30000 (32.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0416s / 655.2849 s
agent0:                 episode reward: -0.8073,                 loss: nan
agent1:                 episode reward: 0.8073,                 loss: 0.3065
Episode: 9801/30000 (32.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9685s / 657.2534 s
agent0:                 episode reward: -1.8979,                 loss: nan
agent1:                 episode reward: 1.8979,                 loss: 0.3108
Episode: 9821/30000 (32.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0355s / 659.2889 s
agent0:                 episode reward: -1.2293,                 loss: nan
agent1:                 episode reward: 1.2293,                 loss: 0.3107
Episode: 9841/30000 (32.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9991s / 661.2879 s
agent0:                 episode reward: -1.5795,                 loss: nan
agent1:                 episode reward: 1.5795,                 loss: 0.3087
Episode: 9861/30000 (32.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9669s / 663.2549 s
agent0:                 episode reward: -1.1618,                 loss: nan
agent1:                 episode reward: 1.1618,                 loss: 0.3060
Episode: 9881/30000 (32.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9509s / 665.2057 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.2573
Episode: 9901/30000 (33.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9574s / 667.1631 s
agent0:                 episode reward: -1.6825,                 loss: nan
agent1:                 episode reward: 1.6825,                 loss: 0.2389
Episode: 9921/30000 (33.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9938s / 669.1569 s
agent0:                 episode reward: -1.4422,                 loss: nan
agent1:                 episode reward: 1.4422,                 loss: 0.2399
Episode: 9941/30000 (33.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9828s / 671.1397 s
agent0:                 episode reward: -0.8942,                 loss: nan
agent1:                 episode reward: 0.8942,                 loss: 0.2404
Episode: 9961/30000 (33.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9788s / 673.1185 s
agent0:                 episode reward: -1.4750,                 loss: nan
agent1:                 episode reward: 1.4750,                 loss: 0.2403
Episode: 9981/30000 (33.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9458s / 675.0642 s
agent0:                 episode reward: -1.0297,                 loss: nan
agent1:                 episode reward: 1.0297,                 loss: 0.1664
Episode: 10001/30000 (33.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9672s / 677.0314 s
agent0:                 episode reward: -1.4349,                 loss: nan
agent1:                 episode reward: 1.4349,                 loss: 0.1465
Episode: 10021/30000 (33.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9758s / 679.0073 s
agent0:                 episode reward: -1.0969,                 loss: nan
agent1:                 episode reward: 1.0969,                 loss: 0.1447
Episode: 10041/30000 (33.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0235s / 681.0308 s
agent0:                 episode reward: -0.8828,                 loss: nan
agent1:                 episode reward: 0.8828,                 loss: 0.1448
Episode: 10061/30000 (33.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9757s / 683.0065 s
agent0:                 episode reward: -0.8612,                 loss: nan
agent1:                 episode reward: 0.8612,                 loss: 0.1441
Episode: 10081/30000 (33.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9762s / 684.9827 s
agent0:                 episode reward: -1.5693,                 loss: nan
agent1:                 episode reward: 1.5693,                 loss: 0.1277
Episode: 10101/30000 (33.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9593s / 686.9420 s
agent0:                 episode reward: -1.4945,                 loss: nan
agent1:                 episode reward: 1.4945,                 loss: 0.1198
Episode: 10121/30000 (33.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9982s / 688.9402 s
agent0:                 episode reward: -1.8898,                 loss: nan
agent1:                 episode reward: 1.8898,                 loss: 0.1201
Episode: 10141/30000 (33.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0901s / 691.0303 s
agent0:                 episode reward: -0.6281,                 loss: nan
agent1:                 episode reward: 0.6281,                 loss: 0.1209
Episode: 10161/30000 (33.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0011s / 693.0314 s
agent0:                 episode reward: -1.2874,                 loss: nan
agent1:                 episode reward: 1.2874,                 loss: 0.1213
Episode: 10181/30000 (33.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9890s / 695.0204 s
agent0:                 episode reward: -1.1851,                 loss: nan
agent1:                 episode reward: 1.1851,                 loss: 0.1115
Episode: 10201/30000 (34.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0110s / 697.0314 s
agent0:                 episode reward: -0.7966,                 loss: nan
agent1:                 episode reward: 0.7966,                 loss: 0.1070
Episode: 10221/30000 (34.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9716s / 699.0030 s
agent0:                 episode reward: -1.2422,                 loss: nan
agent1:                 episode reward: 1.2422,                 loss: 0.1061
Episode: 10241/30000 (34.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0307s / 701.0337 s
agent0:                 episode reward: -0.9896,                 loss: nan
agent1:                 episode reward: 0.9896,                 loss: 0.1046
Episode: 10261/30000 (34.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0233s / 703.0570 s
agent0:                 episode reward: -1.3593,                 loss: nan
agent1:                 episode reward: 1.3593,                 loss: 0.1056
Episode: 10281/30000 (34.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9706s / 705.0276 s
agent0:                 episode reward: -1.5643,                 loss: nan
agent1:                 episode reward: 1.5643,                 loss: 0.1305
Episode: 10301/30000 (34.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0283s / 707.0559 s
agent0:                 episode reward: -1.7374,                 loss: nan
agent1:                 episode reward: 1.7374,                 loss: 0.1353
Episode: 10321/30000 (34.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0434s / 709.0992 s
agent0:                 episode reward: -0.8470,                 loss: nan
agent1:                 episode reward: 0.8470,                 loss: 0.1356
Episode: 10341/30000 (34.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0671s / 711.1664 s
agent0:                 episode reward: -1.0300,                 loss: nan
agent1:                 episode reward: 1.0300,                 loss: 0.1345
Episode: 10361/30000 (34.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0523s / 713.2187 s
agent0:                 episode reward: -1.7070,                 loss: nan
agent1:                 episode reward: 1.7070,                 loss: 0.1354
Episode: 10381/30000 (34.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0378s / 715.2565 s
agent0:                 episode reward: -1.4155,                 loss: nan
agent1:                 episode reward: 1.4155,                 loss: 0.1735
Episode: 10401/30000 (34.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9930s / 717.2495 s
agent0:                 episode reward: -1.0368,                 loss: nan
agent1:                 episode reward: 1.0368,                 loss: 0.1785
Episode: 10421/30000 (34.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0712s / 719.3207 s
agent0:                 episode reward: -1.0860,                 loss: nan
agent1:                 episode reward: 1.0860,                 loss: 0.1786
Episode: 10441/30000 (34.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0640s / 721.3847 s
agent0:                 episode reward: -1.1772,                 loss: nan
agent1:                 episode reward: 1.1772,                 loss: 0.1774
Episode: 10461/30000 (34.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0194s / 723.4041 s
agent0:                 episode reward: -1.0635,                 loss: nan
agent1:                 episode reward: 1.0635,                 loss: 0.1776
Episode: 10481/30000 (34.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0320s / 725.4361 s
agent0:                 episode reward: -1.2901,                 loss: nan
agent1:                 episode reward: 1.2901,                 loss: 0.2246
Episode: 10501/30000 (35.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0443s / 727.4804 s
agent0:                 episode reward: -1.2632,                 loss: nan
agent1:                 episode reward: 1.2632,                 loss: 0.2310
Episode: 10521/30000 (35.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0243s / 729.5047 s
agent0:                 episode reward: -0.2568,                 loss: nan
agent1:                 episode reward: 0.2568,                 loss: 0.2309
Episode: 10541/30000 (35.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0663s / 731.5710 s
agent0:                 episode reward: -1.5997,                 loss: nan
agent1:                 episode reward: 1.5997,                 loss: 0.2309
Episode: 10561/30000 (35.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9877s / 733.5587 s
agent0:                 episode reward: -1.3024,                 loss: nan
agent1:                 episode reward: 1.3024,                 loss: 0.2318
Episode: 10581/30000 (35.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0171s / 735.5758 s
agent0:                 episode reward: -1.1892,                 loss: nan
agent1:                 episode reward: 1.1892,                 loss: 0.2714
Episode: 10601/30000 (35.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0682s / 737.6440 s
agent0:                 episode reward: -1.0352,                 loss: nan
agent1:                 episode reward: 1.0352,                 loss: 0.2756
Episode: 10621/30000 (35.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0203s / 739.6643 s
agent0:                 episode reward: -0.9461,                 loss: nan
agent1:                 episode reward: 0.9461,                 loss: 0.2761
Episode: 10641/30000 (35.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0666s / 741.7309 s
agent0:                 episode reward: -1.1726,                 loss: nan
agent1:                 episode reward: 1.1726,                 loss: 0.2763
Episode: 10661/30000 (35.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0490s / 743.7799 s
agent0:                 episode reward: -1.4451,                 loss: nan
agent1:                 episode reward: 1.4451,                 loss: 0.2748
Episode: 10681/30000 (35.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0867s / 745.8666 s
agent0:                 episode reward: -1.3599,                 loss: nan
agent1:                 episode reward: 1.3599,                 loss: 0.3114
Episode: 10701/30000 (35.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0018s / 747.8684 s
agent0:                 episode reward: -1.7231,                 loss: nan
agent1:                 episode reward: 1.7231,                 loss: 0.3130
Episode: 10721/30000 (35.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9850s / 749.8534 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.3123
Episode: 10741/30000 (35.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0623s / 751.9157 s
agent0:                 episode reward: -1.4348,                 loss: nan
agent1:                 episode reward: 1.4348,                 loss: 0.3122
Episode: 10761/30000 (35.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0504s / 753.9661 s
agent0:                 episode reward: -1.6862,                 loss: nan
agent1:                 episode reward: 1.6862,                 loss: 0.3136
Episode: 10781/30000 (35.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9824s / 755.9485 s
agent0:                 episode reward: -1.4532,                 loss: nan
agent1:                 episode reward: 1.4532,                 loss: 0.2386
Episode: 10801/30000 (36.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9933s / 757.9418 s
agent0:                 episode reward: -1.3242,                 loss: nan
agent1:                 episode reward: 1.3242,                 loss: 0.2211
Episode: 10821/30000 (36.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0016s / 759.9434 s
agent0:                 episode reward: -1.0726,                 loss: nan
agent1:                 episode reward: 1.0726,                 loss: 0.2202
Episode: 10841/30000 (36.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0549s / 761.9982 s
agent0:                 episode reward: -0.9729,                 loss: nan
agent1:                 episode reward: 0.9729,                 loss: 0.2225
Episode: 10861/30000 (36.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0211s / 764.0193 s
agent0:                 episode reward: -1.3571,                 loss: nan
agent1:                 episode reward: 1.3571,                 loss: 0.2235
Episode: 10881/30000 (36.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0248s / 766.0441 s
agent0:                 episode reward: -1.1875,                 loss: nan
agent1:                 episode reward: 1.1875,                 loss: 0.1484
Episode: 10901/30000 (36.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9722s / 768.0163 s
agent0:                 episode reward: -1.2153,                 loss: nan
agent1:                 episode reward: 1.2153,                 loss: 0.1327
Episode: 10921/30000 (36.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9815s / 769.9978 s
agent0:                 episode reward: -1.4758,                 loss: nan
agent1:                 episode reward: 1.4758,                 loss: 0.1321
Episode: 10941/30000 (36.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0642s / 772.0620 s
agent0:                 episode reward: -1.3325,                 loss: nan
agent1:                 episode reward: 1.3325,                 loss: 0.1308
Episode: 10961/30000 (36.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0073s / 774.0693 s
agent0:                 episode reward: -1.6164,                 loss: nan
agent1:                 episode reward: 1.6164,                 loss: 0.1315
Episode: 10981/30000 (36.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0252s / 776.0944 s
agent0:                 episode reward: -1.1215,                 loss: nan
agent1:                 episode reward: 1.1215,                 loss: 0.1103
Episode: 11001/30000 (36.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9980s / 778.0924 s
agent0:                 episode reward: -1.0284,                 loss: nan
agent1:                 episode reward: 1.0284,                 loss: 0.1020
Episode: 11021/30000 (36.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0075s / 780.1000 s
agent0:                 episode reward: -1.8029,                 loss: nan
agent1:                 episode reward: 1.8029,                 loss: 0.1027
Episode: 11041/30000 (36.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0677s / 782.1677 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.1020
Episode: 11061/30000 (36.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9868s / 784.1545 s
agent0:                 episode reward: -1.2583,                 loss: nan
agent1:                 episode reward: 1.2583,                 loss: 0.1022
Episode: 11081/30000 (36.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0072s / 786.1617 s
agent0:                 episode reward: -0.7707,                 loss: nan
agent1:                 episode reward: 0.7707,                 loss: 0.1076
Episode: 11101/30000 (37.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0080s / 788.1696 s
agent0:                 episode reward: -2.0151,                 loss: nan
agent1:                 episode reward: 2.0151,                 loss: 0.1085
Episode: 11121/30000 (37.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0298s / 790.1994 s
agent0:                 episode reward: -1.6852,                 loss: nan
agent1:                 episode reward: 1.6852,                 loss: 0.1071
Episode: 11141/30000 (37.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0562s / 792.2556 s
agent0:                 episode reward: -1.3080,                 loss: nan
agent1:                 episode reward: 1.3080,                 loss: 0.1070
Episode: 11161/30000 (37.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0143s / 794.2699 s
agent0:                 episode reward: -1.5761,                 loss: nan
agent1:                 episode reward: 1.5761,                 loss: 0.1069
Episode: 11181/30000 (37.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0002s / 796.2702 s
agent0:                 episode reward: -0.8473,                 loss: nan
agent1:                 episode reward: 0.8473,                 loss: 0.1501
Episode: 11201/30000 (37.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9851s / 798.2553 s
agent0:                 episode reward: -1.7929,                 loss: nan
agent1:                 episode reward: 1.7929,                 loss: 0.1546
Episode: 11221/30000 (37.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0405s / 800.2958 s
agent0:                 episode reward: -1.4598,                 loss: nan
agent1:                 episode reward: 1.4598,                 loss: 0.1554
Episode: 11241/30000 (37.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0423s / 802.3381 s
agent0:                 episode reward: -0.8638,                 loss: nan
agent1:                 episode reward: 0.8638,                 loss: 0.1560
Episode: 11261/30000 (37.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0372s / 804.3753 s
agent0:                 episode reward: -1.5074,                 loss: nan
agent1:                 episode reward: 1.5074,                 loss: 0.1555
Episode: 11281/30000 (37.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0149s / 806.3902 s
agent0:                 episode reward: -1.1117,                 loss: nan
agent1:                 episode reward: 1.1117,                 loss: 0.1775
Episode: 11301/30000 (37.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0256s / 808.4158 s
agent0:                 episode reward: -1.5404,                 loss: nan
agent1:                 episode reward: 1.5404,                 loss: 0.1810
Episode: 11321/30000 (37.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9873s / 810.4031 s
agent0:                 episode reward: -1.5424,                 loss: nan
agent1:                 episode reward: 1.5424,                 loss: 0.1812
Episode: 11341/30000 (37.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0766s / 812.4797 s
agent0:                 episode reward: -1.6734,                 loss: nan
agent1:                 episode reward: 1.6734,                 loss: 0.1796
Episode: 11361/30000 (37.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9840s / 814.4636 s
agent0:                 episode reward: -0.7852,                 loss: nan
agent1:                 episode reward: 0.7852,                 loss: 0.1809
Episode: 11381/30000 (37.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9922s / 816.4558 s
agent0:                 episode reward: -1.4963,                 loss: nan
agent1:                 episode reward: 1.4963,                 loss: 0.2361
Episode: 11401/30000 (38.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0428s / 818.4986 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.2428
Episode: 11421/30000 (38.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0072s / 820.5058 s
agent0:                 episode reward: -1.0327,                 loss: nan
agent1:                 episode reward: 1.0327,                 loss: 0.2416
Episode: 11441/30000 (38.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0458s / 822.5516 s
agent0:                 episode reward: -1.5143,                 loss: nan
agent1:                 episode reward: 1.5143,                 loss: 0.2424
Episode: 11461/30000 (38.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0361s / 824.5877 s
agent0:                 episode reward: -1.1539,                 loss: nan
agent1:                 episode reward: 1.1539,                 loss: 0.2414
Episode: 11481/30000 (38.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9891s / 826.5768 s
agent0:                 episode reward: -1.4613,                 loss: nan
agent1:                 episode reward: 1.4613,                 loss: 0.2816
Episode: 11501/30000 (38.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9627s / 828.5395 s
agent0:                 episode reward: -0.9301,                 loss: nan
agent1:                 episode reward: 0.9301,                 loss: 0.2845
Episode: 11521/30000 (38.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0158s / 830.5554 s
agent0:                 episode reward: -1.2972,                 loss: nan
agent1:                 episode reward: 1.2972,                 loss: 0.2843
Episode: 11541/30000 (38.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9930s / 832.5483 s
agent0:                 episode reward: -1.4725,                 loss: nan
agent1:                 episode reward: 1.4725,                 loss: 0.2847
Episode: 11561/30000 (38.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0352s / 834.5835 s
agent0:                 episode reward: -0.7805,                 loss: nan
agent1:                 episode reward: 0.7805,                 loss: 0.2841
Episode: 11581/30000 (38.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0179s / 836.6014 s
agent0:                 episode reward: -1.5922,                 loss: nan
agent1:                 episode reward: 1.5922,                 loss: 0.2750
Episode: 11601/30000 (38.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0519s / 838.6533 s
agent0:                 episode reward: -1.1888,                 loss: nan
agent1:                 episode reward: 1.1888,                 loss: 0.2704
Episode: 11621/30000 (38.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9966s / 840.6499 s
agent0:                 episode reward: -0.9563,                 loss: nan
agent1:                 episode reward: 0.9563,                 loss: 0.2695
Episode: 11641/30000 (38.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0082s / 842.6581 s
agent0:                 episode reward: -1.3732,                 loss: nan
agent1:                 episode reward: 1.3732,                 loss: 0.2691
Episode: 11661/30000 (38.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0563s / 844.7144 s
agent0:                 episode reward: -0.9596,                 loss: nan
agent1:                 episode reward: 0.9596,                 loss: 0.2674
Episode: 11681/30000 (38.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0236s / 846.7380 s
agent0:                 episode reward: -1.5675,                 loss: nan
agent1:                 episode reward: 1.5675,                 loss: 0.2792
Episode: 11701/30000 (39.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0051s / 848.7431 s
agent0:                 episode reward: -1.3765,                 loss: nan
agent1:                 episode reward: 1.3765,                 loss: 0.2758
Episode: 11721/30000 (39.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9920s / 850.7351 s
agent0:                 episode reward: -1.3394,                 loss: nan
agent1:                 episode reward: 1.3394,                 loss: 0.2735
Episode: 11741/30000 (39.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9808s / 852.7159 s
agent0:                 episode reward: -1.2331,                 loss: nan
agent1:                 episode reward: 1.2331,                 loss: 0.2738
Episode: 11761/30000 (39.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0868s / 854.8027 s
agent0:                 episode reward: -1.0929,                 loss: nan
agent1:                 episode reward: 1.0929,                 loss: 0.2748
Episode: 11781/30000 (39.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9777s / 856.7804 s
agent0:                 episode reward: -1.8568,                 loss: nan
agent1:                 episode reward: 1.8568,                 loss: 0.1839
Episode: 11801/30000 (39.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9802s / 858.7606 s
agent0:                 episode reward: -1.5407,                 loss: nan
agent1:                 episode reward: 1.5407,                 loss: 0.1659
Episode: 11821/30000 (39.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9886s / 860.7492 s
agent0:                 episode reward: -1.6332,                 loss: nan
agent1:                 episode reward: 1.6332,                 loss: 0.1645
Episode: 11841/30000 (39.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0036s / 862.7528 s
agent0:                 episode reward: -1.4555,                 loss: nan
agent1:                 episode reward: 1.4555,                 loss: 0.1654
Episode: 11861/30000 (39.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0781s / 864.8309 s
agent0:                 episode reward: -0.9560,                 loss: nan
agent1:                 episode reward: 0.9560,                 loss: 0.1638
Episode: 11881/30000 (39.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0159s / 866.8467 s
agent0:                 episode reward: -1.8017,                 loss: nan
agent1:                 episode reward: 1.8017,                 loss: 0.1255
Episode: 11901/30000 (39.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9748s / 868.8216 s
agent0:                 episode reward: -1.8653,                 loss: nan
agent1:                 episode reward: 1.8653,                 loss: 0.1156
Episode: 11921/30000 (39.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0191s / 870.8407 s
agent0:                 episode reward: -1.2778,                 loss: nan
agent1:                 episode reward: 1.2778,                 loss: 0.1143
Episode: 11941/30000 (39.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9849s / 872.8255 s
agent0:                 episode reward: -2.0242,                 loss: nan
agent1:                 episode reward: 2.0242,                 loss: 0.1136
Episode: 11961/30000 (39.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0318s / 874.8573 s
agent0:                 episode reward: -1.4749,                 loss: nan
agent1:                 episode reward: 1.4749,                 loss: 0.1137
Episode: 11981/30000 (39.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9857s / 876.8430 s
agent0:                 episode reward: -1.8936,                 loss: nan
agent1:                 episode reward: 1.8936,                 loss: 0.1110
Episode: 12001/30000 (40.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0001s / 878.8431 s
agent0:                 episode reward: -0.8991,                 loss: nan
agent1:                 episode reward: 0.8991,                 loss: 0.1093
Episode: 12021/30000 (40.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0214s / 880.8645 s
agent0:                 episode reward: -1.7310,                 loss: nan
agent1:                 episode reward: 1.7310,                 loss: 0.1093
Episode: 12041/30000 (40.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0157s / 882.8802 s
agent0:                 episode reward: -1.1933,                 loss: nan
agent1:                 episode reward: 1.1933,                 loss: 0.1089
Episode: 12061/30000 (40.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0423s / 884.9226 s
agent0:                 episode reward: -1.6233,                 loss: nan
agent1:                 episode reward: 1.6233,                 loss: 0.1089
Episode: 12081/30000 (40.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0447s / 886.9672 s
agent0:                 episode reward: -2.4089,                 loss: nan
agent1:                 episode reward: 2.4089,                 loss: 0.1390
Episode: 12101/30000 (40.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9708s / 888.9380 s
agent0:                 episode reward: -1.3757,                 loss: nan
agent1:                 episode reward: 1.3757,                 loss: 0.1439
Episode: 12121/30000 (40.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9825s / 890.9205 s
agent0:                 episode reward: -1.1663,                 loss: nan
agent1:                 episode reward: 1.1663,                 loss: 0.1430
Episode: 12141/30000 (40.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0136s / 892.9342 s
agent0:                 episode reward: -1.7682,                 loss: nan
agent1:                 episode reward: 1.7682,                 loss: 0.1438
Episode: 12161/30000 (40.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1100s / 895.0441 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.1454
Episode: 12181/30000 (40.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9678s / 897.0119 s
agent0:                 episode reward: -1.5138,                 loss: nan
agent1:                 episode reward: 1.5138,                 loss: 0.1964
Episode: 12201/30000 (40.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9976s / 899.0095 s
agent0:                 episode reward: -0.9996,                 loss: nan
agent1:                 episode reward: 0.9996,                 loss: 0.2029
Episode: 12221/30000 (40.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9840s / 900.9935 s
agent0:                 episode reward: -1.1809,                 loss: nan
agent1:                 episode reward: 1.1809,                 loss: 0.2028
Episode: 12241/30000 (40.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9495s / 902.9431 s
agent0:                 episode reward: -1.0425,                 loss: nan
agent1:                 episode reward: 1.0425,                 loss: 0.2035
Episode: 12261/30000 (40.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0571s / 905.0002 s
agent0:                 episode reward: -1.2060,                 loss: nan
agent1:                 episode reward: 1.2060,                 loss: 0.2019
Episode: 12281/30000 (40.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0129s / 907.0131 s
agent0:                 episode reward: -0.6428,                 loss: nan
agent1:                 episode reward: 0.6428,                 loss: 0.2561
Episode: 12301/30000 (41.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0138s / 909.0269 s
agent0:                 episode reward: -0.9968,                 loss: nan
agent1:                 episode reward: 0.9968,                 loss: 0.2609
Episode: 12321/30000 (41.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0089s / 911.0358 s
agent0:                 episode reward: -1.6654,                 loss: nan
agent1:                 episode reward: 1.6654,                 loss: 0.2613
Episode: 12341/30000 (41.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0150s / 913.0509 s
agent0:                 episode reward: -1.0120,                 loss: nan
agent1:                 episode reward: 1.0120,                 loss: 0.2617
Episode: 12361/30000 (41.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0525s / 915.1034 s
agent0:                 episode reward: -1.2015,                 loss: nan
agent1:                 episode reward: 1.2015,                 loss: 0.2609
Episode: 12381/30000 (41.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0420s / 917.1454 s
agent0:                 episode reward: -1.1822,                 loss: nan
agent1:                 episode reward: 1.1822,                 loss: 0.2893
Episode: 12401/30000 (41.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0097s / 919.1552 s
agent0:                 episode reward: -1.2510,                 loss: nan
agent1:                 episode reward: 1.2510,                 loss: 0.2916
Episode: 12421/30000 (41.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0391s / 921.1943 s
agent0:                 episode reward: -1.4713,                 loss: nan
agent1:                 episode reward: 1.4713,                 loss: 0.2892
Episode: 12441/30000 (41.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9948s / 923.1891 s
agent0:                 episode reward: -1.4398,                 loss: nan
agent1:                 episode reward: 1.4398,                 loss: 0.2907
Episode: 12461/30000 (41.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0823s / 925.2713 s
agent0:                 episode reward: -0.7644,                 loss: nan
agent1:                 episode reward: 0.7644,                 loss: 0.2926
Episode: 12481/30000 (41.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9918s / 927.2631 s
agent0:                 episode reward: -0.9476,                 loss: nan
agent1:                 episode reward: 0.9476,                 loss: 0.3025
Episode: 12501/30000 (41.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0449s / 929.3081 s
agent0:                 episode reward: -1.4903,                 loss: nan
agent1:                 episode reward: 1.4903,                 loss: 0.2938
Episode: 12521/30000 (41.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0710s / 931.3790 s
agent0:                 episode reward: -1.3611,                 loss: nan
agent1:                 episode reward: 1.3611,                 loss: 0.2923
Episode: 12541/30000 (41.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9944s / 933.3735 s
agent0:                 episode reward: -1.2777,                 loss: nan
agent1:                 episode reward: 1.2777,                 loss: 0.2931
Episode: 12561/30000 (41.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0387s / 935.4121 s
agent0:                 episode reward: -1.6347,                 loss: nan
agent1:                 episode reward: 1.6347,                 loss: 0.2941
Episode: 12581/30000 (41.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0374s / 937.4495 s
agent0:                 episode reward: -1.1724,                 loss: nan
agent1:                 episode reward: 1.1724,                 loss: 0.2027
Episode: 12601/30000 (42.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0199s / 939.4694 s
agent0:                 episode reward: -1.4320,                 loss: nan
agent1:                 episode reward: 1.4320,                 loss: 0.1783
Episode: 12621/30000 (42.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9913s / 941.4607 s
agent0:                 episode reward: -0.9216,                 loss: nan
agent1:                 episode reward: 0.9216,                 loss: 0.1783
Episode: 12641/30000 (42.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9980s / 943.4587 s
agent0:                 episode reward: -1.5791,                 loss: nan
agent1:                 episode reward: 1.5791,                 loss: 0.1782
Episode: 12661/30000 (42.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0697s / 945.5284 s
agent0:                 episode reward: -0.9919,                 loss: nan
agent1:                 episode reward: 0.9919,                 loss: 0.1780
Episode: 12681/30000 (42.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9929s / 947.5213 s
agent0:                 episode reward: -1.4154,                 loss: nan
agent1:                 episode reward: 1.4154,                 loss: 0.1413
Episode: 12701/30000 (42.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0395s / 949.5608 s
agent0:                 episode reward: -1.4750,                 loss: nan
agent1:                 episode reward: 1.4750,                 loss: 0.1302
Episode: 12721/30000 (42.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0395s / 951.6003 s
agent0:                 episode reward: -1.1079,                 loss: nan
agent1:                 episode reward: 1.1079,                 loss: 0.1304
Episode: 12741/30000 (42.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0242s / 953.6245 s
agent0:                 episode reward: -1.1763,                 loss: nan
agent1:                 episode reward: 1.1763,                 loss: 0.1291
Episode: 12761/30000 (42.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0282s / 955.6526 s
agent0:                 episode reward: -1.7340,                 loss: nan
agent1:                 episode reward: 1.7340,                 loss: 0.1305
Episode: 12781/30000 (42.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0848s / 957.7374 s
agent0:                 episode reward: -1.2328,                 loss: nan
agent1:                 episode reward: 1.2328,                 loss: 0.1064
Episode: 12801/30000 (42.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9990s / 959.7364 s
agent0:                 episode reward: -1.5797,                 loss: nan
agent1:                 episode reward: 1.5797,                 loss: 0.0959
Episode: 12821/30000 (42.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0511s / 961.7875 s
agent0:                 episode reward: -1.1872,                 loss: nan
agent1:                 episode reward: 1.1872,                 loss: 0.0970
Episode: 12841/30000 (42.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0186s / 963.8060 s
agent0:                 episode reward: -1.2728,                 loss: nan
agent1:                 episode reward: 1.2728,                 loss: 0.0955
Episode: 12861/30000 (42.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9884s / 965.7944 s
agent0:                 episode reward: -1.8357,                 loss: nan
agent1:                 episode reward: 1.8357,                 loss: 0.0945
Episode: 12881/30000 (42.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1011s / 967.8955 s
agent0:                 episode reward: -0.9192,                 loss: nan
agent1:                 episode reward: 0.9192,                 loss: 0.1073
Episode: 12901/30000 (43.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0082s / 969.9037 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.1060
Episode: 12921/30000 (43.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0656s / 971.9693 s
agent0:                 episode reward: -0.7056,                 loss: nan
agent1:                 episode reward: 0.7056,                 loss: 0.1048
Episode: 12941/30000 (43.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9886s / 973.9579 s
agent0:                 episode reward: -1.1346,                 loss: nan
agent1:                 episode reward: 1.1346,                 loss: 0.1048
Episode: 12961/30000 (43.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0091s / 975.9670 s
agent0:                 episode reward: -1.3907,                 loss: nan
agent1:                 episode reward: 1.3907,                 loss: 0.1036
Episode: 12981/30000 (43.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1370s / 978.1040 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.1525
Episode: 13001/30000 (43.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9926s / 980.0965 s
agent0:                 episode reward: -0.6831,                 loss: nan
agent1:                 episode reward: 0.6831,                 loss: 0.1573
Episode: 13021/30000 (43.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9866s / 982.0831 s
agent0:                 episode reward: -1.4382,                 loss: nan
agent1:                 episode reward: 1.4382,                 loss: 0.1564
Episode: 13041/30000 (43.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0387s / 984.1219 s
agent0:                 episode reward: -1.2519,                 loss: nan
agent1:                 episode reward: 1.2519,                 loss: 0.1582
Episode: 13061/30000 (43.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0072s / 986.1291 s
agent0:                 episode reward: -1.2842,                 loss: nan
agent1:                 episode reward: 1.2842,                 loss: 0.1553
Episode: 13081/30000 (43.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0732s / 988.2023 s
agent0:                 episode reward: -1.5557,                 loss: nan
agent1:                 episode reward: 1.5557,                 loss: 0.1979
Episode: 13101/30000 (43.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9670s / 990.1693 s
agent0:                 episode reward: -1.0715,                 loss: nan
agent1:                 episode reward: 1.0715,                 loss: 0.2028
Episode: 13121/30000 (43.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9774s / 992.1467 s
agent0:                 episode reward: -1.4233,                 loss: nan
agent1:                 episode reward: 1.4233,                 loss: 0.2030
Episode: 13141/30000 (43.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0015s / 994.1482 s
agent0:                 episode reward: -0.8782,                 loss: nan
agent1:                 episode reward: 0.8782,                 loss: 0.2026
Episode: 13161/30000 (43.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0013s / 996.1495 s
agent0:                 episode reward: -1.4041,                 loss: nan
agent1:                 episode reward: 1.4041,                 loss: 0.2027
Episode: 13181/30000 (43.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0630s / 998.2125 s
agent0:                 episode reward: -1.4081,                 loss: nan
agent1:                 episode reward: 1.4081,                 loss: 0.2525
Episode: 13201/30000 (44.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0015s / 1000.2140 s
agent0:                 episode reward: -1.2682,                 loss: nan
agent1:                 episode reward: 1.2682,                 loss: 0.2562
Episode: 13221/30000 (44.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0156s / 1002.2296 s
agent0:                 episode reward: -1.1672,                 loss: nan
agent1:                 episode reward: 1.1672,                 loss: 0.2557
Episode: 13241/30000 (44.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9918s / 1004.2215 s
agent0:                 episode reward: -1.1500,                 loss: nan
agent1:                 episode reward: 1.1500,                 loss: 0.2535
Episode: 13261/30000 (44.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0147s / 1006.2362 s
agent0:                 episode reward: -1.3609,                 loss: nan
agent1:                 episode reward: 1.3609,                 loss: 0.2528
Episode: 13281/30000 (44.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0267s / 1008.2629 s
agent0:                 episode reward: -1.3471,                 loss: nan
agent1:                 episode reward: 1.3471,                 loss: 0.3087
Episode: 13301/30000 (44.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0400s / 1010.3029 s
agent0:                 episode reward: -1.0382,                 loss: nan
agent1:                 episode reward: 1.0382,                 loss: 0.3113
Episode: 13321/30000 (44.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0332s / 1012.3361 s
agent0:                 episode reward: -1.0862,                 loss: nan
agent1:                 episode reward: 1.0862,                 loss: 0.3129
Episode: 13341/30000 (44.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0043s / 1014.3404 s
agent0:                 episode reward: -1.4385,                 loss: nan
agent1:                 episode reward: 1.4385,                 loss: 0.3112
Episode: 13361/30000 (44.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0121s / 1016.3525 s
agent0:                 episode reward: -1.5907,                 loss: nan
agent1:                 episode reward: 1.5907,                 loss: 0.3091
Episode: 13381/30000 (44.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0730s / 1018.4255 s
agent0:                 episode reward: -1.4872,                 loss: nan
agent1:                 episode reward: 1.4872,                 loss: 0.2767
Episode: 13401/30000 (44.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0450s / 1020.4705 s
agent0:                 episode reward: -1.4696,                 loss: nan
agent1:                 episode reward: 1.4696,                 loss: 0.2666
Episode: 13421/30000 (44.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0120s / 1022.4824 s
agent0:                 episode reward: -1.2972,                 loss: nan
agent1:                 episode reward: 1.2972,                 loss: 0.2677
Episode: 13441/30000 (44.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0453s / 1024.5278 s
agent0:                 episode reward: -1.1169,                 loss: nan
agent1:                 episode reward: 1.1169,                 loss: 0.2668
Episode: 13461/30000 (44.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0195s / 1026.5473 s
agent0:                 episode reward: -1.5308,                 loss: nan
agent1:                 episode reward: 1.5308,                 loss: 0.2664
Episode: 13481/30000 (44.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0448s / 1028.5922 s
agent0:                 episode reward: -1.4252,                 loss: nan
agent1:                 episode reward: 1.4252,                 loss: 0.1934
Episode: 13501/30000 (45.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0838s / 1030.6760 s
agent0:                 episode reward: -2.0101,                 loss: nan
agent1:                 episode reward: 2.0101,                 loss: 0.1761
Episode: 13521/30000 (45.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9769s / 1032.6529 s
agent0:                 episode reward: -1.0629,                 loss: nan
agent1:                 episode reward: 1.0629,                 loss: 0.1765
Episode: 13541/30000 (45.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8431s / 1034.4960 s
agent0:                 episode reward: -0.9803,                 loss: nan
agent1:                 episode reward: 0.9803,                 loss: 0.1736
Episode: 13561/30000 (45.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8558s / 1036.3519 s
agent0:                 episode reward: -0.9091,                 loss: nan
agent1:                 episode reward: 0.9091,                 loss: 0.1751
Episode: 13581/30000 (45.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8762s / 1038.2281 s
agent0:                 episode reward: -1.0996,                 loss: nan
agent1:                 episode reward: 1.0996,                 loss: 0.1479
Episode: 13601/30000 (45.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8390s / 1040.0671 s
agent0:                 episode reward: -1.4740,                 loss: nan
agent1:                 episode reward: 1.4740,                 loss: 0.1399
Episode: 13621/30000 (45.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8350s / 1041.9021 s
agent0:                 episode reward: -1.5339,                 loss: nan
agent1:                 episode reward: 1.5339,                 loss: 0.1376
Episode: 13641/30000 (45.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8285s / 1043.7306 s
agent0:                 episode reward: -1.1801,                 loss: nan
agent1:                 episode reward: 1.1801,                 loss: 0.1366
Episode: 13661/30000 (45.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8713s / 1045.6018 s
agent0:                 episode reward: -1.4507,                 loss: nan
agent1:                 episode reward: 1.4507,                 loss: 0.1364
Episode: 13681/30000 (45.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8174s / 1047.4192 s
agent0:                 episode reward: -1.2187,                 loss: nan
agent1:                 episode reward: 1.2187,                 loss: 0.1203
Episode: 13701/30000 (45.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8835s / 1049.3027 s
agent0:                 episode reward: -1.3380,                 loss: nan
agent1:                 episode reward: 1.3380,                 loss: 0.1143
Episode: 13721/30000 (45.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8423s / 1051.1450 s
agent0:                 episode reward: -1.7462,                 loss: nan
agent1:                 episode reward: 1.7462,                 loss: 0.1137
Episode: 13741/30000 (45.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8424s / 1052.9874 s
agent0:                 episode reward: -1.3813,                 loss: nan
agent1:                 episode reward: 1.3813,                 loss: 0.1148
Episode: 13761/30000 (45.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8375s / 1054.8249 s
agent0:                 episode reward: -1.1134,                 loss: nan
agent1:                 episode reward: 1.1134,                 loss: 0.1137
Episode: 13781/30000 (45.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8289s / 1056.6539 s
agent0:                 episode reward: -1.3443,                 loss: nan
agent1:                 episode reward: 1.3443,                 loss: 0.1242
Episode: 13801/30000 (46.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8718s / 1058.5257 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.1222
Episode: 13821/30000 (46.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8291s / 1060.3548 s
agent0:                 episode reward: -1.1317,                 loss: nan
agent1:                 episode reward: 1.1317,                 loss: 0.1202
Episode: 13841/30000 (46.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8381s / 1062.1929 s
agent0:                 episode reward: -1.1355,                 loss: nan
agent1:                 episode reward: 1.1355,                 loss: 0.1193
Episode: 13861/30000 (46.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8397s / 1064.0325 s
agent0:                 episode reward: -0.8500,                 loss: nan
agent1:                 episode reward: 0.8500,                 loss: 0.1191
Episode: 13881/30000 (46.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8347s / 1065.8673 s
agent0:                 episode reward: -1.2499,                 loss: nan
agent1:                 episode reward: 1.2499,                 loss: 0.1282
Episode: 13901/30000 (46.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8342s / 1067.7015 s
agent0:                 episode reward: -1.9660,                 loss: nan
agent1:                 episode reward: 1.9660,                 loss: 0.1261
Episode: 13921/30000 (46.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9139s / 1069.6153 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.1261
Episode: 13941/30000 (46.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8131s / 1071.4284 s
agent0:                 episode reward: -0.4456,                 loss: nan
agent1:                 episode reward: 0.4456,                 loss: 0.1248
Episode: 13961/30000 (46.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8292s / 1073.2576 s
agent0:                 episode reward: -1.1003,                 loss: nan
agent1:                 episode reward: 1.1003,                 loss: 0.1254
Episode: 13981/30000 (46.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8488s / 1075.1065 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.1659
Episode: 14001/30000 (46.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8338s / 1076.9402 s
agent0:                 episode reward: -1.0054,                 loss: nan
agent1:                 episode reward: 1.0054,                 loss: 0.1729
Episode: 14021/30000 (46.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8986s / 1078.8388 s
agent0:                 episode reward: -1.3820,                 loss: nan
agent1:                 episode reward: 1.3820,                 loss: 0.1707
Episode: 14041/30000 (46.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8225s / 1080.6613 s
agent0:                 episode reward: -1.1322,                 loss: nan
agent1:                 episode reward: 1.1322,                 loss: 0.1708
Episode: 14061/30000 (46.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8212s / 1082.4825 s
agent0:                 episode reward: -1.2395,                 loss: nan
agent1:                 episode reward: 1.2395,                 loss: 0.1714
Episode: 14081/30000 (46.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8298s / 1084.3123 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.2445
Episode: 14101/30000 (47.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8399s / 1086.1522 s
agent0:                 episode reward: -1.2668,                 loss: nan
agent1:                 episode reward: 1.2668,                 loss: 0.2521
Episode: 14121/30000 (47.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8554s / 1088.0076 s
agent0:                 episode reward: -1.2860,                 loss: nan
agent1:                 episode reward: 1.2860,                 loss: 0.2524
Episode: 14141/30000 (47.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8445s / 1089.8522 s
agent0:                 episode reward: -1.3871,                 loss: nan
agent1:                 episode reward: 1.3871,                 loss: 0.2511
Episode: 14161/30000 (47.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8252s / 1091.6774 s
agent0:                 episode reward: -1.0865,                 loss: nan
agent1:                 episode reward: 1.0865,                 loss: 0.2523
Episode: 14181/30000 (47.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8269s / 1093.5042 s
agent0:                 episode reward: -1.0955,                 loss: nan
agent1:                 episode reward: 1.0955,                 loss: 0.2888
Episode: 14201/30000 (47.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8472s / 1095.3514 s
agent0:                 episode reward: -1.2836,                 loss: nan
agent1:                 episode reward: 1.2836,                 loss: 0.2850
Episode: 14221/30000 (47.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8467s / 1097.1981 s
agent0:                 episode reward: -0.9083,                 loss: nan
agent1:                 episode reward: 0.9083,                 loss: 0.2847
Episode: 14241/30000 (47.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8270s / 1099.0252 s
agent0:                 episode reward: -1.2209,                 loss: nan
agent1:                 episode reward: 1.2209,                 loss: 0.2867
Episode: 14261/30000 (47.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9059s / 1100.9310 s
agent0:                 episode reward: -0.9260,                 loss: nan
agent1:                 episode reward: 0.9260,                 loss: 0.2857
Episode: 14281/30000 (47.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9516s / 1102.8827 s
agent0:                 episode reward: -0.7549,                 loss: nan
agent1:                 episode reward: 0.7549,                 loss: 0.2414
Episode: 14301/30000 (47.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1321s / 1105.0148 s
agent0:                 episode reward: -1.2367,                 loss: nan
agent1:                 episode reward: 1.2367,                 loss: 0.2279
Episode: 14321/30000 (47.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1763s / 1107.1910 s
agent0:                 episode reward: -1.1938,                 loss: nan
agent1:                 episode reward: 1.1938,                 loss: 0.2286
Episode: 14341/30000 (47.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1630s / 1109.3540 s
agent0:                 episode reward: -1.4221,                 loss: nan
agent1:                 episode reward: 1.4221,                 loss: 0.2289
Episode: 14361/30000 (47.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8777s / 1111.2317 s
agent0:                 episode reward: -0.8270,                 loss: nan
agent1:                 episode reward: 0.8270,                 loss: 0.2259
Episode: 14381/30000 (47.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8401s / 1113.0718 s
agent0:                 episode reward: -1.0796,                 loss: nan
agent1:                 episode reward: 1.0796,                 loss: 0.1977
Episode: 14401/30000 (48.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9249s / 1114.9967 s
agent0:                 episode reward: -0.7338,                 loss: nan
agent1:                 episode reward: 0.7338,                 loss: 0.1859
Episode: 14421/30000 (48.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9186s / 1116.9153 s
agent0:                 episode reward: -0.8757,                 loss: nan
agent1:                 episode reward: 0.8757,                 loss: 0.1853
Episode: 14441/30000 (48.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8833s / 1118.7985 s
agent0:                 episode reward: -1.3765,                 loss: nan
agent1:                 episode reward: 1.3765,                 loss: 0.1862
Episode: 14461/30000 (48.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9791s / 1120.7777 s
agent0:                 episode reward: -1.7207,                 loss: nan
agent1:                 episode reward: 1.7207,                 loss: 0.1880
Episode: 14481/30000 (48.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9297s / 1122.7074 s
agent0:                 episode reward: -1.2088,                 loss: nan
agent1:                 episode reward: 1.2088,                 loss: 0.1866
Episode: 14501/30000 (48.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9523s / 1124.6598 s
agent0:                 episode reward: -1.1333,                 loss: nan
agent1:                 episode reward: 1.1333,                 loss: 0.1815
Episode: 14521/30000 (48.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9410s / 1126.6008 s
agent0:                 episode reward: -1.1234,                 loss: nan
agent1:                 episode reward: 1.1234,                 loss: 0.1762
Episode: 14541/30000 (48.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9277s / 1128.5285 s
agent0:                 episode reward: -0.4923,                 loss: nan
agent1:                 episode reward: 0.4923,                 loss: 0.1700
Episode: 14561/30000 (48.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9506s / 1130.4791 s
agent0:                 episode reward: -1.3210,                 loss: nan
agent1:                 episode reward: 1.3210,                 loss: 0.1697
Episode: 14581/30000 (48.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0674s / 1132.5466 s
agent0:                 episode reward: -1.5003,                 loss: nan
agent1:                 episode reward: 1.5003,                 loss: 0.1607
Episode: 14601/30000 (48.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0253s / 1134.5719 s
agent0:                 episode reward: -1.0610,                 loss: nan
agent1:                 episode reward: 1.0610,                 loss: 0.1529
Episode: 14621/30000 (48.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8947s / 1136.4666 s
agent0:                 episode reward: -1.3583,                 loss: nan
agent1:                 episode reward: 1.3583,                 loss: 0.1537
Episode: 14641/30000 (48.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2528s / 1138.7194 s
agent0:                 episode reward: -1.4743,                 loss: nan
agent1:                 episode reward: 1.4743,                 loss: 0.1527
Episode: 14661/30000 (48.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1132s / 1140.8327 s
agent0:                 episode reward: -1.4178,                 loss: nan
agent1:                 episode reward: 1.4178,                 loss: 0.1525
Episode: 14681/30000 (48.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9293s / 1142.7620 s
agent0:                 episode reward: -0.0672,                 loss: nan
agent1:                 episode reward: 0.0672,                 loss: 0.1762
Episode: 14701/30000 (49.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8902s / 1144.6522 s
agent0:                 episode reward: -1.0602,                 loss: nan
agent1:                 episode reward: 1.0602,                 loss: 0.1729
Episode: 14721/30000 (49.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8670s / 1146.5192 s
agent0:                 episode reward: -1.6975,                 loss: nan
agent1:                 episode reward: 1.6975,                 loss: 0.1715
Episode: 14741/30000 (49.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8808s / 1148.4001 s
agent0:                 episode reward: -1.9073,                 loss: nan
agent1:                 episode reward: 1.9073,                 loss: 0.1699
Episode: 14761/30000 (49.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8414s / 1150.2415 s
agent0:                 episode reward: -0.9825,                 loss: nan
agent1:                 episode reward: 0.9825,                 loss: 0.1704
Episode: 14781/30000 (49.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8933s / 1152.1348 s
agent0:                 episode reward: -1.2762,                 loss: nan
agent1:                 episode reward: 1.2762,                 loss: 0.1624
Episode: 14801/30000 (49.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8581s / 1153.9929 s
agent0:                 episode reward: -1.4038,                 loss: nan
agent1:                 episode reward: 1.4038,                 loss: 0.1551
Episode: 14821/30000 (49.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8255s / 1155.8183 s
agent0:                 episode reward: -1.1411,                 loss: nan
agent1:                 episode reward: 1.1411,                 loss: 0.1537
Episode: 14841/30000 (49.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8470s / 1157.6653 s
agent0:                 episode reward: -1.3824,                 loss: nan
agent1:                 episode reward: 1.3824,                 loss: 0.1531
Episode: 14861/30000 (49.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8513s / 1159.5166 s
agent0:                 episode reward: -1.3320,                 loss: nan
agent1:                 episode reward: 1.3320,                 loss: 0.1548
Episode: 14881/30000 (49.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1060s / 1161.6226 s
agent0:                 episode reward: -0.8663,                 loss: nan
agent1:                 episode reward: 0.8663,                 loss: 0.1843
Episode: 14901/30000 (49.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9742s / 1163.5968 s
agent0:                 episode reward: -1.5366,                 loss: nan
agent1:                 episode reward: 1.5366,                 loss: 0.1798
Episode: 14921/30000 (49.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9762s / 1165.5730 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.1765
Episode: 14941/30000 (49.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0660s / 1167.6390 s
agent0:                 episode reward: -0.9104,                 loss: nan
agent1:                 episode reward: 0.9104,                 loss: 0.1780
Episode: 14961/30000 (49.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9381s / 1169.5770 s
agent0:                 episode reward: -1.0772,                 loss: nan
agent1:                 episode reward: 1.0772,                 loss: 0.1780
Episode: 14981/30000 (49.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9130s / 1171.4901 s
agent0:                 episode reward: -0.6545,                 loss: nan
agent1:                 episode reward: 0.6545,                 loss: 0.2472
Episode: 15001/30000 (50.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1295s / 1173.6195 s
agent0:                 episode reward: -1.0948,                 loss: nan
agent1:                 episode reward: 1.0948,                 loss: 0.2478
Episode: 15021/30000 (50.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9517s / 1175.5712 s
agent0:                 episode reward: -0.8529,                 loss: nan
agent1:                 episode reward: 0.8529,                 loss: 0.2469
Episode: 15041/30000 (50.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0014s / 1177.5726 s
agent0:                 episode reward: -0.7253,                 loss: nan
agent1:                 episode reward: 0.7253,                 loss: 0.2451
Episode: 15061/30000 (50.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2279s / 1179.8005 s
agent0:                 episode reward: -0.9588,                 loss: nan
agent1:                 episode reward: 0.9588,                 loss: 0.2437
Episode: 15081/30000 (50.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0849s / 1181.8854 s
agent0:                 episode reward: -1.5910,                 loss: nan
agent1:                 episode reward: 1.5910,                 loss: 0.2072
Episode: 15101/30000 (50.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1784s / 1184.0637 s
agent0:                 episode reward: -0.8581,                 loss: nan
agent1:                 episode reward: 0.8581,                 loss: 0.1795
Episode: 15121/30000 (50.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9888s / 1186.0526 s
agent0:                 episode reward: -1.4301,                 loss: nan
agent1:                 episode reward: 1.4301,                 loss: 0.1769
Episode: 15141/30000 (50.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9442s / 1187.9967 s
agent0:                 episode reward: -1.0948,                 loss: nan
agent1:                 episode reward: 1.0948,                 loss: 0.1760
Episode: 15161/30000 (50.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2607s / 1190.2574 s
agent0:                 episode reward: -0.9655,                 loss: nan
agent1:                 episode reward: 0.9655,                 loss: 0.1744
Episode: 15181/30000 (50.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2145s / 1192.4719 s
agent0:                 episode reward: -0.7086,                 loss: nan
agent1:                 episode reward: 0.7086,                 loss: 0.1356
Episode: 15201/30000 (50.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9985s / 1194.4704 s
agent0:                 episode reward: -1.4752,                 loss: nan
agent1:                 episode reward: 1.4752,                 loss: 0.1159
Episode: 15221/30000 (50.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8695s / 1196.3399 s
agent0:                 episode reward: -1.0314,                 loss: nan
agent1:                 episode reward: 1.0314,                 loss: 0.1136
Episode: 15241/30000 (50.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8703s / 1198.2101 s
agent0:                 episode reward: -1.1939,                 loss: nan
agent1:                 episode reward: 1.1939,                 loss: 0.1133
Episode: 15261/30000 (50.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9072s / 1200.1173 s
agent0:                 episode reward: -1.0345,                 loss: nan
agent1:                 episode reward: 1.0345,                 loss: 0.1141
Episode: 15281/30000 (50.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0077s / 1202.1250 s
agent0:                 episode reward: -1.7144,                 loss: nan
agent1:                 episode reward: 1.7144,                 loss: 0.1097
Episode: 15301/30000 (51.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9798s / 1204.1048 s
agent0:                 episode reward: -1.4639,                 loss: nan
agent1:                 episode reward: 1.4639,                 loss: 0.0991
Episode: 15321/30000 (51.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8683s / 1205.9731 s
agent0:                 episode reward: -1.5407,                 loss: nan
agent1:                 episode reward: 1.5407,                 loss: 0.0983
Episode: 15341/30000 (51.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8792s / 1207.8522 s
agent0:                 episode reward: -1.1615,                 loss: nan
agent1:                 episode reward: 1.1615,                 loss: 0.0988
Episode: 15361/30000 (51.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8736s / 1209.7259 s
agent0:                 episode reward: -1.2450,                 loss: nan
agent1:                 episode reward: 1.2450,                 loss: 0.0977
Episode: 15381/30000 (51.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8977s / 1211.6236 s
agent0:                 episode reward: -1.0043,                 loss: nan
agent1:                 episode reward: 1.0043,                 loss: 0.1169
Episode: 15401/30000 (51.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8966s / 1213.5202 s
agent0:                 episode reward: -1.4909,                 loss: nan
agent1:                 episode reward: 1.4909,                 loss: 0.1146
Episode: 15421/30000 (51.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8628s / 1215.3830 s
agent0:                 episode reward: -1.7553,                 loss: nan
agent1:                 episode reward: 1.7553,                 loss: 0.1144
Episode: 15441/30000 (51.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8511s / 1217.2341 s
agent0:                 episode reward: -1.2734,                 loss: nan
agent1:                 episode reward: 1.2734,                 loss: 0.1148
Episode: 15461/30000 (51.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0116s / 1219.2457 s
agent0:                 episode reward: -1.3956,                 loss: nan
agent1:                 episode reward: 1.3956,                 loss: 0.1146
Episode: 15481/30000 (51.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9677s / 1221.2133 s
agent0:                 episode reward: -1.3970,                 loss: nan
agent1:                 episode reward: 1.3970,                 loss: 0.1738
Episode: 15501/30000 (51.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1515s / 1223.3649 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.1823
Episode: 15521/30000 (51.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8895s / 1225.2544 s
agent0:                 episode reward: -1.2300,                 loss: nan
agent1:                 episode reward: 1.2300,                 loss: 0.1815
Episode: 15541/30000 (51.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8712s / 1227.1256 s
agent0:                 episode reward: -1.6750,                 loss: nan
agent1:                 episode reward: 1.6750,                 loss: 0.1805
Episode: 15561/30000 (51.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8668s / 1228.9924 s
agent0:                 episode reward: -1.8228,                 loss: nan
agent1:                 episode reward: 1.8228,                 loss: 0.1814
Episode: 15581/30000 (51.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8600s / 1230.8523 s
agent0:                 episode reward: -0.5843,                 loss: nan
agent1:                 episode reward: 0.5843,                 loss: 0.2290
Episode: 15601/30000 (52.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9138s / 1232.7662 s
agent0:                 episode reward: -1.2830,                 loss: nan
agent1:                 episode reward: 1.2830,                 loss: 0.2319
Episode: 15621/30000 (52.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8471s / 1234.6132 s
agent0:                 episode reward: -1.2526,                 loss: nan
agent1:                 episode reward: 1.2526,                 loss: 0.2299
Episode: 15641/30000 (52.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8654s / 1236.4786 s
agent0:                 episode reward: -1.4661,                 loss: nan
agent1:                 episode reward: 1.4661,                 loss: 0.2288
Episode: 15661/30000 (52.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8712s / 1238.3499 s
agent0:                 episode reward: -1.4951,                 loss: nan
agent1:                 episode reward: 1.4951,                 loss: 0.2294
Episode: 15681/30000 (52.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8570s / 1240.2068 s
agent0:                 episode reward: -1.2167,                 loss: nan
agent1:                 episode reward: 1.2167,                 loss: 0.2267
Episode: 15701/30000 (52.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0912s / 1242.2981 s
agent0:                 episode reward: -1.3487,                 loss: nan
agent1:                 episode reward: 1.3487,                 loss: 0.2236
Episode: 15721/30000 (52.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9198s / 1244.2178 s
agent0:                 episode reward: -1.3213,                 loss: nan
agent1:                 episode reward: 1.3213,                 loss: 0.2232
Episode: 15741/30000 (52.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8797s / 1246.0975 s
agent0:                 episode reward: -1.2279,                 loss: nan
agent1:                 episode reward: 1.2279,                 loss: 0.2235
Episode: 15761/30000 (52.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9381s / 1248.0356 s
agent0:                 episode reward: -1.5391,                 loss: nan
agent1:                 episode reward: 1.5391,                 loss: 0.2240
Episode: 15781/30000 (52.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0614s / 1250.0970 s
agent0:                 episode reward: -1.2855,                 loss: nan
agent1:                 episode reward: 1.2855,                 loss: 0.2093
Episode: 15801/30000 (52.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9055s / 1252.0025 s
agent0:                 episode reward: -1.1845,                 loss: nan
agent1:                 episode reward: 1.1845,                 loss: 0.2030
Episode: 15821/30000 (52.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9388s / 1253.9414 s
agent0:                 episode reward: -1.6400,                 loss: nan
agent1:                 episode reward: 1.6400,                 loss: 0.2021
Episode: 15841/30000 (52.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8943s / 1255.8357 s
agent0:                 episode reward: -1.1704,                 loss: nan
agent1:                 episode reward: 1.1704,                 loss: 0.2023
Episode: 15861/30000 (52.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8595s / 1257.6952 s
agent0:                 episode reward: -1.1109,                 loss: nan
agent1:                 episode reward: 1.1109,                 loss: 0.2021
Episode: 15881/30000 (52.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8968s / 1259.5920 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.2393
Episode: 15901/30000 (53.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8649s / 1261.4569 s
agent0:                 episode reward: -1.2444,                 loss: nan
agent1:                 episode reward: 1.2444,                 loss: 0.2371
Episode: 15921/30000 (53.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8817s / 1263.3387 s
agent0:                 episode reward: -1.9932,                 loss: nan
agent1:                 episode reward: 1.9932,                 loss: 0.2351
Episode: 15941/30000 (53.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8573s / 1265.1960 s
agent0:                 episode reward: -1.5329,                 loss: nan
agent1:                 episode reward: 1.5329,                 loss: 0.2342
Episode: 15961/30000 (53.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9129s / 1267.1089 s
agent0:                 episode reward: -1.2756,                 loss: nan
agent1:                 episode reward: 1.2756,                 loss: 0.2338
Episode: 15981/30000 (53.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0927s / 1269.2016 s
agent0:                 episode reward: -0.8807,                 loss: nan
agent1:                 episode reward: 0.8807,                 loss: 0.2358
Episode: 16001/30000 (53.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9205s / 1271.1221 s
agent0:                 episode reward: -1.1726,                 loss: nan
agent1:                 episode reward: 1.1726,                 loss: 0.2289
Episode: 16021/30000 (53.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8798s / 1273.0019 s
agent0:                 episode reward: -1.4199,                 loss: nan
agent1:                 episode reward: 1.4199,                 loss: 0.2251
Episode: 16041/30000 (53.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9266s / 1274.9285 s
agent0:                 episode reward: -0.9093,                 loss: nan
agent1:                 episode reward: 0.9093,                 loss: 0.2262
Episode: 16061/30000 (53.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8640s / 1276.7924 s
agent0:                 episode reward: -1.9505,                 loss: nan
agent1:                 episode reward: 1.9505,                 loss: 0.2254
Episode: 16081/30000 (53.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9568s / 1278.7493 s
agent0:                 episode reward: -1.5797,                 loss: nan
agent1:                 episode reward: 1.5797,                 loss: 0.1575
Episode: 16101/30000 (53.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0464s / 1280.7957 s
agent0:                 episode reward: -0.4093,                 loss: nan
agent1:                 episode reward: 0.4093,                 loss: 0.1373
Episode: 16121/30000 (53.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9782s / 1282.7738 s
agent0:                 episode reward: -1.4497,                 loss: nan
agent1:                 episode reward: 1.4497,                 loss: 0.1367
Episode: 16141/30000 (53.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9848s / 1284.7587 s
agent0:                 episode reward: -1.3747,                 loss: nan
agent1:                 episode reward: 1.3747,                 loss: 0.1358
Episode: 16161/30000 (53.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9004s / 1286.6591 s
agent0:                 episode reward: -1.2951,                 loss: nan
agent1:                 episode reward: 1.2951,                 loss: 0.1358
Episode: 16181/30000 (53.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8638s / 1288.5229 s
agent0:                 episode reward: -1.2672,                 loss: nan
agent1:                 episode reward: 1.2672,                 loss: 0.1123
Episode: 16201/30000 (54.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0265s / 1290.5494 s
agent0:                 episode reward: -0.7524,                 loss: nan
agent1:                 episode reward: 0.7524,                 loss: 0.0974
Episode: 16221/30000 (54.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8657s / 1292.4150 s
agent0:                 episode reward: -1.2977,                 loss: nan
agent1:                 episode reward: 1.2977,                 loss: 0.0973
Episode: 16241/30000 (54.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9312s / 1294.3462 s
agent0:                 episode reward: -1.4701,                 loss: nan
agent1:                 episode reward: 1.4701,                 loss: 0.0965
Episode: 16261/30000 (54.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0225s / 1296.3687 s
agent0:                 episode reward: -1.5146,                 loss: nan
agent1:                 episode reward: 1.5146,                 loss: 0.0973
Episode: 16281/30000 (54.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9154s / 1298.2841 s
agent0:                 episode reward: -1.1130,                 loss: nan
agent1:                 episode reward: 1.1130,                 loss: 0.1105
Episode: 16301/30000 (54.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8925s / 1300.1766 s
agent0:                 episode reward: -1.2498,                 loss: nan
agent1:                 episode reward: 1.2498,                 loss: 0.1061
Episode: 16321/30000 (54.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9194s / 1302.0960 s
agent0:                 episode reward: -1.0216,                 loss: nan
agent1:                 episode reward: 1.0216,                 loss: 0.1081
Episode: 16341/30000 (54.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0813s / 1304.1773 s
agent0:                 episode reward: -1.6376,                 loss: nan
agent1:                 episode reward: 1.6376,                 loss: 0.1048
Episode: 16361/30000 (54.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8748s / 1306.0521 s
agent0:                 episode reward: -1.6222,                 loss: nan
agent1:                 episode reward: 1.6222,                 loss: 0.1077
Episode: 16381/30000 (54.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8858s / 1307.9378 s
agent0:                 episode reward: -1.4028,                 loss: nan
agent1:                 episode reward: 1.4028,                 loss: 0.1732
Episode: 16401/30000 (54.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8899s / 1309.8278 s
agent0:                 episode reward: -1.1178,                 loss: nan
agent1:                 episode reward: 1.1178,                 loss: 0.1823
Episode: 16421/30000 (54.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8876s / 1311.7154 s
agent0:                 episode reward: -1.1953,                 loss: nan
agent1:                 episode reward: 1.1953,                 loss: 0.1808
Episode: 16441/30000 (54.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9111s / 1313.6265 s
agent0:                 episode reward: -1.3777,                 loss: nan
agent1:                 episode reward: 1.3777,                 loss: 0.1823
Episode: 16461/30000 (54.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0124s / 1315.6389 s
agent0:                 episode reward: -2.1658,                 loss: nan
agent1:                 episode reward: 2.1658,                 loss: 0.1800
Episode: 16481/30000 (54.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8847s / 1317.5236 s
agent0:                 episode reward: -1.7215,                 loss: nan
agent1:                 episode reward: 1.7215,                 loss: 0.2422
Episode: 16501/30000 (55.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0420s / 1319.5656 s
agent0:                 episode reward: -1.7125,                 loss: nan
agent1:                 episode reward: 1.7125,                 loss: 0.2467
Episode: 16521/30000 (55.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9271s / 1321.4927 s
agent0:                 episode reward: -0.9336,                 loss: nan
agent1:                 episode reward: 0.9336,                 loss: 0.2447
Episode: 16541/30000 (55.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8943s / 1323.3870 s
agent0:                 episode reward: -1.4331,                 loss: nan
agent1:                 episode reward: 1.4331,                 loss: 0.2454
Episode: 16561/30000 (55.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9045s / 1325.2915 s
agent0:                 episode reward: -0.6192,                 loss: nan
agent1:                 episode reward: 0.6192,                 loss: 0.2447
Episode: 16581/30000 (55.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0220s / 1327.3135 s
agent0:                 episode reward: -0.8766,                 loss: nan
agent1:                 episode reward: 0.8766,                 loss: 0.2509
Episode: 16601/30000 (55.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9826s / 1329.2961 s
agent0:                 episode reward: -1.3799,                 loss: nan
agent1:                 episode reward: 1.3799,                 loss: 0.2483
Episode: 16621/30000 (55.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8998s / 1331.1959 s
agent0:                 episode reward: -1.2151,                 loss: nan
agent1:                 episode reward: 1.2151,                 loss: 0.2476
Episode: 16641/30000 (55.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8755s / 1333.0714 s
agent0:                 episode reward: -1.4089,                 loss: nan
agent1:                 episode reward: 1.4089,                 loss: 0.2432
Episode: 16661/30000 (55.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8964s / 1334.9677 s
agent0:                 episode reward: -1.3749,                 loss: nan
agent1:                 episode reward: 1.3749,                 loss: 0.2454
Episode: 16681/30000 (55.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8692s / 1336.8370 s
agent0:                 episode reward: -1.5115,                 loss: nan
agent1:                 episode reward: 1.5115,                 loss: 0.2191
Episode: 16701/30000 (55.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8897s / 1338.7267 s
agent0:                 episode reward: -0.7651,                 loss: nan
agent1:                 episode reward: 0.7651,                 loss: 0.2094
Episode: 16721/30000 (55.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9152s / 1340.6418 s
agent0:                 episode reward: -1.4427,                 loss: nan
agent1:                 episode reward: 1.4427,                 loss: 0.2101
Episode: 16741/30000 (55.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8579s / 1342.4997 s
agent0:                 episode reward: -0.8088,                 loss: nan
agent1:                 episode reward: 0.8088,                 loss: 0.2100
Episode: 16761/30000 (55.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8871s / 1344.3869 s
agent0:                 episode reward: -1.4314,                 loss: nan
agent1:                 episode reward: 1.4314,                 loss: 0.2090
Episode: 16781/30000 (55.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9215s / 1346.3084 s
agent0:                 episode reward: -0.9119,                 loss: nan
agent1:                 episode reward: 0.9119,                 loss: 0.2263
Episode: 16801/30000 (56.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0784s / 1348.3868 s
agent0:                 episode reward: -1.3703,                 loss: nan
agent1:                 episode reward: 1.3703,                 loss: 0.2233
Episode: 16821/30000 (56.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0455s / 1350.4323 s
agent0:                 episode reward: -1.3067,                 loss: nan
agent1:                 episode reward: 1.3067,                 loss: 0.2226
Episode: 16841/30000 (56.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1520s / 1352.5843 s
agent0:                 episode reward: -1.0767,                 loss: nan
agent1:                 episode reward: 1.0767,                 loss: 0.2184
Episode: 16861/30000 (56.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0957s / 1354.6800 s
agent0:                 episode reward: -1.5664,                 loss: nan
agent1:                 episode reward: 1.5664,                 loss: 0.2177
Episode: 16881/30000 (56.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0208s / 1356.7009 s
agent0:                 episode reward: -0.8903,                 loss: nan
agent1:                 episode reward: 0.8903,                 loss: 0.2280
Episode: 16901/30000 (56.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0392s / 1358.7401 s
agent0:                 episode reward: -1.4427,                 loss: nan
agent1:                 episode reward: 1.4427,                 loss: 0.2187
Episode: 16921/30000 (56.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0320s / 1360.7720 s
agent0:                 episode reward: -1.0628,                 loss: nan
agent1:                 episode reward: 1.0628,                 loss: 0.2171
Episode: 16941/30000 (56.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8954s / 1362.6674 s
agent0:                 episode reward: -1.0307,                 loss: nan
agent1:                 episode reward: 1.0307,                 loss: 0.2154
Episode: 16961/30000 (56.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8858s / 1364.5532 s
agent0:                 episode reward: -0.7546,                 loss: nan
agent1:                 episode reward: 0.7546,                 loss: 0.2165
Episode: 16981/30000 (56.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8878s / 1366.4410 s
agent0:                 episode reward: -1.5626,                 loss: nan
agent1:                 episode reward: 1.5626,                 loss: 0.1709
Episode: 17001/30000 (56.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9172s / 1368.3582 s
agent0:                 episode reward: -0.8019,                 loss: nan
agent1:                 episode reward: 0.8019,                 loss: 0.1505
Episode: 17021/30000 (56.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0726s / 1370.4308 s
agent0:                 episode reward: -1.4199,                 loss: nan
agent1:                 episode reward: 1.4199,                 loss: 0.1491
Episode: 17041/30000 (56.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8652s / 1372.2960 s
agent0:                 episode reward: -0.7301,                 loss: nan
agent1:                 episode reward: 0.7301,                 loss: 0.1485
Episode: 17061/30000 (56.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8833s / 1374.1793 s
agent0:                 episode reward: -1.3515,                 loss: nan
agent1:                 episode reward: 1.3515,                 loss: 0.1494
Episode: 17081/30000 (56.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9154s / 1376.0947 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.1285
Episode: 17101/30000 (57.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0068s / 1378.1015 s
agent0:                 episode reward: -1.6535,                 loss: nan
agent1:                 episode reward: 1.6535,                 loss: 0.1160
Episode: 17121/30000 (57.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9510s / 1380.0525 s
agent0:                 episode reward: -1.3140,                 loss: nan
agent1:                 episode reward: 1.3140,                 loss: 0.1156
Episode: 17141/30000 (57.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0429s / 1382.0954 s
agent0:                 episode reward: -0.4070,                 loss: nan
agent1:                 episode reward: 0.4070,                 loss: 0.1159
Episode: 17161/30000 (57.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.4715s / 1384.5669 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.1146
Episode: 17181/30000 (57.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.3017s / 1386.8686 s
agent0:                 episode reward: -0.8608,                 loss: nan
agent1:                 episode reward: 0.8608,                 loss: 0.1159
Episode: 17201/30000 (57.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0935s / 1388.9621 s
agent0:                 episode reward: -1.5377,                 loss: nan
agent1:                 episode reward: 1.5377,                 loss: 0.1076
Episode: 17221/30000 (57.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0700s / 1391.0321 s
agent0:                 episode reward: -1.4484,                 loss: nan
agent1:                 episode reward: 1.4484,                 loss: 0.1075
Episode: 17241/30000 (57.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9725s / 1393.0046 s
agent0:                 episode reward: -1.4108,                 loss: nan
agent1:                 episode reward: 1.4108,                 loss: 0.1066
Episode: 17261/30000 (57.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1090s / 1395.1136 s
agent0:                 episode reward: -1.3564,                 loss: nan
agent1:                 episode reward: 1.3564,                 loss: 0.1058
Episode: 17281/30000 (57.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9785s / 1397.0921 s
agent0:                 episode reward: -1.2231,                 loss: nan
agent1:                 episode reward: 1.2231,                 loss: 0.1544
Episode: 17301/30000 (57.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2057s / 1399.2978 s
agent0:                 episode reward: -1.6038,                 loss: nan
agent1:                 episode reward: 1.6038,                 loss: 0.1581
Episode: 17321/30000 (57.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0607s / 1401.3585 s
agent0:                 episode reward: -1.8092,                 loss: nan
agent1:                 episode reward: 1.8092,                 loss: 0.1575
Episode: 17341/30000 (57.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1253s / 1403.4838 s
agent0:                 episode reward: -0.9423,                 loss: nan
agent1:                 episode reward: 0.9423,                 loss: 0.1556
Episode: 17361/30000 (57.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2462s / 1405.7300 s
agent0:                 episode reward: -0.9669,                 loss: nan
agent1:                 episode reward: 0.9669,                 loss: 0.1566
Episode: 17381/30000 (57.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2009s / 1407.9309 s
agent0:                 episode reward: -0.7071,                 loss: nan
agent1:                 episode reward: 0.7071,                 loss: 0.2466
Episode: 17401/30000 (58.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0627s / 1409.9936 s
agent0:                 episode reward: -1.2821,                 loss: nan
agent1:                 episode reward: 1.2821,                 loss: 0.2552
Episode: 17421/30000 (58.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1626s / 1412.1562 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.2560
Episode: 17441/30000 (58.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1642s / 1414.3205 s
agent0:                 episode reward: -1.8218,                 loss: nan
agent1:                 episode reward: 1.8218,                 loss: 0.2537
Episode: 17461/30000 (58.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1605s / 1416.4809 s
agent0:                 episode reward: -1.8967,                 loss: nan
agent1:                 episode reward: 1.8967,                 loss: 0.2547
Episode: 17481/30000 (58.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0585s / 1418.5395 s
agent0:                 episode reward: -0.8339,                 loss: nan
agent1:                 episode reward: 0.8339,                 loss: 0.2676
Episode: 17501/30000 (58.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9663s / 1420.5058 s
agent0:                 episode reward: -1.0648,                 loss: nan
agent1:                 episode reward: 1.0648,                 loss: 0.2553
Episode: 17521/30000 (58.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8840s / 1422.3898 s
agent0:                 episode reward: -1.5506,                 loss: nan
agent1:                 episode reward: 1.5506,                 loss: 0.2542
Episode: 17541/30000 (58.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9172s / 1424.3070 s
agent0:                 episode reward: -1.2911,                 loss: nan
agent1:                 episode reward: 1.2911,                 loss: 0.2549
Episode: 17561/30000 (58.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0001s / 1426.3072 s
agent0:                 episode reward: -0.7772,                 loss: nan
agent1:                 episode reward: 0.7772,                 loss: 0.2557
Episode: 17581/30000 (58.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9565s / 1428.2636 s
agent0:                 episode reward: -1.6382,                 loss: nan
agent1:                 episode reward: 1.6382,                 loss: 0.1951
Episode: 17601/30000 (58.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0991s / 1430.3628 s
agent0:                 episode reward: -1.5151,                 loss: nan
agent1:                 episode reward: 1.5151,                 loss: 0.1773
Episode: 17621/30000 (58.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0172s / 1432.3800 s
agent0:                 episode reward: -1.3237,                 loss: nan
agent1:                 episode reward: 1.3237,                 loss: 0.1756
Episode: 17641/30000 (58.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0083s / 1434.3883 s
agent0:                 episode reward: -1.9012,                 loss: nan
agent1:                 episode reward: 1.9012,                 loss: 0.1766
Episode: 17661/30000 (58.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9902s / 1436.3785 s
agent0:                 episode reward: -1.5557,                 loss: nan
agent1:                 episode reward: 1.5557,                 loss: 0.1783
Episode: 17681/30000 (58.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0393s / 1438.4178 s
agent0:                 episode reward: -1.2098,                 loss: nan
agent1:                 episode reward: 1.2098,                 loss: 0.1391
Episode: 17701/30000 (59.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8973s / 1440.3152 s
agent0:                 episode reward: -1.7239,                 loss: nan
agent1:                 episode reward: 1.7239,                 loss: 0.1258
Episode: 17721/30000 (59.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9723s / 1442.2874 s
agent0:                 episode reward: -1.0292,                 loss: nan
agent1:                 episode reward: 1.0292,                 loss: 0.1263
Episode: 17741/30000 (59.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1354s / 1444.4228 s
agent0:                 episode reward: -1.3147,                 loss: nan
agent1:                 episode reward: 1.3147,                 loss: 0.1252
Episode: 17761/30000 (59.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0026s / 1446.4254 s
agent0:                 episode reward: -1.9625,                 loss: nan
agent1:                 episode reward: 1.9625,                 loss: 0.1272
Episode: 17781/30000 (59.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2708s / 1448.6961 s
agent0:                 episode reward: -1.5354,                 loss: nan
agent1:                 episode reward: 1.5354,                 loss: 0.1516
Episode: 17801/30000 (59.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0400s / 1450.7361 s
agent0:                 episode reward: -1.0537,                 loss: nan
agent1:                 episode reward: 1.0537,                 loss: 0.1513
Episode: 17821/30000 (59.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0465s / 1452.7827 s
agent0:                 episode reward: -1.2286,                 loss: nan
agent1:                 episode reward: 1.2286,                 loss: 0.1504
Episode: 17841/30000 (59.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9851s / 1454.7678 s
agent0:                 episode reward: -1.0949,                 loss: nan
agent1:                 episode reward: 1.0949,                 loss: 0.1498
Episode: 17861/30000 (59.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0434s / 1456.8112 s
agent0:                 episode reward: -1.1198,                 loss: nan
agent1:                 episode reward: 1.1198,                 loss: 0.1496
Episode: 17881/30000 (59.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1436s / 1458.9548 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.2041
Episode: 17901/30000 (59.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0261s / 1460.9809 s
agent0:                 episode reward: -1.0523,                 loss: nan
agent1:                 episode reward: 1.0523,                 loss: 0.2062
Episode: 17921/30000 (59.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0372s / 1463.0181 s
agent0:                 episode reward: -1.6254,                 loss: nan
agent1:                 episode reward: 1.6254,                 loss: 0.2058
Episode: 17941/30000 (59.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0201s / 1465.0381 s
agent0:                 episode reward: -1.3097,                 loss: nan
agent1:                 episode reward: 1.3097,                 loss: 0.2045
Episode: 17961/30000 (59.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9696s / 1467.0077 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.2057
Episode: 17981/30000 (59.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0447s / 1469.0525 s
agent0:                 episode reward: -1.6335,                 loss: nan
agent1:                 episode reward: 1.6335,                 loss: 0.1648
Episode: 18001/30000 (60.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9193s / 1470.9718 s
agent0:                 episode reward: -1.2871,                 loss: nan
agent1:                 episode reward: 1.2871,                 loss: 0.1539
Episode: 18021/30000 (60.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0249s / 1472.9967 s
agent0:                 episode reward: -1.4830,                 loss: nan
agent1:                 episode reward: 1.4830,                 loss: 0.1529
Episode: 18041/30000 (60.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1270s / 1475.1237 s
agent0:                 episode reward: -1.7431,                 loss: nan
agent1:                 episode reward: 1.7431,                 loss: 0.1532
Episode: 18061/30000 (60.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2006s / 1477.3243 s
agent0:                 episode reward: -1.5436,                 loss: nan
agent1:                 episode reward: 1.5436,                 loss: 0.1537
Episode: 18081/30000 (60.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1182s / 1479.4425 s
agent0:                 episode reward: -1.9198,                 loss: nan
agent1:                 episode reward: 1.9198,                 loss: 0.1460
Episode: 18101/30000 (60.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0181s / 1481.4606 s
agent0:                 episode reward: -1.7003,                 loss: nan
agent1:                 episode reward: 1.7003,                 loss: 0.1413
Episode: 18121/30000 (60.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2450s / 1483.7056 s
agent0:                 episode reward: -1.3923,                 loss: nan
agent1:                 episode reward: 1.3923,                 loss: 0.1428
Episode: 18141/30000 (60.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2679s / 1485.9736 s
agent0:                 episode reward: -0.9584,                 loss: nan
agent1:                 episode reward: 0.9584,                 loss: 0.1404
Episode: 18161/30000 (60.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1876s / 1488.1612 s
agent0:                 episode reward: -1.8605,                 loss: nan
agent1:                 episode reward: 1.8605,                 loss: 0.1405
Episode: 18181/30000 (60.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2832s / 1490.4443 s
agent0:                 episode reward: -1.0874,                 loss: nan
agent1:                 episode reward: 1.0874,                 loss: 0.1742
Episode: 18201/30000 (60.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2431s / 1492.6875 s
agent0:                 episode reward: -1.1810,                 loss: nan
agent1:                 episode reward: 1.1810,                 loss: 0.1723
Episode: 18221/30000 (60.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2579s / 1494.9453 s
agent0:                 episode reward: -1.5470,                 loss: nan
agent1:                 episode reward: 1.5470,                 loss: 0.1729
Episode: 18241/30000 (60.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2198s / 1497.1652 s
agent0:                 episode reward: -1.4601,                 loss: nan
agent1:                 episode reward: 1.4601,                 loss: 0.1751
Episode: 18261/30000 (60.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2671s / 1499.4323 s
agent0:                 episode reward: -1.5918,                 loss: nan
agent1:                 episode reward: 1.5918,                 loss: 0.1738
Episode: 18281/30000 (60.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1569s / 1501.5892 s
agent0:                 episode reward: -1.6130,                 loss: nan
agent1:                 episode reward: 1.6130,                 loss: 0.2717
Episode: 18301/30000 (61.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1916s / 1503.7807 s
agent0:                 episode reward: -1.1466,                 loss: nan
agent1:                 episode reward: 1.1466,                 loss: 0.2837
Episode: 18321/30000 (61.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1764s / 1505.9571 s
agent0:                 episode reward: -1.2575,                 loss: nan
agent1:                 episode reward: 1.2575,                 loss: 0.2825
Episode: 18341/30000 (61.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1687s / 1508.1258 s
agent0:                 episode reward: -1.4238,                 loss: nan
agent1:                 episode reward: 1.4238,                 loss: 0.2825
Episode: 18361/30000 (61.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2503s / 1510.3761 s
agent0:                 episode reward: -0.9890,                 loss: nan
agent1:                 episode reward: 0.9890,                 loss: 0.2826
Episode: 18381/30000 (61.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1793s / 1512.5555 s
agent0:                 episode reward: -1.5413,                 loss: nan
agent1:                 episode reward: 1.5413,                 loss: 0.2789
Episode: 18401/30000 (61.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2012s / 1514.7567 s
agent0:                 episode reward: -1.3563,                 loss: nan
agent1:                 episode reward: 1.3563,                 loss: 0.2704
Episode: 18421/30000 (61.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1547s / 1516.9114 s
agent0:                 episode reward: -1.2014,                 loss: nan
agent1:                 episode reward: 1.2014,                 loss: 0.2718
Episode: 18441/30000 (61.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2101s / 1519.1215 s
agent0:                 episode reward: -1.0429,                 loss: nan
agent1:                 episode reward: 1.0429,                 loss: 0.2690
Episode: 18461/30000 (61.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2369s / 1521.3583 s
agent0:                 episode reward: -1.1812,                 loss: nan
agent1:                 episode reward: 1.1812,                 loss: 0.2705
Episode: 18481/30000 (61.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2474s / 1523.6058 s
agent0:                 episode reward: -1.5714,                 loss: nan
agent1:                 episode reward: 1.5714,                 loss: 0.2003
Episode: 18501/30000 (61.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1684s / 1525.7742 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.1790
Episode: 18521/30000 (61.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2017s / 1527.9759 s
agent0:                 episode reward: -1.0394,                 loss: nan
agent1:                 episode reward: 1.0394,                 loss: 0.1783
Episode: 18541/30000 (61.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2031s / 1530.1790 s
agent0:                 episode reward: -1.3136,                 loss: nan
agent1:                 episode reward: 1.3136,                 loss: 0.1787
Episode: 18561/30000 (61.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9263s / 1532.1052 s
agent0:                 episode reward: -1.3181,                 loss: nan
agent1:                 episode reward: 1.3181,                 loss: 0.1774
Episode: 18581/30000 (61.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0359s / 1534.1411 s
agent0:                 episode reward: -1.0470,                 loss: nan
agent1:                 episode reward: 1.0470,                 loss: 0.1321
Episode: 18601/30000 (62.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9730s / 1536.1141 s
agent0:                 episode reward: -1.3602,                 loss: nan
agent1:                 episode reward: 1.3602,                 loss: 0.1132
Episode: 18621/30000 (62.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0732s / 1538.1873 s
agent0:                 episode reward: -1.0520,                 loss: nan
agent1:                 episode reward: 1.0520,                 loss: 0.1130
Episode: 18641/30000 (62.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9397s / 1540.1270 s
agent0:                 episode reward: -1.7855,                 loss: nan
agent1:                 episode reward: 1.7855,                 loss: 0.1128
Episode: 18661/30000 (62.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0462s / 1542.1732 s
agent0:                 episode reward: -1.5020,                 loss: nan
agent1:                 episode reward: 1.5020,                 loss: 0.1122
Episode: 18681/30000 (62.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0045s / 1544.1777 s
agent0:                 episode reward: -1.3909,                 loss: nan
agent1:                 episode reward: 1.3909,                 loss: 0.1361
Episode: 18701/30000 (62.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9405s / 1546.1182 s
agent0:                 episode reward: -1.6022,                 loss: nan
agent1:                 episode reward: 1.6022,                 loss: 0.1372
Episode: 18721/30000 (62.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9215s / 1548.0397 s
agent0:                 episode reward: -1.7111,                 loss: nan
agent1:                 episode reward: 1.7111,                 loss: 0.1374
Episode: 18741/30000 (62.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1203s / 1550.1600 s
agent0:                 episode reward: -0.7940,                 loss: nan
agent1:                 episode reward: 0.7940,                 loss: 0.1351
Episode: 18761/30000 (62.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0061s / 1552.1661 s
agent0:                 episode reward: -1.4655,                 loss: nan
agent1:                 episode reward: 1.4655,                 loss: 0.1356
Episode: 18781/30000 (62.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0374s / 1554.2035 s
agent0:                 episode reward: -1.8965,                 loss: nan
agent1:                 episode reward: 1.8965,                 loss: 0.1907
Episode: 18801/30000 (62.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8564s / 1556.0599 s
agent0:                 episode reward: -1.8103,                 loss: nan
agent1:                 episode reward: 1.8103,                 loss: 0.1967
Episode: 18821/30000 (62.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8829s / 1557.9428 s
agent0:                 episode reward: -1.4159,                 loss: nan
agent1:                 episode reward: 1.4159,                 loss: 0.1954
Episode: 18841/30000 (62.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1263s / 1560.0691 s
agent0:                 episode reward: -0.8235,                 loss: nan
agent1:                 episode reward: 0.8235,                 loss: 0.1959
Episode: 18861/30000 (62.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8653s / 1561.9345 s
agent0:                 episode reward: -1.2443,                 loss: nan
agent1:                 episode reward: 1.2443,                 loss: 0.1947
Episode: 18881/30000 (62.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0677s / 1564.0022 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.1916
Episode: 18901/30000 (63.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9675s / 1565.9696 s
agent0:                 episode reward: -1.0312,                 loss: nan
agent1:                 episode reward: 1.0312,                 loss: 0.1862
Episode: 18921/30000 (63.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1144s / 1568.0841 s
agent0:                 episode reward: -1.5763,                 loss: nan
agent1:                 episode reward: 1.5763,                 loss: 0.1845
Episode: 18941/30000 (63.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9375s / 1570.0216 s
agent0:                 episode reward: -1.8968,                 loss: nan
agent1:                 episode reward: 1.8968,                 loss: 0.1848
Episode: 18961/30000 (63.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9373s / 1571.9589 s
agent0:                 episode reward: -1.0840,                 loss: nan
agent1:                 episode reward: 1.0840,                 loss: 0.1857
Episode: 18981/30000 (63.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8511s / 1573.8100 s
agent0:                 episode reward: -0.8328,                 loss: nan
agent1:                 episode reward: 0.8328,                 loss: 0.1521
Episode: 19001/30000 (63.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0984s / 1575.9084 s
agent0:                 episode reward: -0.8562,                 loss: nan
agent1:                 episode reward: 0.8562,                 loss: 0.1429
Episode: 19021/30000 (63.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9396s / 1577.8479 s
agent0:                 episode reward: -1.0760,                 loss: nan
agent1:                 episode reward: 1.0760,                 loss: 0.1409
Episode: 19041/30000 (63.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8497s / 1579.6976 s
agent0:                 episode reward: -1.3846,                 loss: nan
agent1:                 episode reward: 1.3846,                 loss: 0.1423
Episode: 19061/30000 (63.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8901s / 1581.5878 s
agent0:                 episode reward: -2.2821,                 loss: nan
agent1:                 episode reward: 2.2821,                 loss: 0.1411
Episode: 19081/30000 (63.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0331s / 1583.6209 s
agent0:                 episode reward: -1.1614,                 loss: nan
agent1:                 episode reward: 1.1614,                 loss: 0.1364
Episode: 19101/30000 (63.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2825s / 1585.9033 s
agent0:                 episode reward: -1.4157,                 loss: nan
agent1:                 episode reward: 1.4157,                 loss: 0.1334
Episode: 19121/30000 (63.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0617s / 1587.9650 s
agent0:                 episode reward: -0.5816,                 loss: nan
agent1:                 episode reward: 0.5816,                 loss: 0.1320
Episode: 19141/30000 (63.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9664s / 1589.9314 s
agent0:                 episode reward: -0.8928,                 loss: nan
agent1:                 episode reward: 0.8928,                 loss: 0.1325
Episode: 19161/30000 (63.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8906s / 1591.8220 s
agent0:                 episode reward: -1.3430,                 loss: nan
agent1:                 episode reward: 1.3430,                 loss: 0.1304
Episode: 19181/30000 (63.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8619s / 1593.6838 s
agent0:                 episode reward: -1.0745,                 loss: nan
agent1:                 episode reward: 1.0745,                 loss: 0.1686
Episode: 19201/30000 (64.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8348s / 1595.5186 s
agent0:                 episode reward: -1.5189,                 loss: nan
agent1:                 episode reward: 1.5189,                 loss: 0.1737
Episode: 19221/30000 (64.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9056s / 1597.4242 s
agent0:                 episode reward: -1.4738,                 loss: nan
agent1:                 episode reward: 1.4738,                 loss: 0.1730
Episode: 19241/30000 (64.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9015s / 1599.3257 s
agent0:                 episode reward: -1.6798,                 loss: nan
agent1:                 episode reward: 1.6798,                 loss: 0.1710
Episode: 19261/30000 (64.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9585s / 1601.2843 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.1740
Episode: 19281/30000 (64.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9150s / 1603.1993 s
agent0:                 episode reward: -1.3756,                 loss: nan
agent1:                 episode reward: 1.3756,                 loss: 0.2495
Episode: 19301/30000 (64.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8800s / 1605.0792 s
agent0:                 episode reward: -1.5473,                 loss: nan
agent1:                 episode reward: 1.5473,                 loss: 0.2579
Episode: 19321/30000 (64.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8662s / 1606.9455 s
agent0:                 episode reward: -1.4136,                 loss: nan
agent1:                 episode reward: 1.4136,                 loss: 0.2570
Episode: 19341/30000 (64.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8547s / 1608.8002 s
agent0:                 episode reward: -1.3070,                 loss: nan
agent1:                 episode reward: 1.3070,                 loss: 0.2553
Episode: 19361/30000 (64.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8658s / 1610.6660 s
agent0:                 episode reward: -0.9509,                 loss: nan
agent1:                 episode reward: 0.9509,                 loss: 0.2570
Episode: 19381/30000 (64.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1024s / 1612.7684 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.2534
Episode: 19401/30000 (64.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9197s / 1614.6881 s
agent0:                 episode reward: -1.2034,                 loss: nan
agent1:                 episode reward: 1.2034,                 loss: 0.2403
Episode: 19421/30000 (64.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9877s / 1616.6758 s
agent0:                 episode reward: -0.9720,                 loss: nan
agent1:                 episode reward: 0.9720,                 loss: 0.2382
Episode: 19441/30000 (64.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9190s / 1618.5949 s
agent0:                 episode reward: -1.7543,                 loss: nan
agent1:                 episode reward: 1.7543,                 loss: 0.2398
Episode: 19461/30000 (64.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8278s / 1620.4227 s
agent0:                 episode reward: -1.3011,                 loss: nan
agent1:                 episode reward: 1.3011,                 loss: 0.2390
Episode: 19481/30000 (64.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9065s / 1622.3292 s
agent0:                 episode reward: -1.2933,                 loss: nan
agent1:                 episode reward: 1.2933,                 loss: 0.1898
Episode: 19501/30000 (65.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9772s / 1624.3063 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.1704
Episode: 19521/30000 (65.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1523s / 1626.4586 s
agent0:                 episode reward: -0.9968,                 loss: nan
agent1:                 episode reward: 0.9968,                 loss: 0.1685
Episode: 19541/30000 (65.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0552s / 1628.5138 s
agent0:                 episode reward: -1.4681,                 loss: nan
agent1:                 episode reward: 1.4681,                 loss: 0.1684
Episode: 19561/30000 (65.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9942s / 1630.5081 s
agent0:                 episode reward: -1.5664,                 loss: nan
agent1:                 episode reward: 1.5664,                 loss: 0.1692
Episode: 19581/30000 (65.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9621s / 1632.4701 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.1550
Episode: 19601/30000 (65.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0298s / 1634.4999 s
agent0:                 episode reward: -1.5594,                 loss: nan
agent1:                 episode reward: 1.5594,                 loss: 0.1437
Episode: 19621/30000 (65.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0253s / 1636.5253 s
agent0:                 episode reward: -1.2011,                 loss: nan
agent1:                 episode reward: 1.2011,                 loss: 0.1456
Episode: 19641/30000 (65.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9674s / 1638.4927 s
agent0:                 episode reward: -1.7006,                 loss: nan
agent1:                 episode reward: 1.7006,                 loss: 0.1433
Episode: 19661/30000 (65.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9727s / 1640.4653 s
agent0:                 episode reward: -1.3715,                 loss: nan
agent1:                 episode reward: 1.3715,                 loss: 0.1450
Episode: 19681/30000 (65.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9450s / 1642.4103 s
agent0:                 episode reward: -1.3741,                 loss: nan
agent1:                 episode reward: 1.3741,                 loss: 0.2054
Episode: 19701/30000 (65.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8439s / 1644.2542 s
agent0:                 episode reward: -1.1244,                 loss: nan
agent1:                 episode reward: 1.1244,                 loss: 0.2084
Episode: 19721/30000 (65.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8618s / 1646.1160 s
agent0:                 episode reward: -1.2963,                 loss: nan
agent1:                 episode reward: 1.2963,                 loss: 0.2085
Episode: 19741/30000 (65.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9429s / 1648.0589 s
agent0:                 episode reward: -0.7159,                 loss: nan
agent1:                 episode reward: 0.7159,                 loss: 0.2081
Episode: 19761/30000 (65.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0424s / 1650.1013 s
agent0:                 episode reward: -1.4464,                 loss: nan
agent1:                 episode reward: 1.4464,                 loss: 0.2070
Episode: 19781/30000 (65.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1372s / 1652.2385 s
agent0:                 episode reward: -1.1621,                 loss: nan
agent1:                 episode reward: 1.1621,                 loss: 0.1692
Episode: 19801/30000 (66.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9801s / 1654.2186 s
agent0:                 episode reward: -1.9051,                 loss: nan
agent1:                 episode reward: 1.9051,                 loss: 0.1519
Episode: 19821/30000 (66.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0251s / 1656.2436 s
agent0:                 episode reward: -1.1301,                 loss: nan
agent1:                 episode reward: 1.1301,                 loss: 0.1501
Episode: 19841/30000 (66.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0330s / 1658.2766 s
agent0:                 episode reward: -1.3006,                 loss: nan
agent1:                 episode reward: 1.3006,                 loss: 0.1495
Episode: 19861/30000 (66.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0015s / 1660.2781 s
agent0:                 episode reward: -1.3193,                 loss: nan
agent1:                 episode reward: 1.3193,                 loss: 0.1511
Episode: 19881/30000 (66.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0000s / 1662.2781 s
agent0:                 episode reward: -1.0013,                 loss: nan
agent1:                 episode reward: 1.0013,                 loss: 0.1212
Episode: 19901/30000 (66.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0112s / 1664.2894 s
agent0:                 episode reward: -1.1559,                 loss: nan
agent1:                 episode reward: 1.1559,                 loss: 0.1078
Episode: 19921/30000 (66.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1223s / 1666.4116 s
agent0:                 episode reward: -1.0097,                 loss: nan
agent1:                 episode reward: 1.0097,                 loss: 0.1083
Episode: 19941/30000 (66.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0778s / 1668.4894 s
agent0:                 episode reward: -1.0146,                 loss: nan
agent1:                 episode reward: 1.0146,                 loss: 0.1073
Episode: 19961/30000 (66.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0794s / 1670.5689 s
agent0:                 episode reward: -1.1654,                 loss: nan
agent1:                 episode reward: 1.1654,                 loss: 0.1070
Episode: 19981/30000 (66.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1233s / 1672.6922 s
agent0:                 episode reward: -1.0935,                 loss: nan
agent1:                 episode reward: 1.0935,                 loss: 0.1171
Episode: 20001/30000 (66.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0922s / 1674.7844 s
agent0:                 episode reward: -0.8829,                 loss: nan
agent1:                 episode reward: 0.8829,                 loss: 0.1103
Episode: 20021/30000 (66.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1065s / 1676.8909 s
agent0:                 episode reward: -1.0283,                 loss: nan
agent1:                 episode reward: 1.0283,                 loss: 0.1104
Episode: 20041/30000 (66.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0684s / 1678.9593 s
agent0:                 episode reward: -2.0149,                 loss: nan
agent1:                 episode reward: 2.0149,                 loss: 0.1111
Episode: 20061/30000 (66.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1059s / 1681.0653 s
agent0:                 episode reward: -1.2679,                 loss: nan
agent1:                 episode reward: 1.2679,                 loss: 0.1089
Episode: 20081/30000 (66.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0856s / 1683.1509 s
agent0:                 episode reward: -1.7205,                 loss: nan
agent1:                 episode reward: 1.7205,                 loss: 0.1577
Episode: 20101/30000 (67.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0769s / 1685.2279 s
agent0:                 episode reward: -1.5515,                 loss: nan
agent1:                 episode reward: 1.5515,                 loss: 0.1619
Episode: 20121/30000 (67.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2973s / 1687.5252 s
agent0:                 episode reward: -1.3933,                 loss: nan
agent1:                 episode reward: 1.3933,                 loss: 0.1606
Episode: 20141/30000 (67.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1556s / 1689.6808 s
agent0:                 episode reward: -1.7553,                 loss: nan
agent1:                 episode reward: 1.7553,                 loss: 0.1617
Episode: 20161/30000 (67.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0425s / 1691.7233 s
agent0:                 episode reward: -1.0825,                 loss: nan
agent1:                 episode reward: 1.0825,                 loss: 0.1618
Episode: 20181/30000 (67.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1147s / 1693.8380 s
agent0:                 episode reward: -2.1114,                 loss: nan
agent1:                 episode reward: 2.1114,                 loss: 0.2258
Episode: 20201/30000 (67.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1972s / 1696.0352 s
agent0:                 episode reward: -1.2330,                 loss: nan
agent1:                 episode reward: 1.2330,                 loss: 0.2304
Episode: 20221/30000 (67.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0910s / 1698.1262 s
agent0:                 episode reward: -1.0437,                 loss: nan
agent1:                 episode reward: 1.0437,                 loss: 0.2292
Episode: 20241/30000 (67.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1347s / 1700.2609 s
agent0:                 episode reward: -1.3861,                 loss: nan
agent1:                 episode reward: 1.3861,                 loss: 0.2303
Episode: 20261/30000 (67.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1156s / 1702.3765 s
agent0:                 episode reward: -1.1826,                 loss: nan
agent1:                 episode reward: 1.1826,                 loss: 0.2284
Episode: 20281/30000 (67.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.3358s / 1704.7123 s
agent0:                 episode reward: -0.8852,                 loss: nan
agent1:                 episode reward: 0.8852,                 loss: 0.2589
Episode: 20301/30000 (67.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2690s / 1706.9813 s
agent0:                 episode reward: -0.9220,                 loss: nan
agent1:                 episode reward: 0.9220,                 loss: 0.2509
Episode: 20321/30000 (67.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.3717s / 1709.3530 s
agent0:                 episode reward: -0.9086,                 loss: nan
agent1:                 episode reward: 0.9086,                 loss: 0.2510
Episode: 20341/30000 (67.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2561s / 1711.6091 s
agent0:                 episode reward: -0.7568,                 loss: nan
agent1:                 episode reward: 0.7568,                 loss: 0.2477
Episode: 20361/30000 (67.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2269s / 1713.8360 s
agent0:                 episode reward: -1.1617,                 loss: nan
agent1:                 episode reward: 1.1617,                 loss: 0.2473
Episode: 20381/30000 (67.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2641s / 1716.1001 s
agent0:                 episode reward: -0.1028,                 loss: nan
agent1:                 episode reward: 0.1028,                 loss: 0.2085
Episode: 20401/30000 (68.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1989s / 1718.2990 s
agent0:                 episode reward: -1.1233,                 loss: nan
agent1:                 episode reward: 1.1233,                 loss: 0.1913
Episode: 20421/30000 (68.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0880s / 1720.3870 s
agent0:                 episode reward: -0.8576,                 loss: nan
agent1:                 episode reward: 0.8576,                 loss: 0.1915
Episode: 20441/30000 (68.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0603s / 1722.4472 s
agent0:                 episode reward: -0.5504,                 loss: nan
agent1:                 episode reward: 0.5504,                 loss: 0.1902
Episode: 20461/30000 (68.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1142s / 1724.5614 s
agent0:                 episode reward: -0.3436,                 loss: nan
agent1:                 episode reward: 0.3436,                 loss: 0.1924
Episode: 20481/30000 (68.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0742s / 1726.6356 s
agent0:                 episode reward: -1.0722,                 loss: nan
agent1:                 episode reward: 1.0722,                 loss: 0.1568
Episode: 20501/30000 (68.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0414s / 1728.6771 s
agent0:                 episode reward: -1.1047,                 loss: nan
agent1:                 episode reward: 1.1047,                 loss: 0.1392
Episode: 20521/30000 (68.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0941s / 1730.7711 s
agent0:                 episode reward: -1.2242,                 loss: nan
agent1:                 episode reward: 1.2242,                 loss: 0.1408
Episode: 20541/30000 (68.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0790s / 1732.8502 s
agent0:                 episode reward: -1.1890,                 loss: nan
agent1:                 episode reward: 1.1890,                 loss: 0.1370
Episode: 20561/30000 (68.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1245s / 1734.9747 s
agent0:                 episode reward: -1.3199,                 loss: nan
agent1:                 episode reward: 1.3199,                 loss: 0.1389
Episode: 20581/30000 (68.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0621s / 1737.0368 s
agent0:                 episode reward: -1.1393,                 loss: nan
agent1:                 episode reward: 1.1393,                 loss: 0.1537
Episode: 20601/30000 (68.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0726s / 1739.1094 s
agent0:                 episode reward: -1.9407,                 loss: nan
agent1:                 episode reward: 1.9407,                 loss: 0.1503
Episode: 20621/30000 (68.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0862s / 1741.1956 s
agent0:                 episode reward: -1.0859,                 loss: nan
agent1:                 episode reward: 1.0859,                 loss: 0.1498
Episode: 20641/30000 (68.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.3419s / 1743.5376 s
agent0:                 episode reward: -1.6556,                 loss: nan
agent1:                 episode reward: 1.6556,                 loss: 0.1495
Episode: 20661/30000 (68.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2753s / 1745.8129 s
agent0:                 episode reward: -1.7205,                 loss: nan
agent1:                 episode reward: 1.7205,                 loss: 0.1495
Episode: 20681/30000 (68.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1134s / 1747.9263 s
agent0:                 episode reward: -1.1002,                 loss: nan
agent1:                 episode reward: 1.1002,                 loss: 0.1801
Episode: 20701/30000 (69.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1347s / 1750.0609 s
agent0:                 episode reward: -1.1409,                 loss: nan
agent1:                 episode reward: 1.1409,                 loss: 0.1773
Episode: 20721/30000 (69.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1633s / 1752.2242 s
agent0:                 episode reward: -1.4476,                 loss: nan
agent1:                 episode reward: 1.4476,                 loss: 0.1763
Episode: 20741/30000 (69.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1627s / 1754.3870 s
agent0:                 episode reward: -0.9896,                 loss: nan
agent1:                 episode reward: 0.9896,                 loss: 0.1754
Episode: 20761/30000 (69.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1476s / 1756.5346 s/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -1.0827,                 loss: nan
agent1:                 episode reward: 1.0827,                 loss: 0.1758
Episode: 20781/30000 (69.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1231s / 1758.6576 s
agent0:                 episode reward: -1.1504,                 loss: nan
agent1:                 episode reward: 1.1504,                 loss: 0.1557
Episode: 20801/30000 (69.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1327s / 1760.7903 s
agent0:                 episode reward: -0.8397,                 loss: nan
agent1:                 episode reward: 0.8397,                 loss: 0.1425
Episode: 20821/30000 (69.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1530s / 1762.9433 s
agent0:                 episode reward: -1.1535,                 loss: nan
agent1:                 episode reward: 1.1535,                 loss: 0.1446
Episode: 20841/30000 (69.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1791s / 1765.1223 s
agent0:                 episode reward: -1.4482,                 loss: nan
agent1:                 episode reward: 1.4482,                 loss: 0.1445
Episode: 20861/30000 (69.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1185s / 1767.2409 s
agent0:                 episode reward: -1.4869,                 loss: nan
agent1:                 episode reward: 1.4869,                 loss: 0.1425
Episode: 20881/30000 (69.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1441s / 1769.3850 s
agent0:                 episode reward: -1.1710,                 loss: nan
agent1:                 episode reward: 1.1710,                 loss: 0.1226
Traceback (most recent call last):
  File "exploit_arbitrary_mdp2.py", line 50, in <module>
    parser_args = parser.parse_args()
  File "exploit_arbitrary_mdp2.py", line 42, in launch_rollout
    ### Rollout
  File "/home/quantumiracle/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/home/quantumiracle/research/MARS/mars/rollout.py", line 161, in rollout_normal
    loss = model.update(
  File "/home/quantumiracle/research/MARS/mars/rl/agents/multiagent.py", line 281, in update
    loss = agent.update()
  File "/home/quantumiracle/research/MARS/mars/rl/agents/dqn.py", line 109, in update
    state, action, reward, next_state, done = self.buffer.sample(self.batch_size)
  File "/home/quantumiracle/research/MARS/mars/rl/common/storage.py", line 100, in sample
    sum_reward += (self.gamma**n) * per_env_buffer[i+n].reward
KeyboardInterrupt
