pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 51.0769s / 51.0769 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0129
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0102
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 1618.1775s / 1669.2544 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0192
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0191
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 1948.8611s / 3618.1155 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0192
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0186
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2045.9198s / 5664.0353 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0160
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0161
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2081.0349s / 7745.0702 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0157
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0158
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2089.6972s / 9834.7673 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0164
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0173
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2098.2096s / 11932.9770 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0159
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0160
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2101.3132s / 14034.2902 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0156
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0156
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2092.5524s / 16126.8426 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0171
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0175
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2102.3057s / 18229.1483 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0172
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0171
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2105.4842s / 20334.6325 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0164
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0160
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2092.7034s / 22427.3359 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0175
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0175
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2108.0052s / 24535.3410 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0157
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0161
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2081.1818s / 26616.5229 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0143
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0148
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2089.2366s / 28705.7595 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0157
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0153
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2094.2766s / 30800.0361 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0153
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0155
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2096.2028s / 32896.2389 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0161
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0166
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2090.5553s / 34986.7942 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0167
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0166
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2092.3025s / 37079.0967 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0167
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0166
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2430.1962s / 39509.2928 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0175
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0174
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2463.0806s / 41972.3734 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0162
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0169
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2450.7330s / 44423.1064 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0171
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0175
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2439.4172s / 46862.5236 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0169
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0171
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2435.6535s / 49298.1772 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0164
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0163
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2442.8004s / 51740.9776 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0188
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0176
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2441.4123s / 54182.3899 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0190
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0179
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2439.8822s / 56622.2722 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0167
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0172
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2434.9065s / 59057.1787 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0173
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0176
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2431.0755s / 61488.2542 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0174
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0181
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2449.6703s / 63937.9245 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0187
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0193
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2444.8610s / 66382.7855 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0212
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0214
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2446.1136s / 68828.8991 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0211
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0218
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2432.8460s / 71261.7451 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0278
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0252
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2439.6616s / 73701.4067 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0332
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0296
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2436.5827s / 76137.9894 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0342
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0319
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2442.3700s / 78580.3594 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0384
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0341
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2443.2181s / 81023.5775 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0393
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0400
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2438.3471s / 83461.9246 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0328
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0393
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2435.6656s / 85897.5902 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0335
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0304
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2443.4273s / 88341.0175 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0382
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0385
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2433.2983s / 90774.3158 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0427
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0460
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2447.0824s / 93221.3982 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0540
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0552
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2428.3094s / 95649.7076 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0591
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0613
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2405.5053s / 98055.2128 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0453
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0432
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2392.3614s / 100447.5743 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0396
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0364
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2395.3503s / 102842.9245 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0517
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0346
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2388.2471s / 105231.1716 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0782
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0627
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2394.9266s / 107626.0982 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0679
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0697
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2402.6099s / 110028.7081 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0522
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0562
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2394.3947s / 112423.1028 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0485
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0549
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2395.7516s / 114818.8544 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0484
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0542
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2403.9066s / 117222.7611 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0545
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0531
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2390.8400s / 119613.6010 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0510
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0538
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2405.8659s / 122019.4669 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0605
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0598
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2402.6202s / 124422.0871 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0551
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0545
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2391.4869s / 126813.5740 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0571
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0555
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2395.6871s / 129209.2611 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0588
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0501
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2400.0550s / 131609.3161 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0636
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0591
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1774.4,                last time consumption/overall running time: 2376.1499s / 133985.4661 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0656
env0_second_0:                 episode reward: 16.8000,                 loss: 0.0679
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2398.7876s / 136384.2536 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0727
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0726
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2398.3699s / 138782.6235 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0621
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0625
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2398.5402s / 141181.1637 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0715
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0634
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1771.6,                last time consumption/overall running time: 2384.5939s / 143565.7576 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0925
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0764
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1757.7,                last time consumption/overall running time: 2335.9519s / 145901.7094 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0986
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0861
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2343.1356s / 148244.8450 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0942
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0760
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2353.2249s / 150598.0699 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0684
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0712
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1773.45,                last time consumption/overall running time: 2319.7203s / 152917.7902 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.0785
env0_second_0:                 episode reward: 17.6500,                 loss: 0.0806
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1723.7,                last time consumption/overall running time: 2253.8819s / 155171.6721 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.1100
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0863
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1732.8,                last time consumption/overall running time: 2253.7982s / 157425.4703 s
env0_first_0:                 episode reward: -31.1000,                 loss: 0.1393
env0_second_0:                 episode reward: 31.1000,                 loss: 0.1119
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1761.2,                last time consumption/overall running time: 2297.0492s / 159722.5195 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.1359
env0_second_0:                 episode reward: 20.6500,                 loss: 0.1337
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1759.05,                last time consumption/overall running time: 2284.2894s / 162006.8089 s
env0_first_0:                 episode reward: -22.9500,                 loss: 0.1008
env0_second_0:                 episode reward: 22.9500,                 loss: 0.1268
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1688.75,                last time consumption/overall running time: 2195.0514s / 164201.8603 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.1036
env0_second_0:                 episode reward: 25.1500,                 loss: 0.1245
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1715.15,                last time consumption/overall running time: 2204.3536s / 166406.2138 s
env0_first_0:                 episode reward: -30.8000,                 loss: 0.1336
env0_second_0:                 episode reward: 30.8000,                 loss: 0.1339
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1664.85,                last time consumption/overall running time: 2139.6171s / 168545.8309 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.1890
env0_second_0:                 episode reward: 20.8000,                 loss: 0.1535
env1_first_0:                 episode reward: -27.9500,                 loss: nan
env1_second_0:                 episode reward: 27.9500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1489.3,                last time consumption/overall running time: 1915.7661s / 170461.5971 s
env0_first_0:                 episode reward: -35.0000,                 loss: 0.2090
env0_second_0:                 episode reward: 35.0000,                 loss: 0.1756
env1_first_0:                 episode reward: -41.3500,                 loss: nan
env1_second_0:                 episode reward: 41.3500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1541.9,                last time consumption/overall running time: 1986.0406s / 172447.6377 s
env0_first_0:                 episode reward: -41.1500,                 loss: 0.2448
env0_second_0:                 episode reward: 41.1500,                 loss: 0.2378
env1_first_0:                 episode reward: -38.1000,                 loss: nan
env1_second_0:                 episode reward: 38.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1381.7,                last time consumption/overall running time: 1788.1704s / 174235.8081 s
env0_first_0:                 episode reward: -42.6000,                 loss: 0.2730
env0_second_0:                 episode reward: 42.6000,                 loss: 0.2578
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1485.25,                last time consumption/overall running time: 1926.2359s / 176162.0440 s
env0_first_0:                 episode reward: -36.5500,                 loss: 0.2736
env0_second_0:                 episode reward: 36.5500,                 loss: 0.2579
env1_first_0:                 episode reward: -34.2500,                 loss: nan
env1_second_0:                 episode reward: 34.2500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1378.5,                last time consumption/overall running time: 1776.7782s / 177938.8222 s
env0_first_0:                 episode reward: -39.9000,                 loss: 0.3113
env0_second_0:                 episode reward: 39.9000,                 loss: 0.2340
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1169.1,                last time consumption/overall running time: 1499.8282s / 179438.6505 s
env0_first_0:                 episode reward: -40.8500,                 loss: 0.3105
env0_second_0:                 episode reward: 40.8500,                 loss: 0.2554
env1_first_0:                 episode reward: -45.8000,                 loss: nan
env1_second_0:                 episode reward: 45.8000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1265.2,                last time consumption/overall running time: 1619.3118s / 181057.9623 s
env0_first_0:                 episode reward: -31.9000,                 loss: 0.2956
env0_second_0:                 episode reward: 31.9000,                 loss: 0.2458
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 966.5,                last time consumption/overall running time: 1246.2546s / 182304.2169 s
env0_first_0:                 episode reward: -47.3500,                 loss: 0.2998
env0_second_0:                 episode reward: 47.3500,                 loss: 0.2671
env1_first_0:                 episode reward: -45.7000,                 loss: nan
env1_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1073.65,                last time consumption/overall running time: 1376.5357s / 183680.7527 s
env0_first_0:                 episode reward: -41.4000,                 loss: 0.2967
env0_second_0:                 episode reward: 41.4000,                 loss: 0.3031
env1_first_0:                 episode reward: -47.3000,                 loss: nan
env1_second_0:                 episode reward: 47.3000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 886.65,                last time consumption/overall running time: 1135.5705s / 184816.3232 s
env0_first_0:                 episode reward: -44.8500,                 loss: 0.3465
env0_second_0:                 episode reward: 44.8500,                 loss: 0.3252
env1_first_0:                 episode reward: -65.3500,                 loss: nan
env1_second_0:                 episode reward: 65.3500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 961.1,                last time consumption/overall running time: 1232.9911s / 186049.3143 s
env0_first_0:                 episode reward: -49.6500,                 loss: 0.3972
env0_second_0:                 episode reward: 49.6500,                 loss: 0.3621
env1_first_0:                 episode reward: -47.0000,                 loss: nan
env1_second_0:                 episode reward: 47.0000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1020.5,                last time consumption/overall running time: 1299.4828s / 187348.7971 s
env0_first_0:                 episode reward: -47.9000,                 loss: 0.4747
env0_second_0:                 episode reward: 47.9000,                 loss: 0.3715
env1_first_0:                 episode reward: -47.7500,                 loss: nan
env1_second_0:                 episode reward: 47.7500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 768.2,                last time consumption/overall running time: 976.6485s / 188325.4456 s
env0_first_0:                 episode reward: -45.5000,                 loss: 0.4902
env0_second_0:                 episode reward: 45.5000,                 loss: 0.3505
env1_first_0:                 episode reward: -52.3000,                 loss: nan
env1_second_0:                 episode reward: 52.3000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 816.6,                last time consumption/overall running time: 1042.4295s / 189367.8751 s
env0_first_0:                 episode reward: -53.0000,                 loss: 0.5291
env0_second_0:                 episode reward: 53.0000,                 loss: 0.3713
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 697.4,                last time consumption/overall running time: 881.5019s / 190249.3770 s
env0_first_0:                 episode reward: -46.1500,                 loss: 0.5374
env0_second_0:                 episode reward: 46.1500,                 loss: 0.4030
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 652.5,                last time consumption/overall running time: 825.8903s / 191075.2673 s
env0_first_0:                 episode reward: -48.5500,                 loss: 0.5548
env0_second_0:                 episode reward: 48.5500,                 loss: 0.4355
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 612.55,                last time consumption/overall running time: 767.5097s / 191842.7770 s
env0_first_0:                 episode reward: -67.7500,                 loss: 0.5896
env0_second_0:                 episode reward: 67.7500,                 loss: 0.4676
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 644.55,                last time consumption/overall running time: 803.7281s / 192646.5051 s
env0_first_0:                 episode reward: -44.3500,                 loss: 0.5836
env0_second_0:                 episode reward: 44.3500,                 loss: 0.5021
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 621.8,                last time consumption/overall running time: 778.0387s / 193424.5439 s
env0_first_0:                 episode reward: -52.8000,                 loss: 0.5948
env0_second_0:                 episode reward: 52.8000,                 loss: 0.5197
env1_first_0:                 episode reward: -60.3500,                 loss: nan
env1_second_0:                 episode reward: 60.3500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 624.2,                last time consumption/overall running time: 781.3169s / 194205.8607 s
env0_first_0:                 episode reward: -49.2000,                 loss: 0.6487
env0_second_0:                 episode reward: 49.2000,                 loss: 0.5347
env1_first_0:                 episode reward: -55.5000,                 loss: nan
env1_second_0:                 episode reward: 55.5000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 596.55,                last time consumption/overall running time: 746.2595s / 194952.1202 s
env0_first_0:                 episode reward: -68.3500,                 loss: 0.6293
env0_second_0:                 episode reward: 68.3500,                 loss: 0.6278
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 559.5,                last time consumption/overall running time: 698.2200s / 195650.3403 s
env0_first_0:                 episode reward: -51.4000,                 loss: 0.6646
env0_second_0:                 episode reward: 51.4000,                 loss: 0.6375
env1_first_0:                 episode reward: -62.6000,                 loss: nan
env1_second_0:                 episode reward: 62.6000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 600.0,                last time consumption/overall running time: 753.5515s / 196403.8918 s
env0_first_0:                 episode reward: -51.2500,                 loss: 0.6744
env0_second_0:                 episode reward: 51.2500,                 loss: 0.6050
env1_first_0:                 episode reward: -69.5000,                 loss: nan
env1_second_0:                 episode reward: 69.5000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 615.1,                last time consumption/overall running time: 760.7196s / 197164.6114 s
env0_first_0:                 episode reward: -61.2000,                 loss: 0.6463
env0_second_0:                 episode reward: 61.2000,                 loss: 0.6795
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 508.45,                last time consumption/overall running time: 630.6209s / 197795.2324 s
env0_first_0:                 episode reward: -65.2500,                 loss: 0.6715
env0_second_0:                 episode reward: 65.2500,                 loss: 0.7326
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 606.55,                last time consumption/overall running time: 757.3104s / 198552.5427 s
env0_first_0:                 episode reward: -51.2500,                 loss: 0.7380
env0_second_0:                 episode reward: 51.2500,                 loss: 0.7498
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 488.6,                last time consumption/overall running time: 606.2633s / 199158.8061 s
env0_first_0:                 episode reward: -61.0500,                 loss: 0.8215
env0_second_0:                 episode reward: 61.0500,                 loss: 0.7433
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 453.75,                last time consumption/overall running time: 558.8122s / 199717.6183 s
env0_first_0:                 episode reward: -62.8500,                 loss: 0.7834
env0_second_0:                 episode reward: 62.8500,                 loss: 0.6804
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 574.05,                last time consumption/overall running time: 703.5556s / 200421.1739 s
env0_first_0:                 episode reward: -60.0500,                 loss: 0.7822
env0_second_0:                 episode reward: 60.0500,                 loss: 0.6638
env1_first_0:                 episode reward: -55.5000,                 loss: nan
env1_second_0:                 episode reward: 55.5000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 475.55,                last time consumption/overall running time: 579.3124s / 201000.4863 s
env0_first_0:                 episode reward: -55.3500,                 loss: 0.9002
env0_second_0:                 episode reward: 55.3500,                 loss: 0.6198
env1_first_0:                 episode reward: -71.7500,                 loss: nan
env1_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 482.8,                last time consumption/overall running time: 583.6238s / 201584.1102 s
env0_first_0:                 episode reward: -62.4500,                 loss: 0.9661
env0_second_0:                 episode reward: 62.4500,                 loss: 0.6554
env1_first_0:                 episode reward: -60.9500,                 loss: nan
env1_second_0:                 episode reward: 60.9500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 424.75,                last time consumption/overall running time: 514.0031s / 202098.1133 s
env0_first_0:                 episode reward: -50.1000,                 loss: 0.9938
env0_second_0:                 episode reward: 50.1000,                 loss: 0.6613
env1_first_0:                 episode reward: -67.3500,                 loss: nan
env1_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 455.95,                last time consumption/overall running time: 549.3807s / 202647.4940 s
env0_first_0:                 episode reward: -66.0500,                 loss: 1.0327
env0_second_0:                 episode reward: 66.0500,                 loss: 0.6793
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 600.55,                last time consumption/overall running time: 734.8109s / 203382.3049 s
env0_first_0:                 episode reward: -51.2500,                 loss: 1.0591
env0_second_0:                 episode reward: 51.2500,                 loss: 0.6998
env1_first_0:                 episode reward: -61.3000,                 loss: nan
env1_second_0:                 episode reward: 61.3000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 472.6,                last time consumption/overall running time: 574.6599s / 203956.9648 s
env0_first_0:                 episode reward: -62.8500,                 loss: 1.1084
env0_second_0:                 episode reward: 62.8500,                 loss: 0.6890
env1_first_0:                 episode reward: -75.3500,                 loss: nan
env1_second_0:                 episode reward: 75.3500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 496.55,                last time consumption/overall running time: 602.3874s / 204559.3523 s
env0_first_0:                 episode reward: -63.1500,                 loss: 1.0867
env0_second_0:                 episode reward: 63.1500,                 loss: 0.6783
env1_first_0:                 episode reward: -59.6000,                 loss: nan
env1_second_0:                 episode reward: 59.6000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 530.75,                last time consumption/overall running time: 649.9891s / 205209.3414 s
env0_first_0:                 episode reward: -65.8000,                 loss: 1.0382
env0_second_0:                 episode reward: 65.8000,                 loss: 0.6964
env1_first_0:                 episode reward: -51.7000,                 loss: nan
env1_second_0:                 episode reward: 51.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 509.35,                last time consumption/overall running time: 626.1339s / 205835.4753 s
env0_first_0:                 episode reward: -58.5500,                 loss: 1.0403
env0_second_0:                 episode reward: 58.5500,                 loss: 0.6975
env1_first_0:                 episode reward: -58.4500,                 loss: nan
env1_second_0:                 episode reward: 58.4500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 590.3,                last time consumption/overall running time: 722.2036s / 206557.6789 s
env0_first_0:                 episode reward: -41.7000,                 loss: 1.0140
env0_second_0:                 episode reward: 41.7000,                 loss: 0.7166
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 376.05,                last time consumption/overall running time: 462.5394s / 207020.2183 s
env0_first_0:                 episode reward: -48.8500,                 loss: 0.9269
env0_second_0:                 episode reward: 48.8500,                 loss: 0.7715
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 436.55,                last time consumption/overall running time: 533.1531s / 207553.3715 s
env0_first_0:                 episode reward: -38.2000,                 loss: 0.9129
env0_second_0:                 episode reward: 38.2000,                 loss: 0.7284
env1_first_0:                 episode reward: -76.9000,                 loss: nan
env1_second_0:                 episode reward: 76.9000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 528.15,                last time consumption/overall running time: 645.4157s / 208198.7871 s
env0_first_0:                 episode reward: -55.4000,                 loss: 0.9470
env0_second_0:                 episode reward: 55.4000,                 loss: 0.7267
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 566.5,                last time consumption/overall running time: 692.3519s / 208891.1391 s
env0_first_0:                 episode reward: -44.2500,                 loss: 0.8652
env0_second_0:                 episode reward: 44.2500,                 loss: 0.7614
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 591.65,                last time consumption/overall running time: 722.2864s / 209613.4255 s
env0_first_0:                 episode reward: -52.2500,                 loss: 0.8545
env0_second_0:                 episode reward: 52.2500,                 loss: 0.7579
env1_first_0:                 episode reward: -44.3500,                 loss: nan
env1_second_0:                 episode reward: 44.3500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 478.5,                last time consumption/overall running time: 587.2250s / 210200.6504 s
env0_first_0:                 episode reward: -50.0000,                 loss: 0.8505
env0_second_0:                 episode reward: 50.0000,                 loss: 0.7101
env1_first_0:                 episode reward: -62.6000,                 loss: nan
env1_second_0:                 episode reward: 62.6000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 735.15,                last time consumption/overall running time: 903.5613s / 211104.2118 s
env0_first_0:                 episode reward: -40.5000,                 loss: 0.8426
env0_second_0:                 episode reward: 40.5000,                 loss: 0.7128
env1_first_0:                 episode reward: -44.4000,                 loss: nan
env1_second_0:                 episode reward: 44.4000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 608.45,                last time consumption/overall running time: 745.7638s / 211849.9756 s
env0_first_0:                 episode reward: -64.7000,                 loss: 0.7793
env0_second_0:                 episode reward: 64.7000,                 loss: 0.6829
env1_first_0:                 episode reward: -54.4500,                 loss: nan
env1_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 559.2,                last time consumption/overall running time: 686.5448s / 212536.5204 s
env0_first_0:                 episode reward: -58.6500,                 loss: 0.7390
env0_second_0:                 episode reward: 58.6500,                 loss: 0.6933
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 531.85,                last time consumption/overall running time: 651.5426s / 213188.0630 s
env0_first_0:                 episode reward: -63.4000,                 loss: 0.7775
env0_second_0:                 episode reward: 63.4000,                 loss: 0.7200
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 593.45,                last time consumption/overall running time: 725.0574s / 213913.1204 s
env0_first_0:                 episode reward: -48.7000,                 loss: 0.7916
env0_second_0:                 episode reward: 48.7000,                 loss: 0.7814
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 632.7,                last time consumption/overall running time: 765.0305s / 214678.1509 s
env0_first_0:                 episode reward: -58.8500,                 loss: 0.9051
env0_second_0:                 episode reward: 58.8500,                 loss: 0.7874
env1_first_0:                 episode reward: -44.4500,                 loss: nan
env1_second_0:                 episode reward: 44.4500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 539.15,                last time consumption/overall running time: 654.2356s / 215332.3865 s
env0_first_0:                 episode reward: -59.9000,                 loss: 0.9455
env0_second_0:                 episode reward: 59.9000,                 loss: 0.7901
env1_first_0:                 episode reward: -42.0500,                 loss: nan
env1_second_0:                 episode reward: 42.0500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 509.55,                last time consumption/overall running time: 617.1635s / 215949.5500 s
env0_first_0:                 episode reward: -71.7500,                 loss: 1.0447
env0_second_0:                 episode reward: 71.7500,                 loss: 0.8061
env1_first_0:                 episode reward: -48.8500,                 loss: nan
env1_second_0:                 episode reward: 48.8500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 564.4,                last time consumption/overall running time: 688.7193s / 216638.2693 s
env0_first_0:                 episode reward: -62.0500,                 loss: 1.0788
env0_second_0:                 episode reward: 62.0500,                 loss: 0.8358
env1_first_0:                 episode reward: -56.4500,                 loss: nan
env1_second_0:                 episode reward: 56.4500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 557.25,                last time consumption/overall running time: 665.7899s / 217304.0592 s
env0_first_0:                 episode reward: -42.2500,                 loss: 1.0670
env0_second_0:                 episode reward: 42.2500,                 loss: 0.8078
env1_first_0:                 episode reward: -62.4500,                 loss: nan
env1_second_0:                 episode reward: 62.4500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 499.1,                last time consumption/overall running time: 595.1877s / 217899.2469 s
env0_first_0:                 episode reward: -54.4000,                 loss: 1.1869
env0_second_0:                 episode reward: 54.4000,                 loss: 0.8060
env1_first_0:                 episode reward: -70.9500,                 loss: nan
env1_second_0:                 episode reward: 70.9500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 524.6,                last time consumption/overall running time: 627.1278s / 218526.3747 s
env0_first_0:                 episode reward: -52.9000,                 loss: 1.1912
env0_second_0:                 episode reward: 52.9000,                 loss: 0.8180
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 487.8,                last time consumption/overall running time: 588.6638s / 219115.0386 s
env0_first_0:                 episode reward: -83.8000,                 loss: 1.1833
env0_second_0:                 episode reward: 83.8000,                 loss: 0.8725
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 473.7,                last time consumption/overall running time: 568.5324s / 219683.5710 s
env0_first_0:                 episode reward: -59.8500,                 loss: 1.2028
env0_second_0:                 episode reward: 59.8500,                 loss: 0.9090
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 405.45,                last time consumption/overall running time: 485.6021s / 220169.1730 s
env0_first_0:                 episode reward: -56.2500,                 loss: 1.1869
env0_second_0:                 episode reward: 56.2500,                 loss: 0.9355
env1_first_0:                 episode reward: -60.0000,                 loss: nan
env1_second_0:                 episode reward: 60.0000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 522.4,                last time consumption/overall running time: 624.7935s / 220793.9666 s
env0_first_0:                 episode reward: -48.3000,                 loss: 1.1670
env0_second_0:                 episode reward: 48.3000,                 loss: 0.9116
env1_first_0:                 episode reward: -72.5000,                 loss: nan
env1_second_0:                 episode reward: 72.5000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 507.05,                last time consumption/overall running time: 610.5992s / 221404.5658 s
env0_first_0:                 episode reward: -66.4500,                 loss: 1.1554
env0_second_0:                 episode reward: 66.4500,                 loss: 0.9648
env1_first_0:                 episode reward: -61.6000,                 loss: nan
env1_second_0:                 episode reward: 61.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 491.15,                last time consumption/overall running time: 586.8549s / 221991.4207 s
env0_first_0:                 episode reward: -73.3500,                 loss: 1.1482
env0_second_0:                 episode reward: 73.3500,                 loss: 0.9314
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 580.95,                last time consumption/overall running time: 693.7266s / 222685.1473 s
env0_first_0:                 episode reward: -61.3500,                 loss: 1.2013
env0_second_0:                 episode reward: 61.3500,                 loss: 1.0108
env1_first_0:                 episode reward: -48.3000,                 loss: nan
env1_second_0:                 episode reward: 48.3000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 415.15,                last time consumption/overall running time: 496.4555s / 223181.6028 s
env0_first_0:                 episode reward: -72.0000,                 loss: 1.2323
env0_second_0:                 episode reward: 72.0000,                 loss: 1.0593
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 625.95,                last time consumption/overall running time: 748.4916s / 223930.0944 s
env0_first_0:                 episode reward: -58.9000,                 loss: 1.1713
env0_second_0:                 episode reward: 58.9000,                 loss: 1.0970
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 568.05,                last time consumption/overall running time: 674.4403s / 224604.5347 s
env0_first_0:                 episode reward: -51.3000,                 loss: 1.1635
env0_second_0:                 episode reward: 51.3000,                 loss: 1.0895
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 479.5,                last time consumption/overall running time: 571.8404s / 225176.3751 s
env0_first_0:                 episode reward: -50.0500,                 loss: 1.1796
env0_second_0:                 episode reward: 50.0500,                 loss: 1.0519
env1_first_0:                 episode reward: -54.1000,                 loss: nan
env1_second_0:                 episode reward: 54.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 482.55,                last time consumption/overall running time: 570.7337s / 225747.1088 s
env0_first_0:                 episode reward: -77.9500,                 loss: 1.1776
env0_second_0:                 episode reward: 77.9500,                 loss: 0.9958
env1_first_0:                 episode reward: -45.2500,                 loss: nan
env1_second_0:                 episode reward: 45.2500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 434.65,                last time consumption/overall running time: 517.5473s / 226264.6561 s
env0_first_0:                 episode reward: -71.1000,                 loss: 1.1394
env0_second_0:                 episode reward: 71.1000,                 loss: 1.0107
env1_first_0:                 episode reward: -63.9000,                 loss: nan
env1_second_0:                 episode reward: 63.9000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 533.95,                last time consumption/overall running time: 637.1708s / 226901.8270 s
env0_first_0:                 episode reward: -65.0000,                 loss: 1.1361
env0_second_0:                 episode reward: 65.0000,                 loss: 1.0687
env1_first_0:                 episode reward: -46.0000,                 loss: nan
env1_second_0:                 episode reward: 46.0000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 694.95,                last time consumption/overall running time: 829.1778s / 227731.0047 s
env0_first_0:                 episode reward: -37.4500,                 loss: 1.1615
env0_second_0:                 episode reward: 37.4500,                 loss: 1.0394
env1_first_0:                 episode reward: -54.8500,                 loss: nan
env1_second_0:                 episode reward: 54.8500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 492.1,                last time consumption/overall running time: 583.1640s / 228314.1687 s
env0_first_0:                 episode reward: -57.4000,                 loss: 1.1619
env0_second_0:                 episode reward: 57.4000,                 loss: 1.1150
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 492.8,                last time consumption/overall running time: 580.1694s / 228894.3381 s
env0_first_0:                 episode reward: -50.4500,                 loss: 1.1941
env0_second_0:                 episode reward: 50.4500,                 loss: 1.0856
env1_first_0:                 episode reward: -56.5500,                 loss: nan
env1_second_0:                 episode reward: 56.5500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 698.3,                last time consumption/overall running time: 831.2397s / 229725.5778 s
env0_first_0:                 episode reward: -41.4000,                 loss: 1.1445
env0_second_0:                 episode reward: 41.4000,                 loss: 0.9824
env1_first_0:                 episode reward: -50.7500,                 loss: nan
env1_second_0:                 episode reward: 50.7500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 564.85,                last time consumption/overall running time: 685.9493s / 230411.5272 s
env0_first_0:                 episode reward: -41.1500,                 loss: 1.1291
env0_second_0:                 episode reward: 41.1500,                 loss: 1.0004
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 619.6,                last time consumption/overall running time: 752.4178s / 231163.9449 s
env0_first_0:                 episode reward: -53.9000,                 loss: 1.1294
env0_second_0:                 episode reward: 53.9000,                 loss: 1.0233
env1_first_0:                 episode reward: -52.5000,                 loss: nan
env1_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 447.0,                last time consumption/overall running time: 544.9079s / 231708.8529 s
env0_first_0:                 episode reward: -68.4000,                 loss: 1.1381
env0_second_0:                 episode reward: 68.4000,                 loss: 1.0209
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 461.95,                last time consumption/overall running time: 559.2877s / 232268.1406 s
env0_first_0:                 episode reward: -67.0000,                 loss: 1.1960
env0_second_0:                 episode reward: 67.0000,                 loss: 1.0757
env1_first_0:                 episode reward: -48.0500,                 loss: nan
env1_second_0:                 episode reward: 48.0500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 459.05,                last time consumption/overall running time: 554.7416s / 232822.8822 s
env0_first_0:                 episode reward: -63.4000,                 loss: 1.1809
env0_second_0:                 episode reward: 63.4000,                 loss: 1.1955
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 498.25,                last time consumption/overall running time: 603.9837s / 233426.8659 s
env0_first_0:                 episode reward: -68.1000,                 loss: 1.1715
env0_second_0:                 episode reward: 68.1000,                 loss: 1.1547
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 460.85,                last time consumption/overall running time: 566.8560s / 233993.7219 s
env0_first_0:                 episode reward: -55.5000,                 loss: 1.2906
env0_second_0:                 episode reward: 55.5000,                 loss: 1.2422
env1_first_0:                 episode reward: -65.5500,                 loss: nan
env1_second_0:                 episode reward: 65.5500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 370.05,                last time consumption/overall running time: 450.0318s / 234443.7537 s
env0_first_0:                 episode reward: -57.4000,                 loss: 1.3745
env0_second_0:                 episode reward: 57.4000,                 loss: 1.2470
env1_first_0:                 episode reward: -69.1000,                 loss: nan
env1_second_0:                 episode reward: 69.1000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 471.2,                last time consumption/overall running time: 570.7802s / 235014.5339 s
env0_first_0:                 episode reward: -52.5000,                 loss: 1.3998
env0_second_0:                 episode reward: 52.5000,                 loss: 1.3498
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 504.5,                last time consumption/overall running time: 622.2188s / 235636.7527 s
env0_first_0:                 episode reward: -59.5000,                 loss: 1.4518
env0_second_0:                 episode reward: 59.5000,                 loss: 1.3343
env1_first_0:                 episode reward: -58.6500,                 loss: nan
env1_second_0:                 episode reward: 58.6500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 402.65,                last time consumption/overall running time: 494.7306s / 236131.4833 s
env0_first_0:                 episode reward: -60.6000,                 loss: 1.3809
env0_second_0:                 episode reward: 60.6000,                 loss: 1.3393
env1_first_0:                 episode reward: -52.4500,                 loss: nan
env1_second_0:                 episode reward: 52.4500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 397.6,                last time consumption/overall running time: 487.3154s / 236618.7987 s
env0_first_0:                 episode reward: -50.4500,                 loss: 1.5147
env0_second_0:                 episode reward: 50.4500,                 loss: 1.3255
env1_first_0:                 episode reward: -72.0500,                 loss: nan
env1_second_0:                 episode reward: 72.0500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 519.75,                last time consumption/overall running time: 633.5046s / 237252.3032 s
env0_first_0:                 episode reward: -47.7500,                 loss: 1.4273
env0_second_0:                 episode reward: 47.7500,                 loss: 1.4035
env1_first_0:                 episode reward: -54.5000,                 loss: nan
env1_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 566.6,                last time consumption/overall running time: 686.5460s / 237938.8492 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.3751
env0_second_0:                 episode reward: 55.6000,                 loss: 1.4075
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 462.05,                last time consumption/overall running time: 566.3965s / 238505.2457 s
env0_first_0:                 episode reward: -55.7000,                 loss: 1.4093
env0_second_0:                 episode reward: 55.7000,                 loss: 1.4504
env1_first_0:                 episode reward: -47.5500,                 loss: nan
env1_second_0:                 episode reward: 47.5500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 541.15,                last time consumption/overall running time: 725.5769s / 239230.8226 s
env0_first_0:                 episode reward: -57.4000,                 loss: 1.3720
env0_second_0:                 episode reward: 57.4000,                 loss: 1.3180
env1_first_0:                 episode reward: -58.0500,                 loss: nan
env1_second_0:                 episode reward: 58.0500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 542.1,                last time consumption/overall running time: 659.0031s / 239889.8257 s
env0_first_0:                 episode reward: -60.1000,                 loss: 1.3104
env0_second_0:                 episode reward: 60.1000,                 loss: 1.3483
env1_first_0:                 episode reward: -45.1000,                 loss: nan
env1_second_0:                 episode reward: 45.1000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 464.1,                last time consumption/overall running time: 568.2118s / 240458.0375 s
env0_first_0:                 episode reward: -71.8000,                 loss: 1.2399
env0_second_0:                 episode reward: 71.8000,                 loss: 1.3610
env1_first_0:                 episode reward: -46.0500,                 loss: nan
env1_second_0:                 episode reward: 46.0500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 478.75,                last time consumption/overall running time: 582.1989s / 241040.2364 s
env0_first_0:                 episode reward: -59.0500,                 loss: 1.2901
env0_second_0:                 episode reward: 59.0500,                 loss: 1.3667
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 611.05,                last time consumption/overall running time: 719.8650s / 241760.1014 s
env0_first_0:                 episode reward: -60.1500,                 loss: 1.1994
env0_second_0:                 episode reward: 60.1500,                 loss: 1.3291
env1_first_0:                 episode reward: -50.3500,                 loss: nan
env1_second_0:                 episode reward: 50.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 545.8,                last time consumption/overall running time: 646.1487s / 242406.2501 s
env0_first_0:                 episode reward: -41.4500,                 loss: 1.1256
env0_second_0:                 episode reward: 41.4500,                 loss: 1.3011
env1_first_0:                 episode reward: -67.8000,                 loss: nan
env1_second_0:                 episode reward: 67.8000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 549.25,                last time consumption/overall running time: 656.9481s / 243063.1982 s
env0_first_0:                 episode reward: -56.4500,                 loss: 1.1672
env0_second_0:                 episode reward: 56.4500,                 loss: 1.2409
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 527.35,                last time consumption/overall running time: 621.2775s / 243684.4757 s
env0_first_0:                 episode reward: -46.0000,                 loss: 1.2696
env0_second_0:                 episode reward: 46.0000,                 loss: 1.3011
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 440.85,                last time consumption/overall running time: 516.2416s / 244200.7173 s
env0_first_0:                 episode reward: -62.6500,                 loss: 1.3161
env0_second_0:                 episode reward: 62.6500,                 loss: 1.2595
env1_first_0:                 episode reward: -67.2500,                 loss: nan
env1_second_0:                 episode reward: 67.2500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 527.05,                last time consumption/overall running time: 621.2320s / 244821.9493 s
env0_first_0:                 episode reward: -52.2000,                 loss: 1.4493
env0_second_0:                 episode reward: 52.2000,                 loss: 1.1934
env1_first_0:                 episode reward: -55.3500,                 loss: nan
env1_second_0:                 episode reward: 55.3500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 607.05,                last time consumption/overall running time: 710.3968s / 245532.3461 s
env0_first_0:                 episode reward: -51.2000,                 loss: 1.4894
env0_second_0:                 episode reward: 51.2000,                 loss: 1.2676
env1_first_0:                 episode reward: -47.0500,                 loss: nan
env1_second_0:                 episode reward: 47.0500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 437.15,                last time consumption/overall running time: 516.3436s / 246048.6898 s
env0_first_0:                 episode reward: -55.4500,                 loss: 1.4005
env0_second_0:                 episode reward: 55.4500,                 loss: 1.1722
env1_first_0:                 episode reward: -65.5000,                 loss: nan
env1_second_0:                 episode reward: 65.5000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 527.75,                last time consumption/overall running time: 620.3604s / 246669.0501 s
env0_first_0:                 episode reward: -46.0000,                 loss: 1.4007
env0_second_0:                 episode reward: 46.0000,                 loss: 1.2316
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 465.05,                last time consumption/overall running time: 544.7483s / 247213.7985 s
env0_first_0:                 episode reward: -56.3500,                 loss: 1.3696
env0_second_0:                 episode reward: 56.3500,                 loss: 1.2959
env1_first_0:                 episode reward: -64.3500,                 loss: nan
env1_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 429.55,                last time consumption/overall running time: 506.2413s / 247720.0398 s
env0_first_0:                 episode reward: -55.7000,                 loss: 1.2987
env0_second_0:                 episode reward: 55.7000,                 loss: 1.3047
env1_first_0:                 episode reward: -56.4500,                 loss: nan
env1_second_0:                 episode reward: 56.4500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 582.95,                last time consumption/overall running time: 680.0691s / 248400.1089 s
env0_first_0:                 episode reward: -63.3000,                 loss: 1.2818
env0_second_0:                 episode reward: 63.3000,                 loss: 1.3583
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 392.55,                last time consumption/overall running time: 459.0055s / 248859.1144 s
env0_first_0:                 episode reward: -53.7000,                 loss: 1.2772
env0_second_0:                 episode reward: 53.7000,                 loss: 1.4356
env1_first_0:                 episode reward: -72.6500,                 loss: nan
env1_second_0:                 episode reward: 72.6500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 533.75,                last time consumption/overall running time: 626.8208s / 249485.9352 s
env0_first_0:                 episode reward: -51.2500,                 loss: 1.3360
env0_second_0:                 episode reward: 51.2500,                 loss: 1.5085
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 546.15,                last time consumption/overall running time: 639.9691s / 250125.9043 s
env0_first_0:                 episode reward: -54.7500,                 loss: 1.3530
env0_second_0:                 episode reward: 54.7500,                 loss: 1.4437
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 678.8,                last time consumption/overall running time: 795.5362s / 250921.4405 s
env0_first_0:                 episode reward: -37.9500,                 loss: 1.3410
env0_second_0:                 episode reward: 37.9500,                 loss: 1.4652
env1_first_0:                 episode reward: -60.2000,                 loss: nan
env1_second_0:                 episode reward: 60.2000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 608.3,                last time consumption/overall running time: 711.4498s / 251632.8903 s
env0_first_0:                 episode reward: -49.4500,                 loss: 1.2340
env0_second_0:                 episode reward: 49.4500,                 loss: 1.3634
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 524.4,                last time consumption/overall running time: 610.4841s / 252243.3743 s
env0_first_0:                 episode reward: -47.2500,                 loss: 1.2497
env0_second_0:                 episode reward: 47.2500,                 loss: 1.2282
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 505.85,                last time consumption/overall running time: 586.6645s / 252830.0388 s
env0_first_0:                 episode reward: -55.2500,                 loss: 1.1642
env0_second_0:                 episode reward: 55.2500,                 loss: 1.1820
env1_first_0:                 episode reward: -74.7500,                 loss: nan
env1_second_0:                 episode reward: 74.7500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 702.1,                last time consumption/overall running time: 812.9668s / 253643.0056 s
env0_first_0:                 episode reward: -51.3500,                 loss: 1.1607
env0_second_0:                 episode reward: 51.3500,                 loss: 1.1576
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 545.75,                last time consumption/overall running time: 638.1588s / 254281.1644 s
env0_first_0:                 episode reward: -52.2500,                 loss: 1.0790
env0_second_0:                 episode reward: 52.2500,                 loss: 1.1346
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 571.55,                last time consumption/overall running time: 661.8798s / 254943.0442 s
env0_first_0:                 episode reward: -59.5500,                 loss: 1.0926
env0_second_0:                 episode reward: 59.5500,                 loss: 1.1863
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 530.85,                last time consumption/overall running time: 615.4863s / 255558.5305 s
env0_first_0:                 episode reward: -41.5000,                 loss: 1.1431
env0_second_0:                 episode reward: 41.5000,                 loss: 1.2762
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 602.4,                last time consumption/overall running time: 701.7324s / 256260.2630 s
env0_first_0:                 episode reward: -50.7500,                 loss: 1.2384
env0_second_0:                 episode reward: 50.7500,                 loss: 1.3539
env1_first_0:                 episode reward: -55.0000,                 loss: nan
env1_second_0:                 episode reward: 55.0000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 490.0,                last time consumption/overall running time: 565.0657s / 256825.3286 s
env0_first_0:                 episode reward: -69.0000,                 loss: 1.1994
env0_second_0:                 episode reward: 69.0000,                 loss: 1.3535
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 500.9,                last time consumption/overall running time: 581.4182s / 257406.7468 s
env0_first_0:                 episode reward: -56.4000,                 loss: 1.1506
env0_second_0:                 episode reward: 56.4000,                 loss: 1.4051
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 533.9,                last time consumption/overall running time: 614.9272s / 258021.6740 s
env0_first_0:                 episode reward: -48.1000,                 loss: 1.1311
env0_second_0:                 episode reward: 48.1000,                 loss: 1.3936
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 510.65,                last time consumption/overall running time: 585.7073s / 258607.3813 s
env0_first_0:                 episode reward: -74.8500,                 loss: 1.1390
env0_second_0:                 episode reward: 74.8500,                 loss: 1.3176
env1_first_0:                 episode reward: -40.8000,                 loss: nan
env1_second_0:                 episode reward: 40.8000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 507.5,                last time consumption/overall running time: 580.9194s / 259188.3007 s
env0_first_0:                 episode reward: -59.8500,                 loss: 1.1763
env0_second_0:                 episode reward: 59.8500,                 loss: 1.3098
env1_first_0:                 episode reward: -45.6000,                 loss: nan
env1_second_0:                 episode reward: 45.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 518.9,                last time consumption/overall running time: 593.9985s / 259782.2992 s
env0_first_0:                 episode reward: -60.1500,                 loss: 1.2803
env0_second_0:                 episode reward: 60.1500,                 loss: 1.3081
env1_first_0:                 episode reward: -60.6000,                 loss: nan
env1_second_0:                 episode reward: 60.6000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 484.3,                last time consumption/overall running time: 561.9442s / 260344.2435 s
env0_first_0:                 episode reward: -57.2500,                 loss: 1.3254
env0_second_0:                 episode reward: 57.2500,                 loss: 1.3736
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 482.85,                last time consumption/overall running time: 555.2702s / 260899.5136 s
env0_first_0:                 episode reward: -49.7500,                 loss: 1.3998
env0_second_0:                 episode reward: 49.7500,                 loss: 1.2951
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 523.9,                last time consumption/overall running time: 602.3876s / 261501.9012 s
env0_first_0:                 episode reward: -73.9500,                 loss: 1.4352
env0_second_0:                 episode reward: 73.9500,                 loss: 1.2947
env1_first_0:                 episode reward: -33.7000,                 loss: nan
env1_second_0:                 episode reward: 33.7000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 777.2,                last time consumption/overall running time: 895.4428s / 262397.3440 s
env0_first_0:                 episode reward: -41.0000,                 loss: 1.3536
env0_second_0:                 episode reward: 41.0000,                 loss: 1.1542
env1_first_0:                 episode reward: -58.9500,                 loss: nan
env1_second_0:                 episode reward: 58.9500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 587.7,                last time consumption/overall running time: 683.1710s / 263080.5150 s
env0_first_0:                 episode reward: -50.8500,                 loss: 1.1834
env0_second_0:                 episode reward: 50.8500,                 loss: 1.0756
env1_first_0:                 episode reward: -50.0500,                 loss: nan
env1_second_0:                 episode reward: 50.0500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 590.85,                last time consumption/overall running time: 673.8308s / 263754.3458 s
env0_first_0:                 episode reward: -63.9500,                 loss: 1.1651
env0_second_0:                 episode reward: 63.9500,                 loss: 1.0051
env1_first_0:                 episode reward: -46.9000,                 loss: nan
env1_second_0:                 episode reward: 46.9000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 498.35,                last time consumption/overall running time: 569.9440s / 264324.2897 s
env0_first_0:                 episode reward: -54.7000,                 loss: 1.2260
env0_second_0:                 episode reward: 54.7000,                 loss: 1.0325
env1_first_0:                 episode reward: -59.4500,                 loss: nan
env1_second_0:                 episode reward: 59.4500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 402.0,                last time consumption/overall running time: 460.1036s / 264784.3934 s
env0_first_0:                 episode reward: -45.8500,                 loss: 1.2105
env0_second_0:                 episode reward: 45.8500,                 loss: 1.0828
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 582.95,                last time consumption/overall running time: 668.4867s / 265452.8801 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.3059
env0_second_0:                 episode reward: 60.7000,                 loss: 1.2785
env1_first_0:                 episode reward: -46.6500,                 loss: nan
env1_second_0:                 episode reward: 46.6500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 621.6,                last time consumption/overall running time: 708.8327s / 266161.7128 s
env0_first_0:                 episode reward: -52.8000,                 loss: 1.2586
env0_second_0:                 episode reward: 52.8000,                 loss: 1.2674
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 545.9,                last time consumption/overall running time: 626.4650s / 266788.1777 s
env0_first_0:                 episode reward: -53.5500,                 loss: 1.3678
env0_second_0:                 episode reward: 53.5500,                 loss: 1.3299
env1_first_0:                 episode reward: -61.5500,                 loss: nan
env1_second_0:                 episode reward: 61.5500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 462.15,                last time consumption/overall running time: 531.6289s / 267319.8067 s
env0_first_0:                 episode reward: -62.6500,                 loss: 1.3145
env0_second_0:                 episode reward: 62.6500,                 loss: 1.2684
env1_first_0:                 episode reward: -54.0500,                 loss: nan
env1_second_0:                 episode reward: 54.0500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 407.05,                last time consumption/overall running time: 468.6786s / 267788.4852 s
env0_first_0:                 episode reward: -48.0500,                 loss: 1.2691
env0_second_0:                 episode reward: 48.0500,                 loss: 1.2751
env1_first_0:                 episode reward: -68.9000,                 loss: nan
env1_second_0:                 episode reward: 68.9000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 539.65,                last time consumption/overall running time: 620.1685s / 268408.6537 s
env0_first_0:                 episode reward: -51.7500,                 loss: 1.3325
env0_second_0:                 episode reward: 51.7500,                 loss: 1.2846
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 544.05,                last time consumption/overall running time: 631.2602s / 269039.9139 s
env0_first_0:                 episode reward: -57.9500,                 loss: 1.3376
env0_second_0:                 episode reward: 57.9500,                 loss: 1.2835
env1_first_0:                 episode reward: -60.0500,                 loss: nan
env1_second_0:                 episode reward: 60.0500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 428.3,                last time consumption/overall running time: 503.3170s / 269543.2308 s
env0_first_0:                 episode reward: -62.4000,                 loss: 1.4453
env0_second_0:                 episode reward: 62.4000,                 loss: 1.3458
env1_first_0:                 episode reward: -64.5500,                 loss: nan
env1_second_0:                 episode reward: 64.5500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 514.75,                last time consumption/overall running time: 596.0715s / 270139.3023 s
env0_first_0:                 episode reward: -39.9500,                 loss: 1.4232
env0_second_0:                 episode reward: 39.9500,                 loss: 1.3084
env1_first_0:                 episode reward: -72.0500,                 loss: nan
env1_second_0:                 episode reward: 72.0500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 542.25,                last time consumption/overall running time: 627.9574s / 270767.2597 s
env0_first_0:                 episode reward: -54.3500,                 loss: 1.4925
env0_second_0:                 episode reward: 54.3500,                 loss: 1.3255
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 430.85,                last time consumption/overall running time: 498.0088s / 271265.2686 s
env0_first_0:                 episode reward: -43.5500,                 loss: 1.5611
env0_second_0:                 episode reward: 43.5500,                 loss: 1.2909
env1_first_0:                 episode reward: -50.8500,                 loss: nan
env1_second_0:                 episode reward: 50.8500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 470.0,                last time consumption/overall running time: 541.1498s / 271806.4184 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.5104
env0_second_0:                 episode reward: 60.7000,                 loss: 1.2795
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 527.05,                last time consumption/overall running time: 612.9345s / 272419.3529 s
env0_first_0:                 episode reward: -65.5000,                 loss: 1.5369
env0_second_0:                 episode reward: 65.5000,                 loss: 1.2382
env1_first_0:                 episode reward: -46.9500,                 loss: nan
env1_second_0:                 episode reward: 46.9500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 495.65,                last time consumption/overall running time: 573.7936s / 272993.1464 s
env0_first_0:                 episode reward: -54.7000,                 loss: 1.5943
env0_second_0:                 episode reward: 54.7000,                 loss: 1.3332
env1_first_0:                 episode reward: -57.7500,                 loss: nan
env1_second_0:                 episode reward: 57.7500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 561.6,                last time consumption/overall running time: 646.5528s / 273639.6992 s
env0_first_0:                 episode reward: -47.7000,                 loss: 1.6377
env0_second_0:                 episode reward: 47.7000,                 loss: 1.2902
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 582.9,                last time consumption/overall running time: 665.9211s / 274305.6203 s
env0_first_0:                 episode reward: -49.1000,                 loss: 1.6040
env0_second_0:                 episode reward: 49.1000,                 loss: 1.3467
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 524.65,                last time consumption/overall running time: 599.5662s / 274905.1865 s
env0_first_0:                 episode reward: -46.9500,                 loss: 1.5980
env0_second_0:                 episode reward: 46.9500,                 loss: 1.2466
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 577.2,                last time consumption/overall running time: 659.3448s / 275564.5313 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.6914
env0_second_0:                 episode reward: 58.2000,                 loss: 1.2827
env1_first_0:                 episode reward: -43.1500,                 loss: nan
env1_second_0:                 episode reward: 43.1500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 701.6,                last time consumption/overall running time: 801.5613s / 276366.0925 s
env0_first_0:                 episode reward: -41.0000,                 loss: 1.6480
env0_second_0:                 episode reward: 41.0000,                 loss: 1.2798
env1_first_0:                 episode reward: -51.2500,                 loss: nan
env1_second_0:                 episode reward: 51.2500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 613.25,                last time consumption/overall running time: 702.7223s / 277068.8149 s
env0_first_0:                 episode reward: -27.0000,                 loss: 1.6537
env0_second_0:                 episode reward: 27.0000,                 loss: 1.1927
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 632.2,                last time consumption/overall running time: 721.2497s / 277790.0646 s
env0_first_0:                 episode reward: -38.4500,                 loss: 1.6117
env0_second_0:                 episode reward: 38.4500,                 loss: 1.1698
env1_first_0:                 episode reward: -61.8000,                 loss: nan
env1_second_0:                 episode reward: 61.8000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 551.2,                last time consumption/overall running time: 635.2505s / 278425.3151 s
env0_first_0:                 episode reward: -54.9000,                 loss: 1.6395
env0_second_0:                 episode reward: 54.9000,                 loss: 1.1538
env1_first_0:                 episode reward: -41.3500,                 loss: nan
env1_second_0:                 episode reward: 41.3500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 512.3,                last time consumption/overall running time: 583.9465s / 279009.2616 s
env0_first_0:                 episode reward: -61.3500,                 loss: 1.6203
env0_second_0:                 episode reward: 61.3500,                 loss: 1.1642
env1_first_0:                 episode reward: -57.9500,                 loss: nan
env1_second_0:                 episode reward: 57.9500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 684.95,                last time consumption/overall running time: 778.9392s / 279788.2007 s
env0_first_0:                 episode reward: -59.7000,                 loss: 1.6049
env0_second_0:                 episode reward: 59.7000,                 loss: 1.1850
env1_first_0:                 episode reward: -57.4000,                 loss: nan
env1_second_0:                 episode reward: 57.4000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 544.4,                last time consumption/overall running time: 621.0229s / 280409.2236 s
env0_first_0:                 episode reward: -55.9000,                 loss: 1.5293
env0_second_0:                 episode reward: 55.9000,                 loss: 1.2669
env1_first_0:                 episode reward: -46.6500,                 loss: nan
env1_second_0:                 episode reward: 46.6500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 505.1,                last time consumption/overall running time: 576.8495s / 280986.0731 s
env0_first_0:                 episode reward: -58.6000,                 loss: 1.5589
env0_second_0:                 episode reward: 58.6000,                 loss: 1.1736
env1_first_0:                 episode reward: -47.3000,                 loss: nan
env1_second_0:                 episode reward: 47.3000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 442.45,                last time consumption/overall running time: 506.3155s / 281492.3885 s
env0_first_0:                 episode reward: -68.7500,                 loss: 1.5288
env0_second_0:                 episode reward: 68.7500,                 loss: 1.1320
env1_first_0:                 episode reward: -65.9500,                 loss: nan
env1_second_0:                 episode reward: 65.9500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 588.6,                last time consumption/overall running time: 675.0358s / 282167.4243 s
env0_first_0:                 episode reward: -64.1500,                 loss: 1.5991
env0_second_0:                 episode reward: 64.1500,                 loss: 1.2410
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 451.55,                last time consumption/overall running time: 513.9754s / 282681.3997 s
env0_first_0:                 episode reward: -50.0500,                 loss: 1.6646
env0_second_0:                 episode reward: 50.0500,                 loss: 1.3046
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 630.55,                last time consumption/overall running time: 715.0812s / 283396.4809 s
env0_first_0:                 episode reward: -53.9000,                 loss: 1.6039
env0_second_0:                 episode reward: 53.9000,                 loss: 1.3166
env1_first_0:                 episode reward: -42.2500,                 loss: nan
env1_second_0:                 episode reward: 42.2500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 555.85,                last time consumption/overall running time: 635.5831s / 284032.0640 s
env0_first_0:                 episode reward: -59.3000,                 loss: 1.5882
env0_second_0:                 episode reward: 59.3000,                 loss: 1.2876
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 516.2,                last time consumption/overall running time: 588.6443s / 284620.7083 s
env0_first_0:                 episode reward: -58.1000,                 loss: 1.5250
env0_second_0:                 episode reward: 58.1000,                 loss: 1.2456
env1_first_0:                 episode reward: -55.7500,                 loss: nan
env1_second_0:                 episode reward: 55.7500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 511.75,                last time consumption/overall running time: 583.1459s / 285203.8542 s
env0_first_0:                 episode reward: -50.7000,                 loss: 1.5947
env0_second_0:                 episode reward: 50.7000,                 loss: 1.2251
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 589.8,                last time consumption/overall running time: 677.6405s / 285881.4947 s
env0_first_0:                 episode reward: -56.2500,                 loss: 1.5510
env0_second_0:                 episode reward: 56.2500,                 loss: 1.2239
env1_first_0:                 episode reward: -37.0500,                 loss: nan
env1_second_0:                 episode reward: 37.0500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 620.1,                last time consumption/overall running time: 712.4875s / 286593.9822 s
env0_first_0:                 episode reward: -40.0000,                 loss: 1.5004
env0_second_0:                 episode reward: 40.0000,                 loss: 1.1086
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 529.3,                last time consumption/overall running time: 603.6315s / 287197.6137 s
env0_first_0:                 episode reward: -48.3500,                 loss: 1.4414
env0_second_0:                 episode reward: 48.3500,                 loss: 1.1022
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 648.45,                last time consumption/overall running time: 744.8066s / 287942.4203 s
env0_first_0:                 episode reward: -52.6000,                 loss: 1.4427
env0_second_0:                 episode reward: 52.6000,                 loss: 1.0877
env1_first_0:                 episode reward: -47.5500,                 loss: nan
env1_second_0:                 episode reward: 47.5500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 385.05,                last time consumption/overall running time: 444.7801s / 288387.2004 s
env0_first_0:                 episode reward: -64.3500,                 loss: 1.3817
env0_second_0:                 episode reward: 64.3500,                 loss: 1.0126
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 416.15,                last time consumption/overall running time: 476.6739s / 288863.8743 s
env0_first_0:                 episode reward: -58.5000,                 loss: 1.4124
env0_second_0:                 episode reward: 58.5000,                 loss: 1.0345
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 518.6,                last time consumption/overall running time: 595.0031s / 289458.8774 s
env0_first_0:                 episode reward: -60.8500,                 loss: 1.4334
env0_second_0:                 episode reward: 60.8500,                 loss: 1.0442
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 596.9,                last time consumption/overall running time: 681.9772s / 290140.8546 s
env0_first_0:                 episode reward: -63.9500,                 loss: 1.4508
env0_second_0:                 episode reward: 63.9500,                 loss: 1.1210
env1_first_0:                 episode reward: -37.9500,                 loss: nan
env1_second_0:                 episode reward: 37.9500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 594.0,                last time consumption/overall running time: 678.6053s / 290819.4599 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.2344
env0_second_0:                 episode reward: 56.7500,                 loss: 1.0841
env1_first_0:                 episode reward: -54.3000,                 loss: nan
env1_second_0:                 episode reward: 54.3000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 533.4,                last time consumption/overall running time: 604.7884s / 291424.2483 s
env0_first_0:                 episode reward: -43.5500,                 loss: 1.2650
env0_second_0:                 episode reward: 43.5500,                 loss: 1.0728
env1_first_0:                 episode reward: -59.1000,                 loss: nan
env1_second_0:                 episode reward: 59.1000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 531.55,                last time consumption/overall running time: 597.3767s / 292021.6250 s
env0_first_0:                 episode reward: -57.4000,                 loss: 1.1916
env0_second_0:                 episode reward: 57.4000,                 loss: 1.0967
env1_first_0:                 episode reward: -57.9000,                 loss: nan
env1_second_0:                 episode reward: 57.9000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 462.9,                last time consumption/overall running time: 524.6881s / 292546.3131 s
env0_first_0:                 episode reward: -73.8500,                 loss: 1.2057
env0_second_0:                 episode reward: 73.8500,                 loss: 1.1847
env1_first_0:                 episode reward: -38.7500,                 loss: nan
env1_second_0:                 episode reward: 38.7500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 478.9,                last time consumption/overall running time: 541.1810s / 293087.4941 s
env0_first_0:                 episode reward: -71.0000,                 loss: 1.3030
env0_second_0:                 episode reward: 71.0000,                 loss: 1.1590
env1_first_0:                 episode reward: -52.4000,                 loss: nan
env1_second_0:                 episode reward: 52.4000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 583.95,                last time consumption/overall running time: 656.6849s / 293744.1789 s
env0_first_0:                 episode reward: -62.7000,                 loss: 1.3428
env0_second_0:                 episode reward: 62.7000,                 loss: 1.2194
env1_first_0:                 episode reward: -47.5000,                 loss: nan
env1_second_0:                 episode reward: 47.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 743.1,                last time consumption/overall running time: 828.5742s / 294572.7531 s
env0_first_0:                 episode reward: -47.3000,                 loss: 1.4322
env0_second_0:                 episode reward: 47.3000,                 loss: 1.2668
env1_first_0:                 episode reward: -29.9000,                 loss: nan
env1_second_0:                 episode reward: 29.9000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 657.65,                last time consumption/overall running time: 725.1546s / 295297.9077 s
env0_first_0:                 episode reward: -51.2000,                 loss: 1.4686
env0_second_0:                 episode reward: 51.2000,                 loss: 1.2291
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 614.2,                last time consumption/overall running time: 679.1250s / 295977.0327 s
env0_first_0:                 episode reward: -50.8500,                 loss: 1.4107
env0_second_0:                 episode reward: 50.8500,                 loss: 1.1846
env1_first_0:                 episode reward: -47.2000,                 loss: nan
env1_second_0:                 episode reward: 47.2000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 464.85,                last time consumption/overall running time: 519.5653s / 296496.5980 s
env0_first_0:                 episode reward: -55.8500,                 loss: 1.3822
env0_second_0:                 episode reward: 55.8500,                 loss: 1.1437
env1_first_0:                 episode reward: -54.1000,                 loss: nan
env1_second_0:                 episode reward: 54.1000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 465.5,                last time consumption/overall running time: 521.8195s / 297018.4174 s
env0_first_0:                 episode reward: -53.5000,                 loss: 1.3163
env0_second_0:                 episode reward: 53.5000,                 loss: 1.0946
env1_first_0:                 episode reward: -56.6500,                 loss: nan
env1_second_0:                 episode reward: 56.6500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 668.55,                last time consumption/overall running time: 735.7766s / 297754.1941 s
env0_first_0:                 episode reward: -42.8000,                 loss: 1.2809
env0_second_0:                 episode reward: 42.8000,                 loss: 1.0402
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 556.95,                last time consumption/overall running time: 623.3772s / 298377.5713 s
env0_first_0:                 episode reward: -54.3500,                 loss: 1.3738
env0_second_0:                 episode reward: 54.3500,                 loss: 1.0597
env1_first_0:                 episode reward: -49.1500,                 loss: nan
env1_second_0:                 episode reward: 49.1500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 467.2,                last time consumption/overall running time: 518.6042s / 298896.1755 s
env0_first_0:                 episode reward: -49.5500,                 loss: 1.4255
env0_second_0:                 episode reward: 49.5500,                 loss: 1.0923
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 645.85,                last time consumption/overall running time: 709.5532s / 299605.7287 s
env0_first_0:                 episode reward: -63.1000,                 loss: 1.4824
env0_second_0:                 episode reward: 63.1000,                 loss: 1.0966
env1_first_0:                 episode reward: -51.1000,                 loss: nan
env1_second_0:                 episode reward: 51.1000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 623.85,                last time consumption/overall running time: 692.4495s / 300298.1782 s
env0_first_0:                 episode reward: -50.4500,                 loss: 1.4295
env0_second_0:                 episode reward: 50.4500,                 loss: 1.0615
env1_first_0:                 episode reward: -62.2000,                 loss: nan
env1_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 532.6,                last time consumption/overall running time: 586.8139s / 300884.9920 s
env0_first_0:                 episode reward: -47.5000,                 loss: 1.3868
env0_second_0:                 episode reward: 47.5000,                 loss: 1.0793
env1_first_0:                 episode reward: -44.9000,                 loss: nan
env1_second_0:                 episode reward: 44.9000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 516.6,                last time consumption/overall running time: 568.8393s / 301453.8314 s
env0_first_0:                 episode reward: -57.0500,                 loss: 1.3936
env0_second_0:                 episode reward: 57.0500,                 loss: 1.1405
env1_first_0:                 episode reward: -66.2000,                 loss: nan
env1_second_0:                 episode reward: 66.2000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 479.3,                last time consumption/overall running time: 524.8353s / 301978.6667 s
env0_first_0:                 episode reward: -68.7500,                 loss: 1.4197
env0_second_0:                 episode reward: 68.7500,                 loss: 1.2270
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 526.45,                last time consumption/overall running time: 579.5122s / 302558.1789 s
env0_first_0:                 episode reward: -49.9000,                 loss: 1.4094
env0_second_0:                 episode reward: 49.9000,                 loss: 1.2102
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 560.95,                last time consumption/overall running time: 623.4748s / 303181.6537 s
env0_first_0:                 episode reward: -44.1500,                 loss: 1.3798
env0_second_0:                 episode reward: 44.1500,                 loss: 1.3886
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 725.6,                last time consumption/overall running time: 799.3736s / 303981.0272 s
env0_first_0:                 episode reward: -55.5000,                 loss: 1.3332
env0_second_0:                 episode reward: 55.5000,                 loss: 1.1809
env1_first_0:                 episode reward: -63.5500,                 loss: nan
env1_second_0:                 episode reward: 63.5500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 634.35,                last time consumption/overall running time: 698.8904s / 304679.9176 s
env0_first_0:                 episode reward: -52.7500,                 loss: 1.2064
env0_second_0:                 episode reward: 52.7500,                 loss: 1.1336
env1_first_0:                 episode reward: -44.3500,                 loss: nan
env1_second_0:                 episode reward: 44.3500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 430.5,                last time consumption/overall running time: 472.7018s / 305152.6194 s
env0_first_0:                 episode reward: -64.6500,                 loss: 1.1693
env0_second_0:                 episode reward: 64.6500,                 loss: 0.9905
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 626.65,                last time consumption/overall running time: 679.9006s / 305832.5201 s
env0_first_0:                 episode reward: -58.7500,                 loss: 1.2014
env0_second_0:                 episode reward: 58.7500,                 loss: 1.0257
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 652.65,                last time consumption/overall running time: 711.5621s / 306544.0822 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.4354
env0_second_0:                 episode reward: 55.6000,                 loss: 1.1099
env1_first_0:                 episode reward: -42.2000,                 loss: nan
env1_second_0:                 episode reward: 42.2000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 409.5,                last time consumption/overall running time: 446.9738s / 306991.0560 s
env0_first_0:                 episode reward: -56.1000,                 loss: 1.4859
env0_second_0:                 episode reward: 56.1000,                 loss: 1.1347
env1_first_0:                 episode reward: -54.8500,                 loss: nan
env1_second_0:                 episode reward: 54.8500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 547.45,                last time consumption/overall running time: 603.4660s / 307594.5220 s
env0_first_0:                 episode reward: -46.4500,                 loss: 1.4747
env0_second_0:                 episode reward: 46.4500,                 loss: 1.1475
env1_first_0:                 episode reward: -67.5500,                 loss: nan
env1_second_0:                 episode reward: 67.5500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 534.55,                last time consumption/overall running time: 582.4998s / 308177.0218 s
env0_first_0:                 episode reward: -41.4000,                 loss: 1.4743
env0_second_0:                 episode reward: 41.4000,                 loss: 1.1167
env1_first_0:                 episode reward: -61.9000,                 loss: nan
env1_second_0:                 episode reward: 61.9000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 460.65,                last time consumption/overall running time: 501.7398s / 308678.7616 s
env0_first_0:                 episode reward: -67.5500,                 loss: 1.6015
env0_second_0:                 episode reward: 67.5500,                 loss: 1.1712
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 605.65,                last time consumption/overall running time: 657.7562s / 309336.5179 s
env0_first_0:                 episode reward: -62.4500,                 loss: 1.6526
env0_second_0:                 episode reward: 62.4500,                 loss: 1.1906
env1_first_0:                 episode reward: -45.8500,                 loss: nan
env1_second_0:                 episode reward: 45.8500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 542.75,                last time consumption/overall running time: 585.6302s / 309922.1481 s
env0_first_0:                 episode reward: -37.0000,                 loss: 1.6139
env0_second_0:                 episode reward: 37.0000,                 loss: 1.1521
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 621.7,                last time consumption/overall running time: 666.5693s / 310588.7174 s
env0_first_0:                 episode reward: -52.8500,                 loss: 1.4779
env0_second_0:                 episode reward: 52.8500,                 loss: 1.1503
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 546.05,                last time consumption/overall running time: 589.1623s / 311177.8797 s
env0_first_0:                 episode reward: -71.1500,                 loss: 1.4221
env0_second_0:                 episode reward: 71.1500,                 loss: 1.1566
env1_first_0:                 episode reward: -34.9500,                 loss: nan
env1_second_0:                 episode reward: 34.9500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 520.95,                last time consumption/overall running time: 566.3478s / 311744.2275 s
env0_first_0:                 episode reward: -78.9500,                 loss: 1.3633
env0_second_0:                 episode reward: 78.9500,                 loss: 1.1382
env1_first_0:                 episode reward: -42.6500,                 loss: nan
env1_second_0:                 episode reward: 42.6500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 497.8,                last time consumption/overall running time: 539.8622s / 312284.0897 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.3735
env0_second_0:                 episode reward: 63.0500,                 loss: 1.1459
env1_first_0:                 episode reward: -47.2000,                 loss: nan
env1_second_0:                 episode reward: 47.2000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 662.2,                last time consumption/overall running time: 714.4894s / 312998.5791 s
env0_first_0:                 episode reward: -57.0000,                 loss: 1.3483
env0_second_0:                 episode reward: 57.0000,                 loss: 1.2160
env1_first_0:                 episode reward: -59.0000,                 loss: nan
env1_second_0:                 episode reward: 59.0000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 497.8,                last time consumption/overall running time: 536.3795s / 313534.9586 s
env0_first_0:                 episode reward: -59.2500,                 loss: 1.3370
env0_second_0:                 episode reward: 59.2500,                 loss: 1.1891
env1_first_0:                 episode reward: -46.1500,                 loss: nan
env1_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 539.4,                last time consumption/overall running time: 580.8188s / 314115.7774 s
env0_first_0:                 episode reward: -64.4500,                 loss: 1.4776
env0_second_0:                 episode reward: 64.4500,                 loss: 1.2160
env1_first_0:                 episode reward: -49.6000,                 loss: nan
env1_second_0:                 episode reward: 49.6000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 487.75,                last time consumption/overall running time: 526.0816s / 314641.8590 s
env0_first_0:                 episode reward: -60.8000,                 loss: 1.4935
env0_second_0:                 episode reward: 60.8000,                 loss: 1.1437
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 522.75,                last time consumption/overall running time: 553.9108s / 315195.7699 s
env0_first_0:                 episode reward: -49.1000,                 loss: 1.3536
env0_second_0:                 episode reward: 49.1000,                 loss: 1.1944
env1_first_0:                 episode reward: -66.6000,                 loss: nan
env1_second_0:                 episode reward: 66.6000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 792.75,                last time consumption/overall running time: 849.3276s / 316045.0975 s
env0_first_0:                 episode reward: -46.6500,                 loss: 1.3092
env0_second_0:                 episode reward: 46.6500,                 loss: 1.1076
env1_first_0:                 episode reward: -49.5000,                 loss: nan
env1_second_0:                 episode reward: 49.5000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 529.3,                last time consumption/overall running time: 566.4092s / 316611.5067 s
env0_first_0:                 episode reward: -50.3000,                 loss: 1.2591
env0_second_0:                 episode reward: 50.3000,                 loss: 1.0775
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 480.05,                last time consumption/overall running time: 507.8719s / 317119.3785 s
env0_first_0:                 episode reward: -47.8500,                 loss: 1.2814
env0_second_0:                 episode reward: 47.8500,                 loss: 1.0081
env1_first_0:                 episode reward: -64.8000,                 loss: nan
env1_second_0:                 episode reward: 64.8000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 508.4,                last time consumption/overall running time: 540.0281s / 317659.4067 s
env0_first_0:                 episode reward: -56.3000,                 loss: 1.3233
env0_second_0:                 episode reward: 56.3000,                 loss: 1.0888
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 507.25,                last time consumption/overall running time: 537.5649s / 318196.9716 s
env0_first_0:                 episode reward: -39.0500,                 loss: 1.3004
env0_second_0:                 episode reward: 39.0500,                 loss: 1.0996
env1_first_0:                 episode reward: -51.1500,                 loss: nan
env1_second_0:                 episode reward: 51.1500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 611.95,                last time consumption/overall running time: 646.1764s / 318843.1480 s
env0_first_0:                 episode reward: -51.6000,                 loss: 1.3249
env0_second_0:                 episode reward: 51.6000,                 loss: 1.1540
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 630.75,                last time consumption/overall running time: 666.4846s / 319509.6326 s
env0_first_0:                 episode reward: -51.9000,                 loss: 1.3398
env0_second_0:                 episode reward: 51.9000,                 loss: 1.1366
env1_first_0:                 episode reward: -67.2500,                 loss: nan
env1_second_0:                 episode reward: 67.2500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 670.95,                last time consumption/overall running time: 704.9354s / 320214.5680 s
env0_first_0:                 episode reward: -54.6500,                 loss: 1.1488
env0_second_0:                 episode reward: 54.6500,                 loss: 1.1764
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 657.55,                last time consumption/overall running time: 692.9532s / 320907.5212 s
env0_first_0:                 episode reward: -50.7000,                 loss: 1.1372
env0_second_0:                 episode reward: 50.7000,                 loss: 1.1229
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 483.35,                last time consumption/overall running time: 505.5326s / 321413.0538 s
env0_first_0:                 episode reward: -43.3000,                 loss: 1.0797
env0_second_0:                 episode reward: 43.3000,                 loss: 1.0181
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 540.65,                last time consumption/overall running time: 565.4673s / 321978.5211 s
env0_first_0:                 episode reward: -65.3500,                 loss: 1.1645
env0_second_0:                 episode reward: 65.3500,                 loss: 1.1140
env1_first_0:                 episode reward: -55.9500,                 loss: nan
env1_second_0:                 episode reward: 55.9500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 490.35,                last time consumption/overall running time: 512.8513s / 322491.3724 s
env0_first_0:                 episode reward: -73.2500,                 loss: 1.1880
env0_second_0:                 episode reward: 73.2500,                 loss: 1.1914
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 569.1,                last time consumption/overall running time: 595.1967s / 323086.5691 s
env0_first_0:                 episode reward: -49.3500,                 loss: 1.2745
env0_second_0:                 episode reward: 49.3500,                 loss: 1.1454
env1_first_0:                 episode reward: -55.7500,                 loss: nan
env1_second_0:                 episode reward: 55.7500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 702.1,                last time consumption/overall running time: 730.5396s / 323817.1086 s
env0_first_0:                 episode reward: -22.9500,                 loss: 1.1754
env0_second_0:                 episode reward: 22.9500,                 loss: 1.0732
env1_first_0:                 episode reward: -61.5000,                 loss: nan
env1_second_0:                 episode reward: 61.5000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 573.6,                last time consumption/overall running time: 594.3167s / 324411.4253 s
env0_first_0:                 episode reward: -60.9000,                 loss: 1.1298
env0_second_0:                 episode reward: 60.9000,                 loss: 1.0609
env1_first_0:                 episode reward: -59.1000,                 loss: nan
env1_second_0:                 episode reward: 59.1000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 598.55,                last time consumption/overall running time: 617.2575s / 325028.6828 s
env0_first_0:                 episode reward: -52.9500,                 loss: 1.0602
env0_second_0:                 episode reward: 52.9500,                 loss: 1.0079
env1_first_0:                 episode reward: -56.8000,                 loss: nan
env1_second_0:                 episode reward: 56.8000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 606.7,                last time consumption/overall running time: 625.6200s / 325654.3028 s
env0_first_0:                 episode reward: -64.4500,                 loss: 1.1031
env0_second_0:                 episode reward: 64.4500,                 loss: 0.9709
env1_first_0:                 episode reward: -47.4500,                 loss: nan
env1_second_0:                 episode reward: 47.4500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 624.85,                last time consumption/overall running time: 643.6526s / 326297.9554 s
env0_first_0:                 episode reward: -55.4500,                 loss: 1.2597
env0_second_0:                 episode reward: 55.4500,                 loss: 0.9961
env1_first_0:                 episode reward: -60.4500,                 loss: nan
env1_second_0:                 episode reward: 60.4500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 610.0,                last time consumption/overall running time: 633.5525s / 326931.5079 s
env0_first_0:                 episode reward: -46.6500,                 loss: 1.2980
env0_second_0:                 episode reward: 46.6500,                 loss: 1.0534
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 529.95,                last time consumption/overall running time: 545.0530s / 327476.5609 s
env0_first_0:                 episode reward: -40.8000,                 loss: 1.3260
env0_second_0:                 episode reward: 40.8000,                 loss: 1.0574
env1_first_0:                 episode reward: -72.0000,                 loss: nan
env1_second_0:                 episode reward: 72.0000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 592.6,                last time consumption/overall running time: 605.9653s / 328082.5262 s
env0_first_0:                 episode reward: -49.2000,                 loss: 1.4428
env0_second_0:                 episode reward: 49.2000,                 loss: 1.1406
env1_first_0:                 episode reward: -58.3000,                 loss: nan
env1_second_0:                 episode reward: 58.3000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 568.7,                last time consumption/overall running time: 587.0268s / 328669.5530 s
env0_first_0:                 episode reward: -43.1000,                 loss: 1.3533
env0_second_0:                 episode reward: 43.1000,                 loss: 1.1658
env1_first_0:                 episode reward: -53.7500,                 loss: nan
env1_second_0:                 episode reward: 53.7500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 616.75,                last time consumption/overall running time: 636.7703s / 329306.3233 s
env0_first_0:                 episode reward: -56.0500,                 loss: 1.3396
env0_second_0:                 episode reward: 56.0500,                 loss: 1.1291
env1_first_0:                 episode reward: -37.9500,                 loss: nan
env1_second_0:                 episode reward: 37.9500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 571.7,                last time consumption/overall running time: 594.0627s / 329900.3860 s
env0_first_0:                 episode reward: -63.2500,                 loss: 1.3299
env0_second_0:                 episode reward: 63.2500,                 loss: 1.2636
env1_first_0:                 episode reward: -39.6000,                 loss: nan
env1_second_0:                 episode reward: 39.6000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 563.75,                last time consumption/overall running time: 583.3514s / 330483.7374 s
env0_first_0:                 episode reward: -51.8000,                 loss: 1.2421
env0_second_0:                 episode reward: 51.8000,                 loss: 1.2109
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 672.3,                last time consumption/overall running time: 692.4090s / 331176.1464 s
env0_first_0:                 episode reward: -48.8000,                 loss: 1.2412
env0_second_0:                 episode reward: 48.8000,                 loss: 1.1241
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 501.9,                last time consumption/overall running time: 514.4443s / 331690.5907 s
env0_first_0:                 episode reward: -71.2500,                 loss: 1.3011
env0_second_0:                 episode reward: 71.2500,                 loss: 1.1378
env1_first_0:                 episode reward: -41.9000,                 loss: nan
env1_second_0:                 episode reward: 41.9000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 574.05,                last time consumption/overall running time: 587.5842s / 332278.1750 s
env0_first_0:                 episode reward: -45.5000,                 loss: 1.3703
env0_second_0:                 episode reward: 45.5000,                 loss: 1.1699
env1_first_0:                 episode reward: -54.5000,                 loss: nan
env1_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 598.75,                last time consumption/overall running time: 613.3463s / 332891.5213 s
env0_first_0:                 episode reward: -37.5500,                 loss: 1.2870
env0_second_0:                 episode reward: 37.5500,                 loss: 1.1139
env1_first_0:                 episode reward: -69.3500,                 loss: nan
env1_second_0:                 episode reward: 69.3500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 827.25,                last time consumption/overall running time: 858.2748s / 333749.7962 s
env0_first_0:                 episode reward: -55.7000,                 loss: 1.3413
env0_second_0:                 episode reward: 55.7000,                 loss: 1.1131
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 716.5,                last time consumption/overall running time: 734.6212s / 334484.4173 s
env0_first_0:                 episode reward: -46.2500,                 loss: 1.0992
env0_second_0:                 episode reward: 46.2500,                 loss: 0.9412
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 650.05,                last time consumption/overall running time: 660.7907s / 335145.2080 s
env0_first_0:                 episode reward: -48.6500,                 loss: 1.0412
env0_second_0:                 episode reward: 48.6500,                 loss: 0.8914
env1_first_0:                 episode reward: -48.2500,                 loss: nan
env1_second_0:                 episode reward: 48.2500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 924.2,                last time consumption/overall running time: 937.2871s / 336082.4951 s
env0_first_0:                 episode reward: -40.7500,                 loss: 1.0126
env0_second_0:                 episode reward: 40.7500,                 loss: 0.8570
env1_first_0:                 episode reward: -49.6000,                 loss: nan
env1_second_0:                 episode reward: 49.6000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 655.75,                last time consumption/overall running time: 664.7531s / 336747.2482 s
env0_first_0:                 episode reward: -52.3500,                 loss: 1.1829
env0_second_0:                 episode reward: 52.3500,                 loss: 0.9332
env1_first_0:                 episode reward: -40.0000,                 loss: nan
env1_second_0:                 episode reward: 40.0000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 552.85,                last time consumption/overall running time: 564.1592s / 337311.4074 s
env0_first_0:                 episode reward: -49.2500,                 loss: 1.1550
env0_second_0:                 episode reward: 49.2500,                 loss: 1.0146
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 524.0,                last time consumption/overall running time: 529.2943s / 337840.7017 s
env0_first_0:                 episode reward: -45.8500,                 loss: 1.3080
env0_second_0:                 episode reward: 45.8500,                 loss: 0.9733
env1_first_0:                 episode reward: -66.1000,                 loss: nan
env1_second_0:                 episode reward: 66.1000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 625.75,                last time consumption/overall running time: 631.5939s / 338472.2956 s
env0_first_0:                 episode reward: -58.2500,                 loss: 1.3172
env0_second_0:                 episode reward: 58.2500,                 loss: 1.0182
env1_first_0:                 episode reward: -37.3500,                 loss: nan
env1_second_0:                 episode reward: 37.3500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 566.25,                last time consumption/overall running time: 579.3478s / 339051.6434 s
env0_first_0:                 episode reward: -51.4500,                 loss: 1.5201
env0_second_0:                 episode reward: 51.4500,                 loss: 1.1682
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 576.3,                last time consumption/overall running time: 584.0711s / 339635.7145 s
env0_first_0:                 episode reward: -55.4500,                 loss: 1.4756
env0_second_0:                 episode reward: 55.4500,                 loss: 1.2826
env1_first_0:                 episode reward: -61.7500,                 loss: nan
env1_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 581.5,                last time consumption/overall running time: 585.2137s / 340220.9282 s
env0_first_0:                 episode reward: -59.9500,                 loss: 1.3312
env0_second_0:                 episode reward: 59.9500,                 loss: 1.2048
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 414.95,                last time consumption/overall running time: 416.5192s / 340637.4474 s
env0_first_0:                 episode reward: -47.4500,                 loss: 1.4249
env0_second_0:                 episode reward: 47.4500,                 loss: 1.2486
env1_first_0:                 episode reward: -64.0500,                 loss: nan
env1_second_0:                 episode reward: 64.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 556.05,                last time consumption/overall running time: 559.8486s / 341197.2960 s
env0_first_0:                 episode reward: -48.2500,                 loss: 1.5129
env0_second_0:                 episode reward: 48.2500,                 loss: 1.2970
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 460.55,                last time consumption/overall running time: 463.1656s / 341660.4615 s
env0_first_0:                 episode reward: -65.6500,                 loss: 1.4607
env0_second_0:                 episode reward: 65.6500,                 loss: 1.3948
env1_first_0:                 episode reward: -55.2500,                 loss: nan
env1_second_0:                 episode reward: 55.2500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 556.65,                last time consumption/overall running time: 562.3874s / 342222.8489 s
env0_first_0:                 episode reward: -61.7000,                 loss: 1.4905
env0_second_0:                 episode reward: 61.7000,                 loss: 1.4162
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 429.15,                last time consumption/overall running time: 433.3210s / 342656.1699 s
env0_first_0:                 episode reward: -69.1000,                 loss: 1.5263
env0_second_0:                 episode reward: 69.1000,                 loss: 1.3861
env1_first_0:                 episode reward: -61.8500,                 loss: nan
env1_second_0:                 episode reward: 61.8500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 544.15,                last time consumption/overall running time: 545.6534s / 343201.8233 s
env0_first_0:                 episode reward: -56.6500,                 loss: 1.4213
env0_second_0:                 episode reward: 56.6500,                 loss: 1.4142
env1_first_0:                 episode reward: -38.8500,                 loss: nan
env1_second_0:                 episode reward: 38.8500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 581.4,                last time consumption/overall running time: 584.1482s / 343785.9715 s
env0_first_0:                 episode reward: -51.9000,                 loss: 1.4953
env0_second_0:                 episode reward: 51.9000,                 loss: 1.4405
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 742.7,                last time consumption/overall running time: 750.1454s / 344536.1169 s
env0_first_0:                 episode reward: -49.2500,                 loss: 1.3780
env0_second_0:                 episode reward: 49.2500,                 loss: 1.3281
env1_first_0:                 episode reward: -48.3000,                 loss: nan
env1_second_0:                 episode reward: 48.3000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 707.15,                last time consumption/overall running time: 709.1898s / 345245.3068 s
env0_first_0:                 episode reward: -54.7000,                 loss: 1.4327
env0_second_0:                 episode reward: 54.7000,                 loss: 1.2451
env1_first_0:                 episode reward: -41.9500,                 loss: nan
env1_second_0:                 episode reward: 41.9500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 437.0,                last time consumption/overall running time: 434.7264s / 345680.0332 s
env0_first_0:                 episode reward: -69.4000,                 loss: 1.4791
env0_second_0:                 episode reward: 69.4000,                 loss: 1.2717
env1_first_0:                 episode reward: -44.4000,                 loss: nan
env1_second_0:                 episode reward: 44.4000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 762.4,                last time consumption/overall running time: 768.3992s / 346448.4324 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.5653
env0_second_0:                 episode reward: 63.0500,                 loss: 1.1282
env1_first_0:                 episode reward: -36.2500,                 loss: nan
env1_second_0:                 episode reward: 36.2500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 691.25,                last time consumption/overall running time: 684.7130s / 347133.1455 s
env0_first_0:                 episode reward: -61.2000,                 loss: 1.5556
env0_second_0:                 episode reward: 61.2000,                 loss: 1.1270
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 573.45,                last time consumption/overall running time: 571.8616s / 347705.0071 s
env0_first_0:                 episode reward: -38.6500,                 loss: 1.5064
env0_second_0:                 episode reward: 38.6500,                 loss: 1.2161
env1_first_0:                 episode reward: -72.6500,                 loss: nan
env1_second_0:                 episode reward: 72.6500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 559.05,                last time consumption/overall running time: 563.6473s / 348268.6544 s
env0_first_0:                 episode reward: -52.7500,                 loss: 1.7142
env0_second_0:                 episode reward: 52.7500,                 loss: 1.2544
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 545.4,                last time consumption/overall running time: 543.4755s / 348812.1299 s
env0_first_0:                 episode reward: -62.4500,                 loss: 1.5860
env0_second_0:                 episode reward: 62.4500,                 loss: 1.1870
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 647.75,                last time consumption/overall running time: 647.8826s / 349460.0126 s
env0_first_0:                 episode reward: -47.2500,                 loss: 1.5416
env0_second_0:                 episode reward: 47.2500,                 loss: 1.0790
env1_first_0:                 episode reward: -42.9000,                 loss: nan
env1_second_0:                 episode reward: 42.9000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 770.85,                last time consumption/overall running time: 777.9111s / 350237.9236 s
env0_first_0:                 episode reward: -51.5000,                 loss: 1.5433
env0_second_0:                 episode reward: 51.5000,                 loss: 0.9557
env1_first_0:                 episode reward: -47.2500,                 loss: nan
env1_second_0:                 episode reward: 47.2500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 552.9,                last time consumption/overall running time: 561.0360s / 350798.9597 s
env0_first_0:                 episode reward: -49.2000,                 loss: 1.5351
env0_second_0:                 episode reward: 49.2000,                 loss: 0.9010
env1_first_0:                 episode reward: -60.2000,                 loss: nan
env1_second_0:                 episode reward: 60.2000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 720.2,                last time consumption/overall running time: 723.7338s / 351522.6935 s
env0_first_0:                 episode reward: -25.8500,                 loss: 1.5193
env0_second_0:                 episode reward: 25.8500,                 loss: 0.9179
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 748.45,                last time consumption/overall running time: 749.0471s / 352271.7406 s
env0_first_0:                 episode reward: -47.2000,                 loss: 1.4463
env0_second_0:                 episode reward: 47.2000,                 loss: 0.8537
env1_first_0:                 episode reward: -36.6000,                 loss: nan
env1_second_0:                 episode reward: 36.6000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 796.5,                last time consumption/overall running time: 788.5719s / 353060.3124 s
env0_first_0:                 episode reward: -36.5500,                 loss: 1.3384
env0_second_0:                 episode reward: 36.5500,                 loss: 0.9382
env1_first_0:                 episode reward: -65.7000,                 loss: nan
env1_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 666.95,                last time consumption/overall running time: 663.7667s / 353724.0792 s
env0_first_0:                 episode reward: -56.2000,                 loss: 1.3128
env0_second_0:                 episode reward: 56.2000,                 loss: 0.9170
env1_first_0:                 episode reward: -48.7500,                 loss: nan
env1_second_0:                 episode reward: 48.7500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 620.55,                last time consumption/overall running time: 619.1933s / 354343.2725 s
env0_first_0:                 episode reward: -64.0000,                 loss: 1.4115
env0_second_0:                 episode reward: 64.0000,                 loss: 0.9558
env1_first_0:                 episode reward: -33.8500,                 loss: nan
env1_second_0:                 episode reward: 33.8500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 720.35,                last time consumption/overall running time: 722.7207s / 355065.9932 s
env0_first_0:                 episode reward: -52.0500,                 loss: 1.3642
env0_second_0:                 episode reward: 52.0500,                 loss: 0.9534
env1_first_0:                 episode reward: -68.9000,                 loss: nan
env1_second_0:                 episode reward: 68.9000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 679.0,                last time consumption/overall running time: 690.6024s / 355756.5956 s
env0_first_0:                 episode reward: -40.3000,                 loss: 1.3603
env0_second_0:                 episode reward: 40.3000,                 loss: 0.9643
env1_first_0:                 episode reward: -63.1000,                 loss: nan
env1_second_0:                 episode reward: 63.1000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 578.35,                last time consumption/overall running time: 582.9039s / 356339.4994 s
env0_first_0:                 episode reward: -48.0000,                 loss: 1.3914
env0_second_0:                 episode reward: 48.0000,                 loss: 0.9371
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 472.45,                last time consumption/overall running time: 469.7475s / 356809.2470 s
env0_first_0:                 episode reward: -55.8500,                 loss: 1.4757
env0_second_0:                 episode reward: 55.8500,                 loss: 0.9464
env1_first_0:                 episode reward: -56.7000,                 loss: nan
env1_second_0:                 episode reward: 56.7000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 624.3,                last time consumption/overall running time: 620.3764s / 357429.6233 s
env0_first_0:                 episode reward: -55.2500,                 loss: 1.3698
env0_second_0:                 episode reward: 55.2500,                 loss: 0.9333
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 607.5,                last time consumption/overall running time: 606.6797s / 358036.3031 s
env0_first_0:                 episode reward: -50.7500,                 loss: 1.4775
env0_second_0:                 episode reward: 50.7500,                 loss: 0.9545
env1_first_0:                 episode reward: -54.0000,                 loss: nan
env1_second_0:                 episode reward: 54.0000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 551.95,                last time consumption/overall running time: 553.7645s / 358590.0675 s
env0_first_0:                 episode reward: -47.6500,                 loss: 1.5614
env0_second_0:                 episode reward: 47.6500,                 loss: 0.9008
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 638.25,                last time consumption/overall running time: 631.8080s / 359221.8755 s
env0_first_0:                 episode reward: -44.8500,                 loss: 1.5130
env0_second_0:                 episode reward: 44.8500,                 loss: 1.0369
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 611.65,                last time consumption/overall running time: 609.1720s / 359831.0475 s
env0_first_0:                 episode reward: -48.7000,                 loss: 1.5255
env0_second_0:                 episode reward: 48.7000,                 loss: 1.0301
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 563.95,                last time consumption/overall running time: 561.9407s / 360392.9882 s
env0_first_0:                 episode reward: -60.3000,                 loss: 1.5610
env0_second_0:                 episode reward: 60.3000,                 loss: 1.0250
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 642.15,                last time consumption/overall running time: 647.2648s / 361040.2530 s
env0_first_0:                 episode reward: -53.3500,                 loss: 1.5525
env0_second_0:                 episode reward: 53.3500,                 loss: 0.9911
env1_first_0:                 episode reward: -52.4000,                 loss: nan
env1_second_0:                 episode reward: 52.4000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 587.65,                last time consumption/overall running time: 583.4920s / 361623.7450 s
env0_first_0:                 episode reward: -77.6000,                 loss: 1.3290
env0_second_0:                 episode reward: 77.6000,                 loss: 0.9927
env1_first_0:                 episode reward: -39.4000,                 loss: nan
env1_second_0:                 episode reward: 39.4000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 602.95,                last time consumption/overall running time: 596.2877s / 362220.0327 s
env0_first_0:                 episode reward: -36.1000,                 loss: 1.3796
env0_second_0:                 episode reward: 36.1000,                 loss: 1.0340
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 494.15,                last time consumption/overall running time: 491.2144s / 362711.2471 s
env0_first_0:                 episode reward: -48.2000,                 loss: 1.3687
env0_second_0:                 episode reward: 48.2000,                 loss: 1.0157
env1_first_0:                 episode reward: -57.4000,                 loss: nan
env1_second_0:                 episode reward: 57.4000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 500.1,                last time consumption/overall running time: 493.2132s / 363204.4603 s
env0_first_0:                 episode reward: -55.8000,                 loss: 1.5145
env0_second_0:                 episode reward: 55.8000,                 loss: 1.0289
env1_first_0:                 episode reward: -61.2500,                 loss: nan
env1_second_0:                 episode reward: 61.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 731.35,                last time consumption/overall running time: 725.7486s / 363930.2089 s
env0_first_0:                 episode reward: -51.2500,                 loss: 1.4279
env0_second_0:                 episode reward: 51.2500,                 loss: 1.0059
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 508.65,                last time consumption/overall running time: 499.6454s / 364429.8543 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.4343
env0_second_0:                 episode reward: 56.7500,                 loss: 1.0266
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 731.0,                last time consumption/overall running time: 723.4460s / 365153.3003 s
env0_first_0:                 episode reward: -22.3500,                 loss: 1.3199
env0_second_0:                 episode reward: 22.3500,                 loss: 0.9648
env1_first_0:                 episode reward: -75.8500,                 loss: nan
env1_second_0:                 episode reward: 75.8500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 570.05,                last time consumption/overall running time: 558.3000s / 365711.6003 s
env0_first_0:                 episode reward: -57.7500,                 loss: 1.3039
env0_second_0:                 episode reward: 57.7500,                 loss: 0.9755
env1_first_0:                 episode reward: -38.1000,                 loss: nan
env1_second_0:                 episode reward: 38.1000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 597.2,                last time consumption/overall running time: 590.8606s / 366302.4609 s
env0_first_0:                 episode reward: -55.6500,                 loss: 1.3193
env0_second_0:                 episode reward: 55.6500,                 loss: 0.9730
env1_first_0:                 episode reward: -44.7000,                 loss: nan
env1_second_0:                 episode reward: 44.7000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 624.0,                last time consumption/overall running time: 617.0099s / 366919.4708 s
env0_first_0:                 episode reward: -39.3000,                 loss: 1.3427
env0_second_0:                 episode reward: 39.3000,                 loss: 0.9965
env1_first_0:                 episode reward: -60.2000,                 loss: nan
env1_second_0:                 episode reward: 60.2000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 674.65,                last time consumption/overall running time: 657.1367s / 367576.6075 s
env0_first_0:                 episode reward: -48.4500,                 loss: 1.4701
env0_second_0:                 episode reward: 48.4500,                 loss: 1.0088
env1_first_0:                 episode reward: -62.2000,                 loss: nan
env1_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 478.6,                last time consumption/overall running time: 472.6299s / 368049.2374 s
env0_first_0:                 episode reward: -67.1500,                 loss: 1.5083
env0_second_0:                 episode reward: 67.1500,                 loss: 1.0255
env1_first_0:                 episode reward: -56.5500,                 loss: nan
env1_second_0:                 episode reward: 56.5500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 582.55,                last time consumption/overall running time: 570.0411s / 368619.2785 s
env0_first_0:                 episode reward: -40.3500,                 loss: 1.4752
env0_second_0:                 episode reward: 40.3500,                 loss: 1.0295
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 611.9,                last time consumption/overall running time: 598.2780s / 369217.5565 s
env0_first_0:                 episode reward: -54.2500,                 loss: 1.3923
env0_second_0:                 episode reward: 54.2500,                 loss: 1.0945
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 797.85,                last time consumption/overall running time: 775.8727s / 369993.4292 s
env0_first_0:                 episode reward: -43.9000,                 loss: 1.3425
env0_second_0:                 episode reward: 43.9000,                 loss: 1.0164
env1_first_0:                 episode reward: -41.1000,                 loss: nan
env1_second_0:                 episode reward: 41.1000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 621.6,                last time consumption/overall running time: 610.5466s / 370603.9757 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.3003
env0_second_0:                 episode reward: 56.7500,                 loss: 0.9635
env1_first_0:                 episode reward: -51.9000,                 loss: nan
env1_second_0:                 episode reward: 51.9000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 481.65,                last time consumption/overall running time: 478.6963s / 371082.6720 s
env0_first_0:                 episode reward: -32.7500,                 loss: 1.2946
env0_second_0:                 episode reward: 32.7500,                 loss: 0.9885
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 571.35,                last time consumption/overall running time: 558.3073s / 371640.9793 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.3386
env0_second_0:                 episode reward: 63.0500,                 loss: 1.0505
env1_first_0:                 episode reward: -57.1000,                 loss: nan
env1_second_0:                 episode reward: 57.1000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 499.4,                last time consumption/overall running time: 487.7438s / 372128.7231 s
env0_first_0:                 episode reward: -59.2500,                 loss: 1.3319
env0_second_0:                 episode reward: 59.2500,                 loss: 1.0402
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 619.75,                last time consumption/overall running time: 608.9112s / 372737.6343 s
env0_first_0:                 episode reward: -56.9500,                 loss: 1.3701
env0_second_0:                 episode reward: 56.9500,                 loss: 1.1082
env1_first_0:                 episode reward: -66.5000,                 loss: nan
env1_second_0:                 episode reward: 66.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 616.9,                last time consumption/overall running time: 602.5645s / 373340.1989 s
env0_first_0:                 episode reward: -60.4500,                 loss: 1.3881
env0_second_0:                 episode reward: 60.4500,                 loss: 1.1297
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 742.4,                last time consumption/overall running time: 723.4753s / 374063.6742 s
env0_first_0:                 episode reward: -39.5000,                 loss: 1.3849
env0_second_0:                 episode reward: 39.5000,                 loss: 1.2006
env1_first_0:                 episode reward: -59.5000,                 loss: nan
env1_second_0:                 episode reward: 59.5000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 595.45,                last time consumption/overall running time: 582.7469s / 374646.4211 s
env0_first_0:                 episode reward: -62.3000,                 loss: 1.3291
env0_second_0:                 episode reward: 62.3000,                 loss: 1.0884
env1_first_0:                 episode reward: -41.0000,                 loss: nan
env1_second_0:                 episode reward: 41.0000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 604.95,                last time consumption/overall running time: 590.5617s / 375236.9828 s
env0_first_0:                 episode reward: -53.3500,                 loss: 1.2941
env0_second_0:                 episode reward: 53.3500,                 loss: 1.0564
env1_first_0:                 episode reward: -40.2000,                 loss: nan
env1_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 631.5,                last time consumption/overall running time: 611.2187s / 375848.2014 s
env0_first_0:                 episode reward: -64.5000,                 loss: 1.3807
env0_second_0:                 episode reward: 64.5000,                 loss: 1.0837
env1_first_0:                 episode reward: -56.6000,                 loss: nan
env1_second_0:                 episode reward: 56.6000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 634.15,                last time consumption/overall running time: 616.3327s / 376464.5341 s
env0_first_0:                 episode reward: -59.0000,                 loss: 1.4156
env0_second_0:                 episode reward: 59.0000,                 loss: 1.1678
env1_first_0:                 episode reward: -41.9500,                 loss: nan
env1_second_0:                 episode reward: 41.9500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 658.4,                last time consumption/overall running time: 642.5566s / 377107.0907 s
env0_first_0:                 episode reward: -47.6500,                 loss: 1.3118
env0_second_0:                 episode reward: 47.6500,                 loss: 1.1265
env1_first_0:                 episode reward: -57.8500,                 loss: nan
env1_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 661.95,                last time consumption/overall running time: 642.0824s / 377749.1731 s
env0_first_0:                 episode reward: -43.9000,                 loss: 1.3364
env0_second_0:                 episode reward: 43.9000,                 loss: 1.1573
env1_first_0:                 episode reward: -61.4500,                 loss: nan
env1_second_0:                 episode reward: 61.4500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 623.7,                last time consumption/overall running time: 607.9626s / 378357.1357 s
env0_first_0:                 episode reward: -22.3500,                 loss: 1.2669
env0_second_0:                 episode reward: 22.3500,                 loss: 1.0860
env1_first_0:                 episode reward: -65.7000,                 loss: nan
env1_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 651.4,                last time consumption/overall running time: 635.2903s / 378992.4260 s
env0_first_0:                 episode reward: -57.2000,                 loss: 1.1793
env0_second_0:                 episode reward: 57.2000,                 loss: 1.0245
env1_first_0:                 episode reward: -36.4000,                 loss: nan
env1_second_0:                 episode reward: 36.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 554.6,                last time consumption/overall running time: 543.2115s / 379535.6375 s
env0_first_0:                 episode reward: -59.0500,                 loss: 1.1594
env0_second_0:                 episode reward: 59.0500,                 loss: 0.9669
env1_first_0:                 episode reward: -52.7500,                 loss: nan
env1_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 637.15,                last time consumption/overall running time: 621.1977s / 380156.8352 s
env0_first_0:                 episode reward: -47.5500,                 loss: 1.0332
env0_second_0:                 episode reward: 47.5500,                 loss: 0.9842
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 538.65,                last time consumption/overall running time: 521.1033s / 380677.9385 s
env0_first_0:                 episode reward: -33.4000,                 loss: 1.0984
env0_second_0:                 episode reward: 33.4000,                 loss: 0.9858
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 613.9,                last time consumption/overall running time: 595.9850s / 381273.9235 s
env0_first_0:                 episode reward: -33.9000,                 loss: 1.1484
env0_second_0:                 episode reward: 33.9000,                 loss: 0.9350
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 599.05,                last time consumption/overall running time: 587.9945s / 381861.9180 s
env0_first_0:                 episode reward: -33.6000,                 loss: 1.1432
env0_second_0:                 episode reward: 33.6000,                 loss: 1.0202
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 478.1,                last time consumption/overall running time: 468.6789s / 382330.5969 s
env0_first_0:                 episode reward: -44.1000,                 loss: 1.1813
env0_second_0:                 episode reward: 44.1000,                 loss: 1.0628
env1_first_0:                 episode reward: -58.0500,                 loss: nan
env1_second_0:                 episode reward: 58.0500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 640.95,                last time consumption/overall running time: 623.3431s / 382953.9400 s
env0_first_0:                 episode reward: -48.4500,                 loss: 1.2970
env0_second_0:                 episode reward: 48.4500,                 loss: 1.0482
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 618.2,                last time consumption/overall running time: 606.1219s / 383560.0619 s
env0_first_0:                 episode reward: -40.4000,                 loss: 1.3484
env0_second_0:                 episode reward: 40.4000,                 loss: 1.1141
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 508.6,                last time consumption/overall running time: 492.0209s / 384052.0829 s
env0_first_0:                 episode reward: -51.5000,                 loss: 1.4343
env0_second_0:                 episode reward: 51.5000,                 loss: 1.1879
env1_first_0:                 episode reward: -62.6500,                 loss: nan
env1_second_0:                 episode reward: 62.6500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 439.6,                last time consumption/overall running time: 427.2346s / 384479.3175 s
env0_first_0:                 episode reward: -62.0000,                 loss: 1.4175
env0_second_0:                 episode reward: 62.0000,                 loss: 1.1095
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 479.5,                last time consumption/overall running time: 473.8186s / 384953.1361 s
env0_first_0:                 episode reward: -69.2000,                 loss: 1.5448
env0_second_0:                 episode reward: 69.2000,                 loss: 1.1968
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 479.1,                last time consumption/overall running time: 490.6193s / 385443.7555 s
env0_first_0:                 episode reward: -43.4500,                 loss: 1.5229
env0_second_0:                 episode reward: 43.4500,                 loss: 1.2239
env1_first_0:                 episode reward: -60.9500,                 loss: nan
env1_second_0:                 episode reward: 60.9500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 433.65,                last time consumption/overall running time: 477.0573s / 385920.8127 s
env0_first_0:                 episode reward: -48.0500,                 loss: 1.5815
env0_second_0:                 episode reward: 48.0500,                 loss: 1.2780
env1_first_0:                 episode reward: -61.3500,                 loss: nan
env1_second_0:                 episode reward: 61.3500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 722.9,                last time consumption/overall running time: 793.2315s / 386714.0443 s
env0_first_0:                 episode reward: -50.2000,                 loss: 1.6424
env0_second_0:                 episode reward: 50.2000,                 loss: 1.2717
env1_first_0:                 episode reward: -49.4000,                 loss: nan
env1_second_0:                 episode reward: 49.4000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 414.55,                last time consumption/overall running time: 455.5329s / 387169.5771 s
env0_first_0:                 episode reward: -47.2500,                 loss: 1.5458
env0_second_0:                 episode reward: 47.2500,                 loss: 1.2813
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 577.55,                last time consumption/overall running time: 641.3369s / 387810.9140 s
env0_first_0:                 episode reward: -59.8000,                 loss: 1.6058
env0_second_0:                 episode reward: 59.8000,                 loss: 1.2320
env1_first_0:                 episode reward: -42.7000,                 loss: nan
env1_second_0:                 episode reward: 42.7000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 632.25,                last time consumption/overall running time: 694.4056s / 388505.3196 s
env0_first_0:                 episode reward: -41.8500,                 loss: 1.3852
env0_second_0:                 episode reward: 41.8500,                 loss: 1.1635
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 625.95,                last time consumption/overall running time: 693.5748s / 389198.8944 s
env0_first_0:                 episode reward: -56.3500,                 loss: 1.3418
env0_second_0:                 episode reward: 56.3500,                 loss: 1.1221
env1_first_0:                 episode reward: -59.7000,                 loss: nan
env1_second_0:                 episode reward: 59.7000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 504.6,                last time consumption/overall running time: 560.5428s / 389759.4372 s
env0_first_0:                 episode reward: -68.4500,                 loss: 1.3407
env0_second_0:                 episode reward: 68.4500,                 loss: 1.1629
env1_first_0:                 episode reward: -39.2500,                 loss: nan
env1_second_0:                 episode reward: 39.2500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 594.9,                last time consumption/overall running time: 658.7835s / 390418.2207 s
env0_first_0:                 episode reward: -49.4000,                 loss: 1.3311
env0_second_0:                 episode reward: 49.4000,                 loss: 1.2010
env1_first_0:                 episode reward: -52.7500,                 loss: nan
env1_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 649.85,                last time consumption/overall running time: 726.4603s / 391144.6810 s
env0_first_0:                 episode reward: -52.5500,                 loss: 1.3673
env0_second_0:                 episode reward: 52.5500,                 loss: 1.1305
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 682.45,                last time consumption/overall running time: 753.0325s / 391897.7135 s
env0_first_0:                 episode reward: -43.1500,                 loss: 1.4560
env0_second_0:                 episode reward: 43.1500,                 loss: 0.9704
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 605.9,                last time consumption/overall running time: 665.5896s / 392563.3031 s
env0_first_0:                 episode reward: -72.1500,                 loss: 1.3570
env0_second_0:                 episode reward: 72.1500,                 loss: 0.9700
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 621.85,                last time consumption/overall running time: 682.8933s / 393246.1964 s
env0_first_0:                 episode reward: -60.8000,                 loss: 1.3303
env0_second_0:                 episode reward: 60.8000,                 loss: 0.9960
env1_first_0:                 episode reward: -45.1500,                 loss: nan
env1_second_0:                 episode reward: 45.1500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 518.15,                last time consumption/overall running time: 570.1634s / 393816.3598 s
env0_first_0:                 episode reward: -42.2000,                 loss: 1.3128
env0_second_0:                 episode reward: 42.2000,                 loss: 1.0594
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 669.95,                last time consumption/overall running time: 732.8319s / 394549.1916 s
env0_first_0:                 episode reward: -56.5000,                 loss: 1.2894
env0_second_0:                 episode reward: 56.5000,                 loss: 1.0559
env1_first_0:                 episode reward: -46.3000,                 loss: nan
env1_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 587.1,                last time consumption/overall running time: 636.1328s / 395185.3245 s
env0_first_0:                 episode reward: -40.3000,                 loss: 1.2851
env0_second_0:                 episode reward: 40.3000,                 loss: 1.0566
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 591.7,                last time consumption/overall running time: 650.2984s / 395835.6229 s
env0_first_0:                 episode reward: -50.9500,                 loss: 1.2612
env0_second_0:                 episode reward: 50.9500,                 loss: 1.0065
env1_first_0:                 episode reward: -62.0500,                 loss: nan
env1_second_0:                 episode reward: 62.0500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 501.2,                last time consumption/overall running time: 551.9295s / 396387.5524 s
env0_first_0:                 episode reward: -51.4500,                 loss: 1.3207
env0_second_0:                 episode reward: 51.4500,                 loss: 1.1089
env1_first_0:                 episode reward: -62.4000,                 loss: nan
env1_second_0:                 episode reward: 62.4000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 636.8,                last time consumption/overall running time: 704.7627s / 397092.3152 s
env0_first_0:                 episode reward: -26.5500,                 loss: 1.4476
env0_second_0:                 episode reward: 26.5500,                 loss: 1.1359
env1_first_0:                 episode reward: -65.6000,                 loss: nan
env1_second_0:                 episode reward: 65.6000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 468.65,                last time consumption/overall running time: 512.9234s / 397605.2385 s
env0_first_0:                 episode reward: -58.8500,                 loss: 1.4763
env0_second_0:                 episode reward: 58.8500,                 loss: 1.1262
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 514.7,                last time consumption/overall running time: 557.5331s / 398162.7716 s
env0_first_0:                 episode reward: -71.6500,                 loss: 1.6529
env0_second_0:                 episode reward: 71.6500,                 loss: 1.1313
env1_first_0:                 episode reward: -44.5000,                 loss: nan
env1_second_0:                 episode reward: 44.5000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 549.95,                last time consumption/overall running time: 591.3963s / 398754.1679 s
env0_first_0:                 episode reward: -57.3000,                 loss: 1.7193
env0_second_0:                 episode reward: 57.3000,                 loss: 1.1535
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 622.4,                last time consumption/overall running time: 672.2250s / 399426.3929 s
env0_first_0:                 episode reward: -56.5000,                 loss: 1.5481
env0_second_0:                 episode reward: 56.5000,                 loss: 1.0647
env1_first_0:                 episode reward: -35.1000,                 loss: nan
env1_second_0:                 episode reward: 35.1000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 520.4,                last time consumption/overall running time: 562.9258s / 399989.3187 s
env0_first_0:                 episode reward: -59.2000,                 loss: 1.3809
env0_second_0:                 episode reward: 59.2000,                 loss: 1.1338
env1_first_0:                 episode reward: -54.1500,                 loss: nan
env1_second_0:                 episode reward: 54.1500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 580.75,                last time consumption/overall running time: 625.9739s / 400615.2925 s
env0_first_0:                 episode reward: -50.8000,                 loss: 1.3632
env0_second_0:                 episode reward: 50.8000,                 loss: 1.0835
env1_first_0:                 episode reward: -60.5000,                 loss: nan
env1_second_0:                 episode reward: 60.5000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 495.7,                last time consumption/overall running time: 544.6854s / 401159.9779 s
env0_first_0:                 episode reward: -48.2000,                 loss: 1.3229
env0_second_0:                 episode reward: 48.2000,                 loss: 1.0939
env1_first_0:                 episode reward: -55.1000,                 loss: nan
env1_second_0:                 episode reward: 55.1000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 698.65,                last time consumption/overall running time: 759.2393s / 401919.2172 s
env0_first_0:                 episode reward: -57.3000,                 loss: 1.2799
env0_second_0:                 episode reward: 57.3000,                 loss: 1.0952
env1_first_0:                 episode reward: -56.9500,                 loss: nan
env1_second_0:                 episode reward: 56.9500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 387.45,                last time consumption/overall running time: 421.5939s / 402340.8111 s
env0_first_0:                 episode reward: -68.2000,                 loss: 1.4492
env0_second_0:                 episode reward: 68.2000,                 loss: 1.1435
env1_first_0:                 episode reward: -54.6000,                 loss: nan
env1_second_0:                 episode reward: 54.6000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 540.6,                last time consumption/overall running time: 590.2037s / 402931.0148 s
env0_first_0:                 episode reward: -48.3000,                 loss: 1.5027
env0_second_0:                 episode reward: 48.3000,                 loss: 1.1787
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 532.45,                last time consumption/overall running time: 572.9582s / 403503.9730 s
env0_first_0:                 episode reward: -54.5500,                 loss: 1.5264
env0_second_0:                 episode reward: 54.5500,                 loss: 1.1431
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 764.45,                last time consumption/overall running time: 813.5603s / 404317.5333 s
env0_first_0:                 episode reward: -58.5000,                 loss: 1.5386
env0_second_0:                 episode reward: 58.5000,                 loss: 1.2080
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 623.95,                last time consumption/overall running time: 667.8408s / 404985.3741 s
env0_first_0:                 episode reward: -58.9000,                 loss: 1.4931
env0_second_0:                 episode reward: 58.9000,                 loss: 1.1326
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 569.35,                last time consumption/overall running time: 611.0778s / 405596.4519 s
env0_first_0:                 episode reward: -45.4500,                 loss: 1.3898
env0_second_0:                 episode reward: 45.4500,                 loss: 1.0671
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 564.65,                last time consumption/overall running time: 609.1330s / 406205.5849 s
env0_first_0:                 episode reward: -46.7500,                 loss: 1.4221
env0_second_0:                 episode reward: 46.7500,                 loss: 1.1242
env1_first_0:                 episode reward: -62.4500,                 loss: nan
env1_second_0:                 episode reward: 62.4500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 666.7,                last time consumption/overall running time: 716.1453s / 406921.7302 s
env0_first_0:                 episode reward: -26.5500,                 loss: 1.5332
env0_second_0:                 episode reward: 26.5500,                 loss: 1.1340
env1_first_0:                 episode reward: -65.2000,                 loss: nan
env1_second_0:                 episode reward: 65.2000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 853.8,                last time consumption/overall running time: 914.1724s / 407835.9025 s
env0_first_0:                 episode reward: -38.5500,                 loss: 1.6038
env0_second_0:                 episode reward: 38.5500,                 loss: 1.1108
env1_first_0:                 episode reward: -35.9500,                 loss: nan
env1_second_0:                 episode reward: 35.9500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 609.75,                last time consumption/overall running time: 647.3020s / 408483.2046 s
env0_first_0:                 episode reward: -45.5000,                 loss: 1.4312
env0_second_0:                 episode reward: 45.5000,                 loss: 1.0304
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 514.0,                last time consumption/overall running time: 548.1905s / 409031.3951 s
env0_first_0:                 episode reward: -47.5500,                 loss: 1.3912
env0_second_0:                 episode reward: 47.5500,                 loss: 1.0130
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 730.4,                last time consumption/overall running time: 777.1828s / 409808.5778 s
env0_first_0:                 episode reward: -62.2500,                 loss: 1.4461
env0_second_0:                 episode reward: 62.2500,                 loss: 1.0423
env1_first_0:                 episode reward: -49.8500,                 loss: nan
env1_second_0:                 episode reward: 49.8500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 592.95,                last time consumption/overall running time: 630.5998s / 410439.1777 s
env0_first_0:                 episode reward: -65.3500,                 loss: 1.3800
env0_second_0:                 episode reward: 65.3500,                 loss: 1.0768
env1_first_0:                 episode reward: -41.0000,                 loss: nan
env1_second_0:                 episode reward: 41.0000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 467.45,                last time consumption/overall running time: 497.9923s / 410937.1700 s
env0_first_0:                 episode reward: -51.1000,                 loss: 1.3206
env0_second_0:                 episode reward: 51.1000,                 loss: 1.0480
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 444.75,                last time consumption/overall running time: 473.8563s / 411411.0263 s
env0_first_0:                 episode reward: -59.6500,                 loss: 1.3654
env0_second_0:                 episode reward: 59.6500,                 loss: 1.1107
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 446.1,                last time consumption/overall running time: 474.3513s / 411885.3776 s
env0_first_0:                 episode reward: -68.5000,                 loss: 1.3195
env0_second_0:                 episode reward: 68.5000,                 loss: 1.1776
env1_first_0:                 episode reward: -33.2500,                 loss: nan
env1_second_0:                 episode reward: 33.2500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 430.95,                last time consumption/overall running time: 456.2410s / 412341.6185 s
env0_first_0:                 episode reward: -40.1500,                 loss: 1.3224
env0_second_0:                 episode reward: 40.1500,                 loss: 1.1895
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 605.65,                last time consumption/overall running time: 635.7693s / 412977.3878 s
env0_first_0:                 episode reward: -32.6000,                 loss: 1.3626
env0_second_0:                 episode reward: 32.6000,                 loss: 1.1613
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 604.65,                last time consumption/overall running time: 641.9489s / 413619.3367 s
env0_first_0:                 episode reward: -64.1000,                 loss: 1.4180
env0_second_0:                 episode reward: 64.1000,                 loss: 1.2003
env1_first_0:                 episode reward: -35.3500,                 loss: nan
env1_second_0:                 episode reward: 35.3500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 502.3,                last time consumption/overall running time: 530.0542s / 414149.3909 s
env0_first_0:                 episode reward: -58.1500,                 loss: 1.5165
env0_second_0:                 episode reward: 58.1500,                 loss: 1.1762
env1_first_0:                 episode reward: -41.4000,                 loss: nan
env1_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 687.7,                last time consumption/overall running time: 724.8954s / 414874.2863 s
env0_first_0:                 episode reward: -59.0000,                 loss: 1.5222
env0_second_0:                 episode reward: 59.0000,                 loss: 1.1471
env1_first_0:                 episode reward: -35.0500,                 loss: nan
env1_second_0:                 episode reward: 35.0500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 570.3,                last time consumption/overall running time: 605.1173s / 415479.4037 s
env0_first_0:                 episode reward: -50.8000,                 loss: 1.5032
env0_second_0:                 episode reward: 50.8000,                 loss: 1.2191
env1_first_0:                 episode reward: -40.2000,                 loss: nan
env1_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 678.7,                last time consumption/overall running time: 716.0866s / 416195.4902 s
env0_first_0:                 episode reward: -12.5500,                 loss: 1.4711
env0_second_0:                 episode reward: 12.5500,                 loss: 1.2072
env1_first_0:                 episode reward: -36.7000,                 loss: nan
env1_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 507.05,                last time consumption/overall running time: 538.3816s / 416733.8719 s
env0_first_0:                 episode reward: -70.7000,                 loss: 1.5020
env0_second_0:                 episode reward: 70.7000,                 loss: 1.1838
env1_first_0:                 episode reward: -57.1500,                 loss: nan
env1_second_0:                 episode reward: 57.1500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 779.05,                last time consumption/overall running time: 818.4067s / 417552.2786 s
env0_first_0:                 episode reward: -48.6500,                 loss: 1.5194
env0_second_0:                 episode reward: 48.6500,                 loss: 1.1869
env1_first_0:                 episode reward: -34.5500,                 loss: nan
env1_second_0:                 episode reward: 34.5500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 762.35,                last time consumption/overall running time: 803.8224s / 418356.1010 s
env0_first_0:                 episode reward: -54.9500,                 loss: 1.5001
env0_second_0:                 episode reward: 54.9500,                 loss: 1.1092
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 692.7,                last time consumption/overall running time: 736.6392s / 419092.7402 s
env0_first_0:                 episode reward: -52.7500,                 loss: 1.3888
env0_second_0:                 episode reward: 52.7500,                 loss: 1.2157
env1_first_0:                 episode reward: -28.6500,                 loss: nan
env1_second_0:                 episode reward: 28.6500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 587.05,                last time consumption/overall running time: 618.5907s / 419711.3310 s
env0_first_0:                 episode reward: -45.6500,                 loss: 1.3423
env0_second_0:                 episode reward: 45.6500,                 loss: 1.0220
env1_first_0:                 episode reward: -57.3000,                 loss: nan
env1_second_0:                 episode reward: 57.3000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 591.5,                last time consumption/overall running time: 623.7351s / 420335.0660 s
env0_first_0:                 episode reward: -58.7500,                 loss: 1.4193
env0_second_0:                 episode reward: 58.7500,                 loss: 1.0592
env1_first_0:                 episode reward: -39.9000,                 loss: nan
env1_second_0:                 episode reward: 39.9000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 654.45,                last time consumption/overall running time: 690.3074s / 421025.3734 s
env0_first_0:                 episode reward: -62.9500,                 loss: 1.3182
env0_second_0:                 episode reward: 62.9500,                 loss: 1.0741
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 633.1,                last time consumption/overall running time: 668.0484s / 421693.4218 s
env0_first_0:                 episode reward: -57.1000,                 loss: 1.4723
env0_second_0:                 episode reward: 57.1000,                 loss: 1.1162
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 545.9,                last time consumption/overall running time: 577.0873s / 422270.5091 s
env0_first_0:                 episode reward: -49.4000,                 loss: 1.4549
env0_second_0:                 episode reward: 49.4000,                 loss: 1.1593
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 448.3,                last time consumption/overall running time: 470.7057s / 422741.2147 s
env0_first_0:                 episode reward: -49.9000,                 loss: 1.3542
env0_second_0:                 episode reward: 49.9000,                 loss: 1.0693
env1_first_0:                 episode reward: -41.4000,                 loss: nan
env1_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 723.4,                last time consumption/overall running time: 753.6493s / 423494.8640 s
env0_first_0:                 episode reward: -55.1500,                 loss: 1.2883
env0_second_0:                 episode reward: 55.1500,                 loss: 1.1004
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 471.4,                last time consumption/overall running time: 492.8482s / 423987.7122 s
env0_first_0:                 episode reward: -50.0500,                 loss: 1.5353
env0_second_0:                 episode reward: 50.0500,                 loss: 1.1809
env1_first_0:                 episode reward: -62.2000,                 loss: nan
env1_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 708.65,                last time consumption/overall running time: 741.9831s / 424729.6954 s
env0_first_0:                 episode reward: -49.2500,                 loss: 1.4804
env0_second_0:                 episode reward: 49.2500,                 loss: 1.1373
env1_first_0:                 episode reward: -39.5500,                 loss: nan
env1_second_0:                 episode reward: 39.5500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 684.0,                last time consumption/overall running time: 719.0149s / 425448.7102 s
env0_first_0:                 episode reward: -56.4500,                 loss: 1.4455
env0_second_0:                 episode reward: 56.4500,                 loss: 1.0865
env1_first_0:                 episode reward: -50.7500,                 loss: nan
env1_second_0:                 episode reward: 50.7500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 496.3,                last time consumption/overall running time: 516.7886s / 425965.4988 s
env0_first_0:                 episode reward: -54.7500,                 loss: 1.4238
env0_second_0:                 episode reward: 54.7500,                 loss: 1.1444
env1_first_0:                 episode reward: -58.0000,                 loss: nan
env1_second_0:                 episode reward: 58.0000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 682.5,                last time consumption/overall running time: 714.4770s / 426679.9759 s
env0_first_0:                 episode reward: -35.2500,                 loss: 1.5179
env0_second_0:                 episode reward: 35.2500,                 loss: 1.2458
env1_first_0:                 episode reward: -45.6000,                 loss: nan
env1_second_0:                 episode reward: 45.6000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 545.55,                last time consumption/overall running time: 568.1464s / 427248.1223 s
env0_first_0:                 episode reward: -65.7500,                 loss: 1.4439
env0_second_0:                 episode reward: 65.7500,                 loss: 1.1952
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 736.15,                last time consumption/overall running time: 768.5857s / 428016.7081 s
env0_first_0:                 episode reward: -43.1000,                 loss: 1.4010
env0_second_0:                 episode reward: 43.1000,                 loss: 1.1858
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 634.5,                last time consumption/overall running time: 664.6824s / 428681.3904 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.5060
env0_second_0:                 episode reward: 55.6000,                 loss: 1.2673
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 540.45,                last time consumption/overall running time: 561.6517s / 429243.0421 s
env0_first_0:                 episode reward: -40.4500,                 loss: 1.4972
env0_second_0:                 episode reward: 40.4500,                 loss: 1.2772
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 552.1,                last time consumption/overall running time: 573.7829s / 429816.8250 s
env0_first_0:                 episode reward: -49.6500,                 loss: 1.5357
env0_second_0:                 episode reward: 49.6500,                 loss: 1.3332
env1_first_0:                 episode reward: -48.8500,                 loss: nan
env1_second_0:                 episode reward: 48.8500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 532.0,                last time consumption/overall running time: 551.9879s / 430368.8129 s
env0_first_0:                 episode reward: -55.5000,                 loss: 1.4643
env0_second_0:                 episode reward: 55.5000,                 loss: 1.2722
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 683.45,                last time consumption/overall running time: 718.1225s / 431086.9353 s
env0_first_0:                 episode reward: -41.5000,                 loss: 1.4575
env0_second_0:                 episode reward: 41.5000,                 loss: 1.3492
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 578.5,                last time consumption/overall running time: 600.5800s / 431687.5153 s
env0_first_0:                 episode reward: -53.4500,                 loss: 1.6201
env0_second_0:                 episode reward: 53.4500,                 loss: 1.3275
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 605.35,                last time consumption/overall running time: 635.5453s / 432323.0606 s
env0_first_0:                 episode reward: -48.7500,                 loss: 1.4495
env0_second_0:                 episode reward: 48.7500,                 loss: 1.3259
env1_first_0:                 episode reward: -33.0000,                 loss: nan
env1_second_0:                 episode reward: 33.0000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 481.35,                last time consumption/overall running time: 500.9581s / 432824.0188 s
env0_first_0:                 episode reward: -48.9000,                 loss: 1.3582
env0_second_0:                 episode reward: 48.9000,                 loss: 1.3348
env1_first_0:                 episode reward: -51.6500,                 loss: nan
env1_second_0:                 episode reward: 51.6500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 473.35,                last time consumption/overall running time: 498.1515s / 433322.1702 s
env0_first_0:                 episode reward: -56.1000,                 loss: 1.3551
env0_second_0:                 episode reward: 56.1000,                 loss: 1.3347
env1_first_0:                 episode reward: -47.1000,                 loss: nan
env1_second_0:                 episode reward: 47.1000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 738.45,                last time consumption/overall running time: 770.4812s / 434092.6514 s
env0_first_0:                 episode reward: -30.1000,                 loss: 1.2748
env0_second_0:                 episode reward: 30.1000,                 loss: 1.2938
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 555.8,                last time consumption/overall running time: 584.8599s / 434677.5114 s
env0_first_0:                 episode reward: -42.0500,                 loss: 1.3083
env0_second_0:                 episode reward: 42.0500,                 loss: 1.2535
env1_first_0:                 episode reward: -40.3500,                 loss: nan
env1_second_0:                 episode reward: 40.3500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 506.95,                last time consumption/overall running time: 536.7418s / 435214.2532 s
env0_first_0:                 episode reward: -51.4000,                 loss: 1.4479
env0_second_0:                 episode reward: 51.4000,                 loss: 1.3735
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 497.25,                last time consumption/overall running time: 519.0389s / 435733.2920 s
env0_first_0:                 episode reward: -53.0500,                 loss: 1.5466
env0_second_0:                 episode reward: 53.0500,                 loss: 1.3172
env1_first_0:                 episode reward: -34.2000,                 loss: nan
env1_second_0:                 episode reward: 34.2000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 541.25,                last time consumption/overall running time: 566.6169s / 436299.9089 s
env0_first_0:                 episode reward: -38.1500,                 loss: 1.6506
env0_second_0:                 episode reward: 38.1500,                 loss: 1.3043
env1_first_0:                 episode reward: -55.3500,                 loss: nan
env1_second_0:                 episode reward: 55.3500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 647.05,                last time consumption/overall running time: 677.9511s / 436977.8600 s
env0_first_0:                 episode reward: -30.3000,                 loss: 1.7521
env0_second_0:                 episode reward: 30.3000,                 loss: 1.3446
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 685.4,                last time consumption/overall running time: 704.5443s / 437682.4043 s
env0_first_0:                 episode reward: -52.0500,                 loss: 1.6216
env0_second_0:                 episode reward: 52.0500,                 loss: 1.3712
env1_first_0:                 episode reward: -30.4000,                 loss: nan
env1_second_0:                 episode reward: 30.4000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 566.55,                last time consumption/overall running time: 585.5159s / 438267.9202 s
env0_first_0:                 episode reward: -47.7000,                 loss: 1.5461
env0_second_0:                 episode reward: 47.7000,                 loss: 1.2957
env1_first_0:                 episode reward: -37.3000,                 loss: nan
env1_second_0:                 episode reward: 37.3000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 514.45,                last time consumption/overall running time: 532.3222s / 438800.2424 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn.py:293: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.FloatTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -44.6500,                 loss: 1.5947
env0_second_0:                 episode reward: 44.6500,                 loss: 1.3221
env1_first_0:                 episode reward: -57.1000,                 loss: nan
env1_second_0:                 episode reward: 57.1000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 640.55,                last time consumption/overall running time: 658.1022s / 439458.3446 s
env0_first_0:                 episode reward: -33.3000,                 loss: 1.6350
env0_second_0:                 episode reward: 33.3000,                 loss: 1.4273
env1_first_0:                 episode reward: -62.1000,                 loss: nan
env1_second_0:                 episode reward: 62.1000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 566.2,                last time consumption/overall running time: 585.3362s / 440043.6808 s
env0_first_0:                 episode reward: -53.5500,                 loss: 1.5981
env0_second_0:                 episode reward: 53.5500,                 loss: 1.3001
env1_first_0:                 episode reward: -55.2500,                 loss: nan
env1_second_0:                 episode reward: 55.2500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 422.0,                last time consumption/overall running time: 436.3721s / 440480.0529 s
env0_first_0:                 episode reward: -59.5500,                 loss: 1.7952
env0_second_0:                 episode reward: 59.5500,                 loss: 1.3481
env1_first_0:                 episode reward: -53.7500,                 loss: nan
env1_second_0:                 episode reward: 53.7500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 714.4,                last time consumption/overall running time: 740.6780s / 441220.7309 s
env0_first_0:                 episode reward: -46.3000,                 loss: 1.7953
env0_second_0:                 episode reward: 46.3000,                 loss: 1.2753
env1_first_0:                 episode reward: -56.7000,                 loss: nan
env1_second_0:                 episode reward: 56.7000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 543.7,                last time consumption/overall running time: 561.0199s / 441781.7508 s
env0_first_0:                 episode reward: -44.9000,                 loss: 1.6273
env0_second_0:                 episode reward: 44.9000,                 loss: 1.2417
env1_first_0:                 episode reward: -65.6500,                 loss: nan
env1_second_0:                 episode reward: 65.6500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 707.65,                last time consumption/overall running time: 732.8756s / 442514.6264 s
env0_first_0:                 episode reward: -42.6000,                 loss: 1.4002
env0_second_0:                 episode reward: 42.6000,                 loss: 1.2368
env1_first_0:                 episode reward: -59.7000,                 loss: nan
env1_second_0:                 episode reward: 59.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 639.85,                last time consumption/overall running time: 663.2938s / 443177.9202 s
env0_first_0:                 episode reward: -54.6500,                 loss: 1.3974
env0_second_0:                 episode reward: 54.6500,                 loss: 1.1170
env1_first_0:                 episode reward: -52.8500,                 loss: nan
env1_second_0:                 episode reward: 52.8500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 627.6,                last time consumption/overall running time: 644.9308s / 443822.8509 s
env0_first_0:                 episode reward: -48.2000,                 loss: 1.4297
env0_second_0:                 episode reward: 48.2000,                 loss: 1.1245
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 729.1,                last time consumption/overall running time: 741.1274s / 444563.9783 s
env0_first_0:                 episode reward: -41.0000,                 loss: 1.5905
env0_second_0:                 episode reward: 41.0000,                 loss: 1.1098
env1_first_0:                 episode reward: -45.3000,                 loss: nan
env1_second_0:                 episode reward: 45.3000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 586.6,                last time consumption/overall running time: 595.0196s / 445158.9978 s
env0_first_0:                 episode reward: -61.7000,                 loss: 1.6084
env0_second_0:                 episode reward: 61.7000,                 loss: 1.1272
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 536.6,                last time consumption/overall running time: 545.0786s / 445704.0765 s
env0_first_0:                 episode reward: -51.3500,                 loss: 1.6712
env0_second_0:                 episode reward: 51.3500,                 loss: 1.1905
env1_first_0:                 episode reward: -55.1000,                 loss: nan
env1_second_0:                 episode reward: 55.1000,                 loss: nan
