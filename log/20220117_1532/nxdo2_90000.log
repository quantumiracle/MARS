pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f15cc53e090>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.227, 0.079, 0.076, ..., 0.   , 0.   , 0.   ]) array([0.098, 0.008, 0.073, ..., 0.   , 0.   , 0.   ])]
Load checkpoints (policy family):  [list(['83', '5753', '6419', '9691', '12712', '16446', '20191', '20772', '24729', '28587', '35631', '38431', '38946', '39041', '39808', '40118', '40412', '41100', '41478', '41778', '41983', '42076', '42433', '42768', '43151', '43229', '43949', '44117', '44258', '44846', '45166', '45962', '46596', '46667', '47327', '47599', '47724', '48094', '48455', '48649', '48828', '49089', '49310', '49568', '49947', '50154', '50323', '50446', '51000', '52183', '52933', '53029', '53373', '54083', '54247', '54577', '54813', '55333', '55871', '55920', '55984', '56212', '56500', '56609', '56849', '57129', '57305', '57555', '59346', '59648', '59764', '60207', '60423', '61244', '61420', '61592', '61837', '62162', '62663', '62787', '63152', '63581', '64655', '65225', '65678', '65977', '66229', '66493', '66823', '67596', '67842', '68192', '68377', '68658', '68870', '69079', '69130', '70683', '70945', '71028', '71872', '72171', '72330', '73029', '73234', '73651', '74310', '74673', '75564', '75872', '76617', '77360', '77698', '78278', '78468', '78608', '78725', '78831', '78946', '79127', '79375', '80113', '80412', '80964', '81822', '82081', '82591', '82743', '83276', '83457', '83821', '84289', '84705', '85190', '85520', '86114', '86276', '86458', '86795', '87082', '87322', '87419', '87647', '88120', '89504'])
 list(['121', '6342', '6627', '9768', '12785', '16467', '20231', '20802', '24751', '28619', '35652', '38452', '38973', '39078', '39831', '40164', '40433', '41156', '41501', '41819', '42011', '42097', '42458', '42797', '43176', '43250', '44010', '44146', '44297', '44888', '45313', '45997', '46620', '46694', '47431', '47654', '47771', '48131', '48485', '48670', '48949', '49156', '49349', '49679', '49974', '50175', '50367', '50477', '51025', '52237', '52954', '53079', '53449', '54148', '54273', '54643', '54841', '55369', '55895', '55950', '56022', '56241', '56546', '56722', '56881', '57157', '57352', '57708', '59367', '59703', '59852', '60231', '60531', '61274', '61444', '61613', '61885', '62188', '62700', '62816', '63249', '63724', '64717', '65246', '65752', '66003', '66266', '66518', '66855', '67649', '67880', '68289', '68425', '68783', '68960', '69100', '69268', '70743', '70983', '71060', '71894', '72207', '72417', '73050', '73299', '73719', '74432', '74706', '75649', '75983', '76641', '77384', '77739', '78307', '78490', '78693', '78767', '78877', '78967', '79225', '79437', '80135', '80505', '81139', '81856', '82144', '82612', '82779', '83426', '83515', '83845', '84367', '84741', '85211', '85586', '86171', '86300', '86517', '86857', '87103', '87356', '87440', '87695', '88141'])]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_90000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_90000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_90000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2658s / 1.2658 s
agent0:                 episode reward: -0.9838,                 loss: nan
agent1:                 episode reward: 0.9838,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0815s / 1.3473 s
agent0:                 episode reward: -0.3709,                 loss: nan
agent1:                 episode reward: 0.3709,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 1.6221 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 2.2198 s
agent0:                 episode reward: 0.7408,                 loss: nan
agent1:                 episode reward: -0.7408,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0932s / 2.3130 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0780s / 2.3910 s
agent0:                 episode reward: 0.2520,                 loss: nan
agent1:                 episode reward: -0.2520,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2969s / 2.6880 s
agent0:                 episode reward: -0.0089,                 loss: nan
agent1:                 episode reward: 0.0089,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5315s / 3.2194 s
agent0:                 episode reward: 0.1380,                 loss: nan
agent1:                 episode reward: -0.1380,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4764s / 3.6958 s
agent0:                 episode reward: 0.1753,                 loss: nan
agent1:                 episode reward: -0.1753,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2834s / 3.9793 s
agent0:                 episode reward: 0.2177,                 loss: nan
agent1:                 episode reward: -0.2177,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 4.6584 s
agent0:                 episode reward: -0.0196,                 loss: nan
agent1:                 episode reward: 0.0196,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 40.0896s / 44.7480 s
agent0:                 episode reward: 0.3801,                 loss: nan
agent1:                 episode reward: -0.3801,                 loss: 0.1762
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.4119s / 144.1599 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.1673
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.0242s / 244.1841 s
agent0:                 episode reward: 0.3212,                 loss: nan
agent1:                 episode reward: -0.3212,                 loss: 0.1628
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.4496s / 341.6337 s
agent0:                 episode reward: 0.0786,                 loss: nan
agent1:                 episode reward: -0.0786,                 loss: 0.1609
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1000s / 439.7337 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.1591
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.3761s / 539.1097 s
agent0:                 episode reward: -0.0157,                 loss: nan
agent1:                 episode reward: 0.0157,                 loss: 0.1583
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.4041s / 636.5138 s
agent0:                 episode reward: -0.2209,                 loss: nan
agent1:                 episode reward: 0.2209,                 loss: 0.1545
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.0540s / 735.5678 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: 0.1539
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.2135s / 836.7813 s
agent0:                 episode reward: -0.0519,                 loss: nan
agent1:                 episode reward: 0.0519,                 loss: 0.1542
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.8405s / 937.6218 s
agent0:                 episode reward: -0.0943,                 loss: nan
agent1:                 episode reward: 0.0943,                 loss: 0.1540
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.4697s / 1035.0915 s
agent0:                 episode reward: -0.1765,                 loss: nan
agent1:                 episode reward: 0.1765,                 loss: 0.1554
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.1712s / 1134.2627 s
agent0:                 episode reward: 0.2074,                 loss: nan
agent1:                 episode reward: -0.2074,                 loss: 0.1550
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.5240s / 1233.7868 s
agent0:                 episode reward: -0.1244,                 loss: nan
agent1:                 episode reward: 0.1244,                 loss: 0.1546
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 103.3402s / 1337.1269 s
agent0:                 episode reward: 0.0228,                 loss: nan
agent1:                 episode reward: -0.0228,                 loss: 0.1540
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.9668s / 1436.0937 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: 0.1525
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.7919s / 1533.8857 s
agent0:                 episode reward: -0.4962,                 loss: nan
agent1:                 episode reward: 0.4962,                 loss: 0.1515
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 101.2022s / 1635.0879 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.1520
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.8082s / 1735.8960 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.1592
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.4312s / 1836.3272 s
agent0:                 episode reward: 0.0161,                 loss: nan
agent1:                 episode reward: -0.0161,                 loss: 0.1584
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5842s / 1936.9114 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: 0.1564
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.7148s / 2036.6262 s
agent0:                 episode reward: 0.0798,                 loss: nan
agent1:                 episode reward: -0.0798,                 loss: 0.1565
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5720s / 2137.1981 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.1568
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.4522s / 2236.6503 s
agent0:                 episode reward: -0.1027,                 loss: nan
agent1:                 episode reward: 0.1027,                 loss: 0.1573
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.0856s / 2334.7360 s
agent0:                 episode reward: 0.3805,                 loss: nan
agent1:                 episode reward: -0.3805,                 loss: 0.1578
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.0964s / 2433.8324 s
agent0:                 episode reward: -0.0227,                 loss: nan
agent1:                 episode reward: 0.0227,                 loss: 0.1564
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1042s / 2531.9366 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.1561
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.0857s / 2629.0223 s
agent0:                 episode reward: -0.1171,                 loss: nan
agent1:                 episode reward: 0.1171,                 loss: 0.1574
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 104.4620s / 2733.4843 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.1565
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1156s / 2865.6000 s
agent0:                 episode reward: -0.0966,                 loss: nan
agent1:                 episode reward: 0.0966,                 loss: 0.1563
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5536s / 3003.1535 s
agent0:                 episode reward: 0.4535,                 loss: nan
agent1:                 episode reward: -0.4535,                 loss: 0.1555
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0341s / 3143.1877 s
agent0:                 episode reward: 0.0116,                 loss: nan
agent1:                 episode reward: -0.0116,                 loss: 0.1554
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5005s / 3280.6881 s
agent0:                 episode reward: -0.2647,                 loss: nan
agent1:                 episode reward: 0.2647,                 loss: 0.1544
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1723s / 3415.8604 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: 0.1552
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4249s / 3554.2853 s
agent0:                 episode reward: 0.3247,                 loss: nan
agent1:                 episode reward: -0.3247,                 loss: 0.1551
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0343s / 3691.3196 s
agent0:                 episode reward: 0.0030,                 loss: nan
agent1:                 episode reward: -0.0030,                 loss: 0.1545
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2610s / 3829.5805 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1527
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8102s / 3966.3907 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.1534
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4465s / 4104.8372 s
agent0:                 episode reward: 0.4304,                 loss: nan
agent1:                 episode reward: -0.4304,                 loss: 0.1530
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7611s / 4243.5983 s
agent0:                 episode reward: -0.1886,                 loss: nan
agent1:                 episode reward: 0.1886,                 loss: 0.1549
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7960s / 4379.3944 s
agent0:                 episode reward: 0.2083,                 loss: nan
agent1:                 episode reward: -0.2083,                 loss: 0.1534
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6794s / 4520.0738 s
agent0:                 episode reward: 0.0300,                 loss: nan
agent1:                 episode reward: -0.0300,                 loss: 0.1529
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7722s / 4660.8460 s
agent0:                 episode reward: 0.2996,                 loss: nan
agent1:                 episode reward: -0.2996,                 loss: 0.1526
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4139s / 4804.2600 s
agent0:                 episode reward: -0.1152,                 loss: nan
agent1:                 episode reward: 0.1152,                 loss: 0.1547
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8315s / 4942.0915 s
agent0:                 episode reward: 0.2866,                 loss: nan
agent1:                 episode reward: -0.2866,                 loss: 0.1524
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6768s / 5084.7683 s
agent0:                 episode reward: -0.2581,                 loss: nan
agent1:                 episode reward: 0.2581,                 loss: 0.1534
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4075s / 5223.1759 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.1513
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6956s / 5361.8715 s
agent0:                 episode reward: 0.2038,                 loss: nan
agent1:                 episode reward: -0.2038,                 loss: 0.1524
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5023s / 5502.3737 s
agent0:                 episode reward: 0.3829,                 loss: nan
agent1:                 episode reward: -0.3829,                 loss: 0.1522
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7168s / 5641.0905 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1530
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8627s / 5776.9532 s
agent0:                 episode reward: -0.2562,                 loss: nan
agent1:                 episode reward: 0.2562,                 loss: 0.1518
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5522s / 5913.5054 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1526
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7850s / 6054.2904 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: 0.1546
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5547s / 6191.8450 s
agent0:                 episode reward: -0.1495,                 loss: nan
agent1:                 episode reward: 0.1495,                 loss: 0.1545
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9692s / 6332.8143 s
agent0:                 episode reward: -0.1661,                 loss: nan
agent1:                 episode reward: 0.1661,                 loss: 0.1547
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2270s / 6468.0412 s
agent0:                 episode reward: 0.0189,                 loss: nan
agent1:                 episode reward: -0.0189,                 loss: 0.1556
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5118s / 6606.5530 s
agent0:                 episode reward: -0.0866,                 loss: nan
agent1:                 episode reward: 0.0866,                 loss: 0.1565
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9548s / 6743.5078 s
agent0:                 episode reward: 0.4930,                 loss: nan
agent1:                 episode reward: -0.4930,                 loss: 0.1543
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7293s / 6883.2371 s
agent0:                 episode reward: -0.1976,                 loss: nan
agent1:                 episode reward: 0.1976,                 loss: 0.1575
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3799s / 7020.6170 s
agent0:                 episode reward: 0.0428,                 loss: nan
agent1:                 episode reward: -0.0428,                 loss: 0.1569
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9941s / 7159.6111 s
agent0:                 episode reward: 0.0693,                 loss: nan
agent1:                 episode reward: -0.0693,                 loss: 0.1559
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2717s / 7298.8828 s
agent0:                 episode reward: 0.1089,                 loss: nan
agent1:                 episode reward: -0.1089,                 loss: 0.1562
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5720s / 7438.4548 s
agent0:                 episode reward: -0.1987,                 loss: nan
agent1:                 episode reward: 0.1987,                 loss: 0.1561
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6541s / 7578.1089 s
agent0:                 episode reward: 0.2507,                 loss: nan
agent1:                 episode reward: -0.2507,                 loss: 0.1554
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1510s / 7716.2599 s
agent0:                 episode reward: 0.0176,                 loss: nan
agent1:                 episode reward: -0.0176,                 loss: 0.1550
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6575s / 7854.9174 s
agent0:                 episode reward: -0.0208,                 loss: nan
agent1:                 episode reward: 0.0208,                 loss: 0.1560
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8512s / 7991.7686 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.1557
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0691s / 8130.8377 s
agent0:                 episode reward: 0.0579,                 loss: nan
agent1:                 episode reward: -0.0579,                 loss: 0.1542
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5371s / 8270.3748 s
agent0:                 episode reward: 0.1852,                 loss: nan
agent1:                 episode reward: -0.1852,                 loss: 0.1556
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0089s / 8408.3837 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: 0.1554
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7763s / 8549.1601 s
agent0:                 episode reward: -0.2286,                 loss: nan
agent1:                 episode reward: 0.2286,                 loss: 0.1554
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2050s / 8688.3650 s
agent0:                 episode reward: -0.1191,                 loss: nan
agent1:                 episode reward: 0.1191,                 loss: 0.1544
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6787s / 8828.0437 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.1537
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4650s / 8964.5087 s
agent0:                 episode reward: 0.1506,                 loss: nan
agent1:                 episode reward: -0.1506,                 loss: 0.1538
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3354s / 9102.8442 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: 0.1537
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9830s / 9243.8271 s
agent0:                 episode reward: 0.0042,                 loss: nan
agent1:                 episode reward: -0.0042,                 loss: 0.1527
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5560s / 9382.3832 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: 0.1540
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3994s / 9523.7826 s
agent0:                 episode reward: 0.0204,                 loss: nan
agent1:                 episode reward: -0.0204,                 loss: 0.1551
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2791s / 9660.0617 s
agent0:                 episode reward: 0.0787,                 loss: nan
agent1:                 episode reward: -0.0787,                 loss: 0.1539
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4617s / 9800.5234 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1547
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7369s / 9939.2603 s
agent0:                 episode reward: -0.2264,                 loss: nan
agent1:                 episode reward: 0.2264,                 loss: 0.1539
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9454s / 10078.2057 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.1553
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2740s / 10219.4797 s
agent0:                 episode reward: -0.4050,                 loss: nan
agent1:                 episode reward: 0.4050,                 loss: 0.1541
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1446s / 10356.6242 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.1544
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3000s / 10495.9242 s
agent0:                 episode reward: -0.5341,                 loss: nan
agent1:                 episode reward: 0.5341,                 loss: 0.1541
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7773s / 10634.7015 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.1563
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5036s / 10774.2051 s
agent0:                 episode reward: -0.1515,                 loss: nan
agent1:                 episode reward: 0.1515,                 loss: 0.1578
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6593s / 10912.8644 s
agent0:                 episode reward: -0.0405,                 loss: nan
agent1:                 episode reward: 0.0405,                 loss: 0.1568
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5326s / 11050.3969 s
agent0:                 episode reward: -0.2821,                 loss: nan
agent1:                 episode reward: 0.2821,                 loss: 0.1582
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0446s / 11191.4415 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.1575
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1100s / 11330.5515 s
agent0:                 episode reward: 0.1231,                 loss: nan
agent1:                 episode reward: -0.1231,                 loss: 0.1568
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7082s / 11466.2596 s
agent0:                 episode reward: -0.1223,                 loss: nan
agent1:                 episode reward: 0.1223,                 loss: 0.1576
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5409s / 11606.8005 s
agent0:                 episode reward: 0.1466,                 loss: nan
agent1:                 episode reward: -0.1466,                 loss: 0.1563
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5226s / 11743.3231 s
agent0:                 episode reward: -0.1075,                 loss: nan
agent1:                 episode reward: 0.1075,                 loss: 0.1590
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0393s / 11882.3624 s
agent0:                 episode reward: 0.2039,                 loss: nan
agent1:                 episode reward: -0.2039,                 loss: 0.1566
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6066s / 12019.9690 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.1593
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1469s / 12157.1158 s
agent0:                 episode reward: -0.1161,                 loss: nan
agent1:                 episode reward: 0.1161,                 loss: 0.1564
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6062s / 12298.7220 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.1564
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8198s / 12442.5418 s
agent0:                 episode reward: -0.1900,                 loss: nan
agent1:                 episode reward: 0.1900,                 loss: 0.1552
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2485s / 12583.7902 s
agent0:                 episode reward: -0.1776,                 loss: nan
agent1:                 episode reward: 0.1776,                 loss: 0.1572
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5023s / 12728.2926 s
agent0:                 episode reward: -0.3248,                 loss: nan
agent1:                 episode reward: 0.3248,                 loss: 0.1566
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8804s / 12869.1730 s
agent0:                 episode reward: -0.2957,                 loss: nan
agent1:                 episode reward: 0.2957,                 loss: 0.1589
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6521s / 13009.8251 s
agent0:                 episode reward: 0.0619,                 loss: nan
agent1:                 episode reward: -0.0619,                 loss: 0.1589
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3049s / 13152.1300 s
agent0:                 episode reward: -0.3246,                 loss: nan
agent1:                 episode reward: 0.3246,                 loss: 0.1591
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2006s / 13293.3306 s
agent0:                 episode reward: 0.1934,                 loss: nan
agent1:                 episode reward: -0.1934,                 loss: 0.1595
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4755s / 13434.8061 s
agent0:                 episode reward: 0.1446,                 loss: nan
agent1:                 episode reward: -0.1446,                 loss: 0.1598
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3984s / 13576.2045 s
agent0:                 episode reward: 0.1694,                 loss: nan
agent1:                 episode reward: -0.1694,                 loss: 0.1607
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1324s / 13717.3370 s
agent0:                 episode reward: 0.1223,                 loss: nan
agent1:                 episode reward: -0.1223,                 loss: 0.1605
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6328s / 13856.9698 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1598
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0054s / 13995.9752 s
agent0:                 episode reward: 0.0729,                 loss: nan
agent1:                 episode reward: -0.0729,                 loss: 0.1583
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.0437s / 14141.0189 s
agent0:                 episode reward: -0.1633,                 loss: nan
agent1:                 episode reward: 0.1633,                 loss: 0.1588
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9402s / 14280.9591 s
agent0:                 episode reward: 0.3390,                 loss: nan
agent1:                 episode reward: -0.3390,                 loss: 0.1582
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5831s / 14422.5422 s
agent0:                 episode reward: 0.1761,                 loss: nan
agent1:                 episode reward: -0.1761,                 loss: 0.1583
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4887s / 14565.0309 s
agent0:                 episode reward: 0.2838,                 loss: nan
agent1:                 episode reward: -0.2838,                 loss: 0.1577
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9626s / 14705.9935 s
agent0:                 episode reward: 0.1362,                 loss: nan
agent1:                 episode reward: -0.1362,                 loss: 0.1588
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7407s / 14846.7342 s
agent0:                 episode reward: -0.5525,                 loss: nan
agent1:                 episode reward: 0.5525,                 loss: 0.1584
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6285s / 14989.3627 s
agent0:                 episode reward: 0.2373,                 loss: nan
agent1:                 episode reward: -0.2373,                 loss: 0.1591
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4804s / 15129.8431 s
agent0:                 episode reward: -0.2753,                 loss: nan
agent1:                 episode reward: 0.2753,                 loss: 0.1573
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2827s / 15273.1258 s
agent0:                 episode reward: 0.1574,                 loss: nan
agent1:                 episode reward: -0.1574,                 loss: 0.1581
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5280s / 15412.6538 s
agent0:                 episode reward: -0.2391,                 loss: nan
agent1:                 episode reward: 0.2391,                 loss: 0.1550
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3273s / 15554.9811 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.1565
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0068s / 15697.9879 s
agent0:                 episode reward: 0.0125,                 loss: nan
agent1:                 episode reward: -0.0125,                 loss: 0.1556
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6810s / 15838.6689 s
agent0:                 episode reward: -0.2365,                 loss: nan
agent1:                 episode reward: 0.2365,                 loss: 0.1568
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4799s / 15981.1488 s
agent0:                 episode reward: -0.0055,                 loss: nan
agent1:                 episode reward: 0.0055,                 loss: 0.1581
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.1135s / 16126.2623 s
agent0:                 episode reward: -0.1732,                 loss: nan
agent1:                 episode reward: 0.1732,                 loss: 0.1571
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3201s / 16267.5823 s
agent0:                 episode reward: -0.2408,                 loss: nan
agent1:                 episode reward: 0.2408,                 loss: 0.1560
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2139s / 16407.7962 s
agent0:                 episode reward: -0.0557,                 loss: nan
agent1:                 episode reward: 0.0557,                 loss: 0.1576
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9429s / 16548.7391 s
agent0:                 episode reward: -0.2525,                 loss: nan
agent1:                 episode reward: 0.2525,                 loss: 0.1569
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0659s / 16684.8051 s
agent0:                 episode reward: -0.2803,                 loss: nan
agent1:                 episode reward: 0.2803,                 loss: 0.1557
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8910s / 16824.6960 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.1569
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5418s / 16965.2378 s
agent0:                 episode reward: 0.2692,                 loss: nan
agent1:                 episode reward: -0.2692,                 loss: 0.1556
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4946s / 17104.7324 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: 0.1584
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0618s / 17245.7942 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.1565
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8431s / 17387.6373 s
agent0:                 episode reward: 0.1988,                 loss: nan
agent1:                 episode reward: -0.1988,                 loss: 0.1563
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6096s / 17528.2469 s
agent0:                 episode reward: -0.2082,                 loss: nan
agent1:                 episode reward: 0.2082,                 loss: 0.1557
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8629s / 17667.1098 s
agent0:                 episode reward: -0.2092,                 loss: nan
agent1:                 episode reward: 0.2092,                 loss: 0.1601
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8916s / 17809.0014 s
agent0:                 episode reward: 0.0493,                 loss: nan
agent1:                 episode reward: -0.0493,                 loss: 0.1584
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8522s / 17951.8536 s
agent0:                 episode reward: -0.0247,                 loss: nan
agent1:                 episode reward: 0.0247,                 loss: 0.1584
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6337s / 18091.4873 s
agent0:                 episode reward: 0.1158,                 loss: nan
agent1:                 episode reward: -0.1158,                 loss: 0.1582
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8767s / 18232.3640 s
agent0:                 episode reward: 0.2949,                 loss: nan
agent1:                 episode reward: -0.2949,                 loss: 0.1588
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7495s / 18377.1135 s
agent0:                 episode reward: 0.0686,                 loss: nan
agent1:                 episode reward: -0.0686,                 loss: 0.1588
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6665s / 18518.7800 s
agent0:                 episode reward: -0.0895,                 loss: nan
agent1:                 episode reward: 0.0895,                 loss: 0.1597
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7329s / 18658.5129 s
agent0:                 episode reward: 0.0303,                 loss: nan
agent1:                 episode reward: -0.0303,                 loss: 0.1586
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.4267s / 18803.9397 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.1609
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4349s / 18945.3745 s
agent0:                 episode reward: 0.0221,                 loss: nan
agent1:                 episode reward: -0.0221,                 loss: 0.1595
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9889s / 19084.3634 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.1590
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6846s / 19226.0480 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.1585
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 146.1515s / 19372.1995 s
agent0:                 episode reward: -0.2732,                 loss: nan
agent1:                 episode reward: 0.2732,                 loss: 0.1574
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3852s / 19514.5847 s
agent0:                 episode reward: 0.1035,                 loss: nan
agent1:                 episode reward: -0.1035,                 loss: 0.1610
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3851s / 19656.9698 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: 0.1582
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7823s / 19799.7521 s
agent0:                 episode reward: 0.3509,                 loss: nan
agent1:                 episode reward: -0.3509,                 loss: 0.1580
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0101s / 19938.7623 s
agent0:                 episode reward: -0.0202,                 loss: nan
agent1:                 episode reward: 0.0202,                 loss: 0.1591
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8331s / 20077.5953 s
agent0:                 episode reward: 0.5363,                 loss: nan
agent1:                 episode reward: -0.5363,                 loss: 0.1566
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9724s / 20217.5677 s
agent0:                 episode reward: -0.2196,                 loss: nan
agent1:                 episode reward: 0.2196,                 loss: 0.1575
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1675s / 20358.7352 s
agent0:                 episode reward: -0.3308,                 loss: nan
agent1:                 episode reward: 0.3308,                 loss: 0.1575
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0676s / 20502.8028 s
agent0:                 episode reward: -0.1699,                 loss: nan
agent1:                 episode reward: 0.1699,                 loss: 0.1582
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9943s / 20645.7971 s
agent0:                 episode reward: -0.0019,                 loss: nan
agent1:                 episode reward: 0.0019,                 loss: 0.1568
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8676s / 20781.6647 s
agent0:                 episode reward: -0.2412,                 loss: nan
agent1:                 episode reward: 0.2412,                 loss: 0.1582
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9367s / 20916.6014 s
agent0:                 episode reward: -0.1335,                 loss: nan
agent1:                 episode reward: 0.1335,                 loss: 0.1584
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.5245s / 21047.1260 s
agent0:                 episode reward: -0.0381,                 loss: nan
agent1:                 episode reward: 0.0381,                 loss: 0.1588
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6651s / 21180.7911 s
agent0:                 episode reward: 0.2545,                 loss: nan
agent1:                 episode reward: -0.2545,                 loss: 0.1585
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5968s / 21320.3879 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.1569
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4290s / 21464.8169 s
agent0:                 episode reward: 0.3294,                 loss: nan
agent1:                 episode reward: -0.3294,                 loss: 0.1577
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.8254s / 21610.6423 s
agent0:                 episode reward: -0.0877,                 loss: nan
agent1:                 episode reward: 0.0877,                 loss: 0.1566
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9414s / 21751.5837 s
agent0:                 episode reward: -0.4077,                 loss: nan
agent1:                 episode reward: 0.4077,                 loss: 0.1578
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0781s / 21894.6618 s
agent0:                 episode reward: 0.2948,                 loss: nan
agent1:                 episode reward: -0.2948,                 loss: 0.1580
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3199s / 22035.9817 s
agent0:                 episode reward: 0.1324,                 loss: nan
agent1:                 episode reward: -0.1324,                 loss: 0.1582
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5872s / 22178.5688 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.1567
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5615s / 22321.1304 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.1588
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8076s / 22463.9380 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.1595
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4576s / 22607.3956 s
agent0:                 episode reward: 0.1995,                 loss: nan
agent1:                 episode reward: -0.1995,                 loss: 0.1577
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5817s / 22750.9773 s
agent0:                 episode reward: -0.0596,                 loss: nan
agent1:                 episode reward: 0.0596,                 loss: 0.1595
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5531s / 22895.5304 s
agent0:                 episode reward: -0.1948,                 loss: nan
agent1:                 episode reward: 0.1948,                 loss: 0.1581
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8417s / 23038.3721 s
agent0:                 episode reward: -0.3180,                 loss: nan
agent1:                 episode reward: 0.3180,                 loss: 0.1580
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 147.0859s / 23185.4580 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.1568
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4441s / 23327.9021 s
agent0:                 episode reward: 0.0695,                 loss: nan
agent1:                 episode reward: -0.0695,                 loss: 0.1585
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9021s / 23467.8041 s
agent0:                 episode reward: -0.1201,                 loss: nan
agent1:                 episode reward: 0.1201,                 loss: 0.1580
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8171s / 23610.6213 s
agent0:                 episode reward: -0.3808,                 loss: nan
agent1:                 episode reward: 0.3808,                 loss: 0.1577
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7000s / 23754.3213 s
agent0:                 episode reward: -0.1801,                 loss: nan
agent1:                 episode reward: 0.1801,                 loss: 0.1579
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3463s / 23897.6676 s
agent0:                 episode reward: 0.2127,                 loss: nan
agent1:                 episode reward: -0.2127,                 loss: 0.1578
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4467s / 24039.1143 s
agent0:                 episode reward: -0.0937,                 loss: nan
agent1:                 episode reward: 0.0937,                 loss: 0.1571
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0894s / 24183.2038 s
agent0:                 episode reward: -0.3583,                 loss: nan
agent1:                 episode reward: 0.3583,                 loss: 0.1582
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7255s / 24325.9292 s
agent0:                 episode reward: 0.1182,                 loss: nan
agent1:                 episode reward: -0.1182,                 loss: 0.1588
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1931s / 24467.1223 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1579
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2884s / 24611.4108 s
agent0:                 episode reward: 0.1211,                 loss: nan
agent1:                 episode reward: -0.1211,                 loss: 0.1583
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0457s / 24750.4565 s
agent0:                 episode reward: 0.0182,                 loss: nan
agent1:                 episode reward: -0.0182,                 loss: 0.1568
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 146.4358s / 24896.8923 s
agent0:                 episode reward: 0.5248,                 loss: nan
agent1:                 episode reward: -0.5248,                 loss: 0.1596
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2778s / 25041.1701 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: 0.1576
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0312s / 25184.2013 s
agent0:                 episode reward: -0.0786,                 loss: nan
agent1:                 episode reward: 0.0786,                 loss: 0.1576
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9085s / 25326.1098 s
agent0:                 episode reward: -0.0209,                 loss: nan
agent1:                 episode reward: 0.0209,                 loss: 0.1579
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4025s / 25468.5122 s
agent0:                 episode reward: -0.5518,                 loss: nan
agent1:                 episode reward: 0.5518,                 loss: 0.1583
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 148.3432s / 25616.8554 s
agent0:                 episode reward: -0.1052,                 loss: nan
agent1:                 episode reward: 0.1052,                 loss: 0.1587
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6001s / 25758.4555 s
agent0:                 episode reward: 0.0798,                 loss: nan
agent1:                 episode reward: -0.0798,                 loss: 0.1566
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.8014s / 25903.2570 s
agent0:                 episode reward: -0.4123,                 loss: nan
agent1:                 episode reward: 0.4123,                 loss: 0.1582
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8152s / 26047.0722 s
agent0:                 episode reward: 0.0935,                 loss: nan
agent1:                 episode reward: -0.0935,                 loss: 0.1583
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4221s / 26191.4943 s
agent0:                 episode reward: -0.2989,                 loss: nan
agent1:                 episode reward: 0.2989,                 loss: 0.1567
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3286s / 26332.8229 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.1567
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3439s / 26476.1668 s
agent0:                 episode reward: -0.3017,                 loss: nan
agent1:                 episode reward: 0.3017,                 loss: 0.1574
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.1769s / 26621.3437 s
agent0:                 episode reward: 0.1202,                 loss: nan
agent1:                 episode reward: -0.1202,                 loss: 0.1568
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0568s / 26764.4005 s
agent0:                 episode reward: -0.3645,                 loss: nan
agent1:                 episode reward: 0.3645,                 loss: 0.1581
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 147.5361s / 26911.9366 s
agent0:                 episode reward: -0.0913,                 loss: nan
agent1:                 episode reward: 0.0913,                 loss: 0.1589
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6103s / 27054.5469 s
agent0:                 episode reward: 0.2202,                 loss: nan
agent1:                 episode reward: -0.2202,                 loss: 0.1557
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7162s / 27197.2631 s
agent0:                 episode reward: -0.4065,                 loss: nan
agent1:                 episode reward: 0.4065,                 loss: 0.1551
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0922s / 27339.3553 s
agent0:                 episode reward: -0.0003,                 loss: nan
agent1:                 episode reward: 0.0003,                 loss: 0.1561
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1731s / 27473.5284 s
agent0:                 episode reward: 0.0088,                 loss: nan
agent1:                 episode reward: -0.0088,                 loss: 0.1538
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9456s / 27611.4741 s
agent0:                 episode reward: -0.0288,                 loss: nan
agent1:                 episode reward: 0.0288,                 loss: 0.1553
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6803s / 27745.1543 s
agent0:                 episode reward: -0.3217,                 loss: nan
agent1:                 episode reward: 0.3217,                 loss: 0.1554
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5168s / 27879.6711 s
agent0:                 episode reward: -0.5555,                 loss: nan
agent1:                 episode reward: 0.5555,                 loss: 0.1548
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7055s / 28014.3767 s
agent0:                 episode reward: -0.0625,                 loss: nan
agent1:                 episode reward: 0.0625,                 loss: 0.1563
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2516s / 28147.6283 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1549
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5083s / 28281.1366 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1550
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8960s / 28413.0326 s
agent0:                 episode reward: -0.0518,                 loss: nan
agent1:                 episode reward: 0.0518,                 loss: 0.1556
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6605s / 28550.6931 s
agent0:                 episode reward: 0.0280,                 loss: nan
agent1:                 episode reward: -0.0280,                 loss: 0.1555
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5353s / 28684.2284 s
agent0:                 episode reward: -0.3012,                 loss: nan
agent1:                 episode reward: 0.3012,                 loss: 0.1543
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7627s / 28819.9911 s
agent0:                 episode reward: -0.3098,                 loss: nan
agent1:                 episode reward: 0.3098,                 loss: 0.1538
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6101s / 28954.6012 s
agent0:                 episode reward: 0.2602,                 loss: nan
agent1:                 episode reward: -0.2602,                 loss: 0.1557
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9830s / 29090.5843 s
agent0:                 episode reward: -0.3190,                 loss: nan
agent1:                 episode reward: 0.3190,                 loss: 0.1542
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0380s / 29224.6223 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.1566
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3560s / 29362.9782 s
agent0:                 episode reward: -0.0197,                 loss: nan
agent1:                 episode reward: 0.0197,                 loss: 0.1567
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2033s / 29499.1816 s
agent0:                 episode reward: -0.3834,                 loss: nan
agent1:                 episode reward: 0.3834,                 loss: 0.1569
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0936s / 29632.2752 s
agent0:                 episode reward: 0.2889,                 loss: nan
agent1:                 episode reward: -0.2889,                 loss: 0.1572
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0942s / 29766.3693 s
agent0:                 episode reward: 0.1733,                 loss: nan
agent1:                 episode reward: -0.1733,                 loss: 0.1577
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1780s / 29902.5473 s
agent0:                 episode reward: 0.0424,                 loss: nan
agent1:                 episode reward: -0.0424,                 loss: 0.1581
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9079s / 30034.4552 s
agent0:                 episode reward: -0.1160,                 loss: nan
agent1:                 episode reward: 0.1160,                 loss: 0.1570
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3036s / 30172.7588 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1562
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8179s / 30306.5767 s
agent0:                 episode reward: -0.1244,                 loss: nan
agent1:                 episode reward: 0.1244,                 loss: 0.1564
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3416s / 30440.9183 s
agent0:                 episode reward: -0.0296,                 loss: nan
agent1:                 episode reward: 0.0296,                 loss: 0.1574
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4092s / 30576.3275 s
agent0:                 episode reward: -0.2780,                 loss: nan
agent1:                 episode reward: 0.2780,                 loss: 0.1580
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2888s / 30710.6163 s
agent0:                 episode reward: -0.2317,                 loss: nan
agent1:                 episode reward: 0.2317,                 loss: 0.1578
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7612s / 30845.3775 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.1569
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4054s / 30977.7829 s
agent0:                 episode reward: 0.0357,                 loss: nan
agent1:                 episode reward: -0.0357,                 loss: 0.1570
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5152s / 31111.2981 s
agent0:                 episode reward: -0.2512,                 loss: nan
agent1:                 episode reward: 0.2512,                 loss: 0.1568
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9890s / 31248.2871 s
agent0:                 episode reward: -0.0226,                 loss: nan
agent1:                 episode reward: 0.0226,                 loss: 0.1570
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1375s / 31384.4245 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.1574
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5509s / 31521.9755 s
agent0:                 episode reward: -0.2189,                 loss: nan
agent1:                 episode reward: 0.2189,                 loss: 0.1572
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1713s / 31659.1467 s
agent0:                 episode reward: -0.2419,                 loss: nan
agent1:                 episode reward: 0.2419,                 loss: 0.1565
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7699s / 31790.9166 s
agent0:                 episode reward: 0.0549,                 loss: nan
agent1:                 episode reward: -0.0549,                 loss: 0.1579
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8167s / 31923.7333 s
agent0:                 episode reward: -0.3527,                 loss: nan
agent1:                 episode reward: 0.3527,                 loss: 0.1584
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7001s / 32059.4334 s
agent0:                 episode reward: -0.6034,                 loss: nan
agent1:                 episode reward: 0.6034,                 loss: 0.1571
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1561s / 32194.5895 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.1564
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2086s / 32329.7981 s
agent0:                 episode reward: -0.1515,                 loss: nan
agent1:                 episode reward: 0.1515,                 loss: 0.1551
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1645s / 32463.9626 s
agent0:                 episode reward: 0.0969,                 loss: nan
agent1:                 episode reward: -0.0969,                 loss: 0.1579
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3153s / 32598.2779 s
agent0:                 episode reward: 0.0550,                 loss: nan
agent1:                 episode reward: -0.0550,                 loss: 0.1579
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5345s / 32733.8124 s
agent0:                 episode reward: -0.6935,                 loss: nan
agent1:                 episode reward: 0.6935,                 loss: 0.1576
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.5227s / 32864.3352 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.1578
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6487s / 33000.9839 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.1572
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7580s / 33133.7419 s
agent0:                 episode reward: -0.3065,                 loss: nan
agent1:                 episode reward: 0.3065,                 loss: 0.1558
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8668s / 33268.6087 s
agent0:                 episode reward: 0.0138,                 loss: nan
agent1:                 episode reward: -0.0138,                 loss: 0.1556
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5230s / 33401.1317 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.1566
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0609s / 33535.1926 s
agent0:                 episode reward: -0.1907,                 loss: nan
agent1:                 episode reward: 0.1907,                 loss: 0.1580
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0228s / 33668.2154 s
agent0:                 episode reward: 0.0436,                 loss: nan
agent1:                 episode reward: -0.0436,                 loss: 0.1566
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8632s / 33802.0786 s
agent0:                 episode reward: 0.0051,                 loss: nan
agent1:                 episode reward: -0.0051,                 loss: 0.1577
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9157s / 33936.9942 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1590
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6419s / 34074.6362 s
agent0:                 episode reward: -0.3580,                 loss: nan
agent1:                 episode reward: 0.3580,                 loss: 0.1578
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4919s / 34210.1281 s
agent0:                 episode reward: 0.3521,                 loss: nan
agent1:                 episode reward: -0.3521,                 loss: 0.1592
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5245s / 34344.6526 s
agent0:                 episode reward: 0.0526,                 loss: nan
agent1:                 episode reward: -0.0526,                 loss: 0.1577
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7082s / 34476.3608 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: 0.1577
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4668s / 34612.8276 s
agent0:                 episode reward: -0.2182,                 loss: nan
agent1:                 episode reward: 0.2182,                 loss: 0.1591
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3333s / 34746.1609 s
agent0:                 episode reward: -0.3030,                 loss: nan
agent1:                 episode reward: 0.3030,                 loss: 0.1588
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8154s / 34880.9763 s
agent0:                 episode reward: -0.1538,                 loss: nan
agent1:                 episode reward: 0.1538,                 loss: 0.1586
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5743s / 35018.5505 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.1585
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2755s / 35151.8260 s
agent0:                 episode reward: -0.2193,                 loss: nan
agent1:                 episode reward: 0.2193,                 loss: 0.1585
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9162s / 35287.7422 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1577
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7087s / 35422.4509 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.1600
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9456s / 35558.3965 s
agent0:                 episode reward: -0.3071,                 loss: nan
agent1:                 episode reward: 0.3071,                 loss: 0.1577
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4440s / 35691.8405 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: 0.1582
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6894s / 35826.5299 s
agent0:                 episode reward: -0.1346,                 loss: nan
agent1:                 episode reward: 0.1346,                 loss: 0.1578
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4371s / 35961.9670 s
agent0:                 episode reward: 0.0868,                 loss: nan
agent1:                 episode reward: -0.0868,                 loss: 0.1583
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5995s / 36094.5665 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.1549
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3830s / 36227.9494 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1572
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9217s / 36363.8712 s
agent0:                 episode reward: -0.0631,                 loss: nan
agent1:                 episode reward: 0.0631,                 loss: 0.1555
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4035s / 36499.2746 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.1559
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2132s / 36635.4878 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1546
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8714s / 36768.3592 s
agent0:                 episode reward: 0.0378,                 loss: nan
agent1:                 episode reward: -0.0378,                 loss: 0.1546
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4806s / 36905.8398 s
agent0:                 episode reward: -0.1211,                 loss: nan
agent1:                 episode reward: 0.1211,                 loss: 0.1556
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6408s / 37040.4806 s
agent0:                 episode reward: -0.1241,                 loss: nan
agent1:                 episode reward: 0.1241,                 loss: 0.1559
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2197s / 37174.7003 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.1549
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0616s / 37307.7619 s
agent0:                 episode reward: 0.3029,                 loss: nan
agent1:                 episode reward: -0.3029,                 loss: 0.1546
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5242s / 37444.2861 s
agent0:                 episode reward: -0.1740,                 loss: nan
agent1:                 episode reward: 0.1740,                 loss: 0.1546
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7831s / 37580.0692 s
agent0:                 episode reward: -0.4442,                 loss: nan
agent1:                 episode reward: 0.4442,                 loss: 0.1553
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2451s / 37714.3144 s
agent0:                 episode reward: -0.0952,                 loss: nan
agent1:                 episode reward: 0.0952,                 loss: 0.1545
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7456s / 37851.0600 s
agent0:                 episode reward: 0.2896,                 loss: nan
agent1:                 episode reward: -0.2896,                 loss: 0.1534
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9698s / 37984.0298 s
agent0:                 episode reward: -0.0020,                 loss: nan
agent1:                 episode reward: 0.0020,                 loss: 0.1537
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0694s / 38120.0993 s
agent0:                 episode reward: 0.0310,                 loss: nan
agent1:                 episode reward: -0.0310,                 loss: 0.1566
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6497s / 38257.7490 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: 0.1557
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1932s / 38394.9421 s
agent0:                 episode reward: -0.3129,                 loss: nan
agent1:                 episode reward: 0.3129,                 loss: 0.1581
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6905s / 38528.6326 s
agent0:                 episode reward: -0.2795,                 loss: nan
agent1:                 episode reward: 0.2795,                 loss: 0.1612
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9319s / 38665.5645 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.1590
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7158s / 38800.2803 s
agent0:                 episode reward: -0.3870,                 loss: nan
agent1:                 episode reward: 0.3870,                 loss: 0.1594
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4668s / 38933.7471 s
agent0:                 episode reward: -0.7619,                 loss: nan
agent1:                 episode reward: 0.7619,                 loss: 0.1585
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6995s / 39067.4466 s
agent0:                 episode reward: -0.2944,                 loss: nan
agent1:                 episode reward: 0.2944,                 loss: 0.1599
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0239s / 39205.4705 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1589
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7066s / 39339.1772 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1580
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6047s / 39473.7819 s
agent0:                 episode reward: -0.0050,                 loss: nan
agent1:                 episode reward: 0.0050,                 loss: 0.1597
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1407s / 39607.9225 s
agent0:                 episode reward: 0.0643,                 loss: nan
agent1:                 episode reward: -0.0643,                 loss: 0.1587
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4158s / 39743.3383 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1601
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4777s / 39879.8160 s
agent0:                 episode reward: 0.0638,                 loss: nan
agent1:                 episode reward: -0.0638,                 loss: 0.1584
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8006s / 40013.6165 s
agent0:                 episode reward: -0.2231,                 loss: nan
agent1:                 episode reward: 0.2231,                 loss: 0.1577
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2560s / 40148.8726 s
agent0:                 episode reward: -0.3982,                 loss: nan
agent1:                 episode reward: 0.3982,                 loss: 0.1607
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4510s / 40284.3235 s
agent0:                 episode reward: -0.1509,                 loss: nan
agent1:                 episode reward: 0.1509,                 loss: 0.1578
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8507s / 40416.1742 s
agent0:                 episode reward: -0.0038,                 loss: nan
agent1:                 episode reward: 0.0038,                 loss: 0.1586
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1655s / 40550.3397 s
agent0:                 episode reward: 0.1179,                 loss: nan
agent1:                 episode reward: -0.1179,                 loss: 0.1568
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9202s / 40688.2600 s
agent0:                 episode reward: -0.0384,                 loss: nan
agent1:                 episode reward: 0.0384,                 loss: 0.1553
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4009s / 40825.6608 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: 0.1546
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9147s / 40961.5756 s
agent0:                 episode reward: -0.3338,                 loss: nan
agent1:                 episode reward: 0.3338,                 loss: 0.1550
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2281s / 41094.8036 s
agent0:                 episode reward: -0.0644,                 loss: nan
agent1:                 episode reward: 0.0644,                 loss: 0.1548
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5916s / 41229.3952 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1552
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3518s / 41363.7470 s
agent0:                 episode reward: -0.5218,                 loss: nan
agent1:                 episode reward: 0.5218,                 loss: 0.1566
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1388s / 41497.8858 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1537
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2893s / 41634.1751 s
agent0:                 episode reward: -0.0780,                 loss: nan
agent1:                 episode reward: 0.0780,                 loss: 0.1560
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4418s / 41768.6168 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.1558
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8779s / 41902.4947 s
agent0:                 episode reward: -0.0446,                 loss: nan
agent1:                 episode reward: 0.0446,                 loss: 0.1545
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9646s / 42038.4594 s
agent0:                 episode reward: -0.0242,                 loss: nan
agent1:                 episode reward: 0.0242,                 loss: 0.1558
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8370s / 42171.2964 s
agent0:                 episode reward: -0.2894,                 loss: nan
agent1:                 episode reward: 0.2894,                 loss: 0.1560
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3678s / 42306.6642 s
agent0:                 episode reward: -0.0949,                 loss: nan
agent1:                 episode reward: 0.0949,                 loss: 0.1541
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3561s / 42442.0202 s
agent0:                 episode reward: -0.8285,                 loss: nan
agent1:                 episode reward: 0.8285,                 loss: 0.1546
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6945s / 42576.7147 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1564
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1295s / 42710.8442 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.1546
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8066s / 42845.6507 s
agent0:                 episode reward: -0.0906,                 loss: nan
agent1:                 episode reward: 0.0906,                 loss: 0.1559
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0263s / 42980.6771 s
agent0:                 episode reward: -0.0015,                 loss: nan
agent1:                 episode reward: 0.0015,                 loss: 0.1559
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6424s / 43115.3194 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: 0.1568
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2579s / 43249.5773 s
agent0:                 episode reward: -0.1605,                 loss: nan
agent1:                 episode reward: 0.1605,                 loss: 0.1581
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6316s / 43383.2088 s
agent0:                 episode reward: -0.1840,                 loss: nan
agent1:                 episode reward: 0.1840,                 loss: 0.1578
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8108s / 43517.0196 s
agent0:                 episode reward: -0.1698,                 loss: nan
agent1:                 episode reward: 0.1698,                 loss: 0.1572
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4259s / 43650.4455 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1585
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1043s / 43783.5498 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.1580
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1089s / 43917.6587 s
agent0:                 episode reward: 0.2093,                 loss: nan
agent1:                 episode reward: -0.2093,                 loss: 0.1581
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8499s / 44052.5086 s
agent0:                 episode reward: -0.0965,                 loss: nan
agent1:                 episode reward: 0.0965,                 loss: 0.1577
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2081s / 44189.7168 s
agent0:                 episode reward: -0.4588,                 loss: nan
agent1:                 episode reward: 0.4588,                 loss: 0.1574
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9668s / 44325.6836 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.1567
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7180s / 44460.4016 s
agent0:                 episode reward: -0.2906,                 loss: nan
agent1:                 episode reward: 0.2906,                 loss: 0.1554
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1945s / 44596.5961 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.1570
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6450s / 44731.2411 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.1570
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6171s / 44866.8582 s
agent0:                 episode reward: 0.0397,                 loss: nan
agent1:                 episode reward: -0.0397,                 loss: 0.1554
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1485s / 45008.0067 s
agent0:                 episode reward: -0.2702,                 loss: nan
agent1:                 episode reward: 0.2702,                 loss: 0.1561
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9820s / 45145.9887 s
agent0:                 episode reward: 0.0321,                 loss: nan
agent1:                 episode reward: -0.0321,                 loss: 0.1574
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4181s / 45279.4068 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.1572
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9547s / 45417.3615 s
agent0:                 episode reward: -0.3673,                 loss: nan
agent1:                 episode reward: 0.3673,                 loss: 0.1569
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0124s / 45553.3739 s
agent0:                 episode reward: -0.6227,                 loss: nan
agent1:                 episode reward: 0.6227,                 loss: 0.1562
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7606s / 45688.1345 s
agent0:                 episode reward: -0.0070,                 loss: nan
agent1:                 episode reward: 0.0070,                 loss: 0.1562
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4308s / 45819.5652 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.1557
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6116s / 45957.1769 s
agent0:                 episode reward: -0.2122,                 loss: nan
agent1:                 episode reward: 0.2122,                 loss: 0.1582
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3541s / 46089.5310 s
agent0:                 episode reward: -0.1323,                 loss: nan
agent1:                 episode reward: 0.1323,                 loss: 0.1570
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5998s / 46223.1307 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.1563
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3763s / 46358.5071 s
agent0:                 episode reward: 0.0850,                 loss: nan
agent1:                 episode reward: -0.0850,                 loss: 0.1585
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1049s / 46492.6120 s
agent0:                 episode reward: 0.5318,                 loss: nan
agent1:                 episode reward: -0.5318,                 loss: 0.1567
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6277s / 46627.2397 s
agent0:                 episode reward: -0.0770,                 loss: nan
agent1:                 episode reward: 0.0770,                 loss: 0.1562
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8093s / 46764.0489 s
agent0:                 episode reward: -0.1339,                 loss: nan
agent1:                 episode reward: 0.1339,                 loss: 0.1570
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2791s / 46900.3281 s
agent0:                 episode reward: 0.0576,                 loss: nan
agent1:                 episode reward: -0.0576,                 loss: 0.1553
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4193s / 47033.7474 s
agent0:                 episode reward: -0.5900,                 loss: nan
agent1:                 episode reward: 0.5900,                 loss: 0.1568
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6547s / 47169.4021 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1544
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7694s / 47306.1714 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.1576
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8089s / 47440.9804 s
agent0:                 episode reward: -0.1261,                 loss: nan
agent1:                 episode reward: 0.1261,                 loss: 0.1573
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2357s / 47580.2161 s
agent0:                 episode reward: -0.2372,                 loss: nan
agent1:                 episode reward: 0.2372,                 loss: 0.1575
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4185s / 47714.6346 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.1567
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6221s / 47849.2567 s
agent0:                 episode reward: -0.2312,                 loss: nan
agent1:                 episode reward: 0.2312,                 loss: 0.1561
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1538s / 47983.4105 s
agent0:                 episode reward: 0.0721,                 loss: nan
agent1:                 episode reward: -0.0721,                 loss: 0.1567
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5085s / 48115.9190 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.1563
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6492s / 48254.5682 s
agent0:                 episode reward: -0.3849,                 loss: nan
agent1:                 episode reward: 0.3849,                 loss: 0.1562
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5645s / 48389.1326 s
agent0:                 episode reward: -0.1363,                 loss: nan
agent1:                 episode reward: 0.1363,                 loss: 0.1545
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1124s / 48523.2450 s
agent0:                 episode reward: 0.4504,                 loss: nan
agent1:                 episode reward: -0.4504,                 loss: 0.1557
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4105s / 48657.6555 s
agent0:                 episode reward: -0.5041,                 loss: nan
agent1:                 episode reward: 0.5041,                 loss: 0.1569
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9487s / 48791.6042 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.1559
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0201s / 48926.6242 s
agent0:                 episode reward: -0.3774,                 loss: nan
agent1:                 episode reward: 0.3774,                 loss: 0.1545
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9625s / 49063.5867 s
agent0:                 episode reward: -0.0289,                 loss: nan
agent1:                 episode reward: 0.0289,                 loss: 0.1560
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7974s / 49198.3840 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1562
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2758s / 49333.6598 s
agent0:                 episode reward: -0.6070,                 loss: nan
agent1:                 episode reward: 0.6070,                 loss: 0.1557
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8610s / 49467.5208 s
agent0:                 episode reward: 0.1187,                 loss: nan
agent1:                 episode reward: -0.1187,                 loss: 0.1553
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6725s / 49605.1933 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.1562
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1802s / 49739.3735 s
agent0:                 episode reward: -0.2172,                 loss: nan
agent1:                 episode reward: 0.2172,                 loss: 0.1571
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9790s / 49874.3525 s
agent0:                 episode reward: -0.4499,                 loss: nan
agent1:                 episode reward: 0.4499,                 loss: 0.1580
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7062s / 50010.0587 s
agent0:                 episode reward: -0.0069,                 loss: nan
agent1:                 episode reward: 0.0069,                 loss: 0.1550
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6119s / 50142.6706 s
agent0:                 episode reward: -0.5420,                 loss: nan
agent1:                 episode reward: 0.5420,                 loss: 0.1564
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4530s / 50278.1235 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1548
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1692s / 50412.2928 s
agent0:                 episode reward: -0.3310,                 loss: nan
agent1:                 episode reward: 0.3310,                 loss: 0.1566
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1492s / 50545.4419 s
agent0:                 episode reward: -0.4300,                 loss: nan
agent1:                 episode reward: 0.4300,                 loss: 0.1560
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8953s / 50683.3372 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.1559
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6925s / 50817.0297 s
agent0:                 episode reward: 0.2044,                 loss: nan
agent1:                 episode reward: -0.2044,                 loss: 0.1563
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6110s / 50954.6407 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1565
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3856s / 51089.0263 s
agent0:                 episode reward: 0.0081,                 loss: nan
agent1:                 episode reward: -0.0081,                 loss: 0.1563
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2937s / 51222.3200 s
agent0:                 episode reward: -0.0901,                 loss: nan
agent1:                 episode reward: 0.0901,                 loss: 0.1556
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6790s / 51355.9990 s
agent0:                 episode reward: -0.2196,                 loss: nan
agent1:                 episode reward: 0.2196,                 loss: 0.1562
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7954s / 51487.7944 s
agent0:                 episode reward: -0.0008,                 loss: nan
agent1:                 episode reward: 0.0008,                 loss: 0.1555
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4120s / 51622.2064 s
agent0:                 episode reward: 0.0661,                 loss: nan
agent1:                 episode reward: -0.0661,                 loss: 0.1559
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4890s / 51757.6953 s
agent0:                 episode reward: -0.4753,                 loss: nan
agent1:                 episode reward: 0.4753,                 loss: 0.1558
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0757s / 51892.7711 s
agent0:                 episode reward: -0.6097,                 loss: nan
agent1:                 episode reward: 0.6097,                 loss: 0.1576
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6846s / 52029.4557 s
agent0:                 episode reward: 0.0221,                 loss: nan
agent1:                 episode reward: -0.0221,                 loss: 0.1558
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1010s / 52166.5567 s
agent0:                 episode reward: 0.0327,                 loss: nan
agent1:                 episode reward: -0.0327,                 loss: 0.1578
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6570s / 52301.2137 s
agent0:                 episode reward: -0.3554,                 loss: nan
agent1:                 episode reward: 0.3554,                 loss: 0.1581
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7845s / 52433.9982 s
agent0:                 episode reward: -0.5084,                 loss: nan
agent1:                 episode reward: 0.5084,                 loss: 0.1582
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5177s / 52568.5159 s
agent0:                 episode reward: -0.3151,                 loss: nan
agent1:                 episode reward: 0.3151,                 loss: 0.1576
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5775s / 52702.0934 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: 0.1579
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3710s / 52837.4644 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.1568
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4927s / 52972.9571 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: 0.1580
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7399s / 53107.6969 s
agent0:                 episode reward: -0.1932,                 loss: nan
agent1:                 episode reward: 0.1932,                 loss: 0.1589
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1151s / 53241.8120 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.1579
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7177s / 53380.5297 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1549
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0288s / 53514.5585 s
agent0:                 episode reward: -0.0962,                 loss: nan
agent1:                 episode reward: 0.0962,                 loss: 0.1575
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9820s / 53649.5405 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.1585
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0611s / 53786.6017 s
agent0:                 episode reward: 0.0432,                 loss: nan
agent1:                 episode reward: -0.0432,                 loss: 0.1570
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5815s / 53925.1832 s
agent0:                 episode reward: -0.1569,                 loss: nan
agent1:                 episode reward: 0.1569,                 loss: 0.1579
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7770s / 54060.9602 s
agent0:                 episode reward: 0.1052,                 loss: nan
agent1:                 episode reward: -0.1052,                 loss: 0.1580
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2761s / 54197.2362 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.1566
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9521s / 54334.1883 s
agent0:                 episode reward: -0.0252,                 loss: nan
agent1:                 episode reward: 0.0252,                 loss: 0.1578
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5568s / 54470.7451 s
agent0:                 episode reward: -0.0603,                 loss: nan
agent1:                 episode reward: 0.0603,                 loss: 0.1571
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1448s / 54601.8899 s
agent0:                 episode reward: -0.0380,                 loss: nan
agent1:                 episode reward: 0.0380,                 loss: 0.1558
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4175s / 54736.3074 s
agent0:                 episode reward: 0.2160,                 loss: nan
agent1:                 episode reward: -0.2160,                 loss: 0.1577
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4729s / 54871.7803 s
agent0:                 episode reward: -0.2366,                 loss: nan
agent1:                 episode reward: 0.2366,                 loss: 0.1584
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0216s / 55006.8019 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: 0.1570
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2446s / 55141.0465 s
agent0:                 episode reward: 0.0390,                 loss: nan
agent1:                 episode reward: -0.0390,                 loss: 0.1580
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8665s / 55275.9129 s
agent0:                 episode reward: -0.4547,                 loss: nan
agent1:                 episode reward: 0.4547,                 loss: 0.1578
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1072s / 55409.0201 s
agent0:                 episode reward: -0.4619,                 loss: nan
agent1:                 episode reward: 0.4619,                 loss: 0.1576
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0861s / 55546.1063 s
agent0:                 episode reward: -0.4766,                 loss: nan
agent1:                 episode reward: 0.4766,                 loss: 0.1570
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9638s / 55686.0701 s
agent0:                 episode reward: -0.0327,                 loss: nan
agent1:                 episode reward: 0.0327,                 loss: 0.1565
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6498s / 55820.7199 s
agent0:                 episode reward: -0.0817,                 loss: nan
agent1:                 episode reward: 0.0817,                 loss: 0.1562
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3815s / 55954.1014 s
agent0:                 episode reward: -0.1385,                 loss: nan
agent1:                 episode reward: 0.1385,                 loss: 0.1581
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8546s / 56091.9560 s
agent0:                 episode reward: 0.2769,                 loss: nan
agent1:                 episode reward: -0.2769,                 loss: 0.1559
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2845s / 56229.2405 s
agent0:                 episode reward: -0.5005,                 loss: nan
agent1:                 episode reward: 0.5005,                 loss: 0.1582
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0655s / 56364.3061 s
agent0:                 episode reward: 0.2784,                 loss: nan
agent1:                 episode reward: -0.2784,                 loss: 0.1559
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4876s / 56499.7936 s
agent0:                 episode reward: 0.1097,                 loss: nan
agent1:                 episode reward: -0.1097,                 loss: 0.1576
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0293s / 56635.8229 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.1553
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5368s / 56770.3597 s
agent0:                 episode reward: 0.0359,                 loss: nan
agent1:                 episode reward: -0.0359,                 loss: 0.1563
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8195s / 56902.1793 s
agent0:                 episode reward: 0.0496,                 loss: nan
agent1:                 episode reward: -0.0496,                 loss: 0.1574
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1115s / 57039.2907 s
agent0:                 episode reward: 0.3735,                 loss: nan
agent1:                 episode reward: -0.3735,                 loss: 0.1571
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.3707s / 57170.6614 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.1572
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5465s / 57309.2079 s
agent0:                 episode reward: 0.0236,                 loss: nan
agent1:                 episode reward: -0.0236,                 loss: 0.1562
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4499s / 57441.6578 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: 0.1572
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0787s / 57576.7365 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.1567
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4933s / 57711.2298 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.1561
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3938s / 57848.6236 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.1571
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4146s / 57985.0382 s
agent0:                 episode reward: -0.1931,                 loss: nan
agent1:                 episode reward: 0.1931,                 loss: 0.1565
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5683s / 58121.6065 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.1574
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6623s / 58258.2688 s
agent0:                 episode reward: -0.1584,                 loss: nan
agent1:                 episode reward: 0.1584,                 loss: 0.1575
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2139s / 58392.4826 s
agent0:                 episode reward: -0.0800,                 loss: nan
agent1:                 episode reward: 0.0800,                 loss: 0.1573
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2307s / 58528.7133 s
agent0:                 episode reward: -0.4565,                 loss: nan
agent1:                 episode reward: 0.4565,                 loss: 0.1546
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0860s / 58661.7993 s
agent0:                 episode reward: -0.0262,                 loss: nan
agent1:                 episode reward: 0.0262,                 loss: 0.1543
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2388s / 58796.0382 s
agent0:                 episode reward: 0.1365,                 loss: nan
agent1:                 episode reward: -0.1365,                 loss: 0.1556
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0119s / 58931.0501 s
agent0:                 episode reward: -0.4123,                 loss: nan
agent1:                 episode reward: 0.4123,                 loss: 0.1541
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6844s / 59067.7345 s
agent0:                 episode reward: -0.2507,                 loss: nan
agent1:                 episode reward: 0.2507,                 loss: 0.1557
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3949s / 59201.1294 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.1533
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3810s / 59335.5104 s
agent0:                 episode reward: -0.1918,                 loss: nan
agent1:                 episode reward: 0.1918,                 loss: 0.1565
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5927s / 59475.1032 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: 0.1556
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9049s / 59611.0081 s
agent0:                 episode reward: -0.2296,                 loss: nan
agent1:                 episode reward: 0.2296,                 loss: 0.1559
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1120s / 59746.1201 s
agent0:                 episode reward: -0.4141,                 loss: nan
agent1:                 episode reward: 0.4141,                 loss: 0.1551
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3217s / 59879.4418 s
agent0:                 episode reward: -0.1757,                 loss: nan
agent1:                 episode reward: 0.1757,                 loss: 0.1555
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8910s / 60014.3328 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.1555
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5528s / 60147.8856 s
agent0:                 episode reward: -0.0090,                 loss: nan
agent1:                 episode reward: 0.0090,                 loss: 0.1549
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4782s / 60283.3638 s
agent0:                 episode reward: -0.3373,                 loss: nan
agent1:                 episode reward: 0.3373,                 loss: 0.1535
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1003s / 60417.4641 s
agent0:                 episode reward: -0.6101,                 loss: nan
agent1:                 episode reward: 0.6101,                 loss: 0.1546
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1594s / 60549.6235 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.1551
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9987s / 60683.6222 s
agent0:                 episode reward: 0.0474,                 loss: nan
agent1:                 episode reward: -0.0474,                 loss: 0.1541
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3003s / 60819.9226 s
agent0:                 episode reward: -0.0108,                 loss: nan
agent1:                 episode reward: 0.0108,                 loss: 0.1553
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9448s / 60954.8673 s
agent0:                 episode reward: -0.2120,                 loss: nan
agent1:                 episode reward: 0.2120,                 loss: 0.1539
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9823s / 61089.8497 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.1537
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9591s / 61225.8088 s
agent0:                 episode reward: -0.1862,                 loss: nan
agent1:                 episode reward: 0.1862,                 loss: 0.1536
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5285s / 61360.3373 s
agent0:                 episode reward: -0.0696,                 loss: nan
agent1:                 episode reward: 0.0696,                 loss: 0.1543
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7521s / 61496.0894 s
agent0:                 episode reward: -0.3153,                 loss: nan
agent1:                 episode reward: 0.3153,                 loss: 0.1535
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2803s / 61632.3698 s
agent0:                 episode reward: -0.6671,                 loss: nan
agent1:                 episode reward: 0.6671,                 loss: 0.1551
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8668s / 61772.2365 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.1559
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1050s / 61907.3415 s
agent0:                 episode reward: 0.2781,                 loss: nan
agent1:                 episode reward: -0.2781,                 loss: 0.1543
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8098s / 62042.1513 s
agent0:                 episode reward: -0.2813,                 loss: nan
agent1:                 episode reward: 0.2813,                 loss: 0.1558
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1574s / 62180.3087 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.1553
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0140s / 62321.3227 s
agent0:                 episode reward: 0.0508,                 loss: nan
agent1:                 episode reward: -0.0508,                 loss: 0.1546
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5817s / 62454.9044 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: 0.1559
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1881s / 62587.0925 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.1545
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5718s / 62722.6643 s
agent0:                 episode reward: -0.5912,                 loss: nan
agent1:                 episode reward: 0.5912,                 loss: 0.1540
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6778s / 62858.3421 s
agent0:                 episode reward: -0.4040,                 loss: nan
agent1:                 episode reward: 0.4040,                 loss: 0.1539
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6420s / 62993.9841 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.1552
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3033s / 63131.2874 s
agent0:                 episode reward: -0.2354,                 loss: nan
agent1:                 episode reward: 0.2354,                 loss: 0.1534
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9250s / 63268.2124 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1541
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5594s / 63403.7719 s
agent0:                 episode reward: -0.2224,                 loss: nan
agent1:                 episode reward: 0.2224,                 loss: 0.1545
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9272s / 63539.6991 s
agent0:                 episode reward: -0.1526,                 loss: nan
agent1:                 episode reward: 0.1526,                 loss: 0.1523
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6390s / 63675.3381 s
agent0:                 episode reward: -0.2506,                 loss: nan
agent1:                 episode reward: 0.2506,                 loss: 0.1534
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1911s / 63814.5292 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.1539
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4165s / 63951.9456 s
agent0:                 episode reward: 0.1849,                 loss: nan
agent1:                 episode reward: -0.1849,                 loss: 0.1535
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5211s / 64086.4667 s
agent0:                 episode reward: -0.4929,                 loss: nan
agent1:                 episode reward: 0.4929,                 loss: 0.1525
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9364s / 64221.4031 s
agent0:                 episode reward: 0.2172,                 loss: nan
agent1:                 episode reward: -0.2172,                 loss: 0.1524
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1589s / 64357.5620 s
agent0:                 episode reward: -0.3787,                 loss: nan
agent1:                 episode reward: 0.3787,                 loss: 0.1543
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6392s / 64497.2013 s
agent0:                 episode reward: -0.2648,                 loss: nan
agent1:                 episode reward: 0.2648,                 loss: 0.1529
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0242s / 64634.2254 s
agent0:                 episode reward: -0.0395,                 loss: nan
agent1:                 episode reward: 0.0395,                 loss: 0.1528
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0056s / 64767.2310 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.1554
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8524s / 64904.0834 s
agent0:                 episode reward: 0.0016,                 loss: nan
agent1:                 episode reward: -0.0016,                 loss: 0.1544
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5079s / 65038.5913 s
agent0:                 episode reward: -0.4299,                 loss: nan
agent1:                 episode reward: 0.4299,                 loss: 0.1529
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8953s / 65174.4867 s
agent0:                 episode reward: -0.3757,                 loss: nan
agent1:                 episode reward: 0.3757,                 loss: 0.1536
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1378s / 65309.6244 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.1545
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7692s / 65447.3937 s
agent0:                 episode reward: -0.5768,                 loss: nan
agent1:                 episode reward: 0.5768,                 loss: 0.1542
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3973s / 65580.7910 s
agent0:                 episode reward: -0.3570,                 loss: nan
agent1:                 episode reward: 0.3570,                 loss: 0.1545
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8152s / 65716.6062 s
agent0:                 episode reward: -0.0308,                 loss: nan
agent1:                 episode reward: 0.0308,                 loss: 0.1537
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8171s / 65850.4232 s
agent0:                 episode reward: -0.3949,                 loss: nan
agent1:                 episode reward: 0.3949,                 loss: 0.1546
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1596s / 65986.5829 s
agent0:                 episode reward: -0.0482,                 loss: nan
agent1:                 episode reward: 0.0482,                 loss: 0.1546
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6569s / 66119.2398 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.1519
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7313s / 66253.9711 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1524
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9375s / 66390.9086 s
agent0:                 episode reward: -0.0646,                 loss: nan
agent1:                 episode reward: 0.0646,                 loss: 0.1522
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 129.8512s / 66520.7598 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: 0.1539
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5435s / 66653.3033 s
agent0:                 episode reward: -0.4350,                 loss: nan
agent1:                 episode reward: 0.4350,                 loss: 0.1542
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8666s / 66787.1699 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1539
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9799s / 66922.1498 s
agent0:                 episode reward: 0.0109,                 loss: nan
agent1:                 episode reward: -0.0109,                 loss: 0.1538
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1446s / 67057.2944 s
agent0:                 episode reward: -0.1006,                 loss: nan
agent1:                 episode reward: 0.1006,                 loss: 0.1537
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9914s / 67189.2858 s
agent0:                 episode reward: -0.3258,                 loss: nan
agent1:                 episode reward: 0.3258,                 loss: 0.1539
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2044s / 67323.4902 s
agent0:                 episode reward: -0.3263,                 loss: nan
agent1:                 episode reward: 0.3263,                 loss: 0.1545
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4320s / 67455.9222 s
agent0:                 episode reward: -0.3519,                 loss: nan
agent1:                 episode reward: 0.3519,                 loss: 0.1546
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1889s / 67593.1112 s
agent0:                 episode reward: -0.1134,                 loss: nan
agent1:                 episode reward: 0.1134,                 loss: 0.1550
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9908s / 67728.1020 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.1554
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7099s / 67863.8119 s
agent0:                 episode reward: -0.0972,                 loss: nan
agent1:                 episode reward: 0.0972,                 loss: 0.1551
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7426s / 67997.5545 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.1555
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9442s / 68129.4987 s
agent0:                 episode reward: 0.1662,                 loss: nan
agent1:                 episode reward: -0.1662,                 loss: 0.1544
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1047s / 68263.6035 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.1549
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5108s / 68398.1142 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.1552
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9764s / 68533.0906 s
agent0:                 episode reward: 0.1051,                 loss: nan
agent1:                 episode reward: -0.1051,                 loss: 0.1546
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1382s / 68669.2288 s
agent0:                 episode reward: -0.3296,                 loss: nan
agent1:                 episode reward: 0.3296,                 loss: 0.1546
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7756s / 68805.0044 s
agent0:                 episode reward: -0.5488,                 loss: nan
agent1:                 episode reward: 0.5488,                 loss: 0.1541
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0019s / 68939.0063 s
agent0:                 episode reward: 0.0289,                 loss: nan
agent1:                 episode reward: -0.0289,                 loss: 0.1559
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2298s / 69078.2361 s
agent0:                 episode reward: 0.2069,                 loss: nan
agent1:                 episode reward: -0.2069,                 loss: 0.1539
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9472s / 69210.1834 s
agent0:                 episode reward: -0.0691,                 loss: nan
agent1:                 episode reward: 0.0691,                 loss: 0.1551
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5998s / 69345.7831 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.1557
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4077s / 69481.1908 s
agent0:                 episode reward: -0.5106,                 loss: nan
agent1:                 episode reward: 0.5106,                 loss: 0.1551
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3658s / 69614.5566 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: 0.1552
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8995s / 69748.4561 s
agent0:                 episode reward: -0.2357,                 loss: nan
agent1:                 episode reward: 0.2357,                 loss: 0.1546
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0102s / 69885.4663 s
agent0:                 episode reward: -0.3163,                 loss: nan
agent1:                 episode reward: 0.3163,                 loss: 0.1552
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2438s / 70020.7101 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.1551
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4248s / 70158.1349 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.1542
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8599s / 70292.9948 s
agent0:                 episode reward: -0.6242,                 loss: nan
agent1:                 episode reward: 0.6242,                 loss: 0.1557
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6886s / 70427.6834 s
agent0:                 episode reward: -0.3517,                 loss: nan
agent1:                 episode reward: 0.3517,                 loss: 0.1568
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7410s / 70560.4244 s
agent0:                 episode reward: -0.0426,                 loss: nan
agent1:                 episode reward: 0.0426,                 loss: 0.1549
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0976s / 70695.5220 s
agent0:                 episode reward: 0.0428,                 loss: nan
agent1:                 episode reward: -0.0428,                 loss: 0.1548
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1063s / 70832.6282 s
agent0:                 episode reward: -0.3879,                 loss: nan
agent1:                 episode reward: 0.3879,                 loss: 0.1540
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8549s / 70969.4832 s
agent0:                 episode reward: 0.0697,                 loss: nan
agent1:                 episode reward: -0.0697,                 loss: 0.1533
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6366s / 71105.1198 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.1551
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8896s / 71238.0094 s
agent0:                 episode reward: -0.0323,                 loss: nan
agent1:                 episode reward: 0.0323,                 loss: 0.1550
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1070s / 71374.1164 s
agent0:                 episode reward: -0.0483,                 loss: nan
agent1:                 episode reward: 0.0483,                 loss: 0.1551
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3060s / 71508.4224 s
agent0:                 episode reward: -0.1795,                 loss: nan
agent1:                 episode reward: 0.1795,                 loss: 0.1538
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3256s / 71643.7480 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: 0.1549
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0596s / 71779.8076 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.1543
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9958s / 71911.8033 s
agent0:                 episode reward: -0.1044,                 loss: nan
agent1:                 episode reward: 0.1044,                 loss: 0.1551
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8002s / 72047.6035 s
agent0:                 episode reward: -0.2667,                 loss: nan
agent1:                 episode reward: 0.2667,                 loss: 0.1554
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2442s / 72182.8477 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: 0.1555
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.0838s / 72312.9315 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1559
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9978s / 72444.9293 s
agent0:                 episode reward: -0.3459,                 loss: nan
agent1:                 episode reward: 0.3459,                 loss: 0.1551
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9076s / 72576.8369 s
agent0:                 episode reward: -0.2027,                 loss: nan
agent1:                 episode reward: 0.2027,                 loss: 0.1559
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8762s / 72711.7131 s
agent0:                 episode reward: -0.2241,                 loss: nan
agent1:                 episode reward: 0.2241,                 loss: 0.1559
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9241s / 72846.6373 s
agent0:                 episode reward: -0.1149,                 loss: nan
agent1:                 episode reward: 0.1149,                 loss: 0.1544
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6127s / 72979.2500 s
agent0:                 episode reward: -0.0930,                 loss: nan
agent1:                 episode reward: 0.0930,                 loss: 0.1556
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4154s / 73114.6654 s
agent0:                 episode reward: -0.3633,                 loss: nan
agent1:                 episode reward: 0.3633,                 loss: 0.1571
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0925s / 73251.7580 s
agent0:                 episode reward: -0.0307,                 loss: nan
agent1:                 episode reward: 0.0307,                 loss: 0.1551
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0887s / 73387.8467 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1561
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4446s / 73520.2913 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1574
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9500s / 73657.2413 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.1553
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1395s / 73790.3808 s
agent0:                 episode reward: -0.0166,                 loss: nan
agent1:                 episode reward: 0.0166,                 loss: 0.1554
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3450s / 73924.7259 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1558
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7580s / 74058.4838 s
agent0:                 episode reward: -0.3024,                 loss: nan
agent1:                 episode reward: 0.3024,                 loss: 0.1560
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2413s / 74194.7251 s
agent0:                 episode reward: -0.1643,                 loss: nan
agent1:                 episode reward: 0.1643,                 loss: 0.1554
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6359s / 74331.3610 s
agent0:                 episode reward: -0.4027,                 loss: nan
agent1:                 episode reward: 0.4027,                 loss: 0.1570
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7340s / 74466.0950 s
agent0:                 episode reward: -0.5105,                 loss: nan
agent1:                 episode reward: 0.5105,                 loss: 0.1534
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2357s / 74600.3308 s
agent0:                 episode reward: -0.0976,                 loss: nan
agent1:                 episode reward: 0.0976,                 loss: 0.1536
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7829s / 74734.1137 s
agent0:                 episode reward: -0.5900,                 loss: nan
agent1:                 episode reward: 0.5900,                 loss: 0.1540
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4020s / 74871.5157 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.1547
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2264s / 75005.7421 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.1544
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4308s / 75141.1729 s
agent0:                 episode reward: 0.2381,                 loss: nan
agent1:                 episode reward: -0.2381,                 loss: 0.1532
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4000s / 75273.5729 s
agent0:                 episode reward: -0.5994,                 loss: nan
agent1:                 episode reward: 0.5994,                 loss: 0.1527
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3487s / 75408.9215 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.1543
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9622s / 75543.8837 s
agent0:                 episode reward: -0.0870,                 loss: nan
agent1:                 episode reward: 0.0870,                 loss: 0.1552
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.9460s / 75674.8297 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.1551
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7033s / 75809.5331 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.1543
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5420s / 75945.0751 s
agent0:                 episode reward: -0.2880,                 loss: nan
agent1:                 episode reward: 0.2880,                 loss: 0.1517
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0766s / 76079.1516 s
agent0:                 episode reward: -0.1059,                 loss: nan
agent1:                 episode reward: 0.1059,                 loss: 0.1537
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1237s / 76213.2754 s
agent0:                 episode reward: -0.1750,                 loss: nan
agent1:                 episode reward: 0.1750,                 loss: 0.1544
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0731s / 76349.3484 s
agent0:                 episode reward: -0.5547,                 loss: nan
agent1:                 episode reward: 0.5547,                 loss: 0.1527
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4176s / 76484.7660 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.1552
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0236s / 76621.7896 s
agent0:                 episode reward: -0.0490,                 loss: nan
agent1:                 episode reward: 0.0490,                 loss: 0.1542
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6748s / 76759.4645 s
agent0:                 episode reward: -0.1558,                 loss: nan
agent1:                 episode reward: 0.1558,                 loss: 0.1563
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4321s / 76895.8966 s
agent0:                 episode reward: -0.1648,                 loss: nan
agent1:                 episode reward: 0.1648,                 loss: 0.1543
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5125s / 77029.4091 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.1560
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0146s / 77165.4237 s
agent0:                 episode reward: -0.1445,                 loss: nan
agent1:                 episode reward: 0.1445,                 loss: 0.1566
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3440s / 77299.7678 s
agent0:                 episode reward: 0.0279,                 loss: nan
agent1:                 episode reward: -0.0279,                 loss: 0.1556
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3005s / 77433.0683 s
agent0:                 episode reward: -0.0473,                 loss: nan
agent1:                 episode reward: 0.0473,                 loss: 0.1552
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6659s / 77566.7341 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.1545
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3585s / 77703.0926 s
agent0:                 episode reward: -0.3141,                 loss: nan
agent1:                 episode reward: 0.3141,                 loss: 0.1558
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2371s / 77840.3297 s
agent0:                 episode reward: 0.0300,                 loss: nan
agent1:                 episode reward: -0.0300,                 loss: 0.1560
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9478s / 77975.2776 s
agent0:                 episode reward: -0.4731,                 loss: nan
agent1:                 episode reward: 0.4731,                 loss: 0.1558
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0443s / 78111.3219 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.1543
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1879s / 78242.5098 s
agent0:                 episode reward: -0.1288,                 loss: nan
agent1:                 episode reward: 0.1288,                 loss: 0.1557
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2864s / 78383.7962 s
agent0:                 episode reward: -0.5184,                 loss: nan
agent1:                 episode reward: 0.5184,                 loss: 0.1543
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1555s / 78517.9517 s
agent0:                 episode reward: -0.0180,                 loss: nan
agent1:                 episode reward: 0.0180,                 loss: 0.1554
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9604s / 78654.9121 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1541
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4780s / 78788.3902 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: 0.1541
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8549s / 78922.2451 s
agent0:                 episode reward: -0.2264,                 loss: nan
agent1:                 episode reward: 0.2264,                 loss: 0.1537
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7531s / 79059.9982 s
agent0:                 episode reward: -0.5325,                 loss: nan
agent1:                 episode reward: 0.5325,                 loss: 0.1521
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5160s / 79195.5141 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.1528
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9044s / 79329.4186 s
agent0:                 episode reward: -0.5723,                 loss: nan
agent1:                 episode reward: 0.5723,                 loss: 0.1536
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7430s / 79462.1615 s
agent0:                 episode reward: -0.5496,                 loss: nan
agent1:                 episode reward: 0.5496,                 loss: 0.1516
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6718s / 79596.8333 s
agent0:                 episode reward: -0.4762,                 loss: nan
agent1:                 episode reward: 0.4762,                 loss: 0.1529
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0517s / 79729.8850 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.1532
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5107s / 79865.3957 s
agent0:                 episode reward: -0.2947,                 loss: nan
agent1:                 episode reward: 0.2947,                 loss: 0.1535
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6080s / 79999.0037 s
agent0:                 episode reward: 0.2298,                 loss: nan
agent1:                 episode reward: -0.2298,                 loss: 0.1526
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8984s / 80131.9020 s
agent0:                 episode reward: -0.2937,                 loss: nan
agent1:                 episode reward: 0.2937,                 loss: 0.1530
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3436s / 80268.2456 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: 0.1520
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7858s / 80403.0314 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.1511
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4276s / 80540.4590 s
agent0:                 episode reward: 0.0219,                 loss: nan
agent1:                 episode reward: -0.0219,                 loss: 0.1522
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2694s / 80676.7285 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.1528
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8305s / 80809.5590 s
agent0:                 episode reward: -0.1227,                 loss: nan
agent1:                 episode reward: 0.1227,                 loss: 0.1529
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8236s / 80945.3827 s
agent0:                 episode reward: -0.1749,                 loss: nan
agent1:                 episode reward: 0.1749,                 loss: 0.1519
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6781s / 81078.0607 s
agent0:                 episode reward: -0.5374,                 loss: nan
agent1:                 episode reward: 0.5374,                 loss: 0.1542
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2997s / 81211.3605 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.1574
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0583s / 81345.4187 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.1571
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4864s / 81481.9051 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.1555
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3754s / 81617.2805 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.1565
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6403s / 81751.9208 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: 0.1573
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2331s / 81884.1539 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.1549
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3367s / 82021.4906 s
agent0:                 episode reward: -0.6773,                 loss: nan
agent1:                 episode reward: 0.6773,                 loss: 0.1565
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3373s / 82162.8279 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.1580
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8241s / 82297.6521 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.1542
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8584s / 82432.5104 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: 0.1590
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6076s / 82567.1181 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.1547
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1745s / 82708.2925 s
agent0:                 episode reward: -0.5144,                 loss: nan
agent1:                 episode reward: 0.5144,                 loss: 0.1556
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.9762s / 82839.2687 s
agent0:                 episode reward: -0.2161,                 loss: nan
agent1:                 episode reward: 0.2161,                 loss: 0.1557
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1441s / 82972.4128 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.1566
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2965s / 83106.7093 s
agent0:                 episode reward: 0.0441,                 loss: nan
agent1:                 episode reward: -0.0441,                 loss: 0.1567
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9079s / 83243.6172 s
agent0:                 episode reward: 0.0959,                 loss: nan
agent1:                 episode reward: -0.0959,                 loss: 0.1573
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0361s / 83379.6532 s
agent0:                 episode reward: -0.4651,                 loss: nan
agent1:                 episode reward: 0.4651,                 loss: 0.1548
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6569s / 83515.3102 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.1538
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5044s / 83648.8146 s
agent0:                 episode reward: -0.5867,                 loss: nan
agent1:                 episode reward: 0.5867,                 loss: 0.1556
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6506s / 83782.4652 s
agent0:                 episode reward: -0.1445,                 loss: nan
agent1:                 episode reward: 0.1445,                 loss: 0.1534
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4949s / 83916.9601 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.1533
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4800s / 84051.4401 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.1534
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6767s / 84189.1167 s
agent0:                 episode reward: -0.5232,                 loss: nan
agent1:                 episode reward: 0.5232,                 loss: 0.1542
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6851s / 84325.8019 s
agent0:                 episode reward: -0.9539,                 loss: nan
agent1:                 episode reward: 0.9539,                 loss: 0.1510
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6421s / 84462.4440 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.1529
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6743s / 84599.1183 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: 0.1544
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6982s / 84731.8165 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: 0.1545
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4710s / 84865.2875 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1528
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8424s / 85002.1299 s
agent0:                 episode reward: 0.0942,                 loss: nan
agent1:                 episode reward: -0.0942,                 loss: 0.1527
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9329s / 85136.0628 s
agent0:                 episode reward: -0.2458,                 loss: nan
agent1:                 episode reward: 0.2458,                 loss: 0.1535
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2300s / 85273.2928 s
agent0:                 episode reward: -0.0979,                 loss: nan
agent1:                 episode reward: 0.0979,                 loss: 0.1537
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9720s / 85406.2648 s
agent0:                 episode reward: -0.5102,                 loss: nan
agent1:                 episode reward: 0.5102,                 loss: 0.1519
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3325s / 85540.5973 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.1526
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7213s / 85675.3186 s
agent0:                 episode reward: -0.4878,                 loss: nan
agent1:                 episode reward: 0.4878,                 loss: 0.1523
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7894s / 85813.1080 s
agent0:                 episode reward: -0.3649,                 loss: nan
agent1:                 episode reward: 0.3649,                 loss: 0.1518
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5519s / 85948.6599 s
agent0:                 episode reward: -0.6281,                 loss: nan
agent1:                 episode reward: 0.6281,                 loss: 0.1536
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1054s / 86079.7653 s
agent0:                 episode reward: -0.3662,                 loss: nan
agent1:                 episode reward: 0.3662,                 loss: 0.1526
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9784s / 86214.7437 s
agent0:                 episode reward: -0.4804,                 loss: nan
agent1:                 episode reward: 0.4804,                 loss: 0.1544
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4374s / 86352.1811 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.1533
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7572s / 86485.9383 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.1541
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2946s / 86621.2329 s
agent0:                 episode reward: -0.1583,                 loss: nan
agent1:                 episode reward: 0.1583,                 loss: 0.1530
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9666s / 86755.1994 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: 0.1528
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0901s / 86888.2895 s
agent0:                 episode reward: -0.1494,                 loss: nan
agent1:                 episode reward: 0.1494,                 loss: 0.1530
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4974s / 87026.7869 s
agent0:                 episode reward: -0.7793,                 loss: nan
agent1:                 episode reward: 0.7793,                 loss: 0.1522
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9487s / 87159.7356 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.1537
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3323s / 87297.0680 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.1538
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8926s / 87431.9606 s
agent0:                 episode reward: -0.2550,                 loss: nan
agent1:                 episode reward: 0.2550,                 loss: 0.1531
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3825s / 87565.3431 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.1540
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8601s / 87699.2032 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.1544
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4889s / 87834.6921 s
agent0:                 episode reward: -0.5889,                 loss: nan
agent1:                 episode reward: 0.5889,                 loss: 0.1528
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3361s / 87970.0282 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1543
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0902s / 88110.1185 s
agent0:                 episode reward: -0.0493,                 loss: nan
agent1:                 episode reward: 0.0493,                 loss: 0.1529
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9038s / 88247.0223 s
agent0:                 episode reward: -0.3842,                 loss: nan
agent1:                 episode reward: 0.3842,                 loss: 0.1529
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2991s / 88383.3214 s
agent0:                 episode reward: -0.1727,                 loss: nan
agent1:                 episode reward: 0.1727,                 loss: 0.1531
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4015s / 88517.7229 s
agent0:                 episode reward: -0.4898,                 loss: nan
agent1:                 episode reward: 0.4898,                 loss: 0.1543
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0425s / 88652.7654 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: 0.1538
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4281s / 88787.1935 s
agent0:                 episode reward: -0.3670,                 loss: nan
agent1:                 episode reward: 0.3670,                 loss: 0.1533
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7607s / 88921.9542 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.1560
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3239s / 89057.2781 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.1538
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4150s / 89192.6931 s
agent0:                 episode reward: -0.1435,                 loss: nan
agent1:                 episode reward: 0.1435,                 loss: 0.1544
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1116s / 89330.8047 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.1521
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7681s / 89463.5728 s
agent0:                 episode reward: -0.1334,                 loss: nan
agent1:                 episode reward: 0.1334,                 loss: 0.1525
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1890s / 89600.7619 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.1541
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7189s / 89735.4807 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.1535
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4221s / 89870.9028 s
agent0:                 episode reward: -0.5277,                 loss: nan
agent1:                 episode reward: 0.5277,                 loss: 0.1544
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9277s / 90002.8305 s
agent0:                 episode reward: -0.1741,                 loss: nan
agent1:                 episode reward: 0.1741,                 loss: 0.1534
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2078s / 90139.0384 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.1546
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9713s / 90273.0096 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.1566
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6207s / 90410.6303 s
agent0:                 episode reward: -0.5784,                 loss: nan
agent1:                 episode reward: 0.5784,                 loss: 0.1563
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1595s / 90546.7898 s
agent0:                 episode reward: -0.6752,                 loss: nan
agent1:                 episode reward: 0.6752,                 loss: 0.1565
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7980s / 90681.5879 s
agent0:                 episode reward: -0.2809,                 loss: nan
agent1:                 episode reward: 0.2809,                 loss: 0.1545
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8426s / 90817.4305 s
agent0:                 episode reward: -0.1022,                 loss: nan
agent1:                 episode reward: 0.1022,                 loss: 0.1535
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4277s / 90953.8582 s
agent0:                 episode reward: -0.2373,                 loss: nan
agent1:                 episode reward: 0.2373,                 loss: 0.1553
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7669s / 91090.6251 s
agent0:                 episode reward: -0.0995,                 loss: nan
agent1:                 episode reward: 0.0995,                 loss: 0.1556
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2168s / 91224.8418 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.1556
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1391s / 91358.9809 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.1546
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5573s / 91492.5383 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.1572
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2837s / 91627.8220 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: 0.1570
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8650s / 91762.6870 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.1552
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2067s / 91895.8936 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.1568
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9799s / 92029.8735 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1551
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1204s / 92165.9939 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.1569
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4898s / 92303.4838 s
agent0:                 episode reward: -0.2891,                 loss: nan
agent1:                 episode reward: 0.2891,                 loss: 0.1556
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5355s / 92436.0192 s
agent0:                 episode reward: -0.2571,                 loss: nan
agent1:                 episode reward: 0.2571,                 loss: 0.1544
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0385s / 92570.0577 s
agent0:                 episode reward: -0.2349,                 loss: nan
agent1:                 episode reward: 0.2349,                 loss: 0.1533
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0811s / 92704.1388 s
agent0:                 episode reward: 0.0929,                 loss: nan
agent1:                 episode reward: -0.0929,                 loss: 0.1531
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7585s / 92839.8973 s
agent0:                 episode reward: -0.3460,                 loss: nan
agent1:                 episode reward: 0.3460,                 loss: 0.1551
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9458s / 92974.8431 s
agent0:                 episode reward: -0.7053,                 loss: nan
agent1:                 episode reward: 0.7053,                 loss: 0.1534
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2728s / 93108.1158 s
agent0:                 episode reward: -0.1757,                 loss: nan
agent1:                 episode reward: 0.1757,                 loss: 0.1539
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4583s / 93243.5742 s
agent0:                 episode reward: -0.1574,                 loss: nan
agent1:                 episode reward: 0.1574,                 loss: 0.1553
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3143s / 93378.8884 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.1551
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1129s / 93517.0013 s
agent0:                 episode reward: -0.6148,                 loss: nan
agent1:                 episode reward: 0.6148,                 loss: 0.1551
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1224s / 93656.1238 s
agent0:                 episode reward: -0.2247,                 loss: nan
agent1:                 episode reward: 0.2247,                 loss: 0.1552
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8368s / 93790.9606 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.1550
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7776s / 93926.7382 s
agent0:                 episode reward: -0.8356,                 loss: nan
agent1:                 episode reward: 0.8356,                 loss: 0.1534
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3704s / 94060.1086 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.1540
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9890s / 94195.0977 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.1542
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8529s / 94326.9505 s
agent0:                 episode reward: -0.2425,                 loss: nan
agent1:                 episode reward: 0.2425,                 loss: 0.1536
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7617s / 94462.7123 s
agent0:                 episode reward: -0.7866,                 loss: nan
agent1:                 episode reward: 0.7866,                 loss: 0.1549
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6992s / 94601.4115 s
agent0:                 episode reward: -0.3415,                 loss: nan
agent1:                 episode reward: 0.3415,                 loss: 0.1553
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0223s / 94738.4338 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.1545
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0168s / 94874.4506 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.1563
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8512s / 95012.3017 s
agent0:                 episode reward: 0.0892,                 loss: nan
agent1:                 episode reward: -0.0892,                 loss: 0.1570
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8253s / 95146.1270 s
agent0:                 episode reward: -0.4468,                 loss: nan
agent1:                 episode reward: 0.4468,                 loss: 0.1550
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1747s / 95282.3017 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.1546
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1119s / 95419.4137 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.1541
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2447s / 95554.6583 s
agent0:                 episode reward: -0.2438,                 loss: nan
agent1:                 episode reward: 0.2438,                 loss: 0.1548
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7034s / 95695.3617 s
agent0:                 episode reward: -0.1223,                 loss: nan
agent1:                 episode reward: 0.1223,                 loss: 0.1559
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8681s / 95830.2298 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.1534
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5013s / 95965.7311 s
agent0:                 episode reward: -0.3137,                 loss: nan