Cannot import pettingzoo env:  combat_jet_v1
pong_v3 pettingzoo
type:  pettingzoo
pong_v3
Load pong_v3 environment in type pettingzoo.
Env observation space: <bound method aec_to_parallel_wrapper.observation_space of <pettingzoo.utils.conversions.aec_to_parallel_wrapper object at 0x7f08bd8d19e8>> action space: <bound method aec_to_parallel_wrapper.action_space of <pettingzoo.utils.conversions.aec_to_parallel_wrapper object at 0x7f08bd8d19e8>>
<mars.env.wrappers.mars_wrappers.SSVecWrapper object at 0x7f08bd8cb4e0>
random seed: [710, 326, 778, 123, 815, 567, 546, 975, 234, 335, 182, 118, 916, 847, 346, 364]
<mars.env.wrappers.mars_wrappers.SSVecWrapper object at 0x7f08bd8cb4e0>
discrete_policy 6 Discrete(6)
NashDQNBase(
  (net): CNN(
    (features): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
    )
    (body): Sequential(
      (0): Flatten()
      (1): Linear(in_features=3136, out_features=512, bias=True)
      (2): ReLU()
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Linear(in_features=512, out_features=36, bias=True)
      (6): Softmax(dim=-1)
    )
  )
)
discrete_policy 6 Discrete(6)
NashDQNBase(
  (net): CNN(
    (features): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
    )
    (body): Sequential(
      (0): Flatten()
      (1): Linear(in_features=3136, out_features=512, bias=True)
      (2): ReLU()
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Linear(in_features=512, out_features=36, bias=True)
      (6): Softmax(dim=-1)
    )
  )
)
discrete_policy 6 Discrete(6)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'pong_v3', 'env_type': 'pettingzoo', 'num_envs': 16, 'ram': False, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 5000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [512, 512], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax', 'channel_list': [32, 64, 64], 'kernel_size_list': [8, 4, 3], 'stride_list': [4, 2, 1]}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220622_0025/pettingzoo_pong_v3_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220622_0025/pettingzoo_pong_v3_nash_dqn.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 28.94s / 28.94 s
first_0:                 episode reward: 3.0000,                 loss: 0.0189
second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 792.85s / 821.79 s
first_0:                 episode reward: 2.8000,                 loss: 0.0217
second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 791.49s / 1613.28 s
first_0:                 episode reward: 2.5000,                 loss: 0.0222
second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 800.91s / 2414.19 s
first_0:                 episode reward: 1.9000,                 loss: 0.0223
second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 807.59s / 3221.78 s
first_0:                 episode reward: 1.8000,                 loss: 0.0226
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 816.54s / 4038.31 s
first_0:                 episode reward: 1.2000,                 loss: 0.0225
second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 821.18s / 4859.50 s
first_0:                 episode reward: 2.8500,                 loss: 0.0223
second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 835.18s / 5694.68 s
first_0:                 episode reward: 2.2500,                 loss: 0.0221
second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 841.42s / 6536.10 s
first_0:                 episode reward: 1.8000,                 loss: 0.0223
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 852.90s / 7389.01 s
first_0:                 episode reward: 0.7000,                 loss: 0.0224
second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 858.92s / 8247.92 s
first_0:                 episode reward: 1.5000,                 loss: 0.0223
second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 886.15s / 9134.07 s
first_0:                 episode reward: 1.6500,                 loss: 0.0224
second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 904.16s / 10038.22 s
first_0:                 episode reward: 1.4000,                 loss: 0.0222
second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 919.20s / 10957.42 s
first_0:                 episode reward: 1.3500,                 loss: 0.0223
second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 929.59s / 11887.02 s
first_0:                 episode reward: 1.4500,                 loss: 0.0225
second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 950.64s / 12837.66 s
first_0:                 episode reward: 1.6000,                 loss: 0.0223
second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 958.14s / 13795.80 s
first_0:                 episode reward: 2.1000,                 loss: 0.0228
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 962.54s / 14758.33 s
first_0:                 episode reward: 0.8500,                 loss: 0.0223
second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 947.76s / 15706.09 s
first_0:                 episode reward: 1.4000,                 loss: 0.0223
second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 954.26s / 16660.35 s
first_0:                 episode reward: 1.5000,                 loss: 0.0221
second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 960.51s / 17620.87 s
first_0:                 episode reward: 3.3500,                 loss: 0.0219
second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 946.95s / 18567.82 s
first_0:                 episode reward: 3.1000,                 loss: 0.0218
second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 947.04s / 19514.86 s
first_0:                 episode reward: 2.1000,                 loss: 0.0223
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 952.31s / 20467.17 s
first_0:                 episode reward: 2.5500,                 loss: 0.0223
second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 942.59s / 21409.75 s
first_0:                 episode reward: 0.3500,                 loss: 0.0221
second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 951.98s / 22361.73 s
first_0:                 episode reward: 3.1500,                 loss: 0.0222
second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 957.13s / 23318.86 s
first_0:                 episode reward: 3.8000,                 loss: 0.0220
second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 948.72s / 24267.58 s
first_0:                 episode reward: 1.9500,                 loss: 0.0223
second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 964.42s / 25232.00 s
first_0:                 episode reward: 2.5500,                 loss: 0.0219
second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 966.01s / 26198.01 s
first_0:                 episode reward: 3.2500,                 loss: 0.0222
second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 969.80s / 27167.81 s
first_0:                 episode reward: 0.6500,                 loss: 0.0222
second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 970.20s / 28138.00 s
first_0:                 episode reward: 4.4500,                 loss: 0.0222
second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 968.06s / 29106.06 s
first_0:                 episode reward: 4.0000,                 loss: 0.0220
second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 969.28s / 30075.34 s
first_0:                 episode reward: 3.0500,                 loss: 0.0220
second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 957.57s / 31032.91 s
first_0:                 episode reward: 4.5000,                 loss: 0.0220
second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 953.82s / 31986.73 s
first_0:                 episode reward: 2.8000,                 loss: 0.0224
second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 965.06s / 32951.80 s
first_0:                 episode reward: 0.9500,                 loss: 0.0222
second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 950.39s / 33902.19 s
first_0:                 episode reward: 2.1500,                 loss: 0.0220
second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 959.42s / 34861.61 s
first_0:                 episode reward: 1.5500,                 loss: 0.0223
second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 965.60s / 35827.21 s
first_0:                 episode reward: 3.4500,                 loss: 0.0219
second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 961.81s / 36789.02 s
first_0:                 episode reward: 2.1000,                 loss: 0.0218
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 954.49s / 37743.51 s
first_0:                 episode reward: 2.6000,                 loss: 0.0222
second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 968.87s / 38712.38 s
first_0:                 episode reward: 1.7000,                 loss: 0.0221
second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 967.92s / 39680.29 s
first_0:                 episode reward: 4.0500,                 loss: 0.0223
second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 968.46s / 40648.76 s
first_0:                 episode reward: 3.1500,                 loss: 0.0220
second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 977.87s / 41626.63 s
first_0:                 episode reward: 2.9500,                 loss: 0.0220
second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 976.97s / 42603.60 s
first_0:                 episode reward: 1.8000,                 loss: 0.0222
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 987.91s / 43591.50 s
first_0:                 episode reward: 2.9000,                 loss: 0.0221
second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 998.71s / 44590.21 s
first_0:                 episode reward: 1.9500,                 loss: 0.0221
second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 994.84s / 45585.05 s
first_0:                 episode reward: 0.6500,                 loss: 0.0222
second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 982.97s / 46568.02 s
first_0:                 episode reward: 2.5000,                 loss: 0.0220
second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 962.26s / 47530.28 s
first_0:                 episode reward: 2.6000,                 loss: 0.0221
second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 967.53s / 48497.80 s
first_0:                 episode reward: 0.6000,                 loss: 0.0222
second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 965.94s / 49463.75 s
first_0:                 episode reward: 4.3000,                 loss: 0.0221
second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 974.02s / 50437.77 s
first_0:                 episode reward: 2.1000,                 loss: 0.0219
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 962.44s / 51400.21 s
first_0:                 episode reward: 1.9000,                 loss: 0.0222
second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 964.40s / 52364.61 s
first_0:                 episode reward: 0.2000,                 loss: 0.0220
second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 957.91s / 53322.52 s
first_0:                 episode reward: 2.7000,                 loss: 0.0218
second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 958.03s / 54280.55 s
first_0:                 episode reward: 1.6000,                 loss: 0.0220
second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 962.75s / 55243.29 s
first_0:                 episode reward: 2.4500,                 loss: 0.0220
second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 957.84s / 56201.14 s
first_0:                 episode reward: 0.6500,                 loss: 0.0221
second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 975.70s / 57176.83 s
first_0:                 episode reward: 0.5000,                 loss: 0.0219
second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 974.48s / 58151.32 s
first_0:                 episode reward: 1.4500,                 loss: 0.0221
second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 979.86s / 59131.18 s
first_0:                 episode reward: 1.4000,                 loss: 0.0219
second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 978.97s / 60110.15 s
first_0:                 episode reward: 2.9000,                 loss: 0.0223
second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 980.28s / 61090.43 s
first_0:                 episode reward: 0.9500,                 loss: 0.0220
second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 991.59s / 62082.02 s
first_0:                 episode reward: 3.2000,                 loss: 0.0219
second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 972.58s / 63054.61 s
first_0:                 episode reward: 0.4500,                 loss: 0.0219
second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 960.41s / 64015.01 s
first_0:                 episode reward: 2.9500,                 loss: 0.0219
second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 958.95s / 64973.97 s
first_0:                 episode reward: 1.8000,                 loss: 0.0221
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 963.41s / 65937.38 s
first_0:                 episode reward: 2.1500,                 loss: 0.0221
second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 959.76s / 66897.13 s
first_0:                 episode reward: 0.7500,                 loss: 0.0222
second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 957.85s / 67854.99 s
first_0:                 episode reward: 3.4500,                 loss: 0.0220
second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 952.65s / 68807.63 s
first_0:                 episode reward: 1.8000,                 loss: 0.0218
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 956.58s / 69764.21 s
first_0:                 episode reward: 2.2000,                 loss: 0.0217
second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 968.96s / 70733.17 s
first_0:                 episode reward: 1.7000,                 loss: 0.0220
second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 966.81s / 71699.99 s
first_0:                 episode reward: 0.2500,                 loss: 0.0221
second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 971.02s / 72671.01 s
first_0:                 episode reward: 3.4000,                 loss: 0.0220
second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 973.41s / 73644.41 s
first_0:                 episode reward: 1.2000,                 loss: 0.0215
second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 978.29s / 74622.70 s
first_0:                 episode reward: 2.0000,                 loss: 0.0219
second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 986.39s / 75609.09 s
first_0:                 episode reward: 2.9000,                 loss: 0.0217
second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 980.12s / 76589.21 s
first_0:                 episode reward: 3.4000,                 loss: 0.0220
second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 980.14s / 77569.35 s
first_0:                 episode reward: 1.8000,                 loss: 0.0220
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 984.81s / 78554.16 s
first_0:                 episode reward: 2.3000,                 loss: 0.0215
second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 975.29s / 79529.45 s
first_0:                 episode reward: 2.6000,                 loss: 0.0219
second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 965.52s / 80494.98 s
first_0:                 episode reward: 3.0000,                 loss: 0.0219
second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 963.79s / 81458.77 s
first_0:                 episode reward: -0.2500,                 loss: 0.0217
second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 961.95s / 82420.71 s
first_0:                 episode reward: 2.5000,                 loss: 0.0218
second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 963.39s / 83384.10 s
first_0:                 episode reward: 3.0000,                 loss: 0.0218
second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 963.40s / 84347.50 s
first_0:                 episode reward: 0.9000,                 loss: 0.0220
second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 960.04s / 85307.54 s
first_0:                 episode reward: 3.8500,                 loss: 0.0217
second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 959.47s / 86267.01 s
first_0:                 episode reward: 3.8000,                 loss: 0.0216
second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 958.95s / 87225.96 s
first_0:                 episode reward: 2.1000,                 loss: 0.0218
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 963.17s / 88189.13 s
first_0:                 episode reward: 1.0000,                 loss: 0.0220
second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 971.54s / 89160.67 s
first_0:                 episode reward: 1.3000,                 loss: 0.0218
second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 982.87s / 90143.54 s
first_0:                 episode reward: 2.4500,                 loss: 0.0220
second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 978.68s / 91122.22 s
first_0:                 episode reward: 0.2500,                 loss: 0.0216
second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 978.81s / 92101.03 s
first_0:                 episode reward: 3.1000,                 loss: 0.0217
second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 983.11s / 93084.15 s
first_0:                 episode reward: 2.6500,                 loss: 0.0216
second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 981.18s / 94065.33 s
first_0:                 episode reward: 1.4500,                 loss: 0.0219
second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 975.53s / 95040.85 s
first_0:                 episode reward: 3.8500,                 loss: 0.0216
second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 959.03s / 95999.88 s
first_0:                 episode reward: 3.4000,                 loss: 0.0217
second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 967.12s / 96967.00 s
first_0:                 episode reward: 3.7000,                 loss: 0.0218
second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 961.17s / 97928.17 s
first_0:                 episode reward: 2.5000,                 loss: 0.0217
second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 961.99s / 98890.15 s
first_0:                 episode reward: 1.9000,                 loss: 0.0215
second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 957.67s / 99847.82 s
first_0:                 episode reward: 1.1000,                 loss: 0.0216
second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 955.77s / 100803.59 s
first_0:                 episode reward: 1.3000,                 loss: 0.0217
second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 957.35s / 101760.94 s
first_0:                 episode reward: 1.9500,                 loss: 0.0212
second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 958.29s / 102719.24 s
first_0:                 episode reward: 1.8000,                 loss: 0.0215
second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 960.97s / 103680.21 s
first_0:                 episode reward: 1.9000,                 loss: 0.0216
second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 964.30s / 104644.51 s
first_0:                 episode reward: 2.1000,                 loss: 0.0216
second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 976.19s / 105620.71 s
first_0:                 episode reward: 1.4500,                 loss: 0.0216
second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 981.55s / 106602.25 s
first_0:                 episode reward: 3.1000,                 loss: 0.0212
second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 978.67s / 107580.93 s
first_0:                 episode reward: 2.8500,                 loss: 0.0212
second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 981.31s / 108562.24 s
first_0:                 episode reward: 3.3000,                 loss: 0.0214
second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 987.55s / 109549.79 s
first_0:                 episode reward: 0.9000,                 loss: 0.0215
second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 980.62s / 110530.40 s
first_0:                 episode reward: 0.6500,                 loss: 0.0213
second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 978.17s / 111508.57 s
first_0:                 episode reward: 1.5000,                 loss: 0.0212
second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 965.51s / 112474.08 s
first_0:                 episode reward: 2.5500,                 loss: 0.0213
second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 965.08s / 113439.16 s
first_0:                 episode reward: 1.8500,                 loss: 0.0212
second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 965.09s / 114404.25 s
first_0:                 episode reward: 2.2500,                 loss: 0.0212
second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 965.56s / 115369.81 s
first_0:                 episode reward: 2.0500,                 loss: 0.0209
second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 960.74s / 116330.55 s
first_0:                 episode reward: 0.7000,                 loss: 0.0211
second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 963.80s / 117294.35 s
first_0:                 episode reward: 0.7500,                 loss: 0.0210
second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 961.43s / 118255.78 s
first_0:                 episode reward: 2.0000,                 loss: 0.0215
second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 963.62s / 119219.40 s
first_0:                 episode reward: 2.4500,                 loss: 0.0212
second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 963.50s / 120182.91 s
first_0:                 episode reward: 4.0000,                 loss: 0.0210
second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 966.57s / 121149.47 s
first_0:                 episode reward: 3.1000,                 loss: 0.0209
second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 979.70s / 122129.18 s
first_0:                 episode reward: 3.7500,                 loss: 0.0211
second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 975.43s / 123104.61 s
first_0:                 episode reward: 2.0000,                 loss: 0.0212
second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 977.83s / 124082.44 s
first_0:                 episode reward: 2.2500,                 loss: 0.0213
second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 980.96s / 125063.40 s
first_0:                 episode reward: -0.6000,                 loss: 0.0211
second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 983.67s / 126047.07 s
first_0:                 episode reward: 2.0500,                 loss: 0.0211
second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 978.31s / 127025.37 s
first_0:                 episode reward: 0.7500,                 loss: 0.0211
second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 973.03s / 127998.41 s
first_0:                 episode reward: 0.2500,                 loss: 0.0212
second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 970.20s / 128968.60 s
first_0:                 episode reward: 0.4000,                 loss: 0.0210
second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 967.31s / 129935.92 s
first_0:                 episode reward: 2.3500,                 loss: 0.0211
second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 970.93s / 130906.85 s
first_0:                 episode reward: 2.7500,                 loss: 0.0208
second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 972.81s / 131879.66 s
first_0:                 episode reward: 2.7500,                 loss: 0.0208
second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 964.97s / 132844.63 s
first_0:                 episode reward: 2.3000,                 loss: 0.0208
second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 975.97s / 133820.60 s
first_0:                 episode reward: 2.8500,                 loss: 0.0210
second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 968.84s / 134789.43 s
first_0:                 episode reward: 2.3000,                 loss: 0.0211
second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 966.40s / 135755.83 s
first_0:                 episode reward: 0.7000,                 loss: 0.0208
second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 967.91s / 136723.74 s
first_0:                 episode reward: 0.1000,                 loss: 0.0209
second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 972.85s / 137696.59 s
first_0:                 episode reward: 1.0000,                 loss: 0.0208
second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 989.17s / 138685.76 s
first_0:                 episode reward: 2.8500,                 loss: 0.0207
second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 984.58s / 139670.34 s
first_0:                 episode reward: 3.8000,                 loss: 0.0208
second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 982.14s / 140652.49 s
first_0:                 episode reward: 3.3500,                 loss: 0.0210
second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 992.17s / 141644.65 s
first_0:                 episode reward: 2.8000,                 loss: 0.0208
second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 978.24s / 142622.89 s
first_0:                 episode reward: 1.7500,                 loss: 0.0210
second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 982.14s / 143605.04 s
first_0:                 episode reward: 1.4500,                 loss: 0.0208
second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 964.52s / 144569.56 s
first_0:                 episode reward: 1.3500,                 loss: 0.0208
second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 967.45s / 145537.00 s
first_0:                 episode reward: 2.4000,                 loss: 0.0207
second_0:                 episode reward: -2.4000,                 loss: nan