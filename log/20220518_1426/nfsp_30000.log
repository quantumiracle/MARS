pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f6d5a214c50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/30000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/30000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_30000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_30000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 0.6759 s
agent0:                 episode reward: -0.5509,                 loss: nan
agent1:                 episode reward: 0.5509,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 0.8741 s
agent0:                 episode reward: -0.2850,                 loss: nan
agent1:                 episode reward: 0.2850,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 1.0688 s
agent0:                 episode reward: 0.0739,                 loss: nan
agent1:                 episode reward: -0.0739,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 1.2659 s
agent0:                 episode reward: -0.2254,                 loss: nan
agent1:                 episode reward: 0.2254,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.4639 s
agent0:                 episode reward: -0.0313,                 loss: nan
agent1:                 episode reward: 0.0313,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 1.6576 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 1.8535 s
agent0:                 episode reward: 0.0841,                 loss: nan
agent1:                 episode reward: -0.0841,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 2.0545 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 2.2560 s
agent0:                 episode reward: 0.4161,                 loss: nan
agent1:                 episode reward: -0.4161,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 2.4542 s
agent0:                 episode reward: 0.1083,                 loss: nan
agent1:                 episode reward: -0.1083,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 2.6501 s
agent0:                 episode reward: -0.1589,                 loss: nan
agent1:                 episode reward: 0.1589,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 2.8499 s
agent0:                 episode reward: -0.2784,                 loss: nan
agent1:                 episode reward: 0.2784,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 3.0471 s
agent0:                 episode reward: 0.5400,                 loss: nan
agent1:                 episode reward: -0.5400,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 3.2434 s
agent0:                 episode reward: 0.1719,                 loss: nan
agent1:                 episode reward: -0.1719,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.4435 s
agent0:                 episode reward: 0.2557,                 loss: nan
agent1:                 episode reward: -0.2557,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 3.6476 s
agent0:                 episode reward: 0.2418,                 loss: nan
agent1:                 episode reward: -0.2418,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 3.8428 s
agent0:                 episode reward: 0.1741,                 loss: nan
agent1:                 episode reward: -0.1741,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 4.0411 s
agent0:                 episode reward: 0.1584,                 loss: nan
agent1:                 episode reward: -0.1584,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 4.2399 s
agent0:                 episode reward: -0.4288,                 loss: nan
agent1:                 episode reward: 0.4288,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 4.4373 s
agent0:                 episode reward: 0.0527,                 loss: nan
agent1:                 episode reward: -0.0527,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 4.6395 s
agent0:                 episode reward: 0.4790,                 loss: nan
agent1:                 episode reward: -0.4790,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 4.8425 s
agent0:                 episode reward: -0.0568,                 loss: nan
agent1:                 episode reward: 0.0568,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 5.0402 s
agent0:                 episode reward: 0.0603,                 loss: nan
agent1:                 episode reward: -0.0603,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 5.2388 s
agent0:                 episode reward: 0.1014,                 loss: nan
agent1:                 episode reward: -0.1014,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 5.4396 s
agent0:                 episode reward: -0.0601,                 loss: nan
agent1:                 episode reward: 0.0601,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 5.6351 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 5.8344 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 6.0331 s
agent0:                 episode reward: 0.3399,                 loss: nan
agent1:                 episode reward: -0.3399,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 6.2318 s
agent0:                 episode reward: -0.0508,                 loss: nan
agent1:                 episode reward: 0.0508,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 6.4302 s
agent0:                 episode reward: -0.4364,                 loss: nan
agent1:                 episode reward: 0.4364,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 6.6290 s
agent0:                 episode reward: -0.0453,                 loss: nan
agent1:                 episode reward: 0.0453,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 6.8309 s
agent0:                 episode reward: -0.1853,                 loss: nan
agent1:                 episode reward: 0.1853,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 7.0317 s
agent0:                 episode reward: -0.3677,                 loss: nan
agent1:                 episode reward: 0.3677,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 7.2296 s
agent0:                 episode reward: 0.0916,                 loss: nan
agent1:                 episode reward: -0.0916,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 7.4321 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 7.6306 s
agent0:                 episode reward: -0.4712,                 loss: nan
agent1:                 episode reward: 0.4712,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 7.8248 s
agent0:                 episode reward: -0.0155,                 loss: nan
agent1:                 episode reward: 0.0155,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 8.0278 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 8.2279 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 8.4246 s
agent0:                 episode reward: 0.0757,                 loss: nan
agent1:                 episode reward: -0.0757,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 8.6227 s
agent0:                 episode reward: -0.4896,                 loss: nan
agent1:                 episode reward: 0.4896,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 8.8188 s
agent0:                 episode reward: 0.0698,                 loss: nan
agent1:                 episode reward: -0.0698,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 9.0172 s
agent0:                 episode reward: -0.3214,                 loss: nan
agent1:                 episode reward: 0.3214,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 9.2141 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 9.4167 s
agent0:                 episode reward: -0.7774,                 loss: nan
agent1:                 episode reward: 0.7774,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 9.6186 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 9.8140 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 10.0119 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 10.2092 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.4081 s
agent0:                 episode reward: 0.0225,                 loss: nan
agent1:                 episode reward: -0.0225,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 10.6057 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 10.8063 s
agent0:                 episode reward: -0.0431,                 loss: nan
agent1:                 episode reward: 0.0431,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 11.0022 s
agent0:                 episode reward: -0.1269,                 loss: nan
agent1:                 episode reward: 0.1269,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 11.2019 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 11.3873 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 11.5860 s
agent0:                 episode reward: -0.2250,                 loss: nan
agent1:                 episode reward: 0.2250,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 11.7815 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 11.9822 s
agent0:                 episode reward: -0.2697,                 loss: nan
agent1:                 episode reward: 0.2697,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 12.1744 s
agent0:                 episode reward: 0.0015,                 loss: nan
agent1:                 episode reward: -0.0015,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 12.3716 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 12.5685 s
agent0:                 episode reward: 0.0305,                 loss: nan
agent1:                 episode reward: -0.0305,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 12.7669 s
agent0:                 episode reward: -0.0957,                 loss: nan
agent1:                 episode reward: 0.0957,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 12.9642 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 13.1615 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 13.3589 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 13.5577 s
agent0:                 episode reward: -0.0818,                 loss: nan
agent1:                 episode reward: 0.0818,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 13.7575 s
agent0:                 episode reward: 0.0304,                 loss: nan
agent1:                 episode reward: -0.0304,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 13.9551 s
agent0:                 episode reward: -0.2435,                 loss: nan
agent1:                 episode reward: 0.2435,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 14.1521 s
agent0:                 episode reward: -0.0859,                 loss: nan
agent1:                 episode reward: 0.0859,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 14.3534 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 14.5500 s
agent0:                 episode reward: 0.5802,                 loss: nan
agent1:                 episode reward: -0.5802,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 14.7509 s
agent0:                 episode reward: 0.3593,                 loss: nan
agent1:                 episode reward: -0.3593,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 14.9472 s
agent0:                 episode reward: 0.2035,                 loss: nan
agent1:                 episode reward: -0.2035,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 15.1448 s
agent0:                 episode reward: 0.2852,                 loss: nan
agent1:                 episode reward: -0.2852,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 15.3409 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 15.5443 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 15.7296 s
agent0:                 episode reward: 0.6788,                 loss: nan
agent1:                 episode reward: -0.6788,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.9280 s
agent0:                 episode reward: 0.1183,                 loss: nan
agent1:                 episode reward: -0.1183,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 16.1255 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 16.3230 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 16.5200 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 16.7169 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 16.9124 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 17.1123 s
agent0:                 episode reward: -0.0130,                 loss: nan
agent1:                 episode reward: 0.0130,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 17.3055 s
agent0:                 episode reward: 0.0186,                 loss: nan
agent1:                 episode reward: -0.0186,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 17.5063 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 17.7039 s
agent0:                 episode reward: -0.0897,                 loss: nan
agent1:                 episode reward: 0.0897,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 17.8992 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 18.1036 s
agent0:                 episode reward: 0.1719,                 loss: nan
agent1:                 episode reward: -0.1719,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 18.3017 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 18.5011 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 18.7038 s
agent0:                 episode reward: 0.4323,                 loss: nan
agent1:                 episode reward: -0.4323,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 18.9008 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 19.0952 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 19.2896 s
agent0:                 episode reward: 0.0741,                 loss: nan
agent1:                 episode reward: -0.0741,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 19.4836 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 19.6845 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 19.8807 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 20.0774 s
agent0:                 episode reward: -0.3008,                 loss: nan
agent1:                 episode reward: 0.3008,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 20.2680 s
agent0:                 episode reward: -0.2542,                 loss: nan
agent1:                 episode reward: 0.2542,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 20.4649 s
agent0:                 episode reward: -0.3799,                 loss: nan
agent1:                 episode reward: 0.3799,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 20.6605 s
agent0:                 episode reward: 0.1012,                 loss: nan
agent1:                 episode reward: -0.1012,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 20.8594 s
agent0:                 episode reward: -0.2761,                 loss: nan
agent1:                 episode reward: 0.2761,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 21.0621 s
agent0:                 episode reward: -0.0262,                 loss: nan
agent1:                 episode reward: 0.0262,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 21.2598 s
agent0:                 episode reward: 0.2505,                 loss: nan
agent1:                 episode reward: -0.2505,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 21.4561 s
agent0:                 episode reward: -0.0887,                 loss: nan
agent1:                 episode reward: 0.0887,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 21.6563 s
agent0:                 episode reward: 0.5116,                 loss: nan
agent1:                 episode reward: -0.5116,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 21.8550 s
agent0:                 episode reward: -0.4011,                 loss: nan
agent1:                 episode reward: 0.4011,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 22.0513 s
agent0:                 episode reward: 0.2439,                 loss: nan
agent1:                 episode reward: -0.2439,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 22.2457 s
agent0:                 episode reward: 0.3057,                 loss: nan
agent1:                 episode reward: -0.3057,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 22.4440 s
agent0:                 episode reward: 0.0084,                 loss: nan
agent1:                 episode reward: -0.0084,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 22.6397 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 22.8435 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 23.0458 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 23.2495 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 23.4443 s
agent0:                 episode reward: 0.2740,                 loss: nan
agent1:                 episode reward: -0.2740,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 23.6445 s
agent0:                 episode reward: -0.2128,                 loss: nan
agent1:                 episode reward: 0.2128,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 23.8441 s
agent0:                 episode reward: 0.1287,                 loss: nan
agent1:                 episode reward: -0.1287,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 24.0381 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.2400 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 24.4397 s
agent0:                 episode reward: 0.1603,                 loss: nan
agent1:                 episode reward: -0.1603,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 24.6375 s
agent0:                 episode reward: -0.0731,                 loss: nan
agent1:                 episode reward: 0.0731,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 24.8376 s
agent0:                 episode reward: 0.2602,                 loss: nan
agent1:                 episode reward: -0.2602,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 25.0361 s
agent0:                 episode reward: -0.1287,                 loss: nan
agent1:                 episode reward: 0.1287,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 25.2362 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 25.4358 s
agent0:                 episode reward: 0.1511,                 loss: nan
agent1:                 episode reward: -0.1511,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 25.6368 s
agent0:                 episode reward: -0.1817,                 loss: nan
agent1:                 episode reward: 0.1817,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.8358 s
agent0:                 episode reward: -0.5197,                 loss: nan
agent1:                 episode reward: 0.5197,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 26.0299 s
agent0:                 episode reward: 0.2012,                 loss: nan
agent1:                 episode reward: -0.2012,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 26.2249 s
agent0:                 episode reward: 0.1536,                 loss: nan
agent1:                 episode reward: -0.1536,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 26.4243 s
agent0:                 episode reward: -0.0803,                 loss: nan
agent1:                 episode reward: 0.0803,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 26.6215 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 26.8190 s
agent0:                 episode reward: 0.1138,                 loss: nan
agent1:                 episode reward: -0.1138,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 27.0188 s
agent0:                 episode reward: -0.0526,                 loss: nan
agent1:                 episode reward: 0.0526,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 27.2135 s
agent0:                 episode reward: -0.1165,                 loss: nan
agent1:                 episode reward: 0.1165,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 27.4132 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 27.6111 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 27.8080 s
agent0:                 episode reward: 0.1517,                 loss: nan
agent1:                 episode reward: -0.1517,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 28.0224 s
agent0:                 episode reward: -0.1474,                 loss: nan
agent1:                 episode reward: 0.1474,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 28.2104 s
agent0:                 episode reward: -0.0185,                 loss: nan
agent1:                 episode reward: 0.0185,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 28.4073 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 28.6086 s
agent0:                 episode reward: -0.1673,                 loss: nan
agent1:                 episode reward: 0.1673,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 28.8089 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 29.0122 s
agent0:                 episode reward: 0.1048,                 loss: nan
agent1:                 episode reward: -0.1048,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 29.2135 s
agent0:                 episode reward: 0.1893,                 loss: nan
agent1:                 episode reward: -0.1893,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 29.4115 s
agent0:                 episode reward: -0.0953,                 loss: nan
agent1:                 episode reward: 0.0953,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 29.6091 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 29.8097 s
agent0:                 episode reward: -0.4329,                 loss: nan
agent1:                 episode reward: 0.4329,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 30.0101 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 30.2113 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 30.4120 s
agent0:                 episode reward: 0.5341,                 loss: nan
agent1:                 episode reward: -0.5341,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 30.6045 s
agent0:                 episode reward: 0.3536,                 loss: nan
agent1:                 episode reward: -0.3536,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 30.8054 s
agent0:                 episode reward: 0.2086,                 loss: nan
agent1:                 episode reward: -0.2086,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 31.0073 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 31.2051 s
agent0:                 episode reward: -0.0150,                 loss: nan
agent1:                 episode reward: 0.0150,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 31.4093 s
agent0:                 episode reward: -0.0679,                 loss: nan
agent1:                 episode reward: 0.0679,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 31.6089 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 31.8121 s
agent0:                 episode reward: -0.3409,                 loss: nan
agent1:                 episode reward: 0.3409,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 32.0137 s
agent0:                 episode reward: 0.2177,                 loss: nan
agent1:                 episode reward: -0.2177,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.2124 s
agent0:                 episode reward: 0.5739,                 loss: nan
agent1:                 episode reward: -0.5739,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 32.4150 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 32.6154 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 32.8183 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 33.0172 s
agent0:                 episode reward: 0.4328,                 loss: nan
agent1:                 episode reward: -0.4328,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 33.2168 s
agent0:                 episode reward: -0.2483,                 loss: nan
agent1:                 episode reward: 0.2483,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 33.4167 s
agent0:                 episode reward: -0.1287,                 loss: nan
agent1:                 episode reward: 0.1287,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 33.6173 s
agent0:                 episode reward: -0.2916,                 loss: nan
agent1:                 episode reward: 0.2916,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3580s / 33.9754 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.4594
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 34.5642 s
agent0:                 episode reward: -0.1956,                 loss: nan
agent1:                 episode reward: 0.1956,                 loss: 0.4480
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 35.1470 s
agent0:                 episode reward: -0.0616,                 loss: nan
agent1:                 episode reward: 0.0616,                 loss: 0.4334
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 35.7293 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: 0.4217
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 36.3131 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.4023
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 36.9000 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.3902
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 37.4828 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3772
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 38.0670 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: 0.3711
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 38.6546 s
agent0:                 episode reward: -0.5512,                 loss: nan
agent1:                 episode reward: 0.5512,                 loss: 0.3670
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 39.2437 s
agent0:                 episode reward: 0.0555,                 loss: nan
agent1:                 episode reward: -0.0555,                 loss: 0.3729
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 39.8256 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.3729
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 40.4122 s
agent0:                 episode reward: -0.3072,                 loss: nan
agent1:                 episode reward: 0.3072,                 loss: 0.3694
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 41.0066 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3685
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 41.5872 s
agent0:                 episode reward: -0.3688,                 loss: nan
agent1:                 episode reward: 0.3688,                 loss: 0.3678
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 42.1691 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.3686
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 42.7621 s
agent0:                 episode reward: -0.0647,                 loss: nan
agent1:                 episode reward: 0.0647,                 loss: 0.3698
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 43.3457 s
agent0:                 episode reward: -0.0305,                 loss: nan
agent1:                 episode reward: 0.0305,                 loss: 0.3661
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 43.9292 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.3602
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 44.5114 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.3484
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 45.0925 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.3451
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 45.6842 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.3442
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 46.2693 s
agent0:                 episode reward: 0.2782,                 loss: nan
agent1:                 episode reward: -0.2782,                 loss: 0.3434
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 46.8540 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3424
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 47.4411 s
agent0:                 episode reward: 0.0032,                 loss: nan
agent1:                 episode reward: -0.0032,                 loss: 0.3466
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 48.0230 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.3433
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 48.6044 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.3432
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 49.1911 s
agent0:                 episode reward: -0.6943,                 loss: nan
agent1:                 episode reward: 0.6943,                 loss: 0.3421
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 49.7778 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.3394
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 50.3634 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3401
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 50.9453 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.3401
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 51.5251 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.3381
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 52.1141 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.3393
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 52.6985 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.3380
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 53.2870 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.3397
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 53.8793 s
agent0:                 episode reward: -0.7417,                 loss: nan
agent1:                 episode reward: 0.7417,                 loss: 0.3692
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 54.4631 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.3643
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 55.0521 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3617
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 55.6424 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.3640
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 56.2287 s
agent0:                 episode reward: -0.7819,                 loss: nan
agent1:                 episode reward: 0.7819,                 loss: 0.3639
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 56.8097 s
agent0:                 episode reward: 0.2613,                 loss: nan
agent1:                 episode reward: -0.2613,                 loss: 0.3654
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5756s / 57.3853 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.3647
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 57.9733 s
agent0:                 episode reward: -0.9288,                 loss: nan
agent1:                 episode reward: 0.9288,                 loss: 0.3614
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 58.5599 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.3605
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 59.1432 s
agent0:                 episode reward: -0.4489,                 loss: nan
agent1:                 episode reward: 0.4489,                 loss: 0.3633
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 59.7363 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: 0.3643
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 60.3258 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.3664
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 60.9180 s
agent0:                 episode reward: -0.3724,                 loss: nan
agent1:                 episode reward: 0.3724,                 loss: 0.3617
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 61.5106 s
agent0:                 episode reward: -0.6758,                 loss: nan
agent1:                 episode reward: 0.6758,                 loss: 0.3592
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 62.0934 s
agent0:                 episode reward: 0.4131,                 loss: nan
agent1:                 episode reward: -0.4131,                 loss: 0.3602
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 62.6819 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3611
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 63.2758 s
agent0:                 episode reward: -0.3582,                 loss: nan
agent1:                 episode reward: 0.3582,                 loss: 0.3602
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 63.8674 s
agent0:                 episode reward: -0.4009,                 loss: nan
agent1:                 episode reward: 0.4009,                 loss: 0.3490
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 64.4617 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.3503
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 65.0535 s
agent0:                 episode reward: -0.3940,                 loss: nan
agent1:                 episode reward: 0.3940,                 loss: 0.3510
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 65.6422 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3485
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 66.2291 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.3475
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 66.8131 s
agent0:                 episode reward: -0.3748,                 loss: nan
agent1:                 episode reward: 0.3748,                 loss: 0.3512
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 67.4058 s
agent0:                 episode reward: -0.2007,                 loss: nan
agent1:                 episode reward: 0.2007,                 loss: 0.3495
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 67.9921 s
agent0:                 episode reward: -0.2458,                 loss: nan
agent1:                 episode reward: 0.2458,                 loss: 0.3498
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 68.5820 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.3477
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 69.1697 s
agent0:                 episode reward: -0.3118,                 loss: nan
agent1:                 episode reward: 0.3118,                 loss: 0.3504
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 69.7577 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.3487
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 70.3458 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.3479
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 70.9395 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.3462
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 71.5305 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.3467
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 72.1240 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.3467
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 72.7169 s
agent0:                 episode reward: -0.4811,                 loss: nan
agent1:                 episode reward: 0.4811,                 loss: 0.3443
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 73.3060 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.3531
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 73.8882 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3457
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 74.4787 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.3498
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 75.0711 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.3475
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 75.6522 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.3479
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 76.2344 s
agent0:                 episode reward: -0.6107,                 loss: nan
agent1:                 episode reward: 0.6107,                 loss: 0.3472
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 76.8322 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.3461
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 77.4237 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.3442
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 78.0157 s
agent0:                 episode reward: -0.3512,                 loss: nan
agent1:                 episode reward: 0.3512,                 loss: 0.3444
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 78.6046 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.3457
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 79.1921 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.3435
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 79.7808 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.3453
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 80.3651 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: 0.3425
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 80.9588 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3450
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 81.5390 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.3452
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 82.1254 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.3479
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 82.7181 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.3474
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 83.3068 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.3602
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 83.9007 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.3605
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 84.4879 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.3598
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 85.0821 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.3571
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 85.6798 s
agent0:                 episode reward: -0.2894,                 loss: nan
agent1:                 episode reward: 0.2894,                 loss: 0.3561
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 86.2770 s
agent0:                 episode reward: -0.5014,                 loss: nan
agent1:                 episode reward: 0.5014,                 loss: 0.3589
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 86.8784 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.3624
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 87.4718 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.3558
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 88.0597 s
agent0:                 episode reward: -0.7025,                 loss: nan
agent1:                 episode reward: 0.7025,                 loss: 0.3590
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 88.6400 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.3589
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 89.2260 s
agent0:                 episode reward: -0.1550,                 loss: nan
agent1:                 episode reward: 0.1550,                 loss: 0.3556
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 89.8216 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3587
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 90.4081 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.3572
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 90.9945 s
agent0:                 episode reward: -0.3316,                 loss: nan
agent1:                 episode reward: 0.3316,                 loss: 0.3578
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 91.5764 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.3564
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 92.1711 s
agent0:                 episode reward: -0.3515,                 loss: nan
agent1:                 episode reward: 0.3515,                 loss: 0.3596
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 92.7606 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.3543
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 93.3521 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.3469
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 93.9364 s
agent0:                 episode reward: -0.2123,                 loss: nan
agent1:                 episode reward: 0.2123,                 loss: 0.3459
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 94.5291 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.3452
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 95.1090 s
agent0:                 episode reward: -0.4880,                 loss: nan
agent1:                 episode reward: 0.4880,                 loss: 0.3448
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 95.6991 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3459
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 96.2842 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.3434
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 96.8726 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.3452
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 97.4607 s
agent0:                 episode reward: -0.4171,                 loss: nan
agent1:                 episode reward: 0.4171,                 loss: 0.3446
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 98.0418 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.3448
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 98.6296 s
agent0:                 episode reward: -0.4256,                 loss: nan
agent1:                 episode reward: 0.4256,                 loss: 0.3446
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 99.2173 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.3455
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 99.8037 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: 0.3432
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 100.3946 s
agent0:                 episode reward: -0.1748,                 loss: nan
agent1:                 episode reward: 0.1748,                 loss: 0.3455
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 100.9893 s
agent0:                 episode reward: -0.2066,                 loss: nan
agent1:                 episode reward: 0.2066,                 loss: 0.3451
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 101.5717 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.3453
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 102.1568 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.3481
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 102.7543 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.3516
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 103.3445 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.3524
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 103.9409 s
agent0:                 episode reward: -0.4596,                 loss: nan
agent1:                 episode reward: 0.4596,                 loss: 0.3514
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 104.5410 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: 0.3530
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 105.1358 s
agent0:                 episode reward: -0.7537,                 loss: nan
agent1:                 episode reward: 0.7537,                 loss: 0.3512
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 105.7343 s
agent0:                 episode reward: -0.3067,                 loss: nan
agent1:                 episode reward: 0.3067,                 loss: 0.3525
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 106.3282 s
agent0:                 episode reward: -0.3238,                 loss: nan
agent1:                 episode reward: 0.3238,                 loss: 0.3533
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 106.9230 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.3517
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 107.5212 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.3538
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 108.1177 s
agent0:                 episode reward: -0.3484,                 loss: nan
agent1:                 episode reward: 0.3484,                 loss: 0.3498
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 108.7185 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.3524
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 109.3116 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.3498
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 109.9044 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.3509
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 110.5058 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.3542
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 111.1009 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.3526
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 111.7005 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.3482
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 112.2953 s
agent0:                 episode reward: -0.0257,                 loss: nan
agent1:                 episode reward: 0.0257,                 loss: 0.3504
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 112.8981 s
agent0:                 episode reward: -0.4663,                 loss: nan
agent1:                 episode reward: 0.4663,                 loss: 0.3549
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 113.4940 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.3526
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 114.0968 s
agent0:                 episode reward: -0.7222,                 loss: nan
agent1:                 episode reward: 0.7222,                 loss: 0.3496
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 114.7003 s
agent0:                 episode reward: -0.1767,                 loss: nan
agent1:                 episode reward: 0.1767,                 loss: 0.3515
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 115.3024 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.3528
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 115.9062 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.3506
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 116.5050 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.3521
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 117.1036 s
agent0:                 episode reward: -0.5871,                 loss: nan
agent1:                 episode reward: 0.5871,                 loss: 0.3519
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 117.6982 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: 0.3527
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 118.2919 s
agent0:                 episode reward: -0.6731,                 loss: nan
agent1:                 episode reward: 0.6731,                 loss: 0.3525
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 118.8881 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3512
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 119.4923 s
agent0:                 episode reward: -0.7742,                 loss: nan
agent1:                 episode reward: 0.7742,                 loss: 0.3496
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 120.0831 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.3514
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 120.6837 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.3503
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 121.2774 s
agent0:                 episode reward: -0.5649,                 loss: nan
agent1:                 episode reward: 0.5649,                 loss: 0.3510
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 121.8803 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.3525
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 122.4858 s
agent0:                 episode reward: -0.2909,                 loss: nan
agent1:                 episode reward: 0.2909,                 loss: 0.3498
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 123.0831 s
agent0:                 episode reward: -0.6655,                 loss: nan
agent1:                 episode reward: 0.6655,                 loss: 0.3438
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 123.6861 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.3430
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 124.2815 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.3470
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 124.8790 s
agent0:                 episode reward: -0.3589,                 loss: nan
agent1:                 episode reward: 0.3589,                 loss: 0.3443
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 125.4771 s
agent0:                 episode reward: -0.7789,                 loss: nan
agent1:                 episode reward: 0.7789,                 loss: 0.3459
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 126.0663 s
agent0:                 episode reward: -0.4043,                 loss: nan
agent1:                 episode reward: 0.4043,                 loss: 0.3470
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 126.6641 s
agent0:                 episode reward: -0.1888,                 loss: nan
agent1:                 episode reward: 0.1888,                 loss: 0.3443
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 127.2575 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.3463
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 127.8527 s
agent0:                 episode reward: -0.3241,                 loss: nan
agent1:                 episode reward: 0.3241,                 loss: 0.3471
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 128.4406 s
agent0:                 episode reward: -0.7277,                 loss: nan
agent1:                 episode reward: 0.7277,                 loss: 0.3442
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 129.0411 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.3450
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 129.6408 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.3444
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 130.2394 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.3436
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 130.8415 s
agent0:                 episode reward: -0.9527,                 loss: nan
agent1:                 episode reward: 0.9527,                 loss: 0.3414
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 131.4410 s
agent0:                 episode reward: -1.0157,                 loss: nan
agent1:                 episode reward: 1.0157,                 loss: 0.3420
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 132.0367 s
agent0:                 episode reward: -0.7994,                 loss: nan
agent1:                 episode reward: 0.7994,                 loss: 0.3439
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 132.6300 s
agent0:                 episode reward: -0.2030,                 loss: nan
agent1:                 episode reward: 0.2030,                 loss: 0.3423
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 133.2426 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.3449
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 133.8412 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.3429
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 134.4392 s
agent0:                 episode reward: -0.3898,                 loss: nan
agent1:                 episode reward: 0.3898,                 loss: 0.3473
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 135.0369 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.3420
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 135.6349 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3431
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 136.2338 s
agent0:                 episode reward: -0.3840,                 loss: nan
agent1:                 episode reward: 0.3840,                 loss: 0.3439
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 136.8289 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.3470
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 137.4228 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: 0.3470
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 138.0167 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.3421
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 138.6166 s
agent0:                 episode reward: -0.2080,                 loss: nan
agent1:                 episode reward: 0.2080,                 loss: 0.3448
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 139.2090 s
agent0:                 episode reward: -0.3869,                 loss: nan
agent1:                 episode reward: 0.3869,                 loss: 0.3416
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 139.8106 s
agent0:                 episode reward: -0.8843,                 loss: nan
agent1:                 episode reward: 0.8843,                 loss: 0.3456
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 140.4053 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: 0.3465
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 141.0016 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3487
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 141.6053 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.3438
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 142.2100 s
agent0:                 episode reward: -0.8242,                 loss: nan
agent1:                 episode reward: 0.8242,                 loss: 0.3457
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 142.8031 s
agent0:                 episode reward: -0.4409,                 loss: nan
agent1:                 episode reward: 0.4409,                 loss: 0.3517
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 143.4027 s
agent0:                 episode reward: -0.8211,                 loss: nan
agent1:                 episode reward: 0.8211,                 loss: 0.3536
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 143.9982 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: 0.3513
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 144.5990 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.3514
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 145.1985 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.3503
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 145.7965 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.3530
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 146.4019 s
agent0:                 episode reward: -0.3930,                 loss: nan
agent1:                 episode reward: 0.3930,                 loss: 0.3523
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 146.9996 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3498
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 147.6001 s
agent0:                 episode reward: -0.8083,                 loss: nan
agent1:                 episode reward: 0.8083,                 loss: 0.3529
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 148.2025 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.3496
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 148.8004 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.3538
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 149.3984 s
agent0:                 episode reward: -0.8348,                 loss: nan
agent1:                 episode reward: 0.8348,                 loss: 0.3543
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 149.9980 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3511
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 150.5879 s
agent0:                 episode reward: -0.6731,                 loss: nan
agent1:                 episode reward: 0.6731,                 loss: 0.3543
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 151.1784 s
agent0:                 episode reward: -0.8772,                 loss: nan
agent1:                 episode reward: 0.8772,                 loss: 0.3515
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 151.7769 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.3507
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 152.3733 s
agent0:                 episode reward: -0.4766,                 loss: nan
agent1:                 episode reward: 0.4766,                 loss: 0.3495
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 152.9644 s
agent0:                 episode reward: -0.6695,                 loss: nan
agent1:                 episode reward: 0.6695,                 loss: 0.3427
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 153.5613 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.3402
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 154.1640 s
agent0:                 episode reward: -0.5549,                 loss: nan
agent1:                 episode reward: 0.5549,                 loss: 0.3399
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 154.7576 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.3395
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 155.3616 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.3409
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 155.9604 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.3395
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 156.5569 s
agent0:                 episode reward: -0.8425,                 loss: nan
agent1:                 episode reward: 0.8425,                 loss: 0.3394
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 157.1554 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.3373
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 157.7519 s
agent0:                 episode reward: -0.4433,                 loss: nan
agent1:                 episode reward: 0.4433,                 loss: 0.3401
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 158.3612 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.3397
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 158.9570 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.3367
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 159.5532 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.3385
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 160.1573 s
agent0:                 episode reward: -0.5674,                 loss: nan
agent1:                 episode reward: 0.5674,                 loss: 0.3392
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 160.7599 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3376