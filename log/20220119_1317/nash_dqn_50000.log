pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fb34a636240>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220118151446/mdp_arbitrary_mdp_nash_dqn/50000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220118151446/mdp_arbitrary_mdp_nash_dqn/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220118151446_exploit_50000/mdp_arbitrary_mdp_nash_dqn. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220118151446_exploit_50000/mdp_arbitrary_mdp_nash_dqn.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0449s / 0.0449 s
agent0:                 episode reward: -0.0173,                 loss: nan
agent1:                 episode reward: 0.0173,                 loss: nan
Episode: 11/30000 (0.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2910s / 0.3359 s
agent0:                 episode reward: -0.0351,                 loss: nan
agent1:                 episode reward: 0.0351,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 0.6101 s
agent0:                 episode reward: -0.1174,                 loss: nan
agent1:                 episode reward: 0.1174,                 loss: nan
Episode: 31/30000 (0.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 0.8969 s
agent0:                 episode reward: 0.1560,                 loss: nan
agent1:                 episode reward: -0.1560,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2806s / 1.1775 s
agent0:                 episode reward: 0.2733,                 loss: nan
agent1:                 episode reward: -0.2733,                 loss: nan
Episode: 51/30000 (0.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 1.4524 s
agent0:                 episode reward: 0.4235,                 loss: nan
agent1:                 episode reward: -0.4235,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2773s / 1.7297 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: nan
Episode: 71/30000 (0.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 2.0088 s
agent0:                 episode reward: -0.7729,                 loss: nan
agent1:                 episode reward: 0.7729,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2769s / 2.2857 s
agent0:                 episode reward: -0.0120,                 loss: nan
agent1:                 episode reward: 0.0120,                 loss: nan
Episode: 91/30000 (0.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 2.5653 s
agent0:                 episode reward: 0.4034,                 loss: nan
agent1:                 episode reward: -0.4034,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 2.8664 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: nan
Episode: 111/30000 (0.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 3.1518 s
agent0:                 episode reward: 0.2924,                 loss: nan
agent1:                 episode reward: -0.2924,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 3.4332 s
agent0:                 episode reward: 0.2552,                 loss: nan
agent1:                 episode reward: -0.2552,                 loss: nan
Episode: 131/30000 (0.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 3.7169 s
agent0:                 episode reward: -0.0565,                 loss: nan
agent1:                 episode reward: 0.0565,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 3.9951 s
agent0:                 episode reward: 0.2494,                 loss: nan
agent1:                 episode reward: -0.2494,                 loss: nan
Episode: 151/30000 (0.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 4.2745 s
agent0:                 episode reward: 0.2090,                 loss: nan
agent1:                 episode reward: -0.2090,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 4.5651 s
agent0:                 episode reward: 0.2045,                 loss: nan
agent1:                 episode reward: -0.2045,                 loss: nan
Episode: 171/30000 (0.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3157s / 4.8808 s
agent0:                 episode reward: 0.1789,                 loss: nan
agent1:                 episode reward: -0.1789,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 5.2044 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: nan
Episode: 191/30000 (0.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 5.4939 s
agent0:                 episode reward: 0.1864,                 loss: nan
agent1:                 episode reward: -0.1864,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 5.7944 s
agent0:                 episode reward: 0.2427,                 loss: nan
agent1:                 episode reward: -0.2427,                 loss: nan
Episode: 211/30000 (0.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 6.0989 s
agent0:                 episode reward: 0.1463,                 loss: nan
agent1:                 episode reward: -0.1463,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3541s / 6.4530 s
agent0:                 episode reward: -0.4058,                 loss: nan
agent1:                 episode reward: 0.4058,                 loss: 0.2135
Episode: 231/30000 (0.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 6.8008 s
agent0:                 episode reward: -0.0047,                 loss: nan
agent1:                 episode reward: 0.0047,                 loss: 0.1952
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3515s / 7.1523 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.1819
Episode: 251/30000 (0.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 7.5066 s
agent0:                 episode reward: 0.4981,                 loss: nan
agent1:                 episode reward: -0.4981,                 loss: 0.1740
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 7.8611 s
agent0:                 episode reward: 0.4646,                 loss: nan
agent1:                 episode reward: -0.4646,                 loss: 0.1709
Episode: 271/30000 (0.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3600s / 8.2212 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: 0.1682
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3561s / 8.5773 s
agent0:                 episode reward: 0.5919,                 loss: nan
agent1:                 episode reward: -0.5919,                 loss: 0.1655
Episode: 291/30000 (0.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3573s / 8.9346 s
agent0:                 episode reward: 0.0023,                 loss: nan
agent1:                 episode reward: -0.0023,                 loss: 0.1641
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3451s / 9.2797 s
agent0:                 episode reward: 0.0095,                 loss: nan
agent1:                 episode reward: -0.0095,                 loss: 0.1634
Episode: 311/30000 (1.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3410s / 9.6207 s
agent0:                 episode reward: 0.3534,                 loss: nan
agent1:                 episode reward: -0.3534,                 loss: 0.1617
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3381s / 9.9589 s
agent0:                 episode reward: -0.2399,                 loss: nan
agent1:                 episode reward: 0.2399,                 loss: 0.1592
Episode: 331/30000 (1.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3407s / 10.2995 s
agent0:                 episode reward: 0.4677,                 loss: nan
agent1:                 episode reward: -0.4677,                 loss: 0.1566
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3459s / 10.6454 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.1579
Episode: 351/30000 (1.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3409s / 10.9863 s
agent0:                 episode reward: -0.0329,                 loss: nan
agent1:                 episode reward: 0.0329,                 loss: 0.1579
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 11.3265 s
agent0:                 episode reward: 0.1246,                 loss: nan
agent1:                 episode reward: -0.1246,                 loss: 0.1573
Episode: 371/30000 (1.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 11.6680 s
agent0:                 episode reward: 0.3912,                 loss: nan
agent1:                 episode reward: -0.3912,                 loss: 0.1582
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3940s / 12.0620 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1582
Episode: 391/30000 (1.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3464s / 12.4083 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.1566
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3423s / 12.7507 s
agent0:                 episode reward: 0.1794,                 loss: nan
agent1:                 episode reward: -0.1794,                 loss: 0.1566
Episode: 411/30000 (1.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 13.1024 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.1556
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3941s / 13.4965 s
agent0:                 episode reward: 0.1413,                 loss: nan
agent1:                 episode reward: -0.1413,                 loss: 0.1532
Episode: 431/30000 (1.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3888s / 13.8853 s
agent0:                 episode reward: 0.2554,                 loss: nan
agent1:                 episode reward: -0.2554,                 loss: 0.1538
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3600s / 14.2453 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.1534
Episode: 451/30000 (1.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 14.6408 s
agent0:                 episode reward: -0.0846,                 loss: nan
agent1:                 episode reward: 0.0846,                 loss: 0.1531
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3718s / 15.0126 s
agent0:                 episode reward: -0.3069,                 loss: nan
agent1:                 episode reward: 0.3069,                 loss: 0.1527
Episode: 471/30000 (1.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3721s / 15.3847 s
agent0:                 episode reward: 0.2763,                 loss: nan
agent1:                 episode reward: -0.2763,                 loss: 0.1514
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 15.7485 s
agent0:                 episode reward: 0.1453,                 loss: nan
agent1:                 episode reward: -0.1453,                 loss: 0.1525
Episode: 491/30000 (1.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3558s / 16.1043 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1525
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 16.4648 s
agent0:                 episode reward: 0.3974,                 loss: nan
agent1:                 episode reward: -0.3974,                 loss: 0.1523
Episode: 511/30000 (1.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3600s / 16.8248 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.1516
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3451s / 17.1699 s
agent0:                 episode reward: 0.3689,                 loss: nan
agent1:                 episode reward: -0.3689,                 loss: 0.1528
Episode: 531/30000 (1.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3467s / 17.5166 s
agent0:                 episode reward: 0.1300,                 loss: nan
agent1:                 episode reward: -0.1300,                 loss: 0.1526
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3419s / 17.8585 s
agent0:                 episode reward: 0.2263,                 loss: nan
agent1:                 episode reward: -0.2263,                 loss: 0.1507
Episode: 551/30000 (1.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3693s / 18.2277 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.1701
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 18.5808 s
agent0:                 episode reward: 0.0179,                 loss: nan
agent1:                 episode reward: -0.0179,                 loss: 0.1740
Episode: 571/30000 (1.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3540s / 18.9347 s
agent0:                 episode reward: -0.3465,                 loss: nan
agent1:                 episode reward: 0.3465,                 loss: 0.1663
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 19.2900 s
agent0:                 episode reward: -0.0981,                 loss: nan
agent1:                 episode reward: 0.0981,                 loss: 0.1646
Episode: 591/30000 (1.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 19.6430 s
agent0:                 episode reward: 0.5231,                 loss: nan
agent1:                 episode reward: -0.5231,                 loss: 0.1636
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 19.9923 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.1648
Episode: 611/30000 (2.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 20.3574 s
agent0:                 episode reward: 0.0803,                 loss: nan
agent1:                 episode reward: -0.0803,                 loss: 0.1656
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 20.7092 s
agent0:                 episode reward: 0.3324,                 loss: nan
agent1:                 episode reward: -0.3324,                 loss: 0.1640
Episode: 631/30000 (2.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3614s / 21.0706 s
agent0:                 episode reward: 0.0126,                 loss: nan
agent1:                 episode reward: -0.0126,                 loss: 0.1661
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3780s / 21.4486 s
agent0:                 episode reward: 0.3509,                 loss: nan
agent1:                 episode reward: -0.3509,                 loss: 0.1651
Episode: 651/30000 (2.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3829s / 21.8315 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.1667
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3639s / 22.1954 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: 0.1660
Episode: 671/30000 (2.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3610s / 22.5564 s
agent0:                 episode reward: 0.1567,                 loss: nan
agent1:                 episode reward: -0.1567,                 loss: 0.1638
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3574s / 22.9138 s
agent0:                 episode reward: 0.1668,                 loss: nan
agent1:                 episode reward: -0.1668,                 loss: 0.1618
Episode: 691/30000 (2.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3613s / 23.2750 s
agent0:                 episode reward: 0.1562,                 loss: nan
agent1:                 episode reward: -0.1562,                 loss: 0.1620
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3579s / 23.6329 s
agent0:                 episode reward: 0.2698,                 loss: nan
agent1:                 episode reward: -0.2698,                 loss: 0.1637
Episode: 711/30000 (2.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 23.9901 s
agent0:                 episode reward: -0.0689,                 loss: nan
agent1:                 episode reward: 0.0689,                 loss: 0.1613
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3731s / 24.3632 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.1653
Episode: 731/30000 (2.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3471s / 24.7103 s
agent0:                 episode reward: -0.3153,                 loss: nan
agent1:                 episode reward: 0.3153,                 loss: 0.1636
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 25.0499 s
agent0:                 episode reward: -0.3023,                 loss: nan
agent1:                 episode reward: 0.3023,                 loss: 0.1628
Episode: 751/30000 (2.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 25.4043 s
agent0:                 episode reward: -0.2726,                 loss: nan
agent1:                 episode reward: 0.2726,                 loss: 0.1644
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3729s / 25.7772 s
agent0:                 episode reward: 0.1776,                 loss: nan
agent1:                 episode reward: -0.1776,                 loss: 0.1647
Episode: 771/30000 (2.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3608s / 26.1379 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1651
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 26.5001 s
agent0:                 episode reward: 0.2273,                 loss: nan
agent1:                 episode reward: -0.2273,                 loss: 0.1645
Episode: 791/30000 (2.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3551s / 26.8552 s
agent0:                 episode reward: -0.0156,                 loss: nan
agent1:                 episode reward: 0.0156,                 loss: 0.1672
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3742s / 27.2294 s
agent0:                 episode reward: 0.4464,                 loss: nan
agent1:                 episode reward: -0.4464,                 loss: 0.1665
Episode: 811/30000 (2.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3934s / 27.6229 s
agent0:                 episode reward: 0.0922,                 loss: nan
agent1:                 episode reward: -0.0922,                 loss: 0.1635
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3527s / 27.9756 s
agent0:                 episode reward: -0.8454,                 loss: nan
agent1:                 episode reward: 0.8454,                 loss: 0.1649
Episode: 831/30000 (2.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3564s / 28.3319 s
agent0:                 episode reward: -0.0488,                 loss: nan
agent1:                 episode reward: 0.0488,                 loss: 0.1646
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 28.6829 s
agent0:                 episode reward: 0.2113,                 loss: nan
agent1:                 episode reward: -0.2113,                 loss: 0.1659
Episode: 851/30000 (2.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 29.0449 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: 0.1633
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3657s / 29.4106 s
agent0:                 episode reward: -0.5953,                 loss: nan
agent1:                 episode reward: 0.5953,                 loss: 0.1651
Episode: 871/30000 (2.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3697s / 29.7803 s
agent0:                 episode reward: 0.3347,                 loss: nan
agent1:                 episode reward: -0.3347,                 loss: 0.1646
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3854s / 30.1656 s
agent0:                 episode reward: -0.1396,                 loss: nan
agent1:                 episode reward: 0.1396,                 loss: 0.1646
Episode: 891/30000 (2.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3811s / 30.5467 s
agent0:                 episode reward: 0.7593,                 loss: nan
agent1:                 episode reward: -0.7593,                 loss: 0.1652
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 30.9090 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.1649
Episode: 911/30000 (3.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3562s / 31.2652 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.1623
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3499s / 31.6151 s
agent0:                 episode reward: 0.3213,                 loss: nan
agent1:                 episode reward: -0.3213,                 loss: 0.1641
Episode: 931/30000 (3.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 31.9619 s
agent0:                 episode reward: 0.3244,                 loss: nan
agent1:                 episode reward: -0.3244,                 loss: 0.1619
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3554s / 32.3173 s
agent0:                 episode reward: -0.3381,                 loss: nan
agent1:                 episode reward: 0.3381,                 loss: 0.1637
Episode: 951/30000 (3.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3591s / 32.6765 s
agent0:                 episode reward: 0.1010,                 loss: nan
agent1:                 episode reward: -0.1010,                 loss: 0.1632
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3569s / 33.0334 s
agent0:                 episode reward: -0.1291,                 loss: nan
agent1:                 episode reward: 0.1291,                 loss: 0.1631
Episode: 971/30000 (3.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3697s / 33.4031 s
agent0:                 episode reward: 0.3428,                 loss: nan
agent1:                 episode reward: -0.3428,                 loss: 0.1614
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3571s / 33.7603 s
agent0:                 episode reward: -0.0290,                 loss: nan
agent1:                 episode reward: 0.0290,                 loss: 0.1609
Episode: 991/30000 (3.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3506s / 34.1109 s
agent0:                 episode reward: 0.5602,                 loss: nan
agent1:                 episode reward: -0.5602,                 loss: 0.1627
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3449s / 34.4558 s
agent0:                 episode reward: -0.1967,                 loss: nan
agent1:                 episode reward: 0.1967,                 loss: 0.1626
Episode: 1011/30000 (3.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 34.8049 s
agent0:                 episode reward: -0.0804,                 loss: nan
agent1:                 episode reward: 0.0804,                 loss: 0.1627
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 35.1470 s
agent0:                 episode reward: -0.0983,                 loss: nan
agent1:                 episode reward: 0.0983,                 loss: 0.1634
Episode: 1031/30000 (3.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 35.5076 s
agent0:                 episode reward: 0.3449,                 loss: nan
agent1:                 episode reward: -0.3449,                 loss: 0.1616
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3584s / 35.8660 s
agent0:                 episode reward: -0.3451,                 loss: nan
agent1:                 episode reward: 0.3451,                 loss: 0.1623
Episode: 1051/30000 (3.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3579s / 36.2239 s
agent0:                 episode reward: 0.4015,                 loss: nan
agent1:                 episode reward: -0.4015,                 loss: 0.1616
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4068s / 36.6307 s
agent0:                 episode reward: -0.0120,                 loss: nan
agent1:                 episode reward: 0.0120,                 loss: 0.1619
Episode: 1071/30000 (3.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 36.9851 s
agent0:                 episode reward: -0.0353,                 loss: nan
agent1:                 episode reward: 0.0353,                 loss: 0.1600
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3507s / 37.3358 s
agent0:                 episode reward: -0.4160,                 loss: nan
agent1:                 episode reward: 0.4160,                 loss: 0.1618
Episode: 1091/30000 (3.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3686s / 37.7044 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.1605
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3633s / 38.0677 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: 0.1612
Episode: 1111/30000 (3.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3900s / 38.4577 s
agent0:                 episode reward: -0.1352,                 loss: nan
agent1:                 episode reward: 0.1352,                 loss: 0.1605
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 38.8227 s
agent0:                 episode reward: 0.4554,                 loss: nan
agent1:                 episode reward: -0.4554,                 loss: 0.1612
Episode: 1131/30000 (3.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3515s / 39.1742 s
agent0:                 episode reward: -0.0203,                 loss: nan
agent1:                 episode reward: 0.0203,                 loss: 0.1597
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3561s / 39.5303 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.1625
Episode: 1151/30000 (3.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 39.8821 s
agent0:                 episode reward: 0.4079,                 loss: nan
agent1:                 episode reward: -0.4079,                 loss: 0.1597
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 40.2251 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1619
Episode: 1171/30000 (3.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3443s / 40.5694 s
agent0:                 episode reward: 0.4145,                 loss: nan
agent1:                 episode reward: -0.4145,                 loss: 0.1623
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3523s / 40.9218 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1634
Episode: 1191/30000 (3.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 41.2709 s
agent0:                 episode reward: -0.3020,                 loss: nan
agent1:                 episode reward: 0.3020,                 loss: 0.1641
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 41.6183 s
agent0:                 episode reward: -0.1334,                 loss: nan
agent1:                 episode reward: 0.1334,                 loss: 0.1611
Episode: 1211/30000 (4.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3448s / 41.9631 s
agent0:                 episode reward: 0.0107,                 loss: nan
agent1:                 episode reward: -0.0107,                 loss: 0.1602
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 42.3176 s
agent0:                 episode reward: 0.2620,                 loss: nan
agent1:                 episode reward: -0.2620,                 loss: 0.1588
Episode: 1231/30000 (4.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3918s / 42.7094 s
agent0:                 episode reward: -0.0184,                 loss: nan
agent1:                 episode reward: 0.0184,                 loss: 0.1589
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3713s / 43.0807 s
agent0:                 episode reward: 0.2481,                 loss: nan
agent1:                 episode reward: -0.2481,                 loss: 0.1543
Episode: 1251/30000 (4.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3583s / 43.4390 s
agent0:                 episode reward: -0.5774,                 loss: nan
agent1:                 episode reward: 0.5774,                 loss: 0.1576
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3558s / 43.7948 s
agent0:                 episode reward: -0.0483,                 loss: nan
agent1:                 episode reward: 0.0483,                 loss: 0.1573
Episode: 1271/30000 (4.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3582s / 44.1530 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: 0.1572
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3566s / 44.5096 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1555
Episode: 1291/30000 (4.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3532s / 44.8628 s
agent0:                 episode reward: -0.6545,                 loss: nan
agent1:                 episode reward: 0.6545,                 loss: 0.1573
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3587s / 45.2215 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.1550
Episode: 1311/30000 (4.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3839s / 45.6054 s
agent0:                 episode reward: 0.2194,                 loss: nan
agent1:                 episode reward: -0.2194,                 loss: 0.1546
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3822s / 45.9875 s
agent0:                 episode reward: 0.0820,                 loss: nan
agent1:                 episode reward: -0.0820,                 loss: 0.1569
Episode: 1331/30000 (4.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3649s / 46.3524 s
agent0:                 episode reward: 0.2520,                 loss: nan
agent1:                 episode reward: -0.2520,                 loss: 0.1566
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 46.7347 s
agent0:                 episode reward: 0.3294,                 loss: nan
agent1:                 episode reward: -0.3294,                 loss: 0.1579
Episode: 1351/30000 (4.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3585s / 47.0932 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.1567
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3611s / 47.4543 s
agent0:                 episode reward: 0.1314,                 loss: nan
agent1:                 episode reward: -0.1314,                 loss: 0.1582
Episode: 1371/30000 (4.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 47.8011 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.1574
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3495s / 48.1506 s
agent0:                 episode reward: -0.1015,                 loss: nan
agent1:                 episode reward: 0.1015,                 loss: 0.1576
Episode: 1391/30000 (4.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3594s / 48.5099 s
agent0:                 episode reward: 0.4528,                 loss: nan
agent1:                 episode reward: -0.4528,                 loss: 0.1541
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 48.8952 s
agent0:                 episode reward: 0.0176,                 loss: nan
agent1:                 episode reward: -0.0176,                 loss: 0.1568
Episode: 1411/30000 (4.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3666s / 49.2618 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.1579
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 49.6258 s
agent0:                 episode reward: 0.0659,                 loss: nan
agent1:                 episode reward: -0.0659,                 loss: 0.1573
Episode: 1431/30000 (4.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 49.9898 s
agent0:                 episode reward: 0.1623,                 loss: nan
agent1:                 episode reward: -0.1623,                 loss: 0.1583
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3456s / 50.3354 s
agent0:                 episode reward: -0.1921,                 loss: nan
agent1:                 episode reward: 0.1921,                 loss: 0.1553
Episode: 1451/30000 (4.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3548s / 50.6902 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1561
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 51.0411 s
agent0:                 episode reward: 0.0949,                 loss: nan
agent1:                 episode reward: -0.0949,                 loss: 0.1558
Episode: 1471/30000 (4.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3540s / 51.3951 s
agent0:                 episode reward: -0.0404,                 loss: nan
agent1:                 episode reward: 0.0404,                 loss: 0.1578
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3741s / 51.7692 s
agent0:                 episode reward: 0.2074,                 loss: nan
agent1:                 episode reward: -0.2074,                 loss: 0.1564
Episode: 1491/30000 (4.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3731s / 52.1423 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1575
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3639s / 52.5062 s
agent0:                 episode reward: 0.1658,                 loss: nan
agent1:                 episode reward: -0.1658,                 loss: 0.1544
Episode: 1511/30000 (5.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3636s / 52.8698 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.1578
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3626s / 53.2324 s
agent0:                 episode reward: 0.1574,                 loss: nan
agent1:                 episode reward: -0.1574,                 loss: 0.1573
Episode: 1531/30000 (5.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3617s / 53.5941 s
agent0:                 episode reward: 0.2626,                 loss: nan
agent1:                 episode reward: -0.2626,                 loss: 0.1555
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3629s / 53.9570 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: 0.1571
Episode: 1551/30000 (5.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3626s / 54.3196 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.1547
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3501s / 54.6696 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.1603
Episode: 1571/30000 (5.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3894s / 55.0591 s
agent0:                 episode reward: -0.6280,                 loss: nan
agent1:                 episode reward: 0.6280,                 loss: 0.1564
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3499s / 55.4089 s
agent0:                 episode reward: -0.1880,                 loss: nan
agent1:                 episode reward: 0.1880,                 loss: 0.1585
Episode: 1591/30000 (5.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3498s / 55.7587 s
agent0:                 episode reward: 0.3989,                 loss: nan
agent1:                 episode reward: -0.3989,                 loss: 0.1586
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 56.1104 s
agent0:                 episode reward: 0.2188,                 loss: nan
agent1:                 episode reward: -0.2188,                 loss: 0.1579
Episode: 1611/30000 (5.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 56.4726 s
agent0:                 episode reward: -0.0856,                 loss: nan
agent1:                 episode reward: 0.0856,                 loss: 0.1579
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3648s / 56.8374 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.1584
Episode: 1631/30000 (5.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3639s / 57.2013 s
agent0:                 episode reward: 0.5010,                 loss: nan
agent1:                 episode reward: -0.5010,                 loss: 0.1584
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3558s / 57.5571 s
agent0:                 episode reward: 0.0350,                 loss: nan
agent1:                 episode reward: -0.0350,                 loss: 0.1593
Episode: 1651/30000 (5.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3868s / 57.9439 s
agent0:                 episode reward: 0.1285,                 loss: nan
agent1:                 episode reward: -0.1285,                 loss: 0.1587
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3644s / 58.3083 s
agent0:                 episode reward: -0.3147,                 loss: nan
agent1:                 episode reward: 0.3147,                 loss: 0.1576
Episode: 1671/30000 (5.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3682s / 58.6765 s
agent0:                 episode reward: -0.3023,                 loss: nan
agent1:                 episode reward: 0.3023,                 loss: 0.1579
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 59.0500 s
agent0:                 episode reward: -0.1635,                 loss: nan
agent1:                 episode reward: 0.1635,                 loss: 0.1574
Episode: 1691/30000 (5.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3760s / 59.4260 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1578
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 59.7900 s
agent0:                 episode reward: -0.3989,                 loss: nan
agent1:                 episode reward: 0.3989,                 loss: 0.1574
Episode: 1711/30000 (5.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3740s / 60.1640 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: 0.1596
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3642s / 60.5282 s
agent0:                 episode reward: -0.0945,                 loss: nan
agent1:                 episode reward: 0.0945,                 loss: 0.1590
Episode: 1731/30000 (5.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3817s / 60.9099 s
agent0:                 episode reward: -0.2772,                 loss: nan
agent1:                 episode reward: 0.2772,                 loss: 0.1603
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4052s / 61.3151 s
agent0:                 episode reward: -0.5335,                 loss: nan
agent1:                 episode reward: 0.5335,                 loss: 0.1565
Episode: 1751/30000 (5.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3646s / 61.6797 s
agent0:                 episode reward: 0.5762,                 loss: nan
agent1:                 episode reward: -0.5762,                 loss: 0.1598
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3664s / 62.0461 s
agent0:                 episode reward: 0.2761,                 loss: nan
agent1:                 episode reward: -0.2761,                 loss: 0.1606
Episode: 1771/30000 (5.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 62.4084 s
agent0:                 episode reward: 0.2357,                 loss: nan
agent1:                 episode reward: -0.2357,                 loss: 0.1599
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3721s / 62.7805 s
agent0:                 episode reward: 0.1566,                 loss: nan
agent1:                 episode reward: -0.1566,                 loss: 0.1557
Episode: 1791/30000 (5.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3754s / 63.1559 s
agent0:                 episode reward: 0.3034,                 loss: nan
agent1:                 episode reward: -0.3034,                 loss: 0.1593
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3886s / 63.5445 s
agent0:                 episode reward: -0.8612,                 loss: nan
agent1:                 episode reward: 0.8612,                 loss: 0.1576
Episode: 1811/30000 (6.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 63.9220 s
agent0:                 episode reward: 0.4255,                 loss: nan
agent1:                 episode reward: -0.4255,                 loss: 0.1586
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3925s / 64.3146 s
agent0:                 episode reward: 0.0358,                 loss: nan
agent1:                 episode reward: -0.0358,                 loss: 0.1562
Episode: 1831/30000 (6.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3691s / 64.6837 s
agent0:                 episode reward: -0.5327,                 loss: nan
agent1:                 episode reward: 0.5327,                 loss: 0.1568
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3668s / 65.0505 s
agent0:                 episode reward: 0.1897,                 loss: nan
agent1:                 episode reward: -0.1897,                 loss: 0.1567
Episode: 1851/30000 (6.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3647s / 65.4152 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.1577
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3694s / 65.7846 s
agent0:                 episode reward: 0.1179,                 loss: nan
agent1:                 episode reward: -0.1179,                 loss: 0.1566
Episode: 1871/30000 (6.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3628s / 66.1474 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.1547
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3634s / 66.5108 s
agent0:                 episode reward: 0.3173,                 loss: nan
agent1:                 episode reward: -0.3173,                 loss: 0.1581
Episode: 1891/30000 (6.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3654s / 66.8763 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.1629
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3864s / 67.2627 s
agent0:                 episode reward: 0.2539,                 loss: nan
agent1:                 episode reward: -0.2539,                 loss: 0.1630
Episode: 1911/30000 (6.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3662s / 67.6289 s
agent0:                 episode reward: -0.0984,                 loss: nan
agent1:                 episode reward: 0.0984,                 loss: 0.1637
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3674s / 67.9962 s
agent0:                 episode reward: -0.3412,                 loss: nan
agent1:                 episode reward: 0.3412,                 loss: 0.1620
Episode: 1931/30000 (6.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 68.3600 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.1618
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3636s / 68.7236 s
agent0:                 episode reward: -0.6234,                 loss: nan
agent1:                 episode reward: 0.6234,                 loss: 0.1618
Episode: 1951/30000 (6.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3663s / 69.0899 s
agent0:                 episode reward: 0.1554,                 loss: nan
agent1:                 episode reward: -0.1554,                 loss: 0.1604
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3656s / 69.4555 s
agent0:                 episode reward: -0.0742,                 loss: nan
agent1:                 episode reward: 0.0742,                 loss: 0.1632
Episode: 1971/30000 (6.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3641s / 69.8196 s
agent0:                 episode reward: 0.3225,                 loss: nan
agent1:                 episode reward: -0.3225,                 loss: 0.1616
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3762s / 70.1959 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.1615
Episode: 1991/30000 (6.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3723s / 70.5682 s
agent0:                 episode reward: 0.1542,                 loss: nan
agent1:                 episode reward: -0.1542,                 loss: 0.1627
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3654s / 70.9336 s
agent0:                 episode reward: 0.3702,                 loss: nan
agent1:                 episode reward: -0.3702,                 loss: 0.1634
Episode: 2011/30000 (6.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3668s / 71.3004 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.1628
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 71.6798 s
agent0:                 episode reward: 0.0173,                 loss: nan
agent1:                 episode reward: -0.0173,                 loss: 0.1616
Episode: 2031/30000 (6.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3733s / 72.0530 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1619
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 72.4137 s
agent0:                 episode reward: -0.0060,                 loss: nan
agent1:                 episode reward: 0.0060,                 loss: 0.1649
Episode: 2051/30000 (6.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3658s / 72.7795 s
agent0:                 episode reward: 0.0466,                 loss: nan
agent1:                 episode reward: -0.0466,                 loss: 0.1609
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3732s / 73.1527 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.1620
Episode: 2071/30000 (6.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 73.5251 s
agent0:                 episode reward: -0.0126,                 loss: nan
agent1:                 episode reward: 0.0126,                 loss: 0.1633
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3636s / 73.8887 s
agent0:                 episode reward: -0.2953,                 loss: nan
agent1:                 episode reward: 0.2953,                 loss: 0.1632
Episode: 2091/30000 (6.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3630s / 74.2517 s
agent0:                 episode reward: 0.1132,                 loss: nan
agent1:                 episode reward: -0.1132,                 loss: 0.1634
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3587s / 74.6103 s
agent0:                 episode reward: -0.8598,                 loss: nan
agent1:                 episode reward: 0.8598,                 loss: 0.1627
Episode: 2111/30000 (7.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3674s / 74.9777 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.1620
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3673s / 75.3450 s
agent0:                 episode reward: -0.3098,                 loss: nan
agent1:                 episode reward: 0.3098,                 loss: 0.1630
Episode: 2131/30000 (7.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3726s / 75.7176 s
agent0:                 episode reward: 0.5344,                 loss: nan
agent1:                 episode reward: -0.5344,                 loss: 0.1620
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3628s / 76.0804 s
agent0:                 episode reward: 0.3341,                 loss: nan
agent1:                 episode reward: -0.3341,                 loss: 0.1624
Episode: 2151/30000 (7.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3770s / 76.4574 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: 0.1631
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3556s / 76.8131 s
agent0:                 episode reward: -0.1007,                 loss: nan
agent1:                 episode reward: 0.1007,                 loss: 0.1642
Episode: 2171/30000 (7.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3541s / 77.1671 s
agent0:                 episode reward: 0.4574,                 loss: nan
agent1:                 episode reward: -0.4574,                 loss: 0.1634
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3505s / 77.5177 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.1608
Episode: 2191/30000 (7.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 77.8797 s
agent0:                 episode reward: 0.0392,                 loss: nan
agent1:                 episode reward: -0.0392,                 loss: 0.1627
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3626s / 78.2422 s
agent0:                 episode reward: 0.2461,                 loss: nan
agent1:                 episode reward: -0.2461,                 loss: 0.1631
Episode: 2211/30000 (7.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3791s / 78.6214 s
agent0:                 episode reward: 0.0963,                 loss: nan
agent1:                 episode reward: -0.0963,                 loss: 0.1626
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3810s / 79.0024 s
agent0:                 episode reward: -0.1064,                 loss: nan
agent1:                 episode reward: 0.1064,                 loss: 0.1591
Episode: 2231/30000 (7.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3908s / 79.3932 s
agent0:                 episode reward: 0.1805,                 loss: nan
agent1:                 episode reward: -0.1805,                 loss: 0.1594
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3851s / 79.7783 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.1601
Episode: 2251/30000 (7.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4116s / 80.1899 s
agent0:                 episode reward: -0.5071,                 loss: nan
agent1:                 episode reward: 0.5071,                 loss: 0.1571
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 80.5760 s
agent0:                 episode reward: 0.1061,                 loss: nan
agent1:                 episode reward: -0.1061,                 loss: 0.1583
Episode: 2271/30000 (7.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3869s / 80.9629 s
agent0:                 episode reward: -0.4754,                 loss: nan
agent1:                 episode reward: 0.4754,                 loss: 0.1584
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 81.3423 s
agent0:                 episode reward: 0.3241,                 loss: nan
agent1:                 episode reward: -0.3241,                 loss: 0.1595
Episode: 2291/30000 (7.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3792s / 81.7214 s
agent0:                 episode reward: 0.5012,                 loss: nan
agent1:                 episode reward: -0.5012,                 loss: 0.1597
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4033s / 82.1248 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1590
Episode: 2311/30000 (7.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3950s / 82.5198 s
agent0:                 episode reward: 0.2463,                 loss: nan
agent1:                 episode reward: -0.2463,                 loss: 0.1565
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3721s / 82.8919 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.1587
Episode: 2331/30000 (7.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 83.2646 s
agent0:                 episode reward: -0.5901,                 loss: nan
agent1:                 episode reward: 0.5901,                 loss: 0.1596
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 83.6372 s
agent0:                 episode reward: -0.3143,                 loss: nan
agent1:                 episode reward: 0.3143,                 loss: 0.1576
Episode: 2351/30000 (7.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3696s / 84.0068 s
agent0:                 episode reward: -0.0402,                 loss: nan
agent1:                 episode reward: 0.0402,                 loss: 0.1589
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3592s / 84.3660 s
agent0:                 episode reward: -0.0157,                 loss: nan
agent1:                 episode reward: 0.0157,                 loss: 0.1596
Episode: 2371/30000 (7.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 84.7205 s
agent0:                 episode reward: -0.2501,                 loss: nan
agent1:                 episode reward: 0.2501,                 loss: 0.1581
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3661s / 85.0866 s
agent0:                 episode reward: -0.1102,                 loss: nan
agent1:                 episode reward: 0.1102,                 loss: 0.1600
Episode: 2391/30000 (7.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3659s / 85.4525 s
agent0:                 episode reward: 0.0670,                 loss: nan
agent1:                 episode reward: -0.0670,                 loss: 0.1593
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3583s / 85.8108 s
agent0:                 episode reward: -0.4133,                 loss: nan
agent1:                 episode reward: 0.4133,                 loss: 0.1575
Episode: 2411/30000 (8.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3568s / 86.1676 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.1575
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3522s / 86.5198 s
agent0:                 episode reward: -0.1612,                 loss: nan
agent1:                 episode reward: 0.1612,                 loss: 0.1589
Episode: 2431/30000 (8.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3644s / 86.8842 s
agent0:                 episode reward: -0.1160,                 loss: nan
agent1:                 episode reward: 0.1160,                 loss: 0.1595
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3673s / 87.2515 s
agent0:                 episode reward: -0.0575,                 loss: nan
agent1:                 episode reward: 0.0575,                 loss: 0.1571
Episode: 2451/30000 (8.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3675s / 87.6190 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.1599
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3675s / 87.9865 s
agent0:                 episode reward: 0.4988,                 loss: nan
agent1:                 episode reward: -0.4988,                 loss: 0.1582
Episode: 2471/30000 (8.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4094s / 88.3960 s
agent0:                 episode reward: 0.2505,                 loss: nan
agent1:                 episode reward: -0.2505,                 loss: 0.1598
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3619s / 88.7578 s
agent0:                 episode reward: -0.7563,                 loss: nan
agent1:                 episode reward: 0.7563,                 loss: 0.1606
Episode: 2491/30000 (8.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3729s / 89.1308 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.1588
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3633s / 89.4940 s
agent0:                 episode reward: -0.6848,                 loss: nan
agent1:                 episode reward: 0.6848,                 loss: 0.1594
Episode: 2511/30000 (8.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3600s / 89.8540 s
agent0:                 episode reward: -0.0141,                 loss: nan
agent1:                 episode reward: 0.0141,                 loss: 0.1584
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 90.2191 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.1579
Episode: 2531/30000 (8.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3771s / 90.5962 s
agent0:                 episode reward: -0.0966,                 loss: nan
agent1:                 episode reward: 0.0966,                 loss: 0.1559
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 90.9756 s
agent0:                 episode reward: 0.3296,                 loss: nan
agent1:                 episode reward: -0.3296,                 loss: 0.1589
Episode: 2551/30000 (8.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3870s / 91.3626 s
agent0:                 episode reward: 0.0201,                 loss: nan
agent1:                 episode reward: -0.0201,                 loss: 0.1568
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3630s / 91.7256 s
agent0:                 episode reward: 0.0847,                 loss: nan
agent1:                 episode reward: -0.0847,                 loss: 0.1573
Episode: 2571/30000 (8.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3859s / 92.1115 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.1568
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3575s / 92.4690 s
agent0:                 episode reward: 0.0830,                 loss: nan
agent1:                 episode reward: -0.0830,                 loss: 0.1549
Episode: 2591/30000 (8.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3610s / 92.8300 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: 0.1563
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3542s / 93.1842 s
agent0:                 episode reward: 0.1059,                 loss: nan
agent1:                 episode reward: -0.1059,                 loss: 0.1574
Episode: 2611/30000 (8.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3528s / 93.5370 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: 0.1553
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3551s / 93.8921 s
agent0:                 episode reward: 0.0564,                 loss: nan
agent1:                 episode reward: -0.0564,                 loss: 0.1574
Episode: 2631/30000 (8.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3679s / 94.2600 s
agent0:                 episode reward: 0.8595,                 loss: nan
agent1:                 episode reward: -0.8595,                 loss: 0.1556
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 94.6194 s
agent0:                 episode reward: 0.6166,                 loss: nan
agent1:                 episode reward: -0.6166,                 loss: 0.1576
Episode: 2651/30000 (8.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3554s / 94.9749 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: 0.1568
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3582s / 95.3331 s
agent0:                 episode reward: 0.2024,                 loss: nan
agent1:                 episode reward: -0.2024,                 loss: 0.1569
Episode: 2671/30000 (8.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3705s / 95.7036 s
agent0:                 episode reward: 0.2316,                 loss: nan
agent1:                 episode reward: -0.2316,                 loss: 0.1572
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3700s / 96.0736 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1564
Episode: 2691/30000 (8.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3704s / 96.4440 s
agent0:                 episode reward: 0.5018,                 loss: nan
agent1:                 episode reward: -0.5018,                 loss: 0.1553
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3847s / 96.8287 s
agent0:                 episode reward: -0.4400,                 loss: nan
agent1:                 episode reward: 0.4400,                 loss: 0.1539
Episode: 2711/30000 (9.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3676s / 97.1963 s
agent0:                 episode reward: 0.0574,                 loss: nan
agent1:                 episode reward: -0.0574,                 loss: 0.1533
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3829s / 97.5792 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.1542
Episode: 2731/30000 (9.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3653s / 97.9444 s
agent0:                 episode reward: 0.1519,                 loss: nan
agent1:                 episode reward: -0.1519,                 loss: 0.1551
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3717s / 98.3161 s
agent0:                 episode reward: 0.0505,                 loss: nan
agent1:                 episode reward: -0.0505,                 loss: 0.1554
Episode: 2751/30000 (9.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3657s / 98.6818 s
agent0:                 episode reward: -0.1276,                 loss: nan
agent1:                 episode reward: 0.1276,                 loss: 0.1562
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3799s / 99.0617 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.1556
Episode: 2771/30000 (9.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4043s / 99.4660 s
agent0:                 episode reward: 0.0189,                 loss: nan
agent1:                 episode reward: -0.0189,                 loss: 0.1561
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3898s / 99.8558 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.1542
Episode: 2791/30000 (9.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3672s / 100.2230 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.1575
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3864s / 100.6093 s
agent0:                 episode reward: 0.0774,                 loss: nan
agent1:                 episode reward: -0.0774,                 loss: 0.1555
Episode: 2811/30000 (9.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3637s / 100.9731 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.1557
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3569s / 101.3299 s
agent0:                 episode reward: -0.2950,                 loss: nan
agent1:                 episode reward: 0.2950,                 loss: 0.1539
Episode: 2831/30000 (9.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3865s / 101.7165 s
agent0:                 episode reward: 0.0307,                 loss: nan
agent1:                 episode reward: -0.0307,                 loss: 0.1559
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3875s / 102.1040 s
agent0:                 episode reward: -0.1114,                 loss: nan
agent1:                 episode reward: 0.1114,                 loss: 0.1555
Episode: 2851/30000 (9.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3879s / 102.4919 s
agent0:                 episode reward: 0.0729,                 loss: nan
agent1:                 episode reward: -0.0729,                 loss: 0.1541
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3843s / 102.8762 s
agent0:                 episode reward: 0.4515,                 loss: nan
agent1:                 episode reward: -0.4515,                 loss: 0.1552
Episode: 2871/30000 (9.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3834s / 103.2596 s
agent0:                 episode reward: -0.2151,                 loss: nan
agent1:                 episode reward: 0.2151,                 loss: 0.1543
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 103.6808 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: 0.1570
Episode: 2891/30000 (9.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3850s / 104.0657 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: 0.1569
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3873s / 104.4531 s
agent0:                 episode reward: 0.2589,                 loss: nan
agent1:                 episode reward: -0.2589,                 loss: 0.1573
Episode: 2911/30000 (9.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3753s / 104.8283 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: 0.1573
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3996s / 105.2279 s
agent0:                 episode reward: -0.0857,                 loss: nan
agent1:                 episode reward: 0.0857,                 loss: 0.1552
Episode: 2931/30000 (9.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3720s / 105.5999 s
agent0:                 episode reward: 0.5971,                 loss: nan
agent1:                 episode reward: -0.5971,                 loss: 0.1537
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3624s / 105.9622 s
agent0:                 episode reward: -0.4021,                 loss: nan
agent1:                 episode reward: 0.4021,                 loss: 0.1553
Episode: 2951/30000 (9.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3590s / 106.3212 s
agent0:                 episode reward: -0.1657,                 loss: nan
agent1:                 episode reward: 0.1657,                 loss: 0.1534
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 106.7035 s
agent0:                 episode reward: -0.0042,                 loss: nan
agent1:                 episode reward: 0.0042,                 loss: 0.1553
Episode: 2971/30000 (9.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3613s / 107.0649 s
agent0:                 episode reward: -0.3919,                 loss: nan
agent1:                 episode reward: 0.3919,                 loss: 0.1552
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3587s / 107.4236 s
agent0:                 episode reward: 0.5118,                 loss: nan
agent1:                 episode reward: -0.5118,                 loss: 0.1551
Episode: 2991/30000 (9.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3655s / 107.7890 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.1551
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3621s / 108.1512 s
agent0:                 episode reward: 0.4208,                 loss: nan
agent1:                 episode reward: -0.4208,                 loss: 0.1553
Episode: 3011/30000 (10.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 108.5118 s
agent0:                 episode reward: -0.8851,                 loss: nan
agent1:                 episode reward: 0.8851,                 loss: 0.1526
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3593s / 108.8711 s
agent0:                 episode reward: -0.2221,                 loss: nan
agent1:                 episode reward: 0.2221,                 loss: 0.1562
Episode: 3031/30000 (10.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3594s / 109.2305 s
agent0:                 episode reward: -0.0399,                 loss: nan
agent1:                 episode reward: 0.0399,                 loss: 0.1528
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 109.6113 s
agent0:                 episode reward: -0.4016,                 loss: nan
agent1:                 episode reward: 0.4016,                 loss: 0.1547
Episode: 3051/30000 (10.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3815s / 109.9928 s
agent0:                 episode reward: -0.4517,                 loss: nan
agent1:                 episode reward: 0.4517,                 loss: 0.1547
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3763s / 110.3691 s
agent0:                 episode reward: 0.0668,                 loss: nan
agent1:                 episode reward: -0.0668,                 loss: 0.1543
Episode: 3071/30000 (10.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3737s / 110.7428 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.1548
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3805s / 111.1233 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.1554
Episode: 3091/30000 (10.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3779s / 111.5012 s
agent0:                 episode reward: -0.1600,                 loss: nan
agent1:                 episode reward: 0.1600,                 loss: 0.1543
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3734s / 111.8747 s
agent0:                 episode reward: -0.1366,                 loss: nan
agent1:                 episode reward: 0.1366,                 loss: 0.1524
Episode: 3111/30000 (10.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3892s / 112.2638 s
agent0:                 episode reward: 0.4166,                 loss: nan
agent1:                 episode reward: -0.4166,                 loss: 0.1524
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4022s / 112.6661 s
agent0:                 episode reward: -0.1350,                 loss: nan
agent1:                 episode reward: 0.1350,                 loss: 0.1574
Episode: 3131/30000 (10.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3853s / 113.0514 s
agent0:                 episode reward: -0.0287,                 loss: nan
agent1:                 episode reward: 0.0287,                 loss: 0.1529
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3982s / 113.4495 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.1550
Episode: 3151/30000 (10.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3696s / 113.8191 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.1542
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 114.1919 s
agent0:                 episode reward: -0.2818,                 loss: nan
agent1:                 episode reward: 0.2818,                 loss: 0.1553
Episode: 3171/30000 (10.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3699s / 114.5617 s
agent0:                 episode reward: 0.0795,                 loss: nan
agent1:                 episode reward: -0.0795,                 loss: 0.1546
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3747s / 114.9364 s
agent0:                 episode reward: 0.2495,                 loss: nan
agent1:                 episode reward: -0.2495,                 loss: 0.1545
Episode: 3191/30000 (10.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3760s / 115.3124 s
agent0:                 episode reward: 0.1587,                 loss: nan
agent1:                 episode reward: -0.1587,                 loss: 0.1558
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3831s / 115.6954 s
agent0:                 episode reward: 0.0359,                 loss: nan
agent1:                 episode reward: -0.0359,                 loss: 0.1551
Episode: 3211/30000 (10.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3862s / 116.0816 s
agent0:                 episode reward: 0.2847,                 loss: nan
agent1:                 episode reward: -0.2847,                 loss: 0.1575
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3741s / 116.4557 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.1577
Episode: 3231/30000 (10.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3732s / 116.8289 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.1562
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3744s / 117.2034 s
agent0:                 episode reward: 0.2868,                 loss: nan
agent1:                 episode reward: -0.2868,                 loss: 0.1577
Episode: 3251/30000 (10.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3734s / 117.5767 s
agent0:                 episode reward: -0.4813,                 loss: nan
agent1:                 episode reward: 0.4813,                 loss: 0.1593
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3742s / 117.9509 s
agent0:                 episode reward: -0.1102,                 loss: nan
agent1:                 episode reward: 0.1102,                 loss: 0.1591
Episode: 3271/30000 (10.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3790s / 118.3299 s
agent0:                 episode reward: 0.2655,                 loss: nan
agent1:                 episode reward: -0.2655,                 loss: 0.1599
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3801s / 118.7101 s
agent0:                 episode reward: 0.2060,                 loss: nan
agent1:                 episode reward: -0.2060,                 loss: 0.1596
Episode: 3291/30000 (10.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4008s / 119.1109 s
agent0:                 episode reward: -0.7319,                 loss: nan
agent1:                 episode reward: 0.7319,                 loss: 0.1568
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3753s / 119.4862 s
agent0:                 episode reward: 0.0790,                 loss: nan
agent1:                 episode reward: -0.0790,                 loss: 0.1589
Episode: 3311/30000 (11.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3743s / 119.8605 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.1567
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3772s / 120.2377 s
agent0:                 episode reward: -0.1121,                 loss: nan
agent1:                 episode reward: 0.1121,                 loss: 0.1589
Episode: 3331/30000 (11.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3684s / 120.6061 s
agent0:                 episode reward: -0.3179,                 loss: nan
agent1:                 episode reward: 0.3179,                 loss: 0.1607
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3736s / 120.9797 s
agent0:                 episode reward: 0.2843,                 loss: nan
agent1:                 episode reward: -0.2843,                 loss: 0.1601
Episode: 3351/30000 (11.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3698s / 121.3495 s
agent0:                 episode reward: -0.2675,                 loss: nan
agent1:                 episode reward: 0.2675,                 loss: 0.1602
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4020s / 121.7515 s
agent0:                 episode reward: -0.0461,                 loss: nan
agent1:                 episode reward: 0.0461,                 loss: 0.1595
Episode: 3371/30000 (11.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3907s / 122.1422 s
agent0:                 episode reward: 0.4084,                 loss: nan
agent1:                 episode reward: -0.4084,                 loss: 0.1593
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3618s / 122.5040 s
agent0:                 episode reward: -0.9248,                 loss: nan
agent1:                 episode reward: 0.9248,                 loss: 0.1568
Episode: 3391/30000 (11.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3672s / 122.8711 s
agent0:                 episode reward: 0.1651,                 loss: nan
agent1:                 episode reward: -0.1651,                 loss: 0.1586
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3687s / 123.2399 s
agent0:                 episode reward: -0.1011,                 loss: nan
agent1:                 episode reward: 0.1011,                 loss: 0.1566
Episode: 3411/30000 (11.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3648s / 123.6047 s
agent0:                 episode reward: -0.0994,                 loss: nan
agent1:                 episode reward: 0.0994,                 loss: 0.1592
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3646s / 123.9693 s
agent0:                 episode reward: -0.3506,                 loss: nan
agent1:                 episode reward: 0.3506,                 loss: 0.1582
Episode: 3431/30000 (11.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3706s / 124.3399 s
agent0:                 episode reward: -0.1797,                 loss: nan
agent1:                 episode reward: 0.1797,                 loss: 0.1593
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3653s / 124.7052 s
agent0:                 episode reward: 0.4867,                 loss: nan
agent1:                 episode reward: -0.4867,                 loss: 0.1594
Episode: 3451/30000 (11.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3855s / 125.0907 s
agent0:                 episode reward: 0.1049,                 loss: nan
agent1:                 episode reward: -0.1049,                 loss: 0.1595
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3738s / 125.4646 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.1585
Episode: 3471/30000 (11.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3679s / 125.8324 s
agent0:                 episode reward: 0.2083,                 loss: nan
agent1:                 episode reward: -0.2083,                 loss: 0.1556
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3698s / 126.2022 s
agent0:                 episode reward: -0.0285,                 loss: nan
agent1:                 episode reward: 0.0285,                 loss: 0.1567
Episode: 3491/30000 (11.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3744s / 126.5766 s
agent0:                 episode reward: 0.2633,                 loss: nan
agent1:                 episode reward: -0.2633,                 loss: 0.1568
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3633s / 126.9399 s
agent0:                 episode reward: -0.3279,                 loss: nan
agent1:                 episode reward: 0.3279,                 loss: 0.1592
Episode: 3511/30000 (11.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3696s / 127.3095 s
agent0:                 episode reward: -0.1859,                 loss: nan
agent1:                 episode reward: 0.1859,                 loss: 0.1572
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3781s / 127.6876 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.1594
Episode: 3531/30000 (11.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4053s / 128.0929 s
agent0:                 episode reward: 0.2105,                 loss: nan
agent1:                 episode reward: -0.2105,                 loss: 0.1575
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 128.4821 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.1581
Episode: 3551/30000 (11.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3736s / 128.8558 s
agent0:                 episode reward: -0.3553,                 loss: nan
agent1:                 episode reward: 0.3553,                 loss: 0.1590
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3712s / 129.2269 s
agent0:                 episode reward: -0.5900,                 loss: nan
agent1:                 episode reward: 0.5900,                 loss: 0.1611
Episode: 3571/30000 (11.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3573s / 129.5842 s
agent0:                 episode reward: -0.5610,                 loss: nan
agent1:                 episode reward: 0.5610,                 loss: 0.1604
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 129.9694 s
agent0:                 episode reward: 0.4416,                 loss: nan
agent1:                 episode reward: -0.4416,                 loss: 0.1607
Episode: 3591/30000 (11.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3642s / 130.3336 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.1588
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3646s / 130.6982 s
agent0:                 episode reward: 0.1194,                 loss: nan
agent1:                 episode reward: -0.1194,                 loss: 0.1589
Episode: 3611/30000 (12.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3753s / 131.0735 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.1576
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3677s / 131.4412 s
agent0:                 episode reward: -0.0323,                 loss: nan
agent1:                 episode reward: 0.0323,                 loss: 0.1607
Episode: 3631/30000 (12.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3584s / 131.7996 s
agent0:                 episode reward: 0.6736,                 loss: nan
agent1:                 episode reward: -0.6736,                 loss: 0.1607
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3636s / 132.1631 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.1621
Episode: 3651/30000 (12.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3601s / 132.5232 s
agent0:                 episode reward: 0.0127,                 loss: nan
agent1:                 episode reward: -0.0127,                 loss: 0.1588
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3613s / 132.8846 s
agent0:                 episode reward: -0.2397,                 loss: nan
agent1:                 episode reward: 0.2397,                 loss: 0.1613
Episode: 3671/30000 (12.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3633s / 133.2479 s
agent0:                 episode reward: -0.0357,                 loss: nan
agent1:                 episode reward: 0.0357,                 loss: 0.1598
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 133.6099 s
agent0:                 episode reward: -0.0500,                 loss: nan
agent1:                 episode reward: 0.0500,                 loss: 0.1600
Episode: 3691/30000 (12.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3783s / 133.9882 s
agent0:                 episode reward: 0.0473,                 loss: nan
agent1:                 episode reward: -0.0473,                 loss: 0.1576
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4081s / 134.3963 s
agent0:                 episode reward: -0.0260,                 loss: nan
agent1:                 episode reward: 0.0260,                 loss: 0.1630
Episode: 3711/30000 (12.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3733s / 134.7696 s
agent0:                 episode reward: 0.8940,                 loss: nan
agent1:                 episode reward: -0.8940,                 loss: 0.1583
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3686s / 135.1383 s
agent0:                 episode reward: -0.0286,                 loss: nan
agent1:                 episode reward: 0.0286,                 loss: 0.1628
Episode: 3731/30000 (12.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3707s / 135.5090 s
agent0:                 episode reward: 0.1266,                 loss: nan
agent1:                 episode reward: -0.1266,                 loss: 0.1599
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 135.8815 s
agent0:                 episode reward: -0.3792,                 loss: nan
agent1:                 episode reward: 0.3792,                 loss: 0.1603
Episode: 3751/30000 (12.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3783s / 136.2598 s
agent0:                 episode reward: 0.0498,                 loss: nan
agent1:                 episode reward: -0.0498,                 loss: 0.1588
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3774s / 136.6372 s
agent0:                 episode reward: 0.1134,                 loss: nan
agent1:                 episode reward: -0.1134,                 loss: 0.1617
Episode: 3771/30000 (12.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3788s / 137.0160 s
agent0:                 episode reward: 0.1254,                 loss: nan
agent1:                 episode reward: -0.1254,                 loss: 0.1596
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4049s / 137.4210 s
agent0:                 episode reward: 0.1645,                 loss: nan
agent1:                 episode reward: -0.1645,                 loss: 0.1592
Episode: 3791/30000 (12.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3822s / 137.8031 s
agent0:                 episode reward: 0.2312,                 loss: nan
agent1:                 episode reward: -0.2312,                 loss: 0.1617
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3951s / 138.1983 s
agent0:                 episode reward: 0.1700,                 loss: nan
agent1:                 episode reward: -0.1700,                 loss: 0.1595
Episode: 3811/30000 (12.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3786s / 138.5768 s
agent0:                 episode reward: -0.7560,                 loss: nan
agent1:                 episode reward: 0.7560,                 loss: 0.1608
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3690s / 138.9458 s
agent0:                 episode reward: -0.4378,                 loss: nan
agent1:                 episode reward: 0.4378,                 loss: 0.1602
Episode: 3831/30000 (12.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3667s / 139.3126 s
agent0:                 episode reward: 0.4484,                 loss: nan
agent1:                 episode reward: -0.4484,                 loss: 0.1597
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3663s / 139.6789 s
agent0:                 episode reward: -0.3620,                 loss: nan
agent1:                 episode reward: 0.3620,                 loss: 0.1592
Episode: 3851/30000 (12.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3678s / 140.0467 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: 0.1583
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3938s / 140.4405 s
agent0:                 episode reward: 0.4683,                 loss: nan
agent1:                 episode reward: -0.4683,                 loss: 0.1606
Episode: 3871/30000 (12.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3834s / 140.8239 s
agent0:                 episode reward: 0.2386,                 loss: nan
agent1:                 episode reward: -0.2386,                 loss: 0.1580
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3877s / 141.2116 s
agent0:                 episode reward: 0.4477,                 loss: nan
agent1:                 episode reward: -0.4477,                 loss: 0.1607
Episode: 3891/30000 (12.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3916s / 141.6032 s
agent0:                 episode reward: -0.3041,                 loss: nan
agent1:                 episode reward: 0.3041,                 loss: 0.1603
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3625s / 141.9657 s
agent0:                 episode reward: -0.0798,                 loss: nan
agent1:                 episode reward: 0.0798,                 loss: 0.1603
Episode: 3911/30000 (13.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3750s / 142.3407 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.1613
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3785s / 142.7192 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.1609
Episode: 3931/30000 (13.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3760s / 143.0952 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: 0.1599
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3983s / 143.4935 s
agent0:                 episode reward: -0.2494,                 loss: nan
agent1:                 episode reward: 0.2494,                 loss: 0.1630
Episode: 3951/30000 (13.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3797s / 143.8732 s
agent0:                 episode reward: 0.2023,                 loss: nan
agent1:                 episode reward: -0.2023,                 loss: 0.1621
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3780s / 144.2512 s
agent0:                 episode reward: -0.1398,                 loss: nan
agent1:                 episode reward: 0.1398,                 loss: 0.1612
Episode: 3971/30000 (13.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3818s / 144.6331 s
agent0:                 episode reward: -0.0702,                 loss: nan
agent1:                 episode reward: 0.0702,                 loss: 0.1620
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3756s / 145.0087 s
agent0:                 episode reward: -0.3748,                 loss: nan
agent1:                 episode reward: 0.3748,                 loss: 0.1611
Episode: 3991/30000 (13.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3752s / 145.3838 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.1610
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3751s / 145.7589 s
agent0:                 episode reward: -0.8113,                 loss: nan
agent1:                 episode reward: 0.8113,                 loss: 0.1599
Episode: 4011/30000 (13.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3758s / 146.1347 s
agent0:                 episode reward: -0.2465,                 loss: nan
agent1:                 episode reward: 0.2465,                 loss: 0.1623
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4042s / 146.5390 s
agent0:                 episode reward: -0.2213,                 loss: nan
agent1:                 episode reward: 0.2213,                 loss: 0.1627
Episode: 4031/30000 (13.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3837s / 146.9227 s
agent0:                 episode reward: -0.1474,                 loss: nan
agent1:                 episode reward: 0.1474,                 loss: 0.1603
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3755s / 147.2982 s
agent0:                 episode reward: 0.5060,                 loss: nan
agent1:                 episode reward: -0.5060,                 loss: 0.1625
Episode: 4051/30000 (13.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3739s / 147.6721 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.1633
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3739s / 148.0459 s
agent0:                 episode reward: -0.3579,                 loss: nan
agent1:                 episode reward: 0.3579,                 loss: 0.1628
Episode: 4071/30000 (13.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 148.4187 s
agent0:                 episode reward: 0.3120,                 loss: nan
agent1:                 episode reward: -0.3120,                 loss: 0.1650
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3762s / 148.7949 s
agent0:                 episode reward: 0.4488,                 loss: nan
agent1:                 episode reward: -0.4488,                 loss: 0.1623
Episode: 4091/30000 (13.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3779s / 149.1728 s
agent0:                 episode reward: 0.1470,                 loss: nan
agent1:                 episode reward: -0.1470,                 loss: 0.1630
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4077s / 149.5804 s
agent0:                 episode reward: -0.2465,                 loss: nan
agent1:                 episode reward: 0.2465,                 loss: 0.1602
Episode: 4111/30000 (13.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3768s / 149.9572 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1619
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3766s / 150.3338 s
agent0:                 episode reward: -0.0281,                 loss: nan
agent1:                 episode reward: 0.0281,                 loss: 0.1621
Episode: 4131/30000 (13.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3732s / 150.7069 s
agent0:                 episode reward: 0.2801,                 loss: nan
agent1:                 episode reward: -0.2801,                 loss: 0.1591
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3767s / 151.0837 s
agent0:                 episode reward: 0.1217,                 loss: nan
agent1:                 episode reward: -0.1217,                 loss: 0.1606
Episode: 4151/30000 (13.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3797s / 151.4634 s
agent0:                 episode reward: -0.0020,                 loss: nan
agent1:                 episode reward: 0.0020,                 loss: 0.1617
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3803s / 151.8436 s
agent0:                 episode reward: 0.2787,                 loss: nan
agent1:                 episode reward: -0.2787,                 loss: 0.1616
Episode: 4171/30000 (13.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3787s / 152.2223 s
agent0:                 episode reward: 0.3762,                 loss: nan
agent1:                 episode reward: -0.3762,                 loss: 0.1615
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4075s / 152.6299 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1628
Episode: 4191/30000 (13.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 153.0121 s
agent0:                 episode reward: 0.4022,                 loss: nan
agent1:                 episode reward: -0.4022,                 loss: 0.1642
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3763s / 153.3884 s
agent0:                 episode reward: 0.0815,                 loss: nan
agent1:                 episode reward: -0.0815,                 loss: 0.1611
Episode: 4211/30000 (14.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3756s / 153.7641 s
agent0:                 episode reward: 0.0316,                 loss: nan
agent1:                 episode reward: -0.0316,                 loss: 0.1609
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3769s / 154.1409 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.1605
Episode: 4231/30000 (14.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3774s / 154.5184 s
agent0:                 episode reward: -0.3921,                 loss: nan
agent1:                 episode reward: 0.3921,                 loss: 0.1624
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3802s / 154.8986 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1573
Episode: 4251/30000 (14.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3937s / 155.2923 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.1599
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4060s / 155.6983 s
agent0:                 episode reward: 0.0571,                 loss: nan
agent1:                 episode reward: -0.0571,                 loss: 0.1598
Episode: 4271/30000 (14.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3988s / 156.0972 s
agent0:                 episode reward: -0.0190,                 loss: nan
agent1:                 episode reward: 0.0190,                 loss: 0.1624
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3851s / 156.4823 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1593
Episode: 4291/30000 (14.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 156.8630 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.1613
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3785s / 157.2415 s
agent0:                 episode reward: -0.5167,                 loss: nan
agent1:                 episode reward: 0.5167,                 loss: 0.1613
Episode: 4311/30000 (14.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3795s / 157.6210 s
agent0:                 episode reward: 0.2508,                 loss: nan
agent1:                 episode reward: -0.2508,                 loss: 0.1591
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3781s / 157.9991 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.1614
Episode: 4331/30000 (14.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3795s / 158.3786 s
agent0:                 episode reward: 0.2939,                 loss: nan
agent1:                 episode reward: -0.2939,                 loss: 0.1616
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4025s / 158.7811 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.1591
Episode: 4351/30000 (14.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3811s / 159.1622 s
agent0:                 episode reward: 0.7707,                 loss: nan
agent1:                 episode reward: -0.7707,                 loss: 0.1624
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 159.5441 s
agent0:                 episode reward: -0.3182,                 loss: nan
agent1:                 episode reward: 0.3182,                 loss: 0.1606
Episode: 4371/30000 (14.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3788s / 159.9229 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.1637
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3874s / 160.3103 s
agent0:                 episode reward: 0.1048,                 loss: nan
agent1:                 episode reward: -0.1048,                 loss: 0.1609
Episode: 4391/30000 (14.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3798s / 160.6901 s
agent0:                 episode reward: -0.0428,                 loss: nan
agent1:                 episode reward: 0.0428,                 loss: 0.1619
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3751s / 161.0652 s
agent0:                 episode reward: -0.1329,                 loss: nan
agent1:                 episode reward: 0.1329,                 loss: 0.1622
Episode: 4411/30000 (14.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3715s / 161.4366 s
agent0:                 episode reward: 0.1896,                 loss: nan
agent1:                 episode reward: -0.1896,                 loss: 0.1630
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3802s / 161.8168 s
agent0:                 episode reward: 0.2008,                 loss: nan
agent1:                 episode reward: -0.2008,                 loss: 0.1621
Episode: 4431/30000 (14.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3762s / 162.1930 s
agent0:                 episode reward: -0.0287,                 loss: nan
agent1:                 episode reward: 0.0287,                 loss: 0.1608
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3769s / 162.5699 s
agent0:                 episode reward: -0.1036,                 loss: nan
agent1:                 episode reward: 0.1036,                 loss: 0.1628
Episode: 4451/30000 (14.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3796s / 162.9495 s
agent0:                 episode reward: -1.0127,                 loss: nan
agent1:                 episode reward: 1.0127,                 loss: 0.1599
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3820s / 163.3315 s
agent0:                 episode reward: -0.2985,                 loss: nan
agent1:                 episode reward: 0.2985,                 loss: 0.1622
Episode: 4471/30000 (14.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3649s / 163.6964 s
agent0:                 episode reward: -0.9333,                 loss: nan
agent1:                 episode reward: 0.9333,                 loss: 0.1609
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3615s / 164.0579 s
agent0:                 episode reward: 0.2658,                 loss: nan
agent1:                 episode reward: -0.2658,                 loss: 0.1605
Episode: 4491/30000 (14.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3740s / 164.4319 s
agent0:                 episode reward: -0.0810,                 loss: nan
agent1:                 episode reward: 0.0810,                 loss: 0.1608
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3795s / 164.8114 s
agent0:                 episode reward: 0.0125,                 loss: nan
agent1:                 episode reward: -0.0125,                 loss: 0.1595
Episode: 4511/30000 (15.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3719s / 165.1833 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: 0.1625
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3695s / 165.5528 s
agent0:                 episode reward: -0.2552,                 loss: nan
agent1:                 episode reward: 0.2552,                 loss: 0.1608
Episode: 4531/30000 (15.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3831s / 165.9359 s
agent0:                 episode reward: -0.3868,                 loss: nan
agent1:                 episode reward: 0.3868,                 loss: 0.1640
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3825s / 166.3184 s
agent0:                 episode reward: -0.0439,                 loss: nan
agent1:                 episode reward: 0.0439,                 loss: 0.1630
Episode: 4551/30000 (15.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3870s / 166.7054 s
agent0:                 episode reward: 0.2726,                 loss: nan
agent1:                 episode reward: -0.2726,                 loss: 0.1594
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 167.0865 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.1592
Episode: 4571/30000 (15.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3962s / 167.4827 s
agent0:                 episode reward: 0.3715,                 loss: nan
agent1:                 episode reward: -0.3715,                 loss: 0.1591
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4034s / 167.8861 s
agent0:                 episode reward: 0.0491,                 loss: nan
agent1:                 episode reward: -0.0491,                 loss: 0.1608
Episode: 4591/30000 (15.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3848s / 168.2709 s
agent0:                 episode reward: -0.0503,                 loss: nan
agent1:                 episode reward: 0.0503,                 loss: 0.1621
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3856s / 168.6565 s
agent0:                 episode reward: -0.3545,                 loss: nan
agent1:                 episode reward: 0.3545,                 loss: 0.1605
Episode: 4611/30000 (15.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4033s / 169.0598 s
agent0:                 episode reward: -0.1868,                 loss: nan
agent1:                 episode reward: 0.1868,                 loss: 0.1584
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3836s / 169.4434 s
agent0:                 episode reward: 0.0071,                 loss: nan
agent1:                 episode reward: -0.0071,                 loss: 0.1584
Episode: 4631/30000 (15.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 169.8363 s
agent0:                 episode reward: -0.1064,                 loss: nan
agent1:                 episode reward: 0.1064,                 loss: 0.1574
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3810s / 170.2174 s
agent0:                 episode reward: 0.3148,                 loss: nan
agent1:                 episode reward: -0.3148,                 loss: 0.1594
Episode: 4651/30000 (15.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3970s / 170.6143 s
agent0:                 episode reward: 0.1027,                 loss: nan
agent1:                 episode reward: -0.1027,                 loss: 0.1601
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3951s / 171.0094 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.1587
Episode: 4671/30000 (15.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 171.4050 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1606
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 171.8246 s
agent0:                 episode reward: 0.4027,                 loss: nan
agent1:                 episode reward: -0.4027,                 loss: 0.1594
Episode: 4691/30000 (15.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3988s / 172.2234 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.1591
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3948s / 172.6183 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: 0.1588
Episode: 4711/30000 (15.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3675s / 172.9857 s
agent0:                 episode reward: -0.2014,                 loss: nan
agent1:                 episode reward: 0.2014,                 loss: 0.1600
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3723s / 173.3580 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.1609
Episode: 4731/30000 (15.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3939s / 173.7520 s
agent0:                 episode reward: -0.6157,                 loss: nan
agent1:                 episode reward: 0.6157,                 loss: 0.1601
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3696s / 174.1216 s
agent0:                 episode reward: 0.2514,                 loss: nan
agent1:                 episode reward: -0.2514,                 loss: 0.1610
Episode: 4751/30000 (15.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3657s / 174.4873 s
agent0:                 episode reward: -0.0513,                 loss: nan
agent1:                 episode reward: 0.0513,                 loss: 0.1596
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 174.8680 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.1607
Episode: 4771/30000 (15.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 175.2532 s
agent0:                 episode reward: 0.0636,                 loss: nan
agent1:                 episode reward: -0.0636,                 loss: 0.1581
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3914s / 175.6446 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.1595
Episode: 4791/30000 (15.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3839s / 176.0286 s
agent0:                 episode reward: 0.4034,                 loss: nan
agent1:                 episode reward: -0.4034,                 loss: 0.1597
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 176.4146 s
agent0:                 episode reward: -0.4546,                 loss: nan
agent1:                 episode reward: 0.4546,                 loss: 0.1591
Episode: 4811/30000 (16.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4366s / 176.8513 s
agent0:                 episode reward: -0.1906,                 loss: nan
agent1:                 episode reward: 0.1906,                 loss: 0.1591
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3957s / 177.2470 s
agent0:                 episode reward: -0.1199,                 loss: nan
agent1:                 episode reward: 0.1199,                 loss: 0.1584
Episode: 4831/30000 (16.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 177.6263 s
agent0:                 episode reward: -0.1085,                 loss: nan
agent1:                 episode reward: 0.1085,                 loss: 0.1610
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3896s / 178.0160 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.1611
Episode: 4851/30000 (16.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3822s / 178.3981 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.1584
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3786s / 178.7767 s
agent0:                 episode reward: 0.6855,                 loss: nan
agent1:                 episode reward: -0.6855,                 loss: 0.1593
Episode: 4871/30000 (16.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3872s / 179.1639 s
agent0:                 episode reward: -0.2100,                 loss: nan
agent1:                 episode reward: 0.2100,                 loss: 0.1597
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 179.5415 s
agent0:                 episode reward: -0.0752,                 loss: nan
agent1:                 episode reward: 0.0752,                 loss: 0.1593
Episode: 4891/30000 (16.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 179.9763 s
agent0:                 episode reward: -0.5847,                 loss: nan
agent1:                 episode reward: 0.5847,                 loss: 0.1607
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3777s / 180.3540 s
agent0:                 episode reward: -0.3938,                 loss: nan
agent1:                 episode reward: 0.3938,                 loss: 0.1588
Episode: 4911/30000 (16.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 180.7316 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: 0.1594
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3824s / 181.1140 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.1593
Episode: 4931/30000 (16.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3751s / 181.4891 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.1599
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3913s / 181.8804 s
agent0:                 episode reward: -0.4223,                 loss: nan
agent1:                 episode reward: 0.4223,                 loss: 0.1624
Episode: 4951/30000 (16.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 182.2714 s
agent0:                 episode reward: 0.3573,                 loss: nan
agent1:                 episode reward: -0.3573,                 loss: 0.1616
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3855s / 182.6570 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.1605
Episode: 4971/30000 (16.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 183.0917 s
agent0:                 episode reward: -0.1450,                 loss: nan
agent1:                 episode reward: 0.1450,                 loss: 0.1582
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3882s / 183.4799 s
agent0:                 episode reward: 0.4997,                 loss: nan
agent1:                 episode reward: -0.4997,                 loss: 0.1610
Episode: 4991/30000 (16.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3888s / 183.8686 s
agent0:                 episode reward: 0.0721,                 loss: nan
agent1:                 episode reward: -0.0721,                 loss: 0.1614
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3798s / 184.2485 s
agent0:                 episode reward: -0.3851,                 loss: nan
agent1:                 episode reward: 0.3851,                 loss: 0.1614
Episode: 5011/30000 (16.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3832s / 184.6317 s
agent0:                 episode reward: -0.8983,                 loss: nan
agent1:                 episode reward: 0.8983,                 loss: 0.1623
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3773s / 185.0090 s
agent0:                 episode reward: 0.2122,                 loss: nan
agent1:                 episode reward: -0.2122,                 loss: 0.1594
Episode: 5031/30000 (16.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3827s / 185.3917 s
agent0:                 episode reward: 0.0138,                 loss: nan
agent1:                 episode reward: -0.0138,                 loss: 0.1608
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3791s / 185.7708 s
agent0:                 episode reward: -0.0264,                 loss: nan
agent1:                 episode reward: 0.0264,                 loss: 0.1607
Episode: 5051/30000 (16.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 186.1557 s
agent0:                 episode reward: -0.4195,                 loss: nan
agent1:                 episode reward: 0.4195,                 loss: 0.1602
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3682s / 186.5239 s
agent0:                 episode reward: -0.0721,                 loss: nan
agent1:                 episode reward: 0.0721,                 loss: 0.1584
Episode: 5071/30000 (16.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3661s / 186.8899 s
agent0:                 episode reward: -0.2617,                 loss: nan
agent1:                 episode reward: 0.2617,                 loss: 0.1606
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3694s / 187.2594 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.1621
Episode: 5091/30000 (16.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 187.6321 s
agent0:                 episode reward: 0.1537,                 loss: nan
agent1:                 episode reward: -0.1537,                 loss: 0.1604
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3737s / 188.0058 s
agent0:                 episode reward: -0.6887,                 loss: nan
agent1:                 episode reward: 0.6887,                 loss: 0.1586
Episode: 5111/30000 (17.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4039s / 188.4097 s
agent0:                 episode reward: 0.1248,                 loss: nan
agent1:                 episode reward: -0.1248,                 loss: 0.1601
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3826s / 188.7923 s
agent0:                 episode reward: 0.1944,                 loss: nan
agent1:                 episode reward: -0.1944,                 loss: 0.1590
Episode: 5131/30000 (17.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4338s / 189.2261 s
agent0:                 episode reward: -0.3083,                 loss: nan
agent1:                 episode reward: 0.3083,                 loss: 0.1577
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3973s / 189.6234 s
agent0:                 episode reward: 0.0216,                 loss: nan
agent1:                 episode reward: -0.0216,                 loss: 0.1629
Episode: 5151/30000 (17.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3871s / 190.0105 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: 0.1595
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3803s / 190.3908 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1601
Episode: 5171/30000 (17.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3898s / 190.7807 s
agent0:                 episode reward: -0.0180,                 loss: nan
agent1:                 episode reward: 0.0180,                 loss: 0.1617
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 191.1667 s
agent0:                 episode reward: 0.2081,                 loss: nan
agent1:                 episode reward: -0.2081,                 loss: 0.1593
Episode: 5191/30000 (17.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3876s / 191.5543 s
agent0:                 episode reward: -0.2372,                 loss: nan
agent1:                 episode reward: 0.2372,                 loss: 0.1598
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3920s / 191.9463 s
agent0:                 episode reward: 0.1959,                 loss: nan
agent1:                 episode reward: -0.1959,                 loss: 0.1611
Episode: 5211/30000 (17.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3963s / 192.3426 s
agent0:                 episode reward: -0.4404,                 loss: nan
agent1:                 episode reward: 0.4404,                 loss: 0.1629
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3857s / 192.7283 s
agent0:                 episode reward: -0.3972,                 loss: nan
agent1:                 episode reward: 0.3972,                 loss: 0.1630
Episode: 5231/30000 (17.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 193.1125 s
agent0:                 episode reward: -0.0633,                 loss: nan
agent1:                 episode reward: 0.0633,                 loss: 0.1613
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 193.4967 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.1649
Episode: 5251/30000 (17.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3827s / 193.8794 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: 0.1601
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3802s / 194.2595 s
agent0:                 episode reward: 0.7630,                 loss: nan
agent1:                 episode reward: -0.7630,                 loss: 0.1611
Episode: 5271/30000 (17.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3710s / 194.6306 s
agent0:                 episode reward: 0.1555,                 loss: nan
agent1:                 episode reward: -0.1555,                 loss: 0.1627
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 195.0031 s
agent0:                 episode reward: 0.2239,                 loss: nan
agent1:                 episode reward: -0.2239,                 loss: 0.1638
Episode: 5291/30000 (17.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3878s / 195.3909 s
agent0:                 episode reward: 0.3666,                 loss: nan
agent1:                 episode reward: -0.3666,                 loss: 0.1637
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3859s / 195.7768 s
agent0:                 episode reward: 0.0664,                 loss: nan
agent1:                 episode reward: -0.0664,                 loss: 0.1607
Episode: 5311/30000 (17.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3881s / 196.1648 s
agent0:                 episode reward: -0.2147,                 loss: nan
agent1:                 episode reward: 0.2147,                 loss: 0.1625
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3892s / 196.5540 s
agent0:                 episode reward: 0.4744,                 loss: nan
agent1:                 episode reward: -0.4744,                 loss: 0.1613
Episode: 5331/30000 (17.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3902s / 196.9442 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.1617
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3870s / 197.3311 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.1646
Episode: 5351/30000 (17.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3873s / 197.7184 s
agent0:                 episode reward: -0.0996,                 loss: nan
agent1:                 episode reward: 0.0996,                 loss: 0.1640
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4166s / 198.1350 s
agent0:                 episode reward: 0.1177,                 loss: nan
agent1:                 episode reward: -0.1177,                 loss: 0.1633
Episode: 5371/30000 (17.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3889s / 198.5239 s
agent0:                 episode reward: -0.2664,                 loss: nan
agent1:                 episode reward: 0.2664,                 loss: 0.1631
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 198.9091 s
agent0:                 episode reward: -0.2897,                 loss: nan
agent1:                 episode reward: 0.2897,                 loss: 0.1628
Episode: 5391/30000 (17.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3818s / 199.2909 s
agent0:                 episode reward: 0.1104,                 loss: nan
agent1:                 episode reward: -0.1104,                 loss: 0.1627
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 199.6668 s
agent0:                 episode reward: -0.0182,                 loss: nan
agent1:                 episode reward: 0.0182,                 loss: 0.1607
Episode: 5411/30000 (18.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3814s / 200.0482 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: 0.1631
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3837s / 200.4318 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.1628
Episode: 5431/30000 (18.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4043s / 200.8361 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.1616
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 201.2271 s
agent0:                 episode reward: -0.2275,                 loss: nan
agent1:                 episode reward: 0.2275,                 loss: 0.1640
Episode: 5451/30000 (18.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3738s / 201.6009 s
agent0:                 episode reward: 0.3139,                 loss: nan
agent1:                 episode reward: -0.3139,                 loss: 0.1606
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3765s / 201.9774 s
agent0:                 episode reward: -0.5654,                 loss: nan
agent1:                 episode reward: 0.5654,                 loss: 0.1637
Episode: 5471/30000 (18.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3745s / 202.3520 s
agent0:                 episode reward: 0.0743,                 loss: nan
agent1:                 episode reward: -0.0743,                 loss: 0.1627
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 202.7245 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.1612
Episode: 5491/30000 (18.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3880s / 203.1125 s
agent0:                 episode reward: 0.5006,                 loss: nan
agent1:                 episode reward: -0.5006,                 loss: 0.1616
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3755s / 203.4880 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.1620
Episode: 5511/30000 (18.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3912s / 203.8792 s
agent0:                 episode reward: 0.0191,                 loss: nan
agent1:                 episode reward: -0.0191,                 loss: 0.1633
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 204.2748 s
agent0:                 episode reward: 0.2562,                 loss: nan
agent1:                 episode reward: -0.2562,                 loss: 0.1637
Episode: 5531/30000 (18.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3784s / 204.6532 s
agent0:                 episode reward: 0.5355,                 loss: nan
agent1:                 episode reward: -0.5355,                 loss: 0.1633
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3975s / 205.0506 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: 0.1630
Episode: 5551/30000 (18.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3926s / 205.4433 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.1637
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3874s / 205.8306 s
agent0:                 episode reward: -0.0798,                 loss: nan
agent1:                 episode reward: 0.0798,                 loss: 0.1625
Episode: 5571/30000 (18.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3866s / 206.2172 s
agent0:                 episode reward: -0.5459,                 loss: nan
agent1:                 episode reward: 0.5459,                 loss: 0.1613
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3797s / 206.5969 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.1617
Episode: 5591/30000 (18.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3950s / 206.9919 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.1610
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3940s / 207.3859 s
agent0:                 episode reward: -0.1863,                 loss: nan
agent1:                 episode reward: 0.1863,                 loss: 0.1601
Episode: 5611/30000 (18.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3984s / 207.7843 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.1612
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4027s / 208.1870 s
agent0:                 episode reward: 0.4409,                 loss: nan
agent1:                 episode reward: -0.4409,                 loss: 0.1592
Episode: 5631/30000 (18.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3958s / 208.5828 s
agent0:                 episode reward: -0.4436,                 loss: nan
agent1:                 episode reward: 0.4436,                 loss: 0.1632
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3891s / 208.9719 s
agent0:                 episode reward: 0.1235,                 loss: nan
agent1:                 episode reward: -0.1235,                 loss: 0.1617
Episode: 5651/30000 (18.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3847s / 209.3566 s
agent0:                 episode reward: 0.0859,                 loss: nan
agent1:                 episode reward: -0.0859,                 loss: 0.1603
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3905s / 209.7471 s
agent0:                 episode reward: 0.1231,                 loss: nan
agent1:                 episode reward: -0.1231,                 loss: 0.1610
Episode: 5671/30000 (18.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4020s / 210.1491 s
agent0:                 episode reward: -0.0527,                 loss: nan
agent1:                 episode reward: 0.0527,                 loss: 0.1607
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3892s / 210.5382 s
agent0:                 episode reward: -0.2763,                 loss: nan
agent1:                 episode reward: 0.2763,                 loss: 0.1592
Episode: 5691/30000 (18.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3862s / 210.9244 s
agent0:                 episode reward: -0.0882,                 loss: nan
agent1:                 episode reward: 0.0882,                 loss: 0.1626
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3975s / 211.3219 s
agent0:                 episode reward: 0.0764,                 loss: nan
agent1:                 episode reward: -0.0764,                 loss: 0.1618
Episode: 5711/30000 (19.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 211.7026 s
agent0:                 episode reward: -0.7545,                 loss: nan
agent1:                 episode reward: 0.7545,                 loss: 0.1633
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3806s / 212.0832 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: 0.1592
Episode: 5731/30000 (19.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3848s / 212.4679 s
agent0:                 episode reward: -0.4055,                 loss: nan
agent1:                 episode reward: 0.4055,                 loss: 0.1640
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3840s / 212.8519 s
agent0:                 episode reward: -0.0299,                 loss: nan
agent1:                 episode reward: 0.0299,                 loss: 0.1599
Episode: 5751/30000 (19.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4066s / 213.2585 s
agent0:                 episode reward: -0.0036,                 loss: nan
agent1:                 episode reward: 0.0036,                 loss: 0.1607
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4203s / 213.6788 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.1602
Episode: 5771/30000 (19.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3916s / 214.0705 s
agent0:                 episode reward: 0.2106,                 loss: nan
agent1:                 episode reward: -0.2106,                 loss: 0.1606
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3921s / 214.4625 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.1610
Episode: 5791/30000 (19.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3933s / 214.8559 s
agent0:                 episode reward: -0.2921,                 loss: nan
agent1:                 episode reward: 0.2921,                 loss: 0.1610
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3750s / 215.2308 s
agent0:                 episode reward: -0.1488,                 loss: nan
agent1:                 episode reward: 0.1488,                 loss: 0.1625
Episode: 5811/30000 (19.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3746s / 215.6054 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: 0.1596
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3743s / 215.9797 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.1603
Episode: 5831/30000 (19.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4178s / 216.3975 s
agent0:                 episode reward: 0.1186,                 loss: nan
agent1:                 episode reward: -0.1186,                 loss: 0.1602
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3839s / 216.7814 s
agent0:                 episode reward: 0.0885,                 loss: nan
agent1:                 episode reward: -0.0885,                 loss: 0.1599
Episode: 5851/30000 (19.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3814s / 217.1628 s
agent0:                 episode reward: 0.3585,                 loss: nan
agent1:                 episode reward: -0.3585,                 loss: 0.1637
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3748s / 217.5376 s
agent0:                 episode reward: -0.7426,                 loss: nan
agent1:                 episode reward: 0.7426,                 loss: 0.1606
Episode: 5871/30000 (19.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 217.9188 s
agent0:                 episode reward: -0.9378,                 loss: nan
agent1:                 episode reward: 0.9378,                 loss: 0.1603
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3712s / 218.2899 s
agent0:                 episode reward: -0.7053,                 loss: nan
agent1:                 episode reward: 0.7053,                 loss: 0.1605
Episode: 5891/30000 (19.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 218.6711 s
agent0:                 episode reward: -0.4111,                 loss: nan
agent1:                 episode reward: 0.4111,                 loss: 0.1614
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 219.0470 s
agent0:                 episode reward: -0.2250,                 loss: nan
agent1:                 episode reward: 0.2250,                 loss: 0.1618
Episode: 5911/30000 (19.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3850s / 219.4320 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.1626
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3726s / 219.8046 s
agent0:                 episode reward: -0.0640,                 loss: nan
agent1:                 episode reward: 0.0640,                 loss: 0.1623
Episode: 5931/30000 (19.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3684s / 220.1730 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.1611
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3761s / 220.5491 s
agent0:                 episode reward: -0.1607,                 loss: nan
agent1:                 episode reward: 0.1607,                 loss: 0.1615
Episode: 5951/30000 (19.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3757s / 220.9248 s
agent0:                 episode reward: -0.1528,                 loss: nan
agent1:                 episode reward: 0.1528,                 loss: 0.1630
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3798s / 221.3046 s
agent0:                 episode reward: -0.1187,                 loss: nan
agent1:                 episode reward: 0.1187,                 loss: 0.1655
Episode: 5971/30000 (19.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3710s / 221.6756 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.1596
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3914s / 222.0670 s
agent0:                 episode reward: -0.0172,                 loss: nan
agent1:                 episode reward: 0.0172,                 loss: 0.1598
Episode: 5991/30000 (19.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3913s / 222.4582 s
agent0:                 episode reward: 0.0393,                 loss: nan
agent1:                 episode reward: -0.0393,                 loss: 0.1622
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3744s / 222.8326 s
agent0:                 episode reward: 0.0668,                 loss: nan
agent1:                 episode reward: -0.0668,                 loss: 0.1604
Episode: 6011/30000 (20.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3860s / 223.2186 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1623
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 223.6005 s
agent0:                 episode reward: 0.0213,                 loss: nan
agent1:                 episode reward: -0.0213,                 loss: 0.1617
Episode: 6031/30000 (20.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3925s / 223.9931 s
agent0:                 episode reward: 0.0109,                 loss: nan
agent1:                 episode reward: -0.0109,                 loss: 0.1626
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3869s / 224.3800 s
agent0:                 episode reward: -0.2795,                 loss: nan
agent1:                 episode reward: 0.2795,                 loss: 0.1618
Episode: 6051/30000 (20.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3855s / 224.7655 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1613
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 225.1504 s
agent0:                 episode reward: 0.3279,                 loss: nan
agent1:                 episode reward: -0.3279,                 loss: 0.1601
Episode: 6071/30000 (20.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4115s / 225.5618 s
agent0:                 episode reward: 0.0368,                 loss: nan
agent1:                 episode reward: -0.0368,                 loss: 0.1579
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3850s / 225.9468 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.1629
Episode: 6091/30000 (20.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3904s / 226.3372 s
agent0:                 episode reward: -0.0276,                 loss: nan
agent1:                 episode reward: 0.0276,                 loss: 0.1628
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 226.7282 s
agent0:                 episode reward: 0.1423,                 loss: nan
agent1:                 episode reward: -0.1423,                 loss: 0.1609
Episode: 6111/30000 (20.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3935s / 227.1217 s
agent0:                 episode reward: 0.2471,                 loss: nan
agent1:                 episode reward: -0.2471,                 loss: 0.1612
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3923s / 227.5140 s
agent0:                 episode reward: -0.0561,                 loss: nan
agent1:                 episode reward: 0.0561,                 loss: 0.1653
Episode: 6131/30000 (20.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3950s / 227.9090 s
agent0:                 episode reward: 0.0723,                 loss: nan
agent1:                 episode reward: -0.0723,                 loss: 0.1602
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 228.2983 s
agent0:                 episode reward: 0.0278,                 loss: nan
agent1:                 episode reward: -0.0278,                 loss: 0.1630
Episode: 6151/30000 (20.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 228.6987 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.1620
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3717s / 229.0704 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.1621
Episode: 6171/30000 (20.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3768s / 229.4472 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1602
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3754s / 229.8226 s
agent0:                 episode reward: -0.3254,                 loss: nan
agent1:                 episode reward: 0.3254,                 loss: 0.1609
Episode: 6191/30000 (20.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4031s / 230.2257 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.1638
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3950s / 230.6207 s
agent0:                 episode reward: -0.2887,                 loss: nan
agent1:                 episode reward: 0.2887,                 loss: 0.1616
Episode: 6211/30000 (20.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3761s / 230.9968 s
agent0:                 episode reward: 0.0489,                 loss: nan
agent1:                 episode reward: -0.0489,                 loss: 0.1635
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 231.3817 s
agent0:                 episode reward: -0.3637,                 loss: nan
agent1:                 episode reward: 0.3637,                 loss: 0.1610
Episode: 6231/30000 (20.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4012s / 231.7829 s
agent0:                 episode reward: -0.0465,                 loss: nan
agent1:                 episode reward: 0.0465,                 loss: 0.1558
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3844s / 232.1673 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.1571
Episode: 6251/30000 (20.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3780s / 232.5453 s
agent0:                 episode reward: 0.4187,                 loss: nan
agent1:                 episode reward: -0.4187,                 loss: 0.1568
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4204s / 232.9657 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: 0.1579
Episode: 6271/30000 (20.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4155s / 233.3812 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.1565
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3905s / 233.7717 s
agent0:                 episode reward: -0.0717,                 loss: nan
agent1:                 episode reward: 0.0717,                 loss: 0.1589
Episode: 6291/30000 (20.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 234.1524 s
agent0:                 episode reward: -0.6009,                 loss: nan
agent1:                 episode reward: 0.6009,                 loss: 0.1574
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3946s / 234.5471 s
agent0:                 episode reward: -0.2439,                 loss: nan
agent1:                 episode reward: 0.2439,                 loss: 0.1565
Episode: 6311/30000 (21.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3906s / 234.9377 s
agent0:                 episode reward: 0.3426,                 loss: nan
agent1:                 episode reward: -0.3426,                 loss: 0.1582
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3797s / 235.3174 s
agent0:                 episode reward: -0.0465,                 loss: nan
agent1:                 episode reward: 0.0465,                 loss: 0.1581
Episode: 6331/30000 (21.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 235.6981 s
agent0:                 episode reward: -0.5910,                 loss: nan
agent1:                 episode reward: 0.5910,                 loss: 0.1552
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3779s / 236.0760 s
agent0:                 episode reward: 0.1591,                 loss: nan
agent1:                 episode reward: -0.1591,                 loss: 0.1573
Episode: 6351/30000 (21.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3767s / 236.4527 s
agent0:                 episode reward: -0.0950,                 loss: nan
agent1:                 episode reward: 0.0950,                 loss: 0.1584
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3822s / 236.8349 s
agent0:                 episode reward: 0.0490,                 loss: nan
agent1:                 episode reward: -0.0490,                 loss: 0.1562
Episode: 6371/30000 (21.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3790s / 237.2139 s
agent0:                 episode reward: 0.3028,                 loss: nan
agent1:                 episode reward: -0.3028,                 loss: 0.1575
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3909s / 237.6049 s
agent0:                 episode reward: 0.2337,                 loss: nan
agent1:                 episode reward: -0.2337,                 loss: 0.1570
Episode: 6391/30000 (21.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4037s / 238.0086 s
agent0:                 episode reward: -0.8621,                 loss: nan
agent1:                 episode reward: 0.8621,                 loss: 0.1579
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4136s / 238.4222 s
agent0:                 episode reward: 0.1272,                 loss: nan
agent1:                 episode reward: -0.1272,                 loss: 0.1574
Episode: 6411/30000 (21.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3879s / 238.8101 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.1573
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 239.2045 s
agent0:                 episode reward: -0.3356,                 loss: nan
agent1:                 episode reward: 0.3356,                 loss: 0.1565
Episode: 6431/30000 (21.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3981s / 239.6026 s
agent0:                 episode reward: 0.1675,                 loss: nan
agent1:                 episode reward: -0.1675,                 loss: 0.1546
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3961s / 239.9987 s
agent0:                 episode reward: 0.3721,                 loss: nan
agent1:                 episode reward: -0.3721,                 loss: 0.1596
Episode: 6451/30000 (21.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4005s / 240.3992 s
agent0:                 episode reward: 0.1297,                 loss: nan
agent1:                 episode reward: -0.1297,                 loss: 0.1574
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 240.8227 s
agent0:                 episode reward: -0.2157,                 loss: nan
agent1:                 episode reward: 0.2157,                 loss: 0.1572
Episode: 6471/30000 (21.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4012s / 241.2238 s
agent0:                 episode reward: 0.1202,                 loss: nan
agent1:                 episode reward: -0.1202,                 loss: 0.1567
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 241.6242 s
agent0:                 episode reward: 0.3264,                 loss: nan
agent1:                 episode reward: -0.3264,                 loss: 0.1558
Episode: 6491/30000 (21.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3971s / 242.0213 s
agent0:                 episode reward: 0.0567,                 loss: nan
agent1:                 episode reward: -0.0567,                 loss: 0.1556
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3945s / 242.4158 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1567
Episode: 6511/30000 (21.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 242.8162 s
agent0:                 episode reward: -0.0237,                 loss: nan
agent1:                 episode reward: 0.0237,                 loss: 0.1558
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3968s / 243.2130 s
agent0:                 episode reward: -0.0102,                 loss: nan
agent1:                 episode reward: 0.0102,                 loss: 0.1551
Episode: 6531/30000 (21.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4093s / 243.6223 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.1561
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4220s / 244.0443 s
agent0:                 episode reward: -0.1306,                 loss: nan
agent1:                 episode reward: 0.1306,                 loss: 0.1574
Episode: 6551/30000 (21.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3969s / 244.4412 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.1596
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3887s / 244.8299 s
agent0:                 episode reward: -0.4219,                 loss: nan
agent1:                 episode reward: 0.4219,                 loss: 0.1617
Episode: 6571/30000 (21.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3973s / 245.2272 s
agent0:                 episode reward: 0.4052,                 loss: nan
agent1:                 episode reward: -0.4052,                 loss: 0.1585
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3963s / 245.6235 s
agent0:                 episode reward: -0.2835,                 loss: nan
agent1:                 episode reward: 0.2835,                 loss: 0.1618
Episode: 6591/30000 (21.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3934s / 246.0169 s
agent0:                 episode reward: -0.0745,                 loss: nan
agent1:                 episode reward: 0.0745,                 loss: 0.1603
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3986s / 246.4155 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1625
Episode: 6611/30000 (22.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4341s / 246.8496 s
agent0:                 episode reward: 0.0286,                 loss: nan
agent1:                 episode reward: -0.0286,                 loss: 0.1626
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3926s / 247.2422 s
agent0:                 episode reward: 0.4791,                 loss: nan
agent1:                 episode reward: -0.4791,                 loss: 0.1654
Episode: 6631/30000 (22.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 247.6230 s
agent0:                 episode reward: -0.0298,                 loss: nan
agent1:                 episode reward: 0.0298,                 loss: 0.1628
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 248.0053 s
agent0:                 episode reward: -0.6329,                 loss: nan
agent1:                 episode reward: 0.6329,                 loss: 0.1631
Episode: 6651/30000 (22.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3838s / 248.3891 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1622
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 248.7703 s
agent0:                 episode reward: -0.0389,                 loss: nan
agent1:                 episode reward: 0.0389,                 loss: 0.1627
Episode: 6671/30000 (22.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3795s / 249.1498 s
agent0:                 episode reward: -0.1901,                 loss: nan
agent1:                 episode reward: 0.1901,                 loss: 0.1615
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3806s / 249.5303 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.1609
Episode: 6691/30000 (22.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4008s / 249.9312 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: 0.1605
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3977s / 250.3289 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.1636
Episode: 6711/30000 (22.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4063s / 250.7352 s
agent0:                 episode reward: -0.0168,                 loss: nan
agent1:                 episode reward: 0.0168,                 loss: 0.1620
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 251.1308 s
agent0:                 episode reward: 0.0858,                 loss: nan
agent1:                 episode reward: -0.0858,                 loss: 0.1590
Episode: 6731/30000 (22.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4062s / 251.5370 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: 0.1613
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4062s / 251.9432 s
agent0:                 episode reward: 0.0381,                 loss: nan
agent1:                 episode reward: -0.0381,                 loss: 0.1609
Episode: 6751/30000 (22.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4049s / 252.3481 s
agent0:                 episode reward: 0.1181,                 loss: nan
agent1:                 episode reward: -0.1181,                 loss: 0.1622
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4031s / 252.7512 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: 0.1617
Episode: 6771/30000 (22.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4312s / 253.1823 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.1601
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3870s / 253.5693 s
agent0:                 episode reward: -0.0929,                 loss: nan
agent1:                 episode reward: 0.0929,                 loss: 0.1604
Episode: 6791/30000 (22.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3841s / 253.9534 s
agent0:                 episode reward: -0.2792,                 loss: nan
agent1:                 episode reward: 0.2792,                 loss: 0.1623
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3866s / 254.3400 s
agent0:                 episode reward: 0.0187,                 loss: nan
agent1:                 episode reward: -0.0187,                 loss: 0.1625
Episode: 6811/30000 (22.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 254.7294 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1610
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3903s / 255.1197 s
agent0:                 episode reward: -0.0326,                 loss: nan
agent1:                 episode reward: 0.0326,                 loss: 0.1607
Episode: 6831/30000 (22.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3863s / 255.5059 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.1615
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3917s / 255.8976 s
agent0:                 episode reward: -0.4281,                 loss: nan
agent1:                 episode reward: 0.4281,                 loss: 0.1598
Episode: 6851/30000 (22.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3976s / 256.2952 s
agent0:                 episode reward: -0.6647,                 loss: nan
agent1:                 episode reward: 0.6647,                 loss: 0.1599
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3927s / 256.6880 s
agent0:                 episode reward: -0.2143,                 loss: nan
agent1:                 episode reward: 0.2143,                 loss: 0.1627
Episode: 6871/30000 (22.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3955s / 257.0834 s
agent0:                 episode reward: -0.4020,                 loss: nan
agent1:                 episode reward: 0.4020,                 loss: 0.1598
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3993s / 257.4827 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.1612
Episode: 6891/30000 (22.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4039s / 257.8866 s
agent0:                 episode reward: -0.3772,                 loss: nan
agent1:                 episode reward: 0.3772,                 loss: 0.1612
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3969s / 258.2835 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: 0.1605
Episode: 6911/30000 (23.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3942s / 258.6778 s
agent0:                 episode reward: -0.5551,                 loss: nan
agent1:                 episode reward: 0.5551,                 loss: 0.1615
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4154s / 259.0932 s
agent0:                 episode reward: -0.4068,                 loss: nan
agent1:                 episode reward: 0.4068,                 loss: 0.1602
Episode: 6931/30000 (23.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4012s / 259.4945 s
agent0:                 episode reward: -0.8778,                 loss: nan
agent1:                 episode reward: 0.8778,                 loss: 0.1604
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4005s / 259.8950 s
agent0:                 episode reward: -0.7107,                 loss: nan
agent1:                 episode reward: 0.7107,                 loss: 0.1597
Episode: 6951/30000 (23.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3938s / 260.2888 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.1600
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3947s / 260.6834 s
agent0:                 episode reward: -0.2880,                 loss: nan
agent1:                 episode reward: 0.2880,                 loss: 0.1620
Episode: 6971/30000 (23.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 261.0794 s
agent0:                 episode reward: 0.0098,                 loss: nan
agent1:                 episode reward: -0.0098,                 loss: 0.1592
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 261.4709 s
agent0:                 episode reward: -0.9728,                 loss: nan
agent1:                 episode reward: 0.9728,                 loss: 0.1622
Episode: 6991/30000 (23.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 261.8516 s
agent0:                 episode reward: -0.1769,                 loss: nan
agent1:                 episode reward: 0.1769,                 loss: 0.1608
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4021s / 262.2537 s
agent0:                 episode reward: 0.1348,                 loss: nan
agent1:                 episode reward: -0.1348,                 loss: 0.1609
Episode: 7011/30000 (23.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3780s / 262.6317 s
agent0:                 episode reward: -0.0754,                 loss: nan
agent1:                 episode reward: 0.0754,                 loss: 0.1607
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 263.0139 s
agent0:                 episode reward: -0.0075,                 loss: nan
agent1:                 episode reward: 0.0075,                 loss: 0.1617
Episode: 7031/30000 (23.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3789s / 263.3929 s
agent0:                 episode reward: -0.4831,                 loss: nan
agent1:                 episode reward: 0.4831,                 loss: 0.1601
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4052s / 263.7981 s
agent0:                 episode reward: -0.0306,                 loss: nan
agent1:                 episode reward: 0.0306,                 loss: 0.1590
Episode: 7051/30000 (23.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3802s / 264.1782 s
agent0:                 episode reward: -0.1691,                 loss: nan
agent1:                 episode reward: 0.1691,                 loss: 0.1606
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 264.5577 s
agent0:                 episode reward: 0.1964,                 loss: nan
agent1:                 episode reward: -0.1964,                 loss: 0.1619
Episode: 7071/30000 (23.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3867s / 264.9444 s
agent0:                 episode reward: -0.4215,                 loss: nan
agent1:                 episode reward: 0.4215,                 loss: 0.1608
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4282s / 265.3726 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.1596
Episode: 7091/30000 (23.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4055s / 265.7781 s
agent0:                 episode reward: -0.0474,                 loss: nan
agent1:                 episode reward: 0.0474,                 loss: 0.1589
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3748s / 266.1528 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1582
Episode: 7111/30000 (23.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3787s / 266.5315 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.1605
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3831s / 266.9146 s
agent0:                 episode reward: -0.5434,                 loss: nan
agent1:                 episode reward: 0.5434,                 loss: 0.1595
Episode: 7131/30000 (23.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4038s / 267.3184 s
agent0:                 episode reward: 0.1311,                 loss: nan
agent1:                 episode reward: -0.1311,                 loss: 0.1617
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4054s / 267.7238 s
agent0:                 episode reward: 0.5205,                 loss: nan
agent1:                 episode reward: -0.5205,                 loss: 0.1605
Episode: 7151/30000 (23.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4037s / 268.1274 s
agent0:                 episode reward: -0.0919,                 loss: nan
agent1:                 episode reward: 0.0919,                 loss: 0.1603
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4110s / 268.5385 s
agent0:                 episode reward: -0.3773,                 loss: nan
agent1:                 episode reward: 0.3773,                 loss: 0.1614
Episode: 7171/30000 (23.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3937s / 268.9321 s
agent0:                 episode reward: -0.1295,                 loss: nan
agent1:                 episode reward: 0.1295,                 loss: 0.1595
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3918s / 269.3240 s
agent0:                 episode reward: 0.2305,                 loss: nan
agent1:                 episode reward: -0.2305,                 loss: 0.1611
Episode: 7191/30000 (23.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3882s / 269.7122 s
agent0:                 episode reward: -0.7662,                 loss: nan
agent1:                 episode reward: 0.7662,                 loss: 0.1608
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3873s / 270.0995 s
agent0:                 episode reward: -0.2102,                 loss: nan
agent1:                 episode reward: 0.2102,                 loss: 0.1620
Episode: 7211/30000 (24.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 270.4904 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: 0.1599
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3907s / 270.8811 s
agent0:                 episode reward: 0.1371,                 loss: nan
agent1:                 episode reward: -0.1371,                 loss: 0.1587
Episode: 7231/30000 (24.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4005s / 271.2817 s
agent0:                 episode reward: -0.3483,                 loss: nan
agent1:                 episode reward: 0.3483,                 loss: 0.1613
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4033s / 271.6849 s
agent0:                 episode reward: -0.1004,                 loss: nan
agent1:                 episode reward: 0.1004,                 loss: 0.1587
Episode: 7251/30000 (24.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 272.1101 s
agent0:                 episode reward: 0.1006,                 loss: nan
agent1:                 episode reward: -0.1006,                 loss: 0.1601
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3905s / 272.5006 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: 0.1606
Episode: 7271/30000 (24.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3905s / 272.8910 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.1602
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3969s / 273.2880 s
agent0:                 episode reward: -0.3121,                 loss: nan
agent1:                 episode reward: 0.3121,                 loss: 0.1630
Episode: 7291/30000 (24.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3940s / 273.6820 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.1616
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 274.0643 s
agent0:                 episode reward: -0.1423,                 loss: nan
agent1:                 episode reward: 0.1423,                 loss: 0.1626
Episode: 7311/30000 (24.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 274.4807 s
agent0:                 episode reward: 0.1608,                 loss: nan
agent1:                 episode reward: -0.1608,                 loss: 0.1604
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3892s / 274.8699 s
agent0:                 episode reward: -0.1156,                 loss: nan
agent1:                 episode reward: 0.1156,                 loss: 0.1606
Episode: 7331/30000 (24.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3803s / 275.2502 s
agent0:                 episode reward: -0.3518,                 loss: nan
agent1:                 episode reward: 0.3518,                 loss: 0.1610
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3837s / 275.6339 s
agent0:                 episode reward: 0.1453,                 loss: nan
agent1:                 episode reward: -0.1453,                 loss: 0.1599
Episode: 7351/30000 (24.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3872s / 276.0211 s
agent0:                 episode reward: -0.3348,                 loss: nan
agent1:                 episode reward: 0.3348,                 loss: 0.1594
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3964s / 276.4175 s
agent0:                 episode reward: -0.1630,                 loss: nan
agent1:                 episode reward: 0.1630,                 loss: 0.1603
Episode: 7371/30000 (24.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3999s / 276.8174 s
agent0:                 episode reward: -0.3265,                 loss: nan
agent1:                 episode reward: 0.3265,                 loss: 0.1628
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3996s / 277.2170 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: 0.1594
Episode: 7391/30000 (24.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4257s / 277.6427 s
agent0:                 episode reward: -0.0952,                 loss: nan
agent1:                 episode reward: 0.0952,                 loss: 0.1595
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4063s / 278.0490 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1617
Episode: 7411/30000 (24.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3972s / 278.4462 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1592
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3936s / 278.8398 s
agent0:                 episode reward: -0.0269,                 loss: nan
agent1:                 episode reward: 0.0269,                 loss: 0.1603
Episode: 7431/30000 (24.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3988s / 279.2386 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: 0.1574
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3901s / 279.6287 s
agent0:                 episode reward: -0.1145,                 loss: nan
agent1:                 episode reward: 0.1145,                 loss: 0.1609
Episode: 7451/30000 (24.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3978s / 280.0265 s
agent0:                 episode reward: -0.1934,                 loss: nan
agent1:                 episode reward: 0.1934,                 loss: 0.1609
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4222s / 280.4487 s
agent0:                 episode reward: -0.8402,                 loss: nan
agent1:                 episode reward: 0.8402,                 loss: 0.1619
Episode: 7471/30000 (24.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4040s / 280.8527 s
agent0:                 episode reward: -0.1127,                 loss: nan
agent1:                 episode reward: 0.1127,                 loss: 0.1609
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3900s / 281.2427 s
agent0:                 episode reward: -0.1946,                 loss: nan
agent1:                 episode reward: 0.1946,                 loss: 0.1605
Episode: 7491/30000 (24.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 281.6320 s
agent0:                 episode reward: -0.2978,                 loss: nan
agent1:                 episode reward: 0.2978,                 loss: 0.1607
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3904s / 282.0224 s
agent0:                 episode reward: 0.0730,                 loss: nan
agent1:                 episode reward: -0.0730,                 loss: 0.1617
Episode: 7511/30000 (25.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 282.4076 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: 0.1601
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3879s / 282.7955 s
agent0:                 episode reward: 0.1029,                 loss: nan
agent1:                 episode reward: -0.1029,                 loss: 0.1565
Episode: 7531/30000 (25.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3921s / 283.1876 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.1614
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 283.6035 s
agent0:                 episode reward: -0.1174,                 loss: nan
agent1:                 episode reward: 0.1174,                 loss: 0.1620
Episode: 7551/30000 (25.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4044s / 284.0079 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.1590
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 284.4238 s
agent0:                 episode reward: -0.0569,                 loss: nan
agent1:                 episode reward: 0.0569,                 loss: 0.1622
Episode: 7571/30000 (25.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4387s / 284.8625 s
agent0:                 episode reward: 0.0847,                 loss: nan
agent1:                 episode reward: -0.0847,                 loss: 0.1612
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4254s / 285.2879 s
agent0:                 episode reward: -0.1036,                 loss: nan
agent1:                 episode reward: 0.1036,                 loss: 0.1590
Episode: 7591/30000 (25.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4254s / 285.7133 s
agent0:                 episode reward: 0.1384,                 loss: nan
agent1:                 episode reward: -0.1384,                 loss: 0.1615
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4307s / 286.1440 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.1619
Episode: 7611/30000 (25.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4622s / 286.6062 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1614
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4490s / 287.0552 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.1630
Episode: 7631/30000 (25.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4014s / 287.4566 s
agent0:                 episode reward: 0.1039,                 loss: nan
agent1:                 episode reward: -0.1039,                 loss: 0.1605
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 287.9018 s
agent0:                 episode reward: 0.7759,                 loss: nan
agent1:                 episode reward: -0.7759,                 loss: 0.1611
Episode: 7651/30000 (25.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4148s / 288.3167 s
agent0:                 episode reward: -0.2381,                 loss: nan
agent1:                 episode reward: 0.2381,                 loss: 0.1589
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4316s / 288.7482 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1612
Episode: 7671/30000 (25.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4083s / 289.1566 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1598
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 289.5917 s
agent0:                 episode reward: 0.0394,                 loss: nan
agent1:                 episode reward: -0.0394,                 loss: 0.1629
Episode: 7691/30000 (25.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4560s / 290.0478 s
agent0:                 episode reward: 0.1632,                 loss: nan
agent1:                 episode reward: -0.1632,                 loss: 0.1612
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 290.4605 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.1614
Episode: 7711/30000 (25.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4095s / 290.8699 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1597
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4548s / 291.3247 s
agent0:                 episode reward: -0.4794,                 loss: nan
agent1:                 episode reward: 0.4794,                 loss: 0.1622
Episode: 7731/30000 (25.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4205s / 291.7452 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.1603
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 292.1627 s
agent0:                 episode reward: -0.2787,                 loss: nan
agent1:                 episode reward: 0.2787,                 loss: 0.1613
Episode: 7751/30000 (25.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4100s / 292.5727 s
agent0:                 episode reward: 0.4268,                 loss: nan
agent1:                 episode reward: -0.4268,                 loss: 0.1593
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4893s / 293.0620 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.1600
Episode: 7771/30000 (25.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4304s / 293.4923 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: 0.1603
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4257s / 293.9180 s
agent0:                 episode reward: -0.4372,                 loss: nan
agent1:                 episode reward: 0.4372,                 loss: 0.1602
Episode: 7791/30000 (25.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3998s / 294.3178 s
agent0:                 episode reward: -0.2895,                 loss: nan
agent1:                 episode reward: 0.2895,                 loss: 0.1593
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4013s / 294.7191 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1608
Episode: 7811/30000 (26.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 295.1277 s
agent0:                 episode reward: -0.3587,                 loss: nan
agent1:                 episode reward: 0.3587,                 loss: 0.1609
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4014s / 295.5291 s
agent0:                 episode reward: -0.3495,                 loss: nan
agent1:                 episode reward: 0.3495,                 loss: 0.1600
Episode: 7831/30000 (26.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4739s / 296.0031 s
agent0:                 episode reward: -0.2312,                 loss: nan
agent1:                 episode reward: 0.2312,                 loss: 0.1614
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 296.4163 s
agent0:                 episode reward: -0.6212,                 loss: nan
agent1:                 episode reward: 0.6212,                 loss: 0.1628
Episode: 7851/30000 (26.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 296.8481 s
agent0:                 episode reward: -0.0013,                 loss: nan
agent1:                 episode reward: 0.0013,                 loss: 0.1618
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4087s / 297.2568 s
agent0:                 episode reward: -0.3440,                 loss: nan
agent1:                 episode reward: 0.3440,                 loss: 0.1610
Episode: 7871/30000 (26.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4042s / 297.6609 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.1631
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4118s / 298.0727 s
agent0:                 episode reward: -0.1859,                 loss: nan
agent1:                 episode reward: 0.1859,                 loss: 0.1616
Episode: 7891/30000 (26.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4096s / 298.4824 s
agent0:                 episode reward: 0.6746,                 loss: nan
agent1:                 episode reward: -0.6746,                 loss: 0.1613
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4368s / 298.9192 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1574
Episode: 7911/30000 (26.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4329s / 299.3521 s
agent0:                 episode reward: 0.2076,                 loss: nan
agent1:                 episode reward: -0.2076,                 loss: 0.1615
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 299.7739 s
agent0:                 episode reward: 0.1130,                 loss: nan
agent1:                 episode reward: -0.1130,                 loss: 0.1604
Episode: 7931/30000 (26.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 300.2722 s
agent0:                 episode reward: 0.2412,                 loss: nan
agent1:                 episode reward: -0.2412,                 loss: 0.1608
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 300.7072 s
agent0:                 episode reward: 0.1095,                 loss: nan
agent1:                 episode reward: -0.1095,                 loss: 0.1604
Episode: 7951/30000 (26.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4068s / 301.1139 s
agent0:                 episode reward: -0.1374,                 loss: nan
agent1:                 episode reward: 0.1374,                 loss: 0.1600
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3895s / 301.5034 s
agent0:                 episode reward: -0.3258,                 loss: nan
agent1:                 episode reward: 0.3258,                 loss: 0.1597
Episode: 7971/30000 (26.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 301.8990 s
agent0:                 episode reward: -0.2767,                 loss: nan
agent1:                 episode reward: 0.2767,                 loss: 0.1594
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4073s / 302.3063 s
agent0:                 episode reward: -0.2416,                 loss: nan
agent1:                 episode reward: 0.2416,                 loss: 0.1592
Episode: 7991/30000 (26.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3951s / 302.7014 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.1593
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4008s / 303.1022 s
agent0:                 episode reward: -0.2981,                 loss: nan
agent1:                 episode reward: 0.2981,                 loss: 0.1603
Episode: 8011/30000 (26.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4016s / 303.5038 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.1581
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3991s / 303.9029 s
agent0:                 episode reward: -0.3177,                 loss: nan
agent1:                 episode reward: 0.3177,                 loss: 0.1613
Episode: 8031/30000 (26.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4064s / 304.3093 s
agent0:                 episode reward: -0.6407,                 loss: nan
agent1:                 episode reward: 0.6407,                 loss: 0.1603
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3990s / 304.7084 s
agent0:                 episode reward: -0.2659,                 loss: nan
agent1:                 episode reward: 0.2659,                 loss: 0.1603
Episode: 8051/30000 (26.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 305.1476 s
agent0:                 episode reward: -0.3193,                 loss: nan
agent1:                 episode reward: 0.3193,                 loss: 0.1609
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4759s / 305.6234 s
agent0:                 episode reward: -0.2255,                 loss: nan
agent1:                 episode reward: 0.2255,                 loss: 0.1591
Episode: 8071/30000 (26.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4272s / 306.0506 s
agent0:                 episode reward: -0.3664,                 loss: nan
agent1:                 episode reward: 0.3664,                 loss: 0.1597
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4052s / 306.4558 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.1587
Episode: 8091/30000 (26.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4040s / 306.8597 s
agent0:                 episode reward: -0.1246,                 loss: nan
agent1:                 episode reward: 0.1246,                 loss: 0.1609
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4066s / 307.2663 s
agent0:                 episode reward: 0.3834,                 loss: nan
agent1:                 episode reward: -0.3834,                 loss: 0.1625
Episode: 8111/30000 (27.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4099s / 307.6763 s
agent0:                 episode reward: 0.0688,                 loss: nan
agent1:                 episode reward: -0.0688,                 loss: 0.1582
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 308.1183 s
agent0:                 episode reward: 0.2597,                 loss: nan
agent1:                 episode reward: -0.2597,                 loss: 0.1614
Episode: 8131/30000 (27.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4339s / 308.5521 s
agent0:                 episode reward: 0.0500,                 loss: nan
agent1:                 episode reward: -0.0500,                 loss: 0.1595
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 308.9733 s
agent0:                 episode reward: 0.1084,                 loss: nan
agent1:                 episode reward: -0.1084,                 loss: 0.1584
Episode: 8151/30000 (27.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4136s / 309.3869 s
agent0:                 episode reward: 0.3032,                 loss: nan
agent1:                 episode reward: -0.3032,                 loss: 0.1580
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4136s / 309.8005 s
agent0:                 episode reward: -0.3165,                 loss: nan
agent1:                 episode reward: 0.3165,                 loss: 0.1593
Episode: 8171/30000 (27.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4213s / 310.2218 s
agent0:                 episode reward: -0.6253,                 loss: nan
agent1:                 episode reward: 0.6253,                 loss: 0.1586
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4494s / 310.6711 s
agent0:                 episode reward: -0.1921,                 loss: nan
agent1:                 episode reward: 0.1921,                 loss: 0.1602
Episode: 8191/30000 (27.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4338s / 311.1049 s
agent0:                 episode reward: -0.4191,                 loss: nan
agent1:                 episode reward: 0.4191,                 loss: 0.1620
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4018s / 311.5067 s
agent0:                 episode reward: -0.3581,                 loss: nan
agent1:                 episode reward: 0.3581,                 loss: 0.1601
Episode: 8211/30000 (27.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3830s / 311.8897 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.1616
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 312.2757 s
agent0:                 episode reward: 0.0642,                 loss: nan
agent1:                 episode reward: -0.0642,                 loss: 0.1598
Episode: 8231/30000 (27.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 312.6619 s
agent0:                 episode reward: -0.3461,                 loss: nan
agent1:                 episode reward: 0.3461,                 loss: 0.1604
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3982s / 313.0601 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.1598
Episode: 8251/30000 (27.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3985s / 313.4586 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.1573
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4144s / 313.8731 s
agent0:                 episode reward: 0.0209,                 loss: nan
agent1:                 episode reward: -0.0209,                 loss: 0.1601
Episode: 8271/30000 (27.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4103s / 314.2834 s
agent0:                 episode reward: -0.1693,                 loss: nan
agent1:                 episode reward: 0.1693,                 loss: 0.1578
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3923s / 314.6757 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.1594
Episode: 8291/30000 (27.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3914s / 315.0670 s
agent0:                 episode reward: -0.3091,                 loss: nan
agent1:                 episode reward: 0.3091,                 loss: 0.1592
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3948s / 315.4618 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1602
Episode: 8311/30000 (27.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3864s / 315.8481 s
agent0:                 episode reward: -0.4881,                 loss: nan
agent1:                 episode reward: 0.4881,                 loss: 0.1592
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 316.2396 s
agent0:                 episode reward: -0.2933,                 loss: nan
agent1:                 episode reward: 0.2933,                 loss: 0.1612
Episode: 8331/30000 (27.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3976s / 316.6372 s
agent0:                 episode reward: 0.5534,                 loss: nan
agent1:                 episode reward: -0.5534,                 loss: 0.1587
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3994s / 317.0366 s
agent0:                 episode reward: -0.7500,                 loss: nan
agent1:                 episode reward: 0.7500,                 loss: 0.1583
Episode: 8351/30000 (27.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4257s / 317.4623 s
agent0:                 episode reward: -0.0847,                 loss: nan
agent1:                 episode reward: 0.0847,                 loss: 0.1600
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4011s / 317.8634 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.1584
Episode: 8371/30000 (27.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3977s / 318.2611 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.1606
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3941s / 318.6552 s
agent0:                 episode reward: -0.3469,                 loss: nan
agent1:                 episode reward: 0.3469,                 loss: 0.1566
Episode: 8391/30000 (27.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4000s / 319.0551 s
agent0:                 episode reward: -0.6113,                 loss: nan
agent1:                 episode reward: 0.6113,                 loss: 0.1585
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4102s / 319.4654 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1601
Episode: 8411/30000 (28.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4209s / 319.8863 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.1593
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4371s / 320.3233 s
agent0:                 episode reward: -0.2044,                 loss: nan
agent1:                 episode reward: 0.2044,                 loss: 0.1607
Episode: 8431/30000 (28.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4143s / 320.7376 s
agent0:                 episode reward: 0.3083,                 loss: nan
agent1:                 episode reward: -0.3083,                 loss: 0.1589
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4032s / 321.1408 s
agent0:                 episode reward: -0.6131,                 loss: nan
agent1:                 episode reward: 0.6131,                 loss: 0.1589
Episode: 8451/30000 (28.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 321.5400 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.1582
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4161s / 321.9561 s
agent0:                 episode reward: -0.0088,                 loss: nan
agent1:                 episode reward: 0.0088,                 loss: 0.1581
Episode: 8471/30000 (28.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 322.3491 s
agent0:                 episode reward: -0.5235,                 loss: nan
agent1:                 episode reward: 0.5235,                 loss: 0.1562
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3876s / 322.7367 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.1581
Episode: 8491/30000 (28.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3919s / 323.1285 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1574
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 323.5419 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.1599
Episode: 8511/30000 (28.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3966s / 323.9384 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.1586
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3938s / 324.3323 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.1575
Episode: 8531/30000 (28.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3902s / 324.7225 s
agent0:                 episode reward: -0.5190,                 loss: nan
agent1:                 episode reward: 0.5190,                 loss: 0.1608
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3865s / 325.1090 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.1579
Episode: 8551/30000 (28.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3848s / 325.4938 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: 0.1626
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3841s / 325.8779 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1642
Episode: 8571/30000 (28.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3939s / 326.2718 s
agent0:                 episode reward: -0.8864,                 loss: nan
agent1:                 episode reward: 0.8864,                 loss: 0.1614
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4229s / 326.6947 s
agent0:                 episode reward: -0.0271,                 loss: nan
agent1:                 episode reward: 0.0271,                 loss: 0.1611
Episode: 8591/30000 (28.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 327.1079 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1621
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4144s / 327.5223 s
agent0:                 episode reward: -0.0169,                 loss: nan
agent1:                 episode reward: 0.0169,                 loss: 0.1641
Episode: 8611/30000 (28.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4123s / 327.9346 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.1629
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4129s / 328.3475 s
agent0:                 episode reward: -0.5193,                 loss: nan
agent1:                 episode reward: 0.5193,                 loss: 0.1606
Episode: 8631/30000 (28.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 328.7606 s
agent0:                 episode reward: -0.1905,                 loss: nan
agent1:                 episode reward: 0.1905,                 loss: 0.1609
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4016s / 329.1622 s
agent0:                 episode reward: 0.0307,                 loss: nan
agent1:                 episode reward: -0.0307,                 loss: 0.1605
Episode: 8651/30000 (28.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4226s / 329.5848 s
agent0:                 episode reward: 0.1252,                 loss: nan
agent1:                 episode reward: -0.1252,                 loss: 0.1605
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4092s / 329.9940 s
agent0:                 episode reward: 0.1089,                 loss: nan
agent1:                 episode reward: -0.1089,                 loss: 0.1597
Episode: 8671/30000 (28.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4343s / 330.4284 s
agent0:                 episode reward: 0.2562,                 loss: nan
agent1:                 episode reward: -0.2562,                 loss: 0.1611
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4126s / 330.8409 s
agent0:                 episode reward: 0.0938,                 loss: nan
agent1:                 episode reward: -0.0938,                 loss: 0.1621
Episode: 8691/30000 (28.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4050s / 331.2460 s
agent0:                 episode reward: -0.5040,                 loss: nan
agent1:                 episode reward: 0.5040,                 loss: 0.1618
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 331.6545 s
agent0:                 episode reward: -0.0738,                 loss: nan
agent1:                 episode reward: 0.0738,                 loss: 0.1615
Episode: 8711/30000 (29.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4050s / 332.0595 s
agent0:                 episode reward: 0.3992,                 loss: nan
agent1:                 episode reward: -0.3992,                 loss: 0.1639
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4128s / 332.4723 s
agent0:                 episode reward: -0.6339,                 loss: nan
agent1:                 episode reward: 0.6339,                 loss: 0.1606
Episode: 8731/30000 (29.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4238s / 332.8961 s
agent0:                 episode reward: -0.5096,                 loss: nan
agent1:                 episode reward: 0.5096,                 loss: 0.1645
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4139s / 333.3100 s
agent0:                 episode reward: -0.4450,                 loss: nan
agent1:                 episode reward: 0.4450,                 loss: 0.1608
Episode: 8751/30000 (29.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4114s / 333.7214 s
agent0:                 episode reward: 0.1657,                 loss: nan
agent1:                 episode reward: -0.1657,                 loss: 0.1621
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 334.1349 s
agent0:                 episode reward: -0.3442,                 loss: nan
agent1:                 episode reward: 0.3442,                 loss: 0.1625
Episode: 8771/30000 (29.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4087s / 334.5436 s
agent0:                 episode reward: 0.1783,                 loss: nan
agent1:                 episode reward: -0.1783,                 loss: 0.1636
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4058s / 334.9494 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1622
Episode: 8791/30000 (29.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3922s / 335.3416 s
agent0:                 episode reward: -0.5028,                 loss: nan
agent1:                 episode reward: 0.5028,                 loss: 0.1634
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4075s / 335.7491 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.1625
Episode: 8811/30000 (29.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 336.1384 s
agent0:                 episode reward: -0.1050,                 loss: nan
agent1:                 episode reward: 0.1050,                 loss: 0.1629
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3965s / 336.5349 s
agent0:                 episode reward: 0.0369,                 loss: nan
agent1:                 episode reward: -0.0369,                 loss: 0.1629
Episode: 8831/30000 (29.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3997s / 336.9346 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.1615
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3974s / 337.3320 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1605
Episode: 8851/30000 (29.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4044s / 337.7364 s
agent0:                 episode reward: -0.0127,                 loss: nan
agent1:                 episode reward: 0.0127,                 loss: 0.1595
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3947s / 338.1311 s
agent0:                 episode reward: 0.5488,                 loss: nan
agent1:                 episode reward: -0.5488,                 loss: 0.1612
Episode: 8871/30000 (29.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4460s / 338.5771 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.1631
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4221s / 338.9991 s
agent0:                 episode reward: -0.2890,                 loss: nan
agent1:                 episode reward: 0.2890,                 loss: 0.1640
Episode: 8891/30000 (29.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4049s / 339.4041 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.1636
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4060s / 339.8101 s
agent0:                 episode reward: -1.0399,                 loss: nan
agent1:                 episode reward: 1.0399,                 loss: 0.1644
Episode: 8911/30000 (29.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4093s / 340.2194 s
agent0:                 episode reward: -0.2254,                 loss: nan
agent1:                 episode reward: 0.2254,                 loss: 0.1655
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4092s / 340.6286 s
agent0:                 episode reward: 0.2849,                 loss: nan
agent1:                 episode reward: -0.2849,                 loss: 0.1632
Episode: 8931/30000 (29.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4055s / 341.0341 s
agent0:                 episode reward: 0.0004,                 loss: nan
agent1:                 episode reward: -0.0004,                 loss: 0.1627
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3894s / 341.4236 s
agent0:                 episode reward: -0.2027,                 loss: nan
agent1:                 episode reward: 0.2027,                 loss: 0.1609
Episode: 8951/30000 (29.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 341.8427 s
agent0:                 episode reward: -0.2955,                 loss: nan
agent1:                 episode reward: 0.2955,                 loss: 0.1626
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3923s / 342.2350 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.1659
Episode: 8971/30000 (29.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3881s / 342.6231 s
agent0:                 episode reward: 0.0321,                 loss: nan
agent1:                 episode reward: -0.0321,                 loss: 0.1627
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3930s / 343.0162 s
agent0:                 episode reward: -0.6726,                 loss: nan
agent1:                 episode reward: 0.6726,                 loss: 0.1652
Episode: 8991/30000 (29.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3868s / 343.4030 s
agent0:                 episode reward: 0.3347,                 loss: nan
agent1:                 episode reward: -0.3347,                 loss: 0.1618
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3901s / 343.7931 s
agent0:                 episode reward: 0.3268,                 loss: nan
agent1:                 episode reward: -0.3268,                 loss: 0.1619
Episode: 9011/30000 (30.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3942s / 344.1873 s
agent0:                 episode reward: 0.1990,                 loss: nan
agent1:                 episode reward: -0.1990,                 loss: 0.1635
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3855s / 344.5728 s
agent0:                 episode reward: -0.7652,                 loss: nan
agent1:                 episode reward: 0.7652,                 loss: 0.1661
Episode: 9031/30000 (30.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4107s / 344.9835 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.1608
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3949s / 345.3784 s
agent0:                 episode reward: -0.7753,                 loss: nan
agent1:                 episode reward: 0.7753,                 loss: 0.1622
Episode: 9051/30000 (30.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4199s / 345.7983 s
agent0:                 episode reward: -0.7477,                 loss: nan
agent1:                 episode reward: 0.7477,                 loss: 0.1602
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4217s / 346.2200 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.1637
Episode: 9071/30000 (30.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4257s / 346.6458 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.1640
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4223s / 347.0681 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1631
Episode: 9091/30000 (30.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4017s / 347.4698 s
agent0:                 episode reward: -0.3090,                 loss: nan
agent1:                 episode reward: 0.3090,                 loss: 0.1629
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4124s / 347.8821 s
agent0:                 episode reward: 0.0479,                 loss: nan
agent1:                 episode reward: -0.0479,                 loss: 0.1626
Episode: 9111/30000 (30.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3990s / 348.2811 s
agent0:                 episode reward: -0.5174,                 loss: nan
agent1:                 episode reward: 0.5174,                 loss: 0.1640
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4007s / 348.6818 s
agent0:                 episode reward: -0.7489,                 loss: nan
agent1:                 episode reward: 0.7489,                 loss: 0.1608
Episode: 9131/30000 (30.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3969s / 349.0787 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.1619
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4025s / 349.4813 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.1643
Episode: 9151/30000 (30.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 349.8772 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.1626
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3980s / 350.2752 s
agent0:                 episode reward: 0.4777,                 loss: nan
agent1:                 episode reward: -0.4777,                 loss: 0.1614
Episode: 9171/30000 (30.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4006s / 350.6758 s
agent0:                 episode reward: -0.3327,                 loss: nan
agent1:                 episode reward: 0.3327,                 loss: 0.1631
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4333s / 351.1092 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.1635
Episode: 9191/30000 (30.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4040s / 351.5131 s
agent0:                 episode reward: -0.1074,                 loss: nan
agent1:                 episode reward: 0.1074,                 loss: 0.1633
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3998s / 351.9129 s
agent0:                 episode reward: -0.0595,                 loss: nan
agent1:                 episode reward: 0.0595,                 loss: 0.1616
Episode: 9211/30000 (30.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4020s / 352.3149 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1636
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4214s / 352.7363 s
agent0:                 episode reward: -0.0950,                 loss: nan
agent1:                 episode reward: 0.0950,                 loss: 0.1632
Episode: 9231/30000 (30.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4277s / 353.1640 s
agent0:                 episode reward: -0.5872,                 loss: nan
agent1:                 episode reward: 0.5872,                 loss: 0.1627
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4249s / 353.5889 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.1613
Episode: 9251/30000 (30.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4358s / 354.0247 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.1650
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4253s / 354.4499 s
agent0:                 episode reward: 0.2734,                 loss: nan
agent1:                 episode reward: -0.2734,                 loss: 0.1620
Episode: 9271/30000 (30.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4210s / 354.8709 s
agent0:                 episode reward: -0.1238,                 loss: nan
agent1:                 episode reward: 0.1238,                 loss: 0.1639
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4481s / 355.3190 s
agent0:                 episode reward: -0.0815,                 loss: nan
agent1:                 episode reward: 0.0815,                 loss: 0.1615
Episode: 9291/30000 (30.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4059s / 355.7249 s
agent0:                 episode reward: 0.0340,                 loss: nan
agent1:                 episode reward: -0.0340,                 loss: 0.1635
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4080s / 356.1330 s
agent0:                 episode reward: -0.2001,                 loss: nan
agent1:                 episode reward: 0.2001,                 loss: 0.1625
Episode: 9311/30000 (31.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4081s / 356.5411 s
agent0:                 episode reward: -0.2707,                 loss: nan
agent1:                 episode reward: 0.2707,                 loss: 0.1634
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 356.9588 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1619
Episode: 9331/30000 (31.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4324s / 357.3912 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.1609
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4047s / 357.7958 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.1619
Episode: 9351/30000 (31.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4093s / 358.2051 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.1608
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4053s / 358.6105 s
agent0:                 episode reward: -0.2137,                 loss: nan
agent1:                 episode reward: 0.2137,                 loss: 0.1641
Episode: 9371/30000 (31.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4023s / 359.0128 s
agent0:                 episode reward: -0.7797,                 loss: nan
agent1:                 episode reward: 0.7797,                 loss: 0.1631
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4021s / 359.4149 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.1629
Episode: 9391/30000 (31.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4032s / 359.8181 s
agent0:                 episode reward: -0.2647,                 loss: nan
agent1:                 episode reward: 0.2647,                 loss: 0.1620
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4433s / 360.2614 s
agent0:                 episode reward: -0.1469,                 loss: nan
agent1:                 episode reward: 0.1469,                 loss: 0.1616
Episode: 9411/30000 (31.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4084s / 360.6698 s
agent0:                 episode reward: 0.0268,                 loss: nan
agent1:                 episode reward: -0.0268,                 loss: 0.1644
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3901s / 361.0599 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: 0.1611
Episode: 9431/30000 (31.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3943s / 361.4543 s
agent0:                 episode reward: 0.2965,                 loss: nan
agent1:                 episode reward: -0.2965,                 loss: 0.1639
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 361.8458 s
agent0:                 episode reward: -0.4961,                 loss: nan
agent1:                 episode reward: 0.4961,                 loss: 0.1619
Episode: 9451/30000 (31.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3891s / 362.2349 s
agent0:                 episode reward: -0.1186,                 loss: nan
agent1:                 episode reward: 0.1186,                 loss: 0.1628
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3883s / 362.6232 s
agent0:                 episode reward: -0.2622,                 loss: nan
agent1:                 episode reward: 0.2622,                 loss: 0.1630
Episode: 9471/30000 (31.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3926s / 363.0158 s
agent0:                 episode reward: -0.7466,                 loss: nan
agent1:                 episode reward: 0.7466,                 loss: 0.1622
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 363.4360 s
agent0:                 episode reward: 0.1498,                 loss: nan
agent1:                 episode reward: -0.1498,                 loss: 0.1652
Episode: 9491/30000 (31.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4076s / 363.8437 s
agent0:                 episode reward: -0.4151,                 loss: nan
agent1:                 episode reward: 0.4151,                 loss: 0.1620
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 364.2393 s
agent0:                 episode reward: 0.0881,                 loss: nan
agent1:                 episode reward: -0.0881,                 loss: 0.1620
Episode: 9511/30000 (31.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3945s / 364.6337 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.1624
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3917s / 365.0255 s
agent0:                 episode reward: -0.2370,                 loss: nan
agent1:                 episode reward: 0.2370,                 loss: 0.1620
Episode: 9531/30000 (31.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3985s / 365.4240 s
agent0:                 episode reward: 0.0656,                 loss: nan
agent1:                 episode reward: -0.0656,                 loss: 0.1617
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3916s / 365.8156 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.1639
Episode: 9551/30000 (31.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4050s / 366.2206 s
agent0:                 episode reward: 0.6634,                 loss: nan
agent1:                 episode reward: -0.6634,                 loss: 0.1619
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4115s / 366.6321 s
agent0:                 episode reward: -0.7670,                 loss: nan
agent1:                 episode reward: 0.7670,                 loss: 0.1582
Episode: 9571/30000 (31.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4070s / 367.0391 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.1596
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4043s / 367.4434 s
agent0:                 episode reward: -0.3630,                 loss: nan
agent1:                 episode reward: 0.3630,                 loss: 0.1594
Episode: 9591/30000 (31.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4024s / 367.8458 s
agent0:                 episode reward: -0.3271,                 loss: nan
agent1:                 episode reward: 0.3271,                 loss: 0.1596
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3937s / 368.2395 s
agent0:                 episode reward: -0.2391,                 loss: nan
agent1:                 episode reward: 0.2391,                 loss: 0.1579
Episode: 9611/30000 (32.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 368.6310 s
agent0:                 episode reward: 0.2783,                 loss: nan
agent1:                 episode reward: -0.2783,                 loss: 0.1609
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3917s / 369.0226 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.1632
Episode: 9631/30000 (32.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4225s / 369.4451 s
agent0:                 episode reward: -0.0728,                 loss: nan
agent1:                 episode reward: 0.0728,                 loss: 0.1606
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4076s / 369.8527 s
agent0:                 episode reward: 0.1019,                 loss: nan
agent1:                 episode reward: -0.1019,                 loss: 0.1603
Episode: 9651/30000 (32.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4076s / 370.2603 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: 0.1616
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 370.6689 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.1611
Episode: 9671/30000 (32.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4152s / 371.0841 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.1610
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4120s / 371.4961 s
agent0:                 episode reward: -1.0508,                 loss: nan
agent1:                 episode reward: 1.0508,                 loss: 0.1614
Episode: 9691/30000 (32.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4411s / 371.9372 s
agent0:                 episode reward: -0.1092,                 loss: nan
agent1:                 episode reward: 0.1092,                 loss: 0.1609
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4326s / 372.3698 s
agent0:                 episode reward: -0.2275,                 loss: nan
agent1:                 episode reward: 0.2275,                 loss: 0.1577
Episode: 9711/30000 (32.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 372.7973 s
agent0:                 episode reward: -0.4859,                 loss: nan
agent1:                 episode reward: 0.4859,                 loss: 0.1576
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4188s / 373.2161 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1621
Episode: 9731/30000 (32.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4346s / 373.6507 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.1633
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4323s / 374.0830 s
agent0:                 episode reward: -0.0070,                 loss: nan
agent1:                 episode reward: 0.0070,                 loss: 0.1591
Episode: 9751/30000 (32.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4178s / 374.5009 s
agent0:                 episode reward: -0.4641,                 loss: nan
agent1:                 episode reward: 0.4641,                 loss: 0.1620
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4089s / 374.9098 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: 0.1591
Episode: 9771/30000 (32.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4125s / 375.3222 s
agent0:                 episode reward: 0.1704,                 loss: nan
agent1:                 episode reward: -0.1704,                 loss: 0.1581
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4211s / 375.7434 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.1596
Episode: 9791/30000 (32.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4066s / 376.1500 s
agent0:                 episode reward: -0.3607,                 loss: nan
agent1:                 episode reward: 0.3607,                 loss: 0.1631
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 376.5718 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.1594
Episode: 9811/30000 (32.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4124s / 376.9842 s
agent0:                 episode reward: -0.1654,                 loss: nan
agent1:                 episode reward: 0.1654,                 loss: 0.1605
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4123s / 377.3965 s
agent0:                 episode reward: -0.2092,                 loss: nan
agent1:                 episode reward: 0.2092,                 loss: 0.1613
Episode: 9831/30000 (32.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 377.7894 s
agent0:                 episode reward: -0.5919,                 loss: nan
agent1:                 episode reward: 0.5919,                 loss: 0.1585
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3996s / 378.1890 s
agent0:                 episode reward: -0.7478,                 loss: nan
agent1:                 episode reward: 0.7478,                 loss: 0.1607
Episode: 9851/30000 (32.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4140s / 378.6030 s
agent0:                 episode reward: -0.0374,                 loss: nan
agent1:                 episode reward: 0.0374,                 loss: 0.1611
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4015s / 379.0044 s
agent0:                 episode reward: -0.0075,                 loss: nan
agent1:                 episode reward: 0.0075,                 loss: 0.1607
Episode: 9871/30000 (32.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3947s / 379.3991 s
agent0:                 episode reward: -0.1031,                 loss: nan
agent1:                 episode reward: 0.1031,                 loss: 0.1605
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3971s / 379.7962 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1599
Episode: 9891/30000 (32.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4073s / 380.2035 s
agent0:                 episode reward: -0.5350,                 loss: nan
agent1:                 episode reward: 0.5350,                 loss: 0.1572
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4065s / 380.6100 s
agent0:                 episode reward: 0.1432,                 loss: nan
agent1:                 episode reward: -0.1432,                 loss: 0.1611
Episode: 9911/30000 (33.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3996s / 381.0096 s
agent0:                 episode reward: -0.1650,                 loss: nan
agent1:                 episode reward: 0.1650,                 loss: 0.1578
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4142s / 381.4238 s
agent0:                 episode reward: -0.9723,                 loss: nan
agent1:                 episode reward: 0.9723,                 loss: 0.1596
Episode: 9931/30000 (33.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4418s / 381.8656 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1585
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4125s / 382.2781 s
agent0:                 episode reward: -0.5520,                 loss: nan
agent1:                 episode reward: 0.5520,                 loss: 0.1582
Episode: 9951/30000 (33.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4114s / 382.6894 s
agent0:                 episode reward: -0.3721,                 loss: nan
agent1:                 episode reward: 0.3721,                 loss: 0.1582
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4149s / 383.1043 s
agent0:                 episode reward: -0.2439,                 loss: nan
agent1:                 episode reward: 0.2439,                 loss: 0.1594
Episode: 9971/30000 (33.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4098s / 383.5141 s
agent0:                 episode reward: 0.0428,                 loss: nan
agent1:                 episode reward: -0.0428,                 loss: 0.1576
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4067s / 383.9208 s
agent0:                 episode reward: -0.1035,                 loss: nan
agent1:                 episode reward: 0.1035,                 loss: 0.1574
Episode: 9991/30000 (33.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4038s / 384.3245 s
agent0:                 episode reward: 0.0630,                 loss: nan
agent1:                 episode reward: -0.0630,                 loss: 0.1593
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4300s / 384.7546 s
agent0:                 episode reward: -0.0871,                 loss: nan
agent1:                 episode reward: 0.0871,                 loss: 0.1596
Episode: 10011/30000 (33.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4258s / 385.1803 s
agent0:                 episode reward: -0.0571,                 loss: nan
agent1:                 episode reward: 0.0571,                 loss: 0.1604
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4190s / 385.5993 s
agent0:                 episode reward: -0.6941,                 loss: nan
agent1:                 episode reward: 0.6941,                 loss: 0.1603
Episode: 10031/30000 (33.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4239s / 386.0233 s
agent0:                 episode reward: -0.3386,                 loss: nan
agent1:                 episode reward: 0.3386,                 loss: 0.1592
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4240s / 386.4472 s
agent0:                 episode reward: -0.1781,                 loss: nan
agent1:                 episode reward: 0.1781,                 loss: 0.1596
Episode: 10051/30000 (33.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4233s / 386.8705 s
agent0:                 episode reward: -0.2912,                 loss: nan
agent1:                 episode reward: 0.2912,                 loss: 0.1603
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 387.2956 s
agent0:                 episode reward: 0.0824,                 loss: nan
agent1:                 episode reward: -0.0824,                 loss: 0.1601
Episode: 10071/30000 (33.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4229s / 387.7185 s
agent0:                 episode reward: 0.5803,                 loss: nan
agent1:                 episode reward: -0.5803,                 loss: 0.1606
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4214s / 388.1400 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.1571
Episode: 10091/30000 (33.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4460s / 388.5860 s
agent0:                 episode reward: 0.1192,                 loss: nan
agent1:                 episode reward: -0.1192,                 loss: 0.1552
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4331s / 389.0191 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.1570
Episode: 10111/30000 (33.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4261s / 389.4452 s
agent0:                 episode reward: 0.0788,                 loss: nan
agent1:                 episode reward: -0.0788,                 loss: 0.1603
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4224s / 389.8676 s
agent0:                 episode reward: 0.1842,                 loss: nan
agent1:                 episode reward: -0.1842,                 loss: 0.1567
Episode: 10131/30000 (33.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4098s / 390.2774 s
agent0:                 episode reward: -0.4731,                 loss: nan
agent1:                 episode reward: 0.4731,                 loss: 0.1616
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4293s / 390.7067 s
agent0:                 episode reward: -0.2438,                 loss: nan
agent1:                 episode reward: 0.2438,                 loss: 0.1593
Episode: 10151/30000 (33.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 391.1200 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.1615
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4145s / 391.5345 s
agent0:                 episode reward: -0.5617,                 loss: nan
agent1:                 episode reward: 0.5617,                 loss: 0.1571
Episode: 10171/30000 (33.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4157s / 391.9501 s
agent0:                 episode reward: -0.2934,                 loss: nan
agent1:                 episode reward: 0.2934,                 loss: 0.1590
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4137s / 392.3638 s
agent0:                 episode reward: 0.3215,                 loss: nan
agent1:                 episode reward: -0.3215,                 loss: 0.1605
Episode: 10191/30000 (33.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3942s / 392.7580 s
agent0:                 episode reward: -0.4763,                 loss: nan
agent1:                 episode reward: 0.4763,                 loss: 0.1583
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4065s / 393.1645 s
agent0:                 episode reward: -0.8216,                 loss: nan
agent1:                 episode reward: 0.8216,                 loss: 0.1608
Episode: 10211/30000 (34.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4284s / 393.5929 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.1600
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4290s / 394.0219 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.1589
Episode: 10231/30000 (34.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4181s / 394.4400 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.1601
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4213s / 394.8613 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.1619
Episode: 10251/30000 (34.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4085s / 395.2698 s
agent0:                 episode reward: -0.3191,                 loss: nan
agent1:                 episode reward: 0.3191,                 loss: 0.1599
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3957s / 395.6655 s
agent0:                 episode reward: -1.1998,                 loss: nan
agent1:                 episode reward: 1.1998,                 loss: 0.1587
Episode: 10271/30000 (34.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3966s / 396.0621 s
agent0:                 episode reward: -0.3708,                 loss: nan
agent1:                 episode reward: 0.3708,                 loss: 0.1600
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4022s / 396.4643 s
agent0:                 episode reward: -0.6832,                 loss: nan
agent1:                 episode reward: 0.6832,                 loss: 0.1614
Episode: 10291/30000 (34.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4447s / 396.9090 s
agent0:                 episode reward: 0.4490,                 loss: nan
agent1:                 episode reward: -0.4490,                 loss: 0.1605
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3984s / 397.3074 s
agent0:                 episode reward: -0.4596,                 loss: nan
agent1:                 episode reward: 0.4596,                 loss: 0.1610
Episode: 10311/30000 (34.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4054s / 397.7127 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.1606
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3978s / 398.1105 s
agent0:                 episode reward: -0.3827,                 loss: nan
agent1:                 episode reward: 0.3827,                 loss: 0.1597
Episode: 10331/30000 (34.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 398.5064 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.1608
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 398.9056 s
agent0:                 episode reward: 0.0920,                 loss: nan
agent1:                 episode reward: -0.0920,                 loss: 0.1617
Episode: 10351/30000 (34.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 399.2986 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1599
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4099s / 399.7085 s
agent0:                 episode reward: -0.0810,                 loss: nan
agent1:                 episode reward: 0.0810,                 loss: 0.1583
Episode: 10371/30000 (34.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3978s / 400.1063 s
agent0:                 episode reward: -0.5683,                 loss: nan
agent1:                 episode reward: 0.5683,                 loss: 0.1583
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3982s / 400.5045 s
agent0:                 episode reward: -0.2262,                 loss: nan
agent1:                 episode reward: 0.2262,                 loss: 0.1594
Episode: 10391/30000 (34.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4189s / 400.9234 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.1610
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 401.3409 s
agent0:                 episode reward: -0.3751,                 loss: nan
agent1:                 episode reward: 0.3751,                 loss: 0.1603
Episode: 10411/30000 (34.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4108s / 401.7517 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.1593
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4204s / 402.1721 s
agent0:                 episode reward: -0.6293,                 loss: nan
agent1:                 episode reward: 0.6293,                 loss: 0.1601
Episode: 10431/30000 (34.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 402.5879 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1613
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4411s / 403.0291 s
agent0:                 episode reward: 0.4317,                 loss: nan
agent1:                 episode reward: -0.4317,                 loss: 0.1606
Episode: 10451/30000 (34.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4168s / 403.4459 s
agent0:                 episode reward: -0.6780,                 loss: nan
agent1:                 episode reward: 0.6780,                 loss: 0.1585
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 403.8655 s
agent0:                 episode reward: -0.0381,                 loss: nan
agent1:                 episode reward: 0.0381,                 loss: 0.1643
Episode: 10471/30000 (34.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4036s / 404.2691 s
agent0:                 episode reward: -0.1271,                 loss: nan
agent1:                 episode reward: 0.1271,                 loss: 0.1577
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3975s / 404.6666 s
agent0:                 episode reward: -0.1364,                 loss: nan
agent1:                 episode reward: 0.1364,                 loss: 0.1620
Episode: 10491/30000 (34.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3973s / 405.0638 s
agent0:                 episode reward: -0.0862,                 loss: nan
agent1:                 episode reward: 0.0862,                 loss: 0.1608
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4157s / 405.4796 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1581
Episode: 10511/30000 (35.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3909s / 405.8705 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.1601
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4069s / 406.2774 s
agent0:                 episode reward: 0.0166,                 loss: nan
agent1:                 episode reward: -0.0166,                 loss: 0.1615
Episode: 10531/30000 (35.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4024s / 406.6798 s
agent0:                 episode reward: 0.0185,                 loss: nan
agent1:                 episode reward: -0.0185,                 loss: 0.1601
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4063s / 407.0861 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.1586
Episode: 10551/30000 (35.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4056s / 407.4918 s
agent0:                 episode reward: -0.6640,                 loss: nan
agent1:                 episode reward: 0.6640,                 loss: 0.1620
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4026s / 407.8944 s
agent0:                 episode reward: -0.9381,                 loss: nan
agent1:                 episode reward: 0.9381,                 loss: 0.1616
Episode: 10571/30000 (35.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4198s / 408.3142 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.1630
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4449s / 408.7591 s
agent0:                 episode reward: -0.0863,                 loss: nan
agent1:                 episode reward: 0.0863,                 loss: 0.1604
Episode: 10591/30000 (35.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4126s / 409.1716 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: 0.1577
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4161s / 409.5877 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.1600
Episode: 10611/30000 (35.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4106s / 409.9983 s
agent0:                 episode reward: 0.0142,                 loss: nan
agent1:                 episode reward: -0.0142,                 loss: 0.1625
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4122s / 410.4106 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.1625
Episode: 10631/30000 (35.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3993s / 410.8098 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1611
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3920s / 411.2019 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.1591
Episode: 10651/30000 (35.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4294s / 411.6313 s
agent0:                 episode reward: 0.0995,                 loss: nan
agent1:                 episode reward: -0.0995,                 loss: 0.1592
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4152s / 412.0465 s
agent0:                 episode reward: -0.9538,                 loss: nan
agent1:                 episode reward: 0.9538,                 loss: 0.1620
Episode: 10671/30000 (35.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4187s / 412.4653 s
agent0:                 episode reward: -0.0992,                 loss: nan
agent1:                 episode reward: 0.0992,                 loss: 0.1595
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 412.8811 s
agent0:                 episode reward: 0.4492,                 loss: nan
agent1:                 episode reward: -0.4492,                 loss: 0.1620
Episode: 10691/30000 (35.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 413.3113 s
agent0:                 episode reward: -0.1729,                 loss: nan
agent1:                 episode reward: 0.1729,                 loss: 0.1606
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4059s / 413.7172 s
agent0:                 episode reward: -1.0430,                 loss: nan
agent1:                 episode reward: 1.0430,                 loss: 0.1621
Episode: 10711/30000 (35.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4080s / 414.1252 s
agent0:                 episode reward: -0.6346,                 loss: nan
agent1:                 episode reward: 0.6346,                 loss: 0.1611
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4240s / 414.5492 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.1645
Episode: 10731/30000 (35.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4140s / 414.9631 s
agent0:                 episode reward: -0.0159,                 loss: nan
agent1:                 episode reward: 0.0159,                 loss: 0.1606
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4082s / 415.3713 s
agent0:                 episode reward: -0.2639,                 loss: nan
agent1:                 episode reward: 0.2639,                 loss: 0.1608
Episode: 10751/30000 (35.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4161s / 415.7875 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.1616
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4208s / 416.2083 s
agent0:                 episode reward: -0.3138,                 loss: nan
agent1:                 episode reward: 0.3138,                 loss: 0.1601
Episode: 10771/30000 (35.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4185s / 416.6268 s
agent0:                 episode reward: -0.7721,                 loss: nan
agent1:                 episode reward: 0.7721,                 loss: 0.1622
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 417.0459 s
agent0:                 episode reward: -0.5491,                 loss: nan
agent1:                 episode reward: 0.5491,                 loss: 0.1625
Episode: 10791/30000 (35.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4207s / 417.4666 s
agent0:                 episode reward: -0.0238,                 loss: nan
agent1:                 episode reward: 0.0238,                 loss: 0.1608
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4205s / 417.8870 s
agent0:                 episode reward: -0.7733,                 loss: nan
agent1:                 episode reward: 0.7733,                 loss: 0.1606
Episode: 10811/30000 (36.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4178s / 418.3048 s
agent0:                 episode reward: 0.3773,                 loss: nan
agent1:                 episode reward: -0.3773,                 loss: 0.1599
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4128s / 418.7176 s
agent0:                 episode reward: -0.5702,                 loss: nan
agent1:                 episode reward: 0.5702,                 loss: 0.1618
Episode: 10831/30000 (36.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4151s / 419.1327 s
agent0:                 episode reward: -0.1847,                 loss: nan
agent1:                 episode reward: 0.1847,                 loss: 0.1611
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4179s / 419.5506 s
agent0:                 episode reward: -0.3284,                 loss: nan
agent1:                 episode reward: 0.3284,                 loss: 0.1592
Episode: 10851/30000 (36.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 419.9670 s
agent0:                 episode reward: -0.2572,                 loss: nan
agent1:                 episode reward: 0.2572,                 loss: 0.1590
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4037s / 420.3706 s
agent0:                 episode reward: -0.1940,                 loss: nan
agent1:                 episode reward: 0.1940,                 loss: 0.1610
Episode: 10871/30000 (36.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4243s / 420.7950 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.1609
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 421.2103 s
agent0:                 episode reward: 0.0780,                 loss: nan
agent1:                 episode reward: -0.0780,                 loss: 0.1613
Episode: 10891/30000 (36.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4345s / 421.6448 s
agent0:                 episode reward: -0.1723,                 loss: nan
agent1:                 episode reward: 0.1723,                 loss: 0.1561
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4015s / 422.0463 s
agent0:                 episode reward: -0.5713,                 loss: nan
agent1:                 episode reward: 0.5713,                 loss: 0.1571
Episode: 10911/30000 (36.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4080s / 422.4543 s
agent0:                 episode reward: -0.1458,                 loss: nan
agent1:                 episode reward: 0.1458,                 loss: 0.1598
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4050s / 422.8594 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.1584
Episode: 10931/30000 (36.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4178s / 423.2772 s
agent0:                 episode reward: -0.0163,                 loss: nan
agent1:                 episode reward: 0.0163,                 loss: 0.1592
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4242s / 423.7014 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1579
Episode: 10951/30000 (36.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 424.1226 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.1575
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4115s / 424.5340 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.1578
Episode: 10971/30000 (36.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4078s / 424.9419 s
agent0:                 episode reward: -0.1661,                 loss: nan
agent1:                 episode reward: 0.1661,                 loss: 0.1585
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 425.3551 s
agent0:                 episode reward: -0.5241,                 loss: nan
agent1:                 episode reward: 0.5241,                 loss: 0.1572
Episode: 10991/30000 (36.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4097s / 425.7648 s
agent0:                 episode reward: -0.0755,                 loss: nan
agent1:                 episode reward: 0.0755,                 loss: 0.1584
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 426.1753 s
agent0:                 episode reward: 0.0042,                 loss: nan
agent1:                 episode reward: -0.0042,                 loss: 0.1584
Episode: 11011/30000 (36.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4143s / 426.5896 s
agent0:                 episode reward: -1.1492,                 loss: nan
agent1:                 episode reward: 1.1492,                 loss: 0.1590
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 427.0092 s
agent0:                 episode reward: -0.1328,                 loss: nan
agent1:                 episode reward: 0.1328,                 loss: 0.1596
Episode: 11031/30000 (36.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4070s / 427.4163 s
agent0:                 episode reward: -0.3325,                 loss: nan
agent1:                 episode reward: 0.3325,                 loss: 0.1599
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4070s / 427.8232 s
agent0:                 episode reward: -0.1754,                 loss: nan
agent1:                 episode reward: 0.1754,                 loss: 0.1578
Episode: 11051/30000 (36.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4214s / 428.2446 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.1580
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4084s / 428.6530 s
agent0:                 episode reward: 0.3332,                 loss: nan
agent1:                 episode reward: -0.3332,                 loss: 0.1604
Episode: 11071/30000 (36.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 429.0660 s
agent0:                 episode reward: 0.0004,                 loss: nan
agent1:                 episode reward: -0.0004,                 loss: 0.1604
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4025s / 429.4685 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.1560
Episode: 11091/30000 (36.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4158s / 429.8843 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: 0.1596
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4322s / 430.3165 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.1575
Episode: 11111/30000 (37.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 430.7464 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1613
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4284s / 431.1748 s
agent0:                 episode reward: -0.7841,                 loss: nan
agent1:                 episode reward: 0.7841,                 loss: 0.1609
Episode: 11131/30000 (37.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4194s / 431.5943 s
agent0:                 episode reward: -0.0360,                 loss: nan
agent1:                 episode reward: 0.0360,                 loss: 0.1582
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4206s / 432.0149 s
agent0:                 episode reward: 0.0510,                 loss: nan
agent1:                 episode reward: -0.0510,                 loss: 0.1571
Episode: 11151/30000 (37.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 432.4312 s
agent0:                 episode reward: -0.4452,                 loss: nan
agent1:                 episode reward: 0.4452,                 loss: 0.1575
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4132s / 432.8444 s
agent0:                 episode reward: -0.0911,                 loss: nan
agent1:                 episode reward: 0.0911,                 loss: 0.1586
Episode: 11171/30000 (37.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4219s / 433.2663 s
agent0:                 episode reward: -0.5096,                 loss: nan
agent1:                 episode reward: 0.5096,                 loss: 0.1584
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4119s / 433.6782 s
agent0:                 episode reward: -0.4169,                 loss: nan
agent1:                 episode reward: 0.4169,                 loss: 0.1584
Episode: 11191/30000 (37.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 434.0913 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.1599
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4084s / 434.4997 s
agent0:                 episode reward: -0.0441,                 loss: nan
agent1:                 episode reward: 0.0441,                 loss: 0.1597
Episode: 11211/30000 (37.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4276s / 434.9273 s
agent0:                 episode reward: -0.0171,                 loss: nan
agent1:                 episode reward: 0.0171,                 loss: 0.1589
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4289s / 435.3562 s
agent0:                 episode reward: -0.3208,                 loss: nan
agent1:                 episode reward: 0.3208,                 loss: 0.1587
Episode: 11231/30000 (37.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4285s / 435.7847 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.1592
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 436.2435 s
agent0:                 episode reward: -0.1751,                 loss: nan
agent1:                 episode reward: 0.1751,                 loss: 0.1594
Episode: 11251/30000 (37.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4084s / 436.6519 s
agent0:                 episode reward: -0.4477,                 loss: nan
agent1:                 episode reward: 0.4477,                 loss: 0.1608
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 437.0650 s
agent0:                 episode reward: -0.9471,                 loss: nan
agent1:                 episode reward: 0.9471,                 loss: 0.1622
Episode: 11271/30000 (37.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4136s / 437.4787 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.1577
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4123s / 437.8910 s
agent0:                 episode reward: -0.6148,                 loss: nan
agent1:                 episode reward: 0.6148,                 loss: 0.1605
Episode: 11291/30000 (37.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4281s / 438.3191 s
agent0:                 episode reward: -0.5560,                 loss: nan
agent1:                 episode reward: 0.5560,                 loss: 0.1587
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 438.7393 s
agent0:                 episode reward: -0.1258,                 loss: nan
agent1:                 episode reward: 0.1258,                 loss: 0.1590
Episode: 11311/30000 (37.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4361s / 439.1753 s
agent0:                 episode reward: 0.0555,                 loss: nan
agent1:                 episode reward: -0.0555,                 loss: 0.1596
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 439.5988 s
agent0:                 episode reward: -0.4845,                 loss: nan
agent1:                 episode reward: 0.4845,                 loss: 0.1608
Episode: 11331/30000 (37.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4204s / 440.0193 s
agent0:                 episode reward: -0.1187,                 loss: nan
agent1:                 episode reward: 0.1187,                 loss: 0.1598
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4250s / 440.4443 s
agent0:                 episode reward: -0.1261,                 loss: nan
agent1:                 episode reward: 0.1261,                 loss: 0.1611
Episode: 11351/30000 (37.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4154s / 440.8597 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.1595
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 441.2760 s
agent0:                 episode reward: -0.1006,                 loss: nan
agent1:                 episode reward: 0.1006,                 loss: 0.1594
Episode: 11371/30000 (37.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4121s / 441.6880 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.1597
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4364s / 442.1244 s
agent0:                 episode reward: 0.4650,                 loss: nan
agent1:                 episode reward: -0.4650,                 loss: 0.1606
Episode: 11391/30000 (37.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4203s / 442.5447 s
agent0:                 episode reward: -0.4372,                 loss: nan
agent1:                 episode reward: 0.4372,                 loss: 0.1594
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4139s / 442.9586 s
agent0:                 episode reward: 0.2573,                 loss: nan
agent1:                 episode reward: -0.2573,                 loss: 0.1598
Episode: 11411/30000 (38.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4141s / 443.3727 s
agent0:                 episode reward: 0.0180,                 loss: nan
agent1:                 episode reward: -0.0180,                 loss: 0.1598
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4101s / 443.7828 s
agent0:                 episode reward: 0.1007,                 loss: nan
agent1:                 episode reward: -0.1007,                 loss: 0.1611
Episode: 11431/30000 (38.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4120s / 444.1948 s
agent0:                 episode reward: -0.7324,                 loss: nan
agent1:                 episode reward: 0.7324,                 loss: 0.1615
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 444.6111 s
agent0:                 episode reward: -0.0279,                 loss: nan
agent1:                 episode reward: 0.0279,                 loss: 0.1611
Episode: 11451/30000 (38.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 445.0563 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.1598
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4525s / 445.5088 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.1599
Episode: 11471/30000 (38.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4372s / 445.9460 s
agent0:                 episode reward: -0.3449,                 loss: nan
agent1:                 episode reward: 0.3449,                 loss: 0.1597
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4345s / 446.3805 s
agent0:                 episode reward: -0.9080,                 loss: nan
agent1:                 episode reward: 0.9080,                 loss: 0.1624
Episode: 11491/30000 (38.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4669s / 446.8474 s
agent0:                 episode reward: -1.0173,                 loss: nan
agent1:                 episode reward: 1.0173,                 loss: 0.1597
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 447.2822 s
agent0:                 episode reward: -0.3630,                 loss: nan
agent1:                 episode reward: 0.3630,                 loss: 0.1586
Episode: 11511/30000 (38.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4365s / 447.7187 s
agent0:                 episode reward: 0.0556,                 loss: nan
agent1:                 episode reward: -0.0556,                 loss: 0.1618
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4530s / 448.1717 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: 0.1602
Episode: 11531/30000 (38.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4401s / 448.6118 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.1595
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4232s / 449.0350 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.1599
Episode: 11551/30000 (38.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4288s / 449.4638 s
agent0:                 episode reward: 0.1030,                 loss: nan
agent1:                 episode reward: -0.1030,                 loss: 0.1598
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4281s / 449.8919 s
agent0:                 episode reward: -0.0440,                 loss: nan
agent1:                 episode reward: 0.0440,                 loss: 0.1602
Episode: 11571/30000 (38.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 450.3093 s
agent0:                 episode reward: 0.3023,                 loss: nan
agent1:                 episode reward: -0.3023,                 loss: 0.1593
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4223s / 450.7317 s
agent0:                 episode reward: -0.3841,                 loss: nan
agent1:                 episode reward: 0.3841,                 loss: 0.1617
Episode: 11591/30000 (38.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4304s / 451.1620 s
agent0:                 episode reward: -1.0109,                 loss: nan
agent1:                 episode reward: 1.0109,                 loss: 0.1600
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4305s / 451.5925 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.1610
Episode: 11611/30000 (38.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4157s / 452.0082 s
agent0:                 episode reward: -0.1940,                 loss: nan
agent1:                 episode reward: 0.1940,                 loss: 0.1613
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4158s / 452.4240 s
agent0:                 episode reward: -0.7126,                 loss: nan
agent1:                 episode reward: 0.7126,                 loss: 0.1606
Episode: 11631/30000 (38.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4168s / 452.8408 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.1624
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4233s / 453.2641 s
agent0:                 episode reward: -0.0231,                 loss: nan
agent1:                 episode reward: 0.0231,                 loss: 0.1594
Episode: 11651/30000 (38.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 453.6853 s
agent0:                 episode reward: -0.3532,                 loss: nan
agent1:                 episode reward: 0.3532,                 loss: 0.1618
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 454.1029 s
agent0:                 episode reward: -0.2742,                 loss: nan
agent1:                 episode reward: 0.2742,                 loss: 0.1643
Episode: 11671/30000 (38.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4349s / 454.5379 s
agent0:                 episode reward: -0.4432,                 loss: nan
agent1:                 episode reward: 0.4432,                 loss: 0.1606
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4160s / 454.9539 s
agent0:                 episode reward: 0.3320,                 loss: nan
agent1:                 episode reward: -0.3320,                 loss: 0.1605
Episode: 11691/30000 (38.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4557s / 455.4096 s
agent0:                 episode reward: -0.1466,                 loss: nan
agent1:                 episode reward: 0.1466,                 loss: 0.1613
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4266s / 455.8362 s
agent0:                 episode reward: 0.5786,                 loss: nan
agent1:                 episode reward: -0.5786,                 loss: 0.1616
Episode: 11711/30000 (39.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4217s / 456.2579 s
agent0:                 episode reward: -0.0400,                 loss: nan
agent1:                 episode reward: 0.0400,                 loss: 0.1605
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 456.6809 s
agent0:                 episode reward: -0.3223,                 loss: nan
agent1:                 episode reward: 0.3223,                 loss: 0.1589
Episode: 11731/30000 (39.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4247s / 457.1056 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.1588
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4572s / 457.5627 s
agent0:                 episode reward: -0.2381,                 loss: nan
agent1:                 episode reward: 0.2381,                 loss: 0.1623
Episode: 11751/30000 (39.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4204s / 457.9831 s
agent0:                 episode reward: -0.1110,                 loss: nan
agent1:                 episode reward: 0.1110,                 loss: 0.1614
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4154s / 458.3986 s
agent0:                 episode reward: -0.6130,                 loss: nan
agent1:                 episode reward: 0.6130,                 loss: 0.1607
Episode: 11771/30000 (39.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4207s / 458.8193 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.1603
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4312s / 459.2504 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.1631
Episode: 11791/30000 (39.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4330s / 459.6834 s
agent0:                 episode reward: 0.1863,                 loss: nan
agent1:                 episode reward: -0.1863,                 loss: 0.1592
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4160s / 460.0994 s
agent0:                 episode reward: -0.2384,                 loss: nan
agent1:                 episode reward: 0.2384,                 loss: 0.1639
Episode: 11811/30000 (39.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4449s / 460.5442 s
agent0:                 episode reward: 0.2022,                 loss: nan
agent1:                 episode reward: -0.2022,                 loss: 0.1596
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4273s / 460.9716 s
agent0:                 episode reward: 0.1084,                 loss: nan
agent1:                 episode reward: -0.1084,                 loss: 0.1600
Episode: 11831/30000 (39.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4231s / 461.3947 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.1601
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4165s / 461.8111 s
agent0:                 episode reward: -0.4396,                 loss: nan
agent1:                 episode reward: 0.4396,                 loss: 0.1611
Episode: 11851/30000 (39.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 462.2410 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.1611
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4203s / 462.6614 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.1616
Episode: 11871/30000 (39.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4240s / 463.0854 s
agent0:                 episode reward: 0.1451,                 loss: nan
agent1:                 episode reward: -0.1451,                 loss: 0.1613
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 463.5451 s
agent0:                 episode reward: -0.1112,                 loss: nan
agent1:                 episode reward: 0.1112,                 loss: 0.1600
Episode: 11891/30000 (39.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 463.9686 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.1586
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4223s / 464.3909 s
agent0:                 episode reward: -0.1275,                 loss: nan
agent1:                 episode reward: 0.1275,                 loss: 0.1566
Episode: 11911/30000 (39.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4029s / 464.7938 s
agent0:                 episode reward: 0.1307,                 loss: nan
agent1:                 episode reward: -0.1307,                 loss: 0.1567
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4074s / 465.2012 s
agent0:                 episode reward: -0.2561,                 loss: nan
agent1:                 episode reward: 0.2561,                 loss: 0.1569
Episode: 11931/30000 (39.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4205s / 465.6217 s
agent0:                 episode reward: -0.1463,                 loss: nan
agent1:                 episode reward: 0.1463,                 loss: 0.1580
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 466.0452 s
agent0:                 episode reward: 0.1454,                 loss: nan
agent1:                 episode reward: -0.1454,                 loss: 0.1593
Episode: 11951/30000 (39.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4259s / 466.4711 s
agent0:                 episode reward: 0.0489,                 loss: nan
agent1:                 episode reward: -0.0489,                 loss: 0.1566
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4276s / 466.8987 s
agent0:                 episode reward: -0.2431,                 loss: nan
agent1:                 episode reward: 0.2431,                 loss: 0.1581
Episode: 11971/30000 (39.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4167s / 467.3154 s
agent0:                 episode reward: 0.0108,                 loss: nan
agent1:                 episode reward: -0.0108,                 loss: 0.1582
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4233s / 467.7387 s
agent0:                 episode reward: 0.2386,                 loss: nan
agent1:                 episode reward: -0.2386,                 loss: 0.1578
Episode: 11991/30000 (39.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4151s / 468.1538 s
agent0:                 episode reward: -0.5889,                 loss: nan
agent1:                 episode reward: 0.5889,                 loss: 0.1578
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4129s / 468.5666 s
agent0:                 episode reward: -0.0904,                 loss: nan
agent1:                 episode reward: 0.0904,                 loss: 0.1582
Episode: 12011/30000 (40.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4271s / 468.9937 s
agent0:                 episode reward: -0.4565,                 loss: nan
agent1:                 episode reward: 0.4565,                 loss: 0.1578
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 469.4128 s
agent0:                 episode reward: -0.1757,                 loss: nan
agent1:                 episode reward: 0.1757,                 loss: 0.1589
Episode: 12031/30000 (40.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4167s / 469.8295 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.1585
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4181s / 470.2476 s
agent0:                 episode reward: -0.1902,                 loss: nan
agent1:                 episode reward: 0.1902,                 loss: 0.1601
Episode: 12051/30000 (40.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 470.6640 s
agent0:                 episode reward: -1.1061,                 loss: nan
agent1:                 episode reward: 1.1061,                 loss: 0.1582
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4072s / 471.0713 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: 0.1579
Episode: 12071/30000 (40.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4097s / 471.4810 s
agent0:                 episode reward: -0.1463,                 loss: nan
agent1:                 episode reward: 0.1463,                 loss: 0.1569
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4394s / 471.9204 s
agent0:                 episode reward: -0.0479,                 loss: nan
agent1:                 episode reward: 0.0479,                 loss: 0.1581
Episode: 12091/30000 (40.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4521s / 472.3724 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1577
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4496s / 472.8221 s
agent0:                 episode reward: 0.3450,                 loss: nan
agent1:                 episode reward: -0.3450,                 loss: 0.1568
Episode: 12111/30000 (40.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4360s / 473.2581 s
agent0:                 episode reward: -0.3107,                 loss: nan
agent1:                 episode reward: 0.3107,                 loss: 0.1590
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 473.6928 s
agent0:                 episode reward: -0.6586,                 loss: nan
agent1:                 episode reward: 0.6586,                 loss: 0.1616
Episode: 12131/30000 (40.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4271s / 474.1199 s
agent0:                 episode reward: -0.3694,                 loss: nan
agent1:                 episode reward: 0.3694,                 loss: 0.1590
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4209s / 474.5407 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.1561
Episode: 12151/30000 (40.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4195s / 474.9602 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.1599
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4279s / 475.3881 s
agent0:                 episode reward: -0.2729,                 loss: nan
agent1:                 episode reward: 0.2729,                 loss: 0.1583
Episode: 12171/30000 (40.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4377s / 475.8258 s
agent0:                 episode reward: -0.2801,                 loss: nan
agent1:                 episode reward: 0.2801,                 loss: 0.1576
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 476.2510 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.1577
Episode: 12191/30000 (40.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 476.6728 s
agent0:                 episode reward: 0.0067,                 loss: nan
agent1:                 episode reward: -0.0067,                 loss: 0.1582
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4209s / 477.0937 s
agent0:                 episode reward: -0.0682,                 loss: nan
agent1:                 episode reward: 0.0682,                 loss: 0.1589
Episode: 12211/30000 (40.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4216s / 477.5154 s
agent0:                 episode reward: 0.1043,                 loss: nan
agent1:                 episode reward: -0.1043,                 loss: 0.1566
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4216s / 477.9370 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.1613
Episode: 12231/30000 (40.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 478.3587 s
agent0:                 episode reward: 0.2657,                 loss: nan
agent1:                 episode reward: -0.2657,                 loss: 0.1626
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 478.8007 s
agent0:                 episode reward: 0.1836,                 loss: nan
agent1:                 episode reward: -0.1836,                 loss: 0.1610
Episode: 12251/30000 (40.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4192s / 479.2199 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1597
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4194s / 479.6394 s
agent0:                 episode reward: -0.7461,                 loss: nan
agent1:                 episode reward: 0.7461,                 loss: 0.1591
Episode: 12271/30000 (40.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4237s / 480.0630 s
agent0:                 episode reward: 0.4315,                 loss: nan
agent1:                 episode reward: -0.4315,                 loss: 0.1597
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4396s / 480.5027 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1623
Episode: 12291/30000 (40.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4388s / 480.9414 s
agent0:                 episode reward: -0.5324,                 loss: nan
agent1:                 episode reward: 0.5324,                 loss: 0.1600
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4407s / 481.3821 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: 0.1597
Episode: 12311/30000 (41.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4481s / 481.8303 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: 0.1625
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 482.2734 s
agent0:                 episode reward: 0.4204,                 loss: nan
agent1:                 episode reward: -0.4204,                 loss: 0.1620
Episode: 12331/30000 (41.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4391s / 482.7125 s
agent0:                 episode reward: -0.3858,                 loss: nan
agent1:                 episode reward: 0.3858,                 loss: 0.1590
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4298s / 483.1423 s
agent0:                 episode reward: 0.1993,                 loss: nan
agent1:                 episode reward: -0.1993,                 loss: 0.1607
Episode: 12351/30000 (41.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4208s / 483.5631 s
agent0:                 episode reward: 0.1435,                 loss: nan
agent1:                 episode reward: -0.1435,                 loss: 0.1624
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4250s / 483.9881 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.1626
Episode: 12371/30000 (41.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4613s / 484.4494 s
agent0:                 episode reward: -0.3944,                 loss: nan
agent1:                 episode reward: 0.3944,                 loss: 0.1640
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4322s / 484.8816 s
agent0:                 episode reward: 0.0466,                 loss: nan
agent1:                 episode reward: -0.0466,                 loss: 0.1612
Episode: 12391/30000 (41.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4260s / 485.3076 s
agent0:                 episode reward: -0.2035,                 loss: nan
agent1:                 episode reward: 0.2035,                 loss: 0.1610
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 485.7393 s
agent0:                 episode reward: -0.9697,                 loss: nan
agent1:                 episode reward: 0.9697,                 loss: 0.1634
Episode: 12411/30000 (41.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4171s / 486.1564 s
agent0:                 episode reward: -0.3018,                 loss: nan
agent1:                 episode reward: 0.3018,                 loss: 0.1602
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4055s / 486.5619 s
agent0:                 episode reward: -0.1719,                 loss: nan
agent1:                 episode reward: 0.1719,                 loss: 0.1611
Episode: 12431/30000 (41.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4055s / 486.9674 s
agent0:                 episode reward: -0.7359,                 loss: nan
agent1:                 episode reward: 0.7359,                 loss: 0.1610
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 487.4021 s
agent0:                 episode reward: -0.3254,                 loss: nan
agent1:                 episode reward: 0.3254,                 loss: 0.1635
Episode: 12451/30000 (41.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4280s / 487.8301 s
agent0:                 episode reward: -0.4711,                 loss: nan
agent1:                 episode reward: 0.4711,                 loss: 0.1637
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4172s / 488.2473 s
agent0:                 episode reward: -0.3843,                 loss: nan
agent1:                 episode reward: 0.3843,                 loss: 0.1606
Episode: 12471/30000 (41.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4460s / 488.6933 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.1614
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4271s / 489.1204 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.1619
Episode: 12491/30000 (41.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4323s / 489.5526 s
agent0:                 episode reward: -0.3849,                 loss: nan
agent1:                 episode reward: 0.3849,                 loss: 0.1627
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4137s / 489.9663 s
agent0:                 episode reward: 0.1852,                 loss: nan
agent1:                 episode reward: -0.1852,                 loss: 0.1621
Episode: 12511/30000 (41.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4100s / 490.3763 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.1611
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 490.7890 s
agent0:                 episode reward: -0.2233,                 loss: nan
agent1:                 episode reward: 0.2233,                 loss: 0.1629
Episode: 12531/30000 (41.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4166s / 491.2056 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.1596
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4138s / 491.6194 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1619
Episode: 12551/30000 (41.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4140s / 492.0334 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1608
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 492.4439 s
agent0:                 episode reward: -0.5082,                 loss: nan
agent1:                 episode reward: 0.5082,                 loss: 0.1619
Episode: 12571/30000 (41.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4074s / 492.8513 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.1610
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4257s / 493.2771 s
agent0:                 episode reward: -0.2471,                 loss: nan
agent1:                 episode reward: 0.2471,                 loss: 0.1596
Episode: 12591/30000 (41.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4120s / 493.6891 s
agent0:                 episode reward: -1.2091,                 loss: nan
agent1:                 episode reward: 1.2091,                 loss: 0.1598
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4112s / 494.1003 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.1622
Episode: 12611/30000 (42.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 494.5108 s
agent0:                 episode reward: 0.1280,                 loss: nan
agent1:                 episode reward: -0.1280,                 loss: 0.1566
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4074s / 494.9181 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.1629
Episode: 12631/30000 (42.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4250s / 495.3431 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.1615
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4287s / 495.7718 s
agent0:                 episode reward: -0.2151,                 loss: nan
agent1:                 episode reward: 0.2151,                 loss: 0.1580
Episode: 12651/30000 (42.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4627s / 496.2345 s
agent0:                 episode reward: 0.0927,                 loss: nan
agent1:                 episode reward: -0.0927,                 loss: 0.1599
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4308s / 496.6653 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.1591
Episode: 12671/30000 (42.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4435s / 497.1088 s
agent0:                 episode reward: 0.1411,                 loss: nan
agent1:                 episode reward: -0.1411,                 loss: 0.1603
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4151s / 497.5238 s
agent0:                 episode reward: -0.4275,                 loss: nan
agent1:                 episode reward: 0.4275,                 loss: 0.1615
Episode: 12691/30000 (42.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4213s / 497.9451 s
agent0:                 episode reward: -0.8054,                 loss: nan
agent1:                 episode reward: 0.8054,                 loss: 0.1590
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4179s / 498.3630 s
agent0:                 episode reward: -0.6062,                 loss: nan
agent1:                 episode reward: 0.6062,                 loss: 0.1589
Episode: 12711/30000 (42.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 498.7761 s
agent0:                 episode reward: 0.6973,                 loss: nan
agent1:                 episode reward: -0.6973,                 loss: 0.1601
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4270s / 499.2031 s
agent0:                 episode reward: -0.0965,                 loss: nan
agent1:                 episode reward: 0.0965,                 loss: 0.1597
Episode: 12731/30000 (42.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 499.6283 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.1580
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4222s / 500.0505 s
agent0:                 episode reward: -0.3437,                 loss: nan
agent1:                 episode reward: 0.3437,                 loss: 0.1618
Episode: 12751/30000 (42.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4430s / 500.4935 s
agent0:                 episode reward: -0.0888,                 loss: nan
agent1:                 episode reward: 0.0888,                 loss: 0.1604
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 500.9530 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.1608
Episode: 12771/30000 (42.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4547s / 501.4077 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.1598
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4416s / 501.8493 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.1600
Episode: 12791/30000 (42.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4506s / 502.2999 s
agent0:                 episode reward: -0.1998,                 loss: nan
agent1:                 episode reward: 0.1998,                 loss: 0.1608
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4498s / 502.7497 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.1596
Episode: 12811/30000 (42.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4316s / 503.1813 s
agent0:                 episode reward: -0.1852,                 loss: nan
agent1:                 episode reward: 0.1852,                 loss: 0.1595
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4306s / 503.6119 s
agent0:                 episode reward: 0.0155,                 loss: nan
agent1:                 episode reward: -0.0155,                 loss: 0.1604
Episode: 12831/30000 (42.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4238s / 504.0357 s
agent0:                 episode reward: -0.2097,                 loss: nan
agent1:                 episode reward: 0.2097,                 loss: 0.1620
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4244s / 504.4600 s
agent0:                 episode reward: 0.0808,                 loss: nan
agent1:                 episode reward: -0.0808,                 loss: 0.1599
Episode: 12851/30000 (42.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4224s / 504.8824 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.1606
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4923s / 505.3748 s
agent0:                 episode reward: -0.0136,                 loss: nan
agent1:                 episode reward: 0.0136,                 loss: 0.1581
Episode: 12871/30000 (42.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4816s / 505.8564 s
agent0:                 episode reward: -0.4309,                 loss: nan
agent1:                 episode reward: 0.4309,                 loss: 0.1598
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4436s / 506.2999 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.1589
Episode: 12891/30000 (42.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4138s / 506.7138 s
agent0:                 episode reward: 0.5456,                 loss: nan
agent1:                 episode reward: -0.5456,                 loss: 0.1573
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4229s / 507.1367 s
agent0:                 episode reward: 0.0228,                 loss: nan
agent1:                 episode reward: -0.0228,                 loss: 0.1587
Episode: 12911/30000 (43.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4098s / 507.5465 s
agent0:                 episode reward: 0.1868,                 loss: nan
agent1:                 episode reward: -0.1868,                 loss: 0.1568
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4160s / 507.9625 s
agent0:                 episode reward: 0.0909,                 loss: nan
agent1:                 episode reward: -0.0909,                 loss: 0.1555
Episode: 12931/30000 (43.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4417s / 508.4042 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: 0.1579
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4340s / 508.8382 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1581
Episode: 12951/30000 (43.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4321s / 509.2703 s
agent0:                 episode reward: 0.0317,                 loss: nan
agent1:                 episode reward: -0.0317,                 loss: 0.1590
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4322s / 509.7025 s
agent0:                 episode reward: -0.3179,                 loss: nan
agent1:                 episode reward: 0.3179,                 loss: 0.1577
Episode: 12971/30000 (43.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4278s / 510.1303 s
agent0:                 episode reward: -0.3944,                 loss: nan
agent1:                 episode reward: 0.3944,                 loss: 0.1584
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4169s / 510.5473 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.1578
Episode: 12991/30000 (43.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4156s / 510.9629 s
agent0:                 episode reward: -1.1420,                 loss: nan
agent1:                 episode reward: 1.1420,                 loss: 0.1604
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4255s / 511.3883 s
agent0:                 episode reward: -0.6686,                 loss: nan
agent1:                 episode reward: 0.6686,                 loss: 0.1604
Episode: 13011/30000 (43.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4328s / 511.8211 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.1574
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4240s / 512.2451 s
agent0:                 episode reward: 0.1145,                 loss: nan
agent1:                 episode reward: -0.1145,                 loss: 0.1590
Episode: 13031/30000 (43.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4265s / 512.6716 s
agent0:                 episode reward: -0.1292,                 loss: nan
agent1:                 episode reward: 0.1292,                 loss: 0.1582
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4238s / 513.0954 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: 0.1579
Episode: 13051/30000 (43.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 513.5429 s
agent0:                 episode reward: -0.0283,                 loss: nan
agent1:                 episode reward: 0.0283,                 loss: 0.1584
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4266s / 513.9696 s
agent0:                 episode reward: -0.5488,                 loss: nan
agent1:                 episode reward: 0.5488,                 loss: 0.1584
Episode: 13071/30000 (43.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4215s / 514.3910 s
agent0:                 episode reward: -0.1868,                 loss: nan
agent1:                 episode reward: 0.1868,                 loss: 0.1590
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 514.8529 s
agent0:                 episode reward: -0.2451,                 loss: nan
agent1:                 episode reward: 0.2451,                 loss: 0.1562
Episode: 13091/30000 (43.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4331s / 515.2860 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.1562
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4318s / 515.7178 s
agent0:                 episode reward: -0.1352,                 loss: nan
agent1:                 episode reward: 0.1352,                 loss: 0.1608
Episode: 13111/30000 (43.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4285s / 516.1463 s
agent0:                 episode reward: -0.5699,                 loss: nan
agent1:                 episode reward: 0.5699,                 loss: 0.1582
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4287s / 516.5751 s
agent0:                 episode reward: -0.0962,                 loss: nan
agent1:                 episode reward: 0.0962,                 loss: 0.1594
Episode: 13131/30000 (43.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4291s / 517.0042 s
agent0:                 episode reward: 0.0481,                 loss: nan
agent1:                 episode reward: -0.0481,                 loss: 0.1582
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4278s / 517.4319 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.1590
Episode: 13151/30000 (43.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4421s / 517.8740 s
agent0:                 episode reward: -0.2682,                 loss: nan
agent1:                 episode reward: 0.2682,                 loss: 0.1576
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4269s / 518.3009 s
agent0:                 episode reward: -0.1592,                 loss: nan
agent1:                 episode reward: 0.1592,                 loss: 0.1572
Episode: 13171/30000 (43.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 518.7239 s
agent0:                 episode reward: -0.0877,                 loss: nan
agent1:                 episode reward: 0.0877,                 loss: 0.1600
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4264s / 519.1503 s
agent0:                 episode reward: 0.1120,                 loss: nan
agent1:                 episode reward: -0.1120,                 loss: 0.1580
Episode: 13191/30000 (43.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4377s / 519.5880 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1569
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 520.0232 s
agent0:                 episode reward: -0.1891,                 loss: nan
agent1:                 episode reward: 0.1891,                 loss: 0.1570
Episode: 13211/30000 (44.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4372s / 520.4604 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.1568
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4629s / 520.9232 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.1614
Episode: 13231/30000 (44.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4231s / 521.3464 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.1620
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4188s / 521.7652 s
agent0:                 episode reward: 0.0756,                 loss: nan
agent1:                 episode reward: -0.0756,                 loss: 0.1614
Episode: 13251/30000 (44.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4367s / 522.2019 s
agent0:                 episode reward: -0.4717,                 loss: nan
agent1:                 episode reward: 0.4717,                 loss: 0.1601
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4128s / 522.6147 s
agent0:                 episode reward: 0.1937,                 loss: nan
agent1:                 episode reward: -0.1937,                 loss: 0.1617
Episode: 13271/30000 (44.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4068s / 523.0215 s
agent0:                 episode reward: 0.3931,                 loss: nan
agent1:                 episode reward: -0.3931,                 loss: 0.1614
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4098s / 523.4314 s
agent0:                 episode reward: -0.7342,                 loss: nan
agent1:                 episode reward: 0.7342,                 loss: 0.1616
Episode: 13291/30000 (44.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4389s / 523.8703 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.1610
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4099s / 524.2802 s
agent0:                 episode reward: -0.3987,                 loss: nan
agent1:                 episode reward: 0.3987,                 loss: 0.1603
Episode: 13311/30000 (44.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 524.6976 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.1605
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4167s / 525.1143 s
agent0:                 episode reward: -0.1313,                 loss: nan
agent1:                 episode reward: 0.1313,                 loss: 0.1600
Episode: 13331/30000 (44.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 525.5442 s
agent0:                 episode reward: -0.0255,                 loss: nan
agent1:                 episode reward: 0.0255,                 loss: 0.1608
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4294s / 525.9736 s
agent0:                 episode reward: -0.3005,                 loss: nan
agent1:                 episode reward: 0.3005,                 loss: 0.1619
Episode: 13351/30000 (44.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 526.4011 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.1606
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4370s / 526.8381 s
agent0:                 episode reward: -0.5018,                 loss: nan
agent1:                 episode reward: 0.5018,                 loss: 0.1620
Episode: 13371/30000 (44.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4339s / 527.2719 s
agent0:                 episode reward: -0.4707,                 loss: nan
agent1:                 episode reward: 0.4707,                 loss: 0.1625
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4238s / 527.6957 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.1613
Episode: 13391/30000 (44.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4270s / 528.1227 s
agent0:                 episode reward: -0.6092,                 loss: nan
agent1:                 episode reward: 0.6092,                 loss: 0.1615
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4113s / 528.5340 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.1607
Episode: 13411/30000 (44.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 528.9471 s
agent0:                 episode reward: -0.6685,                 loss: nan
agent1:                 episode reward: 0.6685,                 loss: 0.1614
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 529.3673 s
agent0:                 episode reward: -0.1242,                 loss: nan
agent1:                 episode reward: 0.1242,                 loss: 0.1621
Episode: 13431/30000 (44.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 529.7925 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.1645
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4409s / 530.2334 s
agent0:                 episode reward: -0.9642,                 loss: nan
agent1:                 episode reward: 0.9642,                 loss: 0.1599
Episode: 13451/30000 (44.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4387s / 530.6721 s
agent0:                 episode reward: 0.1695,                 loss: nan
agent1:                 episode reward: -0.1695,                 loss: 0.1624
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4284s / 531.1005 s
agent0:                 episode reward: -0.3043,                 loss: nan
agent1:                 episode reward: 0.3043,                 loss: 0.1617
Episode: 13471/30000 (44.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4270s / 531.5275 s
agent0:                 episode reward: -0.1217,                 loss: nan
agent1:                 episode reward: 0.1217,                 loss: 0.1614
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 531.9504 s
agent0:                 episode reward: 0.0268,                 loss: nan
agent1:                 episode reward: -0.0268,                 loss: 0.1617
Episode: 13491/30000 (44.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 532.3805 s
agent0:                 episode reward: -0.2912,                 loss: nan
agent1:                 episode reward: 0.2912,                 loss: 0.1620
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4445s / 532.8251 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.1636
Episode: 13511/30000 (45.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4283s / 533.2534 s
agent0:                 episode reward: 0.1936,                 loss: nan
agent1:                 episode reward: -0.1936,                 loss: 0.1614
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4274s / 533.6808 s
agent0:                 episode reward: -0.0513,                 loss: nan
agent1:                 episode reward: 0.0513,                 loss: 0.1597
Episode: 13531/30000 (45.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4294s / 534.1102 s
agent0:                 episode reward: -0.9515,                 loss: nan
agent1:                 episode reward: 0.9515,                 loss: 0.1617
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4288s / 534.5390 s
agent0:                 episode reward: 0.1552,                 loss: nan
agent1:                 episode reward: -0.1552,                 loss: 0.1613
Episode: 13551/30000 (45.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4319s / 534.9708 s
agent0:                 episode reward: 0.1502,                 loss: nan
agent1:                 episode reward: -0.1502,                 loss: 0.1610
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4383s / 535.4091 s
agent0:                 episode reward: 0.5298,                 loss: nan
agent1:                 episode reward: -0.5298,                 loss: 0.1612
Episode: 13571/30000 (45.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4598s / 535.8689 s
agent0:                 episode reward: -0.4481,                 loss: nan
agent1:                 episode reward: 0.4481,                 loss: 0.1599
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4357s / 536.3046 s
agent0:                 episode reward: -0.1268,                 loss: nan
agent1:                 episode reward: 0.1268,                 loss: 0.1590
Episode: 13591/30000 (45.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4288s / 536.7334 s
agent0:                 episode reward: -0.4770,                 loss: nan
agent1:                 episode reward: 0.4770,                 loss: 0.1598
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4436s / 537.1769 s
agent0:                 episode reward: -0.2640,                 loss: nan
agent1:                 episode reward: 0.2640,                 loss: 0.1609
Episode: 13611/30000 (45.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4430s / 537.6199 s
agent0:                 episode reward: 0.1847,                 loss: nan
agent1:                 episode reward: -0.1847,                 loss: 0.1619
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 538.0555 s
agent0:                 episode reward: -0.8890,                 loss: nan
agent1:                 episode reward: 0.8890,                 loss: 0.1584
Episode: 13631/30000 (45.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4314s / 538.4870 s
agent0:                 episode reward: 0.4539,                 loss: nan
agent1:                 episode reward: -0.4539,                 loss: 0.1602
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4934s / 538.9804 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.1589
Episode: 13651/30000 (45.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 539.4056 s
agent0:                 episode reward: -0.1108,                 loss: nan
agent1:                 episode reward: 0.1108,                 loss: 0.1601
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 539.8404 s
agent0:                 episode reward: -0.2130,                 loss: nan
agent1:                 episode reward: 0.2130,                 loss: 0.1602
Episode: 13671/30000 (45.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4306s / 540.2711 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.1615
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 540.7012 s
agent0:                 episode reward: 0.0485,                 loss: nan
agent1:                 episode reward: -0.0485,                 loss: 0.1604
Episode: 13691/30000 (45.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4342s / 541.1354 s
agent0:                 episode reward: 0.2598,                 loss: nan
agent1:                 episode reward: -0.2598,                 loss: 0.1607
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 541.5488 s
agent0:                 episode reward: -0.9179,                 loss: nan
agent1:                 episode reward: 0.9179,                 loss: 0.1601
Episode: 13711/30000 (45.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4384s / 541.9872 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: 0.1588
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4137s / 542.4009 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.1599
Episode: 13731/30000 (45.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 542.8239 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: 0.1603
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4225s / 543.2464 s
agent0:                 episode reward: -0.0521,                 loss: nan
agent1:                 episode reward: 0.0521,                 loss: 0.1620
Episode: 13751/30000 (45.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4435s / 543.6900 s
agent0:                 episode reward: -0.0572,                 loss: nan
agent1:                 episode reward: 0.0572,                 loss: 0.1615
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 544.1385 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1626
Episode: 13771/30000 (45.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 544.5794 s
agent0:                 episode reward: -0.1484,                 loss: nan
agent1:                 episode reward: 0.1484,                 loss: 0.1583
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4701s / 545.0495 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.1602
Episode: 13791/30000 (45.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4384s / 545.4879 s
agent0:                 episode reward: -0.2738,                 loss: nan
agent1:                 episode reward: 0.2738,                 loss: 0.1601
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 545.9178 s
agent0:                 episode reward: -0.3204,                 loss: nan
agent1:                 episode reward: 0.3204,                 loss: 0.1586
Episode: 13811/30000 (46.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4266s / 546.3444 s
agent0:                 episode reward: -0.1847,                 loss: nan
agent1:                 episode reward: 0.1847,                 loss: 0.1610
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4259s / 546.7703 s
agent0:                 episode reward: -0.2111,                 loss: nan
agent1:                 episode reward: 0.2111,                 loss: 0.1599
Episode: 13831/30000 (46.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 547.2308 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.1589
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4363s / 547.6672 s
agent0:                 episode reward: -0.2824,                 loss: nan
agent1:                 episode reward: 0.2824,                 loss: 0.1601
Episode: 13851/30000 (46.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4361s / 548.1033 s
agent0:                 episode reward: -0.2023,                 loss: nan
agent1:                 episode reward: 0.2023,                 loss: 0.1586
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4209s / 548.5242 s
agent0:                 episode reward: -0.5886,                 loss: nan
agent1:                 episode reward: 0.5886,                 loss: 0.1591
Episode: 13871/30000 (46.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 548.9727 s
agent0:                 episode reward: -0.0074,                 loss: nan
agent1:                 episode reward: 0.0074,                 loss: 0.1590
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4144s / 549.3870 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.1590
Episode: 13891/30000 (46.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 549.8005 s
agent0:                 episode reward: -0.1204,                 loss: nan
agent1:                 episode reward: 0.1204,                 loss: 0.1611
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4120s / 550.2125 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.1613
Episode: 13911/30000 (46.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4183s / 550.6308 s
agent0:                 episode reward: -0.7237,                 loss: nan
agent1:                 episode reward: 0.7237,                 loss: 0.1613
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4200s / 551.0508 s
agent0:                 episode reward: 0.0104,                 loss: nan
agent1:                 episode reward: -0.0104,                 loss: 0.1648
Episode: 13931/30000 (46.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4399s / 551.4907 s
agent0:                 episode reward: -0.7404,                 loss: nan
agent1:                 episode reward: 0.7404,                 loss: 0.1633
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4340s / 551.9248 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.1630
Episode: 13951/30000 (46.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4373s / 552.3621 s
agent0:                 episode reward: 0.1103,                 loss: nan
agent1:                 episode reward: -0.1103,                 loss: 0.1598
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 552.7938 s
agent0:                 episode reward: 0.0671,                 loss: nan
agent1:                 episode reward: -0.0671,                 loss: 0.1628
Episode: 13971/30000 (46.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4349s / 553.2287 s
agent0:                 episode reward: 0.3392,                 loss: nan
agent1:                 episode reward: -0.3392,                 loss: 0.1628
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 553.6588 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.1612
Episode: 13991/30000 (46.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4422s / 554.1010 s
agent0:                 episode reward: -0.3149,                 loss: nan
agent1:                 episode reward: 0.3149,                 loss: 0.1621
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4213s / 554.5223 s
agent0:                 episode reward: -0.5106,                 loss: nan
agent1:                 episode reward: 0.5106,                 loss: 0.1622
Episode: 14011/30000 (46.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 554.9382 s
agent0:                 episode reward: -0.6515,                 loss: nan
agent1:                 episode reward: 0.6515,                 loss: 0.1619
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 555.3682 s
agent0:                 episode reward: 0.2365,                 loss: nan
agent1:                 episode reward: -0.2365,                 loss: 0.1649
Episode: 14031/30000 (46.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 555.7912 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1634
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 556.2188 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: 0.1627
Episode: 14051/30000 (46.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 556.6440 s
agent0:                 episode reward: -0.6804,                 loss: nan
agent1:                 episode reward: 0.6804,                 loss: 0.1623
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4286s / 557.0726 s
agent0:                 episode reward: -0.1329,                 loss: nan
agent1:                 episode reward: 0.1329,                 loss: 0.1590
Episode: 14071/30000 (46.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4413s / 557.5139 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.1619
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4271s / 557.9410 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: 0.1631
Episode: 14091/30000 (46.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4293s / 558.3703 s
agent0:                 episode reward: -0.7603,                 loss: nan
agent1:                 episode reward: 0.7603,                 loss: 0.1624
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4287s / 558.7990 s
agent0:                 episode reward: -0.1714,                 loss: nan
agent1:                 episode reward: 0.1714,                 loss: 0.1617
Episode: 14111/30000 (47.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 559.2153 s
agent0:                 episode reward: -0.5880,                 loss: nan
agent1:                 episode reward: 0.5880,                 loss: 0.1638
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4276s / 559.6429 s
agent0:                 episode reward: -0.3260,                 loss: nan
agent1:                 episode reward: 0.3260,                 loss: 0.1639
Episode: 14131/30000 (47.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4223s / 560.0652 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.1626
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4664s / 560.5317 s
agent0:                 episode reward: 0.2918,                 loss: nan
agent1:                 episode reward: -0.2918,                 loss: 0.1621
Episode: 14151/30000 (47.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4360s / 560.9676 s
agent0:                 episode reward: -0.2164,                 loss: nan
agent1:                 episode reward: 0.2164,                 loss: 0.1611
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4378s / 561.4054 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.1630
Episode: 14171/30000 (47.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4375s / 561.8429 s
agent0:                 episode reward: -0.0427,                 loss: nan
agent1:                 episode reward: 0.0427,                 loss: 0.1616
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4411s / 562.2840 s
agent0:                 episode reward: -0.6652,                 loss: nan
agent1:                 episode reward: 0.6652,                 loss: 0.1622
Episode: 14191/30000 (47.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4358s / 562.7198 s
agent0:                 episode reward: 0.5587,                 loss: nan
agent1:                 episode reward: -0.5587,                 loss: 0.1615
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4310s / 563.1509 s
agent0:                 episode reward: -0.2126,                 loss: nan
agent1:                 episode reward: 0.2126,                 loss: 0.1625
Episode: 14211/30000 (47.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4394s / 563.5903 s
agent0:                 episode reward: -0.7736,                 loss: nan
agent1:                 episode reward: 0.7736,                 loss: 0.1624
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 564.0253 s
agent0:                 episode reward: -0.0210,                 loss: nan
agent1:                 episode reward: 0.0210,                 loss: 0.1638
Episode: 14231/30000 (47.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4101s / 564.4354 s
agent0:                 episode reward: -0.5620,                 loss: nan
agent1:                 episode reward: 0.5620,                 loss: 0.1645
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 564.8551 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.1636
Episode: 14251/30000 (47.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4302s / 565.2853 s
agent0:                 episode reward: 0.0569,                 loss: nan
agent1:                 episode reward: -0.0569,                 loss: 0.1641
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 565.7205 s
agent0:                 episode reward: -0.1580,                 loss: nan
agent1:                 episode reward: 0.1580,                 loss: 0.1626
Episode: 14271/30000 (47.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4252s / 566.1457 s
agent0:                 episode reward: -0.0715,                 loss: nan
agent1:                 episode reward: 0.0715,                 loss: 0.1684
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4542s / 566.5999 s
agent0:                 episode reward: -0.3327,                 loss: nan
agent1:                 episode reward: 0.3327,                 loss: 0.1650
Episode: 14291/30000 (47.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4465s / 567.0464 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.1629
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4542s / 567.5006 s
agent0:                 episode reward: -0.3040,                 loss: nan
agent1:                 episode reward: 0.3040,                 loss: 0.1647
Episode: 14311/30000 (47.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4503s / 567.9509 s
agent0:                 episode reward: -0.1415,                 loss: nan
agent1:                 episode reward: 0.1415,                 loss: 0.1649
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4527s / 568.4036 s
agent0:                 episode reward: -0.9967,                 loss: nan
agent1:                 episode reward: 0.9967,                 loss: 0.1635
Episode: 14331/30000 (47.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4305s / 568.8342 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.1632
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4291s / 569.2632 s
agent0:                 episode reward: 0.1754,                 loss: nan
agent1:                 episode reward: -0.1754,                 loss: 0.1649
Episode: 14351/30000 (47.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4428s / 569.7060 s
agent0:                 episode reward: -0.5351,                 loss: nan
agent1:                 episode reward: 0.5351,                 loss: 0.1666
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4302s / 570.1363 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.1626
Episode: 14371/30000 (47.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4314s / 570.5676 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1639
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4281s / 570.9957 s
agent0:                 episode reward: 0.0986,                 loss: nan
agent1:                 episode reward: -0.0986,                 loss: 0.1638
Episode: 14391/30000 (47.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4336s / 571.4293 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.1621
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4489s / 571.8782 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: 0.1642
Episode: 14411/30000 (48.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4969s / 572.3751 s
agent0:                 episode reward: 0.0112,                 loss: nan
agent1:                 episode reward: -0.0112,                 loss: 0.1645
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4686s / 572.8437 s
agent0:                 episode reward: 0.4925,                 loss: nan
agent1:                 episode reward: -0.4925,                 loss: 0.1639
Episode: 14431/30000 (48.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4507s / 573.2944 s
agent0:                 episode reward: 0.0513,                 loss: nan
agent1:                 episode reward: -0.0513,                 loss: 0.1633
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4434s / 573.7378 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.1621
Episode: 14451/30000 (48.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4454s / 574.1832 s
agent0:                 episode reward: 0.0924,                 loss: nan
agent1:                 episode reward: -0.0924,                 loss: 0.1620
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4183s / 574.6016 s
agent0:                 episode reward: -0.3576,                 loss: nan
agent1:                 episode reward: 0.3576,                 loss: 0.1636
Episode: 14471/30000 (48.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4155s / 575.0171 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.1653
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4134s / 575.4305 s
agent0:                 episode reward: -0.5079,                 loss: nan
agent1:                 episode reward: 0.5079,                 loss: 0.1656
Episode: 14491/30000 (48.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4154s / 575.8459 s
agent0:                 episode reward: -0.2215,                 loss: nan
agent1:                 episode reward: 0.2215,                 loss: 0.1669
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4158s / 576.2617 s
agent0:                 episode reward: -0.5755,                 loss: nan
agent1:                 episode reward: 0.5755,                 loss: 0.1657
Episode: 14511/30000 (48.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 576.6748 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1646
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4255s / 577.1002 s
agent0:                 episode reward: -0.4738,                 loss: nan
agent1:                 episode reward: 0.4738,                 loss: 0.1634
Episode: 14531/30000 (48.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 577.5176 s
agent0:                 episode reward: -0.5076,                 loss: nan
agent1:                 episode reward: 0.5076,                 loss: 0.1619
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4138s / 577.9314 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.1645
Episode: 14551/30000 (48.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4377s / 578.3691 s
agent0:                 episode reward: -0.2593,                 loss: nan
agent1:                 episode reward: 0.2593,                 loss: 0.1630
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4361s / 578.8052 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.1612
Episode: 14571/30000 (48.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4263s / 579.2314 s
agent0:                 episode reward: -0.2864,                 loss: nan
agent1:                 episode reward: 0.2864,                 loss: 0.1608
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4228s / 579.6542 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.1619
Episode: 14591/30000 (48.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4280s / 580.0822 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.1630
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 580.5279 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.1598
Episode: 14611/30000 (48.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4330s / 580.9609 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.1617
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4434s / 581.4043 s
agent0:                 episode reward: 0.1245,                 loss: nan
agent1:                 episode reward: -0.1245,                 loss: 0.1633
Episode: 14631/30000 (48.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 581.8519 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: 0.1587
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4534s / 582.3053 s
agent0:                 episode reward: -0.6511,                 loss: nan
agent1:                 episode reward: 0.6511,                 loss: 0.1621
Episode: 14651/30000 (48.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4332s / 582.7385 s
agent0:                 episode reward: -0.0319,                 loss: nan
agent1:                 episode reward: 0.0319,                 loss: 0.1629
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4334s / 583.1719 s
agent0:                 episode reward: 0.1857,                 loss: nan
agent1:                 episode reward: -0.1857,                 loss: 0.1606
Episode: 14671/30000 (48.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4412s / 583.6131 s
agent0:                 episode reward: -0.6928,                 loss: nan
agent1:                 episode reward: 0.6928,                 loss: 0.1625
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4435s / 584.0566 s
agent0:                 episode reward: -0.9176,                 loss: nan
agent1:                 episode reward: 0.9176,                 loss: 0.1617
Episode: 14691/30000 (48.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 584.5052 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.1650
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4418s / 584.9470 s
agent0:                 episode reward: -0.0008,                 loss: nan
agent1:                 episode reward: 0.0008,                 loss: 0.1633
Episode: 14711/30000 (49.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4461s / 585.3931 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: 0.1614
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4424s / 585.8355 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.1617
Episode: 14731/30000 (49.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4367s / 586.2722 s
agent0:                 episode reward: -0.7407,                 loss: nan
agent1:                 episode reward: 0.7407,                 loss: 0.1618
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4386s / 586.7108 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: 0.1633
Episode: 14751/30000 (49.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4625s / 587.1733 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: 0.1614
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4359s / 587.6092 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.1635
Episode: 14771/30000 (49.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4186s / 588.0278 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.1629
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 588.4490 s
agent0:                 episode reward: -0.6706,                 loss: nan
agent1:                 episode reward: 0.6706,                 loss: 0.1616
Episode: 14791/30000 (49.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4409s / 588.8898 s
agent0:                 episode reward: 0.0376,                 loss: nan
agent1:                 episode reward: -0.0376,                 loss: 0.1614
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 589.3245 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: 0.1644
Episode: 14811/30000 (49.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4360s / 589.7605 s
agent0:                 episode reward: -0.3992,                 loss: nan
agent1:                 episode reward: 0.3992,                 loss: 0.1630
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 590.2318 s
agent0:                 episode reward: -0.6019,                 loss: nan
agent1:                 episode reward: 0.6019,                 loss: 0.1622
Episode: 14831/30000 (49.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4497s / 590.6815 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.1598
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4364s / 591.1179 s
agent0:                 episode reward: -0.2308,                 loss: nan
agent1:                 episode reward: 0.2308,                 loss: 0.1644
Episode: 14851/30000 (49.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 591.5527 s
agent0:                 episode reward: -0.0120,                 loss: nan
agent1:                 episode reward: 0.0120,                 loss: 0.1602
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 591.9852 s
agent0:                 episode reward: -0.3872,                 loss: nan
agent1:                 episode reward: 0.3872,                 loss: 0.1645
Episode: 14871/30000 (49.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4357s / 592.4209 s
agent0:                 episode reward: 0.0500,                 loss: nan
agent1:                 episode reward: -0.0500,                 loss: 0.1614
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4314s / 592.8523 s
agent0:                 episode reward: 0.0430,                 loss: nan
agent1:                 episode reward: -0.0430,                 loss: 0.1638
Episode: 14891/30000 (49.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4478s / 593.3001 s
agent0:                 episode reward: -0.4466,                 loss: nan
agent1:                 episode reward: 0.4466,                 loss: 0.1610
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4451s / 593.7452 s
agent0:                 episode reward: -0.9737,                 loss: nan
agent1:                 episode reward: 0.9737,                 loss: 0.1648
Episode: 14911/30000 (49.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 594.1914 s
agent0:                 episode reward: -0.1077,                 loss: nan
agent1:                 episode reward: 0.1077,                 loss: 0.1630
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4354s / 594.6268 s
agent0:                 episode reward: -0.0658,                 loss: nan
agent1:                 episode reward: 0.0658,                 loss: 0.1641
Episode: 14931/30000 (49.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4710s / 595.0978 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.1640
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4667s / 595.5645 s
agent0:                 episode reward: -0.8768,                 loss: nan
agent1:                 episode reward: 0.8768,                 loss: 0.1637
Episode: 14951/30000 (49.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 596.0183 s
agent0:                 episode reward: -0.0359,                 loss: nan
agent1:                 episode reward: 0.0359,                 loss: 0.1647
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 596.5067 s
agent0:                 episode reward: -0.6965,                 loss: nan
agent1:                 episode reward: 0.6965,                 loss: 0.1608
Episode: 14971/30000 (49.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 596.9423 s
agent0:                 episode reward: -0.0296,                 loss: nan
agent1:                 episode reward: 0.0296,                 loss: 0.1603
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 597.4020 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: 0.1639
Episode: 14991/30000 (49.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4358s / 597.8378 s
agent0:                 episode reward: -0.1851,                 loss: nan
agent1:                 episode reward: 0.1851,                 loss: 0.1632
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4442s / 598.2820 s
agent0:                 episode reward: -0.2781,                 loss: nan
agent1:                 episode reward: 0.2781,                 loss: 0.1641
Episode: 15011/30000 (50.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4477s / 598.7297 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.1640
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 599.1688 s
agent0:                 episode reward: -0.9896,                 loss: nan
agent1:                 episode reward: 0.9896,                 loss: 0.1639
Episode: 15031/30000 (50.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4520s / 599.6209 s
agent0:                 episode reward: -0.6234,                 loss: nan
agent1:                 episode reward: 0.6234,                 loss: 0.1638
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 600.0565 s
agent0:                 episode reward: 0.0833,                 loss: nan
agent1:                 episode reward: -0.0833,                 loss: 0.1613
Episode: 15051/30000 (50.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4536s / 600.5101 s
agent0:                 episode reward: 0.4223,                 loss: nan
agent1:                 episode reward: -0.4223,                 loss: 0.1623
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4611s / 600.9712 s
agent0:                 episode reward: -0.1147,                 loss: nan
agent1:                 episode reward: 0.1147,                 loss: 0.1599
Episode: 15071/30000 (50.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4527s / 601.4239 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.1619
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4523s / 601.8762 s
agent0:                 episode reward: 0.2818,                 loss: nan
agent1:                 episode reward: -0.2818,                 loss: 0.1629
Episode: 15091/30000 (50.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4343s / 602.3105 s
agent0:                 episode reward: -0.7689,                 loss: nan
agent1:                 episode reward: 0.7689,                 loss: 0.1627
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4341s / 602.7445 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.1633
Episode: 15111/30000 (50.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4189s / 603.1634 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1647
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4182s / 603.5817 s
agent0:                 episode reward: -0.2922,                 loss: nan
agent1:                 episode reward: 0.2922,                 loss: 0.1634
Episode: 15131/30000 (50.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4213s / 604.0030 s
agent0:                 episode reward: 0.3205,                 loss: nan
agent1:                 episode reward: -0.3205,                 loss: 0.1642
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 604.4226 s
agent0:                 episode reward: 0.0299,                 loss: nan
agent1:                 episode reward: -0.0299,                 loss: 0.1643
Episode: 15151/30000 (50.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4215s / 604.8441 s
agent0:                 episode reward: 0.1414,                 loss: nan
agent1:                 episode reward: -0.1414,                 loss: 0.1631
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4249s / 605.2690 s
agent0:                 episode reward: 0.1272,                 loss: nan
agent1:                 episode reward: -0.1272,                 loss: 0.1624
Episode: 15171/30000 (50.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4709s / 605.7399 s
agent0:                 episode reward: 0.0499,                 loss: nan
agent1:                 episode reward: -0.0499,                 loss: 0.1610
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4313s / 606.1712 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.1619
Episode: 15191/30000 (50.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 606.5963 s
agent0:                 episode reward: 0.0724,                 loss: nan
agent1:                 episode reward: -0.0724,                 loss: 0.1621
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4214s / 607.0177 s
agent0:                 episode reward: -0.1052,                 loss: nan
agent1:                 episode reward: 0.1052,                 loss: 0.1627
Episode: 15211/30000 (50.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4210s / 607.4387 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.1630
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 607.8599 s
agent0:                 episode reward: -0.0528,                 loss: nan
agent1:                 episode reward: 0.0528,                 loss: 0.1613
Episode: 15231/30000 (50.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4222s / 608.2821 s
agent0:                 episode reward: -0.1180,                 loss: nan
agent1:                 episode reward: 0.1180,                 loss: 0.1631
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4234s / 608.7055 s
agent0:                 episode reward: 0.1305,                 loss: nan
agent1:                 episode reward: -0.1305,                 loss: 0.1621
Episode: 15251/30000 (50.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4200s / 609.1255 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.1607
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4219s / 609.5474 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.1634
Episode: 15271/30000 (50.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4178s / 609.9652 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.1599
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4228s / 610.3880 s
agent0:                 episode reward: 0.0264,                 loss: nan
agent1:                 episode reward: -0.0264,                 loss: 0.1626
Episode: 15291/30000 (50.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4184s / 610.8064 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.1631
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4457s / 611.2520 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1635
Episode: 15311/30000 (51.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4219s / 611.6739 s
agent0:                 episode reward: 0.0940,                 loss: nan
agent1:                 episode reward: -0.0940,                 loss: 0.1638
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4193s / 612.0932 s
agent0:                 episode reward: -0.1188,                 loss: nan
agent1:                 episode reward: 0.1188,                 loss: 0.1636
Episode: 15331/30000 (51.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4186s / 612.5118 s
agent0:                 episode reward: -0.3108,                 loss: nan
agent1:                 episode reward: 0.3108,                 loss: 0.1624
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4187s / 612.9305 s
agent0:                 episode reward: -0.2611,                 loss: nan
agent1:                 episode reward: 0.2611,                 loss: 0.1635
Episode: 15351/30000 (51.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4371s / 613.3676 s
agent0:                 episode reward: -0.7654,                 loss: nan
agent1:                 episode reward: 0.7654,                 loss: 0.1631
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4494s / 613.8170 s
agent0:                 episode reward: -0.1851,                 loss: nan
agent1:                 episode reward: 0.1851,                 loss: 0.1633
Episode: 15371/30000 (51.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 614.2731 s
agent0:                 episode reward: 0.3430,                 loss: nan
agent1:                 episode reward: -0.3430,                 loss: 0.1615
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4253s / 614.6985 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.1655
Episode: 15391/30000 (51.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4278s / 615.1263 s
agent0:                 episode reward: -0.3204,                 loss: nan
agent1:                 episode reward: 0.3204,                 loss: 0.1611
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4311s / 615.5574 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.1618
Episode: 15411/30000 (51.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4625s / 616.0199 s
agent0:                 episode reward: 0.1830,                 loss: nan
agent1:                 episode reward: -0.1830,                 loss: 0.1614
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4464s / 616.4663 s
agent0:                 episode reward: -0.6032,                 loss: nan
agent1:                 episode reward: 0.6032,                 loss: 0.1624
Episode: 15431/30000 (51.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4417s / 616.9081 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.1632
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4523s / 617.3604 s
agent0:                 episode reward: -0.4673,                 loss: nan
agent1:                 episode reward: 0.4673,                 loss: 0.1643
Episode: 15451/30000 (51.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4487s / 617.8091 s
agent0:                 episode reward: -0.1687,                 loss: nan
agent1:                 episode reward: 0.1687,                 loss: 0.1620
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4274s / 618.2365 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.1620
Episode: 15471/30000 (51.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4294s / 618.6658 s
agent0:                 episode reward: -0.0632,                 loss: nan
agent1:                 episode reward: 0.0632,                 loss: 0.1638
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4259s / 619.0917 s
agent0:                 episode reward: -0.3011,                 loss: nan
agent1:                 episode reward: 0.3011,                 loss: 0.1643
Episode: 15491/30000 (51.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4147s / 619.5064 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.1625
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4205s / 619.9269 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1592
Episode: 15511/30000 (51.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4293s / 620.3562 s
agent0:                 episode reward: -0.0330,                 loss: nan
agent1:                 episode reward: 0.0330,                 loss: 0.1601
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4436s / 620.7997 s
agent0:                 episode reward: 0.1988,                 loss: nan
agent1:                 episode reward: -0.1988,                 loss: 0.1626
Episode: 15531/30000 (51.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4400s / 621.2397 s
agent0:                 episode reward: -0.2840,                 loss: nan
agent1:                 episode reward: 0.2840,                 loss: 0.1643
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4425s / 621.6822 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.1654
Episode: 15551/30000 (51.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4435s / 622.1257 s
agent0:                 episode reward: -0.9272,                 loss: nan
agent1:                 episode reward: 0.9272,                 loss: 0.1615
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4735s / 622.5992 s
agent0:                 episode reward: -0.6817,                 loss: nan
agent1:                 episode reward: 0.6817,                 loss: 0.1659
Episode: 15571/30000 (51.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 623.0450 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1649
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 623.5206 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: 0.1623
Episode: 15591/30000 (51.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4663s / 623.9868 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.1660
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4607s / 624.4475 s
agent0:                 episode reward: -0.9005,                 loss: nan
agent1:                 episode reward: 0.9005,                 loss: 0.1614
Episode: 15611/30000 (52.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4445s / 624.8920 s
agent0:                 episode reward: -0.1785,                 loss: nan
agent1:                 episode reward: 0.1785,                 loss: 0.1639
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4364s / 625.3284 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.1661
Episode: 15631/30000 (52.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4489s / 625.7773 s
agent0:                 episode reward: -0.3480,                 loss: nan
agent1:                 episode reward: 0.3480,                 loss: 0.1644
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4548s / 626.2322 s
agent0:                 episode reward: -0.2259,                 loss: nan
agent1:                 episode reward: 0.2259,                 loss: 0.1630
Episode: 15651/30000 (52.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4804s / 626.7125 s
agent0:                 episode reward: -0.2292,                 loss: nan
agent1:                 episode reward: 0.2292,                 loss: 0.1647
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4441s / 627.1566 s
agent0:                 episode reward: -0.2384,                 loss: nan
agent1:                 episode reward: 0.2384,                 loss: 0.1661
Episode: 15671/30000 (52.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4416s / 627.5983 s
agent0:                 episode reward: -0.5240,                 loss: nan
agent1:                 episode reward: 0.5240,                 loss: 0.1654
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4349s / 628.0332 s
agent0:                 episode reward: -0.3729,                 loss: nan
agent1:                 episode reward: 0.3729,                 loss: 0.1653
Episode: 15691/30000 (52.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4332s / 628.4664 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.1642
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 628.8989 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.1661
Episode: 15711/30000 (52.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4339s / 629.3328 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.1643
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4515s / 629.7843 s
agent0:                 episode reward: -0.6787,                 loss: nan
agent1:                 episode reward: 0.6787,                 loss: 0.1635
Episode: 15731/30000 (52.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4386s / 630.2229 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.1641
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 630.6817 s
agent0:                 episode reward: -0.1440,                 loss: nan
agent1:                 episode reward: 0.1440,                 loss: 0.1624
Episode: 15751/30000 (52.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 631.1247 s
agent0:                 episode reward: -0.3671,                 loss: nan
agent1:                 episode reward: 0.3671,                 loss: 0.1629
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4424s / 631.5672 s
agent0:                 episode reward: -0.9349,                 loss: nan
agent1:                 episode reward: 0.9349,                 loss: 0.1636
Episode: 15771/30000 (52.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4427s / 632.0099 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.1605
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4384s / 632.4483 s
agent0:                 episode reward: -0.2227,                 loss: nan
agent1:                 episode reward: 0.2227,                 loss: 0.1616
Episode: 15791/30000 (52.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4864s / 632.9347 s
agent0:                 episode reward: 0.1858,                 loss: nan
agent1:                 episode reward: -0.1858,                 loss: 0.1645
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4596s / 633.3942 s
agent0:                 episode reward: -0.5194,                 loss: nan
agent1:                 episode reward: 0.5194,                 loss: 0.1653
Episode: 15811/30000 (52.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4569s / 633.8511 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1656
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4399s / 634.2910 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.1634
Episode: 15831/30000 (52.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4501s / 634.7411 s
agent0:                 episode reward: 0.0254,                 loss: nan
agent1:                 episode reward: -0.0254,                 loss: 0.1660
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4730s / 635.2142 s
agent0:                 episode reward: -0.3055,                 loss: nan
agent1:                 episode reward: 0.3055,                 loss: 0.1626
Episode: 15851/30000 (52.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4561s / 635.6703 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1633
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 636.1292 s
agent0:                 episode reward: -0.4292,                 loss: nan
agent1:                 episode reward: 0.4292,                 loss: 0.1625
Episode: 15871/30000 (52.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4456s / 636.5748 s
agent0:                 episode reward: -0.3061,                 loss: nan
agent1:                 episode reward: 0.3061,                 loss: 0.1630
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4454s / 637.0201 s
agent0:                 episode reward: -0.2715,                 loss: nan
agent1:                 episode reward: 0.2715,                 loss: 0.1639
Episode: 15891/30000 (52.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4483s / 637.4685 s
agent0:                 episode reward: -0.4929,                 loss: nan
agent1:                 episode reward: 0.4929,                 loss: 0.1636
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 637.9105 s
agent0:                 episode reward: -0.2820,                 loss: nan
agent1:                 episode reward: 0.2820,                 loss: 0.1632
Episode: 15911/30000 (53.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4451s / 638.3556 s
agent0:                 episode reward: -0.0585,                 loss: nan
agent1:                 episode reward: 0.0585,                 loss: 0.1657
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4577s / 638.8133 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.1655
Episode: 15931/30000 (53.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 639.2846 s
agent0:                 episode reward: -0.4459,                 loss: nan
agent1:                 episode reward: 0.4459,                 loss: 0.1649
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 639.7368 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.1675
Episode: 15951/30000 (53.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4659s / 640.2027 s
agent0:                 episode reward: 0.1228,                 loss: nan
agent1:                 episode reward: -0.1228,                 loss: 0.1640
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4706s / 640.6733 s
agent0:                 episode reward: 0.1306,                 loss: nan
agent1:                 episode reward: -0.1306,                 loss: 0.1646
Episode: 15971/30000 (53.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 641.1322 s
agent0:                 episode reward: 0.0278,                 loss: nan
agent1:                 episode reward: -0.0278,                 loss: 0.1628
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 641.5807 s
agent0:                 episode reward: -0.7215,                 loss: nan
agent1:                 episode reward: 0.7215,                 loss: 0.1637
Episode: 15991/30000 (53.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4665s / 642.0473 s
agent0:                 episode reward: -0.5174,                 loss: nan
agent1:                 episode reward: 0.5174,                 loss: 0.1660
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4546s / 642.5019 s
agent0:                 episode reward: -0.1937,                 loss: nan
agent1:                 episode reward: 0.1937,                 loss: 0.1658
Episode: 16011/30000 (53.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4326s / 642.9345 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.1662
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4432s / 643.3777 s
agent0:                 episode reward: -0.3340,                 loss: nan
agent1:                 episode reward: 0.3340,                 loss: 0.1665
Episode: 16031/30000 (53.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4351s / 643.8129 s
agent0:                 episode reward: -0.3138,                 loss: nan
agent1:                 episode reward: 0.3138,                 loss: 0.1625
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4375s / 644.2504 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1641
Episode: 16051/30000 (53.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4425s / 644.6929 s
agent0:                 episode reward: -0.1968,                 loss: nan
agent1:                 episode reward: 0.1968,                 loss: 0.1639
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4628s / 645.1558 s
agent0:                 episode reward: -0.2509,                 loss: nan
agent1:                 episode reward: 0.2509,                 loss: 0.1642
Episode: 16071/30000 (53.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4430s / 645.5988 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1629
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4376s / 646.0363 s
agent0:                 episode reward: 0.3947,                 loss: nan
agent1:                 episode reward: -0.3947,                 loss: 0.1679
Episode: 16091/30000 (53.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4371s / 646.4735 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: 0.1642
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4463s / 646.9197 s
agent0:                 episode reward: -0.9374,                 loss: nan
agent1:                 episode reward: 0.9374,                 loss: 0.1650
Episode: 16111/30000 (53.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 647.4095 s
agent0:                 episode reward: -0.7798,                 loss: nan
agent1:                 episode reward: 0.7798,                 loss: 0.1632
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4533s / 647.8629 s
agent0:                 episode reward: -0.3062,                 loss: nan
agent1:                 episode reward: 0.3062,                 loss: 0.1655
Episode: 16131/30000 (53.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4584s / 648.3213 s
agent0:                 episode reward: -0.2560,                 loss: nan
agent1:                 episode reward: 0.2560,                 loss: 0.1621
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4359s / 648.7572 s
agent0:                 episode reward: -0.4673,                 loss: nan
agent1:                 episode reward: 0.4673,                 loss: 0.1624
Episode: 16151/30000 (53.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 649.2058 s
agent0:                 episode reward: -0.1970,                 loss: nan
agent1:                 episode reward: 0.1970,                 loss: 0.1655
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4472s / 649.6530 s
agent0:                 episode reward: -0.0333,                 loss: nan
agent1:                 episode reward: 0.0333,                 loss: 0.1640
Episode: 16171/30000 (53.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4388s / 650.0918 s
agent0:                 episode reward: -0.8074,                 loss: nan
agent1:                 episode reward: 0.8074,                 loss: 0.1639
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4223s / 650.5141 s
agent0:                 episode reward: -0.1485,                 loss: nan
agent1:                 episode reward: 0.1485,                 loss: 0.1646
Episode: 16191/30000 (53.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4357s / 650.9499 s
agent0:                 episode reward: -0.2435,                 loss: nan
agent1:                 episode reward: 0.2435,                 loss: 0.1636
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4427s / 651.3926 s
agent0:                 episode reward: -0.2256,                 loss: nan
agent1:                 episode reward: 0.2256,                 loss: 0.1665
Episode: 16211/30000 (54.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4234s / 651.8160 s
agent0:                 episode reward: -0.4470,                 loss: nan
agent1:                 episode reward: 0.4470,                 loss: 0.1670
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4219s / 652.2379 s
agent0:                 episode reward: -0.6305,                 loss: nan
agent1:                 episode reward: 0.6305,                 loss: 0.1624
Episode: 16231/30000 (54.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4239s / 652.6618 s
agent0:                 episode reward: -0.2352,                 loss: nan
agent1:                 episode reward: 0.2352,                 loss: 0.1604
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4232s / 653.0850 s
agent0:                 episode reward: -0.0466,                 loss: nan
agent1:                 episode reward: 0.0466,                 loss: 0.1625
Episode: 16251/30000 (54.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4233s / 653.5083 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.1626
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4198s / 653.9281 s
agent0:                 episode reward: -0.7955,                 loss: nan
agent1:                 episode reward: 0.7955,                 loss: 0.1620
Episode: 16271/30000 (54.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4531s / 654.3812 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: 0.1643
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 654.8042 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.1661
Episode: 16291/30000 (54.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4735s / 655.2777 s
agent0:                 episode reward: -0.3418,                 loss: nan
agent1:                 episode reward: 0.3418,                 loss: 0.1604
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4793s / 655.7570 s
agent0:                 episode reward: -0.2204,                 loss: nan
agent1:                 episode reward: 0.2204,                 loss: 0.1625
Episode: 16311/30000 (54.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 656.2031 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.1613
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4450s / 656.6482 s
agent0:                 episode reward: -0.1095,                 loss: nan
agent1:                 episode reward: 0.1095,                 loss: 0.1629
Episode: 16331/30000 (54.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4502s / 657.0984 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1657
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4512s / 657.5495 s
agent0:                 episode reward: -0.2723,                 loss: nan
agent1:                 episode reward: 0.2723,                 loss: 0.1601
Episode: 16351/30000 (54.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 657.9927 s
agent0:                 episode reward: -0.1260,                 loss: nan
agent1:                 episode reward: 0.1260,                 loss: 0.1613
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4477s / 658.4404 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.1629
Episode: 16371/30000 (54.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4440s / 658.8843 s
agent0:                 episode reward: -0.0137,                 loss: nan
agent1:                 episode reward: 0.0137,                 loss: 0.1656
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4532s / 659.3376 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.1634
Episode: 16391/30000 (54.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 659.7881 s
agent0:                 episode reward: -0.3430,                 loss: nan
agent1:                 episode reward: 0.3430,                 loss: 0.1623
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4593s / 660.2474 s
agent0:                 episode reward: -0.0341,                 loss: nan
agent1:                 episode reward: 0.0341,                 loss: 0.1626
Episode: 16411/30000 (54.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4578s / 660.7052 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.1632
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4479s / 661.1530 s
agent0:                 episode reward: -0.3905,                 loss: nan
agent1:                 episode reward: 0.3905,                 loss: 0.1634
Episode: 16431/30000 (54.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4493s / 661.6023 s
agent0:                 episode reward: -0.1990,                 loss: nan
agent1:                 episode reward: 0.1990,                 loss: 0.1635
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4511s / 662.0534 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.1650
Episode: 16451/30000 (54.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4541s / 662.5075 s
agent0:                 episode reward: -0.2308,                 loss: nan
agent1:                 episode reward: 0.2308,                 loss: 0.1655
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4490s / 662.9565 s
agent0:                 episode reward: -1.1110,                 loss: nan
agent1:                 episode reward: 1.1110,                 loss: 0.1623
Episode: 16471/30000 (54.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4718s / 663.4283 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.1626
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 663.8581 s
agent0:                 episode reward: 0.1713,                 loss: nan
agent1:                 episode reward: -0.1713,                 loss: 0.1641
Episode: 16491/30000 (54.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4692s / 664.3273 s
agent0:                 episode reward: -0.3913,                 loss: nan
agent1:                 episode reward: 0.3913,                 loss: 0.1631
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4460s / 664.7733 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1614
Episode: 16511/30000 (55.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4469s / 665.2202 s
agent0:                 episode reward: -0.1099,                 loss: nan
agent1:                 episode reward: 0.1099,                 loss: 0.1644
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4425s / 665.6628 s
agent0:                 episode reward: -0.6832,                 loss: nan
agent1:                 episode reward: 0.6832,                 loss: 0.1621
Episode: 16531/30000 (55.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4469s / 666.1097 s
agent0:                 episode reward: -0.2939,                 loss: nan
agent1:                 episode reward: 0.2939,                 loss: 0.1643
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4710s / 666.5807 s
agent0:                 episode reward: -0.0871,                 loss: nan
agent1:                 episode reward: 0.0871,                 loss: 0.1652
Episode: 16551/30000 (55.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4525s / 667.0332 s
agent0:                 episode reward: -0.0766,                 loss: nan
agent1:                 episode reward: 0.0766,                 loss: 0.1593
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4558s / 667.4890 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.1591
Episode: 16571/30000 (55.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4488s / 667.9378 s
agent0:                 episode reward: -0.4202,                 loss: nan
agent1:                 episode reward: 0.4202,                 loss: 0.1634
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4492s / 668.3870 s
agent0:                 episode reward: 0.1182,                 loss: nan
agent1:                 episode reward: -0.1182,                 loss: 0.1640
Episode: 16591/30000 (55.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4494s / 668.8364 s
agent0:                 episode reward: -0.9466,                 loss: nan
agent1:                 episode reward: 0.9466,                 loss: 0.1633
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4592s / 669.2956 s
agent0:                 episode reward: -0.3627,                 loss: nan
agent1:                 episode reward: 0.3627,                 loss: 0.1629
Episode: 16611/30000 (55.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4580s / 669.7535 s
agent0:                 episode reward: -0.5029,                 loss: nan
agent1:                 episode reward: 0.5029,                 loss: 0.1612
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 670.1987 s
agent0:                 episode reward: -0.8319,                 loss: nan
agent1:                 episode reward: 0.8319,                 loss: 0.1602
Episode: 16631/30000 (55.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4478s / 670.6465 s
agent0:                 episode reward: -0.4870,                 loss: nan
agent1:                 episode reward: 0.4870,                 loss: 0.1625
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4318s / 671.0783 s
agent0:                 episode reward: -0.3975,                 loss: nan
agent1:                 episode reward: 0.3975,                 loss: 0.1647
Episode: 16651/30000 (55.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4225s / 671.5008 s
agent0:                 episode reward: -0.0162,                 loss: nan
agent1:                 episode reward: 0.0162,                 loss: 0.1606
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 671.9260 s
agent0:                 episode reward: -0.2860,                 loss: nan
agent1:                 episode reward: 0.2860,                 loss: 0.1605
Episode: 16671/30000 (55.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4740s / 672.4000 s
agent0:                 episode reward: -0.1508,                 loss: nan
agent1:                 episode reward: 0.1508,                 loss: 0.1634
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4436s / 672.8436 s
agent0:                 episode reward: 0.0408,                 loss: nan
agent1:                 episode reward: -0.0408,                 loss: 0.1603
Episode: 16691/30000 (55.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 673.2867 s
agent0:                 episode reward: -0.1002,                 loss: nan
agent1:                 episode reward: 0.1002,                 loss: 0.1609
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4535s / 673.7402 s
agent0:                 episode reward: -0.0643,                 loss: nan
agent1:                 episode reward: 0.0643,                 loss: 0.1638
Episode: 16711/30000 (55.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4430s / 674.1832 s
agent0:                 episode reward: 0.1129,                 loss: nan
agent1:                 episode reward: -0.1129,                 loss: 0.1618
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4526s / 674.6358 s
agent0:                 episode reward: -0.9746,                 loss: nan
agent1:                 episode reward: 0.9746,                 loss: 0.1618
Episode: 16731/30000 (55.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4599s / 675.0958 s
agent0:                 episode reward: 0.5989,                 loss: nan
agent1:                 episode reward: -0.5989,                 loss: 0.1621
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 675.5734 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.1613
Episode: 16751/30000 (55.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4580s / 676.0314 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.1629
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 676.4799 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.1620
Episode: 16771/30000 (55.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4523s / 676.9322 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.1607
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4466s / 677.3789 s
agent0:                 episode reward: 0.2080,                 loss: nan
agent1:                 episode reward: -0.2080,                 loss: 0.1624
Episode: 16791/30000 (55.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4491s / 677.8280 s
agent0:                 episode reward: -0.6954,                 loss: nan
agent1:                 episode reward: 0.6954,                 loss: 0.1623
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4570s / 678.2850 s
agent0:                 episode reward: -0.4806,                 loss: nan
agent1:                 episode reward: 0.4806,                 loss: 0.1637
Episode: 16811/30000 (56.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4566s / 678.7415 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.1613
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4517s / 679.1932 s
agent0:                 episode reward: 0.0327,                 loss: nan
agent1:                 episode reward: -0.0327,                 loss: 0.1607
Episode: 16831/30000 (56.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4517s / 679.6449 s
agent0:                 episode reward: -0.1711,                 loss: nan
agent1:                 episode reward: 0.1711,                 loss: 0.1626
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4491s / 680.0940 s
agent0:                 episode reward: 0.0492,                 loss: nan
agent1:                 episode reward: -0.0492,                 loss: 0.1586
Episode: 16851/30000 (56.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4498s / 680.5438 s
agent0:                 episode reward: 0.1009,                 loss: nan
agent1:                 episode reward: -0.1009,                 loss: 0.1619
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4767s / 681.0205 s
agent0:                 episode reward: -0.1959,                 loss: nan
agent1:                 episode reward: 0.1959,                 loss: 0.1644
Episode: 16871/30000 (56.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4621s / 681.4826 s
agent0:                 episode reward: -0.1675,                 loss: nan
agent1:                 episode reward: 0.1675,                 loss: 0.1608
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4539s / 681.9364 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.1635
Episode: 16891/30000 (56.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4514s / 682.3878 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.1639
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4493s / 682.8371 s
agent0:                 episode reward: -0.3391,                 loss: nan
agent1:                 episode reward: 0.3391,                 loss: 0.1617
Episode: 16911/30000 (56.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 683.2857 s
agent0:                 episode reward: -1.0244,                 loss: nan
agent1:                 episode reward: 1.0244,                 loss: 0.1657
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4498s / 683.7356 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.1608
Episode: 16931/30000 (56.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4473s / 684.1828 s
agent0:                 episode reward: -0.0178,                 loss: nan
agent1:                 episode reward: 0.0178,                 loss: 0.1630
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4699s / 684.6527 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: 0.1618
Episode: 16951/30000 (56.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4518s / 685.1045 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.1626
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4461s / 685.5506 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.1617
Episode: 16971/30000 (56.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 686.0011 s
agent0:                 episode reward: -0.1758,                 loss: nan
agent1:                 episode reward: 0.1758,                 loss: 0.1632
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4398s / 686.4409 s
agent0:                 episode reward: 0.0149,                 loss: nan
agent1:                 episode reward: -0.0149,                 loss: 0.1598
Episode: 16991/30000 (56.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4283s / 686.8692 s
agent0:                 episode reward: -0.4453,                 loss: nan
agent1:                 episode reward: 0.4453,                 loss: 0.1586
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4286s / 687.2979 s
agent0:                 episode reward: -0.4586,                 loss: nan
agent1:                 episode reward: 0.4586,                 loss: 0.1622
Episode: 17011/30000 (56.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4474s / 687.7453 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1614
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4316s / 688.1768 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.1624
Episode: 17031/30000 (56.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 688.6230 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: 0.1595
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4465s / 689.0695 s
agent0:                 episode reward: -0.7709,                 loss: nan
agent1:                 episode reward: 0.7709,                 loss: 0.1620
Episode: 17051/30000 (56.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 689.5012 s
agent0:                 episode reward: -0.4843,                 loss: nan
agent1:                 episode reward: 0.4843,                 loss: 0.1585
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4236s / 689.9248 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.1618
Episode: 17071/30000 (56.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 690.3499 s
agent0:                 episode reward: -0.0167,                 loss: nan
agent1:                 episode reward: 0.0167,                 loss: 0.1619
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4555s / 690.8055 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.1624
Episode: 17091/30000 (56.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4343s / 691.2398 s
agent0:                 episode reward: -0.0542,                 loss: nan
agent1:                 episode reward: 0.0542,                 loss: 0.1620
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4274s / 691.6671 s
agent0:                 episode reward: -0.2693,                 loss: nan
agent1:                 episode reward: 0.2693,                 loss: 0.1607
Episode: 17111/30000 (57.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4428s / 692.1099 s
agent0:                 episode reward: -0.1317,                 loss: nan
agent1:                 episode reward: 0.1317,                 loss: 0.1623
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4395s / 692.5494 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.1632
Episode: 17131/30000 (57.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 692.9914 s
agent0:                 episode reward: -0.2104,                 loss: nan
agent1:                 episode reward: 0.2104,                 loss: 0.1607
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4390s / 693.4305 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.1626
Episode: 17151/30000 (57.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 693.8910 s
agent0:                 episode reward: -0.2201,                 loss: nan
agent1:                 episode reward: 0.2201,                 loss: 0.1613
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 694.3330 s
agent0:                 episode reward: 0.2682,                 loss: nan
agent1:                 episode reward: -0.2682,                 loss: 0.1628
Episode: 17171/30000 (57.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4386s / 694.7716 s
agent0:                 episode reward: -0.2380,                 loss: nan
agent1:                 episode reward: 0.2380,                 loss: 0.1632
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4466s / 695.2182 s
agent0:                 episode reward: -0.1688,                 loss: nan
agent1:                 episode reward: 0.1688,                 loss: 0.1616
Episode: 17191/30000 (57.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 695.6574 s
agent0:                 episode reward: -0.5239,                 loss: nan
agent1:                 episode reward: 0.5239,                 loss: 0.1615
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 696.1083 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: 0.1629
Episode: 17211/30000 (57.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4541s / 696.5624 s
agent0:                 episode reward: -0.2730,                 loss: nan
agent1:                 episode reward: 0.2730,                 loss: 0.1603
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4648s / 697.0273 s
agent0:                 episode reward: -0.3711,                 loss: nan
agent1:                 episode reward: 0.3711,                 loss: 0.1620
Episode: 17231/30000 (57.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4771s / 697.5044 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.1624
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4488s / 697.9531 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.1603
Episode: 17251/30000 (57.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 698.4041 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.1597
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4511s / 698.8552 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1601
Episode: 17271/30000 (57.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4541s / 699.3093 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.1624
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4770s / 699.7864 s
agent0:                 episode reward: -0.3769,                 loss: nan
agent1:                 episode reward: 0.3769,                 loss: 0.1607
Episode: 17291/30000 (57.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4604s / 700.2468 s
agent0:                 episode reward: -0.1239,                 loss: nan
agent1:                 episode reward: 0.1239,                 loss: 0.1603
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 700.6930 s
agent0:                 episode reward: -0.2078,                 loss: nan
agent1:                 episode reward: 0.2078,                 loss: 0.1607
Episode: 17311/30000 (57.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4379s / 701.1309 s
agent0:                 episode reward: -0.1780,                 loss: nan
agent1:                 episode reward: 0.1780,                 loss: 0.1622
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4478s / 701.5787 s
agent0:                 episode reward: -0.2567,                 loss: nan
agent1:                 episode reward: 0.2567,                 loss: 0.1614
Episode: 17331/30000 (57.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 702.0196 s
agent0:                 episode reward: -0.4292,                 loss: nan
agent1:                 episode reward: 0.4292,                 loss: 0.1607
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 702.4589 s
agent0:                 episode reward: 0.2026,                 loss: nan
agent1:                 episode reward: -0.2026,                 loss: 0.1623
Episode: 17351/30000 (57.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4565s / 702.9154 s
agent0:                 episode reward: -0.8942,                 loss: nan
agent1:                 episode reward: 0.8942,                 loss: 0.1611
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4363s / 703.3517 s
agent0:                 episode reward: -0.1069,                 loss: nan
agent1:                 episode reward: 0.1069,                 loss: 0.1643
Episode: 17371/30000 (57.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4312s / 703.7829 s
agent0:                 episode reward: -0.7563,                 loss: nan
agent1:                 episode reward: 0.7563,                 loss: 0.1605
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4295s / 704.2124 s
agent0:                 episode reward: -0.0780,                 loss: nan
agent1:                 episode reward: 0.0780,                 loss: 0.1616
Episode: 17391/30000 (57.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4328s / 704.6452 s
agent0:                 episode reward: 0.2883,                 loss: nan
agent1:                 episode reward: -0.2883,                 loss: 0.1644
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4311s / 705.0763 s
agent0:                 episode reward: -0.1519,                 loss: nan
agent1:                 episode reward: 0.1519,                 loss: 0.1616
Episode: 17411/30000 (58.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4353s / 705.5116 s
agent0:                 episode reward: 0.3128,                 loss: nan
agent1:                 episode reward: -0.3128,                 loss: 0.1614
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4980s / 706.0095 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.1615
Episode: 17431/30000 (58.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4353s / 706.4448 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: 0.1620
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4428s / 706.8876 s
agent0:                 episode reward: -0.2596,                 loss: nan
agent1:                 episode reward: 0.2596,                 loss: 0.1594
Episode: 17451/30000 (58.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 707.3313 s
agent0:                 episode reward: -0.1159,                 loss: nan
agent1:                 episode reward: 0.1159,                 loss: 0.1599
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 707.7669 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.1593
Episode: 17471/30000 (58.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4390s / 708.2059 s
agent0:                 episode reward: -0.0925,                 loss: nan
agent1:                 episode reward: 0.0925,                 loss: 0.1607
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4297s / 708.6356 s
agent0:                 episode reward: 0.2322,                 loss: nan
agent1:                 episode reward: -0.2322,                 loss: 0.1603
Episode: 17491/30000 (58.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4369s / 709.0725 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.1616
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4753s / 709.5477 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.1600
Episode: 17511/30000 (58.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4319s / 709.9796 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.1599
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4375s / 710.4172 s
agent0:                 episode reward: -0.4440,                 loss: nan
agent1:                 episode reward: 0.4440,                 loss: 0.1606
Episode: 17531/30000 (58.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4610s / 710.8782 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.1611
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4500s / 711.3282 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: 0.1591
Episode: 17551/30000 (58.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4570s / 711.7852 s
agent0:                 episode reward: -0.0023,                 loss: nan
agent1:                 episode reward: 0.0023,                 loss: 0.1610
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4314s / 712.2166 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.1589
Episode: 17571/30000 (58.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 712.6490 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.1609
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4339s / 713.0829 s
agent0:                 episode reward: -0.1486,                 loss: nan
agent1:                 episode reward: 0.1486,                 loss: 0.1609
Episode: 17591/30000 (58.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4315s / 713.5144 s
agent0:                 episode reward: 0.1609,                 loss: nan
agent1:                 episode reward: -0.1609,                 loss: 0.1597
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4319s / 713.9463 s
agent0:                 episode reward: -0.3256,                 loss: nan
agent1:                 episode reward: 0.3256,                 loss: 0.1611
Episode: 17611/30000 (58.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4693s / 714.4156 s
agent0:                 episode reward: -0.9599,                 loss: nan
agent1:                 episode reward: 0.9599,                 loss: 0.1600
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4752s / 714.8908 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.1611
Episode: 17631/30000 (58.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4785s / 715.3693 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.1618
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4742s / 715.8434 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.1629
Episode: 17651/30000 (58.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4694s / 716.3128 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.1611
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4675s / 716.7804 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1590
Episode: 17671/30000 (58.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4623s / 717.2427 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.1584
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4606s / 717.7033 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.1595
Episode: 17691/30000 (58.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4811s / 718.1844 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.1600
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4481s / 718.6326 s
agent0:                 episode reward: -0.4846,                 loss: nan
agent1:                 episode reward: 0.4846,                 loss: 0.1603
Episode: 17711/30000 (59.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4440s / 719.0765 s
agent0:                 episode reward: 0.1447,                 loss: nan
agent1:                 episode reward: -0.1447,                 loss: 0.1596
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4446s / 719.5211 s
agent0:                 episode reward: 0.2477,                 loss: nan
agent1:                 episode reward: -0.2477,                 loss: 0.1606
Episode: 17731/30000 (59.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4393s / 719.9605 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.1610
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4447s / 720.4052 s
agent0:                 episode reward: 0.0131,                 loss: nan
agent1:                 episode reward: -0.0131,                 loss: 0.1614
Episode: 17751/30000 (59.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 720.8708 s
agent0:                 episode reward: -0.1486,                 loss: nan
agent1:                 episode reward: 0.1486,                 loss: 0.1587
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4381s / 721.3089 s
agent0:                 episode reward: -0.6381,                 loss: nan
agent1:                 episode reward: 0.6381,                 loss: 0.1592
Episode: 17771/30000 (59.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4340s / 721.7429 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.1601
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4331s / 722.1759 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.1634
Episode: 17791/30000 (59.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4610s / 722.6369 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: 0.1580
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 723.0806 s
agent0:                 episode reward: -0.8269,                 loss: nan
agent1:                 episode reward: 0.8269,                 loss: 0.1601
Episode: 17811/30000 (59.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 723.5291 s
agent0:                 episode reward: -0.0654,                 loss: nan
agent1:                 episode reward: 0.0654,                 loss: 0.1573
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4807s / 724.0098 s
agent0:                 episode reward: 0.1903,                 loss: nan
agent1:                 episode reward: -0.1903,                 loss: 0.1591
Episode: 17831/30000 (59.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4558s / 724.4656 s
agent0:                 episode reward: -0.2529,                 loss: nan
agent1:                 episode reward: 0.2529,                 loss: 0.1602
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4446s / 724.9102 s
agent0:                 episode reward: -0.3995,                 loss: nan
agent1:                 episode reward: 0.3995,                 loss: 0.1606
Episode: 17851/30000 (59.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4446s / 725.3548 s
agent0:                 episode reward: -0.1542,                 loss: nan
agent1:                 episode reward: 0.1542,                 loss: 0.1606
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4425s / 725.7973 s
agent0:                 episode reward: -0.0490,                 loss: nan
agent1:                 episode reward: 0.0490,                 loss: 0.1587
Episode: 17871/30000 (59.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4467s / 726.2440 s
agent0:                 episode reward: -0.2840,                 loss: nan
agent1:                 episode reward: 0.2840,                 loss: 0.1590
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4448s / 726.6888 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.1593
Episode: 17891/30000 (59.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4698s / 727.1586 s
agent0:                 episode reward: 0.0821,                 loss: nan
agent1:                 episode reward: -0.0821,                 loss: 0.1599
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4519s / 727.6106 s
agent0:                 episode reward: -0.3199,                 loss: nan
agent1:                 episode reward: 0.3199,                 loss: 0.1618
Episode: 17911/30000 (59.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4521s / 728.0627 s
agent0:                 episode reward: 0.0094,                 loss: nan
agent1:                 episode reward: -0.0094,                 loss: 0.1615
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4574s / 728.5201 s
agent0:                 episode reward: 0.0758,                 loss: nan
agent1:                 episode reward: -0.0758,                 loss: 0.1651
Episode: 17931/30000 (59.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4550s / 728.9751 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.1605
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4520s / 729.4271 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.1632
Episode: 17951/30000 (59.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4548s / 729.8819 s
agent0:                 episode reward: -0.4260,                 loss: nan
agent1:                 episode reward: 0.4260,                 loss: 0.1606
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4910s / 730.3729 s
agent0:                 episode reward: 0.1796,                 loss: nan
agent1:                 episode reward: -0.1796,                 loss: 0.1607
Episode: 17971/30000 (59.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4808s / 730.8536 s
agent0:                 episode reward: 0.1375,                 loss: nan
agent1:                 episode reward: -0.1375,                 loss: 0.1632
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4557s / 731.3093 s
agent0:                 episode reward: -0.3221,                 loss: nan
agent1:                 episode reward: 0.3221,                 loss: 0.1608
Episode: 17991/30000 (59.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4423s / 731.7516 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.1616
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4376s / 732.1893 s
agent0:                 episode reward: -0.0215,                 loss: nan
agent1:                 episode reward: 0.0215,                 loss: 0.1607
Episode: 18011/30000 (60.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4387s / 732.6280 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.1579
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4439s / 733.0718 s
agent0:                 episode reward: -0.1280,                 loss: nan
agent1:                 episode reward: 0.1280,                 loss: 0.1615
Episode: 18031/30000 (60.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4670s / 733.5389 s
agent0:                 episode reward: -1.1102,                 loss: nan
agent1:                 episode reward: 1.1102,                 loss: 0.1604
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4512s / 733.9900 s
agent0:                 episode reward: -0.1791,                 loss: nan
agent1:                 episode reward: 0.1791,                 loss: 0.1634
Episode: 18051/30000 (60.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4502s / 734.4402 s
agent0:                 episode reward: -0.5062,                 loss: nan
agent1:                 episode reward: 0.5062,                 loss: 0.1592
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4484s / 734.8886 s
agent0:                 episode reward: -1.0418,                 loss: nan
agent1:                 episode reward: 1.0418,                 loss: 0.1628
Episode: 18071/30000 (60.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 735.3396 s
agent0:                 episode reward: -0.1815,                 loss: nan
agent1:                 episode reward: 0.1815,                 loss: 0.1624
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4523s / 735.7918 s
agent0:                 episode reward: -0.6924,                 loss: nan
agent1:                 episode reward: 0.6924,                 loss: 0.1637
Episode: 18091/30000 (60.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4635s / 736.2553 s
agent0:                 episode reward: 0.5085,                 loss: nan
agent1:                 episode reward: -0.5085,                 loss: 0.1603
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 736.7092 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.1616
Episode: 18111/30000 (60.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4566s / 737.1657 s
agent0:                 episode reward: -0.1478,                 loss: nan
agent1:                 episode reward: 0.1478,                 loss: 0.1638
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 737.6275 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.1627
Episode: 18131/30000 (60.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4472s / 738.0747 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: 0.1598
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4606s / 738.5353 s
agent0:                 episode reward: -0.2201,                 loss: nan
agent1:                 episode reward: 0.2201,                 loss: 0.1593
Episode: 18151/30000 (60.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4567s / 738.9920 s
agent0:                 episode reward: -0.4980,                 loss: nan
agent1:                 episode reward: 0.4980,                 loss: 0.1610
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 739.4676 s
agent0:                 episode reward: -0.2234,                 loss: nan
agent1:                 episode reward: 0.2234,                 loss: 0.1609
Episode: 18171/30000 (60.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4469s / 739.9145 s
agent0:                 episode reward: 0.3168,                 loss: nan
agent1:                 episode reward: -0.3168,                 loss: 0.1606
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4338s / 740.3484 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.1613
Episode: 18191/30000 (60.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 740.7832 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.1616
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4342s / 741.2174 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.1592
Episode: 18211/30000 (60.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 741.6530 s
agent0:                 episode reward: 0.2834,                 loss: nan
agent1:                 episode reward: -0.2834,                 loss: 0.1596
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4654s / 742.1184 s
agent0:                 episode reward: -0.3985,                 loss: nan
agent1:                 episode reward: 0.3985,                 loss: 0.1609
Episode: 18231/30000 (60.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4515s / 742.5700 s
agent0:                 episode reward: 0.3008,                 loss: nan
agent1:                 episode reward: -0.3008,                 loss: 0.1616
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4634s / 743.0334 s
agent0:                 episode reward: -0.2963,                 loss: nan
agent1:                 episode reward: 0.2963,                 loss: 0.1596
Episode: 18251/30000 (60.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4530s / 743.4864 s
agent0:                 episode reward: -0.1550,                 loss: nan
agent1:                 episode reward: 0.1550,                 loss: 0.1603
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4509s / 743.9373 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.1600
Episode: 18271/30000 (60.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4533s / 744.3906 s
agent0:                 episode reward: -0.1860,                 loss: nan
agent1:                 episode reward: 0.1860,                 loss: 0.1616
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4596s / 744.8501 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.1613
Episode: 18291/30000 (60.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4875s / 745.3377 s
agent0:                 episode reward: -0.3147,                 loss: nan
agent1:                 episode reward: 0.3147,                 loss: 0.1589
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4563s / 745.7940 s
agent0:                 episode reward: -0.8194,                 loss: nan
agent1:                 episode reward: 0.8194,                 loss: 0.1613
Episode: 18311/30000 (61.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4610s / 746.2550 s
agent0:                 episode reward: -0.3493,                 loss: nan
agent1:                 episode reward: 0.3493,                 loss: 0.1607
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 746.7140 s
agent0:                 episode reward: -0.5024,                 loss: nan
agent1:                 episode reward: 0.5024,                 loss: 0.1609
Episode: 18331/30000 (61.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4542s / 747.1683 s
agent0:                 episode reward: -0.3648,                 loss: nan
agent1:                 episode reward: 0.3648,                 loss: 0.1608
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4790s / 747.6473 s
agent0:                 episode reward: -0.0961,                 loss: nan
agent1:                 episode reward: 0.0961,                 loss: 0.1609
Episode: 18351/30000 (61.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4687s / 748.1159 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.1622
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4599s / 748.5758 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.1622
Episode: 18371/30000 (61.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4554s / 749.0312 s
agent0:                 episode reward: -1.0963,                 loss: nan
agent1:                 episode reward: 1.0963,                 loss: 0.1622
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4561s / 749.4873 s
agent0:                 episode reward: -0.1814,                 loss: nan
agent1:                 episode reward: 0.1814,                 loss: 0.1612
Episode: 18391/30000 (61.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4659s / 749.9532 s
agent0:                 episode reward: -0.8064,                 loss: nan
agent1:                 episode reward: 0.8064,                 loss: 0.1613
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4515s / 750.4047 s
agent0:                 episode reward: -0.4894,                 loss: nan
agent1:                 episode reward: 0.4894,                 loss: 0.1578
Episode: 18411/30000 (61.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4441s / 750.8489 s
agent0:                 episode reward: -0.1676,                 loss: nan
agent1:                 episode reward: 0.1676,                 loss: 0.1620
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4704s / 751.3193 s
agent0:                 episode reward: -0.3196,                 loss: nan
agent1:                 episode reward: 0.3196,                 loss: 0.1602
Episode: 18431/30000 (61.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4442s / 751.7634 s
agent0:                 episode reward: 0.1495,                 loss: nan
agent1:                 episode reward: -0.1495,                 loss: 0.1626
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 752.1952 s
agent0:                 episode reward: -1.0848,                 loss: nan
agent1:                 episode reward: 1.0848,                 loss: 0.1575
Episode: 18451/30000 (61.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4323s / 752.6275 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.1610
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4321s / 753.0596 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.1611
Episode: 18471/30000 (61.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 753.4897 s
agent0:                 episode reward: -0.6206,                 loss: nan
agent1:                 episode reward: 0.6206,                 loss: 0.1609
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 753.9172 s
agent0:                 episode reward: 0.1096,                 loss: nan
agent1:                 episode reward: -0.1096,                 loss: 0.1613
Episode: 18491/30000 (61.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4469s / 754.3641 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.1613
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4336s / 754.7976 s
agent0:                 episode reward: -0.7294,                 loss: nan
agent1:                 episode reward: 0.7294,                 loss: 0.1633
Episode: 18511/30000 (61.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4342s / 755.2318 s
agent0:                 episode reward: 0.1738,                 loss: nan
agent1:                 episode reward: -0.1738,                 loss: 0.1620
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4511s / 755.6830 s
agent0:                 episode reward: -0.2575,                 loss: nan
agent1:                 episode reward: 0.2575,                 loss: 0.1615
Episode: 18531/30000 (61.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4758s / 756.1587 s
agent0:                 episode reward: 0.0464,                 loss: nan
agent1:                 episode reward: -0.0464,                 loss: 0.1625
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4563s / 756.6150 s
agent0:                 episode reward: 0.0930,                 loss: nan
agent1:                 episode reward: -0.0930,                 loss: 0.1605
Episode: 18551/30000 (61.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4583s / 757.0733 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.1622
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4994s / 757.5727 s
agent0:                 episode reward: -0.4612,                 loss: nan
agent1:                 episode reward: 0.4612,                 loss: 0.1637
Episode: 18571/30000 (61.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4543s / 758.0269 s
agent0:                 episode reward: -0.5040,                 loss: nan
agent1:                 episode reward: 0.5040,                 loss: 0.1618
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4619s / 758.4888 s
agent0:                 episode reward: -0.6266,                 loss: nan
agent1:                 episode reward: 0.6266,                 loss: 0.1593
Episode: 18591/30000 (61.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4642s / 758.9530 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: 0.1623
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4554s / 759.4084 s
agent0:                 episode reward: -0.0394,                 loss: nan
agent1:                 episode reward: 0.0394,                 loss: 0.1615
Episode: 18611/30000 (62.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4596s / 759.8680 s
agent0:                 episode reward: -0.5428,                 loss: nan
agent1:                 episode reward: 0.5428,                 loss: 0.1625
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4643s / 760.3323 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.1598
Episode: 18631/30000 (62.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4690s / 760.8013 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.1622
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4495s / 761.2508 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.1614
Episode: 18651/30000 (62.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 761.6857 s
agent0:                 episode reward: -0.6188,                 loss: nan
agent1:                 episode reward: 0.6188,                 loss: 0.1625
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4329s / 762.1187 s
agent0:                 episode reward: -0.3282,                 loss: nan
agent1:                 episode reward: 0.3282,                 loss: 0.1622
Episode: 18671/30000 (62.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4521s / 762.5708 s
agent0:                 episode reward: -0.6786,                 loss: nan
agent1:                 episode reward: 0.6786,                 loss: 0.1614
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 763.0364 s
agent0:                 episode reward: -0.0538,                 loss: nan
agent1:                 episode reward: 0.0538,                 loss: 0.1623
Episode: 18691/30000 (62.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4899s / 763.5262 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.1630
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4781s / 764.0043 s
agent0:                 episode reward: -0.3128,                 loss: nan
agent1:                 episode reward: 0.3128,                 loss: 0.1607
Episode: 18711/30000 (62.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4904s / 764.4948 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1618
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4576s / 764.9523 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.1603
Episode: 18731/30000 (62.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 765.4142 s
agent0:                 episode reward: -0.4498,                 loss: nan
agent1:                 episode reward: 0.4498,                 loss: 0.1635
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4619s / 765.8761 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.1618
Episode: 18751/30000 (62.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4558s / 766.3319 s
agent0:                 episode reward: -0.4717,                 loss: nan
agent1:                 episode reward: 0.4717,                 loss: 0.1614
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4731s / 766.8050 s
agent0:                 episode reward: -0.7411,                 loss: nan
agent1:                 episode reward: 0.7411,                 loss: 0.1616
Episode: 18771/30000 (62.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 767.2481 s
agent0:                 episode reward: -1.0465,                 loss: nan
agent1:                 episode reward: 1.0465,                 loss: 0.1625
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4423s / 767.6904 s
agent0:                 episode reward: -0.3301,                 loss: nan
agent1:                 episode reward: 0.3301,                 loss: 0.1619
Episode: 18791/30000 (62.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 768.1324 s
agent0:                 episode reward: -0.2864,                 loss: nan
agent1:                 episode reward: 0.2864,                 loss: 0.1637
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4450s / 768.5774 s
agent0:                 episode reward: -0.6224,                 loss: nan
agent1:                 episode reward: 0.6224,                 loss: 0.1617
Episode: 18811/30000 (62.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4471s / 769.0245 s
agent0:                 episode reward: -0.4986,                 loss: nan
agent1:                 episode reward: 0.4986,                 loss: 0.1604
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4540s / 769.4785 s
agent0:                 episode reward: -0.7398,                 loss: nan
agent1:                 episode reward: 0.7398,                 loss: 0.1607
Episode: 18831/30000 (62.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4515s / 769.9300 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.1622
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4382s / 770.3683 s
agent0:                 episode reward: 0.3321,                 loss: nan
agent1:                 episode reward: -0.3321,                 loss: 0.1623
Episode: 18851/30000 (62.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4345s / 770.8027 s
agent0:                 episode reward: -0.3951,                 loss: nan
agent1:                 episode reward: 0.3951,                 loss: 0.1622
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4566s / 771.2593 s
agent0:                 episode reward: -0.9862,                 loss: nan
agent1:                 episode reward: 0.9862,                 loss: 0.1624
Episode: 18871/30000 (62.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4628s / 771.7221 s
agent0:                 episode reward: -0.3044,                 loss: nan
agent1:                 episode reward: 0.3044,                 loss: 0.1600
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4555s / 772.1776 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.1621
Episode: 18891/30000 (62.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 772.6660 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.1618
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4533s / 773.1193 s
agent0:                 episode reward: -0.2870,                 loss: nan
agent1:                 episode reward: 0.2870,                 loss: 0.1619
Episode: 18911/30000 (63.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 773.5798 s
agent0:                 episode reward: -0.2721,                 loss: nan
agent1:                 episode reward: 0.2721,                 loss: 0.1653
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4683s / 774.0481 s
agent0:                 episode reward: -0.3555,                 loss: nan
agent1:                 episode reward: 0.3555,                 loss: 0.1649
Episode: 18931/30000 (63.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4632s / 774.5112 s
agent0:                 episode reward: -0.5808,                 loss: nan
agent1:                 episode reward: 0.5808,                 loss: 0.1627
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4665s / 774.9777 s
agent0:                 episode reward: -0.3600,                 loss: nan
agent1:                 episode reward: 0.3600,                 loss: 0.1643
Episode: 18951/30000 (63.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4513s / 775.4290 s
agent0:                 episode reward: -0.5145,                 loss: nan
agent1:                 episode reward: 0.5145,                 loss: 0.1645
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4736s / 775.9026 s
agent0:                 episode reward: -0.0945,                 loss: nan
agent1:                 episode reward: 0.0945,                 loss: 0.1665
Episode: 18971/30000 (63.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 776.3564 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1606
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4528s / 776.8093 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.1636
Episode: 18991/30000 (63.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4519s / 777.2611 s
agent0:                 episode reward: 0.0104,                 loss: nan
agent1:                 episode reward: -0.0104,                 loss: 0.1627
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4556s / 777.7168 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.1615
Episode: 19011/30000 (63.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 778.1729 s
agent0:                 episode reward: -0.3072,                 loss: nan
agent1:                 episode reward: 0.3072,                 loss: 0.1621
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4549s / 778.6278 s
agent0:                 episode reward: 0.2712,                 loss: nan
agent1:                 episode reward: -0.2712,                 loss: 0.1642
Episode: 19031/30000 (63.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4587s / 779.0865 s
agent0:                 episode reward: -0.4248,                 loss: nan
agent1:                 episode reward: 0.4248,                 loss: 0.1628
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 779.5403 s
agent0:                 episode reward: -0.7937,                 loss: nan
agent1:                 episode reward: 0.7937,                 loss: 0.1621
Episode: 19051/30000 (63.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4559s / 779.9961 s
agent0:                 episode reward: -0.4019,                 loss: nan
agent1:                 episode reward: 0.4019,                 loss: 0.1644
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4395s / 780.4357 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.1609
Episode: 19071/30000 (63.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 780.8832 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.1620
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4385s / 781.3217 s
agent0:                 episode reward: 0.4632,                 loss: nan
agent1:                 episode reward: -0.4632,                 loss: 0.1628
Episode: 19091/30000 (63.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4874s / 781.8091 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.1624
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4575s / 782.2666 s
agent0:                 episode reward: -0.6266,                 loss: nan
agent1:                 episode reward: 0.6266,                 loss: 0.1645
Episode: 19111/30000 (63.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4634s / 782.7300 s
agent0:                 episode reward: -0.9551,                 loss: nan
agent1:                 episode reward: 0.9551,                 loss: 0.1638
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4573s / 783.1873 s
agent0:                 episode reward: 0.0543,                 loss: nan
agent1:                 episode reward: -0.0543,                 loss: 0.1628
Episode: 19131/30000 (63.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4649s / 783.6522 s
agent0:                 episode reward: -0.8163,                 loss: nan
agent1:                 episode reward: 0.8163,                 loss: 0.1654
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 784.1109 s
agent0:                 episode reward: -0.9827,                 loss: nan
agent1:                 episode reward: 0.9827,                 loss: 0.1637
Episode: 19151/30000 (63.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4739s / 784.5848 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: 0.1651
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 785.0679 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.1602
Episode: 19171/30000 (63.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4492s / 785.5171 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.1624
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4535s / 785.9706 s
agent0:                 episode reward: -0.0478,                 loss: nan
agent1:                 episode reward: 0.0478,                 loss: 0.1605
Episode: 19191/30000 (63.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4768s / 786.4474 s
agent0:                 episode reward: 0.4058,                 loss: nan
agent1:                 episode reward: -0.4058,                 loss: 0.1629
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4737s / 786.9211 s
agent0:                 episode reward: -0.4181,                 loss: nan
agent1:                 episode reward: 0.4181,                 loss: 0.1612
Episode: 19211/30000 (64.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4674s / 787.3885 s
agent0:                 episode reward: -0.2993,                 loss: nan
agent1:                 episode reward: 0.2993,                 loss: 0.1624
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4842s / 787.8727 s
agent0:                 episode reward: -0.9902,                 loss: nan
agent1:                 episode reward: 0.9902,                 loss: 0.1625
Episode: 19231/30000 (64.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4571s / 788.3298 s
agent0:                 episode reward: 0.2959,                 loss: nan
agent1:                 episode reward: -0.2959,                 loss: 0.1625
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 788.7936 s
agent0:                 episode reward: -0.7449,                 loss: nan
agent1:                 episode reward: 0.7449,                 loss: 0.1615
Episode: 19251/30000 (64.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4794s / 789.2730 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: 0.1608
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4549s / 789.7279 s
agent0:                 episode reward: -0.4108,                 loss: nan
agent1:                 episode reward: 0.4108,                 loss: 0.1611
Episode: 19271/30000 (64.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4560s / 790.1839 s
agent0:                 episode reward: -0.3292,                 loss: nan
agent1:                 episode reward: 0.3292,                 loss: 0.1595
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4677s / 790.6516 s
agent0:                 episode reward: -0.2837,                 loss: nan
agent1:                 episode reward: 0.2837,                 loss: 0.1603
Episode: 19291/30000 (64.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4648s / 791.1164 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.1612
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4612s / 791.5777 s
agent0:                 episode reward: -0.4969,                 loss: nan
agent1:                 episode reward: 0.4969,                 loss: 0.1644
Episode: 19311/30000 (64.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 792.0253 s
agent0:                 episode reward: -0.2889,                 loss: nan
agent1:                 episode reward: 0.2889,                 loss: 0.1631
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4448s / 792.4701 s
agent0:                 episode reward: -0.6416,                 loss: nan
agent1:                 episode reward: 0.6416,                 loss: 0.1616
Episode: 19331/30000 (64.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4454s / 792.9154 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.1615
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4331s / 793.3485 s
agent0:                 episode reward: -0.3689,                 loss: nan
agent1:                 episode reward: 0.3689,                 loss: 0.1606
Episode: 19351/30000 (64.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4451s / 793.7936 s
agent0:                 episode reward: 0.2316,                 loss: nan
agent1:                 episode reward: -0.2316,                 loss: 0.1609
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 794.2388 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.1612
Episode: 19371/30000 (64.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4386s / 794.6774 s
agent0:                 episode reward: -0.3071,                 loss: nan
agent1:                 episode reward: 0.3071,                 loss: 0.1606
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 795.1167 s
agent0:                 episode reward: -0.8868,                 loss: nan
agent1:                 episode reward: 0.8868,                 loss: 0.1588
Episode: 19391/30000 (64.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 795.5603 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.1588
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4483s / 796.0086 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.1625
Episode: 19411/30000 (64.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4389s / 796.4475 s
agent0:                 episode reward: 0.0992,                 loss: nan
agent1:                 episode reward: -0.0992,                 loss: 0.1608
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4732s / 796.9207 s
agent0:                 episode reward: -0.2385,                 loss: nan
agent1:                 episode reward: 0.2385,                 loss: 0.1617
Episode: 19431/30000 (64.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4675s / 797.3882 s
agent0:                 episode reward: -0.9386,                 loss: nan
agent1:                 episode reward: 0.9386,                 loss: 0.1623
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4805s / 797.8687 s
agent0:                 episode reward: -0.5941,                 loss: nan
agent1:                 episode reward: 0.5941,                 loss: 0.1621
Episode: 19451/30000 (64.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4526s / 798.3212 s
agent0:                 episode reward: 0.1751,                 loss: nan
agent1:                 episode reward: -0.1751,                 loss: 0.1606
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4537s / 798.7749 s
agent0:                 episode reward: 0.0871,                 loss: nan
agent1:                 episode reward: -0.0871,                 loss: 0.1606
Episode: 19471/30000 (64.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4541s / 799.2290 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.1607
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4542s / 799.6832 s
agent0:                 episode reward: -0.1215,                 loss: nan
agent1:                 episode reward: 0.1215,                 loss: 0.1623
Episode: 19491/30000 (64.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 800.1622 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.1628
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4530s / 800.6153 s
agent0:                 episode reward: -0.8360,                 loss: nan
agent1:                 episode reward: 0.8360,                 loss: 0.1616
Episode: 19511/30000 (65.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 801.0748 s
agent0:                 episode reward: -0.7020,                 loss: nan
agent1:                 episode reward: 0.7020,                 loss: 0.1603
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4527s / 801.5275 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.1619
Episode: 19531/30000 (65.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4578s / 801.9852 s
agent0:                 episode reward: -0.2307,                 loss: nan
agent1:                 episode reward: 0.2307,                 loss: 0.1623
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4630s / 802.4482 s
agent0:                 episode reward: -0.0402,                 loss: nan
agent1:                 episode reward: 0.0402,                 loss: 0.1611
Episode: 19551/30000 (65.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4803s / 802.9286 s
agent0:                 episode reward: -0.9799,                 loss: nan
agent1:                 episode reward: 0.9799,                 loss: 0.1604
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4876s / 803.4161 s
agent0:                 episode reward: -0.2517,                 loss: nan
agent1:                 episode reward: 0.2517,                 loss: 0.1612
Episode: 19571/30000 (65.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4582s / 803.8743 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: 0.1624
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4569s / 804.3312 s
agent0:                 episode reward: -0.8883,                 loss: nan
agent1:                 episode reward: 0.8883,                 loss: 0.1590
Episode: 19591/30000 (65.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4570s / 804.7882 s
agent0:                 episode reward: 0.3525,                 loss: nan
agent1:                 episode reward: -0.3525,                 loss: 0.1608
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4594s / 805.2476 s
agent0:                 episode reward: -0.7970,                 loss: nan
agent1:                 episode reward: 0.7970,                 loss: 0.1603
Episode: 19611/30000 (65.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4543s / 805.7019 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1607
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4990s / 806.2009 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.1606
Episode: 19631/30000 (65.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4544s / 806.6553 s
agent0:                 episode reward: -0.3431,                 loss: nan
agent1:                 episode reward: 0.3431,                 loss: 0.1596
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4530s / 807.1084 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.1594
Episode: 19651/30000 (65.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4495s / 807.5579 s
agent0:                 episode reward: 0.0840,                 loss: nan
agent1:                 episode reward: -0.0840,                 loss: 0.1620
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 808.0117 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.1614
Episode: 19671/30000 (65.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4530s / 808.4646 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.1620
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4546s / 808.9193 s
agent0:                 episode reward: -0.1912,                 loss: nan
agent1:                 episode reward: 0.1912,                 loss: 0.1579
Episode: 19691/30000 (65.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4790s / 809.3983 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: 0.1625
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 809.8696 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.1616
Episode: 19711/30000 (65.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4748s / 810.3444 s
agent0:                 episode reward: -0.6590,                 loss: nan
agent1:                 episode reward: 0.6590,                 loss: 0.1597
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4981s / 810.8424 s
agent0:                 episode reward: -0.8322,                 loss: nan
agent1:                 episode reward: 0.8322,                 loss: 0.1578
Episode: 19731/30000 (65.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5095s / 811.3520 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.1599
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4651s / 811.8171 s
agent0:                 episode reward: 0.4388,                 loss: nan
agent1:                 episode reward: -0.4388,                 loss: 0.1601
Episode: 19751/30000 (65.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4808s / 812.2979 s
agent0:                 episode reward: -0.4413,                 loss: nan
agent1:                 episode reward: 0.4413,                 loss: 0.1625
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4561s / 812.7539 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.1621
Episode: 19771/30000 (65.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4616s / 813.2156 s
agent0:                 episode reward: -0.5306,                 loss: nan
agent1:                 episode reward: 0.5306,                 loss: 0.1616
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4613s / 813.6768 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1620
Episode: 19791/30000 (65.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5062s / 814.1831 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.1601
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5054s / 814.6884 s
agent0:                 episode reward: -0.3004,                 loss: nan
agent1:                 episode reward: 0.3004,                 loss: 0.1616
Episode: 19811/30000 (66.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4588s / 815.1472 s
agent0:                 episode reward: -0.6820,                 loss: nan
agent1:                 episode reward: 0.6820,                 loss: 0.1623
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4834s / 815.6306 s
agent0:                 episode reward: -0.3513,                 loss: nan
agent1:                 episode reward: 0.3513,                 loss: 0.1608
Episode: 19831/30000 (66.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4658s / 816.0964 s
agent0:                 episode reward: -0.0586,                 loss: nan
agent1:                 episode reward: 0.0586,                 loss: 0.1618
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4616s / 816.5580 s
agent0:                 episode reward: -0.1232,                 loss: nan
agent1:                 episode reward: 0.1232,                 loss: 0.1594
Episode: 19851/30000 (66.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 817.0240 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.1592
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4551s / 817.4791 s
agent0:                 episode reward: -0.0411,                 loss: nan
agent1:                 episode reward: 0.0411,                 loss: 0.1638
Episode: 19871/30000 (66.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5161s / 817.9952 s
agent0:                 episode reward: -0.4583,                 loss: nan
agent1:                 episode reward: 0.4583,                 loss: 0.1607
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 818.5736 s
agent0:                 episode reward: -0.0304,                 loss: nan
agent1:                 episode reward: 0.0304,                 loss: 0.1601
Episode: 19891/30000 (66.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5278s / 819.1014 s
agent0:                 episode reward: -0.2442,                 loss: nan
agent1:                 episode reward: 0.2442,                 loss: 0.1647
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4924s / 819.5937 s
agent0:                 episode reward: -0.4651,                 loss: nan
agent1:                 episode reward: 0.4651,                 loss: 0.1630
Episode: 19911/30000 (66.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 820.0694 s
agent0:                 episode reward: -0.4727,                 loss: nan
agent1:                 episode reward: 0.4727,                 loss: 0.1632
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4652s / 820.5345 s
agent0:                 episode reward: -0.4292,                 loss: nan
agent1:                 episode reward: 0.4292,                 loss: 0.1618
Episode: 19931/30000 (66.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4495s / 820.9840 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.1587
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4672s / 821.4513 s
agent0:                 episode reward: -0.5830,                 loss: nan
agent1:                 episode reward: 0.5830,                 loss: 0.1627
Episode: 19951/30000 (66.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 821.9226 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.1612
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4403s / 822.3629 s
agent0:                 episode reward: 0.1743,                 loss: nan
agent1:                 episode reward: -0.1743,                 loss: 0.1626
Episode: 19971/30000 (66.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4702s / 822.8330 s
agent0:                 episode reward: -0.4304,                 loss: nan
agent1:                 episode reward: 0.4304,                 loss: 0.1617
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5103s / 823.3434 s
agent0:                 episode reward: -0.0217,                 loss: nan
agent1:                 episode reward: 0.0217,                 loss: 0.1609
Episode: 19991/30000 (66.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4826s / 823.8260 s
agent0:                 episode reward: -0.6075,                 loss: nan
agent1:                 episode reward: 0.6075,                 loss: 0.1619
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 824.2850 s
agent0:                 episode reward: 0.1530,                 loss: nan
agent1:                 episode reward: -0.1530,                 loss: 0.1613
Episode: 20011/30000 (66.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 824.7512 s
agent0:                 episode reward: -0.4946,                 loss: nan
agent1:                 episode reward: 0.4946,                 loss: 0.1604
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4447s / 825.1959 s
agent0:                 episode reward: -0.3163,                 loss: nan
agent1:                 episode reward: 0.3163,                 loss: 0.1623
Episode: 20031/30000 (66.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4470s / 825.6429 s
agent0:                 episode reward: -0.4948,                 loss: nan
agent1:                 episode reward: 0.4948,                 loss: 0.1621
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4613s / 826.1042 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.1615
Episode: 20051/30000 (66.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4487s / 826.5529 s
agent0:                 episode reward: 0.1959,                 loss: nan
agent1:                 episode reward: -0.1959,                 loss: 0.1627
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4449s / 826.9978 s
agent0:                 episode reward: -1.0338,                 loss: nan
agent1:                 episode reward: 1.0338,                 loss: 0.1593
Episode: 20071/30000 (66.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 827.4639 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.1612
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4694s / 827.9332 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.1608
Episode: 20091/30000 (66.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4679s / 828.4011 s
agent0:                 episode reward: 0.2490,                 loss: nan
agent1:                 episode reward: -0.2490,                 loss: 0.1636
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4535s / 828.8547 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1600
Episode: 20111/30000 (67.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4626s / 829.3172 s
agent0:                 episode reward: -0.8213,                 loss: nan
agent1:                 episode reward: 0.8213,                 loss: 0.1608
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4606s / 829.7778 s
agent0:                 episode reward: -0.0500,                 loss: nan
agent1:                 episode reward: 0.0500,                 loss: 0.1644
Episode: 20131/30000 (67.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4608s / 830.2386 s
agent0:                 episode reward: -0.1097,                 loss: nan
agent1:                 episode reward: 0.1097,                 loss: 0.1612
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4680s / 830.7067 s
agent0:                 episode reward: -0.6332,                 loss: nan
agent1:                 episode reward: 0.6332,                 loss: 0.1633
Episode: 20151/30000 (67.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5005s / 831.2071 s
agent0:                 episode reward: 0.0484,                 loss: nan
agent1:                 episode reward: -0.0484,                 loss: 0.1610
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4779s / 831.6851 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.1598
Episode: 20171/30000 (67.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4698s / 832.1549 s
agent0:                 episode reward: -0.2755,                 loss: nan
agent1:                 episode reward: 0.2755,                 loss: 0.1581
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4693s / 832.6242 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.1613
Episode: 20191/30000 (67.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4685s / 833.0927 s
agent0:                 episode reward: -0.5292,                 loss: nan
agent1:                 episode reward: 0.5292,                 loss: 0.1637
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4854s / 833.5782 s
agent0:                 episode reward: -0.3790,                 loss: nan
agent1:                 episode reward: 0.3790,                 loss: 0.1616
Episode: 20211/30000 (67.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4646s / 834.0427 s
agent0:                 episode reward: -0.1215,                 loss: nan
agent1:                 episode reward: 0.1215,                 loss: 0.1636
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4706s / 834.5133 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1605
Episode: 20231/30000 (67.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4689s / 834.9822 s
agent0:                 episode reward: -0.5914,                 loss: nan
agent1:                 episode reward: 0.5914,                 loss: 0.1633
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4959s / 835.4781 s
agent0:                 episode reward: -0.0768,                 loss: nan
agent1:                 episode reward: 0.0768,                 loss: 0.1637
Episode: 20251/30000 (67.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4974s / 835.9755 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.1651
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5128s / 836.4883 s
agent0:                 episode reward: -0.9150,                 loss: nan
agent1:                 episode reward: 0.9150,                 loss: 0.1641
Episode: 20271/30000 (67.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4736s / 836.9619 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.1657
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4705s / 837.4324 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.1642
Episode: 20291/30000 (67.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4715s / 837.9039 s
agent0:                 episode reward: -0.0852,                 loss: nan
agent1:                 episode reward: 0.0852,                 loss: 0.1642
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4529s / 838.3568 s
agent0:                 episode reward: -0.0479,                 loss: nan
agent1:                 episode reward: 0.0479,                 loss: 0.1632
Episode: 20311/30000 (67.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 838.8044 s
agent0:                 episode reward: -0.5213,                 loss: nan
agent1:                 episode reward: 0.5213,                 loss: 0.1657
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 839.2862 s
agent0:                 episode reward: -0.3650,                 loss: nan
agent1:                 episode reward: 0.3650,                 loss: 0.1638
Episode: 20331/30000 (67.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 839.7676 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.1634
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4668s / 840.2343 s
agent0:                 episode reward: 0.2251,                 loss: nan
agent1:                 episode reward: -0.2251,                 loss: 0.1652
Episode: 20351/30000 (67.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4760s / 840.7103 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.1664
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4745s / 841.1847 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.1614
Episode: 20371/30000 (67.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4690s / 841.6537 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.1616
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4794s / 842.1332 s
agent0:                 episode reward: -0.3289,                 loss: nan
agent1:                 episode reward: 0.3289,                 loss: 0.1632
Episode: 20391/30000 (67.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5019s / 842.6351 s
agent0:                 episode reward: -0.7617,                 loss: nan
agent1:                 episode reward: 0.7617,                 loss: 0.1649
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4757s / 843.1108 s
agent0:                 episode reward: -0.5235,                 loss: nan
agent1:                 episode reward: 0.5235,                 loss: 0.1655
Episode: 20411/30000 (68.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4753s / 843.5861 s
agent0:                 episode reward: -0.2671,                 loss: nan
agent1:                 episode reward: 0.2671,                 loss: 0.1649
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4731s / 844.0593 s
agent0:                 episode reward: -0.1663,                 loss: nan
agent1:                 episode reward: 0.1663,                 loss: 0.1654
Episode: 20431/30000 (68.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 844.5231 s
agent0:                 episode reward: -0.3170,                 loss: nan
agent1:                 episode reward: 0.3170,                 loss: 0.1634
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 844.9752 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1627
Episode: 20451/30000 (68.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 845.4314 s
agent0:                 episode reward: -0.1379,                 loss: nan
agent1:                 episode reward: 0.1379,                 loss: 0.1630
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4640s / 845.8954 s
agent0:                 episode reward: -0.5316,                 loss: nan
agent1:                 episode reward: 0.5316,                 loss: 0.1648
Episode: 20471/30000 (68.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4474s / 846.3429 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: 0.1641
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4447s / 846.7876 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.1631
Episode: 20491/30000 (68.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 847.2386 s
agent0:                 episode reward: -0.2459,                 loss: nan
agent1:                 episode reward: 0.2459,                 loss: 0.1642
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4725s / 847.7111 s
agent0:                 episode reward: -0.6979,                 loss: nan
agent1:                 episode reward: 0.6979,                 loss: 0.1636
Episode: 20511/30000 (68.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 848.1597 s
agent0:                 episode reward: -0.0953,                 loss: nan
agent1:                 episode reward: 0.0953,                 loss: 0.1652
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 848.6193 s
agent0:                 episode reward: -0.3011,                 loss: nan
agent1:                 episode reward: 0.3011,                 loss: 0.1619
Episode: 20531/30000 (68.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4516s / 849.0709 s
agent0:                 episode reward: -0.4746,                 loss: nan
agent1:                 episode reward: 0.4746,                 loss: 0.1648
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 849.5194 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.1651
Episode: 20551/30000 (68.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4474s / 849.9667 s
agent0:                 episode reward: -0.8232,                 loss: nan
agent1:                 episode reward: 0.8232,                 loss: 0.1619
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 850.4152 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.1616
Episode: 20571/30000 (68.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4480s / 850.8632 s
agent0:                 episode reward: -0.8576,                 loss: nan
agent1:                 episode reward: 0.8576,                 loss: 0.1570
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4532s / 851.3165 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.1621
Episode: 20591/30000 (68.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5065s / 851.8230 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1589
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4741s / 852.2971 s
agent0:                 episode reward: -0.2792,                 loss: nan
agent1:                 episode reward: 0.2792,                 loss: 0.1625
Episode: 20611/30000 (68.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 852.7749 s
agent0:                 episode reward: -0.0501,                 loss: nan
agent1:                 episode reward: 0.0501,                 loss: 0.1611
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4596s / 853.2345 s
agent0:                 episode reward: -0.0440,                 loss: nan
agent1:                 episode reward: 0.0440,                 loss: 0.1592
Episode: 20631/30000 (68.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4490s / 853.6835 s
agent0:                 episode reward: -0.7004,                 loss: nan
agent1:                 episode reward: 0.7004,                 loss: 0.1578
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4494s / 854.1328 s
agent0:                 episode reward: -0.2343,                 loss: nan
agent1:                 episode reward: 0.2343,                 loss: 0.1618
Episode: 20651/30000 (68.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 854.5759 s
agent0:                 episode reward: -0.1479,                 loss: nan
agent1:                 episode reward: 0.1479,                 loss: 0.1585
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4771s / 855.0531 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.1595
Episode: 20671/30000 (68.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4503s / 855.5033 s
agent0:                 episode reward: -0.8617,                 loss: nan
agent1:                 episode reward: 0.8617,                 loss: 0.1615
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4668s / 855.9702 s
agent0:                 episode reward: 0.2755,                 loss: nan
agent1:                 episode reward: -0.2755,                 loss: 0.1584
Episode: 20691/30000 (68.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4489s / 856.4190 s
agent0:                 episode reward: -0.1973,                 loss: nan
agent1:                 episode reward: 0.1973,                 loss: 0.1605
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4504s / 856.8695 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: 0.1611
Episode: 20711/30000 (69.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4503s / 857.3198 s
agent0:                 episode reward: -0.8420,                 loss: nan
agent1:                 episode reward: 0.8420,                 loss: 0.1594
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4608s / 857.7806 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.1576
Episode: 20731/30000 (69.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 858.2583 s
agent0:                 episode reward: -0.8418,                 loss: nan
agent1:                 episode reward: 0.8418,                 loss: 0.1611
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4637s / 858.7220 s
agent0:                 episode reward: -0.4120,                 loss: nan
agent1:                 episode reward: 0.4120,                 loss: 0.1590
Episode: 20751/30000 (69.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4647s / 859.1867 s
agent0:                 episode reward: -0.4792,                 loss: nan
agent1:                 episode reward: 0.4792,                 loss: 0.1604
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4690s / 859.6557 s
agent0:                 episode reward: -0.2147,                 loss: nan
agent1:                 episode reward: 0.2147,                 loss: 0.1604
Episode: 20771/30000 (69.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4593s / 860.1149 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.1595
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4816s / 860.5965 s
agent0:                 episode reward: 0.0071,                 loss: nan
agent1:                 episode reward: -0.0071,                 loss: 0.1580
Episode: 20791/30000 (69.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5255s / 861.1220 s
agent0:                 episode reward: -0.1376,                 loss: nan
agent1:                 episode reward: 0.1376,                 loss: 0.1625
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4674s / 861.5894 s
agent0:                 episode reward: -0.1668,                 loss: nan
agent1:                 episode reward: 0.1668,                 loss: 0.1607
Episode: 20811/30000 (69.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4662s / 862.0556 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: 0.1586
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4669s / 862.5225 s
agent0:                 episode reward: -0.4244,                 loss: nan
agent1:                 episode reward: 0.4244,                 loss: 0.1603
Episode: 20831/30000 (69.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4680s / 862.9906 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.1598
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4635s / 863.4541 s
agent0:                 episode reward: -0.2213,                 loss: nan
agent1:                 episode reward: 0.2213,                 loss: 0.1609
Episode: 20851/30000 (69.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5020s / 863.9561 s
agent0:                 episode reward: -0.2023,                 loss: nan
agent1:                 episode reward: 0.2023,                 loss: 0.1607
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 864.4459 s
agent0:                 episode reward: 0.2755,                 loss: nan
agent1:                 episode reward: -0.2755,                 loss: 0.1598
Episode: 20871/30000 (69.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4686s / 864.9144 s
agent0:                 episode reward: -0.1403,                 loss: nan
agent1:                 episode reward: 0.1403,                 loss: 0.1618
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4634s / 865.3778 s
agent0:                 episode reward: 0.0658,                 loss: nan
agent1:                 episode reward: -0.0658,                 loss: 0.1584
Episode: 20891/30000 (69.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4671s / 865.8449 s
agent0:                 episode reward: -0.2288,                 loss: nan
agent1:                 episode reward: 0.2288,                 loss: 0.1624
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 866.3053 s
agent0:                 episode reward: 0.2167,                 loss: nan
agent1:                 episode reward: -0.2167,                 loss: 0.1601
Episode: 20911/30000 (69.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4632s / 866.7685 s
agent0:                 episode reward: -0.6875,                 loss: nan
agent1:                 episode reward: 0.6875,                 loss: 0.1605
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4943s / 867.2628 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.1612
Episode: 20931/30000 (69.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4738s / 867.7366 s
agent0:                 episode reward: -0.2157,                 loss: nan
agent1:                 episode reward: 0.2157,                 loss: 0.1620
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4725s / 868.2091 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.1607
Episode: 20951/30000 (69.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4672s / 868.6764 s
agent0:                 episode reward: -0.3681,                 loss: nan
agent1:                 episode reward: 0.3681,                 loss: 0.1600
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4720s / 869.1484 s
agent0:                 episode reward: -0.2601,                 loss: nan
agent1:                 episode reward: 0.2601,                 loss: 0.1620
Episode: 20971/30000 (69.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 869.6123 s
agent0:                 episode reward: 0.0948,                 loss: nan
agent1:                 episode reward: -0.0948,                 loss: 0.1597
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4627s / 870.0749 s
agent0:                 episode reward: -0.2784,                 loss: nan
agent1:                 episode reward: 0.2784,                 loss: 0.1631
Episode: 20991/30000 (69.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4536s / 870.5285 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.1614
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4480s / 870.9766 s
agent0:                 episode reward: -0.2635,                 loss: nan
agent1:                 episode reward: 0.2635,                 loss: 0.1611
Episode: 21011/30000 (70.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4649s / 871.4415 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.1583
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4730s / 871.9145 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.1614
Episode: 21031/30000 (70.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4701s / 872.3846 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.1623
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4971s / 872.8818 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.1620
Episode: 21051/30000 (70.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5028s / 873.3845 s
agent0:                 episode reward: -0.1857,                 loss: nan
agent1:                 episode reward: 0.1857,                 loss: 0.1614
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4815s / 873.8660 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.1638
Episode: 21071/30000 (70.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4765s / 874.3425 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.1586
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4970s / 874.8395 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.1611
Episode: 21091/30000 (70.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4831s / 875.3227 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.1609
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4891s / 875.8117 s
agent0:                 episode reward: -0.5875,                 loss: nan
agent1:                 episode reward: 0.5875,                 loss: 0.1599
Episode: 21111/30000 (70.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4981s / 876.3098 s
agent0:                 episode reward: -0.5627,                 loss: nan
agent1:                 episode reward: 0.5627,                 loss: 0.1617
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 876.7910 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.1631
Episode: 21131/30000 (70.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 877.2724 s
agent0:                 episode reward: -0.3575,                 loss: nan
agent1:                 episode reward: 0.3575,                 loss: 0.1613
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4796s / 877.7520 s
agent0:                 episode reward: -0.4694,                 loss: nan
agent1:                 episode reward: 0.4694,                 loss: 0.1621
Episode: 21151/30000 (70.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 878.2297 s
agent0:                 episode reward: -0.1086,                 loss: nan
agent1:                 episode reward: 0.1086,                 loss: 0.1607
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4786s / 878.7084 s
agent0:                 episode reward: 0.5163,                 loss: nan
agent1:                 episode reward: -0.5163,                 loss: 0.1602
Episode: 21171/30000 (70.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4865s / 879.1949 s
agent0:                 episode reward: 0.0070,                 loss: nan
agent1:                 episode reward: -0.0070,                 loss: 0.1586
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6440s / 879.8389 s
agent0:                 episode reward: -0.4905,                 loss: nan
agent1:                 episode reward: 0.4905,                 loss: 0.1599
Episode: 21191/30000 (70.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 880.3166 s
agent0:                 episode reward: -1.0058,                 loss: nan
agent1:                 episode reward: 1.0058,                 loss: 0.1609
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4763s / 880.7929 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1617
Episode: 21211/30000 (70.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5026s / 881.2955 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.1620
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4660s / 881.7615 s
agent0:                 episode reward: 0.1646,                 loss: nan
agent1:                 episode reward: -0.1646,                 loss: 0.1607
Episode: 21231/30000 (70.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4792s / 882.2407 s
agent0:                 episode reward: -0.3973,                 loss: nan
agent1:                 episode reward: 0.3973,                 loss: 0.1613
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 882.7268 s
agent0:                 episode reward: -0.4695,                 loss: nan
agent1:                 episode reward: 0.4695,                 loss: 0.1590
Episode: 21251/30000 (70.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4783s / 883.2051 s
agent0:                 episode reward: 0.0274,                 loss: nan
agent1:                 episode reward: -0.0274,                 loss: 0.1616
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4728s / 883.6779 s
agent0:                 episode reward: 0.4151,                 loss: nan
agent1:                 episode reward: -0.4151,                 loss: 0.1623
Episode: 21271/30000 (70.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 884.1609 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.1604
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4784s / 884.6392 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: 0.1615
Episode: 21291/30000 (70.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4746s / 885.1138 s
agent0:                 episode reward: -0.0219,                 loss: nan
agent1:                 episode reward: 0.0219,                 loss: 0.1626
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5003s / 885.6142 s
agent0:                 episode reward: -0.5636,                 loss: nan
agent1:                 episode reward: 0.5636,                 loss: 0.1592
Episode: 21311/30000 (71.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4776s / 886.0917 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1606
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4526s / 886.5443 s
agent0:                 episode reward: 0.2970,                 loss: nan
agent1:                 episode reward: -0.2970,                 loss: 0.1614
Episode: 21331/30000 (71.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4527s / 886.9970 s
agent0:                 episode reward: -0.7148,                 loss: nan
agent1:                 episode reward: 0.7148,                 loss: 0.1637
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4557s / 887.4527 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.1616
Episode: 21351/30000 (71.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4621s / 887.9148 s
agent0:                 episode reward: -0.7934,                 loss: nan
agent1:                 episode reward: 0.7934,                 loss: 0.1619
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4715s / 888.3863 s
agent0:                 episode reward: -0.2856,                 loss: nan
agent1:                 episode reward: 0.2856,                 loss: 0.1594
Episode: 21371/30000 (71.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4698s / 888.8561 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.1609
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4798s / 889.3359 s
agent0:                 episode reward: 0.6695,                 loss: nan
agent1:                 episode reward: -0.6695,                 loss: 0.1602
Episode: 21391/30000 (71.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4576s / 889.7935 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.1610
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 890.2553 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.1611
Episode: 21411/30000 (71.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4750s / 890.7303 s
agent0:                 episode reward: -0.8111,                 loss: nan
agent1:                 episode reward: 0.8111,                 loss: 0.1618
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4714s / 891.2017 s
agent0:                 episode reward: -0.7615,                 loss: nan
agent1:                 episode reward: 0.7615,                 loss: 0.1613
Episode: 21431/30000 (71.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5112s / 891.7130 s
agent0:                 episode reward: 0.0461,                 loss: nan
agent1:                 episode reward: -0.0461,                 loss: 0.1589
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 892.1974 s
agent0:                 episode reward: -0.7888,                 loss: nan
agent1:                 episode reward: 0.7888,                 loss: 0.1617
Episode: 21451/30000 (71.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4727s / 892.6701 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.1613
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 893.1478 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.1596
Episode: 21471/30000 (71.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5161s / 893.6639 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.1611
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4751s / 894.1390 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.1597
Episode: 21491/30000 (71.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4925s / 894.6315 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.1610
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4845s / 895.1159 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.1601
Episode: 21511/30000 (71.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4698s / 895.5858 s
agent0:                 episode reward: -0.5758,                 loss: nan
agent1:                 episode reward: 0.5758,                 loss: 0.1603
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4730s / 896.0588 s
agent0:                 episode reward: 0.5654,                 loss: nan
agent1:                 episode reward: -0.5654,                 loss: 0.1612
Episode: 21531/30000 (71.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4777s / 896.5364 s
agent0:                 episode reward: -0.4221,                 loss: nan
agent1:                 episode reward: 0.4221,                 loss: 0.1628
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4732s / 897.0096 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: 0.1597
Episode: 21551/30000 (71.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4878s / 897.4974 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.1579
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4796s / 897.9769 s
agent0:                 episode reward: -0.3863,                 loss: nan
agent1:                 episode reward: 0.3863,                 loss: 0.1587
Episode: 21571/30000 (71.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4531s / 898.4301 s
agent0:                 episode reward: 0.0720,                 loss: nan
agent1:                 episode reward: -0.0720,                 loss: 0.1589
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 898.8822 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.1605
Episode: 21591/30000 (71.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 899.3419 s
agent0:                 episode reward: -1.2272,                 loss: nan
agent1:                 episode reward: 1.2272,                 loss: 0.1595
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4827s / 899.8246 s
agent0:                 episode reward: -0.7949,                 loss: nan
agent1:                 episode reward: 0.7949,                 loss: 0.1594
Episode: 21611/30000 (72.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4652s / 900.2898 s
agent0:                 episode reward: -0.6965,                 loss: nan
agent1:                 episode reward: 0.6965,                 loss: 0.1583
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5078s / 900.7976 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.1597
Episode: 21631/30000 (72.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4738s / 901.2714 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.1583
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4710s / 901.7424 s
agent0:                 episode reward: 0.0917,                 loss: nan
agent1:                 episode reward: -0.0917,                 loss: 0.1578
Episode: 21651/30000 (72.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4928s / 902.2353 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.1563
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4995s / 902.7348 s
agent0:                 episode reward: -0.3946,                 loss: nan
agent1:                 episode reward: 0.3946,                 loss: 0.1601
Episode: 21671/30000 (72.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4790s / 903.2137 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1585
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 903.6955 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.1589
Episode: 21691/30000 (72.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4904s / 904.1859 s
agent0:                 episode reward: 0.1145,                 loss: nan
agent1:                 episode reward: -0.1145,                 loss: 0.1583
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 904.6683 s
agent0:                 episode reward: 0.1784,                 loss: nan
agent1:                 episode reward: -0.1784,                 loss: 0.1612
Episode: 21711/30000 (72.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4769s / 905.1452 s
agent0:                 episode reward: 0.0910,                 loss: nan
agent1:                 episode reward: -0.0910,                 loss: 0.1576
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4744s / 905.6196 s
agent0:                 episode reward: 0.1382,                 loss: nan
agent1:                 episode reward: -0.1382,                 loss: 0.1581
Episode: 21731/30000 (72.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5051s / 906.1247 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.1589
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4806s / 906.6053 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.1591
Episode: 21751/30000 (72.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4796s / 907.0849 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.1563
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4649s / 907.5498 s
agent0:                 episode reward: -0.2498,                 loss: nan
agent1:                 episode reward: 0.2498,                 loss: 0.1604
Episode: 21771/30000 (72.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4651s / 908.0149 s
agent0:                 episode reward: -0.2381,                 loss: nan
agent1:                 episode reward: 0.2381,                 loss: 0.1589
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4583s / 908.4732 s
agent0:                 episode reward: -0.5814,                 loss: nan
agent1:                 episode reward: 0.5814,                 loss: 0.1578
Episode: 21791/30000 (72.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4682s / 908.9413 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1597
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4730s / 909.4144 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1602
Episode: 21811/30000 (72.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4835s / 909.8979 s
agent0:                 episode reward: -0.1728,                 loss: nan
agent1:                 episode reward: 0.1728,                 loss: 0.1574
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4792s / 910.3771 s
agent0:                 episode reward: -0.4264,                 loss: nan
agent1:                 episode reward: 0.4264,                 loss: 0.1612
Episode: 21831/30000 (72.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4839s / 910.8610 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.1590
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4785s / 911.3395 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1584
Episode: 21851/30000 (72.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4790s / 911.8185 s
agent0:                 episode reward: -0.5232,                 loss: nan
agent1:                 episode reward: 0.5232,                 loss: 0.1584
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4855s / 912.3040 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.1588
Episode: 21871/30000 (72.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4745s / 912.7785 s
agent0:                 episode reward: 0.3022,                 loss: nan
agent1:                 episode reward: -0.3022,                 loss: 0.1586
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4939s / 913.2724 s
agent0:                 episode reward: -1.2447,                 loss: nan
agent1:                 episode reward: 1.2447,                 loss: 0.1577
Episode: 21891/30000 (72.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4831s / 913.7555 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: 0.1631
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4955s / 914.2509 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.1613
Episode: 21911/30000 (73.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4616s / 914.7125 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.1626
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4587s / 915.1713 s
agent0:                 episode reward: -0.6713,                 loss: nan
agent1:                 episode reward: 0.6713,                 loss: 0.1653
Episode: 21931/30000 (73.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4579s / 915.6292 s
agent0:                 episode reward: -0.8113,                 loss: nan
agent1:                 episode reward: 0.8113,                 loss: 0.1605
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4916s / 916.1208 s
agent0:                 episode reward: -1.0982,                 loss: nan
agent1:                 episode reward: 1.0982,                 loss: 0.1602
Episode: 21951/30000 (73.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4624s / 916.5832 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: 0.1621
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4599s / 917.0432 s
agent0:                 episode reward: -0.8247,                 loss: nan
agent1:                 episode reward: 0.8247,                 loss: 0.1621
Episode: 21971/30000 (73.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 917.5028 s
agent0:                 episode reward: -0.5298,                 loss: nan
agent1:                 episode reward: 0.5298,                 loss: 0.1615
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4560s / 917.9588 s
agent0:                 episode reward: -0.1441,                 loss: nan
agent1:                 episode reward: 0.1441,                 loss: 0.1629
Episode: 21991/30000 (73.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4637s / 918.4226 s
agent0:                 episode reward: -0.2802,                 loss: nan
agent1:                 episode reward: 0.2802,                 loss: 0.1613
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 918.8816 s
agent0:                 episode reward: -0.8096,                 loss: nan
agent1:                 episode reward: 0.8096,                 loss: 0.1635
Episode: 22011/30000 (73.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4632s / 919.3448 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.1631
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 919.7970 s
agent0:                 episode reward: -0.1785,                 loss: nan
agent1:                 episode reward: 0.1785,                 loss: 0.1649
Episode: 22031/30000 (73.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4549s / 920.2519 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.1639
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4717s / 920.7236 s
agent0:                 episode reward: -0.7104,                 loss: nan
agent1:                 episode reward: 0.7104,                 loss: 0.1653
Episode: 22051/30000 (73.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4851s / 921.2087 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.1636
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4872s / 921.6960 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.1622
Episode: 22071/30000 (73.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4980s / 922.1940 s
agent0:                 episode reward: -0.1300,                 loss: nan
agent1:                 episode reward: 0.1300,                 loss: 0.1652
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5124s / 922.7064 s
agent0:                 episode reward: -0.2727,                 loss: nan
agent1:                 episode reward: 0.2727,                 loss: 0.1631
Episode: 22091/30000 (73.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 923.1879 s
agent0:                 episode reward: -0.8341,                 loss: nan
agent1:                 episode reward: 0.8341,                 loss: 0.1594
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4906s / 923.6785 s
agent0:                 episode reward: -0.6939,                 loss: nan
agent1:                 episode reward: 0.6939,                 loss: 0.1635
Episode: 22111/30000 (73.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 924.1698 s
agent0:                 episode reward: -0.8102,                 loss: nan
agent1:                 episode reward: 0.8102,                 loss: 0.1625
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5103s / 924.6801 s
agent0:                 episode reward: -0.0959,                 loss: nan
agent1:                 episode reward: 0.0959,                 loss: 0.1634
Episode: 22131/30000 (73.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 925.1785 s
agent0:                 episode reward: -0.5933,                 loss: nan
agent1:                 episode reward: 0.5933,                 loss: 0.1647
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4842s / 925.6627 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: 0.1619
Episode: 22151/30000 (73.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4841s / 926.1468 s
agent0:                 episode reward: -0.9542,                 loss: nan
agent1:                 episode reward: 0.9542,                 loss: 0.1619
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4789s / 926.6256 s
agent0:                 episode reward: -0.7336,                 loss: nan
agent1:                 episode reward: 0.7336,                 loss: 0.1634
Episode: 22171/30000 (73.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4773s / 927.1029 s
agent0:                 episode reward: -0.2652,                 loss: nan
agent1:                 episode reward: 0.2652,                 loss: 0.1607
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4789s / 927.5818 s
agent0:                 episode reward: -1.0323,                 loss: nan
agent1:                 episode reward: 1.0323,                 loss: 0.1650
Episode: 22191/30000 (73.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4957s / 928.0776 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.1624
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4850s / 928.5626 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.1631
Episode: 22211/30000 (74.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4816s / 929.0442 s
agent0:                 episode reward: -0.9135,                 loss: nan
agent1:                 episode reward: 0.9135,                 loss: 0.1641
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4809s / 929.5251 s
agent0:                 episode reward: -0.3514,                 loss: nan
agent1:                 episode reward: 0.3514,                 loss: 0.1611
Episode: 22231/30000 (74.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4806s / 930.0057 s
agent0:                 episode reward: -0.4411,                 loss: nan
agent1:                 episode reward: 0.4411,                 loss: 0.1621
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4816s / 930.4873 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.1607
Episode: 22251/30000 (74.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5172s / 931.0045 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.1598
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4887s / 931.4932 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.1635
Episode: 22271/30000 (74.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4760s / 931.9692 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: 0.1606
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4820s / 932.4512 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.1601
Episode: 22291/30000 (74.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4688s / 932.9200 s
agent0:                 episode reward: -0.3489,                 loss: nan
agent1:                 episode reward: 0.3489,                 loss: 0.1615
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4703s / 933.3903 s
agent0:                 episode reward: -0.1343,                 loss: nan
agent1:                 episode reward: 0.1343,                 loss: 0.1603
Episode: 22311/30000 (74.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4772s / 933.8675 s
agent0:                 episode reward: -0.2361,                 loss: nan
agent1:                 episode reward: 0.2361,                 loss: 0.1625
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 934.3472 s
agent0:                 episode reward: 0.0369,                 loss: nan
agent1:                 episode reward: -0.0369,                 loss: 0.1641
Episode: 22331/30000 (74.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4709s / 934.8181 s
agent0:                 episode reward: -0.1117,                 loss: nan
agent1:                 episode reward: 0.1117,                 loss: 0.1601
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 935.2778 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.1605
Episode: 22351/30000 (74.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4611s / 935.7389 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.1619
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4587s / 936.1976 s
agent0:                 episode reward: -0.0828,                 loss: nan
agent1:                 episode reward: 0.0828,                 loss: 0.1597
Episode: 22371/30000 (74.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4592s / 936.6567 s
agent0:                 episode reward: -0.0063,                 loss: nan
agent1:                 episode reward: 0.0063,                 loss: 0.1608
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4847s / 937.1414 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.1645
Episode: 22391/30000 (74.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4593s / 937.6007 s
agent0:                 episode reward: -0.2294,                 loss: nan
agent1:                 episode reward: 0.2294,                 loss: 0.1614
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4581s / 938.0587 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: 0.1639
Episode: 22411/30000 (74.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4577s / 938.5165 s
agent0:                 episode reward: -0.4722,                 loss: nan
agent1:                 episode reward: 0.4722,                 loss: 0.1625
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4561s / 938.9726 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.1614
Episode: 22431/30000 (74.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4784s / 939.4510 s
agent0:                 episode reward: 0.2368,                 loss: nan
agent1:                 episode reward: -0.2368,                 loss: 0.1606
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4744s / 939.9254 s
agent0:                 episode reward: -0.0906,                 loss: nan
agent1:                 episode reward: 0.0906,                 loss: 0.1614
Episode: 22451/30000 (74.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4976s / 940.4230 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.1620
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4758s / 940.8988 s
agent0:                 episode reward: 0.0460,                 loss: nan
agent1:                 episode reward: -0.0460,                 loss: 0.1620
Episode: 22471/30000 (74.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4829s / 941.3817 s
agent0:                 episode reward: -0.8728,                 loss: nan
agent1:                 episode reward: 0.8728,                 loss: 0.1615
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 941.8612 s
agent0:                 episode reward: -0.7916,                 loss: nan
agent1:                 episode reward: 0.7916,                 loss: 0.1628
Episode: 22491/30000 (74.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4848s / 942.3460 s
agent0:                 episode reward: -0.1407,                 loss: nan
agent1:                 episode reward: 0.1407,                 loss: 0.1616
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4847s / 942.8307 s
agent0:                 episode reward: -0.9608,                 loss: nan
agent1:                 episode reward: 0.9608,                 loss: 0.1608
Episode: 22511/30000 (75.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5239s / 943.3546 s
agent0:                 episode reward: -0.0695,                 loss: nan
agent1:                 episode reward: 0.0695,                 loss: 0.1625
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4524s / 943.8070 s
agent0:                 episode reward: -1.0472,                 loss: nan
agent1:                 episode reward: 1.0472,                 loss: 0.1606
Episode: 22531/30000 (75.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4935s / 944.3005 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.1617
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 944.7817 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.1618
Episode: 22551/30000 (75.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4819s / 945.2636 s
agent0:                 episode reward: -0.7343,                 loss: nan
agent1:                 episode reward: 0.7343,                 loss: 0.1610
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4931s / 945.7566 s
agent0:                 episode reward: -0.2170,                 loss: nan
agent1:                 episode reward: 0.2170,                 loss: 0.1629
Episode: 22571/30000 (75.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5138s / 946.2704 s
agent0:                 episode reward: -0.6906,                 loss: nan
agent1:                 episode reward: 0.6906,                 loss: 0.1627
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4862s / 946.7566 s
agent0:                 episode reward: -0.4764,                 loss: nan
agent1:                 episode reward: 0.4764,                 loss: 0.1618
Episode: 22591/30000 (75.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 947.2380 s
agent0:                 episode reward: -0.9508,                 loss: nan
agent1:                 episode reward: 0.9508,                 loss: 0.1620
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5112s / 947.7492 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.1612
Episode: 22611/30000 (75.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4823s / 948.2315 s
agent0:                 episode reward: -0.1313,                 loss: nan
agent1:                 episode reward: 0.1313,                 loss: 0.1595
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4783s / 948.7098 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.1595
Episode: 22631/30000 (75.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 949.1983 s
agent0:                 episode reward: 0.0160,                 loss: nan
agent1:                 episode reward: -0.0160,                 loss: 0.1598
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4829s / 949.6812 s
agent0:                 episode reward: -0.2898,                 loss: nan
agent1:                 episode reward: 0.2898,                 loss: 0.1597
Episode: 22651/30000 (75.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4627s / 950.1439 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1621
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 950.6283 s
agent0:                 episode reward: -0.5602,                 loss: nan
agent1:                 episode reward: 0.5602,                 loss: 0.1616
Episode: 22671/30000 (75.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4857s / 951.1140 s
agent0:                 episode reward: -0.2309,                 loss: nan
agent1:                 episode reward: 0.2309,                 loss: 0.1607
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4877s / 951.6017 s
agent0:                 episode reward: -0.5085,                 loss: nan
agent1:                 episode reward: 0.5085,                 loss: 0.1634
Episode: 22691/30000 (75.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4879s / 952.0896 s
agent0:                 episode reward: -0.9983,                 loss: nan
agent1:                 episode reward: 0.9983,                 loss: 0.1606
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4993s / 952.5890 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.1603
Episode: 22711/30000 (75.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4904s / 953.0794 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.1614
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4781s / 953.5575 s
agent0:                 episode reward: -0.7407,                 loss: nan
agent1:                 episode reward: 0.7407,                 loss: 0.1598
Episode: 22731/30000 (75.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4596s / 954.0171 s
agent0:                 episode reward: -0.5786,                 loss: nan
agent1:                 episode reward: 0.5786,                 loss: 0.1621
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4612s / 954.4784 s
agent0:                 episode reward: -0.1959,                 loss: nan
agent1:                 episode reward: 0.1959,                 loss: 0.1603
Episode: 22751/30000 (75.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4612s / 954.9395 s
agent0:                 episode reward: -0.1578,                 loss: nan
agent1:                 episode reward: 0.1578,                 loss: 0.1616
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4976s / 955.4372 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1587
Episode: 22771/30000 (75.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4873s / 955.9245 s
agent0:                 episode reward: -0.3391,                 loss: nan
agent1:                 episode reward: 0.3391,                 loss: 0.1600
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5012s / 956.4257 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.1612
Episode: 22791/30000 (75.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4744s / 956.9001 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.1596
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4773s / 957.3774 s
agent0:                 episode reward: -0.5221,                 loss: nan
agent1:                 episode reward: 0.5221,                 loss: 0.1598
Episode: 22811/30000 (76.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4741s / 957.8516 s
agent0:                 episode reward: -0.3460,                 loss: nan
agent1:                 episode reward: 0.3460,                 loss: 0.1604
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4794s / 958.3310 s
agent0:                 episode reward: -0.2607,                 loss: nan
agent1:                 episode reward: 0.2607,                 loss: 0.1622
Episode: 22831/30000 (76.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4769s / 958.8079 s
agent0:                 episode reward: 0.0471,                 loss: nan
agent1:                 episode reward: -0.0471,                 loss: 0.1633
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 959.2683 s
agent0:                 episode reward: -0.8556,                 loss: nan
agent1:                 episode reward: 0.8556,                 loss: 0.1620
Episode: 22851/30000 (76.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4695s / 959.7378 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.1635
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4822s / 960.2201 s
agent0:                 episode reward: -0.0624,                 loss: nan
agent1:                 episode reward: 0.0624,                 loss: 0.1611
Episode: 22871/30000 (76.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4821s / 960.7021 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.1591
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4878s / 961.1899 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.1605
Episode: 22891/30000 (76.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5235s / 961.7135 s
agent0:                 episode reward: -0.0564,                 loss: nan
agent1:                 episode reward: 0.0564,                 loss: 0.1633
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4933s / 962.2067 s
agent0:                 episode reward: -0.4901,                 loss: nan
agent1:                 episode reward: 0.4901,                 loss: 0.1648
Episode: 22911/30000 (76.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4972s / 962.7039 s
agent0:                 episode reward: 0.2662,                 loss: nan
agent1:                 episode reward: -0.2662,                 loss: 0.1629
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4912s / 963.1951 s
agent0:                 episode reward: -0.1391,                 loss: nan
agent1:                 episode reward: 0.1391,                 loss: 0.1640
Episode: 22931/30000 (76.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4954s / 963.6906 s
agent0:                 episode reward: -0.4794,                 loss: nan
agent1:                 episode reward: 0.4794,                 loss: 0.1610
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5037s / 964.1942 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.1619
Episode: 22951/30000 (76.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5623s / 964.7566 s
agent0:                 episode reward: -0.9585,                 loss: nan
agent1:                 episode reward: 0.9585,                 loss: 0.1630
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4845s / 965.2411 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.1622
Episode: 22971/30000 (76.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4906s / 965.7317 s
agent0:                 episode reward: -0.2108,                 loss: nan
agent1:                 episode reward: 0.2108,                 loss: 0.1615
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4876s / 966.2192 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1639
Episode: 22991/30000 (76.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4860s / 966.7053 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.1612
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4837s / 967.1890 s
agent0:                 episode reward: -0.6091,                 loss: nan
agent1:                 episode reward: 0.6091,                 loss: 0.1620
Episode: 23011/30000 (76.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5000s / 967.6891 s
agent0:                 episode reward: 0.0046,                 loss: nan
agent1:                 episode reward: -0.0046,                 loss: 0.1601
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4936s / 968.1827 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.1598
Episode: 23031/30000 (76.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4945s / 968.6772 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: 0.1630
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4843s / 969.1614 s
agent0:                 episode reward: -0.4240,                 loss: nan
agent1:                 episode reward: 0.4240,                 loss: 0.1640
Episode: 23051/30000 (76.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4728s / 969.6342 s
agent0:                 episode reward: 0.0623,                 loss: nan
agent1:                 episode reward: -0.0623,                 loss: 0.1611
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4619s / 970.0961 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.1621
Episode: 23071/30000 (76.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 970.5617 s
agent0:                 episode reward: -0.0143,                 loss: nan
agent1:                 episode reward: 0.0143,                 loss: 0.1612
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4903s / 971.0519 s
agent0:                 episode reward: -0.7641,                 loss: nan
agent1:                 episode reward: 0.7641,                 loss: 0.1621
Episode: 23091/30000 (76.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4951s / 971.5470 s
agent0:                 episode reward: -0.1019,                 loss: nan
agent1:                 episode reward: 0.1019,                 loss: 0.1606
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5005s / 972.0475 s
agent0:                 episode reward: -0.5217,                 loss: nan
agent1:                 episode reward: 0.5217,                 loss: 0.1612
Episode: 23111/30000 (77.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5027s / 972.5502 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.1617
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5018s / 973.0520 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.1614
Episode: 23131/30000 (77.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4691s / 973.5211 s
agent0:                 episode reward: -0.3471,                 loss: nan
agent1:                 episode reward: 0.3471,                 loss: 0.1641
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4925s / 974.0136 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.1603
Episode: 23151/30000 (77.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4685s / 974.4820 s
agent0:                 episode reward: -0.5077,                 loss: nan
agent1:                 episode reward: 0.5077,                 loss: 0.1592
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4676s / 974.9497 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.1632
Episode: 23171/30000 (77.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4687s / 975.4184 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.1614
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4641s / 975.8825 s
agent0:                 episode reward: -1.0274,                 loss: nan
agent1:                 episode reward: 1.0274,                 loss: 0.1629
Episode: 23191/30000 (77.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4622s / 976.3447 s
agent0:                 episode reward: -0.8882,                 loss: nan
agent1:                 episode reward: 0.8882,                 loss: 0.1642
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4758s / 976.8205 s
agent0:                 episode reward: -0.8048,                 loss: nan
agent1:                 episode reward: 0.8048,                 loss: 0.1645
Episode: 23211/30000 (77.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4673s / 977.2878 s
agent0:                 episode reward: -0.1432,                 loss: nan
agent1:                 episode reward: 0.1432,                 loss: 0.1623
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 977.7473 s
agent0:                 episode reward: -0.3818,                 loss: nan
agent1:                 episode reward: 0.3818,                 loss: 0.1620
Episode: 23231/30000 (77.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4602s / 978.2075 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.1635
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4556s / 978.6631 s
agent0:                 episode reward: 0.2776,                 loss: nan
agent1:                 episode reward: -0.2776,                 loss: 0.1601
Episode: 23251/30000 (77.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4576s / 979.1207 s
agent0:                 episode reward: -0.3190,                 loss: nan
agent1:                 episode reward: 0.3190,                 loss: 0.1603
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4591s / 979.5797 s
agent0:                 episode reward: 0.1684,                 loss: nan
agent1:                 episode reward: -0.1684,                 loss: 0.1595
Episode: 23271/30000 (77.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 980.0627 s
agent0:                 episode reward: 0.0763,                 loss: nan
agent1:                 episode reward: -0.0763,                 loss: 0.1609
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4679s / 980.5307 s
agent0:                 episode reward: -0.2004,                 loss: nan
agent1:                 episode reward: 0.2004,                 loss: 0.1614
Episode: 23291/30000 (77.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4604s / 980.9910 s
agent0:                 episode reward: 0.0573,                 loss: nan
agent1:                 episode reward: -0.0573,                 loss: 0.1644
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 981.5001 s
agent0:                 episode reward: 0.0798,                 loss: nan
agent1:                 episode reward: -0.0798,                 loss: 0.1620
Episode: 23311/30000 (77.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4906s / 981.9907 s
agent0:                 episode reward: -0.7007,                 loss: nan
agent1:                 episode reward: 0.7007,                 loss: 0.1595
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4943s / 982.4850 s
agent0:                 episode reward: -0.4693,                 loss: nan
agent1:                 episode reward: 0.4693,                 loss: 0.1602
Episode: 23331/30000 (77.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4989s / 982.9839 s
agent0:                 episode reward: -0.8301,                 loss: nan
agent1:                 episode reward: 0.8301,                 loss: 0.1621
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 983.4823 s
agent0:                 episode reward: -0.5308,                 loss: nan
agent1:                 episode reward: 0.5308,                 loss: 0.1601
Episode: 23351/30000 (77.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 983.9707 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.1598
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 984.4620 s
agent0:                 episode reward: -0.9120,                 loss: nan
agent1:                 episode reward: 0.9120,                 loss: 0.1628
Episode: 23371/30000 (77.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4889s / 984.9509 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1617
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4856s / 985.4365 s
agent0:                 episode reward: -0.4823,                 loss: nan
agent1:                 episode reward: 0.4823,                 loss: 0.1621
Episode: 23391/30000 (77.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4967s / 985.9331 s
agent0:                 episode reward: 0.1290,                 loss: nan
agent1:                 episode reward: -0.1290,                 loss: 0.1584
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 986.4342 s
agent0:                 episode reward: -0.3392,                 loss: nan
agent1:                 episode reward: 0.3392,                 loss: 0.1599
Episode: 23411/30000 (78.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4910s / 986.9252 s
agent0:                 episode reward: -0.2719,                 loss: nan
agent1:                 episode reward: 0.2719,                 loss: 0.1619
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4876s / 987.4128 s
agent0:                 episode reward: -0.3162,                 loss: nan
agent1:                 episode reward: 0.3162,                 loss: 0.1628
Episode: 23431/30000 (78.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 987.8990 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.1627
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4853s / 988.3843 s
agent0:                 episode reward: -0.0432,                 loss: nan
agent1:                 episode reward: 0.0432,                 loss: 0.1621
Episode: 23451/30000 (78.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4871s / 988.8714 s
agent0:                 episode reward: -0.7755,                 loss: nan
agent1:                 episode reward: 0.7755,                 loss: 0.1609
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5391s / 989.4105 s
agent0:                 episode reward: -0.7469,                 loss: nan
agent1:                 episode reward: 0.7469,                 loss: 0.1628
Episode: 23471/30000 (78.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5012s / 989.9117 s
agent0:                 episode reward: -0.8070,                 loss: nan
agent1:                 episode reward: 0.8070,                 loss: 0.1592
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4924s / 990.4041 s
agent0:                 episode reward: -0.6920,                 loss: nan
agent1:                 episode reward: 0.6920,                 loss: 0.1600
Episode: 23491/30000 (78.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4892s / 990.8932 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1620
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 991.3831 s
agent0:                 episode reward: -0.0609,                 loss: nan
agent1:                 episode reward: 0.0609,                 loss: 0.1588
Episode: 23511/30000 (78.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4811s / 991.8642 s
agent0:                 episode reward: -0.2139,                 loss: nan
agent1:                 episode reward: 0.2139,                 loss: 0.1601
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5151s / 992.3793 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.1614
Episode: 23531/30000 (78.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4649s / 992.8442 s
agent0:                 episode reward: -0.3052,                 loss: nan
agent1:                 episode reward: 0.3052,                 loss: 0.1610
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4676s / 993.3118 s
agent0:                 episode reward: -0.1302,                 loss: nan
agent1:                 episode reward: 0.1302,                 loss: 0.1620
Episode: 23551/30000 (78.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4687s / 993.7805 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.1623
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4621s / 994.2426 s
agent0:                 episode reward: -0.4202,                 loss: nan
agent1:                 episode reward: 0.4202,                 loss: 0.1600
Episode: 23571/30000 (78.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 994.7087 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.1594
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4819s / 995.1906 s
agent0:                 episode reward: -0.2378,                 loss: nan
agent1:                 episode reward: 0.2378,                 loss: 0.1596
Episode: 23591/30000 (78.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4643s / 995.6549 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.1601
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4620s / 996.1169 s
agent0:                 episode reward: -0.4128,                 loss: nan
agent1:                 episode reward: 0.4128,                 loss: 0.1590
Episode: 23611/30000 (78.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4615s / 996.5784 s
agent0:                 episode reward: -0.1348,                 loss: nan
agent1:                 episode reward: 0.1348,                 loss: 0.1630
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4594s / 997.0378 s
agent0:                 episode reward: -0.8979,                 loss: nan
agent1:                 episode reward: 0.8979,                 loss: 0.1600
Episode: 23631/30000 (78.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4650s / 997.5028 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.1609
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4805s / 997.9833 s
agent0:                 episode reward: 0.3771,                 loss: nan
agent1:                 episode reward: -0.3771,                 loss: 0.1609
Episode: 23651/30000 (78.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 998.4747 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: 0.1581
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4834s / 998.9581 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1593
Episode: 23671/30000 (78.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 999.4378 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.1597
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4888s / 999.9266 s
agent0:                 episode reward: -0.0997,                 loss: nan
agent1:                 episode reward: 0.0997,                 loss: 0.1587
Episode: 23691/30000 (78.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4874s / 1000.4140 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.1586
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4951s / 1000.9091 s
agent0:                 episode reward: -0.0470,                 loss: nan
agent1:                 episode reward: 0.0470,                 loss: 0.1585
Episode: 23711/30000 (79.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5042s / 1001.4132 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: 0.1597
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4909s / 1001.9041 s
agent0:                 episode reward: 0.0283,                 loss: nan
agent1:                 episode reward: -0.0283,                 loss: 0.1592
Episode: 23731/30000 (79.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4857s / 1002.3898 s
agent0:                 episode reward: -0.7503,                 loss: nan
agent1:                 episode reward: 0.7503,                 loss: 0.1555
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4866s / 1002.8764 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.1603
Episode: 23751/30000 (79.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4599s / 1003.3364 s
agent0:                 episode reward: -0.8774,                 loss: nan
agent1:                 episode reward: 0.8774,                 loss: 0.1623
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4698s / 1003.8061 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.1621
Episode: 23771/30000 (79.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4833s / 1004.2894 s
agent0:                 episode reward: -0.2560,                 loss: nan
agent1:                 episode reward: 0.2560,                 loss: 0.1624
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4839s / 1004.7733 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.1600
Episode: 23791/30000 (79.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4811s / 1005.2544 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.1613
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 1005.7368 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.1612
Episode: 23811/30000 (79.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5107s / 1006.2476 s
agent0:                 episode reward: -0.1576,                 loss: nan
agent1:                 episode reward: 0.1576,                 loss: 0.1580
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4972s / 1006.7448 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1572
Episode: 23831/30000 (79.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4903s / 1007.2351 s
agent0:                 episode reward: -0.6280,                 loss: nan
agent1:                 episode reward: 0.6280,                 loss: 0.1577
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5093s / 1007.7444 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.1616
Episode: 23851/30000 (79.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4748s / 1008.2192 s
agent0:                 episode reward: -0.3899,                 loss: nan
agent1:                 episode reward: 0.3899,                 loss: 0.1591
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4662s / 1008.6854 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1611
Episode: 23871/30000 (79.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4672s / 1009.1526 s
agent0:                 episode reward: -0.8145,                 loss: nan
agent1:                 episode reward: 0.8145,                 loss: 0.1622
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4686s / 1009.6212 s
agent0:                 episode reward: 0.0574,                 loss: nan
agent1:                 episode reward: -0.0574,                 loss: 0.1598
Episode: 23891/30000 (79.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4671s / 1010.0883 s
agent0:                 episode reward: -0.7174,                 loss: nan
agent1:                 episode reward: 0.7174,                 loss: 0.1613
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4823s / 1010.5706 s
agent0:                 episode reward: -0.2053,                 loss: nan
agent1:                 episode reward: 0.2053,                 loss: 0.1594
Episode: 23911/30000 (79.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 1011.0551 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.1588
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4969s / 1011.5520 s
agent0:                 episode reward: -0.3843,                 loss: nan
agent1:                 episode reward: 0.3843,                 loss: 0.1590
Episode: 23931/30000 (79.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4877s / 1012.0397 s
agent0:                 episode reward: -0.0390,                 loss: nan
agent1:                 episode reward: 0.0390,                 loss: 0.1585
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4885s / 1012.5282 s
agent0:                 episode reward: -0.1031,                 loss: nan
agent1:                 episode reward: 0.1031,                 loss: 0.1588
Episode: 23951/30000 (79.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4856s / 1013.0139 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.1579
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5149s / 1013.5288 s
agent0:                 episode reward: -0.0653,                 loss: nan
agent1:                 episode reward: 0.0653,                 loss: 0.1599
Episode: 23971/30000 (79.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5151s / 1014.0439 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.1566
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5373s / 1014.5812 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.1597
Episode: 23991/30000 (79.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 1015.0909 s
agent0:                 episode reward: -0.4579,                 loss: nan
agent1:                 episode reward: 0.4579,                 loss: 0.1581
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 1015.5891 s
agent0:                 episode reward: -0.7430,                 loss: nan
agent1:                 episode reward: 0.7430,                 loss: 0.1597
Episode: 24011/30000 (80.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4917s / 1016.0808 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.1610
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5029s / 1016.5838 s
agent0:                 episode reward: -0.4761,                 loss: nan
agent1:                 episode reward: 0.4761,                 loss: 0.1572
Episode: 24031/30000 (80.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4998s / 1017.0835 s
agent0:                 episode reward: -0.4122,                 loss: nan
agent1:                 episode reward: 0.4122,                 loss: 0.1553
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 1017.5665 s
agent0:                 episode reward: -1.0415,                 loss: nan
agent1:                 episode reward: 1.0415,                 loss: 0.1596
Episode: 24051/30000 (80.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 1018.0456 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1600
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4854s / 1018.5310 s
agent0:                 episode reward: -0.4883,                 loss: nan
agent1:                 episode reward: 0.4883,                 loss: 0.1589
Episode: 24071/30000 (80.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 1019.0104 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.1593
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4821s / 1019.4925 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.1562
Episode: 24091/30000 (80.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5154s / 1020.0079 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.1596
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4601s / 1020.4680 s
agent0:                 episode reward: -0.3176,                 loss: nan
agent1:                 episode reward: 0.3176,                 loss: 0.1602
Episode: 24111/30000 (80.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4680s / 1020.9360 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.1592
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4659s / 1021.4019 s
agent0:                 episode reward: 0.3071,                 loss: nan
agent1:                 episode reward: -0.3071,                 loss: 0.1575
Episode: 24131/30000 (80.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4843s / 1021.8863 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.1588
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4908s / 1022.3770 s
agent0:                 episode reward: -0.3446,                 loss: nan
agent1:                 episode reward: 0.3446,                 loss: 0.1605
Episode: 24151/30000 (80.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5291s / 1022.9061 s
agent0:                 episode reward: -0.1109,                 loss: nan
agent1:                 episode reward: 0.1109,                 loss: 0.1592
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4917s / 1023.3978 s
agent0:                 episode reward: -0.3348,                 loss: nan
agent1:                 episode reward: 0.3348,                 loss: 0.1598
Episode: 24171/30000 (80.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4865s / 1023.8843 s
agent0:                 episode reward: -0.8093,                 loss: nan
agent1:                 episode reward: 0.8093,                 loss: 0.1615
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4918s / 1024.3761 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.1594
Episode: 24191/30000 (80.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 1024.8646 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.1589
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4870s / 1025.3516 s
agent0:                 episode reward: -0.4064,                 loss: nan
agent1:                 episode reward: 0.4064,                 loss: 0.1579
Episode: 24211/30000 (80.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5074s / 1025.8590 s
agent0:                 episode reward: 0.1665,                 loss: nan
agent1:                 episode reward: -0.1665,                 loss: 0.1621
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5032s / 1026.3621 s
agent0:                 episode reward: 0.1743,                 loss: nan
agent1:                 episode reward: -0.1743,                 loss: 0.1627
Episode: 24231/30000 (80.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 1026.8505 s
agent0:                 episode reward: 0.0638,                 loss: nan
agent1:                 episode reward: -0.0638,                 loss: 0.1626
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4911s / 1027.3415 s
agent0:                 episode reward: -0.1805,                 loss: nan
agent1:                 episode reward: 0.1805,                 loss: 0.1613
Episode: 24251/30000 (80.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4931s / 1027.8346 s
agent0:                 episode reward: -0.2514,                 loss: nan
agent1:                 episode reward: 0.2514,                 loss: 0.1620
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4940s / 1028.3287 s
agent0:                 episode reward: -0.3260,                 loss: nan
agent1:                 episode reward: 0.3260,                 loss: 0.1631
Episode: 24271/30000 (80.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4815s / 1028.8102 s
agent0:                 episode reward: -0.6028,                 loss: nan
agent1:                 episode reward: 0.6028,                 loss: 0.1606
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4657s / 1029.2759 s
agent0:                 episode reward: -0.9238,                 loss: nan
agent1:                 episode reward: 0.9238,                 loss: 0.1603
Episode: 24291/30000 (80.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4678s / 1029.7437 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.1612
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4684s / 1030.2121 s
agent0:                 episode reward: -0.9173,                 loss: nan
agent1:                 episode reward: 0.9173,                 loss: 0.1607
Episode: 24311/30000 (81.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4685s / 1030.6806 s
agent0:                 episode reward: -0.6088,                 loss: nan
agent1:                 episode reward: 0.6088,                 loss: 0.1611
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5035s / 1031.1841 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1637
Episode: 24331/30000 (81.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5145s / 1031.6986 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.1630
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4929s / 1032.1915 s
agent0:                 episode reward: -0.4205,                 loss: nan
agent1:                 episode reward: 0.4205,                 loss: 0.1621
Episode: 24351/30000 (81.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4650s / 1032.6565 s
agent0:                 episode reward: -1.2423,                 loss: nan
agent1:                 episode reward: 1.2423,                 loss: 0.1627
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4607s / 1033.1172 s
agent0:                 episode reward: -0.6380,                 loss: nan
agent1:                 episode reward: 0.6380,                 loss: 0.1622
Episode: 24371/30000 (81.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4672s / 1033.5844 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.1615
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4669s / 1034.0512 s
agent0:                 episode reward: -0.6177,                 loss: nan
agent1:                 episode reward: 0.6177,                 loss: 0.1602
Episode: 24391/30000 (81.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4877s / 1034.5389 s
agent0:                 episode reward: -0.7797,                 loss: nan
agent1:                 episode reward: 0.7797,                 loss: 0.1625
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4746s / 1035.0135 s
agent0:                 episode reward: -0.0568,                 loss: nan
agent1:                 episode reward: 0.0568,                 loss: 0.1620
Episode: 24411/30000 (81.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4671s / 1035.4806 s
agent0:                 episode reward: -0.4649,                 loss: nan
agent1:                 episode reward: 0.4649,                 loss: 0.1616
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4853s / 1035.9659 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.1596
Episode: 24431/30000 (81.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4810s / 1036.4469 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.1617
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 1036.9264 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.1627
Episode: 24451/30000 (81.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4745s / 1037.4009 s
agent0:                 episode reward: -0.1178,                 loss: nan
agent1:                 episode reward: 0.1178,                 loss: 0.1609
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5019s / 1037.9028 s
agent0:                 episode reward: -0.0242,                 loss: nan
agent1:                 episode reward: 0.0242,                 loss: 0.1611
Episode: 24471/30000 (81.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4721s / 1038.3748 s
agent0:                 episode reward: -0.2964,                 loss: nan
agent1:                 episode reward: 0.2964,                 loss: 0.1617
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4882s / 1038.8630 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.1616
Episode: 24491/30000 (81.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4959s / 1039.3589 s
agent0:                 episode reward: -0.4626,                 loss: nan
agent1:                 episode reward: 0.4626,                 loss: 0.1624
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5128s / 1039.8717 s
agent0:                 episode reward: 0.2236,                 loss: nan
agent1:                 episode reward: -0.2236,                 loss: 0.1623
Episode: 24511/30000 (81.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 1040.3840 s
agent0:                 episode reward: 0.1732,                 loss: nan
agent1:                 episode reward: -0.1732,                 loss: 0.1621
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5095s / 1040.8935 s
agent0:                 episode reward: -0.1070,                 loss: nan
agent1:                 episode reward: 0.1070,                 loss: 0.1607
Episode: 24531/30000 (81.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 1041.3981 s
agent0:                 episode reward: 0.0799,                 loss: nan
agent1:                 episode reward: -0.0799,                 loss: 0.1639
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5136s / 1041.9117 s
agent0:                 episode reward: 0.3140,                 loss: nan
agent1:                 episode reward: -0.3140,                 loss: 0.1631
Episode: 24551/30000 (81.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5141s / 1042.4258 s
agent0:                 episode reward: -0.4805,                 loss: nan
agent1:                 episode reward: 0.4805,                 loss: 0.1623
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4940s / 1042.9198 s
agent0:                 episode reward: -1.1834,                 loss: nan
agent1:                 episode reward: 1.1834,                 loss: 0.1605
Episode: 24571/30000 (81.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4888s / 1043.4086 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.1613
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 1043.9069 s
agent0:                 episode reward: -0.6655,                 loss: nan
agent1:                 episode reward: 0.6655,                 loss: 0.1605
Episode: 24591/30000 (81.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4965s / 1044.4035 s
agent0:                 episode reward: -0.7448,                 loss: nan
agent1:                 episode reward: 0.7448,                 loss: 0.1630
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4924s / 1044.8959 s
agent0:                 episode reward: -0.4325,                 loss: nan
agent1:                 episode reward: 0.4325,                 loss: 0.1608
Episode: 24611/30000 (82.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 1045.3857 s
agent0:                 episode reward: -0.4933,                 loss: nan
agent1:                 episode reward: 0.4933,                 loss: 0.1615
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4921s / 1045.8778 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: 0.1574
Episode: 24631/30000 (82.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4729s / 1046.3507 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.1600
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5016s / 1046.8523 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: 0.1595
Episode: 24651/30000 (82.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5061s / 1047.3584 s
agent0:                 episode reward: -0.4747,                 loss: nan
agent1:                 episode reward: 0.4747,                 loss: 0.1607
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5174s / 1047.8757 s
agent0:                 episode reward: -1.2214,                 loss: nan
agent1:                 episode reward: 1.2214,                 loss: 0.1622
Episode: 24671/30000 (82.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4974s / 1048.3732 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.1615
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4860s / 1048.8592 s
agent0:                 episode reward: -0.0686,                 loss: nan
agent1:                 episode reward: 0.0686,                 loss: 0.1609
Episode: 24691/30000 (82.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4875s / 1049.3467 s
agent0:                 episode reward: -0.6954,                 loss: nan
agent1:                 episode reward: 0.6954,                 loss: 0.1657
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5012s / 1049.8479 s
agent0:                 episode reward: -0.0172,                 loss: nan
agent1:                 episode reward: 0.0172,                 loss: 0.1620
Episode: 24711/30000 (82.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 1050.3634 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.1612
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4944s / 1050.8578 s
agent0:                 episode reward: -0.3242,                 loss: nan
agent1:                 episode reward: 0.3242,                 loss: 0.1608
Episode: 24731/30000 (82.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4847s / 1051.3425 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.1628
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5021s / 1051.8446 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1622
Episode: 24751/30000 (82.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4964s / 1052.3410 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.1606
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5005s / 1052.8415 s
agent0:                 episode reward: -0.2502,                 loss: nan
agent1:                 episode reward: 0.2502,                 loss: 0.1601
Episode: 24771/30000 (82.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5110s / 1053.3525 s
agent0:                 episode reward: -0.2887,                 loss: nan
agent1:                 episode reward: 0.2887,                 loss: 0.1635
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4978s / 1053.8503 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1615
Episode: 24791/30000 (82.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4883s / 1054.3386 s
agent0:                 episode reward: -0.4168,                 loss: nan
agent1:                 episode reward: 0.4168,                 loss: 0.1585
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5293s / 1054.8679 s
agent0:                 episode reward: -0.1769,                 loss: nan
agent1:                 episode reward: 0.1769,                 loss: 0.1615
Episode: 24811/30000 (82.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5414s / 1055.4093 s
agent0:                 episode reward: -0.4016,                 loss: nan
agent1:                 episode reward: 0.4016,                 loss: 0.1617
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5647s / 1055.9740 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.1593
Episode: 24831/30000 (82.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5535s / 1056.5275 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.1596
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5308s / 1057.0583 s
agent0:                 episode reward: -0.6153,                 loss: nan
agent1:                 episode reward: 0.6153,                 loss: 0.1614
Episode: 24851/30000 (82.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4926s / 1057.5508 s
agent0:                 episode reward: -0.2497,                 loss: nan
agent1:                 episode reward: 0.2497,                 loss: 0.1599
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5355s / 1058.0864 s
agent0:                 episode reward: -0.8899,                 loss: nan
agent1:                 episode reward: 0.8899,                 loss: 0.1603
Episode: 24871/30000 (82.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5043s / 1058.5907 s
agent0:                 episode reward: 0.2854,                 loss: nan
agent1:                 episode reward: -0.2854,                 loss: 0.1583
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5069s / 1059.0976 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.1611
Episode: 24891/30000 (82.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5056s / 1059.6031 s
agent0:                 episode reward: 0.0110,                 loss: nan
agent1:                 episode reward: -0.0110,                 loss: 0.1600
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5014s / 1060.1045 s
agent0:                 episode reward: -0.8828,                 loss: nan
agent1:                 episode reward: 0.8828,                 loss: 0.1611
Episode: 24911/30000 (83.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4787s / 1060.5832 s
agent0:                 episode reward: -0.4764,                 loss: nan
agent1:                 episode reward: 0.4764,                 loss: 0.1607
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4988s / 1061.0820 s
agent0:                 episode reward: -0.5207,                 loss: nan
agent1:                 episode reward: 0.5207,                 loss: 0.1619
Episode: 24931/30000 (83.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5368s / 1061.6188 s
agent0:                 episode reward: -0.2320,                 loss: nan
agent1:                 episode reward: 0.2320,                 loss: 0.1600
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5338s / 1062.1526 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.1597
Episode: 24951/30000 (83.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5323s / 1062.6849 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.1598
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4954s / 1063.1804 s
agent0:                 episode reward: -0.3070,                 loss: nan
agent1:                 episode reward: 0.3070,                 loss: 0.1603
Episode: 24971/30000 (83.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4932s / 1063.6736 s
agent0:                 episode reward: -0.2674,                 loss: nan
agent1:                 episode reward: 0.2674,                 loss: 0.1609
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4963s / 1064.1699 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.1596
Episode: 24991/30000 (83.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5248s / 1064.6947 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.1626
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4942s / 1065.1889 s
agent0:                 episode reward: -0.0646,                 loss: nan
agent1:                 episode reward: 0.0646,                 loss: 0.1627
Episode: 25011/30000 (83.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5222s / 1065.7111 s
agent0:                 episode reward: 0.2192,                 loss: nan
agent1:                 episode reward: -0.2192,                 loss: 0.1619
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 1066.2122 s
agent0:                 episode reward: 0.4926,                 loss: nan
agent1:                 episode reward: -0.4926,                 loss: 0.1627
Episode: 25031/30000 (83.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4908s / 1066.7030 s
agent0:                 episode reward: -0.8559,                 loss: nan
agent1:                 episode reward: 0.8559,                 loss: 0.1598
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4976s / 1067.2006 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: 0.1610
Episode: 25051/30000 (83.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5136s / 1067.7141 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1587
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4927s / 1068.2068 s
agent0:                 episode reward: -0.9842,                 loss: nan
agent1:                 episode reward: 0.9842,                 loss: 0.1628
Episode: 25071/30000 (83.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5237s / 1068.7305 s
agent0:                 episode reward: -0.2989,                 loss: nan
agent1:                 episode reward: 0.2989,                 loss: 0.1603
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4762s / 1069.2067 s
agent0:                 episode reward: 0.4537,                 loss: nan
agent1:                 episode reward: -0.4537,                 loss: 0.1617
Episode: 25091/30000 (83.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4807s / 1069.6874 s
agent0:                 episode reward: -0.5964,                 loss: nan
agent1:                 episode reward: 0.5964,                 loss: 0.1601
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5064s / 1070.1938 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.1623
Episode: 25111/30000 (83.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4873s / 1070.6811 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.1588
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4749s / 1071.1560 s
agent0:                 episode reward: -0.8951,                 loss: nan
agent1:                 episode reward: 0.8951,                 loss: 0.1619
Episode: 25131/30000 (83.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5370s / 1071.6931 s
agent0:                 episode reward: -0.4563,                 loss: nan
agent1:                 episode reward: 0.4563,                 loss: 0.1597
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5748s / 1072.2679 s
agent0:                 episode reward: -0.0797,                 loss: nan
agent1:                 episode reward: 0.0797,                 loss: 0.1593
Episode: 25151/30000 (83.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5197s / 1072.7876 s
agent0:                 episode reward: -0.5223,                 loss: nan
agent1:                 episode reward: 0.5223,                 loss: 0.1596
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5231s / 1073.3108 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.1618
Episode: 25171/30000 (83.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5216s / 1073.8323 s
agent0:                 episode reward: -0.2993,                 loss: nan
agent1:                 episode reward: 0.2993,                 loss: 0.1622
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5295s / 1074.3618 s
agent0:                 episode reward: -0.6274,                 loss: nan
agent1:                 episode reward: 0.6274,                 loss: 0.1600
Episode: 25191/30000 (83.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5068s / 1074.8686 s
agent0:                 episode reward: -0.0749,                 loss: nan
agent1:                 episode reward: 0.0749,                 loss: 0.1613
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4959s / 1075.3645 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.1614
Episode: 25211/30000 (84.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 1075.9615 s
agent0:                 episode reward: 0.4501,                 loss: nan
agent1:                 episode reward: -0.4501,                 loss: 0.1602
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5611s / 1076.5226 s
agent0:                 episode reward: -0.1017,                 loss: nan
agent1:                 episode reward: 0.1017,                 loss: 0.1633
Episode: 25231/30000 (84.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5239s / 1077.0465 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.1632
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5138s / 1077.5603 s
agent0:                 episode reward: -0.1263,                 loss: nan
agent1:                 episode reward: 0.1263,                 loss: 0.1642
Episode: 25251/30000 (84.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5132s / 1078.0735 s
agent0:                 episode reward: 0.1099,                 loss: nan
agent1:                 episode reward: -0.1099,                 loss: 0.1617
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4799s / 1078.5534 s
agent0:                 episode reward: -0.6198,                 loss: nan
agent1:                 episode reward: 0.6198,                 loss: 0.1644
Episode: 25271/30000 (84.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4774s / 1079.0308 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.1614
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4947s / 1079.5255 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.1606
Episode: 25291/30000 (84.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4810s / 1080.0064 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.1618
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4768s / 1080.4832 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.1635
Episode: 25311/30000 (84.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5325s / 1081.0157 s
agent0:                 episode reward: -0.9798,                 loss: nan
agent1:                 episode reward: 0.9798,                 loss: 0.1617
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5700s / 1081.5857 s
agent0:                 episode reward: -0.2634,                 loss: nan
agent1:                 episode reward: 0.2634,                 loss: 0.1631
Episode: 25331/30000 (84.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5196s / 1082.1053 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1625
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5008s / 1082.6061 s
agent0:                 episode reward: -0.5578,                 loss: nan
agent1:                 episode reward: 0.5578,                 loss: 0.1649
Episode: 25351/30000 (84.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 1083.1072 s
agent0:                 episode reward: -0.3819,                 loss: nan
agent1:                 episode reward: 0.3819,                 loss: 0.1631
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5188s / 1083.6260 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.1611
Episode: 25371/30000 (84.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5611s / 1084.1872 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.1632
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 1084.6758 s
agent0:                 episode reward: 0.1529,                 loss: nan
agent1:                 episode reward: -0.1529,                 loss: 0.1641
Episode: 25391/30000 (84.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5269s / 1085.2027 s
agent0:                 episode reward: 0.0454,                 loss: nan
agent1:                 episode reward: -0.0454,                 loss: 0.1599
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5254s / 1085.7281 s
agent0:                 episode reward: 0.1664,                 loss: nan
agent1:                 episode reward: -0.1664,                 loss: 0.1609
Episode: 25411/30000 (84.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5383s / 1086.2663 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.1639
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5603s / 1086.8266 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1623
Episode: 25431/30000 (84.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5434s / 1087.3700 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.1639
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5078s / 1087.8778 s
agent0:                 episode reward: -0.1807,                 loss: nan
agent1:                 episode reward: 0.1807,                 loss: 0.1613
Episode: 25451/30000 (84.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5247s / 1088.4025 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.1657
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5059s / 1088.9084 s
agent0:                 episode reward: -0.5190,                 loss: nan
agent1:                 episode reward: 0.5190,                 loss: 0.1635
Episode: 25471/30000 (84.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 1089.4131 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.1616
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5507s / 1089.9638 s
agent0:                 episode reward: -0.3800,                 loss: nan
agent1:                 episode reward: 0.3800,                 loss: 0.1642
Episode: 25491/30000 (84.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5322s / 1090.4960 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.1599
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 1091.0170 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.1613
Episode: 25511/30000 (85.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5087s / 1091.5257 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.1634
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 1092.0354 s
agent0:                 episode reward: 0.1429,                 loss: nan
agent1:                 episode reward: -0.1429,                 loss: 0.1611
Episode: 25531/30000 (85.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5101s / 1092.5455 s
agent0:                 episode reward: 0.0168,                 loss: nan
agent1:                 episode reward: -0.0168,                 loss: 0.1639
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5392s / 1093.0847 s
agent0:                 episode reward: -0.7311,                 loss: nan
agent1:                 episode reward: 0.7311,                 loss: 0.1606
Episode: 25551/30000 (85.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5138s / 1093.5985 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1605
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5115s / 1094.1100 s
agent0:                 episode reward: 0.0036,                 loss: nan
agent1:                 episode reward: -0.0036,                 loss: 0.1576
Episode: 25571/30000 (85.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4967s / 1094.6067 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.1613
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4850s / 1095.0917 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.1579
Episode: 25591/30000 (85.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4988s / 1095.5905 s
agent0:                 episode reward: -0.8319,                 loss: nan
agent1:                 episode reward: 0.8319,                 loss: 0.1576
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4986s / 1096.0891 s
agent0:                 episode reward: -0.7134,                 loss: nan
agent1:                 episode reward: 0.7134,                 loss: 0.1600
Episode: 25611/30000 (85.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4784s / 1096.5675 s
agent0:                 episode reward: -0.6075,                 loss: nan
agent1:                 episode reward: 0.6075,                 loss: 0.1583
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 1097.0573 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.1583
Episode: 25631/30000 (85.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 1097.5385 s
agent0:                 episode reward: -0.7291,                 loss: nan
agent1:                 episode reward: 0.7291,                 loss: 0.1612
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4975s / 1098.0360 s
agent0:                 episode reward: -0.3855,                 loss: nan
agent1:                 episode reward: 0.3855,                 loss: 0.1591
Episode: 25651/30000 (85.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4858s / 1098.5217 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.1584
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4839s / 1099.0056 s
agent0:                 episode reward: 0.0670,                 loss: nan
agent1:                 episode reward: -0.0670,                 loss: 0.1576
Episode: 25671/30000 (85.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4749s / 1099.4805 s
agent0:                 episode reward: -0.5448,                 loss: nan
agent1:                 episode reward: 0.5448,                 loss: 0.1609
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4723s / 1099.9528 s
agent0:                 episode reward: -0.5761,                 loss: nan
agent1:                 episode reward: 0.5761,                 loss: 0.1590
Episode: 25691/30000 (85.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4758s / 1100.4286 s
agent0:                 episode reward: -0.0419,                 loss: nan
agent1:                 episode reward: 0.0419,                 loss: 0.1604
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4851s / 1100.9137 s
agent0:                 episode reward: -0.0394,                 loss: nan
agent1:                 episode reward: 0.0394,                 loss: 0.1578
Episode: 25711/30000 (85.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4955s / 1101.4093 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.1577
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5217s / 1101.9309 s
agent0:                 episode reward: 0.0051,                 loss: nan
agent1:                 episode reward: -0.0051,                 loss: 0.1595
Episode: 25731/30000 (85.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4968s / 1102.4277 s
agent0:                 episode reward: -0.5447,                 loss: nan
agent1:                 episode reward: 0.5447,                 loss: 0.1581
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4947s / 1102.9225 s
agent0:                 episode reward: -0.3052,                 loss: nan
agent1:                 episode reward: 0.3052,                 loss: 0.1577
Episode: 25751/30000 (85.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 1103.4347 s
agent0:                 episode reward: -0.0608,                 loss: nan
agent1:                 episode reward: 0.0608,                 loss: 0.1579
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5180s / 1103.9527 s
agent0:                 episode reward: 0.2433,                 loss: nan
agent1:                 episode reward: -0.2433,                 loss: 0.1564
Episode: 25771/30000 (85.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5026s / 1104.4553 s
agent0:                 episode reward: -0.0342,                 loss: nan
agent1:                 episode reward: 0.0342,                 loss: 0.1565
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5254s / 1104.9807 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.1586
Episode: 25791/30000 (85.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5134s / 1105.4941 s
agent0:                 episode reward: 0.3591,                 loss: nan
agent1:                 episode reward: -0.3591,                 loss: 0.1605
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5075s / 1106.0016 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.1614
Episode: 25811/30000 (86.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5284s / 1106.5299 s
agent0:                 episode reward: 0.1136,                 loss: nan
agent1:                 episode reward: -0.1136,                 loss: 0.1579
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5024s / 1107.0324 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.1584
Episode: 25831/30000 (86.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4953s / 1107.5276 s
agent0:                 episode reward: 0.2217,                 loss: nan
agent1:                 episode reward: -0.2217,                 loss: 0.1592
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5228s / 1108.0504 s
agent0:                 episode reward: -0.6481,                 loss: nan
agent1:                 episode reward: 0.6481,                 loss: 0.1595
Episode: 25851/30000 (86.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5554s / 1108.6058 s
agent0:                 episode reward: -0.7740,                 loss: nan
agent1:                 episode reward: 0.7740,                 loss: 0.1602
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 1109.1149 s
agent0:                 episode reward: -0.4306,                 loss: nan
agent1:                 episode reward: 0.4306,                 loss: 0.1585
Episode: 25871/30000 (86.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5018s / 1109.6167 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.1621
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4930s / 1110.1097 s
agent0:                 episode reward: -0.8849,                 loss: nan
agent1:                 episode reward: 0.8849,                 loss: 0.1619
Episode: 25891/30000 (86.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4973s / 1110.6069 s
agent0:                 episode reward: -0.0338,                 loss: nan
agent1:                 episode reward: 0.0338,                 loss: 0.1604
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5003s / 1111.1073 s
agent0:                 episode reward: 0.0440,                 loss: nan
agent1:                 episode reward: -0.0440,                 loss: 0.1613
Episode: 25911/30000 (86.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4945s / 1111.6018 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.1608
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4968s / 1112.0986 s
agent0:                 episode reward: -0.6197,                 loss: nan
agent1:                 episode reward: 0.6197,                 loss: 0.1617
Episode: 25931/30000 (86.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4981s / 1112.5967 s
agent0:                 episode reward: -0.7141,                 loss: nan
agent1:                 episode reward: 0.7141,                 loss: 0.1613
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4993s / 1113.0960 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1635
Episode: 25951/30000 (86.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5471s / 1113.6431 s
agent0:                 episode reward: -1.1704,                 loss: nan
agent1:                 episode reward: 1.1704,                 loss: 0.1614
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 1114.1414 s
agent0:                 episode reward: -0.0873,                 loss: nan
agent1:                 episode reward: 0.0873,                 loss: 0.1610
Episode: 25971/30000 (86.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5321s / 1114.6735 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.1611
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4954s / 1115.1688 s
agent0:                 episode reward: 0.5919,                 loss: nan
agent1:                 episode reward: -0.5919,                 loss: 0.1613
Episode: 25991/30000 (86.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 1115.6671 s
agent0:                 episode reward: -0.4913,                 loss: nan
agent1:                 episode reward: 0.4913,                 loss: 0.1610
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5165s / 1116.1836 s
agent0:                 episode reward: -0.6671,                 loss: nan
agent1:                 episode reward: 0.6671,                 loss: 0.1621
Episode: 26011/30000 (86.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5284s / 1116.7121 s
agent0:                 episode reward: -0.7868,                 loss: nan
agent1:                 episode reward: 0.7868,                 loss: 0.1598
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4841s / 1117.1961 s
agent0:                 episode reward: -0.1400,                 loss: nan
agent1:                 episode reward: 0.1400,                 loss: 0.1603
Episode: 26031/30000 (86.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 1117.6778 s
agent0:                 episode reward: 0.3439,                 loss: nan
agent1:                 episode reward: -0.3439,                 loss: 0.1630
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4789s / 1118.1568 s
agent0:                 episode reward: -0.2818,                 loss: nan
agent1:                 episode reward: 0.2818,                 loss: 0.1611
Episode: 26051/30000 (86.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 1118.6392 s
agent0:                 episode reward: -0.1603,                 loss: nan
agent1:                 episode reward: 0.1603,                 loss: 0.1624
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 1119.1208 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.1606
Episode: 26071/30000 (86.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 1119.6023 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.1614
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 1120.0935 s
agent0:                 episode reward: 0.0882,                 loss: nan
agent1:                 episode reward: -0.0882,                 loss: 0.1623
Episode: 26091/30000 (86.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5188s / 1120.6124 s
agent0:                 episode reward: -0.8087,                 loss: nan
agent1:                 episode reward: 0.8087,                 loss: 0.1591
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5095s / 1121.1219 s
agent0:                 episode reward: -0.0046,                 loss: nan
agent1:                 episode reward: 0.0046,                 loss: 0.1624
Episode: 26111/30000 (87.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4992s / 1121.6210 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.1608
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5211s / 1122.1422 s
agent0:                 episode reward: 0.0407,                 loss: nan
agent1:                 episode reward: -0.0407,                 loss: 0.1601
Episode: 26131/30000 (87.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5149s / 1122.6570 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.1624
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5316s / 1123.1887 s
agent0:                 episode reward: -0.5955,                 loss: nan
agent1:                 episode reward: 0.5955,                 loss: 0.1616
Episode: 26151/30000 (87.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4961s / 1123.6848 s
agent0:                 episode reward: -0.4994,                 loss: nan
agent1:                 episode reward: 0.4994,                 loss: 0.1647
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4953s / 1124.1802 s
agent0:                 episode reward: 0.0567,                 loss: nan
agent1:                 episode reward: -0.0567,                 loss: 0.1603
Episode: 26171/30000 (87.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4920s / 1124.6722 s
agent0:                 episode reward: -0.3381,                 loss: nan
agent1:                 episode reward: 0.3381,                 loss: 0.1598
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5005s / 1125.1727 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.1618
Episode: 26191/30000 (87.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5110s / 1125.6837 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1624
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5026s / 1126.1863 s
agent0:                 episode reward: 0.1567,                 loss: nan
agent1:                 episode reward: -0.1567,                 loss: 0.1628
Episode: 26211/30000 (87.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4954s / 1126.6817 s
agent0:                 episode reward: -0.5713,                 loss: nan
agent1:                 episode reward: 0.5713,                 loss: 0.1610
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4944s / 1127.1760 s
agent0:                 episode reward: -0.0798,                 loss: nan
agent1:                 episode reward: 0.0798,                 loss: 0.1602
Episode: 26231/30000 (87.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4981s / 1127.6741 s
agent0:                 episode reward: -0.2783,                 loss: nan
agent1:                 episode reward: 0.2783,                 loss: 0.1614
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5027s / 1128.1769 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.1591
Episode: 26251/30000 (87.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5188s / 1128.6956 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.1623
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5107s / 1129.2063 s
agent0:                 episode reward: -0.4630,                 loss: nan
agent1:                 episode reward: 0.4630,                 loss: 0.1583
Episode: 26271/30000 (87.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4875s / 1129.6938 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.1589
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4966s / 1130.1903 s
agent0:                 episode reward: -0.3266,                 loss: nan
agent1:                 episode reward: 0.3266,                 loss: 0.1601
Episode: 26291/30000 (87.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5017s / 1130.6921 s
agent0:                 episode reward: -0.4205,                 loss: nan
agent1:                 episode reward: 0.4205,                 loss: 0.1617
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 1131.1932 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.1619
Episode: 26311/30000 (87.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5668s / 1131.7600 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.1588
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4999s / 1132.2599 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.1612
Episode: 26331/30000 (87.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5038s / 1132.7637 s
agent0:                 episode reward: -0.3530,                 loss: nan
agent1:                 episode reward: 0.3530,                 loss: 0.1591
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4995s / 1133.2632 s
agent0:                 episode reward: -0.1093,                 loss: nan
agent1:                 episode reward: 0.1093,                 loss: 0.1615
Episode: 26351/30000 (87.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4970s / 1133.7602 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.1637
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4963s / 1134.2565 s
agent0:                 episode reward: -0.8786,                 loss: nan
agent1:                 episode reward: 0.8786,                 loss: 0.1606
Episode: 26371/30000 (87.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5064s / 1134.7629 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1579
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5024s / 1135.2653 s
agent0:                 episode reward: -0.0579,                 loss: nan
agent1:                 episode reward: 0.0579,                 loss: 0.1611
Episode: 26391/30000 (87.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4963s / 1135.7617 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.1607
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5003s / 1136.2619 s
agent0:                 episode reward: -0.0676,                 loss: nan
agent1:                 episode reward: 0.0676,                 loss: 0.1601
Episode: 26411/30000 (88.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4993s / 1136.7613 s
agent0:                 episode reward: -0.6821,                 loss: nan
agent1:                 episode reward: 0.6821,                 loss: 0.1591
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4964s / 1137.2577 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.1598
Episode: 26431/30000 (88.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5041s / 1137.7617 s
agent0:                 episode reward: -0.0729,                 loss: nan
agent1:                 episode reward: 0.0729,                 loss: 0.1581
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5089s / 1138.2706 s
agent0:                 episode reward: 0.1397,                 loss: nan
agent1:                 episode reward: -0.1397,                 loss: 0.1610
Episode: 26451/30000 (88.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4946s / 1138.7652 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.1594
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4952s / 1139.2605 s
agent0:                 episode reward: -0.0187,                 loss: nan
agent1:                 episode reward: 0.0187,                 loss: 0.1616
Episode: 26471/30000 (88.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5126s / 1139.7730 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.1623
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5397s / 1140.3128 s
agent0:                 episode reward: -0.8999,                 loss: nan
agent1:                 episode reward: 0.8999,                 loss: 0.1603
Episode: 26491/30000 (88.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5498s / 1140.8626 s
agent0:                 episode reward: 0.3041,                 loss: nan
agent1:                 episode reward: -0.3041,                 loss: 0.1610
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4921s / 1141.3546 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.1591
Episode: 26511/30000 (88.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4907s / 1141.8453 s
agent0:                 episode reward: -0.3738,                 loss: nan
agent1:                 episode reward: 0.3738,                 loss: 0.1605
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4989s / 1142.3442 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.1597
Episode: 26531/30000 (88.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4779s / 1142.8222 s
agent0:                 episode reward: -0.3638,                 loss: nan
agent1:                 episode reward: 0.3638,                 loss: 0.1588
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5083s / 1143.3305 s
agent0:                 episode reward: -0.7098,                 loss: nan
agent1:                 episode reward: 0.7098,                 loss: 0.1590
Episode: 26551/30000 (88.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5020s / 1143.8325 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.1619
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5343s / 1144.3668 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.1630
Episode: 26571/30000 (88.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5112s / 1144.8779 s
agent0:                 episode reward: -0.7372,                 loss: nan
agent1:                 episode reward: 0.7372,                 loss: 0.1636
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5066s / 1145.3845 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.1617
Episode: 26591/30000 (88.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4948s / 1145.8793 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.1639
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4827s / 1146.3621 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: 0.1612
Episode: 26611/30000 (88.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4792s / 1146.8413 s
agent0:                 episode reward: -0.1793,                 loss: nan
agent1:                 episode reward: 0.1793,                 loss: 0.1631
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4966s / 1147.3379 s
agent0:                 episode reward: -0.4225,                 loss: nan
agent1:                 episode reward: 0.4225,                 loss: 0.1642
Episode: 26631/30000 (88.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4784s / 1147.8163 s
agent0:                 episode reward: -0.3336,                 loss: nan
agent1:                 episode reward: 0.3336,                 loss: 0.1648
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4970s / 1148.3133 s
agent0:                 episode reward: 0.0468,                 loss: nan
agent1:                 episode reward: -0.0468,                 loss: 0.1643
Episode: 26651/30000 (88.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4771s / 1148.7904 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.1624
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4821s / 1149.2725 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.1636
Episode: 26671/30000 (88.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 1149.7520 s
agent0:                 episode reward: 0.1143,                 loss: nan
agent1:                 episode reward: -0.1143,                 loss: 0.1652
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5071s / 1150.2591 s
agent0:                 episode reward: -0.7509,                 loss: nan
agent1:                 episode reward: 0.7509,                 loss: 0.1629
Episode: 26691/30000 (88.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5227s / 1150.7818 s
agent0:                 episode reward: -0.6192,                 loss: nan
agent1:                 episode reward: 0.6192,                 loss: 0.1622
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4993s / 1151.2811 s
agent0:                 episode reward: -0.3637,                 loss: nan
agent1:                 episode reward: 0.3637,                 loss: 0.1578
Episode: 26711/30000 (89.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5021s / 1151.7832 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.1610
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5031s / 1152.2864 s
agent0:                 episode reward: -0.7726,                 loss: nan
agent1:                 episode reward: 0.7726,                 loss: 0.1627
Episode: 26731/30000 (89.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5196s / 1152.8060 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.1653
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5135s / 1153.3195 s
agent0:                 episode reward: -0.3793,                 loss: nan
agent1:                 episode reward: 0.3793,                 loss: 0.1629
Episode: 26751/30000 (89.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5056s / 1153.8251 s
agent0:                 episode reward: -0.6989,                 loss: nan
agent1:                 episode reward: 0.6989,                 loss: 0.1635
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5044s / 1154.3295 s
agent0:                 episode reward: -0.3411,                 loss: nan
agent1:                 episode reward: 0.3411,                 loss: 0.1623
Episode: 26771/30000 (89.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4954s / 1154.8248 s
agent0:                 episode reward: -0.0938,                 loss: nan
agent1:                 episode reward: 0.0938,                 loss: 0.1615
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4843s / 1155.3091 s
agent0:                 episode reward: -0.1779,                 loss: nan
agent1:                 episode reward: 0.1779,                 loss: 0.1652
Episode: 26791/30000 (89.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4908s / 1155.7999 s
agent0:                 episode reward: -0.4831,                 loss: nan
agent1:                 episode reward: 0.4831,                 loss: 0.1607
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5215s / 1156.3214 s
agent0:                 episode reward: -0.6694,                 loss: nan
agent1:                 episode reward: 0.6694,                 loss: 0.1618
Episode: 26811/30000 (89.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5164s / 1156.8378 s
agent0:                 episode reward: -0.2655,                 loss: nan
agent1:                 episode reward: 0.2655,                 loss: 0.1627
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5168s / 1157.3546 s
agent0:                 episode reward: -0.0307,                 loss: nan
agent1:                 episode reward: 0.0307,                 loss: 0.1626
Episode: 26831/30000 (89.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5226s / 1157.8772 s
agent0:                 episode reward: -0.4439,                 loss: nan
agent1:                 episode reward: 0.4439,                 loss: 0.1656
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5179s / 1158.3951 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: 0.1604
Episode: 26851/30000 (89.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5305s / 1158.9256 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.1624
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5185s / 1159.4441 s
agent0:                 episode reward: -0.2490,                 loss: nan
agent1:                 episode reward: 0.2490,                 loss: 0.1626
Episode: 26871/30000 (89.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5093s / 1159.9534 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.1620
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5081s / 1160.4615 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.1610
Episode: 26891/30000 (89.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5029s / 1160.9644 s
agent0:                 episode reward: -0.1328,                 loss: nan
agent1:                 episode reward: 0.1328,                 loss: 0.1611
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5004s / 1161.4648 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.1634
Episode: 26911/30000 (89.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5368s / 1162.0016 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: 0.1592
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5289s / 1162.5305 s
agent0:                 episode reward: -0.4181,                 loss: nan
agent1:                 episode reward: 0.4181,                 loss: 0.1601
Episode: 26931/30000 (89.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5339s / 1163.0644 s
agent0:                 episode reward: -0.6006,                 loss: nan
agent1:                 episode reward: 0.6006,                 loss: 0.1603
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5187s / 1163.5831 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1614
Episode: 26951/30000 (89.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5212s / 1164.1043 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.1610
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5039s / 1164.6082 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.1604
Episode: 26971/30000 (89.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5372s / 1165.1454 s
agent0:                 episode reward: 0.0102,                 loss: nan
agent1:                 episode reward: -0.0102,                 loss: 0.1595
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5182s / 1165.6636 s
agent0:                 episode reward: -0.9147,                 loss: nan
agent1:                 episode reward: 0.9147,                 loss: 0.1627
Episode: 26991/30000 (89.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 1166.1740 s
agent0:                 episode reward: -0.0753,                 loss: nan
agent1:                 episode reward: 0.0753,                 loss: 0.1588
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 1166.6836 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.1612
Episode: 27011/30000 (90.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5200s / 1167.2036 s
agent0:                 episode reward: -0.4992,                 loss: nan
agent1:                 episode reward: 0.4992,                 loss: 0.1622
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5203s / 1167.7239 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.1623
Episode: 27031/30000 (90.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5164s / 1168.2403 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: 0.1614
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5176s / 1168.7579 s
agent0:                 episode reward: -0.3680,                 loss: nan
agent1:                 episode reward: 0.3680,                 loss: 0.1619
Episode: 27051/30000 (90.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5253s / 1169.2831 s
agent0:                 episode reward: -0.3305,                 loss: nan
agent1:                 episode reward: 0.3305,                 loss: 0.1607
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5285s / 1169.8116 s
agent0:                 episode reward: -0.3562,                 loss: nan
agent1:                 episode reward: 0.3562,                 loss: 0.1619
Episode: 27071/30000 (90.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5252s / 1170.3368 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1621
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5527s / 1170.8895 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: 0.1601
Episode: 27091/30000 (90.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5185s / 1171.4080 s
agent0:                 episode reward: -0.0496,                 loss: nan
agent1:                 episode reward: 0.0496,                 loss: 0.1637
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5002s / 1171.9082 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.1602
Episode: 27111/30000 (90.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4986s / 1172.4068 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1616
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 1172.9113 s
agent0:                 episode reward: -0.3685,                 loss: nan
agent1:                 episode reward: 0.3685,                 loss: 0.1611
Episode: 27131/30000 (90.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5177s / 1173.4290 s
agent0:                 episode reward: -0.4931,                 loss: nan
agent1:                 episode reward: 0.4931,                 loss: 0.1626
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 1173.9499 s
agent0:                 episode reward: -0.0207,                 loss: nan
agent1:                 episode reward: 0.0207,                 loss: 0.1642
Episode: 27151/30000 (90.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5242s / 1174.4742 s
agent0:                 episode reward: -0.1707,                 loss: nan
agent1:                 episode reward: 0.1707,                 loss: 0.1621
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5059s / 1174.9801 s
agent0:                 episode reward: -0.1566,                 loss: nan
agent1:                 episode reward: 0.1566,                 loss: 0.1648
Episode: 27171/30000 (90.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5099s / 1175.4900 s
agent0:                 episode reward: 0.2328,                 loss: nan
agent1:                 episode reward: -0.2328,                 loss: 0.1599
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5121s / 1176.0021 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.1620
Episode: 27191/30000 (90.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5157s / 1176.5178 s
agent0:                 episode reward: -0.2237,                 loss: nan
agent1:                 episode reward: 0.2237,                 loss: 0.1623
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5209s / 1177.0387 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.1630
Episode: 27211/30000 (90.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5028s / 1177.5415 s
agent0:                 episode reward: 0.0535,                 loss: nan
agent1:                 episode reward: -0.0535,                 loss: 0.1621
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 1178.0227 s
agent0:                 episode reward: -0.2750,                 loss: nan
agent1:                 episode reward: 0.2750,                 loss: 0.1616
Episode: 27231/30000 (90.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 1178.5051 s
agent0:                 episode reward: -0.4348,                 loss: nan
agent1:                 episode reward: 0.4348,                 loss: 0.1614
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5317s / 1179.0368 s
agent0:                 episode reward: -0.2601,                 loss: nan
agent1:                 episode reward: 0.2601,                 loss: 0.1607
Episode: 27251/30000 (90.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5347s / 1179.5715 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.1619
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5495s / 1180.1210 s
agent0:                 episode reward: -0.4879,                 loss: nan
agent1:                 episode reward: 0.4879,                 loss: 0.1607
Episode: 27271/30000 (90.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4932s / 1180.6143 s
agent0:                 episode reward: 0.0358,                 loss: nan
agent1:                 episode reward: -0.0358,                 loss: 0.1609
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5688s / 1181.1830 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.1605
Episode: 27291/30000 (90.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5632s / 1181.7463 s
agent0:                 episode reward: -0.7374,                 loss: nan
agent1:                 episode reward: 0.7374,                 loss: 0.1635
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5320s / 1182.2783 s
agent0:                 episode reward: -0.2215,                 loss: nan
agent1:                 episode reward: 0.2215,                 loss: 0.1626
Episode: 27311/30000 (91.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4977s / 1182.7760 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.1615
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5363s / 1183.3123 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.1620
Episode: 27331/30000 (91.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5064s / 1183.8187 s
agent0:                 episode reward: -0.5324,                 loss: nan
agent1:                 episode reward: 0.5324,                 loss: 0.1613
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5278s / 1184.3466 s
agent0:                 episode reward: -0.6620,                 loss: nan
agent1:                 episode reward: 0.6620,                 loss: 0.1619
Episode: 27351/30000 (91.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5241s / 1184.8707 s
agent0:                 episode reward: -0.1288,                 loss: nan
agent1:                 episode reward: 0.1288,                 loss: 0.1624
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5371s / 1185.4078 s
agent0:                 episode reward: -0.3007,                 loss: nan
agent1:                 episode reward: 0.3007,                 loss: 0.1610
Episode: 27371/30000 (91.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5296s / 1185.9374 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.1634
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5497s / 1186.4871 s
agent0:                 episode reward: -0.0418,                 loss: nan
agent1:                 episode reward: 0.0418,                 loss: 0.1613
Episode: 27391/30000 (91.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5021s / 1186.9892 s
agent0:                 episode reward: -0.9569,                 loss: nan
agent1:                 episode reward: 0.9569,                 loss: 0.1618
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4910s / 1187.4802 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.1629
Episode: 27411/30000 (91.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5241s / 1188.0043 s
agent0:                 episode reward: -1.0532,                 loss: nan
agent1:                 episode reward: 1.0532,                 loss: 0.1623
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4889s / 1188.4932 s
agent0:                 episode reward: -1.0199,                 loss: nan
agent1:                 episode reward: 1.0199,                 loss: 0.1617
Episode: 27431/30000 (91.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4911s / 1188.9844 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: 0.1619
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5147s / 1189.4990 s
agent0:                 episode reward: 0.2941,                 loss: nan
agent1:                 episode reward: -0.2941,                 loss: 0.1608
Episode: 27451/30000 (91.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5094s / 1190.0084 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1605
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4803s / 1190.4887 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.1644
Episode: 27471/30000 (91.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4847s / 1190.9733 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: 0.1622
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4816s / 1191.4550 s
agent0:                 episode reward: -0.6231,                 loss: nan
agent1:                 episode reward: 0.6231,                 loss: 0.1629
Episode: 27491/30000 (91.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4794s / 1191.9344 s
agent0:                 episode reward: -0.6746,                 loss: nan
agent1:                 episode reward: 0.6746,                 loss: 0.1634
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5096s / 1192.4440 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.1613
Episode: 27511/30000 (91.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4848s / 1192.9288 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.1628
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4787s / 1193.4076 s
agent0:                 episode reward: -0.2069,                 loss: nan
agent1:                 episode reward: 0.2069,                 loss: 0.1650
Episode: 27531/30000 (91.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 1193.8867 s
agent0:                 episode reward: -0.1673,                 loss: nan
agent1:                 episode reward: 0.1673,                 loss: 0.1622
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4793s / 1194.3660 s
agent0:                 episode reward: -0.0377,                 loss: nan
agent1:                 episode reward: 0.0377,                 loss: 0.1605
Episode: 27551/30000 (91.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4829s / 1194.8489 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.1615
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4948s / 1195.3437 s
agent0:                 episode reward: -0.3782,                 loss: nan
agent1:                 episode reward: 0.3782,                 loss: 0.1584
Episode: 27571/30000 (91.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5153s / 1195.8589 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: 0.1614
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5024s / 1196.3614 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: 0.1569
Episode: 27591/30000 (91.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5161s / 1196.8775 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.1595
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5124s / 1197.3899 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.1609
Episode: 27611/30000 (92.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5137s / 1197.9037 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1604
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5487s / 1198.4524 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.1580
Episode: 27631/30000 (92.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5190s / 1198.9713 s
agent0:                 episode reward: -0.7974,                 loss: nan
agent1:                 episode reward: 0.7974,                 loss: 0.1610
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5036s / 1199.4749 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.1594
Episode: 27651/30000 (92.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5127s / 1199.9876 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.1583
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 1200.4960 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.1585
Episode: 27671/30000 (92.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5191s / 1201.0151 s
agent0:                 episode reward: 0.4877,                 loss: nan
agent1:                 episode reward: -0.4877,                 loss: 0.1597
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5402s / 1201.5552 s
agent0:                 episode reward: -0.3182,                 loss: nan
agent1:                 episode reward: 0.3182,                 loss: 0.1601
Episode: 27691/30000 (92.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5195s / 1202.0747 s
agent0:                 episode reward: -0.7290,                 loss: nan
agent1:                 episode reward: 0.7290,                 loss: 0.1599
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5072s / 1202.5819 s
agent0:                 episode reward: -0.2788,                 loss: nan
agent1:                 episode reward: 0.2788,                 loss: 0.1604
Episode: 27711/30000 (92.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5191s / 1203.1010 s
agent0:                 episode reward: -0.1586,                 loss: nan
agent1:                 episode reward: 0.1586,                 loss: 0.1615
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5742s / 1203.6751 s
agent0:                 episode reward: -0.1610,                 loss: nan
agent1:                 episode reward: 0.1610,                 loss: 0.1592
Episode: 27731/30000 (92.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5286s / 1204.2037 s
agent0:                 episode reward: -0.6063,                 loss: nan
agent1:                 episode reward: 0.6063,                 loss: 0.1615
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5592s / 1204.7629 s
agent0:                 episode reward: -1.0248,                 loss: nan
agent1:                 episode reward: 1.0248,                 loss: 0.1600
Episode: 27751/30000 (92.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5284s / 1205.2913 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.1588
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5292s / 1205.8205 s
agent0:                 episode reward: -0.5334,                 loss: nan
agent1:                 episode reward: 0.5334,                 loss: 0.1607
Episode: 27771/30000 (92.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5255s / 1206.3460 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.1601
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 1206.9375 s
agent0:                 episode reward: -0.8442,                 loss: nan
agent1:                 episode reward: 0.8442,                 loss: 0.1588
Episode: 27791/30000 (92.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5589s / 1207.4964 s
agent0:                 episode reward: -0.1368,                 loss: nan
agent1:                 episode reward: 0.1368,                 loss: 0.1600
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 1208.0755 s
agent0:                 episode reward: -0.4727,                 loss: nan
agent1:                 episode reward: 0.4727,                 loss: 0.1609
Episode: 27811/30000 (92.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5485s / 1208.6240 s
agent0:                 episode reward: -0.2999,                 loss: nan
agent1:                 episode reward: 0.2999,                 loss: 0.1595
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5344s / 1209.1584 s
agent0:                 episode reward: -0.5962,                 loss: nan
agent1:                 episode reward: 0.5962,                 loss: 0.1585
Episode: 27831/30000 (92.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5281s / 1209.6864 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.1594
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5224s / 1210.2089 s
agent0:                 episode reward: -0.4673,                 loss: nan
agent1:                 episode reward: 0.4673,                 loss: 0.1594
Episode: 27851/30000 (92.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5408s / 1210.7496 s
agent0:                 episode reward: -0.4190,                 loss: nan
agent1:                 episode reward: 0.4190,                 loss: 0.1624
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5376s / 1211.2872 s
agent0:                 episode reward: -0.3647,                 loss: nan
agent1:                 episode reward: 0.3647,                 loss: 0.1605
Episode: 27871/30000 (92.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5369s / 1211.8241 s
agent0:                 episode reward: -0.1514,                 loss: nan
agent1:                 episode reward: 0.1514,                 loss: 0.1602
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5120s / 1212.3361 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.1574
Episode: 27891/30000 (92.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4904s / 1212.8265 s
agent0:                 episode reward: -0.4118,                 loss: nan
agent1:                 episode reward: 0.4118,                 loss: 0.1603
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4891s / 1213.3157 s
agent0:                 episode reward: -0.7639,                 loss: nan
agent1:                 episode reward: 0.7639,                 loss: 0.1620
Episode: 27911/30000 (93.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5019s / 1213.8176 s
agent0:                 episode reward: -0.2727,                 loss: nan
agent1:                 episode reward: 0.2727,                 loss: 0.1596
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5150s / 1214.3326 s
agent0:                 episode reward: -0.0813,                 loss: nan
agent1:                 episode reward: 0.0813,                 loss: 0.1616
Episode: 27931/30000 (93.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5313s / 1214.8638 s
agent0:                 episode reward: 0.0460,                 loss: nan
agent1:                 episode reward: -0.0460,                 loss: 0.1608
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 1215.3761 s
agent0:                 episode reward: -0.7638,                 loss: nan
agent1:                 episode reward: 0.7638,                 loss: 0.1640
Episode: 27951/30000 (93.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5140s / 1215.8901 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1629
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4986s / 1216.3888 s
agent0:                 episode reward: -0.2731,                 loss: nan
agent1:                 episode reward: 0.2731,                 loss: 0.1610
Episode: 27971/30000 (93.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5159s / 1216.9047 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.1593
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5086s / 1217.4132 s
agent0:                 episode reward: -0.6109,                 loss: nan
agent1:                 episode reward: 0.6109,                 loss: 0.1610
Episode: 27991/30000 (93.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5070s / 1217.9202 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1626
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5079s / 1218.4281 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.1612
Episode: 28011/30000 (93.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5170s / 1218.9451 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.1645
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5154s / 1219.4605 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.1621
Episode: 28031/30000 (93.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5498s / 1220.0104 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.1637
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5674s / 1220.5777 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: 0.1638
Episode: 28051/30000 (93.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 1221.1601 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.1621
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5458s / 1221.7059 s
agent0:                 episode reward: -0.1726,                 loss: nan
agent1:                 episode reward: 0.1726,                 loss: 0.1633
Episode: 28071/30000 (93.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5738s / 1222.2797 s
agent0:                 episode reward: -1.2336,                 loss: nan
agent1:                 episode reward: 1.2336,                 loss: 0.1627
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5552s / 1222.8349 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.1652
Episode: 28091/30000 (93.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 1223.4452 s
agent0:                 episode reward: 0.0825,                 loss: nan
agent1:                 episode reward: -0.0825,                 loss: 0.1619
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5383s / 1223.9836 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.1616
Episode: 28111/30000 (93.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5156s / 1224.4991 s
agent0:                 episode reward: -0.0657,                 loss: nan
agent1:                 episode reward: 0.0657,                 loss: 0.1632
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5291s / 1225.0283 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.1623
Episode: 28131/30000 (93.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5154s / 1225.5437 s
agent0:                 episode reward: -0.5296,                 loss: nan
agent1:                 episode reward: 0.5296,                 loss: 0.1649
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5415s / 1226.0853 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.1640
Episode: 28151/30000 (93.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5300s / 1226.6152 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.1642
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5038s / 1227.1191 s
agent0:                 episode reward: -0.0610,                 loss: nan
agent1:                 episode reward: 0.0610,                 loss: 0.1616
Episode: 28171/30000 (93.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5386s / 1227.6577 s
agent0:                 episode reward: -0.7450,                 loss: nan
agent1:                 episode reward: 0.7450,                 loss: 0.1622
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5094s / 1228.1671 s
agent0:                 episode reward: -0.6474,                 loss: nan
agent1:                 episode reward: 0.6474,                 loss: 0.1633
Episode: 28191/30000 (93.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5108s / 1228.6779 s
agent0:                 episode reward: -0.1005,                 loss: nan
agent1:                 episode reward: 0.1005,                 loss: 0.1606
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5627s / 1229.2406 s
agent0:                 episode reward: -1.2095,                 loss: nan
agent1:                 episode reward: 1.2095,                 loss: 0.1603
Episode: 28211/30000 (94.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5452s / 1229.7858 s
agent0:                 episode reward: -1.0715,                 loss: nan
agent1:                 episode reward: 1.0715,                 loss: 0.1636
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5538s / 1230.3396 s
agent0:                 episode reward: -0.0264,                 loss: nan
agent1:                 episode reward: 0.0264,                 loss: 0.1602
Episode: 28231/30000 (94.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5357s / 1230.8752 s
agent0:                 episode reward: 0.1284,                 loss: nan
agent1:                 episode reward: -0.1284,                 loss: 0.1612
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5621s / 1231.4374 s
agent0:                 episode reward: -0.6643,                 loss: nan
agent1:                 episode reward: 0.6643,                 loss: 0.1609
Episode: 28251/30000 (94.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7241s / 1232.1615 s
agent0:                 episode reward: -0.5809,                 loss: nan
agent1:                 episode reward: 0.5809,                 loss: 0.1577
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8187s / 1232.9801 s
agent0:                 episode reward: -0.7172,                 loss: nan
agent1:                 episode reward: 0.7172,                 loss: 0.1598
Episode: 28271/30000 (94.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5316s / 1233.5117 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: 0.1592
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5211s / 1234.0329 s
agent0:                 episode reward: -0.4336,                 loss: nan
agent1:                 episode reward: 0.4336,                 loss: 0.1608
Episode: 28291/30000 (94.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5176s / 1234.5505 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.1579
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5164s / 1235.0668 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1594
Episode: 28311/30000 (94.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5355s / 1235.6023 s
agent0:                 episode reward: -0.5502,                 loss: nan
agent1:                 episode reward: 0.5502,                 loss: 0.1594
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5175s / 1236.1197 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1610
Episode: 28331/30000 (94.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5294s / 1236.6492 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.1614
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5358s / 1237.1849 s
agent0:                 episode reward: -0.6112,                 loss: nan
agent1:                 episode reward: 0.6112,                 loss: 0.1584
Episode: 28351/30000 (94.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5306s / 1237.7155 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.1587
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5089s / 1238.2244 s
agent0:                 episode reward: -0.1081,                 loss: nan
agent1:                 episode reward: 0.1081,                 loss: 0.1601
Episode: 28371/30000 (94.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5397s / 1238.7641 s
agent0:                 episode reward: -0.9201,                 loss: nan
agent1:                 episode reward: 0.9201,                 loss: 0.1592
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5198s / 1239.2839 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.1582
Episode: 28391/30000 (94.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5092s / 1239.7931 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1613
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 1240.3793 s
agent0:                 episode reward: 0.4776,                 loss: nan
agent1:                 episode reward: -0.4776,                 loss: 0.1578
Episode: 28411/30000 (94.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8328s / 1241.2120 s
agent0:                 episode reward: -0.6098,                 loss: nan
agent1:                 episode reward: 0.6098,                 loss: 0.1596
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7229s / 1241.9350 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.1601
Episode: 28431/30000 (94.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7876s / 1242.7226 s
agent0:                 episode reward: 0.0678,                 loss: nan
agent1:                 episode reward: -0.0678,                 loss: 0.1606
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 1243.3163 s
agent0:                 episode reward: -0.7948,                 loss: nan
agent1:                 episode reward: 0.7948,                 loss: 0.1579
Episode: 28451/30000 (94.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5779s / 1243.8942 s
agent0:                 episode reward: -0.0993,                 loss: nan
agent1:                 episode reward: 0.0993,                 loss: 0.1595
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8773s / 1244.7715 s
agent0:                 episode reward: -0.7649,                 loss: nan
agent1:                 episode reward: 0.7649,                 loss: 0.1599
Episode: 28471/30000 (94.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5525s / 1245.3240 s
agent0:                 episode reward: 0.0241,                 loss: nan
agent1:                 episode reward: -0.0241,                 loss: 0.1591
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5379s / 1245.8619 s
agent0:                 episode reward: -0.4463,                 loss: nan
agent1:                 episode reward: 0.4463,                 loss: 0.1593
Episode: 28491/30000 (94.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7921s / 1246.6539 s
agent0:                 episode reward: 0.1809,                 loss: nan
agent1:                 episode reward: -0.1809,                 loss: 0.1600
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5511s / 1247.2050 s
agent0:                 episode reward: -0.7408,                 loss: nan
agent1:                 episode reward: 0.7408,                 loss: 0.1589
Episode: 28511/30000 (95.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5609s / 1247.7659 s
agent0:                 episode reward: -0.5399,                 loss: nan
agent1:                 episode reward: 0.5399,                 loss: 0.1582
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5634s / 1248.3293 s
agent0:                 episode reward: 0.1960,                 loss: nan
agent1:                 episode reward: -0.1960,                 loss: 0.1603
Episode: 28531/30000 (95.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7163s / 1249.0456 s
agent0:                 episode reward: -0.1310,                 loss: nan
agent1:                 episode reward: 0.1310,                 loss: 0.1583
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5366s / 1249.5822 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.1607
Episode: 28551/30000 (95.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5774s / 1250.1596 s
agent0:                 episode reward: 0.1308,                 loss: nan
agent1:                 episode reward: -0.1308,                 loss: 0.1639
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 1250.7695 s
agent0:                 episode reward: -0.2858,                 loss: nan
agent1:                 episode reward: 0.2858,                 loss: 0.1624
Episode: 28571/30000 (95.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5348s / 1251.3044 s
agent0:                 episode reward: -0.1042,                 loss: nan
agent1:                 episode reward: 0.1042,                 loss: 0.1626
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5232s / 1251.8276 s
agent0:                 episode reward: -0.3287,                 loss: nan
agent1:                 episode reward: 0.3287,                 loss: 0.1638
Episode: 28591/30000 (95.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 1252.3367 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.1598
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5263s / 1252.8630 s
agent0:                 episode reward: -0.4905,                 loss: nan
agent1:                 episode reward: 0.4905,                 loss: 0.1623
Episode: 28611/30000 (95.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5239s / 1253.3869 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1615
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5747s / 1253.9617 s
agent0:                 episode reward: -0.6066,                 loss: nan
agent1:                 episode reward: 0.6066,                 loss: 0.1629
Episode: 28631/30000 (95.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5253s / 1254.4869 s
agent0:                 episode reward: -0.0823,                 loss: nan
agent1:                 episode reward: 0.0823,                 loss: 0.1625
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4930s / 1254.9799 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.1628
Episode: 28651/30000 (95.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4978s / 1255.4778 s
agent0:                 episode reward: -0.2045,                 loss: nan
agent1:                 episode reward: 0.2045,                 loss: 0.1614
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5013s / 1255.9791 s
agent0:                 episode reward: -0.2380,                 loss: nan
agent1:                 episode reward: 0.2380,                 loss: 0.1600
Episode: 28671/30000 (95.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5150s / 1256.4941 s
agent0:                 episode reward: -0.7458,                 loss: nan
agent1:                 episode reward: 0.7458,                 loss: 0.1632
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5310s / 1257.0250 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1647
Episode: 28691/30000 (95.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5220s / 1257.5470 s
agent0:                 episode reward: -0.0681,                 loss: nan
agent1:                 episode reward: 0.0681,                 loss: 0.1611
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5135s / 1258.0605 s
agent0:                 episode reward: -0.0924,                 loss: nan
agent1:                 episode reward: 0.0924,                 loss: 0.1632
Episode: 28711/30000 (95.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5079s / 1258.5685 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1625
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5192s / 1259.0876 s
agent0:                 episode reward: -0.8572,                 loss: nan
agent1:                 episode reward: 0.8572,                 loss: 0.1636
Episode: 28731/30000 (95.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 1259.6087 s
agent0:                 episode reward: -0.6026,                 loss: nan
agent1:                 episode reward: 0.6026,                 loss: 0.1623
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5431s / 1260.1518 s
agent0:                 episode reward: -0.4308,                 loss: nan
agent1:                 episode reward: 0.4308,                 loss: 0.1617
Episode: 28751/30000 (95.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5192s / 1260.6710 s
agent0:                 episode reward: -0.8659,                 loss: nan
agent1:                 episode reward: 0.8659,                 loss: 0.1623
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5139s / 1261.1848 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.1626
Episode: 28771/30000 (95.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5139s / 1261.6987 s
agent0:                 episode reward: -0.2650,                 loss: nan
agent1:                 episode reward: 0.2650,                 loss: 0.1622
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5141s / 1262.2128 s
agent0:                 episode reward: -0.6252,                 loss: nan
agent1:                 episode reward: 0.6252,                 loss: 0.1632
Episode: 28791/30000 (95.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4956s / 1262.7084 s
agent0:                 episode reward: -0.1495,                 loss: nan
agent1:                 episode reward: 0.1495,                 loss: 0.1627
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 1263.2238 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.1609
Episode: 28811/30000 (96.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5179s / 1263.7417 s
agent0:                 episode reward: -0.3417,                 loss: nan
agent1:                 episode reward: 0.3417,                 loss: 0.1621
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5246s / 1264.2663 s
agent0:                 episode reward: -0.1599,                 loss: nan
agent1:                 episode reward: 0.1599,                 loss: 0.1615
Episode: 28831/30000 (96.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5421s / 1264.8084 s
agent0:                 episode reward: -0.8157,                 loss: nan
agent1:                 episode reward: 0.8157,                 loss: 0.1625
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5241s / 1265.3325 s
agent0:                 episode reward: -0.9805,                 loss: nan
agent1:                 episode reward: 0.9805,                 loss: 0.1625
Episode: 28851/30000 (96.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5248s / 1265.8573 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.1613
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5472s / 1266.4045 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.1635
Episode: 28871/30000 (96.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5238s / 1266.9282 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.1636
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5149s / 1267.4431 s
agent0:                 episode reward: -0.1121,                 loss: nan
agent1:                 episode reward: 0.1121,                 loss: 0.1624
Episode: 28891/30000 (96.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 1267.9586 s
agent0:                 episode reward: -0.2238,                 loss: nan
agent1:                 episode reward: 0.2238,                 loss: 0.1622
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5175s / 1268.4761 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1604
Episode: 28911/30000 (96.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5300s / 1269.0061 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.1635
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5300s / 1269.5360 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.1601
Episode: 28931/30000 (96.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5140s / 1270.0501 s
agent0:                 episode reward: -0.9134,                 loss: nan
agent1:                 episode reward: 0.9134,                 loss: 0.1616
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 1270.5604 s
agent0:                 episode reward: -0.8784,                 loss: nan
agent1:                 episode reward: 0.8784,                 loss: 0.1614
Episode: 28951/30000 (96.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5187s / 1271.0791 s
agent0:                 episode reward: -0.7096,                 loss: nan
agent1:                 episode reward: 0.7096,                 loss: 0.1631
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5152s / 1271.5943 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1640
Episode: 28971/30000 (96.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5137s / 1272.1080 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.1607
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5177s / 1272.6258 s
agent0:                 episode reward: -0.8973,                 loss: nan
agent1:                 episode reward: 0.8973,                 loss: 0.1635
Episode: 28991/30000 (96.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5470s / 1273.1728 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.1595
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5139s / 1273.6867 s
agent0:                 episode reward: 0.3211,                 loss: nan
agent1:                 episode reward: -0.3211,                 loss: 0.1625
Episode: 29011/30000 (96.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5262s / 1274.2129 s
agent0:                 episode reward: -0.0940,                 loss: nan
agent1:                 episode reward: 0.0940,                 loss: 0.1594
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4929s / 1274.7058 s
agent0:                 episode reward: -0.4295,                 loss: nan
agent1:                 episode reward: 0.4295,                 loss: 0.1598
Episode: 29031/30000 (96.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5130s / 1275.2188 s
agent0:                 episode reward: -0.1075,                 loss: nan
agent1:                 episode reward: 0.1075,                 loss: 0.1607
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4975s / 1275.7163 s
agent0:                 episode reward: -0.3302,                 loss: nan
agent1:                 episode reward: 0.3302,                 loss: 0.1602
Episode: 29051/30000 (96.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4921s / 1276.2085 s
agent0:                 episode reward: -1.0835,                 loss: nan
agent1:                 episode reward: 1.0835,                 loss: 0.1608
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4963s / 1276.7047 s
agent0:                 episode reward: 0.1669,                 loss: nan
agent1:                 episode reward: -0.1669,                 loss: 0.1630
Episode: 29071/30000 (96.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 1277.1908 s
agent0:                 episode reward: -0.7140,                 loss: nan
agent1:                 episode reward: 0.7140,                 loss: 0.1612
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4915s / 1277.6823 s
agent0:                 episode reward: -1.0193,                 loss: nan
agent1:                 episode reward: 1.0193,                 loss: 0.1623
Episode: 29091/30000 (96.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5013s / 1278.1836 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.1598
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5283s / 1278.7120 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.1614
Episode: 29111/30000 (97.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5142s / 1279.2262 s
agent0:                 episode reward: 0.1019,                 loss: nan
agent1:                 episode reward: -0.1019,                 loss: 0.1604
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5239s / 1279.7501 s
agent0:                 episode reward: -0.3677,                 loss: nan
agent1:                 episode reward: 0.3677,                 loss: 0.1601
Episode: 29131/30000 (97.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5323s / 1280.2824 s
agent0:                 episode reward: 0.1112,                 loss: nan
agent1:                 episode reward: -0.1112,                 loss: 0.1616
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5207s / 1280.8032 s
agent0:                 episode reward: -0.0251,                 loss: nan
agent1:                 episode reward: 0.0251,                 loss: 0.1606
Episode: 29151/30000 (97.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5379s / 1281.3410 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1600
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5516s / 1281.8927 s
agent0:                 episode reward: 0.1061,                 loss: nan
agent1:                 episode reward: -0.1061,                 loss: 0.1608
Episode: 29171/30000 (97.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5174s / 1282.4101 s
agent0:                 episode reward: -0.0682,                 loss: nan
agent1:                 episode reward: 0.0682,                 loss: 0.1628
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5191s / 1282.9292 s
agent0:                 episode reward: -0.9092,                 loss: nan
agent1:                 episode reward: 0.9092,                 loss: 0.1620
Episode: 29191/30000 (97.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5207s / 1283.4499 s
agent0:                 episode reward: -0.5237,                 loss: nan
agent1:                 episode reward: 0.5237,                 loss: 0.1594
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5132s / 1283.9631 s
agent0:                 episode reward: 0.1276,                 loss: nan
agent1:                 episode reward: -0.1276,                 loss: 0.1610
Episode: 29211/30000 (97.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5446s / 1284.5078 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.1608
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5268s / 1285.0346 s
agent0:                 episode reward: -0.0922,                 loss: nan
agent1:                 episode reward: 0.0922,                 loss: 0.1605
Episode: 29231/30000 (97.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5096s / 1285.5442 s
agent0:                 episode reward: -0.0688,                 loss: nan
agent1:                 episode reward: 0.0688,                 loss: 0.1604
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5219s / 1286.0661 s
agent0:                 episode reward: 0.2518,                 loss: nan
agent1:                 episode reward: -0.2518,                 loss: 0.1595
Episode: 29251/30000 (97.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5149s / 1286.5810 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.1609
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5044s / 1287.0855 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.1613
Episode: 29271/30000 (97.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5106s / 1287.5960 s
agent0:                 episode reward: -0.1254,                 loss: nan
agent1:                 episode reward: 0.1254,                 loss: 0.1608
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4907s / 1288.0867 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.1597
Episode: 29291/30000 (97.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4934s / 1288.5801 s
agent0:                 episode reward: -0.9959,                 loss: nan
agent1:                 episode reward: 0.9959,                 loss: 0.1586
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4930s / 1289.0731 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.1607
Episode: 29311/30000 (97.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4995s / 1289.5726 s
agent0:                 episode reward: 0.1499,                 loss: nan
agent1:                 episode reward: -0.1499,                 loss: 0.1606
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5181s / 1290.0907 s
agent0:                 episode reward: 0.3333,                 loss: nan
agent1:                 episode reward: -0.3333,                 loss: 0.1595
Episode: 29331/30000 (97.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5156s / 1290.6063 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.1602
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4936s / 1291.1000 s
agent0:                 episode reward: -0.0217,                 loss: nan
agent1:                 episode reward: 0.0217,                 loss: 0.1610
Episode: 29351/30000 (97.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5025s / 1291.6025 s
agent0:                 episode reward: -1.3101,                 loss: nan
agent1:                 episode reward: 1.3101,                 loss: 0.1606
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4916s / 1292.0941 s
agent0:                 episode reward: -0.9511,                 loss: nan
agent1:                 episode reward: 0.9511,                 loss: 0.1598
Episode: 29371/30000 (97.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5073s / 1292.6014 s
agent0:                 episode reward: -0.1766,                 loss: nan
agent1:                 episode reward: 0.1766,                 loss: 0.1602
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5427s / 1293.1442 s
agent0:                 episode reward: -0.8593,                 loss: nan
agent1:                 episode reward: 0.8593,                 loss: 0.1599
Episode: 29391/30000 (97.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5420s / 1293.6861 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1622
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5207s / 1294.2068 s
agent0:                 episode reward: -0.5496,                 loss: nan
agent1:                 episode reward: 0.5496,                 loss: 0.1577
Episode: 29411/30000 (98.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5176s / 1294.7244 s
agent0:                 episode reward: 0.0796,                 loss: nan
agent1:                 episode reward: -0.0796,                 loss: 0.1604
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5110s / 1295.2354 s
agent0:                 episode reward: -0.7149,                 loss: nan
agent1:                 episode reward: 0.7149,                 loss: 0.1619
Episode: 29431/30000 (98.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5437s / 1295.7791 s
agent0:                 episode reward: -0.8524,                 loss: nan
agent1:                 episode reward: 0.8524,                 loss: 0.1573
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5118s / 1296.2909 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.1599
Episode: 29451/30000 (98.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5379s / 1296.8288 s
agent0:                 episode reward: -0.0165,                 loss: nan
agent1:                 episode reward: 0.0165,                 loss: 0.1590
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5315s / 1297.3603 s
agent0:                 episode reward: 0.1692,                 loss: nan
agent1:                 episode reward: -0.1692,                 loss: 0.1606
Episode: 29471/30000 (98.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 1297.8699 s
agent0:                 episode reward: -0.2522,                 loss: nan
agent1:                 episode reward: 0.2522,                 loss: 0.1581
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5325s / 1298.4024 s
agent0:                 episode reward: -0.0799,                 loss: nan
agent1:                 episode reward: 0.0799,                 loss: 0.1607
Episode: 29491/30000 (98.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5206s / 1298.9230 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.1589
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5094s / 1299.4324 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.1601
Episode: 29511/30000 (98.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5338s / 1299.9662 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1599
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5116s / 1300.4778 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.1581
Episode: 29531/30000 (98.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5147s / 1300.9925 s
agent0:                 episode reward: -0.5305,                 loss: nan
agent1:                 episode reward: 0.5305,                 loss: 0.1598
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5218s / 1301.5143 s
agent0:                 episode reward: 0.5126,                 loss: nan
agent1:                 episode reward: -0.5126,                 loss: 0.1598
Episode: 29551/30000 (98.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5170s / 1302.0313 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.1599
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5164s / 1302.5477 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.1630
Episode: 29571/30000 (98.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5494s / 1303.0971 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1626
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5273s / 1303.6244 s
agent0:                 episode reward: -0.3013,                 loss: nan
agent1:                 episode reward: 0.3013,                 loss: 0.1613
Episode: 29591/30000 (98.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5353s / 1304.1597 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.1622
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5385s / 1304.6982 s
agent0:                 episode reward: -0.4276,                 loss: nan
agent1:                 episode reward: 0.4276,                 loss: 0.1643
Episode: 29611/30000 (98.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5249s / 1305.2232 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: 0.1633
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5320s / 1305.7552 s
agent0:                 episode reward: -0.5977,                 loss: nan
agent1:                 episode reward: 0.5977,                 loss: 0.1653
Episode: 29631/30000 (98.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5374s / 1306.2926 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1642
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5383s / 1306.8309 s
agent0:                 episode reward: -0.2791,                 loss: nan
agent1:                 episode reward: 0.2791,                 loss: 0.1652
Episode: 29651/30000 (98.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5206s / 1307.3515 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1613
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5126s / 1307.8641 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.1588
Episode: 29671/30000 (98.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 1308.3764 s
agent0:                 episode reward: -0.4881,                 loss: nan
agent1:                 episode reward: 0.4881,                 loss: 0.1632
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5121s / 1308.8885 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.1643
Episode: 29691/30000 (98.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5156s / 1309.4041 s
agent0:                 episode reward: -0.7549,                 loss: nan
agent1:                 episode reward: 0.7549,                 loss: 0.1623
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5052s / 1309.9093 s
agent0:                 episode reward: -0.4536,                 loss: nan
agent1:                 episode reward: 0.4536,                 loss: 0.1628
Episode: 29711/30000 (99.0367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5131s / 1310.4225 s
agent0:                 episode reward: -0.7191,                 loss: nan
agent1:                 episode reward: 0.7191,                 loss: 0.1641
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5225s / 1310.9449 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1639
Episode: 29731/30000 (99.1033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5198s / 1311.4647 s
agent0:                 episode reward: -0.4573,                 loss: nan
agent1:                 episode reward: 0.4573,                 loss: 0.1652
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5362s / 1312.0009 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.1624
Episode: 29751/30000 (99.1700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5333s / 1312.5342 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.1638
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5359s / 1313.0701 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.1615
Episode: 29771/30000 (99.2367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5356s / 1313.6057 s
agent0:                 episode reward: -0.1524,                 loss: nan
agent1:                 episode reward: 0.1524,                 loss: 0.1625
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5417s / 1314.1474 s
agent0:                 episode reward: -0.4589,                 loss: nan
agent1:                 episode reward: 0.4589,                 loss: 0.1626
Episode: 29791/30000 (99.3033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5330s / 1314.6804 s
agent0:                 episode reward: -0.2927,                 loss: nan
agent1:                 episode reward: 0.2927,                 loss: 0.1613
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 1315.2672 s
agent0:                 episode reward: -0.2131,                 loss: nan
agent1:                 episode reward: 0.2131,                 loss: 0.1630
Episode: 29811/30000 (99.3700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5384s / 1315.8056 s
agent0:                 episode reward: -0.0435,                 loss: nan
agent1:                 episode reward: 0.0435,                 loss: 0.1630
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5408s / 1316.3464 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.1642
Episode: 29831/30000 (99.4367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5343s / 1316.8807 s
agent0:                 episode reward: -0.2777,                 loss: nan
agent1:                 episode reward: 0.2777,                 loss: 0.1616
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5338s / 1317.4145 s
agent0:                 episode reward: -1.1347,                 loss: nan
agent1:                 episode reward: 1.1347,                 loss: 0.1621
Episode: 29851/30000 (99.5033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5360s / 1317.9504 s
agent0:                 episode reward: -0.3070,                 loss: nan
agent1:                 episode reward: 0.3070,                 loss: 0.1633
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5513s / 1318.5018 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.1620
Episode: 29871/30000 (99.5700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5362s / 1319.0380 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.1640
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5346s / 1319.5725 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.1629
Episode: 29891/30000 (99.6367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5143s / 1320.0869 s
agent0:                 episode reward: 0.0184,                 loss: nan
agent1:                 episode reward: -0.0184,                 loss: 0.1632
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5454s / 1320.6323 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.1626
Episode: 29911/30000 (99.7033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5472s / 1321.1794 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.1610
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5339s / 1321.7134 s
agent0:                 episode reward: -0.4614,                 loss: nan
agent1:                 episode reward: 0.4614,                 loss: 0.1630
Episode: 29931/30000 (99.7700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4934s / 1322.2067 s
agent0:                 episode reward: 0.1612,                 loss: nan
agent1:                 episode reward: -0.1612,                 loss: 0.1607
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4900s / 1322.6967 s/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.1617
Episode: 29951/30000 (99.8367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5437s / 1323.2404 s
agent0:                 episode reward: -0.2764,                 loss: nan
agent1:                 episode reward: 0.2764,                 loss: 0.1619
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5156s / 1323.7560 s
agent0:                 episode reward: -0.5704,                 loss: nan
agent1:                 episode reward: 0.5704,                 loss: 0.1624
Episode: 29971/30000 (99.9033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5398s / 1324.2957 s
agent0:                 episode reward: -0.7445,                 loss: nan
agent1:                 episode reward: 0.7445,                 loss: 0.1626
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5211s / 1324.8168 s
agent0:                 episode reward: 0.1731,                 loss: nan
agent1:                 episode reward: -0.1731,                 loss: 0.1624
Episode: 29991/30000 (99.9700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 1325.3379 s
agent0:                 episode reward: 0.1912,                 loss: nan
agent1:                 episode reward: -0.1912,                 loss: 0.1591
