pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
basketball_pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24, 37, 60, 35]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'basketball_pong_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 15, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220425_1813/pettingzoo_basketball_pong_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220425_1813/pettingzoo_basketball_pong_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 3.7410s / 3.7410 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3715
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 72.6259s / 76.3669 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0452
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5503s / 153.9172 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0191
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 82.1053s / 236.0224 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0149
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5774s / 322.5998 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0143
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.4073s / 413.0071 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0141
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.4980s / 508.5052 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0140
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4853s / 607.9905 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0138
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5249s / 713.5154 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0135
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.5476s / 823.0629 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0136
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 114.7952s / 937.8582 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0132
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 119.3374s / 1057.1955 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0133
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.7074s / 1181.9029 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0129
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.5488s / 1311.4517 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0128
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 137.9822s / 1449.4339 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0125
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.4021s / 1591.8360 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0124
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 146.7313s / 1738.5673 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0122
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1727s / 1891.7400 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0122
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.3426s / 2044.0826 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0124
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4854s / 2197.5680 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0121
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.3027s / 2348.8707 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0122
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.0935s / 2500.9642 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0121
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.7249s / 2652.6891 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.1940s / 2804.8831 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0123
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.8833s / 2957.7664 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0121
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8387s / 3111.6051 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0125
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5656s / 3265.1707 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0121
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.0609s / 3418.2317 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0120
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.4565s / 3570.6882 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.6616s / 3722.3498 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0123
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4339s / 3875.7837 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0122
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0994s / 4029.8831 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0127
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3152s / 4184.1983 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0125
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2268s / 4337.4251 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0122
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4333s / 4490.8584 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0122
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0577s / 4644.9161 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0123
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.4640s / 4797.3802 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0121
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6272s / 4951.0073 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5452s / 5105.5526 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0131
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4587s / 5260.0113 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0125
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9049s / 5412.9162 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0124
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9329s / 5566.8490 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1884s / 5721.0374 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0120
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8671s / 5874.9045 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5576s / 6029.4621 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0120
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9233s / 6183.3853 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0120
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8817s / 6338.2671 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0116
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0898s / 6492.3569 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0118
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6141s / 6646.9710 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9001s / 6800.8711 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0111
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1603s / 6955.0314 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0109
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8033s / 7108.8346 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0106
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2224s / 7262.0571 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0109
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4420s / 7415.4991 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0110
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1734s / 7570.6725 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2794s / 7725.9519 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0109
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8035s / 7879.7554 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0106
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4987s / 8034.2541 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0108
env0_second_0:                 episode reward: -2.2500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2136s / 8188.4677 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0103
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6996s / 8342.1673 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0103
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9150s / 8496.0823 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0105
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8895s / 8650.9718 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0105
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.5570s / 8806.5288 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0106
env0_second_0:                 episode reward: -2.2500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8832s / 8961.4120 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0105
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0102s / 9115.4222 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0107
env0_second_0:                 episode reward: -2.2500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.2575s / 9271.6797 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6710s / 9425.3506 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0105
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8558s / 9579.2064 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0108
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3187s / 9733.5251 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.7870s / 9887.3122 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0107
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9821s / 10042.2943 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0106
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6764s / 10195.9707 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0113
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3531s / 10350.3238 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0114
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1509s / 10505.4747 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0107
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5112s / 10658.9858 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0107
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5854s / 10813.5712 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0108
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6504s / 10967.2216 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0105
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6999s / 11121.9215 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0105
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8881s / 11276.8097 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9670s / 11430.7767 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0109
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4371s / 11584.2138 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0110
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1915s / 11739.4053 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0107
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5129s / 11893.9181 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0106
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6505s / 12048.5686 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0106
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5442s / 12202.1129 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0104
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1105s / 12356.2233 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0103
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0864s / 12510.3097 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0101
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0767s / 12665.3864 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0099
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8841s / 12820.2705 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0099
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5414s / 12974.8119 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0098
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.4500,                 loss: nan
env3_second_0:                 episode reward: -3.4500,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4298s / 13129.2418 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0097
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6616s / 13284.9033 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4137s / 13440.3171 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0098
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.3785s / 13595.6956 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0097
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0376s / 13750.7332 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0097
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1358s / 13905.8690 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0095
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8611s / 14060.7301 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0095
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.3922s / 14217.1223 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0095
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2183s / 14371.3406 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0094
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7616s / 14526.1021 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0096
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5348s / 14679.6369 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6744s / 14834.3113 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0095
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6505s / 14989.9618 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0096
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0384s / 15145.0001 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0096
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.8769s / 15302.8771 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0094
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.7551s / 15456.6322 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0097
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1448s / 15611.7770 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0098
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6367s / 15767.4137 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0105
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8796s / 15922.2933 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9492s / 16077.2425 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0112
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7896s / 16232.0322 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0116
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1808s / 16387.2130 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0116
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2811s / 16540.4941 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0118
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8394s / 16695.3335 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0123
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1993s / 16849.5328 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0118
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5566s / 17004.0894 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0117
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4739s / 17158.5634 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0116
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2018s / 17312.7652 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0108
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7706s / 17467.5357 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0106
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9154s / 17622.4512 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0104
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0656s / 17777.5168 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1103s / 17932.6271 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0104
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0549s / 18086.6820 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0108
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8103s / 18240.4922 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0108
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2058s / 18394.6981 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0110
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9458s / 18550.6439 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0107
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4955s / 18704.1394 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0105
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.8416s / 18859.9810 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0105
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1243s / 19014.1053 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0105
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2511s / 19168.3564 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0101
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2860s / 19323.6424 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0101
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6817s / 19477.3241 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0102
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9363s / 19633.2604 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0098
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.2000,                 loss: nan
env3_second_0:                 episode reward: -3.2000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9927s / 19789.2531 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0095
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2242s / 19943.4773 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0092
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.1060s / 20099.5833 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0089
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6745s / 20254.2578 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0088
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9438s / 20410.2016 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0093
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0933s / 20566.2949 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0087
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6251s / 20720.9201 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0089
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.2507s / 20877.1708 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0086
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2417s / 21032.4124 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0082
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
env2_first_0:                 episode reward: 4.0000,                 loss: nan
env2_second_0:                 episode reward: -4.0000,                 loss: nan
env3_first_0:                 episode reward: 4.0000,                 loss: nan
env3_second_0:                 episode reward: -4.0000,                 loss: nan
env4_first_0:                 episode reward: 4.0000,                 loss: nan
env4_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8276s / 21187.2400 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0078
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4140s / 21341.6541 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.3772s / 21497.0312 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0077
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.8515s / 21652.8827 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0077
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0569s / 21808.9396 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0079
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0323s / 21963.9719 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.5818s / 22120.5537 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.1918s / 22276.7455 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0076
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6772s / 22431.4227 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0003s / 22585.4230 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0078
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6804s / 22741.1034 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0080
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.5006s / 22896.6040 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0078
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.7561s / 23052.3601 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0077
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8691s / 23207.2292 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0073
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6518s / 23360.8809 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0074
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.3000,                 loss: nan
env4_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1780s / 23516.0590 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0073
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0278s / 23671.0867 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0073
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0248s / 23827.1115 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0078
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4228s / 23981.5342 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0083
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1832s / 24135.7174 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0079
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.7340s / 24291.4514 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0078
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5515s / 24446.0029 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0080
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.5028s / 24601.5058 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0078
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4419s / 24755.9476 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0077
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.5837s / 24912.5314 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0077
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.9938s / 25066.5252 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0079
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4013s / 25220.9264 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0079
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.1417s / 25376.0681 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0076
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4187s / 25531.4869 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0077
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.8032s / 25687.2901 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.3405s / 25843.6306 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0077
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.7484s / 25999.3790 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0081
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2311s / 26154.6101 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0080
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 3.9500,                 loss: nan
env4_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.3527s / 26309.9627 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0077
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2757s / 26465.2385 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0076
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.4409s / 26621.6794 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0075
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7307s / 26776.4100 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0076
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2340s / 26931.6441 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0074
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9652s / 27086.6093 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0073
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0912s / 27242.7005 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0072
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6517s / 27397.3522 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0072
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8058s / 27552.1579 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0073
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2194s / 27706.3773 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.0069
env0_second_0:                 episode reward: -4.6000,                 loss: nan
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
env2_first_0:                 episode reward: 4.6000,                 loss: nan
env2_second_0:                 episode reward: -4.6000,                 loss: nan
env3_first_0:                 episode reward: 4.6000,                 loss: nan
env3_second_0:                 episode reward: -4.6000,                 loss: nan
env4_first_0:                 episode reward: 4.6000,                 loss: nan
env4_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.0003s / 27863.3776 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0068
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6679s / 28019.0455 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0065
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.3930s / 28172.4385 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0067
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8027s / 28327.2412 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6753s / 28482.9165 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.5477s / 28638.4642 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0070
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9838s / 28794.4480 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0073
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.6122s / 28951.0602 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0072
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.1357s / 29107.1959 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0072
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9941s / 29263.1901 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0069
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6997s / 29418.8897 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0069
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6992s / 29574.5889 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0067
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.6500,                 loss: nan
env4_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9117s / 29730.5006 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0067
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3483s / 29884.8489 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0067
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2829s / 30040.1318 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3268s / 30194.4586 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0122s / 30350.4707 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0070
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6329s / 30506.1036 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0071
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6369s / 30661.7405 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.0492s / 30817.7897 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.4239s / 30974.2136 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4007s / 31129.6143 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0066
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6714s / 31285.2857 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0068
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.9407s / 31441.2264 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0067
env0_second_0:                 episode reward: -2.2500,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.8138s / 31598.0403 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0069
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.3345s / 31754.3748 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0071
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4300s / 31909.8047 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0069
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.5429s / 32066.3476 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1308s / 32219.4784 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.2820s / 32371.7604 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.1840s / 32525.9444 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.7698s / 32678.7142 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0074
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4799s / 32832.1941 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0076
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.3675s / 32985.5616 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0076
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1958s / 33138.7574 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0074
env0_second_0:                 episode reward: -4.2500,                 loss: nan
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
env2_first_0:                 episode reward: 4.2500,                 loss: nan
env2_second_0:                 episode reward: -4.2500,                 loss: nan
env3_first_0:                 episode reward: 4.2500,                 loss: nan
env3_second_0:                 episode reward: -4.2500,                 loss: nan
env4_first_0:                 episode reward: 4.2500,                 loss: nan
env4_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.6643s / 33291.4217 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0069
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9771s / 33446.3988 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0073
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9863s / 33599.3851 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0069
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.2000,                 loss: nan
env3_second_0:                 episode reward: -3.2000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4749s / 33754.8599 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.0075
env0_second_0:                 episode reward: -4.8500,                 loss: nan
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 4.8500,                 loss: nan
env2_second_0:                 episode reward: -4.8500,                 loss: nan
env3_first_0:                 episode reward: 4.8500,                 loss: nan
env3_second_0:                 episode reward: -4.8500,                 loss: nan
env4_first_0:                 episode reward: 4.8500,                 loss: nan
env4_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.5631s / 33907.4230 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0071
env0_second_0:                 episode reward: -4.2000,                 loss: nan
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
env2_first_0:                 episode reward: 4.2000,                 loss: nan
env2_second_0:                 episode reward: -4.2000,                 loss: nan
env3_first_0:                 episode reward: 4.2000,                 loss: nan
env3_second_0:                 episode reward: -4.2000,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.3368s / 34052.7598 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0066
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 3.4000,                 loss: nan
env3_second_0:                 episode reward: -3.4000,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.2550s / 34197.0149 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0067
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 146.5530s / 34343.5679 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0064
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.1755s / 34488.7433 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0062
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.4874s / 34632.2307 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0062
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.8789s / 34776.1096 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0063
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.7725s / 34918.8821 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0063
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.0591s / 35062.9411 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0064
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.9907s / 35208.9319 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0063
env0_second_0:                 episode reward: -4.5000,                 loss: nan
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 4.5000,                 loss: nan
env4_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.3988s / 35353.3307 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.7500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.0354s / 35497.3660 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0058
env0_second_0:                 episode reward: -4.5000,                 loss: nan
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 4.5000,                 loss: nan
env4_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.5277s / 35642.8937 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0059
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.2866s / 35786.1803 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0060
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.0446s / 35931.2249 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0059
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
env3_first_0:                 episode reward: 3.7000,                 loss: nan
env3_second_0:                 episode reward: -3.7000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.2051s / 36074.4300 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0059
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.8311s / 36218.2611 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.7500,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 3.7500,                 loss: nan
env4_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.1603s / 36360.4214 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0061
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.4500,                 loss: nan
env3_second_0:                 episode reward: -3.4500,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.6211s / 36503.0425 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0059
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.4528s / 36648.4953 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
env3_first_0:                 episode reward: 3.7000,                 loss: nan
env3_second_0:                 episode reward: -3.7000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.6693s / 36791.1646 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6074s / 36934.7720 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0064
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.1281s / 37078.9001 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0063
env0_second_0:                 episode reward: -4.1500,                 loss: nan
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.1500,                 loss: nan
env2_second_0:                 episode reward: -4.1500,                 loss: nan
env3_first_0:                 episode reward: 4.1500,                 loss: nan
env3_second_0:                 episode reward: -4.1500,                 loss: nan
env4_first_0:                 episode reward: 4.1500,                 loss: nan
env4_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.7336s / 37223.6337 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0061
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6692s / 37367.3029 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0059
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5010s / 37510.8039 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0059
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.9990s / 37654.8029 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0061
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.2627s / 37799.0656 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0063
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.8282s / 37943.8939 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0065
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.1889s / 38087.0827 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0062
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.6002s / 38229.6829 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6708s / 38373.3537 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.0264s / 38515.3801 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0065
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.3429s / 38657.7230 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.4022s / 38801.1251 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0068
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.6080s / 38943.7332 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.9364s / 39087.6696 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0072
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.1812s / 39231.8508 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0072
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.0579s / 39374.9087 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0074
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6411s / 39518.5498 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0073
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5383s / 39662.0882 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0074
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6776s / 39805.7657 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.5303s / 39951.2960 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0076
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6688s / 40094.9648 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0075
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 141.6190s / 40236.5838 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0076
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.2695s / 40379.8533 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0079
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.4690s / 40523.3224 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0078
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.7999s / 40669.1222 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0075
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.6018s / 40813.7240 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0072
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.2783s / 40957.0024 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0072
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.0403s / 41101.0427 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0072
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.9301s / 41244.9727 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0072
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.5671s / 41389.5398 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0072
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5950s / 41533.1348 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.9503s / 41676.0851 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.2277s / 41820.3128 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0073
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.7439s / 41964.0567 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0068
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.2402s / 42107.2970 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0069
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.3574s / 42250.6543 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.0070
env0_second_0:                 episode reward: -4.4000,                 loss: nan
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.4000,                 loss: nan
env2_second_0:                 episode reward: -4.4000,                 loss: nan
env3_first_0:                 episode reward: 4.4000,                 loss: nan
env3_second_0:                 episode reward: -4.4000,                 loss: nan
env4_first_0:                 episode reward: 4.4000,                 loss: nan
env4_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.9718s / 42394.6261 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0064
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.0561s / 42537.6822 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0064
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.1884s / 42680.8706 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0062
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 3.9500,                 loss: nan
env4_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.3478s / 42825.2184 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0061
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
env2_first_0:                 episode reward: 4.5500,                 loss: nan
env2_second_0:                 episode reward: -4.5500,                 loss: nan
env3_first_0:                 episode reward: 4.5500,                 loss: nan
env3_second_0:                 episode reward: -4.5500,                 loss: nan
env4_first_0:                 episode reward: 4.5500,                 loss: nan
env4_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.1129s / 42969.3313 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.0058
env0_second_0:                 episode reward: -4.9500,                 loss: nan
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
env2_first_0:                 episode reward: 4.9500,                 loss: nan
env2_second_0:                 episode reward: -4.9500,                 loss: nan
env3_first_0:                 episode reward: 4.9500,                 loss: nan
env3_second_0:                 episode reward: -4.9500,                 loss: nan
env4_first_0:                 episode reward: 4.9500,                 loss: nan
env4_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.3775s / 43113.7088 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0056
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5854s / 43257.2941 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.0056
env0_second_0:                 episode reward: -4.3000,                 loss: nan
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
env3_first_0:                 episode reward: 4.3000,                 loss: nan
env3_second_0:                 episode reward: -4.3000,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.1851s / 43399.4792 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0056
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.7476s / 43542.2269 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0057
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.3634s / 43686.5903 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0056
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.7506s / 43832.3409 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0055
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.7863s / 43976.1272 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0054
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.2000,                 loss: nan
env3_second_0:                 episode reward: -3.2000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5388s / 44119.6660 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0057
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.1171s / 44262.7831 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0054
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6292s / 44406.4123 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0054
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.2000,                 loss: nan
env3_second_0:                 episode reward: -3.2000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.1113s / 44550.5235 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0056
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.4312s / 44694.9547 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0055
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.3836s / 44838.3383 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0056
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.6749s / 44981.0132 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0059
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.7424s / 45124.7557 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0059
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.3000,                 loss: nan
env4_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.8062s / 45269.5618 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0063
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6060s / 45413.1678 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.8662s / 45557.0340 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.4501s / 45701.4841 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.1455s / 45846.6296 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.5844s / 45991.2140 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.1821s / 46134.3961 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.3859s / 46278.7819 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0071
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.2414s / 46423.0234 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0077
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.9736s / 46563.9969 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0077
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.9388s / 46704.9357 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0081
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.6418s / 46845.5775 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0082
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.2822s / 46984.8597 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0077
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.1806s / 47121.0403 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0077
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.3788s / 47255.4191 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0075
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.5960s / 47391.0151 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0074
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.3630s / 47526.3781 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0072
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.6534s / 47663.0315 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0073
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.7587s / 47802.7903 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0070
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.0734s / 47938.8637 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0068
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.7500,                 loss: nan
env4_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.8648s / 48074.7285 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0064
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.1018s / 48209.8303 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0064
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.1736s / 48344.0039 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0064
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.9131s / 48478.9170 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0061
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.3856s / 48611.3026 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.2357s / 48745.5383 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0058
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.2516s / 48878.7899 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0059
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.0247s / 49013.8146 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0059
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.7604s / 49149.5750 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0060
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.2257s / 49284.8006 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0061
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.0564s / 49420.8570 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0061
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.2000s / 49556.0570 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.6794s / 49691.7364 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.4500,                 loss: nan
env3_second_0:                 episode reward: -3.4500,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.3562s / 49826.0926 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0059
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.2501s / 49960.3427 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.7326s / 50094.0752 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0062
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 137.1108s / 50231.1860 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0063
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.4106s / 50364.5966 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0061
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.0912s / 50497.6877 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.3514s / 50634.0391 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0065
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.1084s / 50767.1475 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.6410s / 50901.7885 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.6984s / 51037.4869 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.4992s / 51171.9861 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.5530s / 51306.5391 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.8722s / 51443.4113 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.2885s / 51577.6998 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.3324s / 51713.0323 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.0283s / 51848.0605 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0072
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.4497s / 51982.5103 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0074
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.6500,                 loss: nan
env4_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.9849s / 52116.4951 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.0069
env0_second_0:                 episode reward: -4.4000,                 loss: nan
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.4000,                 loss: nan
env2_second_0:                 episode reward: -4.4000,                 loss: nan
env3_first_0:                 episode reward: 4.4000,                 loss: nan
env3_second_0:                 episode reward: -4.4000,                 loss: nan
env4_first_0:                 episode reward: 4.4000,                 loss: nan
env4_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.0874s / 52250.5826 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0067
env0_second_0:                 episode reward: -4.1500,                 loss: nan
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
env2_first_0:                 episode reward: 4.1500,                 loss: nan
env2_second_0:                 episode reward: -4.1500,                 loss: nan
env3_first_0:                 episode reward: 4.1500,                 loss: nan
env3_second_0:                 episode reward: -4.1500,                 loss: nan
env4_first_0:                 episode reward: 4.1500,                 loss: nan
env4_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.8355s / 52387.4180 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.0063
env0_second_0:                 episode reward: -4.9000,                 loss: nan
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
env2_first_0:                 episode reward: 4.9000,                 loss: nan
env2_second_0:                 episode reward: -4.9000,                 loss: nan
env3_first_0:                 episode reward: 4.9000,                 loss: nan
env3_second_0:                 episode reward: -4.9000,                 loss: nan
env4_first_0:                 episode reward: 4.9000,                 loss: nan
env4_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.7839s / 52521.2019 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0063
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 3.9500,                 loss: nan
env4_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.6461s / 52656.8480 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.0064
env0_second_0:                 episode reward: -4.4500,                 loss: nan
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
env2_first_0:                 episode reward: 4.4500,                 loss: nan
env2_second_0:                 episode reward: -4.4500,                 loss: nan
env3_first_0:                 episode reward: 4.4500,                 loss: nan
env3_second_0:                 episode reward: -4.4500,                 loss: nan
env4_first_0:                 episode reward: 4.4500,                 loss: nan
env4_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.4979s / 52793.3459 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0062
env0_second_0:                 episode reward: -3.8500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 3.8500,                 loss: nan
env2_second_0:                 episode reward: -3.8500,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 3.8500,                 loss: nan
env4_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.2352s / 52929.5811 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0060
env0_second_0:                 episode reward: -4.0500,                 loss: nan
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
env3_first_0:                 episode reward: 4.0500,                 loss: nan
env3_second_0:                 episode reward: -4.0500,                 loss: nan
env4_first_0:                 episode reward: 4.0500,                 loss: nan
env4_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.9414s / 53065.5225 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0058
env0_second_0:                 episode reward: -3.3500,                 loss: nan
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.8617s / 53200.3842 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0060
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.6918s / 53334.0760 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0057
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.6500,                 loss: nan
env4_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 135.5302s / 53469.6062 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0057
env0_second_0:                 episode reward: -4.1000,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.1000,                 loss: nan
env2_second_0:                 episode reward: -4.1000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.9959s / 53603.6022 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0056
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.4469s / 53737.0491 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.0055
env0_second_0:                 episode reward: -4.3500,                 loss: nan
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 4.3500,                 loss: nan
env2_second_0:                 episode reward: -4.3500,                 loss: nan
env3_first_0:                 episode reward: 4.3500,                 loss: nan
env3_second_0:                 episode reward: -4.3500,                 loss: nan
env4_first_0:                 episode reward: 4.3500,                 loss: nan
env4_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.4706s / 53870.5197 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0056
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.0826s / 54004.6023 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0055
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.3991s / 54139.0014 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0055
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.5204s / 54271.5219 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0055
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.1004s / 54407.6222 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0056
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 136.0743s / 54543.6965 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0056
env0_second_0:                 episode reward: -2.2500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.7105s / 54676.4071 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.7886s / 54809.1956 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0058
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.3730s / 54942.5686 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0063
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.7880s / 55074.3566 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0060
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.3133s / 55208.6699 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0061
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.1858s / 55341.8557 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0062
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.6382s / 55473.4939 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0061
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.1548s / 55603.6487 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.1957s / 55735.8443 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0064
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.8384s / 55868.6828 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.1043s / 55998.7871 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.3670s / 56130.1540 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0069
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.6242s / 56261.7783 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0074
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.2851s / 56393.0634 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0071
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.3752s / 56525.4386 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0069
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.2090s / 56656.6477 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.6832s / 56791.3309 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0076
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.1649s / 56923.4958 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0077
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.7520s / 57057.2479 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0076
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.9051s / 57188.1530 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0082
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.3036s / 57321.4566 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0084
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.3910s / 57452.8476 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0085
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.1851s / 57583.0327 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0087
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.6265s / 57717.6592 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0090
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.0798s / 57848.7390 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0098
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.6681s / 57979.4071 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0099
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.6484s / 58108.0555 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0095
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.4006s / 58239.4562 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0100
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.0646s / 58367.5207 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 129.3270s / 58496.8477 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0099
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.9796s / 58627.8273 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0101
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 130.1064s / 58757.9338 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0100
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 133.1845s / 58891.1183 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 134.3237s / 59025.4420 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0100
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.3821s / 59151.8241 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0105
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.6688s / 59277.4929 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0100
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.6099s / 59404.1029 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0095
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.2339s / 59530.3368 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0095
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.2609s / 59656.5976 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0096
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.2509s / 59783.8486 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0098
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.7370s / 59908.5856 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0096
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8786s / 60034.4642 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0095
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.6168s / 60160.0810 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0089
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.0754s / 60287.1564 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0088
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.4185s / 60413.5749 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0089
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8203s / 60539.3952 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.0086
env0_second_0:                 episode reward: -4.6000,                 loss: nan
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
env2_first_0:                 episode reward: 4.6000,                 loss: nan
env2_second_0:                 episode reward: -4.6000,                 loss: nan
env3_first_0:                 episode reward: 4.6000,                 loss: nan
env3_second_0:                 episode reward: -4.6000,                 loss: nan
env4_first_0:                 episode reward: 4.6000,                 loss: nan
env4_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.2259s / 60664.6210 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0082
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.2256s / 60790.8466 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0080
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 128.1303s / 60918.9769 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0078
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.9319s / 61044.9089 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0071
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.5199s / 61170.4288 s
env0_first_0:                 episode reward: 4.6500,                 loss: 0.0070
env0_second_0:                 episode reward: -4.6500,                 loss: nan
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 4.6500,                 loss: nan
env3_second_0:                 episode reward: -4.6500,                 loss: nan
env4_first_0:                 episode reward: 4.6500,                 loss: nan
env4_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7424s / 61296.1712 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0068
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.6697s / 61420.8408 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0067
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.4992s / 61545.3400 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0065
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.5000,                 loss: nan
env4_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.9448s / 61672.2848 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0063
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.1069s / 61799.3918 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0063
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
env3_first_0:                 episode reward: 3.7000,                 loss: nan
env3_second_0:                 episode reward: -3.7000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.3187s / 61925.7105 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.4560s / 62052.1665 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.3253s / 62177.4918 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0059
env0_second_0:                 episode reward: -3.3500,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.7046s / 62302.1964 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.6254s / 62428.8218 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.2750s / 62554.0968 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0059
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.6500,                 loss: nan
env4_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.9582s / 62681.0550 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0061
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.5261s / 62806.5810 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8159s / 62932.3969 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0064
env0_second_0:                 episode reward: -4.5000,                 loss: nan
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 4.5000,                 loss: nan
env4_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.9086s / 63055.3055 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.4747s / 63179.7802 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0062
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.6286s / 63303.4088 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0064
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 3.4000,                 loss: nan
env3_second_0:                 episode reward: -3.4000,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.3868s / 63426.7956 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0066
env0_second_0:                 episode reward: -3.3500,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7843s / 63552.5798 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0063
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.5484s / 63676.1282 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0062
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8002s / 63801.9284 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0061
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.4500,                 loss: nan
env3_second_0:                 episode reward: -3.4500,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.6000s / 63926.5284 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0061
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.8337s / 64051.3622 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0062
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.8414s / 64179.2035 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.0060
env0_second_0:                 episode reward: -4.3000,                 loss: nan
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
env3_first_0:                 episode reward: 4.3000,                 loss: nan
env3_second_0:                 episode reward: -4.3000,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.9945s / 64306.1980 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.6174s / 64430.8155 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0059
env0_second_0:                 episode reward: -4.1500,                 loss: nan
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.1500,                 loss: nan
env2_second_0:                 episode reward: -4.1500,                 loss: nan
env3_first_0:                 episode reward: 4.1500,                 loss: nan
env3_second_0:                 episode reward: -4.1500,                 loss: nan
env4_first_0:                 episode reward: 4.1500,                 loss: nan
env4_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1538s / 64555.9693 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0058
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
env2_first_0:                 episode reward: 4.0000,                 loss: nan
env2_second_0:                 episode reward: -4.0000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.2221s / 64681.1914 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.8428s / 64808.0342 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0058
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.4801s / 64933.5142 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.4135s / 65056.9277 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0060
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.5078s / 65182.4355 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.6500,                 loss: nan
env4_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.8557s / 65306.2912 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0062
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1501s / 65431.4413 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0058
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 4.0000,                 loss: nan
env3_second_0:                 episode reward: -4.0000,                 loss: nan
env4_first_0:                 episode reward: 4.0000,                 loss: nan
env4_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.8505s / 65559.2918 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0058
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.9500,                 loss: nan
env2_second_0:                 episode reward: -3.9500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 3.9500,                 loss: nan
env4_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.8129s / 65682.1047 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0061
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.6558s / 65807.7605 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0061
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.3843s / 65932.1447 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
env3_first_0:                 episode reward: 3.7000,                 loss: nan
env3_second_0:                 episode reward: -3.7000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.0525s / 66057.1972 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.2028s / 66183.4000 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0060
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.5909s / 66308.9910 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0061
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.8444s / 66431.8353 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0062
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.6687s / 66557.5040 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.4663s / 66683.9703 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0064
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.5952s / 66807.5655 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.2077s / 66933.7732 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0066
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8125s / 67059.5857 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.1802s / 67186.7659 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0067
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.6221s / 67313.3879 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0067
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.0473s / 67439.4352 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.6203s / 67564.0556 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0070
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.7000,                 loss: nan
env3_second_0:                 episode reward: -3.7000,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.2799s / 67688.3355 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0070
env0_second_0:                 episode reward: -3.3500,                 loss: nan
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.6752s / 67814.0106 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0070
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.8730s / 67940.8836 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.6500,                 loss: nan
env3_second_0:                 episode reward: -2.6500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 127.0564s / 68067.9400 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0073
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 3.4000,                 loss: nan
env3_second_0:                 episode reward: -3.4000,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.8225s / 68193.7626 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0076
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.3151s / 68318.0777 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0077
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1082s / 68443.1859 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0082
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.2028s / 68568.3887 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0079
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.7764s / 68691.1651 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0073
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.1000,                 loss: nan
env2_second_0:                 episode reward: -4.1000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.4574s / 68817.6225 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0072
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.1143s / 68942.7368 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0071
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.2806s / 69066.0174 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.2443s / 69188.2616 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0071
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.9756s / 69312.2372 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0068
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.5557s / 69436.7929 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0067
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.0399s / 69562.8328 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0068
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.7359s / 69687.5687 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.4282s / 69810.9968 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0071
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.9122s / 69934.9091 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0072
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 125.7570s / 70060.6660 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0077
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 124.6001s / 70185.2662 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0077
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.6908s / 70308.9569 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0075
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 121.9738s / 70430.9308 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0075
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 120.0452s / 70550.9760 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0076
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 120.1067s / 70671.0827 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0076
env0_second_0:                 episode reward: -3.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 122.2019s / 70793.2846 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0075
env0_second_0:                 episode reward: -3.7500,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nanLoad basketball_pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load basketball_pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load basketball_pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load basketball_pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load basketball_pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
