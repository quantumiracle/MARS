pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'num_process': 1, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [1024, 1024, 1024], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 459.0,                last time consumption/overall running time: 1.6524s / 1.6524 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0452
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0442
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 557.0,                last time consumption/overall running time: 32.2673s / 33.9197 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0475
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0489
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 572.15,                last time consumption/overall running time: 43.3807s / 77.3004 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0341
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 570.15,                last time consumption/overall running time: 50.9309s / 128.2313 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0267
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0267
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 577.7,                last time consumption/overall running time: 56.9974s / 185.2286 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0270
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 604.85,                last time consumption/overall running time: 63.9943s / 249.2229 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 579.0,                last time consumption/overall running time: 64.4222s / 313.6451 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 548.6,                last time consumption/overall running time: 63.4892s / 377.1343 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0278
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0273
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 568.3,                last time consumption/overall running time: 68.0680s / 445.2022 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0265
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 559.6,                last time consumption/overall running time: 68.2242s / 513.4264 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0286
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 545.5,                last time consumption/overall running time: 67.9773s / 581.4037 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0286
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0283
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 554.8,                last time consumption/overall running time: 69.0185s / 650.4223 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0291
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 576.25,                last time consumption/overall running time: 71.9279s / 722.3502 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0302
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0309
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 572.25,                last time consumption/overall running time: 71.5361s / 793.8863 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0313
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0311
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 549.8,                last time consumption/overall running time: 68.6250s / 862.5113 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0315
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0321
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 558.25,                last time consumption/overall running time: 70.0030s / 932.5143 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0323
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0315
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 567.6,                last time consumption/overall running time: 71.1676s / 1003.6818 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0320
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0333
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 631.95,                last time consumption/overall running time: 79.2195s / 1082.9014 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0297
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0316
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 544.4,                last time consumption/overall running time: 68.4596s / 1151.3610 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0300
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0329
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 569.85,                last time consumption/overall running time: 72.0807s / 1223.4417 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0302
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0345
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 547.75,                last time consumption/overall running time: 69.1609s / 1292.6026 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0334
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0333
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 610.0,                last time consumption/overall running time: 76.5148s / 1369.1174 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0309
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0341
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 570.3,                last time consumption/overall running time: 71.6233s / 1440.7406 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0305
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0340
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 579.0,                last time consumption/overall running time: 73.0063s / 1513.7470 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0304
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0345
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 541.2,                last time consumption/overall running time: 68.0114s / 1581.7583 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0334
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0309
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 568.35,                last time consumption/overall running time: 72.0604s / 1653.8188 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0326
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0301
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 602.65,                last time consumption/overall running time: 76.0721s / 1729.8909 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0308
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 566.0,                last time consumption/overall running time: 72.4427s / 1802.3336 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0323
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0334
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 595.05,                last time consumption/overall running time: 74.6946s / 1877.0282 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0319
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0310
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 560.4,                last time consumption/overall running time: 70.3259s / 1947.3541 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0314
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0336
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 556.45,                last time consumption/overall running time: 69.8623s / 2017.2164 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0299
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0345
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 570.4,                last time consumption/overall running time: 71.5183s / 2088.7347 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0290
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0337
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 542.85,                last time consumption/overall running time: 67.9058s / 2156.6405 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0300
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0331
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 603.1,                last time consumption/overall running time: 75.5951s / 2232.2356 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0324
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0304
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 581.0,                last time consumption/overall running time: 72.9721s / 2305.2077 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0314
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0324
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 572.75,                last time consumption/overall running time: 71.8520s / 2377.0597 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0300
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0323
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 542.2,                last time consumption/overall running time: 68.0595s / 2445.1192 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0290
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0309
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 579.75,                last time consumption/overall running time: 73.1849s / 2518.3041 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0314
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0313
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 563.4,                last time consumption/overall running time: 71.9443s / 2590.2484 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0300
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0311
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 560.1,                last time consumption/overall running time: 70.3218s / 2660.5702 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0327
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0323
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 585.25,                last time consumption/overall running time: 73.5994s / 2734.1696 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0321
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0317
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 591.55,                last time consumption/overall running time: 74.5508s / 2808.7203 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0298
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0312
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 581.35,                last time consumption/overall running time: 73.1520s / 2881.8724 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0298
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0296
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 572.1,                last time consumption/overall running time: 71.9621s / 2953.8345 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0318
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 599.65,                last time consumption/overall running time: 75.3471s / 3029.1816 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0304
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 593.4,                last time consumption/overall running time: 75.0480s / 3104.2296 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0295
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0306
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 573.35,                last time consumption/overall running time: 72.4809s / 3176.7105 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0297
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0321
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 603.55,                last time consumption/overall running time: 76.5255s / 3253.2361 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0308
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0324
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 584.25,                last time consumption/overall running time: 74.2079s / 3327.4440 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0306
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0317
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 557.45,                last time consumption/overall running time: 70.8223s / 3398.2663 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0288
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0320
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 540.5,                last time consumption/overall running time: 67.9706s / 3466.2369 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0315
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 583.7,                last time consumption/overall running time: 73.3412s / 3539.5781 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0267
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0298
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 571.3,                last time consumption/overall running time: 72.0030s / 3611.5811 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0282
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0318
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 548.9,                last time consumption/overall running time: 69.7748s / 3681.3560 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0269
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0343
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 545.2,                last time consumption/overall running time: 69.2655s / 3750.6214 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0282
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0348
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 583.45,                last time consumption/overall running time: 73.3756s / 3823.9971 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0307
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 550.4,                last time consumption/overall running time: 69.2540s / 3893.2510 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0327
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 530.4,                last time consumption/overall running time: 67.1264s / 3960.3774 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0264
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0330
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 599.5,                last time consumption/overall running time: 75.6806s / 4036.0580 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0287
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0307
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 547.65,                last time consumption/overall running time: 68.8603s / 4104.9183 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0318
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 579.15,                last time consumption/overall running time: 73.3490s / 4178.2673 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0288
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0297
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 576.6,                last time consumption/overall running time: 73.1665s / 4251.4339 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0279
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0293
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 580.5,                last time consumption/overall running time: 73.3004s / 4324.7343 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0281
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 565.05,                last time consumption/overall running time: 71.9752s / 4396.7095 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0282
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0270
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 551.85,                last time consumption/overall running time: 69.5533s / 4466.2628 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 556.6,                last time consumption/overall running time: 70.1340s / 4536.3967 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0276
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 570.05,                last time consumption/overall running time: 71.9798s / 4608.3766 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0291
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0258
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 591.75,                last time consumption/overall running time: 74.4377s / 4682.8143 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0293
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0289
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 564.4,                last time consumption/overall running time: 71.3137s / 4754.1280 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0289
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 535.0,                last time consumption/overall running time: 67.1836s / 4821.3116 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0292
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0276
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 571.6,                last time consumption/overall running time: 72.0162s / 4893.3278 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0287
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0297
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 573.1,                last time consumption/overall running time: 72.2924s / 4965.6202 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0278
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0293
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 577.55,                last time consumption/overall running time: 72.7791s / 5038.3993 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0300
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0295
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 557.6,                last time consumption/overall running time: 70.6597s / 5109.0590 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0314
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0284
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 535.45,                last time consumption/overall running time: 67.8187s / 5176.8777 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0289
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0315
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 560.55,                last time consumption/overall running time: 71.5960s / 5248.4737 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0284
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 564.45,                last time consumption/overall running time: 70.9900s / 5319.4636 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0299
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 576.45,                last time consumption/overall running time: 72.2182s / 5391.6818 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0272
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0296
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 524.8,                last time consumption/overall running time: 66.2029s / 5457.8847 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0307
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 543.35,                last time consumption/overall running time: 68.1886s / 5526.0733 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0275
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0298
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 565.05,                last time consumption/overall running time: 71.0198s / 5597.0931 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0272
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0301
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 597.2,                last time consumption/overall running time: 75.0382s / 5672.1313 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0276
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0291
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 565.4,                last time consumption/overall running time: 70.9842s / 5743.1156 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0300
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0310
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 581.35,                last time consumption/overall running time: 72.8962s / 5816.0118 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0289
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0297
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 548.7,                last time consumption/overall running time: 69.2755s / 5885.2873 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0279
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0290
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 572.15,                last time consumption/overall running time: 72.4414s / 5957.7286 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0263
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0273
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 552.8,                last time consumption/overall running time: 69.9866s / 6027.7153 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0294
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0272
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 559.45,                last time consumption/overall running time: 70.3476s / 6098.0629 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0275
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0280
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 553.8,                last time consumption/overall running time: 70.2078s / 6168.2707 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0288
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 550.45,                last time consumption/overall running time: 69.0519s / 6237.3226 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0283
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0275
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 573.6,                last time consumption/overall running time: 71.8893s / 6309.2119 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0306
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 565.75,                last time consumption/overall running time: 71.3051s / 6380.5170 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0282
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0291
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 596.25,                last time consumption/overall running time: 75.4684s / 6455.9855 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0301
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0285
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 564.5,                last time consumption/overall running time: 71.6047s / 6527.5901 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0297
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 552.75,                last time consumption/overall running time: 69.6055s / 6597.1956 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0288
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 591.6,                last time consumption/overall running time: 74.9906s / 6672.1862 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0293
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0299
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 578.55,                last time consumption/overall running time: 72.9509s / 6745.1370 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0287
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 596.5,                last time consumption/overall running time: 75.3768s / 6820.5138 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0297
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0305
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 530.8,                last time consumption/overall running time: 66.8154s / 6887.3293 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0306
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 590.95,                last time consumption/overall running time: 74.5232s / 6961.8525 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0292
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0316
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 522.0,                last time consumption/overall running time: 65.8068s / 7027.6593 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0303
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0304
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 599.25,                last time consumption/overall running time: 75.3381s / 7102.9974 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0281
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0298
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 583.6,                last time consumption/overall running time: 73.3237s / 7176.3211 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0305
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 578.0,                last time consumption/overall running time: 72.7830s / 7249.1040 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0284
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 552.75,                last time consumption/overall running time: 69.9165s / 7319.0205 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0299
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0313
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 569.3,                last time consumption/overall running time: 71.7576s / 7390.7781 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0295
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 578.05,                last time consumption/overall running time: 73.6151s / 7464.3932 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0307
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0289
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 553.9,                last time consumption/overall running time: 70.0110s / 7534.4042 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0292
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0301
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 572.65,                last time consumption/overall running time: 72.5371s / 7606.9414 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0289
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0295
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 579.2,                last time consumption/overall running time: 73.1860s / 7680.1273 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0269
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0279
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 557.05,                last time consumption/overall running time: 70.2774s / 7750.4047 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0274
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0282
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 610.15,                last time consumption/overall running time: 76.8835s / 7827.2881 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0288
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 547.3,                last time consumption/overall running time: 68.9067s / 7896.1948 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0278
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0285
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 567.85,                last time consumption/overall running time: 71.5064s / 7967.7013 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0308
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 554.55,                last time consumption/overall running time: 69.7794s / 8037.4807 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0300
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 580.1,                last time consumption/overall running time: 73.1429s / 8110.6236 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0268
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 585.35,                last time consumption/overall running time: 73.9418s / 8184.5654 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0268
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 563.05,                last time consumption/overall running time: 72.5831s / 8257.1485 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0283
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0293
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 540.6,                last time consumption/overall running time: 69.1106s / 8326.2591 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0289
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0290
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 564.3,                last time consumption/overall running time: 71.2143s / 8397.4734 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0300
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 573.5,                last time consumption/overall running time: 72.4599s / 8469.9334 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0282
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0279
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 554.95,                last time consumption/overall running time: 70.1918s / 8540.1252 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0299
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 552.35,                last time consumption/overall running time: 69.8539s / 8609.9791 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0291
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0295
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 554.1,                last time consumption/overall running time: 70.0571s / 8680.0362 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0303
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0286
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 614.9,                last time consumption/overall running time: 77.2929s / 8757.3291 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0273
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0299
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 601.85,                last time consumption/overall running time: 75.4243s / 8832.7534 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0291
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 552.9,                last time consumption/overall running time: 69.7883s / 8902.5417 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0283
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 588.45,                last time consumption/overall running time: 74.4707s / 8977.0124 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0274
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 557.0,                last time consumption/overall running time: 70.6110s / 9047.6233 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0282
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0312
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 578.2,                last time consumption/overall running time: 72.8295s / 9120.4529 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0262
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0300
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 574.0,                last time consumption/overall running time: 71.9603s / 9192.4132 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0251
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0286
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 564.65,                last time consumption/overall running time: 71.7525s / 9264.1657 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0284
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 550.8,                last time consumption/overall running time: 69.4454s / 9333.6110 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0253
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 581.45,                last time consumption/overall running time: 73.3517s / 9406.9627 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0293
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 569.6,                last time consumption/overall running time: 71.8973s / 9478.8601 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0270
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0279
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 592.4,                last time consumption/overall running time: 74.8463s / 9553.7063 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0268
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0270
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 561.5,                last time consumption/overall running time: 71.2832s / 9624.9895 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0274
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 601.05,                last time consumption/overall running time: 76.0497s / 9701.0392 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0279
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0266
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 598.25,                last time consumption/overall running time: 75.8694s / 9776.9086 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0281
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 592.75,                last time consumption/overall running time: 74.8347s / 9851.7433 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0278
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 570.1,                last time consumption/overall running time: 72.3186s / 9924.0619 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0277
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0275
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 583.15,                last time consumption/overall running time: 73.8245s / 9997.8864 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0278
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 530.55,                last time consumption/overall running time: 67.1500s / 10065.0364 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0269
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0287
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 573.8,                last time consumption/overall running time: 72.3339s / 10137.3703 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0267
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 575.0,                last time consumption/overall running time: 72.9105s / 10210.2808 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 617.45,                last time consumption/overall running time: 77.8724s / 10288.1532 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0282
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0294
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 608.55,                last time consumption/overall running time: 77.3855s / 10365.5387 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 568.65,                last time consumption/overall running time: 71.5173s / 10437.0560 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 588.55,                last time consumption/overall running time: 74.1599s / 10511.2159 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0266
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0280
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 593.95,                last time consumption/overall running time: 74.9437s / 10586.1596 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0280
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0291
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 598.4,                last time consumption/overall running time: 75.5762s / 10661.7358 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0280
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0298
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 570.85,                last time consumption/overall running time: 72.2024s / 10733.9383 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0283
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 567.05,                last time consumption/overall running time: 71.5343s / 10805.4726 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0296
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 544.05,                last time consumption/overall running time: 69.2998s / 10874.7725 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0279
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 611.85,                last time consumption/overall running time: 77.0008s / 10951.7733 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0291
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0284
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 564.45,                last time consumption/overall running time: 71.1738s / 11022.9470 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0300
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0294
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 545.8,                last time consumption/overall running time: 68.5332s / 11091.4803 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0277
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0271
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 556.5,                last time consumption/overall running time: 70.2518s / 11161.7320 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0287
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0301
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 598.85,                last time consumption/overall running time: 75.4408s / 11237.1728 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0298
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 586.3,                last time consumption/overall running time: 74.0726s / 11311.2454 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0267
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0300
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 550.5,                last time consumption/overall running time: 69.1955s / 11380.4409 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0274
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0296
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 568.95,                last time consumption/overall running time: 71.7629s / 11452.2038 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0270
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0304
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 563.5,                last time consumption/overall running time: 70.9446s / 11523.1483 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0279
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0301
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 587.5,                last time consumption/overall running time: 73.8489s / 11596.9972 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0291
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0301
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 593.35,                last time consumption/overall running time: 74.8584s / 11671.8557 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0295
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 553.9,                last time consumption/overall running time: 69.6021s / 11741.4577 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0293
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0298
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 570.15,                last time consumption/overall running time: 71.6997s / 11813.1574 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0279
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0296
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 549.85,                last time consumption/overall running time: 69.3161s / 11882.4735 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0285
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0303
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 582.5,                last time consumption/overall running time: 73.4710s / 11955.9445 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0265
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 575.75,                last time consumption/overall running time: 72.6872s / 12028.6317 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0283
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0269
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 602.85,                last time consumption/overall running time: 75.7813s / 12104.4130 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0290
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 586.4,                last time consumption/overall running time: 73.8695s / 12178.2825 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0274
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0280
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 598.25,                last time consumption/overall running time: 75.8160s / 12254.0984 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0279
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 539.55,                last time consumption/overall running time: 68.3091s / 12322.4075 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0265
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0272
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 581.15,                last time consumption/overall running time: 73.1806s / 12395.5881 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0268
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 590.3,                last time consumption/overall running time: 74.7675s / 12470.3556 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0285
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0282
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 566.2,                last time consumption/overall running time: 72.1543s / 12542.5099 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 580.25,                last time consumption/overall running time: 74.1386s / 12616.6485 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0270
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 543.4,                last time consumption/overall running time: 68.9738s / 12685.6223 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0267
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0286
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 575.05,                last time consumption/overall running time: 73.5491s / 12759.1713 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0292
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0283
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 594.85,                last time consumption/overall running time: 75.3755s / 12834.5468 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0303
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0303
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 571.75,                last time consumption/overall running time: 73.1387s / 12907.6855 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0284
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 569.55,                last time consumption/overall running time: 73.0037s / 12980.6893 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0299
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 586.85,                last time consumption/overall running time: 74.6907s / 13055.3800 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0276
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0281
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 560.85,                last time consumption/overall running time: 71.9437s / 13127.3236 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0290
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 569.65,                last time consumption/overall running time: 72.4335s / 13199.7572 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0281
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 577.45,                last time consumption/overall running time: 73.8787s / 13273.6358 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0295
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 524.05,                last time consumption/overall running time: 66.9145s / 13340.5504 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0291
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0311
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 599.85,                last time consumption/overall running time: 76.5094s / 13417.0597 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0285
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0300
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 581.1,                last time consumption/overall running time: 73.5596s / 13490.6193 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0291
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0282
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 547.7,                last time consumption/overall running time: 69.1127s / 13559.7320 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0292
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0281
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 604.85,                last time consumption/overall running time: 77.9579s / 13637.6899 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0288
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 585.7,                last time consumption/overall running time: 74.6230s / 13712.3128 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0282
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 559.0,                last time consumption/overall running time: 70.7003s / 13783.0131 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0278
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0298
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 547.75,                last time consumption/overall running time: 69.5736s / 13852.5867 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0292
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0306
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 560.85,                last time consumption/overall running time: 71.1560s / 13923.7427 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 558.95,                last time consumption/overall running time: 70.7716s / 13994.5143 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0299
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0297
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 583.8,                last time consumption/overall running time: 74.2131s / 14068.7274 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0280
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0306
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 598.75,                last time consumption/overall running time: 75.9128s / 14144.6402 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0296
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 583.05,                last time consumption/overall running time: 74.3464s / 14218.9866 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0282
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0297
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 604.35,                last time consumption/overall running time: 76.4201s / 14295.4067 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0281
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 531.0,                last time consumption/overall running time: 67.5832s / 14362.9899 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0290
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 552.8,                last time consumption/overall running time: 70.3652s / 14433.3551 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0280
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 562.7,                last time consumption/overall running time: 71.4773s / 14504.8324 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 597.4,                last time consumption/overall running time: 75.5829s / 14580.4153 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0280
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0266
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 584.15,                last time consumption/overall running time: 74.0049s / 14654.4202 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0281
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 563.4,                last time consumption/overall running time: 71.4505s / 14725.8707 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0289
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0286
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 593.35,                last time consumption/overall running time: 75.1798s / 14801.0505 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0273
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 589.5,                last time consumption/overall running time: 74.9193s / 14875.9698 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0280
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0271
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 553.15,                last time consumption/overall running time: 70.6299s / 14946.5997 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0263
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 558.05,                last time consumption/overall running time: 70.5810s / 15017.1807 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0272
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 545.7,                last time consumption/overall running time: 69.7534s / 15086.9341 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0281
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0287
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 588.9,                last time consumption/overall running time: 75.6022s / 15162.5362 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0281
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 559.85,                last time consumption/overall running time: 71.2897s / 15233.8259 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0273
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0282
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 581.6,                last time consumption/overall running time: 73.9503s / 15307.7762 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0270
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 551.15,                last time consumption/overall running time: 69.8468s / 15377.6231 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0273
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 551.05,                last time consumption/overall running time: 69.7212s / 15447.3442 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0285
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0272
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 549.0,                last time consumption/overall running time: 69.3172s / 15516.6614 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0286
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 583.35,                last time consumption/overall running time: 74.1055s / 15590.7669 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0276
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0282
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 530.8,                last time consumption/overall running time: 67.4378s / 15658.2047 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0296
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0294
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 604.1,                last time consumption/overall running time: 76.4893s / 15734.6940 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0289
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0293
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 598.7,                last time consumption/overall running time: 75.9363s / 15810.6303 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0291
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0275
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 587.2,                last time consumption/overall running time: 74.9079s / 15885.5382 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 567.45,                last time consumption/overall running time: 71.8045s / 15957.3427 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0294
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 590.9,                last time consumption/overall running time: 74.9879s / 16032.3306 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0296
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0289
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 546.1,                last time consumption/overall running time: 69.4045s / 16101.7352 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0277
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0273
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 528.95,                last time consumption/overall running time: 67.1081s / 16168.8432 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0285
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0297
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 552.25,                last time consumption/overall running time: 70.7247s / 16239.5679 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0300
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0293
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 614.0,                last time consumption/overall running time: 78.1616s / 16317.7295 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0293
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0284
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 581.55,                last time consumption/overall running time: 74.4317s / 16392.1613 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0305
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0277
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 572.5,                last time consumption/overall running time: 73.0071s / 16465.1684 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0286
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 550.05,                last time consumption/overall running time: 69.8676s / 16535.0360 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0310
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0290
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 566.5,                last time consumption/overall running time: 72.7894s / 16607.8253 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0295
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 566.9,                last time consumption/overall running time: 72.1667s / 16679.9920 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0292
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0259
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 577.35,                last time consumption/overall running time: 73.0198s / 16753.0119 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0297
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 583.5,                last time consumption/overall running time: 74.5146s / 16827.5265 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0289
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 570.55,                last time consumption/overall running time: 72.5059s / 16900.0324 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0289
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 568.95,                last time consumption/overall running time: 72.4352s / 16972.4676 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0294
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0280
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 571.9,                last time consumption/overall running time: 72.2563s / 17044.7238 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0295
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0283
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 588.5,                last time consumption/overall running time: 74.9000s / 17119.6239 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0297
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0277
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 561.3,                last time consumption/overall running time: 71.2290s / 17190.8528 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0293
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0279
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 547.7,                last time consumption/overall running time: 69.3548s / 17260.2076 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0269
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 556.8,                last time consumption/overall running time: 70.5720s / 17330.7796 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0287
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 584.8,                last time consumption/overall running time: 74.4428s / 17405.2225 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0286
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0279
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 629.8,                last time consumption/overall running time: 79.7119s / 17484.9344 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0280
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0278
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 627.2,                last time consumption/overall running time: 79.4711s / 17564.4056 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0291
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0277
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 530.5,                last time consumption/overall running time: 67.6472s / 17632.0528 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0264
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 601.05,                last time consumption/overall running time: 76.0917s / 17708.1445 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0270
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0272
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 546.95,                last time consumption/overall running time: 69.4245s / 17777.5690 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0257
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 595.1,                last time consumption/overall running time: 75.4861s / 17853.0551 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0277
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 593.85,                last time consumption/overall running time: 75.3142s / 17928.3693 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0276
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 568.9,                last time consumption/overall running time: 71.9880s / 18000.3573 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0263
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0287
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 561.55,                last time consumption/overall running time: 70.7862s / 18071.1435 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0272
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0286
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 558.0,                last time consumption/overall running time: 70.4197s / 18141.5633 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0296
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0271
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 517.6,                last time consumption/overall running time: 65.6887s / 18207.2520 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0281
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0282
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 550.4,                last time consumption/overall running time: 70.0566s / 18277.3087 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0287
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0284
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 549.0,                last time consumption/overall running time: 69.9338s / 18347.2425 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0279
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 573.2,                last time consumption/overall running time: 72.8006s / 18420.0431 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 597.05,                last time consumption/overall running time: 75.5523s / 18495.5954 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0295
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 599.85,                last time consumption/overall running time: 76.0866s / 18571.6820 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0282
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0280
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 604.4,                last time consumption/overall running time: 76.5459s / 18648.2279 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0281
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0294
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 562.4,                last time consumption/overall running time: 71.3886s / 18719.6165 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0288
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0282
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 570.5,                last time consumption/overall running time: 72.6354s / 18792.2520 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0281
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0291
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 586.3,                last time consumption/overall running time: 74.7688s / 18867.0208 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 621.3,                last time consumption/overall running time: 78.6747s / 18945.6955 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0292
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 557.45,                last time consumption/overall running time: 70.9701s / 19016.6655 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0297
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 555.4,                last time consumption/overall running time: 70.6852s / 19087.3508 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0297
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 594.9,                last time consumption/overall running time: 75.5813s / 19162.9320 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0266
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0281
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 598.25,                last time consumption/overall running time: 76.1448s / 19239.0769 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0256
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 572.2,                last time consumption/overall running time: 72.7747s / 19311.8515 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0262
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0273
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 591.1,                last time consumption/overall running time: 74.7047s / 19386.5563 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0287
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 540.6,                last time consumption/overall running time: 68.8750s / 19455.4313 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0280
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0294
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 540.8,                last time consumption/overall running time: 68.6969s / 19524.1282 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0264
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0287
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 549.05,                last time consumption/overall running time: 69.6850s / 19593.8132 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0273
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0272
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 572.2,                last time consumption/overall running time: 72.3633s / 19666.1766 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0276
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 559.0,                last time consumption/overall running time: 71.0148s / 19737.1913 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0273
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 559.25,                last time consumption/overall running time: 70.4151s / 19807.6064 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0274
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0279
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 557.2,                last time consumption/overall running time: 70.8220s / 19878.4284 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0275
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 569.2,                last time consumption/overall running time: 72.3123s / 19950.7407 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0281
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0296
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 546.75,                last time consumption/overall running time: 69.6700s / 20020.4107 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0289
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 573.55,                last time consumption/overall running time: 73.1640s / 20093.5747 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 551.45,                last time consumption/overall running time: 70.5261s / 20164.1009 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0275
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0274
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 585.2,                last time consumption/overall running time: 75.0308s / 20239.1317 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0285
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0265
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 596.65,                last time consumption/overall running time: 75.6641s / 20314.7958 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0278
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 568.85,                last time consumption/overall running time: 72.0891s / 20386.8849 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0276
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0268
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 579.05,                last time consumption/overall running time: 73.8302s / 20460.7151 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0287
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0259
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 567.0,                last time consumption/overall running time: 72.8456s / 20533.5607 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 572.65,                last time consumption/overall running time: 72.4384s / 20605.9992 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0273
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 556.75,                last time consumption/overall running time: 70.4283s / 20676.4275 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0288
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0284
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 542.6,                last time consumption/overall running time: 68.8779s / 20745.3054 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0273
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0270
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 577.5,                last time consumption/overall running time: 74.1273s / 20819.4327 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0293
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0267
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 577.75,                last time consumption/overall running time: 73.6971s / 20893.1299 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0289
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0267
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 606.55,                last time consumption/overall running time: 76.9239s / 20970.0538 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0286
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 589.15,                last time consumption/overall running time: 74.7846s / 21044.8384 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0284
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 599.05,                last time consumption/overall running time: 76.4508s / 21121.2891 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0284
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0294
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 584.5,                last time consumption/overall running time: 74.3287s / 21195.6178 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0265
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0268
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 594.75,                last time consumption/overall running time: 75.7215s / 21271.3393 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0284
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 583.05,                last time consumption/overall running time: 74.4222s / 21345.7615 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0291
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 554.45,                last time consumption/overall running time: 70.4490s / 21416.2105 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0258
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0296
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 592.55,                last time consumption/overall running time: 75.5756s / 21491.7861 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0274
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 587.85,                last time consumption/overall running time: 74.8517s / 21566.6378 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0254
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0287
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 545.85,                last time consumption/overall running time: 69.8694s / 21636.5071 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0264
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0299
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 595.45,                last time consumption/overall running time: 76.4017s / 21712.9088 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0268
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0299
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 570.4,                last time consumption/overall running time: 72.4634s / 21785.3722 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0270
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0294
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 575.45,                last time consumption/overall running time: 73.3841s / 21858.7564 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0274
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0286
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 589.7,                last time consumption/overall running time: 75.3113s / 21934.0676 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0300
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 572.1,                last time consumption/overall running time: 72.8760s / 22006.9436 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0265
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0295
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 574.85,                last time consumption/overall running time: 73.5529s / 22080.4966 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0283
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0286
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 534.25,                last time consumption/overall running time: 67.9071s / 22148.4037 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0293
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0283
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 581.05,                last time consumption/overall running time: 74.4405s / 22222.8442 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0277
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0288
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 547.4,                last time consumption/overall running time: 70.0311s / 22292.8753 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0289
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 577.4,                last time consumption/overall running time: 74.0015s / 22366.8768 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0270
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0283
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 601.35,                last time consumption/overall running time: 76.5074s / 22443.3842 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0293
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0296
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 581.1,                last time consumption/overall running time: 74.1598s / 22517.5440 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0297
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0271
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 588.85,                last time consumption/overall running time: 74.7781s / 22592.3220 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0285
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0271
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 545.0,                last time consumption/overall running time: 68.7159s / 22661.0379 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0281
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0276
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 558.3,                last time consumption/overall running time: 71.3717s / 22732.4096 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0285
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0276
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 586.95,                last time consumption/overall running time: 74.4065s / 22806.8161 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0275
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 551.6,                last time consumption/overall running time: 69.9243s / 22876.7404 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0295
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0259
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 595.7,                last time consumption/overall running time: 75.8143s / 22952.5547 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0293
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0264
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 560.45,                last time consumption/overall running time: 71.4325s / 23023.9872 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 597.25,                last time consumption/overall running time: 75.4618s / 23099.4491 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0283
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0269
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 555.65,                last time consumption/overall running time: 70.3760s / 23169.8250 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0266
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 570.5,                last time consumption/overall running time: 72.0923s / 23241.9173 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0278
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 570.25,                last time consumption/overall running time: 73.0699s / 23314.9872 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0289
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0279
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 570.0,                last time consumption/overall running time: 73.2483s / 23388.2355 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0293
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 592.65,                last time consumption/overall running time: 75.5345s / 23463.7699 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0285
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 572.65,                last time consumption/overall running time: 72.8301s / 23536.6000 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0278
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0281
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 579.35,                last time consumption/overall running time: 73.2685s / 23609.8686 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0274
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 595.25,                last time consumption/overall running time: 75.2072s / 23685.0757 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0295
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 566.65,                last time consumption/overall running time: 71.5680s / 23756.6437 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 545.75,                last time consumption/overall running time: 69.3452s / 23825.9889 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0269
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0277
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 596.7,                last time consumption/overall running time: 75.4583s / 23901.4472 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0269
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 576.5,                last time consumption/overall running time: 73.0950s / 23974.5422 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0286
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0268
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 585.8,                last time consumption/overall running time: 73.9866s / 24048.5287 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0275
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 584.95,                last time consumption/overall running time: 74.5711s / 24123.0998 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0262
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 541.4,                last time consumption/overall running time: 68.2668s / 24191.3666 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0278
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 586.3,                last time consumption/overall running time: 74.3882s / 24265.7548 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0265
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0273
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 555.55,                last time consumption/overall running time: 70.4117s / 24336.1665 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0263
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0276
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 619.85,                last time consumption/overall running time: 78.6766s / 24414.8431 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 587.45,                last time consumption/overall running time: 74.5069s / 24489.3500 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0293
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 609.85,                last time consumption/overall running time: 77.4468s / 24566.7968 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0260
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0282
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 543.65,                last time consumption/overall running time: 68.5689s / 24635.3656 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0267
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0283
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 581.9,                last time consumption/overall running time: 73.6969s / 24709.0625 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0277
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0268
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 600.5,                last time consumption/overall running time: 76.5910s / 24785.6535 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0256
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0281
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 577.05,                last time consumption/overall running time: 73.2051s / 24858.8586 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0265
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 580.3,                last time consumption/overall running time: 73.6496s / 24932.5082 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0274
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0285
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 567.95,                last time consumption/overall running time: 72.2433s / 25004.7515 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0262
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0265
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 602.5,                last time consumption/overall running time: 76.9565s / 25081.7080 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0268
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0267
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 571.85,                last time consumption/overall running time: 73.0138s / 25154.7217 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 575.85,                last time consumption/overall running time: 73.2158s / 25227.9376 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0258
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0265
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 571.95,                last time consumption/overall running time: 73.1339s / 25301.0715 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0287
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0263
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 566.95,                last time consumption/overall running time: 72.0167s / 25373.0881 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0270
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 577.4,                last time consumption/overall running time: 73.2988s / 25446.3869 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0291
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0275
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 582.25,                last time consumption/overall running time: 74.1929s / 25520.5798 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0268
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 592.5,                last time consumption/overall running time: 75.0379s / 25595.6177 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0269
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 630.75,                last time consumption/overall running time: 80.2647s / 25675.8824 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0289
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0269
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 609.35,                last time consumption/overall running time: 77.7410s / 25753.6235 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0262
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 609.0,                last time consumption/overall running time: 77.4237s / 25831.0471 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0269
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0263
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 549.95,                last time consumption/overall running time: 69.7180s / 25900.7651 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0268
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 569.7,                last time consumption/overall running time: 72.7473s / 25973.5124 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0275
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0263
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 598.9,                last time consumption/overall running time: 76.3377s / 26049.8501 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0254
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0254
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 557.8,                last time consumption/overall running time: 70.8312s / 26120.6813 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0275
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0248
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 568.3,                last time consumption/overall running time: 72.0268s / 26192.7081 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0276
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0259
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 563.7,                last time consumption/overall running time: 71.2256s / 26263.9338 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0277
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0258
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 575.5,                last time consumption/overall running time: 73.5033s / 26337.4371 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0268
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 589.25,                last time consumption/overall running time: 74.7575s / 26412.1946 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0254
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0266
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 631.4,                last time consumption/overall running time: 80.4485s / 26492.6431 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 545.7,                last time consumption/overall running time: 69.4980s / 26562.1411 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0265
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0267
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 552.0,                last time consumption/overall running time: 70.2321s / 26632.3732 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0271
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0282
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 572.6,                last time consumption/overall running time: 72.5121s / 26704.8853 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0262
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0278
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 566.7,                last time consumption/overall running time: 72.0937s / 26776.9789 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0251
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0268
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 562.05,                last time consumption/overall running time: 71.5089s / 26848.4878 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 583.4,                last time consumption/overall running time: 74.1021s / 26922.5899 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0250
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0287
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 561.0,                last time consumption/overall running time: 70.9344s / 26993.5243 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0251
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0280
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 537.8,                last time consumption/overall running time: 67.8700s / 27061.3944 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0259
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 568.75,                last time consumption/overall running time: 72.4490s / 27133.8433 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0276
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 555.5,                last time consumption/overall running time: 70.2376s / 27204.0809 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0284
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0279
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 592.4,                last time consumption/overall running time: 75.3551s / 27279.4360 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0297
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0282
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 573.75,                last time consumption/overall running time: 72.5981s / 27352.0342 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0288
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0284
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 597.6,                last time consumption/overall running time: 75.4868s / 27427.5209 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0304
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 559.1,                last time consumption/overall running time: 70.9774s / 27498.4983 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0270
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0281
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 586.45,                last time consumption/overall running time: 75.0314s / 27573.5297 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0285
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0290
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 570.25,                last time consumption/overall running time: 72.7287s / 27646.2584 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0272
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0269
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 574.6,                last time consumption/overall running time: 72.5884s / 27718.8467 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 583.95,                last time consumption/overall running time: 74.3114s / 27793.1581 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0301
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0274
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 580.9,                last time consumption/overall running time: 73.8895s / 27867.0476 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0288
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0282
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 564.8,                last time consumption/overall running time: 71.7231s / 27938.7706 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0270
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0280
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 570.55,                last time consumption/overall running time: 72.6802s / 28011.4509 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0288
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 580.7,                last time consumption/overall running time: 73.7241s / 28085.1750 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0271
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0289
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 586.6,                last time consumption/overall running time: 74.2423s / 28159.4172 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0293
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 582.85,                last time consumption/overall running time: 74.4836s / 28233.9008 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0272
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0257
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 566.45,                last time consumption/overall running time: 72.2121s / 28306.1129 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0263
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0284
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 608.65,                last time consumption/overall running time: 77.6881s / 28383.8010 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0277
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0293
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 598.9,                last time consumption/overall running time: 76.6778s / 28460.4787 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0260
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0267
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 594.15,                last time consumption/overall running time: 75.2403s / 28535.7191 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0270
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0266
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 602.35,                last time consumption/overall running time: 76.5335s / 28612.2526 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0261
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0275
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 569.2,                last time consumption/overall running time: 71.9550s / 28684.2076 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0258
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0257
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 575.6,                last time consumption/overall running time: 73.3639s / 28757.5715 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0246
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0262
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 577.85,                last time consumption/overall running time: 73.3676s / 28830.9390 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0267
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0260
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 617.05,                last time consumption/overall running time: 78.5738s / 28909.5129 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0268
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0268
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 556.15,                last time consumption/overall running time: 71.1308s / 28980.6437 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0271
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0268
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 576.15,                last time consumption/overall running time: 73.0909s / 29053.7346 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0270
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0268
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 583.75,                last time consumption/overall running time: 74.1297s / 29127.8643 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0282
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0275
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 557.5,                last time consumption/overall running time: 70.8815s / 29198.7457 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0272
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0268
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 581.9,                last time consumption/overall running time: 73.8495s / 29272.5953 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0281
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 581.15,                last time consumption/overall running time: 73.7666s / 29346.3618 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0285
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0286
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 567.75,                last time consumption/overall running time: 72.3516s / 29418.7134 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0279
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 580.25,                last time consumption/overall running time: 73.6625s / 29492.3759 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0298
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0288
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 575.85,                last time consumption/overall running time: 73.5540s / 29565.9299 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0279
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0287
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 590.0,                last time consumption/overall running time: 75.5648s / 29641.4946 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0282
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0289
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 562.45,                last time consumption/overall running time: 71.5074s / 29713.0021 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0280
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0276
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 576.2,                last time consumption/overall running time: 73.4574s / 29786.4595 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0274
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 574.95,                last time consumption/overall running time: 72.6389s / 29859.0984 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0279
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0263
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 606.7,                last time consumption/overall running time: 76.9939s / 29936.0923 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0259
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 575.4,                last time consumption/overall running time: 73.1214s / 30009.2137 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0284
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 585.15,                last time consumption/overall running time: 74.3622s / 30083.5759 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0275
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0273
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 561.55,                last time consumption/overall running time: 87.1739s / 30170.7498 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0292
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 558.85,                last time consumption/overall running time: 71.5652s / 30242.3150 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0276
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 572.75,                last time consumption/overall running time: 73.0508s / 30315.3658 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0284
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0276
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 554.35,                last time consumption/overall running time: 70.8580s / 30386.2239 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0263
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 611.05,                last time consumption/overall running time: 77.7604s / 30463.9843 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0267
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 622.3,                last time consumption/overall running time: 78.8611s / 30542.8453 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0278
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0274
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 605.4,                last time consumption/overall running time: 76.6398s / 30619.4851 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0264
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0294
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 618.55,                last time consumption/overall running time: 78.9147s / 30698.3998 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0289
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0280
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 606.65,                last time consumption/overall running time: 77.4171s / 30775.8169 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0283
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 567.7,                last time consumption/overall running time: 72.4109s / 30848.2278 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0276
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 580.6,                last time consumption/overall running time: 74.0080s / 30922.2358 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0275
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0296
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 560.5,                last time consumption/overall running time: 70.9569s / 30993.1927 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0289
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0276
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 617.55,                last time consumption/overall running time: 78.3160s / 31071.5087 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0291
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0271
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 567.35,                last time consumption/overall running time: 72.2894s / 31143.7980 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0262
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 582.45,                last time consumption/overall running time: 73.9361s / 31217.7341 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0275
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0263
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 611.4,                last time consumption/overall running time: 77.8999s / 31295.6341 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0265
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0269
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 524.75,                last time consumption/overall running time: 67.0342s / 31362.6682 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0260
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0271
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 572.7,                last time consumption/overall running time: 73.3358s / 31436.0041 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0274
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0288
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 564.4,                last time consumption/overall running time: 72.2114s / 31508.2154 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0269
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 587.6,                last time consumption/overall running time: 74.7448s / 31582.9602 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0267
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 624.0,                last time consumption/overall running time: 79.1659s / 31662.1261 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0266
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 536.65,                last time consumption/overall running time: 68.0113s / 31730.1374 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0275
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0292
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 587.7,                last time consumption/overall running time: 74.6545s / 31804.7920 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0270
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0281
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 561.05,                last time consumption/overall running time: 71.2838s / 31876.0757 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0257
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 601.65,                last time consumption/overall running time: 76.5500s / 31952.6257 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0256
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 585.2,                last time consumption/overall running time: 74.7165s / 32027.3422 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0268
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0270
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 566.7,                last time consumption/overall running time: 72.4476s / 32099.7898 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0273
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 576.95,                last time consumption/overall running time: 73.1931s / 32172.9828 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0284
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 608.0,                last time consumption/overall running time: 77.3563s / 32250.3392 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0269
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0285
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 559.0,                last time consumption/overall running time: 70.7952s / 32321.1344 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0277
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 623.6,                last time consumption/overall running time: 79.3326s / 32400.4670 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0266
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 615.45,                last time consumption/overall running time: 78.4710s / 32478.9380 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0291
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 553.3,                last time consumption/overall running time: 70.5034s / 32549.4414 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0265
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0267
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 549.1,                last time consumption/overall running time: 69.9100s / 32619.3513 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0268
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0278
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 622.6,                last time consumption/overall running time: 79.7671s / 32699.1184 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0265
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0275
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 582.85,                last time consumption/overall running time: 74.1558s / 32773.2742 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0273
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0289
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 593.7,                last time consumption/overall running time: 75.5357s / 32848.8099 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0268
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0273
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 559.2,                last time consumption/overall running time: 70.9202s / 32919.7301 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 580.4,                last time consumption/overall running time: 74.1996s / 32993.9297 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0256
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0279
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 590.15,                last time consumption/overall running time: 75.1347s / 33069.0644 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0278
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 565.1,                last time consumption/overall running time: 71.6667s / 33140.7311 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0275
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0266
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 596.95,                last time consumption/overall running time: 76.1225s / 33216.8535 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0268
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 595.55,                last time consumption/overall running time: 76.0064s / 33292.8600 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0284
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 552.4,                last time consumption/overall running time: 70.0804s / 33362.9404 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0280
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 587.75,                last time consumption/overall running time: 74.7623s / 33437.7027 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0285
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0275
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 616.05,                last time consumption/overall running time: 78.3132s / 33516.0159 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0296
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0266
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 604.7,                last time consumption/overall running time: 76.7931s / 33592.8091 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0288
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0266
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 574.7,                last time consumption/overall running time: 72.8099s / 33665.6190 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0286
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0279
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 609.55,                last time consumption/overall running time: 77.7713s / 33743.3903 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0289
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0280
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 601.1,                last time consumption/overall running time: 76.1136s / 33819.5039 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0291
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0265
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 620.75,                last time consumption/overall running time: 79.1317s / 33898.6357 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0294
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0271
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 612.6,                last time consumption/overall running time: 77.9939s / 33976.6296 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0280
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0266
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 621.35,                last time consumption/overall running time: 79.1681s / 34055.7977 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0275
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 574.25,                last time consumption/overall running time: 72.4417s / 34128.2394 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0268
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 550.0,                last time consumption/overall running time: 69.6071s / 34197.8465 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0294
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0257
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 575.15,                last time consumption/overall running time: 73.3924s / 34271.2389 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0274
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 605.8,                last time consumption/overall running time: 77.2293s / 34348.4682 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0282
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 590.55,                last time consumption/overall running time: 74.8847s / 34423.3529 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0280
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0271
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 571.1,                last time consumption/overall running time: 72.3426s / 34495.6956 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0293
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0257
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 578.4,                last time consumption/overall running time: 73.3861s / 34569.0817 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0275
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 587.05,                last time consumption/overall running time: 74.6807s / 34643.7624 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0264
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 561.85,                last time consumption/overall running time: 71.4281s / 34715.1905 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0259
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 577.5,                last time consumption/overall running time: 73.4328s / 34788.6233 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0261
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 600.25,                last time consumption/overall running time: 76.9941s / 34865.6174 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0271
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0266
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 567.4,                last time consumption/overall running time: 72.1558s / 34937.7731 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0268
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0271
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 575.0,                last time consumption/overall running time: 73.1908s / 35010.9640 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0267
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0277
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 541.55,                last time consumption/overall running time: 68.6680s / 35079.6320 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0272
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0276
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 553.3,                last time consumption/overall running time: 70.2174s / 35149.8494 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0259
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0270
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 602.55,                last time consumption/overall running time: 76.6902s / 35226.5396 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0265
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0286
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 608.4,                last time consumption/overall running time: 77.3971s / 35303.9368 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0263
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0266
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 566.7,                last time consumption/overall running time: 71.3983s / 35375.3351 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0269
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 583.75,                last time consumption/overall running time: 73.7254s / 35449.0604 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0278
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0285
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 565.55,                last time consumption/overall running time: 71.6835s / 35520.7439 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0267
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0279
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 559.55,                last time consumption/overall running time: 70.8356s / 35591.5796 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0269
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0277
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 625.7,                last time consumption/overall running time: 79.3258s / 35670.9053 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0257
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0269
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 567.95,                last time consumption/overall running time: 71.8142s / 35742.7196 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0264
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0264
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 575.5,                last time consumption/overall running time: 72.7631s / 35815.4826 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0268
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0275
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 585.35,                last time consumption/overall running time: 74.2673s / 35889.7499 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0256Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_second_0:                 episode reward: 0.5500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 582.25,                last time consumption/overall running time: 73.7978s / 35963.5477 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0258
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0269
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 582.1,                last time consumption/overall running time: 73.5404s / 36037.0880 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0249
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0258
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 587.35,                last time consumption/overall running time: 74.2411s / 36111.3292 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0260
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0267
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 595.15,                last time consumption/overall running time: 75.4767s / 36186.8059 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0256
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 621.5,                last time consumption/overall running time: 78.3754s / 36265.1813 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0257
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
