pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f996d425cf8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 0.6817 s
agent0:                 episode reward: -0.0866,                 loss: nan
agent1:                 episode reward: 0.0866,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 0.8816 s
agent0:                 episode reward: -0.4026,                 loss: nan
agent1:                 episode reward: 0.4026,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 1.0803 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 1.2796 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 1.4754 s
agent0:                 episode reward: -0.4707,                 loss: nan
agent1:                 episode reward: 0.4707,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 1.6754 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.8734 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 2.0698 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 2.2669 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 2.4646 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 2.6623 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 2.8578 s
agent0:                 episode reward: -0.7238,                 loss: nan
agent1:                 episode reward: 0.7238,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 3.0598 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 3.2595 s
agent0:                 episode reward: -0.0203,                 loss: nan
agent1:                 episode reward: 0.0203,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 3.4603 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 3.6587 s
agent0:                 episode reward: -0.4983,                 loss: nan
agent1:                 episode reward: 0.4983,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 3.8579 s
agent0:                 episode reward: -0.2133,                 loss: nan
agent1:                 episode reward: 0.2133,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 4.0604 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 4.2594 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 4.4583 s
agent0:                 episode reward: -0.2648,                 loss: nan
agent1:                 episode reward: 0.2648,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 4.6570 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 4.8600 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 5.0580 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 5.2560 s
agent0:                 episode reward: -0.4738,                 loss: nan
agent1:                 episode reward: 0.4738,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 5.4488 s
agent0:                 episode reward: -0.2774,                 loss: nan
agent1:                 episode reward: 0.2774,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 5.6494 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 5.8464 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 6.0459 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 6.2492 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 6.4512 s
agent0:                 episode reward: -0.8324,                 loss: nan
agent1:                 episode reward: 0.8324,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.6511 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 6.8463 s
agent0:                 episode reward: -0.3891,                 loss: nan
agent1:                 episode reward: 0.3891,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 7.0426 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 7.2439 s
agent0:                 episode reward: -0.2259,                 loss: nan
agent1:                 episode reward: 0.2259,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 7.4404 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 7.6425 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 7.8410 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 8.0339 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 8.2270 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 8.4286 s
agent0:                 episode reward: -0.4379,                 loss: nan
agent1:                 episode reward: 0.4379,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 8.6301 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 8.8284 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 9.0330 s
agent0:                 episode reward: -0.3853,                 loss: nan
agent1:                 episode reward: 0.3853,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 9.2315 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 9.4291 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 9.6246 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 9.8230 s
agent0:                 episode reward: -0.8278,                 loss: nan
agent1:                 episode reward: 0.8278,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 10.0145 s
agent0:                 episode reward: -0.5499,                 loss: nan
agent1:                 episode reward: 0.5499,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 10.2166 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 10.4171 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.6140 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.8109 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 11.0079 s
agent0:                 episode reward: -0.3202,                 loss: nan
agent1:                 episode reward: 0.3202,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 11.2060 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 11.4182 s
agent0:                 episode reward: -0.1130,                 loss: nan
agent1:                 episode reward: 0.1130,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 11.6218 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 11.8192 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 12.0206 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 12.2191 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 12.4176 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 12.6130 s
agent0:                 episode reward: -0.5939,                 loss: nan
agent1:                 episode reward: 0.5939,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 12.8107 s
agent0:                 episode reward: -0.1059,                 loss: nan
agent1:                 episode reward: 0.1059,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 13.0096 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 13.2049 s
agent0:                 episode reward: -0.0603,                 loss: nan
agent1:                 episode reward: 0.0603,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 13.4086 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 13.6059 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 13.8036 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 13.9998 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 14.1964 s
agent0:                 episode reward: -0.4480,                 loss: nan
agent1:                 episode reward: 0.4480,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 14.3951 s
agent0:                 episode reward: -0.2427,                 loss: nan
agent1:                 episode reward: 0.2427,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 14.5975 s
agent0:                 episode reward: -0.1579,                 loss: nan
agent1:                 episode reward: 0.1579,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 14.7955 s
agent0:                 episode reward: 0.0453,                 loss: nan
agent1:                 episode reward: -0.0453,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 14.9894 s
agent0:                 episode reward: -0.2473,                 loss: nan
agent1:                 episode reward: 0.2473,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 15.1876 s
agent0:                 episode reward: -0.6953,                 loss: nan
agent1:                 episode reward: 0.6953,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 15.3883 s
agent0:                 episode reward: -0.2237,                 loss: nan
agent1:                 episode reward: 0.2237,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 15.5854 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 15.7835 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 15.9832 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 16.1833 s
agent0:                 episode reward: -0.2881,                 loss: nan
agent1:                 episode reward: 0.2881,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 16.3855 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 16.5828 s
agent0:                 episode reward: -0.5301,                 loss: nan
agent1:                 episode reward: 0.5301,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 16.7790 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 16.9807 s
agent0:                 episode reward: -0.5575,                 loss: nan
agent1:                 episode reward: 0.5575,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 17.1760 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 17.3779 s
agent0:                 episode reward: -0.1830,                 loss: nan
agent1:                 episode reward: 0.1830,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 17.5765 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 17.7740 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.9735 s
agent0:                 episode reward: -0.4232,                 loss: nan
agent1:                 episode reward: 0.4232,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 18.1678 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 18.3660 s
agent0:                 episode reward: -0.7960,                 loss: nan
agent1:                 episode reward: 0.7960,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 18.5670 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 18.7675 s
agent0:                 episode reward: -0.0464,                 loss: nan
agent1:                 episode reward: 0.0464,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 18.9653 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 19.1645 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 19.3672 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 19.5666 s
agent0:                 episode reward: -0.1623,                 loss: nan
agent1:                 episode reward: 0.1623,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.7662 s
agent0:                 episode reward: -0.6035,                 loss: nan
agent1:                 episode reward: 0.6035,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 19.9599 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 20.1596 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 20.3561 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 20.5509 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2053s / 20.7562 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 20.9551 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 21.1529 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 21.3543 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 21.5540 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 21.7527 s
agent0:                 episode reward: -0.1008,                 loss: nan
agent1:                 episode reward: 0.1008,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 21.9532 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 22.1514 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 22.3485 s
agent0:                 episode reward: -0.0690,                 loss: nan
agent1:                 episode reward: 0.0690,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 22.5455 s
agent0:                 episode reward: -0.6205,                 loss: nan
agent1:                 episode reward: 0.6205,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 22.7425 s
agent0:                 episode reward: -0.5356,                 loss: nan
agent1:                 episode reward: 0.5356,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 22.9431 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 23.1368 s
agent0:                 episode reward: -0.5673,                 loss: nan
agent1:                 episode reward: 0.5673,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 23.3331 s
agent0:                 episode reward: -0.9062,                 loss: nan
agent1:                 episode reward: 0.9062,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 23.5270 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.7248 s
agent0:                 episode reward: -0.3925,                 loss: nan
agent1:                 episode reward: 0.3925,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 23.9212 s
agent0:                 episode reward: -0.2886,                 loss: nan
agent1:                 episode reward: 0.2886,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 24.1162 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 24.3127 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 24.5107 s
agent0:                 episode reward: -0.5130,                 loss: nan
agent1:                 episode reward: 0.5130,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 24.7084 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 24.9100 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 25.1066 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 25.3033 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 25.5047 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 25.7002 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 25.8971 s
agent0:                 episode reward: -0.7379,                 loss: nan
agent1:                 episode reward: 0.7379,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 26.0980 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 26.2997 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 26.4991 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 26.6966 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 26.8937 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 27.0700 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 27.2649 s
agent0:                 episode reward: -0.3254,                 loss: nan
agent1:                 episode reward: 0.3254,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 27.4621 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 27.6613 s
agent0:                 episode reward: -0.1501,                 loss: nan
agent1:                 episode reward: 0.1501,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 27.8549 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2344s / 28.0893 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 28.2887 s
agent0:                 episode reward: -0.4924,                 loss: nan
agent1:                 episode reward: 0.4924,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 28.4880 s
agent0:                 episode reward: -0.5483,                 loss: nan
agent1:                 episode reward: 0.5483,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 28.6860 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 28.8897 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 29.0884 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 29.2928 s
agent0:                 episode reward: -0.2771,                 loss: nan
agent1:                 episode reward: 0.2771,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 29.4902 s
agent0:                 episode reward: -0.1496,                 loss: nan
agent1:                 episode reward: 0.1496,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 29.6859 s
agent0:                 episode reward: -0.4534,                 loss: nan
agent1:                 episode reward: 0.4534,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 29.8827 s
agent0:                 episode reward: -0.4170,                 loss: nan
agent1:                 episode reward: 0.4170,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 30.0764 s
agent0:                 episode reward: -0.3516,                 loss: nan
agent1:                 episode reward: 0.3516,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 30.2754 s
agent0:                 episode reward: -0.3621,                 loss: nan
agent1:                 episode reward: 0.3621,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 30.4749 s
agent0:                 episode reward: 0.0528,                 loss: nan
agent1:                 episode reward: -0.0528,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 30.6779 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 30.8767 s
agent0:                 episode reward: -0.0282,                 loss: nan
agent1:                 episode reward: 0.0282,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 31.0768 s
agent0:                 episode reward: -0.1118,                 loss: nan
agent1:                 episode reward: 0.1118,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 31.2769 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 31.4788 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 31.6760 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 31.8757 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.0744 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 32.2737 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 32.4732 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 32.6708 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 32.8605 s
agent0:                 episode reward: -0.3432,                 loss: nan
agent1:                 episode reward: 0.3432,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 33.0537 s
agent0:                 episode reward: -0.3137,                 loss: nan
agent1:                 episode reward: 0.3137,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 33.2423 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 33.4332 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 33.6286 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 33.9824 s
agent0:                 episode reward: -0.6387,                 loss: nan
agent1:                 episode reward: 0.6387,                 loss: 0.4336
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 34.5770 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.4209
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 35.1629 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.4079
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 35.7434 s
agent0:                 episode reward: -0.7399,                 loss: nan
agent1:                 episode reward: 0.7399,                 loss: 0.3920
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 36.3391 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: 0.3751
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 36.9267 s
agent0:                 episode reward: -0.2836,                 loss: nan
agent1:                 episode reward: 0.2836,                 loss: 0.3632
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 37.5098 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.3543
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 38.0910 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.3541
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 38.6898 s
agent0:                 episode reward: -0.6421,                 loss: nan
agent1:                 episode reward: 0.6421,                 loss: 0.3487
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 39.2752 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.3490
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 39.8674 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.3501
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 40.4553 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.3493
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 41.0474 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.3459
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 41.6313 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: 0.3465
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 42.2207 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3438
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 42.8068 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.3450
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 43.3998 s
agent0:                 episode reward: -0.8482,                 loss: nan
agent1:                 episode reward: 0.8482,                 loss: 0.3444
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 43.9856 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.3914
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 44.5750 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3728
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 45.1629 s
agent0:                 episode reward: -0.8241,                 loss: nan
agent1:                 episode reward: 0.8241,                 loss: 0.3665
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 45.7500 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.3600
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 46.3398 s
agent0:                 episode reward: -0.6291,                 loss: nan
agent1:                 episode reward: 0.6291,                 loss: 0.3575
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 46.9331 s
agent0:                 episode reward: -0.6788,                 loss: nan
agent1:                 episode reward: 0.6788,                 loss: 0.3553
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 47.5191 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3505
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 48.1042 s
agent0:                 episode reward: -1.1264,                 loss: nan
agent1:                 episode reward: 1.1264,                 loss: 0.3519
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 48.6919 s
agent0:                 episode reward: -0.6575,                 loss: nan
agent1:                 episode reward: 0.6575,                 loss: 0.3513
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 49.2831 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.3498
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 49.8806 s
agent0:                 episode reward: -0.6066,                 loss: nan
agent1:                 episode reward: 0.6066,                 loss: 0.3480
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 50.4727 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.3500
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 51.0617 s
agent0:                 episode reward: -1.1051,                 loss: nan
agent1:                 episode reward: 1.1051,                 loss: 0.3486
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 51.6505 s
agent0:                 episode reward: -1.0865,                 loss: nan
agent1:                 episode reward: 1.0865,                 loss: 0.3458
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 52.2377 s
agent0:                 episode reward: -1.1326,                 loss: nan
agent1:                 episode reward: 1.1326,                 loss: 0.3477
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 52.8209 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.3454
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 53.4126 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.3504
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 53.9975 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3990
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 54.5798 s
agent0:                 episode reward: -0.9816,                 loss: nan
agent1:                 episode reward: 0.9816,                 loss: 0.3864
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 55.1681 s
agent0:                 episode reward: -0.4883,                 loss: nan
agent1:                 episode reward: 0.4883,                 loss: 0.3880
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 55.7534 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.3863
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 56.3395 s
agent0:                 episode reward: -0.9095,                 loss: nan
agent1:                 episode reward: 0.9095,                 loss: 0.3841
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 56.9214 s
agent0:                 episode reward: -0.4982,                 loss: nan
agent1:                 episode reward: 0.4982,                 loss: 0.3864
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 57.5077 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.3840
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 58.1004 s
agent0:                 episode reward: -0.9325,                 loss: nan
agent1:                 episode reward: 0.9325,                 loss: 0.3838
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 58.6875 s
agent0:                 episode reward: -0.9208,                 loss: nan
agent1:                 episode reward: 0.9208,                 loss: 0.3845
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 59.2771 s
agent0:                 episode reward: -0.7308,                 loss: nan
agent1:                 episode reward: 0.7308,                 loss: 0.3845
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 59.8584 s
agent0:                 episode reward: -0.4689,                 loss: nan
agent1:                 episode reward: 0.4689,                 loss: 0.3851
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 60.4530 s
agent0:                 episode reward: -0.8768,                 loss: nan
agent1:                 episode reward: 0.8768,                 loss: 0.3840
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 61.0550 s
agent0:                 episode reward: -0.3135,                 loss: nan
agent1:                 episode reward: 0.3135,                 loss: 0.3860
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 61.6465 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3854
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 62.2350 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.3870
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 62.8271 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: 0.3838
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 63.4157 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.3850
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 64.0034 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.3786
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 64.5878 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.3742
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 65.1690 s
agent0:                 episode reward: -0.5595,                 loss: nan
agent1:                 episode reward: 0.5595,                 loss: 0.3725
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 65.7576 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3736
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 66.3480 s
agent0:                 episode reward: -0.9140,                 loss: nan
agent1:                 episode reward: 0.9140,                 loss: 0.3717
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 66.9440 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.3737
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 67.5375 s
agent0:                 episode reward: -0.4841,                 loss: nan
agent1:                 episode reward: 0.4841,                 loss: 0.3755
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 68.1343 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3738
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 68.7244 s
agent0:                 episode reward: -0.7231,                 loss: nan
agent1:                 episode reward: 0.7231,                 loss: 0.3740
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 69.3108 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.3731
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 69.8984 s
agent0:                 episode reward: -0.8329,                 loss: nan
agent1:                 episode reward: 0.8329,                 loss: 0.3724
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 70.4885 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.3706
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 71.0791 s
agent0:                 episode reward: -0.7612,                 loss: nan
agent1:                 episode reward: 0.7612,                 loss: 0.3706
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 71.6698 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.3697
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 72.2580 s
agent0:                 episode reward: -0.9059,                 loss: nan
agent1:                 episode reward: 0.9059,                 loss: 0.3713
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 72.8438 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.3693
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 73.4302 s
agent0:                 episode reward: -1.0935,                 loss: nan
agent1:                 episode reward: 1.0935,                 loss: 0.3793
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 74.0220 s
agent0:                 episode reward: -1.1785,                 loss: nan
agent1:                 episode reward: 1.1785,                 loss: 0.3680
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 74.6127 s
agent0:                 episode reward: -0.8552,                 loss: nan
agent1:                 episode reward: 0.8552,                 loss: 0.3671
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 75.2035 s
agent0:                 episode reward: -1.2146,                 loss: nan
agent1:                 episode reward: 1.2146,                 loss: 0.3651
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 75.7888 s
agent0:                 episode reward: -0.5831,                 loss: nan
agent1:                 episode reward: 0.5831,                 loss: 0.3637
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 76.3752 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.3636
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 76.9651 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.3641
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5776s / 77.5427 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.3618
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 78.1296 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: 0.3621
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 78.7080 s
agent0:                 episode reward: -0.7833,                 loss: nan
agent1:                 episode reward: 0.7833,                 loss: 0.3643
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 79.2963 s
agent0:                 episode reward: -0.3640,                 loss: nan
agent1:                 episode reward: 0.3640,                 loss: 0.3636
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 79.8870 s
agent0:                 episode reward: -0.5389,                 loss: nan
agent1:                 episode reward: 0.5389,                 loss: 0.3620
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 80.4766 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.3642
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 81.0612 s
agent0:                 episode reward: -0.6586,                 loss: nan
agent1:                 episode reward: 0.6586,                 loss: 0.3635
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 81.6563 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.3627
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 82.2488 s
agent0:                 episode reward: -0.8055,                 loss: nan
agent1:                 episode reward: 0.8055,                 loss: 0.3650
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 82.8365 s
agent0:                 episode reward: -1.0617,                 loss: nan
agent1:                 episode reward: 1.0617,                 loss: 0.3685
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 83.4244 s
agent0:                 episode reward: -0.6144,                 loss: nan
agent1:                 episode reward: 0.6144,                 loss: 0.3874
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 84.0142 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.3740
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 84.6001 s
agent0:                 episode reward: -0.5341,                 loss: nan
agent1:                 episode reward: 0.5341,                 loss: 0.3737
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 85.1921 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.3766
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 85.7769 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.3714
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 86.3705 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.3726
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 86.9733 s
agent0:                 episode reward: -0.8158,                 loss: nan
agent1:                 episode reward: 0.8158,                 loss: 0.3740
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 87.5673 s
agent0:                 episode reward: -0.7263,                 loss: nan
agent1:                 episode reward: 0.7263,                 loss: 0.3713
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 88.1580 s
agent0:                 episode reward: -0.7233,                 loss: nan
agent1:                 episode reward: 0.7233,                 loss: 0.3716
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 88.7460 s
agent0:                 episode reward: -0.5853,                 loss: nan
agent1:                 episode reward: 0.5853,                 loss: 0.3728
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 89.3394 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.3729
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 89.9283 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.3746
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 90.5176 s
agent0:                 episode reward: -0.8267,                 loss: nan
agent1:                 episode reward: 0.8267,                 loss: 0.3745
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 91.1018 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.3716
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 91.6876 s
agent0:                 episode reward: -0.6454,                 loss: nan
agent1:                 episode reward: 0.6454,                 loss: 0.3726
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 92.2837 s
agent0:                 episode reward: -0.8681,                 loss: nan
agent1:                 episode reward: 0.8681,                 loss: 0.3730
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 92.8752 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.3792
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 93.4666 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.3661
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 94.0535 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3637
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 94.6352 s
agent0:                 episode reward: -0.8360,                 loss: nan
agent1:                 episode reward: 0.8360,                 loss: 0.3618
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 95.2272 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3658
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 95.8188 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.3653
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 96.4115 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.3616
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 96.9962 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.3638
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 97.5806 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.3614
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 98.1697 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.3625
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 98.7592 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.3635
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 99.3502 s
agent0:                 episode reward: -0.4597,                 loss: nan
agent1:                 episode reward: 0.4597,                 loss: 0.3648
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 99.9463 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.3604
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 100.5494 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.3623
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 101.1419 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: 0.3617
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 101.7289 s
agent0:                 episode reward: -0.6782,                 loss: nan
agent1:                 episode reward: 0.6782,                 loss: 0.3623
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 102.3234 s
agent0:                 episode reward: -0.6869,                 loss: nan
agent1:                 episode reward: 0.6869,                 loss: 0.3623
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 102.9066 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.3694
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 103.5068 s
agent0:                 episode reward: -0.8926,                 loss: nan
agent1:                 episode reward: 0.8926,                 loss: 0.3648
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 104.0988 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.3630
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 104.6931 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.3649
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 105.2906 s
agent0:                 episode reward: -0.9936,                 loss: nan
agent1:                 episode reward: 0.9936,                 loss: 0.3689
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 105.8821 s
agent0:                 episode reward: -0.1568,                 loss: nan
agent1:                 episode reward: 0.1568,                 loss: 0.3649
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 106.4874 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: 0.3687
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 107.0833 s
agent0:                 episode reward: -0.8699,                 loss: nan
agent1:                 episode reward: 0.8699,                 loss: 0.3660
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 107.6712 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.3670
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 108.2767 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.3658
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 108.8651 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3672
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 109.4636 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.3658
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 110.0674 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.3629
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 110.6549 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.3675
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 111.2485 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.3685
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 111.8374 s
agent0:                 episode reward: -1.0440,                 loss: nan
agent1:                 episode reward: 1.0440,                 loss: 0.3656
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 112.4403 s
agent0:                 episode reward: -0.1515,                 loss: nan
agent1:                 episode reward: 0.1515,                 loss: 0.3695
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 113.0328 s
agent0:                 episode reward: -0.9496,                 loss: nan
agent1:                 episode reward: 0.9496,                 loss: 0.3766
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 113.6303 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.3703
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 114.2222 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3713
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 114.8256 s
agent0:                 episode reward: -0.7882,                 loss: nan
agent1:                 episode reward: 0.7882,                 loss: 0.3717
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 115.4231 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.3717
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 116.0145 s
agent0:                 episode reward: -0.8796,                 loss: nan
agent1:                 episode reward: 0.8796,                 loss: 0.3661
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 116.6162 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.3724
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 117.2128 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.3693
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 117.8124 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.3718
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 118.4069 s
agent0:                 episode reward: -0.6707,                 loss: nan
agent1:                 episode reward: 0.6707,                 loss: 0.3709
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 118.9978 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: 0.3663
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 119.5980 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.3722
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 120.1911 s
agent0:                 episode reward: -1.0018,                 loss: nan
agent1:                 episode reward: 1.0018,                 loss: 0.3683
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 120.7846 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3702
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 121.3748 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.3687
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 121.9805 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3681
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 122.5912 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.3741
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 123.1924 s
agent0:                 episode reward: -0.7609,                 loss: nan
agent1:                 episode reward: 0.7609,                 loss: 0.3618
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 123.7990 s
agent0:                 episode reward: -1.0793,                 loss: nan
agent1:                 episode reward: 1.0793,                 loss: 0.3585
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 124.4040 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.3609
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 125.0059 s
agent0:                 episode reward: -0.8973,                 loss: nan
agent1:                 episode reward: 0.8973,                 loss: 0.3614
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 125.6034 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.3592
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 126.2108 s
agent0:                 episode reward: -0.7028,                 loss: nan
agent1:                 episode reward: 0.7028,                 loss: 0.3598
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 126.8144 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: 0.3563
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 127.4141 s
agent0:                 episode reward: -0.7624,                 loss: nan
agent1:                 episode reward: 0.7624,                 loss: 0.3586
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 128.0227 s
agent0:                 episode reward: -0.2566,                 loss: nan
agent1:                 episode reward: 0.2566,                 loss: 0.3608
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 128.6182 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.3616
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 129.2231 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.3584
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 129.8424 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.3569
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 130.4560 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.3575
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 131.0690 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.3611
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 131.6786 s
agent0:                 episode reward: -0.9200,                 loss: nan
agent1:                 episode reward: 0.9200,                 loss: 0.3597
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 132.2922 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3578
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 132.9052 s
agent0:                 episode reward: -0.4168,                 loss: nan
agent1:                 episode reward: 0.4168,                 loss: 0.3786
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 133.5157 s
agent0:                 episode reward: -0.7895,                 loss: nan
agent1:                 episode reward: 0.7895,                 loss: 0.3810
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 134.1224 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.3800
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 134.7338 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.3798
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 135.3474 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3787
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 135.9605 s
agent0:                 episode reward: -0.6047,                 loss: nan
agent1:                 episode reward: 0.6047,                 loss: 0.3793
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 136.5762 s
agent0:                 episode reward: -0.9007,                 loss: nan
agent1:                 episode reward: 0.9007,                 loss: 0.3789
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 137.1891 s
agent0:                 episode reward: -0.7540,                 loss: nan
agent1:                 episode reward: 0.7540,                 loss: 0.3812
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 137.8059 s
agent0:                 episode reward: -0.9042,                 loss: nan
agent1:                 episode reward: 0.9042,                 loss: 0.3810
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 138.4211 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.3758
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 139.0332 s
agent0:                 episode reward: -0.7901,                 loss: nan
agent1:                 episode reward: 0.7901,                 loss: 0.3791
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 139.6509 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.3787
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 140.2605 s
agent0:                 episode reward: -1.0016,                 loss: nan
agent1:                 episode reward: 1.0016,                 loss: 0.3767
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6164s / 140.8769 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.3794
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 141.4826 s
agent0:                 episode reward: -1.0057,                 loss: nan
agent1:                 episode reward: 1.0057,                 loss: 0.3789
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6156s / 142.0982 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.3817
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 142.7110 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.3830
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 143.3130 s
agent0:                 episode reward: -0.6736,                 loss: nan
agent1:                 episode reward: 0.6736,                 loss: 0.3605
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 143.9107 s
agent0:                 episode reward: -0.9508,                 loss: nan
agent1:                 episode reward: 0.9508,                 loss: 0.3504
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 144.5061 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.3553
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 145.1086 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.3520
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 145.7097 s
agent0:                 episode reward: -0.3331,                 loss: nan
agent1:                 episode reward: 0.3331,                 loss: 0.3533
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 146.3182 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.3502
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 146.9208 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.3529
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6083s / 147.5291 s
agent0:                 episode reward: -0.8961,                 loss: nan
agent1:                 episode reward: 0.8961,                 loss: 0.3521
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 148.1325 s
agent0:                 episode reward: -0.8189,                 loss: nan
agent1:                 episode reward: 0.8189,                 loss: 0.3511
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 148.7412 s
agent0:                 episode reward: -0.3255,                 loss: nan
agent1:                 episode reward: 0.3255,                 loss: 0.3496
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 149.3499 s
agent0:                 episode reward: -0.7720,                 loss: nan
agent1:                 episode reward: 0.7720,                 loss: 0.3518
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 149.9595 s
agent0:                 episode reward: -1.2820,                 loss: nan
agent1:                 episode reward: 1.2820,                 loss: 0.3500
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 150.5547 s
agent0:                 episode reward: -1.0977,                 loss: nan
agent1:                 episode reward: 1.0977,                 loss: 0.3492
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 151.1518 s
agent0:                 episode reward: -0.9227,                 loss: nan
agent1:                 episode reward: 0.9227,                 loss: 0.3519
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 151.7560 s
agent0:                 episode reward: -0.9448,                 loss: nan
agent1:                 episode reward: 0.9448,                 loss: 0.3510
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 152.3509 s
agent0:                 episode reward: -1.2092,                 loss: nan
agent1:                 episode reward: 1.2092,                 loss: 0.3495
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 152.9506 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.3637
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 153.5618 s
agent0:                 episode reward: -0.1001,                 loss: nan
agent1:                 episode reward: 0.1001,                 loss: 0.3404
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 154.1617 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.3373
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 154.7603 s
agent0:                 episode reward: -0.8418,                 loss: nan
agent1:                 episode reward: 0.8418,                 loss: 0.3371
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 155.3769 s
agent0:                 episode reward: -0.7996,                 loss: nan
agent1:                 episode reward: 0.7996,                 loss: 0.3381
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 155.9827 s
agent0:                 episode reward: -0.7585,                 loss: nan
agent1:                 episode reward: 0.7585,                 loss: 0.3379
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 156.5808 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.3374
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 157.1901 s
agent0:                 episode reward: -0.6420,                 loss: nan
agent1:                 episode reward: 0.6420,                 loss: 0.3360
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 157.8032 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.3383
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 158.4122 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.3352
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 159.0157 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.3391
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 159.6168 s
agent0:                 episode reward: -0.8824,                 loss: nan
agent1:                 episode reward: 0.8824,                 loss: 0.3372
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 160.2259 s
agent0:                 episode reward: -1.1767,                 loss: nan
agent1:                 episode reward: 1.1767,                 loss: 0.3353
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 160.8267 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3368
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 161.4400 s
agent0:                 episode reward: -0.7500,                 loss: nan
agent1:                 episode reward: 0.7500,                 loss: 0.3371
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 162.0403 s
agent0:                 episode reward: -0.6742,                 loss: nan
agent1:                 episode reward: 0.6742,                 loss: 0.3377
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 162.6480 s
agent0:                 episode reward: -0.7650,                 loss: nan
agent1:                 episode reward: 0.7650,                 loss: 0.3388
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 163.2549 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.3764
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 163.8625 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.3835
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 164.4607 s
agent0:                 episode reward: -0.9381,                 loss: nan
agent1:                 episode reward: 0.9381,                 loss: 0.3836
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 165.0624 s
agent0:                 episode reward: -0.7270,                 loss: nan
agent1:                 episode reward: 0.7270,                 loss: 0.3812
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 165.6639 s
agent0:                 episode reward: -0.9748,                 loss: nan
agent1:                 episode reward: 0.9748,                 loss: 0.3835
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 166.2696 s
agent0:                 episode reward: -1.0097,                 loss: nan
agent1:                 episode reward: 1.0097,                 loss: 0.3819
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 166.8786 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: 0.3816
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 167.4836 s
agent0:                 episode reward: -0.4591,                 loss: nan
agent1:                 episode reward: 0.4591,                 loss: 0.3829
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 168.0993 s
agent0:                 episode reward: -0.6852,                 loss: nan
agent1:                 episode reward: 0.6852,                 loss: 0.3808
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6108s / 168.7101 s
agent0:                 episode reward: -1.0051,                 loss: nan
agent1:                 episode reward: 1.0051,                 loss: 0.3827
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 169.3133 s
agent0:                 episode reward: -0.6353,                 loss: nan
agent1:                 episode reward: 0.6353,                 loss: 0.3823
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6109s / 169.9241 s
agent0:                 episode reward: -0.6707,                 loss: nan
agent1:                 episode reward: 0.6707,                 loss: 0.3822
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 170.5262 s
agent0:                 episode reward: -0.7427,                 loss: nan
agent1:                 episode reward: 0.7427,                 loss: 0.3828
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 171.1414 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.3812
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 171.7479 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.3816
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6108s / 172.3587 s
agent0:                 episode reward: -0.8634,                 loss: nan
agent1:                 episode reward: 0.8634,                 loss: 0.3831
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6169s / 172.9756 s
agent0:                 episode reward: -0.5425,                 loss: nan
agent1:                 episode reward: 0.5425,                 loss: 0.3836
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6195s / 173.5951 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.3672
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 174.2046 s
agent0:                 episode reward: -0.7441,                 loss: nan
agent1:                 episode reward: 0.7441,                 loss: 0.3662
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 174.8160 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.3693
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 175.4223 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.3684
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 176.0361 s
agent0:                 episode reward: -0.9467,                 loss: nan
agent1:                 episode reward: 0.9467,                 loss: 0.3694
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 176.6431 s
agent0:                 episode reward: -0.5728,                 loss: nan
agent1:                 episode reward: 0.5728,                 loss: 0.3671
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 177.2522 s
agent0:                 episode reward: -1.0029,                 loss: nan
agent1:                 episode reward: 1.0029,                 loss: 0.3692
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 177.8615 s
agent0:                 episode reward: -0.7745,                 loss: nan
agent1:                 episode reward: 0.7745,                 loss: 0.3687
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 178.4703 s
agent0:                 episode reward: -0.7112,                 loss: nan
agent1:                 episode reward: 0.7112,                 loss: 0.3675
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 179.0881 s
agent0:                 episode reward: -0.8449,                 loss: nan
agent1:                 episode reward: 0.8449,                 loss: 0.3693
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 179.7000 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.3671
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 180.3067 s
agent0:                 episode reward: -1.0249,                 loss: nan
agent1:                 episode reward: 1.0249,                 loss: 0.3674
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 180.9161 s
agent0:                 episode reward: -0.7473,                 loss: nan
agent1:                 episode reward: 0.7473,                 loss: 0.3702
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6141s / 181.5302 s
agent0:                 episode reward: -0.3599,                 loss: nan
agent1:                 episode reward: 0.3599,                 loss: 0.3667
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 182.1402 s
agent0:                 episode reward: -1.0592,                 loss: nan
agent1:                 episode reward: 1.0592,                 loss: 0.3686
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 182.7513 s
agent0:                 episode reward: -0.7705,                 loss: nan
agent1:                 episode reward: 0.7705,                 loss: 0.3671
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6165s / 183.3678 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.3696
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 183.9730 s
agent0:                 episode reward: -0.5086,                 loss: nan
agent1:                 episode reward: 0.5086,                 loss: 0.3648
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 184.5841 s
agent0:                 episode reward: -0.8351,                 loss: nan
agent1:                 episode reward: 0.8351,                 loss: 0.3622
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 185.1956 s
agent0:                 episode reward: -0.6886,                 loss: nan
agent1:                 episode reward: 0.6886,                 loss: 0.3574
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 185.8102 s
agent0:                 episode reward: -0.9552,                 loss: nan
agent1:                 episode reward: 0.9552,                 loss: 0.3642
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6221s / 186.4323 s
agent0:                 episode reward: -0.5490,                 loss: nan
agent1:                 episode reward: 0.5490,                 loss: 0.3651
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 187.0450 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.3623
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 187.6628 s
agent0:                 episode reward: -0.6332,                 loss: nan
agent1:                 episode reward: 0.6332,                 loss: 0.3584
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6179s / 188.2807 s
agent0:                 episode reward: -0.4823,                 loss: nan
agent1:                 episode reward: 0.4823,                 loss: 0.3655
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 188.8899 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.3624
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 189.4966 s
agent0:                 episode reward: -0.5360,                 loss: nan
agent1:                 episode reward: 0.5360,                 loss: 0.3614
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 190.1115 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.3620
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6241s / 190.7356 s
agent0:                 episode reward: -0.8061,                 loss: nan
agent1:                 episode reward: 0.8061,                 loss: 0.3605
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 191.3552 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.3637
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 191.9681 s
agent0:                 episode reward: -0.5233,                 loss: nan
agent1:                 episode reward: 0.5233,                 loss: 0.3624
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 192.5809 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.3626
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 193.1981 s
agent0:                 episode reward: -0.4288,                 loss: nan
agent1:                 episode reward: 0.4288,                 loss: 0.3619
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6207s / 193.8189 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.3794
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6141s / 194.4330 s
agent0:                 episode reward: -0.9108,                 loss: nan
agent1:                 episode reward: 0.9108,                 loss: 0.3818
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6185s / 195.0515 s
agent0:                 episode reward: -0.6300,                 loss: nan
agent1:                 episode reward: 0.6300,                 loss: 0.3821
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 195.6651 s
agent0:                 episode reward: -0.6970,                 loss: nan
agent1:                 episode reward: 0.6970,                 loss: 0.3802
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 196.2800 s
agent0:                 episode reward: -0.7855,                 loss: nan
agent1:                 episode reward: 0.7855,                 loss: 0.3796
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 196.8967 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.3800
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 197.5137 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.3823
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 198.1275 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3834
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 198.7359 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.3834
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 199.3486 s
agent0:                 episode reward: -0.8231,                 loss: nan
agent1:                 episode reward: 0.8231,                 loss: 0.3810
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 199.9637 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3818
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6208s / 200.5845 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.3814
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 201.2029 s
agent0:                 episode reward: -0.5125,                 loss: nan
agent1:                 episode reward: 0.5125,                 loss: 0.3815
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6139s / 201.8168 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.3815
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 202.4310 s
agent0:                 episode reward: -0.8506,                 loss: nan
agent1:                 episode reward: 0.8506,                 loss: 0.3824
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 203.0460 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: 0.3813
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6171s / 203.6632 s
agent0:                 episode reward: -0.6854,                 loss: nan
agent1:                 episode reward: 0.6854,                 loss: 0.3808
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6254s / 204.2886 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.3749
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 204.9082 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.3738
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 205.5118 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.3773
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 206.1320 s
agent0:                 episode reward: -0.8600,                 loss: nan
agent1:                 episode reward: 0.8600,                 loss: 0.3721
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6173s / 206.7493 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.3731
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6183s / 207.3676 s
agent0:                 episode reward: -0.6630,                 loss: nan
agent1:                 episode reward: 0.6630,                 loss: 0.3746
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 207.9804 s
agent0:                 episode reward: -0.9739,                 loss: nan
agent1:                 episode reward: 0.9739,                 loss: 0.3732
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 208.6070 s
agent0:                 episode reward: -0.6789,                 loss: nan
agent1:                 episode reward: 0.6789,                 loss: 0.3725
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6218s / 209.2288 s
agent0:                 episode reward: -0.7999,                 loss: nan
agent1:                 episode reward: 0.7999,                 loss: 0.3728
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 209.8553 s
agent0:                 episode reward: -0.6851,                 loss: nan
agent1:                 episode reward: 0.6851,                 loss: 0.3711
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 210.4683 s
agent0:                 episode reward: -0.6916,                 loss: nan
agent1:                 episode reward: 0.6916,                 loss: 0.3728
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6210s / 211.0893 s
agent0:                 episode reward: -0.5321,                 loss: nan
agent1:                 episode reward: 0.5321,                 loss: 0.3734
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 211.7071 s
agent0:                 episode reward: -0.5188,                 loss: nan
agent1:                 episode reward: 0.5188,                 loss: 0.3727
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 212.3321 s
agent0:                 episode reward: -0.7587,                 loss: nan
agent1:                 episode reward: 0.7587,                 loss: 0.3750
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6241s / 212.9562 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.3735
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6205s / 213.5767 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.3703
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6173s / 214.1940 s
agent0:                 episode reward: -0.8412,                 loss: nan
agent1:                 episode reward: 0.8412,                 loss: 0.3702
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6198s / 214.8138 s
agent0:                 episode reward: -1.0698,                 loss: nan
agent1:                 episode reward: 1.0698,                 loss: 0.3606
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6238s / 215.4376 s
agent0:                 episode reward: -0.8045,                 loss: nan
agent1:                 episode reward: 0.8045,                 loss: 0.3574
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6262s / 216.0639 s
agent0:                 episode reward: -0.9770,                 loss: nan
agent1:                 episode reward: 0.9770,                 loss: 0.3589
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6259s / 216.6898 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.3589
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6219s / 217.3117 s
agent0:                 episode reward: -0.8399,                 loss: nan
agent1:                 episode reward: 0.8399,                 loss: 0.3609
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6206s / 217.9323 s
agent0:                 episode reward: -0.9404,                 loss: nan
agent1:                 episode reward: 0.9404,                 loss: 0.3567
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6228s / 218.5551 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.3573
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6179s / 219.1730 s
agent0:                 episode reward: -0.9139,                 loss: nan
agent1:                 episode reward: 0.9139,                 loss: 0.3605
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6220s / 219.7949 s
agent0:                 episode reward: -0.6011,                 loss: nan
agent1:                 episode reward: 0.6011,                 loss: 0.3579
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 220.4134 s
agent0:                 episode reward: -0.6342,                 loss: nan
agent1:                 episode reward: 0.6342,                 loss: 0.3587
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 221.0431 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.3594
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6212s / 221.6644 s
agent0:                 episode reward: -0.8735,                 loss: nan
agent1:                 episode reward: 0.8735,                 loss: 0.3591
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 222.2940 s
agent0:                 episode reward: -1.0135,                 loss: nan
agent1:                 episode reward: 1.0135,                 loss: 0.3569
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 222.9236 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3631
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6277s / 223.5513 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.3607
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6212s / 224.1725 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.3564
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6266s / 224.7991 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.3763
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 225.4188 s
agent0:                 episode reward: -0.7463,                 loss: nan
agent1:                 episode reward: 0.7463,                 loss: 0.3816
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6254s / 226.0441 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.3811
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6300s / 226.6742 s
agent0:                 episode reward: -1.1899,                 loss: nan
agent1:                 episode reward: 1.1899,                 loss: 0.3832
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6242s / 227.2984 s
agent0:                 episode reward: -1.0348,                 loss: nan
agent1:                 episode reward: 1.0348,                 loss: 0.3793
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 227.9249 s
agent0:                 episode reward: -0.3695,                 loss: nan
agent1:                 episode reward: 0.3695,                 loss: 0.3797
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 228.5574 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.3829
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6278s / 229.1852 s
agent0:                 episode reward: -0.8440,                 loss: nan
agent1:                 episode reward: 0.8440,                 loss: 0.3805
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 229.8148 s
agent0:                 episode reward: -0.7933,                 loss: nan
agent1:                 episode reward: 0.7933,                 loss: 0.3810
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6234s / 230.4381 s
agent0:                 episode reward: -0.7062,                 loss: nan
agent1:                 episode reward: 0.7062,                 loss: 0.3826
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6364s / 231.0745 s
agent0:                 episode reward: -0.4876,                 loss: nan
agent1:                 episode reward: 0.4876,                 loss: 0.3808
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 231.7102 s
agent0:                 episode reward: -0.5625,                 loss: nan
agent1:                 episode reward: 0.5625,                 loss: 0.3813
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6322s / 232.3423 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.3834
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 232.9680 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.3790
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 233.5932 s
agent0:                 episode reward: -0.5786,                 loss: nan
agent1:                 episode reward: 0.5786,                 loss: 0.3803
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 234.2118 s
agent0:                 episode reward: -1.0074,                 loss: nan
agent1:                 episode reward: 1.0074,                 loss: 0.3805
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6396s / 234.8514 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.3839
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6213s / 235.4727 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.3710
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6225s / 236.0952 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.3661
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6259s / 236.7211 s
agent0:                 episode reward: -0.6522,                 loss: nan
agent1:                 episode reward: 0.6522,                 loss: 0.3677
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 237.3578 s
agent0:                 episode reward: -1.0610,                 loss: nan
agent1:                 episode reward: 1.0610,                 loss: 0.3678
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 237.9870 s
agent0:                 episode reward: -0.8608,                 loss: nan
agent1:                 episode reward: 0.8608,                 loss: 0.3675
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 238.6140 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.3686
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 239.2432 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.3674
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6326s / 239.8757 s
agent0:                 episode reward: -0.4450,                 loss: nan
agent1:                 episode reward: 0.4450,                 loss: 0.3683
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6314s / 240.5072 s
agent0:                 episode reward: -0.8327,                 loss: nan
agent1:                 episode reward: 0.8327,                 loss: 0.3682
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6283s / 241.1355 s
agent0:                 episode reward: -1.1432,                 loss: nan
agent1:                 episode reward: 1.1432,                 loss: 0.3673
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6245s / 241.7600 s
agent0:                 episode reward: -0.6095,                 loss: nan
agent1:                 episode reward: 0.6095,                 loss: 0.3673
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 242.3867 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.3702
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6290s / 243.0156 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.3696
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6308s / 243.6465 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.3692
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6226s / 244.2691 s
agent0:                 episode reward: -0.4315,                 loss: nan
agent1:                 episode reward: 0.4315,                 loss: 0.3672
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6257s / 244.8948 s
agent0:                 episode reward: -0.9301,                 loss: nan
agent1:                 episode reward: 0.9301,                 loss: 0.3705
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6291s / 245.5239 s
agent0:                 episode reward: -0.7775,                 loss: nan
agent1:                 episode reward: 0.7775,                 loss: 0.3708
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6258s / 246.1497 s
agent0:                 episode reward: -0.7614,                 loss: nan
agent1:                 episode reward: 0.7614,                 loss: 0.3742
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6253s / 246.7750 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.3748
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6287s / 247.4036 s
agent0:                 episode reward: -0.5560,                 loss: nan
agent1:                 episode reward: 0.5560,                 loss: 0.3736
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 248.0403 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.3726
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6209s / 248.6612 s
agent0:                 episode reward: -0.8397,                 loss: nan
agent1:                 episode reward: 0.8397,                 loss: 0.3764
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6284s / 249.2896 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.3744
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6264s / 249.9161 s
agent0:                 episode reward: -0.6594,                 loss: nan
agent1:                 episode reward: 0.6594,                 loss: 0.3760
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6235s / 250.5396 s
agent0:                 episode reward: -0.6109,                 loss: nan
agent1:                 episode reward: 0.6109,                 loss: 0.3768
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 251.1599 s
agent0:                 episode reward: -0.9459,                 loss: nan
agent1:                 episode reward: 0.9459,                 loss: 0.3745
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6304s / 251.7903 s
agent0:                 episode reward: -1.1087,                 loss: nan
agent1:                 episode reward: 1.1087,                 loss: 0.3721
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6321s / 252.4224 s
agent0:                 episode reward: -0.3663,                 loss: nan
agent1:                 episode reward: 0.3663,                 loss: 0.3756
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6291s / 253.0515 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3751
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 253.6809 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.3763
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6307s / 254.3116 s
agent0:                 episode reward: -0.4936,                 loss: nan
agent1:                 episode reward: 0.4936,                 loss: 0.3736
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6272s / 254.9388 s
agent0:                 episode reward: -0.8492,                 loss: nan
agent1:                 episode reward: 0.8492,                 loss: 0.3763
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6286s / 255.5674 s
agent0:                 episode reward: -1.0476,                 loss: nan
agent1:                 episode reward: 1.0476,                 loss: 0.3728
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6305s / 256.1979 s
agent0:                 episode reward: -0.6446,                 loss: nan
agent1:                 episode reward: 0.6446,                 loss: 0.3762
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6343s / 256.8322 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.3763
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 257.4620 s
agent0:                 episode reward: -0.9019,                 loss: nan
agent1:                 episode reward: 0.9019,                 loss: 0.3773
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6284s / 258.0904 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.3772
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6410s / 258.7314 s
agent0:                 episode reward: -0.6564,                 loss: nan
agent1:                 episode reward: 0.6564,                 loss: 0.3734
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6333s / 259.3647 s
agent0:                 episode reward: -0.8726,                 loss: nan
agent1:                 episode reward: 0.8726,                 loss: 0.3788
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6342s / 259.9989 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.3769
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6302s / 260.6290 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.3732
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 261.2582 s
agent0:                 episode reward: -0.7100,                 loss: nan
agent1:                 episode reward: 0.7100,                 loss: 0.3789
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6391s / 261.8973 s
agent0:                 episode reward: -0.7820,                 loss: nan
agent1:                 episode reward: 0.7820,                 loss: 0.3766
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6375s / 262.5348 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.3761
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 263.1645 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.3754
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6430s / 263.8075 s
agent0:                 episode reward: -0.5682,                 loss: nan
agent1:                 episode reward: 0.5682,                 loss: 0.3784
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 264.4343 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.3759
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6372s / 265.0715 s
agent0:                 episode reward: -0.9228,                 loss: nan
agent1:                 episode reward: 0.9228,                 loss: 0.3744
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6387s / 265.7102 s
agent0:                 episode reward: -0.6116,                 loss: nan
agent1:                 episode reward: 0.6116,                 loss: 0.3756
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 266.3459 s
agent0:                 episode reward: -0.5177,                 loss: nan
agent1:                 episode reward: 0.5177,                 loss: 0.3766
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6446s / 266.9905 s
agent0:                 episode reward: -0.7937,                 loss: nan
agent1:                 episode reward: 0.7937,                 loss: 0.3693
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6422s / 267.6327 s
agent0:                 episode reward: -0.9761,                 loss: nan
agent1:                 episode reward: 0.9761,                 loss: 0.3715
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 268.2838 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.3689
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6459s / 268.9297 s
agent0:                 episode reward: -0.5459,                 loss: nan
agent1:                 episode reward: 0.5459,                 loss: 0.3711
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6679s / 269.5976 s
agent0:                 episode reward: -1.1442,                 loss: nan
agent1:                 episode reward: 1.1442,                 loss: 0.3709
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 270.2435 s
agent0:                 episode reward: -0.8731,                 loss: nan
agent1:                 episode reward: 0.8731,                 loss: 0.3726
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6423s / 270.8858 s
agent0:                 episode reward: -0.7095,                 loss: nan
agent1:                 episode reward: 0.7095,                 loss: 0.3704
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6533s / 271.5391 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.3730
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6405s / 272.1796 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.3709
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 272.8214 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.3688
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6393s / 273.4607 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.3699
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 274.1040 s
agent0:                 episode reward: -0.9252,                 loss: nan
agent1:                 episode reward: 0.9252,                 loss: 0.3727
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 274.7519 s
agent0:                 episode reward: -0.7554,                 loss: nan
agent1:                 episode reward: 0.7554,                 loss: 0.3676
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6437s / 275.3956 s
agent0:                 episode reward: -1.1195,                 loss: nan
agent1:                 episode reward: 1.1195,                 loss: 0.3708
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6359s / 276.0315 s
agent0:                 episode reward: -0.6328,                 loss: nan
agent1:                 episode reward: 0.6328,                 loss: 0.3688
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6529s / 276.6844 s
agent0:                 episode reward: -0.9184,                 loss: nan
agent1:                 episode reward: 0.9184,                 loss: 0.3681
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 277.3201 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.3705
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6439s / 277.9640 s
agent0:                 episode reward: -0.6097,                 loss: nan
agent1:                 episode reward: 0.6097,                 loss: 0.3636
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6374s / 278.6014 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.3615
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 279.2580 s
agent0:                 episode reward: -0.7080,                 loss: nan
agent1:                 episode reward: 0.7080,                 loss: 0.3642
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 279.8996 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.3634
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6413s / 280.5409 s
agent0:                 episode reward: -0.5657,                 loss: nan
agent1:                 episode reward: 0.5657,                 loss: 0.3638
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 281.1867 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.3640
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6332s / 281.8199 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.3642
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 282.4752 s
agent0:                 episode reward: -0.2503,                 loss: nan
agent1:                 episode reward: 0.2503,                 loss: 0.3642
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6463s / 283.1215 s
agent0:                 episode reward: -0.7146,                 loss: nan
agent1:                 episode reward: 0.7146,                 loss: 0.3650
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6379s / 283.7594 s
agent0:                 episode reward: -0.8236,                 loss: nan
agent1:                 episode reward: 0.8236,                 loss: 0.3635
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 284.4032 s
agent0:                 episode reward: -0.7429,                 loss: nan
agent1:                 episode reward: 0.7429,                 loss: 0.3646
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6372s / 285.0403 s
agent0:                 episode reward: -0.9534,                 loss: nan
agent1:                 episode reward: 0.9534,                 loss: 0.3643
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6361s / 285.6764 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.3641
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6318s / 286.3082 s
agent0:                 episode reward: -0.6779,                 loss: nan
agent1:                 episode reward: 0.6779,                 loss: 0.3620
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 286.9449 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.3664
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6423s / 287.5872 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.3624
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6484s / 288.2355 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.3780
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 288.8909 s
agent0:                 episode reward: -0.6060,                 loss: nan
agent1:                 episode reward: 0.6060,                 loss: 0.3755
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6534s / 289.5444 s
agent0:                 episode reward: -0.7696,                 loss: nan
agent1:                 episode reward: 0.7696,                 loss: 0.3763
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6602s / 290.2046 s
agent0:                 episode reward: -1.0883,                 loss: nan
agent1:                 episode reward: 1.0883,                 loss: 0.3746
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6381s / 290.8427 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.3750
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6487s / 291.4914 s
agent0:                 episode reward: -0.7108,                 loss: nan
agent1:                 episode reward: 0.7108,                 loss: 0.3760
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6473s / 292.1386 s
agent0:                 episode reward: -0.7834,                 loss: nan
agent1:                 episode reward: 0.7834,                 loss: 0.3757
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6509s / 292.7895 s
agent0:                 episode reward: -0.9333,                 loss: nan
agent1:                 episode reward: 0.9333,                 loss: 0.3755
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6525s / 293.4420 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.3756
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 294.0950 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.3772
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6460s / 294.7409 s
agent0:                 episode reward: -0.5130,                 loss: nan
agent1:                 episode reward: 0.5130,                 loss: 0.3768
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6605s / 295.4014 s
agent0:                 episode reward: -0.6023,                 loss: nan
agent1:                 episode reward: 0.6023,                 loss: 0.3766
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6541s / 296.0556 s
agent0:                 episode reward: -0.4032,                 loss: nan
agent1:                 episode reward: 0.4032,                 loss: 0.3752
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6558s / 296.7114 s
agent0:                 episode reward: -0.4702,                 loss: nan
agent1:                 episode reward: 0.4702,                 loss: 0.3755
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6588s / 297.3702 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: 0.3759
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6470s / 298.0172 s
agent0:                 episode reward: -1.0098,                 loss: nan
agent1:                 episode reward: 1.0098,                 loss: 0.3775
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6442s / 298.6614 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.3777
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6686s / 299.3300 s
agent0:                 episode reward: -0.6451,                 loss: nan
agent1:                 episode reward: 0.6451,                 loss: 0.3630
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6981s / 300.0281 s
agent0:                 episode reward: -0.7300,                 loss: nan
agent1:                 episode reward: 0.7300,                 loss: 0.3609
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6459s / 300.6741 s
agent0:                 episode reward: -0.7321,                 loss: nan
agent1:                 episode reward: 0.7321,                 loss: 0.3598
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6473s / 301.3214 s
agent0:                 episode reward: -0.6302,                 loss: nan
agent1:                 episode reward: 0.6302,                 loss: 0.3608
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6644s / 301.9858 s
agent0:                 episode reward: -0.3553,                 loss: nan
agent1:                 episode reward: 0.3553,                 loss: 0.3603
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6452s / 302.6310 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.3596
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 303.2766 s
agent0:                 episode reward: -0.2357,                 loss: nan
agent1:                 episode reward: 0.2357,                 loss: 0.3600
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6451s / 303.9218 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.3614
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 304.5665 s
agent0:                 episode reward: -0.7385,                 loss: nan
agent1:                 episode reward: 0.7385,                 loss: 0.3578
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6420s / 305.2086 s
agent0:                 episode reward: -1.0653,                 loss: nan
agent1:                 episode reward: 1.0653,                 loss: 0.3605
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 305.8452 s
agent0:                 episode reward: -0.7332,                 loss: nan
agent1:                 episode reward: 0.7332,                 loss: 0.3616
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6402s / 306.4854 s
agent0:                 episode reward: -0.5934,                 loss: nan
agent1:                 episode reward: 0.5934,                 loss: 0.3606
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 307.1389 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.3595
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6426s / 307.7815 s
agent0:                 episode reward: -0.7976,                 loss: nan
agent1:                 episode reward: 0.7976,                 loss: 0.3606
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6517s / 308.4332 s
agent0:                 episode reward: -0.7678,                 loss: nan
agent1:                 episode reward: 0.7678,                 loss: 0.3581
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6622s / 309.0954 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.3597
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 309.7484 s
agent0:                 episode reward: -0.9487,                 loss: nan
agent1:                 episode reward: 0.9487,                 loss: 0.3670
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6613s / 310.4096 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: 0.3678
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 311.0647 s
agent0:                 episode reward: -0.4607,                 loss: nan
agent1:                 episode reward: 0.4607,                 loss: 0.3651
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6539s / 311.7187 s
agent0:                 episode reward: -0.9461,                 loss: nan
agent1:                 episode reward: 0.9461,                 loss: 0.3637
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 312.3737 s
agent0:                 episode reward: -0.4068,                 loss: nan
agent1:                 episode reward: 0.4068,                 loss: 0.3687
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 313.0244 s
agent0:                 episode reward: -0.8030,                 loss: nan
agent1:                 episode reward: 0.8030,                 loss: 0.3654
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6467s / 313.6711 s
agent0:                 episode reward: -0.7089,                 loss: nan
agent1:                 episode reward: 0.7089,                 loss: 0.3678
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6512s / 314.3223 s
agent0:                 episode reward: -1.0746,                 loss: nan
agent1:                 episode reward: 1.0746,                 loss: 0.3671
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 314.9773 s
agent0:                 episode reward: -1.2827,                 loss: nan
agent1:                 episode reward: 1.2827,                 loss: 0.3669
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 315.6357 s
agent0:                 episode reward: -0.9170,                 loss: nan
agent1:                 episode reward: 0.9170,                 loss: 0.3682
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6559s / 316.2916 s
agent0:                 episode reward: -0.9027,                 loss: nan
agent1:                 episode reward: 0.9027,                 loss: 0.3666
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6499s / 316.9415 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.3670
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 317.5892 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.3679
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 318.2348 s
agent0:                 episode reward: -0.7491,                 loss: nan
agent1:                 episode reward: 0.7491,                 loss: 0.3658
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6561s / 318.8909 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.3662
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6613s / 319.5522 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.3652
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6577s / 320.2099 s
agent0:                 episode reward: -0.8895,                 loss: nan
agent1:                 episode reward: 0.8895,                 loss: 0.3686
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6606s / 320.8705 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.3787
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6560s / 321.5265 s
agent0:                 episode reward: -0.7526,                 loss: nan
agent1:                 episode reward: 0.7526,                 loss: 0.3764
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6517s / 322.1782 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.3748
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 322.8360 s
agent0:                 episode reward: -1.0849,                 loss: nan
agent1:                 episode reward: 1.0849,                 loss: 0.3773
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 323.4915 s
agent0:                 episode reward: -0.6933,                 loss: nan
agent1:                 episode reward: 0.6933,                 loss: 0.3776
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6563s / 324.1478 s
agent0:                 episode reward: -0.2592,                 loss: nan
agent1:                 episode reward: 0.2592,                 loss: 0.3755
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6513s / 324.7991 s
agent0:                 episode reward: -0.7967,                 loss: nan
agent1:                 episode reward: 0.7967,                 loss: 0.3754
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 325.4600 s
agent0:                 episode reward: -0.9484,                 loss: nan
agent1:                 episode reward: 0.9484,                 loss: 0.3775
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 326.1167 s
agent0:                 episode reward: -0.9585,                 loss: nan
agent1:                 episode reward: 0.9585,                 loss: 0.3766
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6570s / 326.7737 s
agent0:                 episode reward: -0.7217,                 loss: nan
agent1:                 episode reward: 0.7217,                 loss: 0.3751
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6532s / 327.4269 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3761
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 328.0835 s
agent0:                 episode reward: -0.7137,                 loss: nan
agent1:                 episode reward: 0.7137,                 loss: 0.3780
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 328.7436 s
agent0:                 episode reward: -0.4292,                 loss: nan
agent1:                 episode reward: 0.4292,                 loss: 0.3749
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6557s / 329.3993 s
agent0:                 episode reward: -0.7861,                 loss: nan
agent1:                 episode reward: 0.7861,                 loss: 0.3767
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6585s / 330.0578 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: 0.3760
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6603s / 330.7181 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.3771
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6617s / 331.3798 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.3760
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 332.0462 s
agent0:                 episode reward: -0.6867,                 loss: nan
agent1:                 episode reward: 0.6867,                 loss: 0.3682
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6548s / 332.7010 s
agent0:                 episode reward: -1.0025,                 loss: nan
agent1:                 episode reward: 1.0025,                 loss: 0.3655
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6636s / 333.3646 s
agent0:                 episode reward: -0.6926,                 loss: nan
agent1:                 episode reward: 0.6926,                 loss: 0.3656
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6677s / 334.0322 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.3653
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6650s / 334.6973 s
agent0:                 episode reward: -0.5901,                 loss: nan
agent1:                 episode reward: 0.5901,                 loss: 0.3656
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6639s / 335.3612 s
agent0:                 episode reward: -0.9111,                 loss: nan
agent1:                 episode reward: 0.9111,                 loss: 0.3637
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6642s / 336.0254 s
agent0:                 episode reward: -0.6938,                 loss: nan
agent1:                 episode reward: 0.6938,                 loss: 0.3643
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6625s / 336.6878 s
agent0:                 episode reward: -0.9157,                 loss: nan
agent1:                 episode reward: 0.9157,                 loss: 0.3641
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6644s / 337.3522 s
agent0:                 episode reward: -0.7633,                 loss: nan
agent1:                 episode reward: 0.7633,                 loss: 0.3648
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 338.0072 s
agent0:                 episode reward: -1.1435,                 loss: nan
agent1:                 episode reward: 1.1435,                 loss: 0.3658
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 338.6651 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.3653
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6599s / 339.3250 s
agent0:                 episode reward: -0.7230,                 loss: nan
agent1:                 episode reward: 0.7230,                 loss: 0.3666
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 339.9913 s
agent0:                 episode reward: -0.4765,                 loss: nan
agent1:                 episode reward: 0.4765,                 loss: 0.3653
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6689s / 340.6602 s
agent0:                 episode reward: -0.9376,                 loss: nan
agent1:                 episode reward: 0.9376,                 loss: 0.3644
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6576s / 341.3178 s
agent0:                 episode reward: -0.4234,                 loss: nan
agent1:                 episode reward: 0.4234,                 loss: 0.3637
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6662s / 341.9840 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.3667
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6618s / 342.6458 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.3687
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6638s / 343.3096 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.3749
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6623s / 343.9720 s
agent0:                 episode reward: -0.6330,                 loss: nan
agent1:                 episode reward: 0.6330,                 loss: 0.3760
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6574s / 344.6293 s
agent0:                 episode reward: -0.9083,                 loss: nan
agent1:                 episode reward: 0.9083,                 loss: 0.3740
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6580s / 345.2873 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.3768
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6692s / 345.9565 s
agent0:                 episode reward: -1.1990,                 loss: nan
agent1:                 episode reward: 1.1990,                 loss: 0.3749
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6733s / 346.6298 s
agent0:                 episode reward: -0.9700,                 loss: nan
agent1:                 episode reward: 0.9700,                 loss: 0.3753
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6710s / 347.3008 s
agent0:                 episode reward: -0.6454,                 loss: nan
agent1:                 episode reward: 0.6454,                 loss: 0.3736
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6653s / 347.9661 s
agent0:                 episode reward: -0.7215,                 loss: nan
agent1:                 episode reward: 0.7215,                 loss: 0.3723
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 348.6261 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.3738
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 349.2787 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3739
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6629s / 349.9416 s
agent0:                 episode reward: -0.7931,                 loss: nan
agent1:                 episode reward: 0.7931,                 loss: 0.3702
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6666s / 350.6083 s
agent0:                 episode reward: -0.6030,                 loss: nan
agent1:                 episode reward: 0.6030,                 loss: 0.3734
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6651s / 351.2734 s
agent0:                 episode reward: -0.9790,                 loss: nan
agent1:                 episode reward: 0.9790,                 loss: 0.3754
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6626s / 351.9360 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.3749
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6698s / 352.6058 s
agent0:                 episode reward: -0.7626,                 loss: nan
agent1:                 episode reward: 0.7626,                 loss: 0.3726
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6672s / 353.2729 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3741
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6752s / 353.9481 s
agent0:                 episode reward: -0.8396,                 loss: nan
agent1:                 episode reward: 0.8396,                 loss: 0.3767
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6657s / 354.6139 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.3763
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6706s / 355.2844 s
agent0:                 episode reward: -0.3721,                 loss: nan
agent1:                 episode reward: 0.3721,                 loss: 0.3726
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 355.9602 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.3742
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6628s / 356.6230 s
agent0:                 episode reward: -0.6590,                 loss: nan
agent1:                 episode reward: 0.6590,                 loss: 0.3755
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6658s / 357.2888 s
agent0:                 episode reward: -0.6539,                 loss: nan
agent1:                 episode reward: 0.6539,                 loss: 0.3743
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6784s / 357.9673 s
agent0:                 episode reward: -0.6844,                 loss: nan
agent1:                 episode reward: 0.6844,                 loss: 0.3748
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6678s / 358.6350 s
agent0:                 episode reward: -0.4663,                 loss: nan
agent1:                 episode reward: 0.4663,                 loss: 0.3753
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6735s / 359.3085 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.3747
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 359.9854 s
agent0:                 episode reward: -0.9665,                 loss: nan
agent1:                 episode reward: 0.9665,                 loss: 0.3748
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6713s / 360.6567 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.3769
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6830s / 361.3398 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.3745
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6774s / 362.0172 s
agent0:                 episode reward: -0.8435,                 loss: nan
agent1:                 episode reward: 0.8435,                 loss: 0.3747
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6674s / 362.6846 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3761
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6617s / 363.3463 s
agent0:                 episode reward: -0.7608,                 loss: nan
agent1:                 episode reward: 0.7608,                 loss: 0.3765
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6652s / 364.0115 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.3765
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 364.6670 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.3731
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6715s / 365.3385 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3692
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6635s / 366.0020 s
agent0:                 episode reward: -0.5995,                 loss: nan
agent1:                 episode reward: 0.5995,                 loss: 0.3683
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6658s / 366.6678 s
agent0:                 episode reward: -0.5555,                 loss: nan
agent1:                 episode reward: 0.5555,                 loss: 0.3671
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6601s / 367.3279 s
agent0:                 episode reward: -0.8186,                 loss: nan
agent1:                 episode reward: 0.8186,                 loss: 0.3683
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 367.9943 s
agent0:                 episode reward: -1.1142,                 loss: nan
agent1:                 episode reward: 1.1142,                 loss: 0.3650
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6665s / 368.6608 s
agent0:                 episode reward: -0.9885,                 loss: nan
agent1:                 episode reward: 0.9885,                 loss: 0.3668
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6604s / 369.3213 s
agent0:                 episode reward: -0.5893,                 loss: nan
agent1:                 episode reward: 0.5893,                 loss: 0.3677
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6602s / 369.9815 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.3644
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6635s / 370.6449 s
agent0:                 episode reward: -0.9016,                 loss: nan
agent1:                 episode reward: 0.9016,                 loss: 0.3671
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6644s / 371.3093 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: 0.3699
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 371.9904 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.3658
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6691s / 372.6595 s
agent0:                 episode reward: -0.0397,                 loss: nan
agent1:                 episode reward: 0.0397,                 loss: 0.3665
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6651s / 373.3246 s
agent0:                 episode reward: -0.4546,                 loss: nan
agent1:                 episode reward: 0.4546,                 loss: 0.3637
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6682s / 373.9928 s
agent0:                 episode reward: -0.9809,                 loss: nan
agent1:                 episode reward: 0.9809,                 loss: 0.3661
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6755s / 374.6682 s
agent0:                 episode reward: -0.7641,                 loss: nan
agent1:                 episode reward: 0.7641,                 loss: 0.3673
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6774s / 375.3456 s
agent0:                 episode reward: -0.9035,                 loss: nan
agent1:                 episode reward: 0.9035,                 loss: 0.3704
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6668s / 376.0124 s
agent0:                 episode reward: -0.6635,                 loss: nan
agent1:                 episode reward: 0.6635,                 loss: 0.3737
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6742s / 376.6867 s
agent0:                 episode reward: -0.9279,                 loss: nan
agent1:                 episode reward: 0.9279,                 loss: 0.3747
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6701s / 377.3567 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: 0.3754
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6881s / 378.0448 s
agent0:                 episode reward: -0.5670,                 loss: nan
agent1:                 episode reward: 0.5670,                 loss: 0.3761
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6772s / 378.7221 s
agent0:                 episode reward: -0.8955,                 loss: nan
agent1:                 episode reward: 0.8955,                 loss: 0.3766
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6782s / 379.4003 s
agent0:                 episode reward: -0.7978,                 loss: nan
agent1:                 episode reward: 0.7978,                 loss: 0.3769
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6598s / 380.0601 s
agent0:                 episode reward: -0.6783,                 loss: nan
agent1:                 episode reward: 0.6783,                 loss: 0.3760
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6661s / 380.7261 s
agent0:                 episode reward: -0.8325,                 loss: nan
agent1:                 episode reward: 0.8325,                 loss: 0.3787
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6719s / 381.3980 s
agent0:                 episode reward: -0.7396,                 loss: nan
agent1:                 episode reward: 0.7396,                 loss: 0.3747
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6631s / 382.0612 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.3778
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6711s / 382.7323 s
agent0:                 episode reward: -0.6644,                 loss: nan
agent1:                 episode reward: 0.6644,                 loss: 0.3751
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6889s / 383.4212 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.3764
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6718s / 384.0930 s
agent0:                 episode reward: -0.8465,                 loss: nan
agent1:                 episode reward: 0.8465,                 loss: 0.3765
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6752s / 384.7682 s
agent0:                 episode reward: -0.7763,                 loss: nan
agent1:                 episode reward: 0.7763,                 loss: 0.3728
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6796s / 385.4478 s
agent0:                 episode reward: -0.6967,                 loss: nan
agent1:                 episode reward: 0.6967,                 loss: 0.3746
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6722s / 386.1201 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3762
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6687s / 386.7888 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.3745
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6687s / 387.4575 s
agent0:                 episode reward: -0.8683,                 loss: nan
agent1:                 episode reward: 0.8683,                 loss: 0.3741
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6766s / 388.1341 s
agent0:                 episode reward: -0.7430,                 loss: nan
agent1:                 episode reward: 0.7430,                 loss: 0.3724
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6658s / 388.7999 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.3711
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6756s / 389.4755 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.3708
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6757s / 390.1512 s
agent0:                 episode reward: -0.4392,                 loss: nan
agent1:                 episode reward: 0.4392,                 loss: 0.3715
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6754s / 390.8266 s
agent0:                 episode reward: -0.9054,                 loss: nan
agent1:                 episode reward: 0.9054,                 loss: 0.3686
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 391.5024 s
agent0:                 episode reward: -0.7447,                 loss: nan
agent1:                 episode reward: 0.7447,                 loss: 0.3718
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6636s / 392.1660 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3742
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6765s / 392.8425 s
agent0:                 episode reward: -0.6457,                 loss: nan
agent1:                 episode reward: 0.6457,                 loss: 0.3701
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6577s / 393.5003 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.3732
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6704s / 394.1707 s
agent0:                 episode reward: -0.8958,                 loss: nan
agent1:                 episode reward: 0.8958,                 loss: 0.3746
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6658s / 394.8365 s
agent0:                 episode reward: -0.7772,                 loss: nan
agent1:                 episode reward: 0.7772,                 loss: 0.3726
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 395.5182 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.3745
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6667s / 396.1849 s
agent0:                 episode reward: -0.8083,                 loss: nan
agent1:                 episode reward: 0.8083,                 loss: 0.3713
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6869s / 396.8718 s
agent0:                 episode reward: -0.2712,                 loss: nan
agent1:                 episode reward: 0.2712,                 loss: 0.3726
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6872s / 397.5591 s
agent0:                 episode reward: -0.4718,                 loss: nan
agent1:                 episode reward: 0.4718,                 loss: 0.3714
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6713s / 398.2304 s
agent0:                 episode reward: -0.9011,                 loss: nan
agent1:                 episode reward: 0.9011,                 loss: 0.3724
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6797s / 398.9101 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.3624
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6891s / 399.5992 s
agent0:                 episode reward: -0.9030,                 loss: nan
agent1:                 episode reward: 0.9030,                 loss: 0.3602
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6707s / 400.2698 s
agent0:                 episode reward: -1.1578,                 loss: nan
agent1:                 episode reward: 1.1578,                 loss: 0.3608
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6783s / 400.9481 s
agent0:                 episode reward: -0.6985,                 loss: nan
agent1:                 episode reward: 0.6985,                 loss: 0.3575
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6870s / 401.6352 s
agent0:                 episode reward: -0.5183,                 loss: nan
agent1:                 episode reward: 0.5183,                 loss: 0.3614
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6796s / 402.3147 s
agent0:                 episode reward: -0.9571,                 loss: nan
agent1:                 episode reward: 0.9571,                 loss: 0.3590
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6703s / 402.9850 s
agent0:                 episode reward: -0.8282,                 loss: nan
agent1:                 episode reward: 0.8282,                 loss: 0.3628
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6820s / 403.6670 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.3574
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6837s / 404.3507 s
agent0:                 episode reward: -1.1556,                 loss: nan
agent1:                 episode reward: 1.1556,                 loss: 0.3610
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6878s / 405.0385 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3577
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6797s / 405.7181 s
agent0:                 episode reward: -0.3099,                 loss: nan
agent1:                 episode reward: 0.3099,                 loss: 0.3594
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6803s / 406.3984 s
agent0:                 episode reward: -0.9404,                 loss: nan
agent1:                 episode reward: 0.9404,                 loss: 0.3574
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6794s / 407.0778 s
agent0:                 episode reward: -0.9612,                 loss: nan
agent1:                 episode reward: 0.9612,                 loss: 0.3589
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6733s / 407.7510 s
agent0:                 episode reward: -0.3935,                 loss: nan
agent1:                 episode reward: 0.3935,                 loss: 0.3592
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 408.4296 s
agent0:                 episode reward: -0.7959,                 loss: nan
agent1:                 episode reward: 0.7959,                 loss: 0.3583
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6779s / 409.1075 s
agent0:                 episode reward: -0.8853,                 loss: nan
agent1:                 episode reward: 0.8853,                 loss: 0.3573
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6837s / 409.7912 s
agent0:                 episode reward: -0.5289,                 loss: nan
agent1:                 episode reward: 0.5289,                 loss: 0.3651
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6836s / 410.4748 s
agent0:                 episode reward: -1.0273,                 loss: nan
agent1:                 episode reward: 1.0273,                 loss: 0.3757
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6811s / 411.1560 s
agent0:                 episode reward: -0.4527,                 loss: nan
agent1:                 episode reward: 0.4527,                 loss: 0.3785
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6795s / 411.8355 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.3784
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6833s / 412.5188 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.3778
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6773s / 413.1961 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.3769
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6777s / 413.8738 s
agent0:                 episode reward: -0.6551,                 loss: nan
agent1:                 episode reward: 0.6551,                 loss: 0.3773
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6855s / 414.5593 s
agent0:                 episode reward: -0.7046,                 loss: nan
agent1:                 episode reward: 0.7046,                 loss: 0.3801
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6833s / 415.2425 s
agent0:                 episode reward: -0.8292,                 loss: nan
agent1:                 episode reward: 0.8292,                 loss: 0.3780
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6894s / 415.9320 s
agent0:                 episode reward: -0.5304,                 loss: nan
agent1:                 episode reward: 0.5304,                 loss: 0.3781
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6827s / 416.6146 s
agent0:                 episode reward: -1.2503,                 loss: nan
agent1:                 episode reward: 1.2503,                 loss: 0.3790
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 417.2926 s
agent0:                 episode reward: -0.7305,                 loss: nan
agent1:                 episode reward: 0.7305,                 loss: 0.3783
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 417.9695 s
agent0:                 episode reward: -0.5066,                 loss: nan
agent1:                 episode reward: 0.5066,                 loss: 0.3781
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 418.6434 s
agent0:                 episode reward: -1.0705,                 loss: nan
agent1:                 episode reward: 1.0705,                 loss: 0.3775
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6793s / 419.3228 s
agent0:                 episode reward: -0.6017,                 loss: nan
agent1:                 episode reward: 0.6017,                 loss: 0.3770
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6803s / 420.0031 s
agent0:                 episode reward: -0.2634,                 loss: nan
agent1:                 episode reward: 0.2634,                 loss: 0.3769
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6915s / 420.6946 s
agent0:                 episode reward: -1.0937,                 loss: nan
agent1:                 episode reward: 1.0937,                 loss: 0.3797
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6744s / 421.3690 s
agent0:                 episode reward: -1.0082,                 loss: nan
agent1:                 episode reward: 1.0082,                 loss: 0.3756
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6940s / 422.0631 s
agent0:                 episode reward: -0.4843,                 loss: nan
agent1:                 episode reward: 0.4843,                 loss: 0.3720
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6876s / 422.7506 s
agent0:                 episode reward: -0.5325,                 loss: nan
agent1:                 episode reward: 0.5325,                 loss: 0.3718
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6822s / 423.4328 s
agent0:                 episode reward: -0.8898,                 loss: nan
agent1:                 episode reward: 0.8898,                 loss: 0.3721
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6721s / 424.1048 s
agent0:                 episode reward: -0.8286,                 loss: nan
agent1:                 episode reward: 0.8286,                 loss: 0.3692
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 424.7839 s
agent0:                 episode reward: -0.9963,                 loss: nan
agent1:                 episode reward: 0.9963,                 loss: 0.3711
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6872s / 425.4710 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.3735
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6906s / 426.1617 s
agent0:                 episode reward: -0.5176,                 loss: nan
agent1:                 episode reward: 0.5176,                 loss: 0.3705
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6816s / 426.8432 s
agent0:                 episode reward: -0.7513,                 loss: nan
agent1:                 episode reward: 0.7513,                 loss: 0.3723
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6910s / 427.5342 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.3694
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6784s / 428.2126 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.3707
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6849s / 428.8975 s
agent0:                 episode reward: -1.0536,                 loss: nan
agent1:                 episode reward: 1.0536,                 loss: 0.3722
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6867s / 429.5842 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.3738
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6841s / 430.2683 s
agent0:                 episode reward: -0.8228,                 loss: nan
agent1:                 episode reward: 0.8228,                 loss: 0.3743
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6877s / 430.9559 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.3709
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 431.6417 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.3726
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6864s / 432.3281 s
agent0:                 episode reward: -1.0046,                 loss: nan
agent1:                 episode reward: 1.0046,                 loss: 0.3721
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7131s / 433.0413 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: 0.3647
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6987s / 433.7400 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.3608
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6990s / 434.4390 s
agent0:                 episode reward: -0.9212,                 loss: nan
agent1:                 episode reward: 0.9212,                 loss: 0.3587
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6883s / 435.1273 s
agent0:                 episode reward: -0.7767,                 loss: nan
agent1:                 episode reward: 0.7767,                 loss: 0.3616
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6849s / 435.8123 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.3591
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7014s / 436.5137 s
agent0:                 episode reward: -1.0132,                 loss: nan
agent1:                 episode reward: 1.0132,                 loss: 0.3591
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6915s / 437.2052 s
agent0:                 episode reward: -0.9102,                 loss: nan
agent1:                 episode reward: 0.9102,                 loss: 0.3581
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6951s / 437.9003 s
agent0:                 episode reward: -0.8396,                 loss: nan
agent1:                 episode reward: 0.8396,                 loss: 0.3597
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6904s / 438.5908 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.3590
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7000s / 439.2908 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3581
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6903s / 439.9811 s
agent0:                 episode reward: -0.9002,                 loss: nan
agent1:                 episode reward: 0.9002,                 loss: 0.3589
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6912s / 440.6723 s
agent0:                 episode reward: -0.8499,                 loss: nan
agent1:                 episode reward: 0.8499,                 loss: 0.3613
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6914s / 441.3637 s
agent0:                 episode reward: -0.8292,                 loss: nan
agent1:                 episode reward: 0.8292,                 loss: 0.3591
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7008s / 442.0645 s
agent0:                 episode reward: -0.3127,                 loss: nan
agent1:                 episode reward: 0.3127,                 loss: 0.3598
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7109s / 442.7754 s
agent0:                 episode reward: -0.8916,                 loss: nan
agent1:                 episode reward: 0.8916,                 loss: 0.3594
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6911s / 443.4665 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: 0.3624
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6888s / 444.1553 s
agent0:                 episode reward: -0.9543,                 loss: nan
agent1:                 episode reward: 0.9543,                 loss: 0.3674
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6968s / 444.8522 s
agent0:                 episode reward: -0.8093,                 loss: nan
agent1:                 episode reward: 0.8093,                 loss: 0.3782
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7039s / 445.5561 s
agent0:                 episode reward: -0.8492,                 loss: nan
agent1:                 episode reward: 0.8492,                 loss: 0.3785
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6880s / 446.2441 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.3779
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6943s / 446.9384 s
agent0:                 episode reward: -0.4632,                 loss: nan
agent1:                 episode reward: 0.4632,                 loss: 0.3777
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6979s / 447.6363 s
agent0:                 episode reward: -0.6231,                 loss: nan
agent1:                 episode reward: 0.6231,                 loss: 0.3784
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6947s / 448.3310 s
agent0:                 episode reward: -0.6323,                 loss: nan
agent1:                 episode reward: 0.6323,                 loss: 0.3780
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6878s / 449.0189 s
agent0:                 episode reward: -0.8183,                 loss: nan
agent1:                 episode reward: 0.8183,                 loss: 0.3785
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 449.7106 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.3797
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7051s / 450.4157 s
agent0:                 episode reward: -0.8804,                 loss: nan
agent1:                 episode reward: 0.8804,                 loss: 0.3783
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6911s / 451.1068 s
agent0:                 episode reward: -0.8327,                 loss: nan
agent1:                 episode reward: 0.8327,                 loss: 0.3767
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6984s / 451.8052 s
agent0:                 episode reward: -0.6609,                 loss: nan
agent1:                 episode reward: 0.6609,                 loss: 0.3788
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7078s / 452.5130 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.3788
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6893s / 453.2023 s
agent0:                 episode reward: -0.8351,                 loss: nan
agent1:                 episode reward: 0.8351,                 loss: 0.3796
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6948s / 453.8972 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.3780
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6972s / 454.5944 s
agent0:                 episode reward: -0.9034,                 loss: nan
agent1:                 episode reward: 0.9034,                 loss: 0.3762
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6949s / 455.2893 s
agent0:                 episode reward: -0.1635,                 loss: nan
agent1:                 episode reward: 0.1635,                 loss: 0.3797
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6951s / 455.9844 s
agent0:                 episode reward: -0.9354,                 loss: nan
agent1:                 episode reward: 0.9354,                 loss: 0.3706
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7019s / 456.6863 s
agent0:                 episode reward: -0.9337,                 loss: nan
agent1:                 episode reward: 0.9337,                 loss: 0.3676
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6958s / 457.3821 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.3678
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6925s / 458.0747 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.3679
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6948s / 458.7694 s
agent0:                 episode reward: -0.6843,                 loss: nan
agent1:                 episode reward: 0.6843,                 loss: 0.3657
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6971s / 459.4665 s
agent0:                 episode reward: -0.6040,                 loss: nan
agent1:                 episode reward: 0.6040,                 loss: 0.3655
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6910s / 460.1575 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.3666
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7019s / 460.8594 s
agent0:                 episode reward: -0.6647,                 loss: nan
agent1:                 episode reward: 0.6647,                 loss: 0.3664
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6948s / 461.5542 s
agent0:                 episode reward: -0.8465,                 loss: nan
agent1:                 episode reward: 0.8465,                 loss: 0.3680
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6959s / 462.2501 s
agent0:                 episode reward: -0.6207,                 loss: nan
agent1:                 episode reward: 0.6207,                 loss: 0.3662
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7022s / 462.9523 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.3706
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6961s / 463.6484 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.3665
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6996s / 464.3480 s
agent0:                 episode reward: -0.5430,                 loss: nan
agent1:                 episode reward: 0.5430,                 loss: 0.3685
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6995s / 465.0475 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3663
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7021s / 465.7496 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.3677
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7113s / 466.4609 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3674
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7118s / 467.1727 s
agent0:                 episode reward: -0.6362,                 loss: nan
agent1:                 episode reward: 0.6362,                 loss: 0.3661
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7093s / 467.8820 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.3668
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7145s / 468.5965 s
agent0:                 episode reward: -0.5086,                 loss: nan
agent1:                 episode reward: 0.5086,                 loss: 0.3612
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7101s / 469.3067 s
agent0:                 episode reward: -1.0115,                 loss: nan
agent1:                 episode reward: 1.0115,                 loss: 0.3635
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7117s / 470.0183 s
agent0:                 episode reward: -0.5438,                 loss: nan
agent1:                 episode reward: 0.5438,                 loss: 0.3629
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7127s / 470.7310 s
agent0:                 episode reward: -0.9517,                 loss: nan
agent1:                 episode reward: 0.9517,                 loss: 0.3642
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7017s / 471.4327 s
agent0:                 episode reward: -0.8123,                 loss: nan
agent1:                 episode reward: 0.8123,                 loss: 0.3633
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7073s / 472.1400 s
agent0:                 episode reward: -0.6264,                 loss: nan
agent1:                 episode reward: 0.6264,                 loss: 0.3634
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7293s / 472.8693 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3624
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7241s / 473.5934 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.3614
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7086s / 474.3020 s
agent0:                 episode reward: -0.9294,                 loss: nan
agent1:                 episode reward: 0.9294,                 loss: 0.3617
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7093s / 475.0113 s
agent0:                 episode reward: -0.8308,                 loss: nan
agent1:                 episode reward: 0.8308,                 loss: 0.3634
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7069s / 475.7182 s
agent0:                 episode reward: -0.5590,                 loss: nan
agent1:                 episode reward: 0.5590,                 loss: 0.3626
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 476.4348 s
agent0:                 episode reward: -0.6434,                 loss: nan
agent1:                 episode reward: 0.6434,                 loss: 0.3617
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7152s / 477.1501 s
agent0:                 episode reward: -0.9809,                 loss: nan
agent1:                 episode reward: 0.9809,                 loss: 0.3625
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7085s / 477.8586 s
agent0:                 episode reward: -0.6032,                 loss: nan
agent1:                 episode reward: 0.6032,                 loss: 0.3631
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7061s / 478.5647 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.3645
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7194s / 479.2841 s
agent0:                 episode reward: -0.6913,                 loss: nan
agent1:                 episode reward: 0.6913,                 loss: 0.3715
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7065s / 479.9906 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.3800
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7026s / 480.6931 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.3783
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7077s / 481.4008 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.3795
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7155s / 482.1163 s
agent0:                 episode reward: -0.8405,                 loss: nan
agent1:                 episode reward: 0.8405,                 loss: 0.3825
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7092s / 482.8254 s
agent0:                 episode reward: -1.0317,                 loss: nan
agent1:                 episode reward: 1.0317,                 loss: 0.3790
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7155s / 483.5409 s
agent0:                 episode reward: -0.5461,                 loss: nan
agent1:                 episode reward: 0.5461,                 loss: 0.3816
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7137s / 484.2546 s
agent0:                 episode reward: -0.6725,                 loss: nan
agent1:                 episode reward: 0.6725,                 loss: 0.3810
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7153s / 484.9699 s
agent0:                 episode reward: -0.8677,                 loss: nan
agent1:                 episode reward: 0.8677,                 loss: 0.3793
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7146s / 485.6845 s
agent0:                 episode reward: -0.7060,                 loss: nan
agent1:                 episode reward: 0.7060,                 loss: 0.3792
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7125s / 486.3970 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: 0.3803
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7264s / 487.1234 s
agent0:                 episode reward: -0.9994,                 loss: nan
agent1:                 episode reward: 0.9994,                 loss: 0.3770
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7231s / 487.8466 s
agent0:                 episode reward: -0.8144,                 loss: nan
agent1:                 episode reward: 0.8144,                 loss: 0.3792
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7081s / 488.5547 s
agent0:                 episode reward: -0.8608,                 loss: nan
agent1:                 episode reward: 0.8608,                 loss: 0.3788
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7180s / 489.2727 s
agent0:                 episode reward: -1.1185,                 loss: nan
agent1:                 episode reward: 1.1185,                 loss: 0.3792
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7116s / 489.9844 s
agent0:                 episode reward: -0.9538,                 loss: nan
agent1:                 episode reward: 0.9538,                 loss: 0.3816
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 490.7012 s
agent0:                 episode reward: -0.7642,                 loss: nan
agent1:                 episode reward: 0.7642,                 loss: 0.3783
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7118s / 491.4131 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.3727
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7075s / 492.1205 s
agent0:                 episode reward: -0.5566,                 loss: nan
agent1:                 episode reward: 0.5566,                 loss: 0.3669
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7163s / 492.8368 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.3689
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7156s / 493.5524 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.3702
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7185s / 494.2710 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: 0.3696
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7201s / 494.9911 s
agent0:                 episode reward: -0.9817,                 loss: nan
agent1:                 episode reward: 0.9817,                 loss: 0.3690
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7085s / 495.6996 s
agent0:                 episode reward: -0.4364,                 loss: nan
agent1:                 episode reward: 0.4364,                 loss: 0.3668
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7096s / 496.4093 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.3659
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7105s / 497.1197 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.3683
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7174s / 497.8371 s
agent0:                 episode reward: -0.4667,                 loss: nan
agent1:                 episode reward: 0.4667,                 loss: 0.3690
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7152s / 498.5523 s
agent0:                 episode reward: -0.6709,                 loss: nan
agent1:                 episode reward: 0.6709,                 loss: 0.3690
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7173s / 499.2696 s
agent0:                 episode reward: -0.8349,                 loss: nan
agent1:                 episode reward: 0.8349,                 loss: 0.3669
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7236s / 499.9931 s
agent0:                 episode reward: -0.7923,                 loss: nan
agent1:                 episode reward: 0.7923,                 loss: 0.3700
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7246s / 500.7178 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.3700
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7315s / 501.4492 s
agent0:                 episode reward: -0.3341,                 loss: nan
agent1:                 episode reward: 0.3341,                 loss: 0.3688
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7314s / 502.1806 s
agent0:                 episode reward: -0.7900,                 loss: nan
agent1:                 episode reward: 0.7900,                 loss: 0.3709
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7244s / 502.9050 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3698
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7359s / 503.6409 s
agent0:                 episode reward: -0.6415,                 loss: nan
agent1:                 episode reward: 0.6415,                 loss: 0.3671
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7272s / 504.3682 s
agent0:                 episode reward: -0.9234,                 loss: nan
agent1:                 episode reward: 0.9234,                 loss: 0.3639
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7269s / 505.0950 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.3649
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7228s / 505.8179 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.3644
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7228s / 506.5406 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.3636
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7164s / 507.2571 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.3636
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7443s / 508.0014 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.3632
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7241s / 508.7254 s
agent0:                 episode reward: -0.8836,                 loss: nan
agent1:                 episode reward: 0.8836,                 loss: 0.3653
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7168s / 509.4423 s
agent0:                 episode reward: -1.1359,                 loss: nan
agent1:                 episode reward: 1.1359,                 loss: 0.3625
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7197s / 510.1620 s
agent0:                 episode reward: -0.6326,                 loss: nan
agent1:                 episode reward: 0.6326,                 loss: 0.3639
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7248s / 510.8868 s
agent0:                 episode reward: -0.7304,                 loss: nan
agent1:                 episode reward: 0.7304,                 loss: 0.3617
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7209s / 511.6077 s
agent0:                 episode reward: -0.8899,                 loss: nan
agent1:                 episode reward: 0.8899,                 loss: 0.3637
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7292s / 512.3369 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.3654
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7137s / 513.0506 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.3628
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7126s / 513.7632 s
agent0:                 episode reward: -1.2227,                 loss: nan
agent1:                 episode reward: 1.2227,                 loss: 0.3640
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7213s / 514.4845 s
agent0:                 episode reward: -0.9481,                 loss: nan
agent1:                 episode reward: 0.9481,                 loss: 0.3622
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7248s / 515.2093 s
agent0:                 episode reward: -0.8750,                 loss: nan
agent1:                 episode reward: 0.8750,                 loss: 0.3722
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7140s / 515.9233 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.3790
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7364s / 516.6598 s
agent0:                 episode reward: -0.8731,                 loss: nan
agent1:                 episode reward: 0.8731,                 loss: 0.3786
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7147s / 517.3745 s
agent0:                 episode reward: -1.0109,                 loss: nan
agent1:                 episode reward: 1.0109,                 loss: 0.3784
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7339s / 518.1084 s
agent0:                 episode reward: -0.6441,                 loss: nan
agent1:                 episode reward: 0.6441,                 loss: 0.3766
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7236s / 518.8321 s
agent0:                 episode reward: -0.7785,                 loss: nan
agent1:                 episode reward: 0.7785,                 loss: 0.3768
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7168s / 519.5489 s
agent0:                 episode reward: -0.7056,                 loss: nan
agent1:                 episode reward: 0.7056,                 loss: 0.3780
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7290s / 520.2780 s
agent0:                 episode reward: -0.6837,                 loss: nan
agent1:                 episode reward: 0.6837,                 loss: 0.3760
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7133s / 520.9912 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.3763
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7131s / 521.7043 s
agent0:                 episode reward: -0.9018,                 loss: nan
agent1:                 episode reward: 0.9018,                 loss: 0.3794
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7218s / 522.4261 s
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.3758
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7207s / 523.1468 s
agent0:                 episode reward: -0.8872,                 loss: nan
agent1:                 episode reward: 0.8872,                 loss: 0.3774
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7161s / 523.8629 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.3752
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 524.5835 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.3750
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7255s / 525.3090 s
agent0:                 episode reward: -0.4306,                 loss: nan
agent1:                 episode reward: 0.4306,                 loss: 0.3773
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7200s / 526.0291 s
agent0:                 episode reward: -0.5779,                 loss: nan
agent1:                 episode reward: 0.5779,                 loss: 0.3774
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7176s / 526.7467 s
agent0:                 episode reward: -0.9652,                 loss: nan
agent1:                 episode reward: 0.9652,                 loss: 0.3766
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7226s / 527.4693 s
agent0:                 episode reward: -0.7740,                 loss: nan
agent1:                 episode reward: 0.7740,                 loss: 0.3701
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7264s / 528.1957 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.3618
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7259s / 528.9216 s
agent0:                 episode reward: -1.1803,                 loss: nan
agent1:                 episode reward: 1.1803,                 loss: 0.3601
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7199s / 529.6415 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.3623
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7211s / 530.3626 s
agent0:                 episode reward: -1.1477,                 loss: nan
agent1:                 episode reward: 1.1477,                 loss: 0.3607
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 531.0795 s
agent0:                 episode reward: -0.2622,                 loss: nan
agent1:                 episode reward: 0.2622,                 loss: 0.3617
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7161s / 531.7956 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.3588
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7315s / 532.5271 s
agent0:                 episode reward: -0.4653,                 loss: nan
agent1:                 episode reward: 0.4653,                 loss: 0.3607
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7191s / 533.2462 s
agent0:                 episode reward: -0.7093,                 loss: nan
agent1:                 episode reward: 0.7093,                 loss: 0.3600
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7271s / 533.9734 s
agent0:                 episode reward: -1.2373,                 loss: nan
agent1:                 episode reward: 1.2373,                 loss: 0.3617
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7326s / 534.7059 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3621
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7289s / 535.4348 s
agent0:                 episode reward: -0.6972,                 loss: nan
agent1:                 episode reward: 0.6972,                 loss: 0.3608
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7299s / 536.1648 s
agent0:                 episode reward: -0.6870,                 loss: nan
agent1:                 episode reward: 0.6870,                 loss: 0.3611
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7277s / 536.8924 s
agent0:                 episode reward: -0.7466,                 loss: nan
agent1:                 episode reward: 0.7466,                 loss: 0.3594
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7291s / 537.6216 s
agent0:                 episode reward: -0.6169,                 loss: nan
agent1:                 episode reward: 0.6169,                 loss: 0.3609
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7239s / 538.3454 s
agent0:                 episode reward: -0.8591,                 loss: nan
agent1:                 episode reward: 0.8591,                 loss: 0.3587
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7281s / 539.0735 s
agent0:                 episode reward: -0.5097,                 loss: nan
agent1:                 episode reward: 0.5097,                 loss: 0.3629
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7312s / 539.8047 s
agent0:                 episode reward: -0.8031,                 loss: nan
agent1:                 episode reward: 0.8031,                 loss: 0.3701
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7187s / 540.5233 s
agent0:                 episode reward: -0.8703,                 loss: nan
agent1:                 episode reward: 0.8703,                 loss: 0.3725
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7090s / 541.2324 s
agent0:                 episode reward: -0.2702,                 loss: nan
agent1:                 episode reward: 0.2702,                 loss: 0.3703
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7297s / 541.9621 s
agent0:                 episode reward: -0.9690,                 loss: nan
agent1:                 episode reward: 0.9690,                 loss: 0.3687
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7078s / 542.6699 s
agent0:                 episode reward: -0.9882,                 loss: nan
agent1:                 episode reward: 0.9882,                 loss: 0.3680
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7185s / 543.3884 s
agent0:                 episode reward: -0.5706,                 loss: nan
agent1:                 episode reward: 0.5706,                 loss: 0.3665
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7196s / 544.1080 s
agent0:                 episode reward: -0.7376,                 loss: nan
agent1:                 episode reward: 0.7376,                 loss: 0.3718
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7283s / 544.8362 s
agent0:                 episode reward: -0.9936,                 loss: nan
agent1:                 episode reward: 0.9936,                 loss: 0.3685
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7479s / 545.5841 s
agent0:                 episode reward: -0.5221,                 loss: nan
agent1:                 episode reward: 0.5221,                 loss: 0.3697
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7407s / 546.3247 s
agent0:                 episode reward: -0.5571,                 loss: nan
agent1:                 episode reward: 0.5571,                 loss: 0.3689
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7378s / 547.0626 s
agent0:                 episode reward: -0.2224,                 loss: nan
agent1:                 episode reward: 0.2224,                 loss: 0.3682
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7349s / 547.7975 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.3698
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7403s / 548.5378 s
agent0:                 episode reward: -0.6286,                 loss: nan
agent1:                 episode reward: 0.6286,                 loss: 0.3712
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 549.2860 s
agent0:                 episode reward: -0.8264,                 loss: nan
agent1:                 episode reward: 0.8264,                 loss: 0.3672
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7402s / 550.0262 s
agent0:                 episode reward: -0.3944,                 loss: nan
agent1:                 episode reward: 0.3944,                 loss: 0.3705
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7449s / 550.7711 s
agent0:                 episode reward: -0.6489,                 loss: nan
agent1:                 episode reward: 0.6489,                 loss: 0.3722
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7402s / 551.5113 s
agent0:                 episode reward: -0.1827,                 loss: nan
agent1:                 episode reward: 0.1827,                 loss: 0.3742
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7430s / 552.2542 s
agent0:                 episode reward: -0.9068,                 loss: nan
agent1:                 episode reward: 0.9068,                 loss: 0.3777
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7524s / 553.0067 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.3796
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7452s / 553.7519 s
agent0:                 episode reward: -0.5577,                 loss: nan
agent1:                 episode reward: 0.5577,                 loss: 0.3775
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7313s / 554.4831 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.3765
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7323s / 555.2154 s
agent0:                 episode reward: -0.7841,                 loss: nan
agent1:                 episode reward: 0.7841,                 loss: 0.3773
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7498s / 555.9652 s
agent0:                 episode reward: -0.8487,                 loss: nan
agent1:                 episode reward: 0.8487,                 loss: 0.3768
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7466s / 556.7118 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.3784
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7472s / 557.4590 s
agent0:                 episode reward: -0.5767,                 loss: nan
agent1:                 episode reward: 0.5767,                 loss: 0.3780
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7436s / 558.2026 s
agent0:                 episode reward: -1.0650,                 loss: nan
agent1:                 episode reward: 1.0650,                 loss: 0.3766
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7294s / 558.9319 s
agent0:                 episode reward: -0.4064,                 loss: nan
agent1:                 episode reward: 0.4064,                 loss: 0.3758
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7407s / 559.6726 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3765
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7438s / 560.4164 s
agent0:                 episode reward: -0.9485,                 loss: nan
agent1:                 episode reward: 0.9485,                 loss: 0.3732
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7320s / 561.1484 s
agent0:                 episode reward: -0.6910,                 loss: nan
agent1:                 episode reward: 0.6910,                 loss: 0.3767
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7373s / 561.8858 s
agent0:                 episode reward: -0.9773,                 loss: nan
agent1:                 episode reward: 0.9773,                 loss: 0.3753
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7312s / 562.6170 s
agent0:                 episode reward: -0.7943,                 loss: nan
agent1:                 episode reward: 0.7943,                 loss: 0.3781
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7318s / 563.3488 s
agent0:                 episode reward: -0.6567,                 loss: nan
agent1:                 episode reward: 0.6567,                 loss: 0.3739
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7608s / 564.1096 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.3705
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7382s / 564.8478 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.3617
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7380s / 565.5858 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.3632
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7412s / 566.3269 s
agent0:                 episode reward: -0.4716,                 loss: nan
agent1:                 episode reward: 0.4716,                 loss: 0.3648
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7393s / 567.0662 s
agent0:                 episode reward: -0.7051,                 loss: nan
agent1:                 episode reward: 0.7051,                 loss: 0.3647
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7323s / 567.7985 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.3630
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7401s / 568.5386 s
agent0:                 episode reward: -0.8326,                 loss: nan
agent1:                 episode reward: 0.8326,                 loss: 0.3666
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7341s / 569.2727 s
agent0:                 episode reward: -0.9031,                 loss: nan
agent1:                 episode reward: 0.9031,                 loss: 0.3641
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7302s / 570.0028 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.3672
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7430s / 570.7459 s
agent0:                 episode reward: -0.0087,                 loss: nan
agent1:                 episode reward: 0.0087,                 loss: 0.3663
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7429s / 571.4888 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: 0.3668
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7496s / 572.2384 s
agent0:                 episode reward: -0.8223,                 loss: nan
agent1:                 episode reward: 0.8223,                 loss: 0.3628
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7339s / 572.9723 s
agent0:                 episode reward: -0.8018,                 loss: nan
agent1:                 episode reward: 0.8018,                 loss: 0.3659
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7375s / 573.7098 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.3634
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7396s / 574.4494 s
agent0:                 episode reward: -0.4909,                 loss: nan
agent1:                 episode reward: 0.4909,                 loss: 0.3645
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7459s / 575.1953 s
agent0:                 episode reward: -0.6848,                 loss: nan
agent1:                 episode reward: 0.6848,                 loss: 0.3633
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 575.9481 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.3646
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 576.6969 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.3671
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7336s / 577.4305 s
agent0:                 episode reward: -0.2631,                 loss: nan
agent1:                 episode reward: 0.2631,                 loss: 0.3670
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7309s / 578.1614 s
agent0:                 episode reward: -0.9092,                 loss: nan
agent1:                 episode reward: 0.9092,                 loss: 0.3706
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7538s / 578.9152 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.3673
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7402s / 579.6554 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.3662
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7539s / 580.4093 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.3644
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7413s / 581.1506 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.3658
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7439s / 581.8945 s
agent0:                 episode reward: -0.7612,                 loss: nan
agent1:                 episode reward: 0.7612,                 loss: 0.3693
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7388s / 582.6332 s
agent0:                 episode reward: -0.8544,                 loss: nan
agent1:                 episode reward: 0.8544,                 loss: 0.3641
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7536s / 583.3868 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3686
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7480s / 584.1348 s
agent0:                 episode reward: -0.1951,                 loss: nan
agent1:                 episode reward: 0.1951,                 loss: 0.3666
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7462s / 584.8810 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.3667
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7515s / 585.6325 s
agent0:                 episode reward: -0.7076,                 loss: nan
agent1:                 episode reward: 0.7076,                 loss: 0.3643
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7446s / 586.3771 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.3661
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7466s / 587.1237 s
agent0:                 episode reward: -1.0595,                 loss: nan
agent1:                 episode reward: 1.0595,                 loss: 0.3640
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7471s / 587.8708 s
agent0:                 episode reward: -0.8571,                 loss: nan
agent1:                 episode reward: 0.8571,                 loss: 0.3659
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7449s / 588.6158 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: 0.3728
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7502s / 589.3660 s
agent0:                 episode reward: -1.0022,                 loss: nan
agent1:                 episode reward: 1.0022,                 loss: 0.3792
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7546s / 590.1205 s
agent0:                 episode reward: -0.9269,                 loss: nan
agent1:                 episode reward: 0.9269,                 loss: 0.3779
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7507s / 590.8713 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.3759
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7549s / 591.6261 s
agent0:                 episode reward: -0.6305,                 loss: nan
agent1:                 episode reward: 0.6305,                 loss: 0.3758
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7613s / 592.3875 s
agent0:                 episode reward: -0.6987,                 loss: nan
agent1:                 episode reward: 0.6987,                 loss: 0.3799
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7457s / 593.1331 s
agent0:                 episode reward: -0.5762,                 loss: nan
agent1:                 episode reward: 0.5762,                 loss: 0.3804
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7532s / 593.8863 s
agent0:                 episode reward: -0.7600,                 loss: nan
agent1:                 episode reward: 0.7600,                 loss: 0.3797
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7533s / 594.6396 s
agent0:                 episode reward: -0.8306,                 loss: nan
agent1:                 episode reward: 0.8306,                 loss: 0.3775
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7603s / 595.3999 s
agent0:                 episode reward: -0.7836,                 loss: nan
agent1:                 episode reward: 0.7836,                 loss: 0.3788
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7489s / 596.1488 s
agent0:                 episode reward: -1.1335,                 loss: nan
agent1:                 episode reward: 1.1335,                 loss: 0.3752
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7559s / 596.9047 s
agent0:                 episode reward: -0.7214,                 loss: nan
agent1:                 episode reward: 0.7214,                 loss: 0.3770
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7474s / 597.6521 s
agent0:                 episode reward: -0.9675,                 loss: nan
agent1:                 episode reward: 0.9675,                 loss: 0.3785
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7537s / 598.4058 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.3781
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 599.1593 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.3789
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7573s / 599.9165 s
agent0:                 episode reward: -0.5908,                 loss: nan
agent1:                 episode reward: 0.5908,                 loss: 0.3784
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7629s / 600.6795 s
agent0:                 episode reward: -0.8985,                 loss: nan
agent1:                 episode reward: 0.8985,                 loss: 0.3765
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7583s / 601.4377 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: 0.3699
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 602.1906 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3660
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7457s / 602.9362 s
agent0:                 episode reward: -0.6654,                 loss: nan
agent1:                 episode reward: 0.6654,                 loss: 0.3658
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7611s / 603.6974 s
agent0:                 episode reward: -0.7693,                 loss: nan
agent1:                 episode reward: 0.7693,                 loss: 0.3645
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7645s / 604.4619 s
agent0:                 episode reward: -0.9229,                 loss: nan
agent1:                 episode reward: 0.9229,                 loss: 0.3665
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7604s / 605.2224 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.3637
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7625s / 605.9849 s
agent0:                 episode reward: -0.0448,                 loss: nan
agent1:                 episode reward: 0.0448,                 loss: 0.3651
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7524s / 606.7373 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.3654
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7581s / 607.4954 s
agent0:                 episode reward: -0.6682,                 loss: nan
agent1:                 episode reward: 0.6682,                 loss: 0.3625
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7595s / 608.2549 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.3650
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7640s / 609.0189 s
agent0:                 episode reward: -0.7311,                 loss: nan
agent1:                 episode reward: 0.7311,                 loss: 0.3662
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7690s / 609.7878 s
agent0:                 episode reward: -0.7306,                 loss: nan
agent1:                 episode reward: 0.7306,                 loss: 0.3640
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7721s / 610.5600 s
agent0:                 episode reward: -0.3065,                 loss: nan
agent1:                 episode reward: 0.3065,                 loss: 0.3635
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7610s / 611.3210 s
agent0:                 episode reward: -0.8320,                 loss: nan
agent1:                 episode reward: 0.8320,                 loss: 0.3652
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7618s / 612.0828 s
agent0:                 episode reward: -0.8046,                 loss: nan
agent1:                 episode reward: 0.8046,                 loss: 0.3661
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7554s / 612.8382 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3672
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7586s / 613.5968 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.3659
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7588s / 614.3556 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.3682
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7544s / 615.1100 s
agent0:                 episode reward: -0.6183,                 loss: nan
agent1:                 episode reward: 0.6183,                 loss: 0.3669
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7679s / 615.8778 s
agent0:                 episode reward: -0.6991,                 loss: nan
agent1:                 episode reward: 0.6991,                 loss: 0.3679
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7624s / 616.6402 s
agent0:                 episode reward: -0.8050,                 loss: nan
agent1:                 episode reward: 0.8050,                 loss: 0.3664
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7549s / 617.3951 s
agent0:                 episode reward: -0.6627,                 loss: nan
agent1:                 episode reward: 0.6627,                 loss: 0.3688
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7728s / 618.1680 s
agent0:                 episode reward: -0.4792,                 loss: nan
agent1:                 episode reward: 0.4792,                 loss: 0.3686
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7665s / 618.9345 s
agent0:                 episode reward: -0.7467,                 loss: nan
agent1:                 episode reward: 0.7467,                 loss: 0.3665
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7532s / 619.6876 s
agent0:                 episode reward: -0.5776,                 loss: nan
agent1:                 episode reward: 0.5776,                 loss: 0.3669
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7687s / 620.4564 s
agent0:                 episode reward: -0.6033,                 loss: nan
agent1:                 episode reward: 0.6033,                 loss: 0.3667
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7612s / 621.2176 s
agent0:                 episode reward: -0.5375,                 loss: nan
agent1:                 episode reward: 0.5375,                 loss: 0.3691
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7756s / 621.9932 s
agent0:                 episode reward: -0.4870,                 loss: nan
agent1:                 episode reward: 0.4870,                 loss: 0.3674
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7842s / 622.7774 s
agent0:                 episode reward: -0.7145,                 loss: nan
agent1:                 episode reward: 0.7145,                 loss: 0.3670
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7631s / 623.5405 s
agent0:                 episode reward: -0.8184,                 loss: nan
agent1:                 episode reward: 0.8184,                 loss: 0.3657
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7551s / 624.2956 s
agent0:                 episode reward: -0.7598,                 loss: nan
agent1:                 episode reward: 0.7598,                 loss: 0.3675
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7825s / 625.0781 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.3669
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7626s / 625.8407 s
agent0:                 episode reward: -0.8462,                 loss: nan
agent1:                 episode reward: 0.8462,                 loss: 0.3672
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7977s / 626.6384 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.3737
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7631s / 627.4015 s
agent0:                 episode reward: -0.6794,                 loss: nan
agent1:                 episode reward: 0.6794,                 loss: 0.3778
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7664s / 628.1679 s
agent0:                 episode reward: -0.8216,                 loss: nan
agent1:                 episode reward: 0.8216,                 loss: 0.3779
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7763s / 628.9442 s
agent0:                 episode reward: -1.0110,                 loss: nan
agent1:                 episode reward: 1.0110,                 loss: 0.3777
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7755s / 629.7197 s
agent0:                 episode reward: -0.8024,                 loss: nan
agent1:                 episode reward: 0.8024,                 loss: 0.3784
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7605s / 630.4803 s
agent0:                 episode reward: -1.2200,                 loss: nan
agent1:                 episode reward: 1.2200,                 loss: 0.3754
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7714s / 631.2517 s
agent0:                 episode reward: -0.8970,                 loss: nan
agent1:                 episode reward: 0.8970,                 loss: 0.3785
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7716s / 632.0234 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.3783
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7749s / 632.7983 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.3770
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7807s / 633.5790 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: 0.3763
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7594s / 634.3383 s
agent0:                 episode reward: -0.6561,                 loss: nan
agent1:                 episode reward: 0.6561,                 loss: 0.3769
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7738s / 635.1121 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.3753
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7623s / 635.8745 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.3783
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7657s / 636.6402 s
agent0:                 episode reward: -0.4026,                 loss: nan
agent1:                 episode reward: 0.4026,                 loss: 0.3769
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7711s / 637.4113 s
agent0:                 episode reward: -0.6704,                 loss: nan
agent1:                 episode reward: 0.6704,                 loss: 0.3765
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7683s / 638.1796 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.3763
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7699s / 638.9495 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.3771
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7823s / 639.7318 s
agent0:                 episode reward: -0.5563,                 loss: nan
agent1:                 episode reward: 0.5563,                 loss: 0.3716
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7710s / 640.5028 s
agent0:                 episode reward: -1.0264,                 loss: nan
agent1:                 episode reward: 1.0264,                 loss: 0.3692
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7818s / 641.2846 s
agent0:                 episode reward: -0.8356,                 loss: nan
agent1:                 episode reward: 0.8356,                 loss: 0.3678
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7718s / 642.0564 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.3700
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7764s / 642.8328 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.3684
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7796s / 643.6124 s
agent0:                 episode reward: -0.2667,                 loss: nan
agent1:                 episode reward: 0.2667,                 loss: 0.3704
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7726s / 644.3850 s
agent0:                 episode reward: -0.7935,                 loss: nan
agent1:                 episode reward: 0.7935,                 loss: 0.3678
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7646s / 645.1496 s
agent0:                 episode reward: -0.8929,                 loss: nan
agent1:                 episode reward: 0.8929,                 loss: 0.3676
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7668s / 645.9165 s
agent0:                 episode reward: -0.8345,                 loss: nan
agent1:                 episode reward: 0.8345,                 loss: 0.3671
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7709s / 646.6874 s
agent0:                 episode reward: -1.0629,                 loss: nan
agent1:                 episode reward: 1.0629,                 loss: 0.3682
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7747s / 647.4621 s
agent0:                 episode reward: -0.6728,                 loss: nan
agent1:                 episode reward: 0.6728,                 loss: 0.3684
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7627s / 648.2248 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.3657
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7662s / 648.9910 s
agent0:                 episode reward: -0.8255,                 loss: nan
agent1:                 episode reward: 0.8255,                 loss: 0.3692
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7827s / 649.7737 s
agent0:                 episode reward: -0.5350,                 loss: nan
agent1:                 episode reward: 0.5350,                 loss: 0.3687
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7814s / 650.5551 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.3686
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7841s / 651.3392 s
agent0:                 episode reward: -0.7890,                 loss: nan
agent1:                 episode reward: 0.7890,                 loss: 0.3658
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7847s / 652.1239 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.3677
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7704s / 652.8943 s
agent0:                 episode reward: -1.0675,                 loss: nan
agent1:                 episode reward: 1.0675,                 loss: 0.3659
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7715s / 653.6658 s
agent0:                 episode reward: -1.0560,                 loss: nan
agent1:                 episode reward: 1.0560,                 loss: 0.3678
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7836s / 654.4494 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.3635
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7780s / 655.2274 s
agent0:                 episode reward: -0.6729,                 loss: nan
agent1:                 episode reward: 0.6729,                 loss: 0.3658
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7737s / 656.0011 s
agent0:                 episode reward: -0.7225,                 loss: nan
agent1:                 episode reward: 0.7225,                 loss: 0.3670
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7762s / 656.7773 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.3650
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7866s / 657.5639 s
agent0:                 episode reward: -0.5592,                 loss: nan
agent1:                 episode reward: 0.5592,                 loss: 0.3649
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7975s / 658.3614 s
agent0:                 episode reward: -0.1934,                 loss: nan
agent1:                 episode reward: 0.1934,                 loss: 0.3649
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7782s / 659.1396 s
agent0:                 episode reward: -0.9625,                 loss: nan
agent1:                 episode reward: 0.9625,                 loss: 0.3679
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7879s / 659.9275 s
agent0:                 episode reward: -0.4254,                 loss: nan
agent1:                 episode reward: 0.4254,                 loss: 0.3649
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7903s / 660.7178 s
agent0:                 episode reward: -0.5927,                 loss: nan
agent1:                 episode reward: 0.5927,                 loss: 0.3672
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7813s / 661.4991 s
agent0:                 episode reward: -0.6303,                 loss: nan
agent1:                 episode reward: 0.6303,                 loss: 0.3673
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7814s / 662.2805 s
agent0:                 episode reward: -0.8873,                 loss: nan
agent1:                 episode reward: 0.8873,                 loss: 0.3665
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7878s / 663.0683 s
agent0:                 episode reward: -0.7303,                 loss: nan
agent1:                 episode reward: 0.7303,                 loss: 0.3661
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7871s / 663.8554 s
agent0:                 episode reward: -0.8752,                 loss: nan
agent1:                 episode reward: 0.8752,                 loss: 0.3672
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8024s / 664.6578 s
agent0:                 episode reward: -0.5931,                 loss: nan
agent1:                 episode reward: 0.5931,                 loss: 0.3680
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8115s / 665.4693 s
agent0:                 episode reward: -0.4762,                 loss: nan
agent1:                 episode reward: 0.4762,                 loss: 0.3725
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7788s / 666.2481 s
agent0:                 episode reward: -0.9080,                 loss: nan
agent1:                 episode reward: 0.9080,                 loss: 0.3769
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7853s / 667.0334 s
agent0:                 episode reward: -0.7208,                 loss: nan
agent1:                 episode reward: 0.7208,                 loss: 0.3766
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7916s / 667.8250 s
agent0:                 episode reward: -0.6906,                 loss: nan
agent1:                 episode reward: 0.6906,                 loss: 0.3770
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7873s / 668.6123 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.3762
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7976s / 669.4099 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.3773
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8202s / 670.2301 s
agent0:                 episode reward: -1.0443,                 loss: nan
agent1:                 episode reward: 1.0443,                 loss: 0.3775
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7933s / 671.0235 s
agent0:                 episode reward: -0.4166,                 loss: nan
agent1:                 episode reward: 0.4166,                 loss: 0.3757
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7937s / 671.8172 s
agent0:                 episode reward: -0.4122,                 loss: nan
agent1:                 episode reward: 0.4122,                 loss: 0.3747
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7800s / 672.5972 s
agent0:                 episode reward: -0.7893,                 loss: nan
agent1:                 episode reward: 0.7893,                 loss: 0.3762
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7931s / 673.3903 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.3750
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7873s / 674.1775 s
agent0:                 episode reward: -0.3619,                 loss: nan
agent1:                 episode reward: 0.3619,                 loss: 0.3764
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7792s / 674.9567 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.3786
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8030s / 675.7597 s
agent0:                 episode reward: -0.7404,                 loss: nan
agent1:                 episode reward: 0.7404,                 loss: 0.3773
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7993s / 676.5590 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.3751
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7931s / 677.3521 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.3775
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7870s / 678.1391 s
agent0:                 episode reward: -0.8515,                 loss: nan
agent1:                 episode reward: 0.8515,                 loss: 0.3764
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7988s / 678.9379 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.3691
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7908s / 679.7287 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: 0.3626
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8036s / 680.5324 s
agent0:                 episode reward: -0.7779,                 loss: nan
agent1:                 episode reward: 0.7779,                 loss: 0.3616
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8090s / 681.3414 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.3662
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8317s / 682.1731 s
agent0:                 episode reward: -1.0091,                 loss: nan
agent1:                 episode reward: 1.0091,                 loss: 0.3653
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7978s / 682.9708 s
agent0:                 episode reward: -0.9514,                 loss: nan
agent1:                 episode reward: 0.9514,                 loss: 0.3651
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7960s / 683.7668 s
agent0:                 episode reward: -0.3418,                 loss: nan
agent1:                 episode reward: 0.3418,                 loss: 0.3622
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8056s / 684.5725 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: 0.3652
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7973s / 685.3698 s
agent0:                 episode reward: -0.8348,                 loss: nan
agent1:                 episode reward: 0.8348,                 loss: 0.3654
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7970s / 686.1668 s
agent0:                 episode reward: -0.9028,                 loss: nan
agent1:                 episode reward: 0.9028,                 loss: 0.3607
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8013s / 686.9681 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.3644
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7908s / 687.7588 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3654
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8024s / 688.5612 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.3632
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7986s / 689.3598 s
agent0:                 episode reward: -0.9649,                 loss: nan
agent1:                 episode reward: 0.9649,                 loss: 0.3646
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7939s / 690.1536 s
agent0:                 episode reward: -1.0165,                 loss: nan
agent1:                 episode reward: 1.0165,                 loss: 0.3635
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7899s / 690.9436 s
agent0:                 episode reward: -0.7376,                 loss: nan
agent1:                 episode reward: 0.7376,                 loss: 0.3644
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7966s / 691.7402 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.3668
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7955s / 692.5357 s
agent0:                 episode reward: -0.6085,                 loss: nan
agent1:                 episode reward: 0.6085,                 loss: 0.3683
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8006s / 693.3363 s
agent0:                 episode reward: -1.0665,                 loss: nan
agent1:                 episode reward: 1.0665,                 loss: 0.3691
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7955s / 694.1317 s
agent0:                 episode reward: -0.9493,                 loss: nan
agent1:                 episode reward: 0.9493,                 loss: 0.3709
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8106s / 694.9424 s
agent0:                 episode reward: -0.7348,                 loss: nan
agent1:                 episode reward: 0.7348,                 loss: 0.3676
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7931s / 695.7354 s
agent0:                 episode reward: -0.6275,                 loss: nan
agent1:                 episode reward: 0.6275,                 loss: 0.3672
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8109s / 696.5463 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.3684
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7862s / 697.3325 s
agent0:                 episode reward: -1.0841,                 loss: nan
agent1:                 episode reward: 1.0841,                 loss: 0.3687
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 698.1427 s
agent0:                 episode reward: -0.9370,                 loss: nan
agent1:                 episode reward: 0.9370,                 loss: 0.3704
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 698.9659 s
agent0:                 episode reward: -0.8809,                 loss: nan
agent1:                 episode reward: 0.8809,                 loss: 0.3703
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8112s / 699.7772 s
agent0:                 episode reward: -0.4376,                 loss: nan
agent1:                 episode reward: 0.4376,                 loss: 0.3693
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8058s / 700.5830 s
agent0:                 episode reward: -0.7985,                 loss: nan
agent1:                 episode reward: 0.7985,                 loss: 0.3678
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8116s / 701.3945 s
agent0:                 episode reward: -0.9055,                 loss: nan
agent1:                 episode reward: 0.9055,                 loss: 0.3703
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8006s / 702.1951 s
agent0:                 episode reward: -0.6050,                 loss: nan
agent1:                 episode reward: 0.6050,                 loss: 0.3694
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8014s / 702.9965 s
agent0:                 episode reward: -0.9528,                 loss: nan
agent1:                 episode reward: 0.9528,                 loss: 0.3724
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7942s / 703.7907 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.3685
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7897s / 704.5804 s
agent0:                 episode reward: -0.6669,                 loss: nan
agent1:                 episode reward: 0.6669,                 loss: 0.3663
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7904s / 705.3708 s
agent0:                 episode reward: -0.7178,                 loss: nan
agent1:                 episode reward: 0.7178,                 loss: 0.3741
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8102s / 706.1810 s
agent0:                 episode reward: -1.0642,                 loss: nan
agent1:                 episode reward: 1.0642,                 loss: 0.3755
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7998s / 706.9808 s
agent0:                 episode reward: -0.9892,                 loss: nan
agent1:                 episode reward: 0.9892,                 loss: 0.3747
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8003s / 707.7811 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3767
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7989s / 708.5799 s
agent0:                 episode reward: -0.3885,                 loss: nan
agent1:                 episode reward: 0.3885,                 loss: 0.3746
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8109s / 709.3909 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3740
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8146s / 710.2054 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.3724
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 711.0156 s
agent0:                 episode reward: -0.9297,                 loss: nan
agent1:                 episode reward: 0.9297,                 loss: 0.3767
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8023s / 711.8178 s
agent0:                 episode reward: -0.8372,                 loss: nan
agent1:                 episode reward: 0.8372,                 loss: 0.3742
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8126s / 712.6304 s
agent0:                 episode reward: -0.8889,                 loss: nan
agent1:                 episode reward: 0.8889,                 loss: 0.3769
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8004s / 713.4308 s
agent0:                 episode reward: -0.7716,                 loss: nan
agent1:                 episode reward: 0.7716,                 loss: 0.3759
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7977s / 714.2285 s
agent0:                 episode reward: -1.1510,                 loss: nan
agent1:                 episode reward: 1.1510,                 loss: 0.3761
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8079s / 715.0364 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.3737
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8151s / 715.8515 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3746
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8077s / 716.6592 s
agent0:                 episode reward: -0.9129,                 loss: nan
agent1:                 episode reward: 0.9129,                 loss: 0.3736
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8105s / 717.4697 s
agent0:                 episode reward: -0.8392,                 loss: nan
agent1:                 episode reward: 0.8392,                 loss: 0.3770
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8059s / 718.2755 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.3753
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8141s / 719.0896 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.3684
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8122s / 719.9018 s
agent0:                 episode reward: -0.9655,                 loss: nan
agent1:                 episode reward: 0.9655,                 loss: 0.3628
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8289s / 720.7307 s
agent0:                 episode reward: -0.9749,                 loss: nan
agent1:                 episode reward: 0.9749,                 loss: 0.3671
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8104s / 721.5410 s
agent0:                 episode reward: -1.0328,                 loss: nan
agent1:                 episode reward: 1.0328,                 loss: 0.3642
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8066s / 722.3476 s
agent0:                 episode reward: -0.9431,                 loss: nan
agent1:                 episode reward: 0.9431,                 loss: 0.3670
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8190s / 723.1666 s
agent0:                 episode reward: -1.1268,                 loss: nan
agent1:                 episode reward: 1.1268,                 loss: 0.3645
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8201s / 723.9867 s
agent0:                 episode reward: -0.7200,                 loss: nan
agent1:                 episode reward: 0.7200,                 loss: 0.3645
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8112s / 724.7979 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.3653
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8144s / 725.6123 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.3664
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8429s / 726.4552 s
agent0:                 episode reward: -0.9985,                 loss: nan
agent1:                 episode reward: 0.9985,                 loss: 0.3635
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8099s / 727.2651 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: 0.3644
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8141s / 728.0792 s
agent0:                 episode reward: -0.5455,                 loss: nan
agent1:                 episode reward: 0.5455,                 loss: 0.3630
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8137s / 728.8929 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.3652
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8303s / 729.7232 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: 0.3639
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8270s / 730.5503 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.3641
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8297s / 731.3800 s
agent0:                 episode reward: -0.5133,                 loss: nan
agent1:                 episode reward: 0.5133,                 loss: 0.3654
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8250s / 732.2050 s
agent0:                 episode reward: -0.6786,                 loss: nan
agent1:                 episode reward: 0.6786,                 loss: 0.3618
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8169s / 733.0219 s
agent0:                 episode reward: -1.1522,                 loss: nan
agent1:                 episode reward: 1.1522,                 loss: 0.3715
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8225s / 733.8444 s
agent0:                 episode reward: -0.8617,                 loss: nan
agent1:                 episode reward: 0.8617,                 loss: 0.3705
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8233s / 734.6677 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.3732
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8168s / 735.4845 s
agent0:                 episode reward: -0.6932,                 loss: nan
agent1:                 episode reward: 0.6932,                 loss: 0.3719
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8138s / 736.2983 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.3716
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8231s / 737.1214 s
agent0:                 episode reward: -0.4358,                 loss: nan
agent1:                 episode reward: 0.4358,                 loss: 0.3716
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8306s / 737.9521 s
agent0:                 episode reward: -0.8361,                 loss: nan
agent1:                 episode reward: 0.8361,                 loss: 0.3729
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8204s / 738.7725 s
agent0:                 episode reward: -1.0218,                 loss: nan
agent1:                 episode reward: 1.0218,                 loss: 0.3733
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8291s / 739.6016 s
agent0:                 episode reward: -0.6831,                 loss: nan
agent1:                 episode reward: 0.6831,                 loss: 0.3736
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8210s / 740.4226 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.3709
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8195s / 741.2421 s
agent0:                 episode reward: -0.7875,                 loss: nan
agent1:                 episode reward: 0.7875,                 loss: 0.3724
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8168s / 742.0589 s
agent0:                 episode reward: -0.4949,                 loss: nan
agent1:                 episode reward: 0.4949,                 loss: 0.3712
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8295s / 742.8884 s
agent0:                 episode reward: -0.8288,                 loss: nan
agent1:                 episode reward: 0.8288,                 loss: 0.3723
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8408s / 743.7292 s
agent0:                 episode reward: -0.4289,                 loss: nan
agent1:                 episode reward: 0.4289,                 loss: 0.3703
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8215s / 744.5507 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.3712
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8304s / 745.3811 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.3683
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8296s / 746.2107 s
agent0:                 episode reward: -0.5616,                 loss: nan
agent1:                 episode reward: 0.5616,                 loss: 0.3729
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8257s / 747.0363 s
agent0:                 episode reward: -0.4769,                 loss: nan
agent1:                 episode reward: 0.4769,                 loss: 0.3744
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8276s / 747.8640 s
agent0:                 episode reward: -0.7812,                 loss: nan
agent1:                 episode reward: 0.7812,                 loss: 0.3752
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8192s / 748.6832 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: 0.3753
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8340s / 749.5172 s
agent0:                 episode reward: -1.1606,                 loss: nan
agent1:                 episode reward: 1.1606,                 loss: 0.3737
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8137s / 750.3309 s
agent0:                 episode reward: -0.5303,                 loss: nan
agent1:                 episode reward: 0.5303,                 loss: 0.3746
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8268s / 751.1576 s
agent0:                 episode reward: -0.8052,                 loss: nan
agent1:                 episode reward: 0.8052,                 loss: 0.3755
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8205s / 751.9781 s
agent0:                 episode reward: -0.9859,                 loss: nan
agent1:                 episode reward: 0.9859,                 loss: 0.3750
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 752.8014 s
agent0:                 episode reward: -0.7308,                 loss: nan
agent1:                 episode reward: 0.7308,                 loss: 0.3763
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8318s / 753.6332 s
agent0:                 episode reward: -0.7851,                 loss: nan
agent1:                 episode reward: 0.7851,                 loss: 0.3737
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8250s / 754.4582 s
agent0:                 episode reward: -0.4951,                 loss: nan
agent1:                 episode reward: 0.4951,                 loss: 0.3740
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8199s / 755.2781 s
agent0:                 episode reward: -0.8487,                 loss: nan
agent1:                 episode reward: 0.8487,                 loss: 0.3742
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8441s / 756.1222 s
agent0:                 episode reward: -1.0277,                 loss: nan
agent1:                 episode reward: 1.0277,                 loss: 0.3723
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8274s / 756.9495 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3758
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8430s / 757.7925 s
agent0:                 episode reward: -0.8191,                 loss: nan
agent1:                 episode reward: 0.8191,                 loss: 0.3748
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8318s / 758.6243 s
agent0:                 episode reward: -0.8322,                 loss: nan
agent1:                 episode reward: 0.8322,                 loss: 0.3757
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8256s / 759.4499 s
agent0:                 episode reward: -0.3252,                 loss: nan
agent1:                 episode reward: 0.3252,                 loss: 0.3775
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8280s / 760.2779 s
agent0:                 episode reward: -0.6483,                 loss: nan
agent1:                 episode reward: 0.6483,                 loss: 0.3680
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8220s / 761.0999 s
agent0:                 episode reward: -0.9805,                 loss: nan
agent1:                 episode reward: 0.9805,                 loss: 0.3608
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8234s / 761.9233 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.3615
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8396s / 762.7629 s
agent0:                 episode reward: -0.8778,                 loss: nan
agent1:                 episode reward: 0.8778,                 loss: 0.3639
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8314s / 763.5943 s
agent0:                 episode reward: -0.7030,                 loss: nan
agent1:                 episode reward: 0.7030,                 loss: 0.3632
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8338s / 764.4281 s
agent0:                 episode reward: -0.7474,                 loss: nan
agent1:                 episode reward: 0.7474,                 loss: 0.3639
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8492s / 765.2774 s
agent0:                 episode reward: -0.7555,                 loss: nan
agent1:                 episode reward: 0.7555,                 loss: 0.3610
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8191s / 766.0964 s
agent0:                 episode reward: -0.9299,                 loss: nan
agent1:                 episode reward: 0.9299,                 loss: 0.3651
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8285s / 766.9249 s
agent0:                 episode reward: -0.8666,                 loss: nan
agent1:                 episode reward: 0.8666,                 loss: 0.3619
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8357s / 767.7606 s
agent0:                 episode reward: -0.8990,                 loss: nan
agent1:                 episode reward: 0.8990,                 loss: 0.3609
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8260s / 768.5865 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3632
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8295s / 769.4161 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.3645
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8361s / 770.2521 s
agent0:                 episode reward: -0.7995,                 loss: nan
agent1:                 episode reward: 0.7995,                 loss: 0.3648
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8361s / 771.0882 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.3606
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8419s / 771.9301 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3637
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8280s / 772.7581 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.3637
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8398s / 773.5979 s
agent0:                 episode reward: -0.6491,                 loss: nan
agent1:                 episode reward: 0.6491,                 loss: 0.3638
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8351s / 774.4330 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.3703
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8362s / 775.2692 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.3696
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8501s / 776.1193 s
agent0:                 episode reward: -0.8723,                 loss: nan
agent1:                 episode reward: 0.8723,                 loss: 0.3687
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8618s / 776.9811 s
agent0:                 episode reward: -0.3175,                 loss: nan
agent1:                 episode reward: 0.3175,                 loss: 0.3721
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8461s / 777.8272 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3696
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8515s / 778.6787 s
agent0:                 episode reward: -0.7755,                 loss: nan
agent1:                 episode reward: 0.7755,                 loss: 0.3709
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8445s / 779.5232 s
agent0:                 episode reward: -0.7477,                 loss: nan
agent1:                 episode reward: 0.7477,                 loss: 0.3704
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8479s / 780.3710 s
agent0:                 episode reward: -0.6048,                 loss: nan
agent1:                 episode reward: 0.6048,                 loss: 0.3702
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8490s / 781.2200 s
agent0:                 episode reward: -0.4189,                 loss: nan
agent1:                 episode reward: 0.4189,                 loss: 0.3716
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8510s / 782.0710 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.3698
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8499s / 782.9209 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.3719
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8588s / 783.7797 s
agent0:                 episode reward: -0.8237,                 loss: nan
agent1:                 episode reward: 0.8237,                 loss: 0.3717
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 784.6244 s
agent0:                 episode reward: -0.8468,                 loss: nan
agent1:                 episode reward: 0.8468,                 loss: 0.3688
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8420s / 785.4665 s
agent0:                 episode reward: -0.8443,                 loss: nan
agent1:                 episode reward: 0.8443,                 loss: 0.3696
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8418s / 786.3083 s
agent0:                 episode reward: -0.4840,                 loss: nan
agent1:                 episode reward: 0.4840,                 loss: 0.3712
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8650s / 787.1733 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3706
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8555s / 788.0288 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.3697
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8403s / 788.8691 s
agent0:                 episode reward: -1.0585,                 loss: nan
agent1:                 episode reward: 1.0585,                 loss: 0.3721
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8460s / 789.7151 s
agent0:                 episode reward: -0.6820,                 loss: nan
agent1:                 episode reward: 0.6820,                 loss: 0.3724
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8413s / 790.5564 s
agent0:                 episode reward: -1.0001,                 loss: nan
agent1:                 episode reward: 1.0001,                 loss: 0.3672
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8437s / 791.4001 s
agent0:                 episode reward: -0.4672,                 loss: nan
agent1:                 episode reward: 0.4672,                 loss: 0.3721
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8386s / 792.2387 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.3723
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8466s / 793.0853 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3723
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8608s / 793.9461 s
agent0:                 episode reward: -0.6425,                 loss: nan
agent1:                 episode reward: 0.6425,                 loss: 0.3729
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8479s / 794.7939 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.3724
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8606s / 795.6545 s
agent0:                 episode reward: -0.8848,                 loss: nan
agent1:                 episode reward: 0.8848,                 loss: 0.3702
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8592s / 796.5137 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.3734
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 797.3666 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.3695
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8566s / 798.2233 s
agent0:                 episode reward: -1.2383,                 loss: nan
agent1:                 episode reward: 1.2383,                 loss: 0.3706
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 799.0679 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.3709
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 799.9208 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.3715
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8676s / 800.7884 s
agent0:                 episode reward: -0.5655,                 loss: nan
agent1:                 episode reward: 0.5655,                 loss: 0.3699
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8571s / 801.6454 s
agent0:                 episode reward: -1.1660,                 loss: nan
agent1:                 episode reward: 1.1660,                 loss: 0.3711
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8472s / 802.4926 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.3728
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8505s / 803.3431 s
agent0:                 episode reward: -0.8381,                 loss: nan
agent1:                 episode reward: 0.8381,                 loss: 0.3723
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8377s / 804.1808 s
agent0:                 episode reward: -0.7836,                 loss: nan
agent1:                 episode reward: 0.7836,                 loss: 0.3732
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8548s / 805.0357 s
agent0:                 episode reward: -1.3097,                 loss: nan
agent1:                 episode reward: 1.3097,                 loss: 0.3723
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8556s / 805.8912 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.3709
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8526s / 806.7438 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.3709
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8625s / 807.6063 s
agent0:                 episode reward: -0.9203,                 loss: nan
agent1:                 episode reward: 0.9203,                 loss: 0.3709
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8703s / 808.4766 s
agent0:                 episode reward: -0.9101,                 loss: nan
agent1:                 episode reward: 0.9101,                 loss: 0.3730
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8599s / 809.3365 s
agent0:                 episode reward: -0.8686,                 loss: nan
agent1:                 episode reward: 0.8686,                 loss: 0.3722
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8609s / 810.1974 s
agent0:                 episode reward: -0.6041,                 loss: nan
agent1:                 episode reward: 0.6041,                 loss: 0.3716
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8521s / 811.0495 s
agent0:                 episode reward: -0.6823,                 loss: nan
agent1:                 episode reward: 0.6823,                 loss: 0.3721
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8531s / 811.9026 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.3726
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8791s / 812.7817 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.3736
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8582s / 813.6399 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.3722
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8697s / 814.5096 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.3712
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8489s / 815.3586 s
agent0:                 episode reward: -0.2509,                 loss: nan
agent1:                 episode reward: 0.2509,                 loss: 0.3738
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8589s / 816.2174 s
agent0:                 episode reward: -0.5331,                 loss: nan
agent1:                 episode reward: 0.5331,                 loss: 0.3713
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8526s / 817.0700 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.3754
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8636s / 817.9336 s
agent0:                 episode reward: -0.6586,                 loss: nan
agent1:                 episode reward: 0.6586,                 loss: 0.3739
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8534s / 818.7870 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.3756
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8475s / 819.6345 s
agent0:                 episode reward: -1.0992,                 loss: nan
agent1:                 episode reward: 1.0992,                 loss: 0.3736
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8796s / 820.5141 s
agent0:                 episode reward: -0.8836,                 loss: nan
agent1:                 episode reward: 0.8836,                 loss: 0.3765
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8671s / 821.3811 s
agent0:                 episode reward: -0.8396,                 loss: nan
agent1:                 episode reward: 0.8396,                 loss: 0.3735
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8590s / 822.2402 s
agent0:                 episode reward: -0.8275,                 loss: nan
agent1:                 episode reward: 0.8275,                 loss: 0.3739
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8711s / 823.1113 s
agent0:                 episode reward: -0.9247,                 loss: nan
agent1:                 episode reward: 0.9247,                 loss: 0.3745
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8578s / 823.9691 s
agent0:                 episode reward: -0.7290,                 loss: nan
agent1:                 episode reward: 0.7290,                 loss: 0.3721
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8511s / 824.8202 s
agent0:                 episode reward: -0.3728,                 loss: nan
agent1:                 episode reward: 0.3728,                 loss: 0.3743
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 825.6929 s
agent0:                 episode reward: -0.8527,                 loss: nan
agent1:                 episode reward: 0.8527,                 loss: 0.3752
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8530s / 826.5459 s
agent0:                 episode reward: -0.5933,                 loss: nan
agent1:                 episode reward: 0.5933,                 loss: 0.3748
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8635s / 827.4094 s
agent0:                 episode reward: -0.4118,                 loss: nan
agent1:                 episode reward: 0.4118,                 loss: 0.3765
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8847s / 828.2942 s
agent0:                 episode reward: -0.8975,                 loss: nan
agent1:                 episode reward: 0.8975,                 loss: 0.3765
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8646s / 829.1588 s
agent0:                 episode reward: -0.8616,                 loss: nan
agent1:                 episode reward: 0.8616,                 loss: 0.3740
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8664s / 830.0252 s
agent0:                 episode reward: -0.9585,                 loss: nan
agent1:                 episode reward: 0.9585,                 loss: 0.3737
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8668s / 830.8920 s
agent0:                 episode reward: -0.9914,                 loss: nan
agent1:                 episode reward: 0.9914,                 loss: 0.3718
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8531s / 831.7451 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3626
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8568s / 832.6019 s
agent0:                 episode reward: -0.8239,                 loss: nan
agent1:                 episode reward: 0.8239,                 loss: 0.3664
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8667s / 833.4686 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.3633
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8629s / 834.3314 s
agent0:                 episode reward: -0.7622,                 loss: nan
agent1:                 episode reward: 0.7622,                 loss: 0.3647
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8815s / 835.2129 s
agent0:                 episode reward: -0.7452,                 loss: nan
agent1:                 episode reward: 0.7452,                 loss: 0.3660
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8670s / 836.0799 s
agent0:                 episode reward: -0.8194,                 loss: nan
agent1:                 episode reward: 0.8194,                 loss: 0.3611
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8694s / 836.9493 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.3639
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8849s / 837.8342 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.3640
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8835s / 838.7178 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.3646
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8625s / 839.5803 s
agent0:                 episode reward: -0.3763,                 loss: nan
agent1:                 episode reward: 0.3763,                 loss: 0.3630
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8675s / 840.4477 s
agent0:                 episode reward: -0.6835,                 loss: nan
agent1:                 episode reward: 0.6835,                 loss: 0.3635
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8722s / 841.3200 s
agent0:                 episode reward: -0.4269,                 loss: nan
agent1:                 episode reward: 0.4269,                 loss: 0.3637
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8786s / 842.1986 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.3634
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8727s / 843.0713 s
agent0:                 episode reward: -0.6283,                 loss: nan
agent1:                 episode reward: 0.6283,                 loss: 0.3655
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8847s / 843.9561 s
agent0:                 episode reward: -0.5902,                 loss: nan
agent1:                 episode reward: 0.5902,                 loss: 0.3621
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8834s / 844.8395 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.3639
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8894s / 845.7289 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.3695
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8561s / 846.5850 s
agent0:                 episode reward: -0.8757,                 loss: nan
agent1:                 episode reward: 0.8757,                 loss: 0.3713
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8736s / 847.4585 s
agent0:                 episode reward: -0.6101,                 loss: nan
agent1:                 episode reward: 0.6101,                 loss: 0.3716
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8686s / 848.3271 s
agent0:                 episode reward: -0.7106,                 loss: nan
agent1:                 episode reward: 0.7106,                 loss: 0.3697
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8743s / 849.2014 s
agent0:                 episode reward: -1.0866,                 loss: nan
agent1:                 episode reward: 1.0866,                 loss: 0.3714
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8701s / 850.0715 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.3721
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8641s / 850.9356 s
agent0:                 episode reward: -0.5367,                 loss: nan
agent1:                 episode reward: 0.5367,                 loss: 0.3716
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8873s / 851.8230 s
agent0:                 episode reward: -1.0001,                 loss: nan
agent1:                 episode reward: 1.0001,                 loss: 0.3707
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9184s / 852.7413 s
agent0:                 episode reward: -0.7943,                 loss: nan
agent1:                 episode reward: 0.7943,                 loss: 0.3718
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8702s / 853.6115 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.3731
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8765s / 854.4880 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.3700
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8805s / 855.3686 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3713
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8688s / 856.2374 s
agent0:                 episode reward: -0.6977,                 loss: nan
agent1:                 episode reward: 0.6977,                 loss: 0.3723
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8719s / 857.1092 s
agent0:                 episode reward: -0.9570,                 loss: nan
agent1:                 episode reward: 0.9570,                 loss: 0.3710
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8764s / 857.9856 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.3722
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8694s / 858.8551 s
agent0:                 episode reward: -0.9814,                 loss: nan
agent1:                 episode reward: 0.9814,                 loss: 0.3693
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8755s / 859.7305 s
agent0:                 episode reward: -0.6520,                 loss: nan
agent1:                 episode reward: 0.6520,                 loss: 0.3699
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8762s / 860.6068 s
agent0:                 episode reward: -0.7915,                 loss: nan
agent1:                 episode reward: 0.7915,                 loss: 0.3713
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8848s / 861.4916 s
agent0:                 episode reward: -0.4322,                 loss: nan
agent1:                 episode reward: 0.4322,                 loss: 0.3712
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8820s / 862.3737 s
agent0:                 episode reward: -0.7008,                 loss: nan
agent1:                 episode reward: 0.7008,                 loss: 0.3695
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8910s / 863.2647 s
agent0:                 episode reward: -0.8542,                 loss: nan
agent1:                 episode reward: 0.8542,                 loss: 0.3722
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8712s / 864.1359 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.3694
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8692s / 865.0051 s
agent0:                 episode reward: -0.6551,                 loss: nan
agent1:                 episode reward: 0.6551,                 loss: 0.3701
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8778s / 865.8829 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.3687
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8827s / 866.7656 s
agent0:                 episode reward: -1.0677,                 loss: nan
agent1:                 episode reward: 1.0677,                 loss: 0.3719
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8779s / 867.6435 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.3710
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8835s / 868.5270 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.3725
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8998s / 869.4268 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.3702
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8867s / 870.3135 s
agent0:                 episode reward: -0.5340,                 loss: nan
agent1:                 episode reward: 0.5340,                 loss: 0.3729
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8861s / 871.1996 s
agent0:                 episode reward: -0.9560,                 loss: nan
agent1:                 episode reward: 0.9560,                 loss: 0.3703
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8857s / 872.0853 s
agent0:                 episode reward: -0.6641,                 loss: nan
agent1:                 episode reward: 0.6641,                 loss: 0.3705
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9058s / 872.9911 s
agent0:                 episode reward: -0.8988,                 loss: nan
agent1:                 episode reward: 0.8988,                 loss: 0.3714
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8773s / 873.8684 s
agent0:                 episode reward: -0.4478,                 loss: nan
agent1:                 episode reward: 0.4478,                 loss: 0.3677
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8893s / 874.7577 s
agent0:                 episode reward: -0.7736,                 loss: nan
agent1:                 episode reward: 0.7736,                 loss: 0.3691
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8914s / 875.6492 s
agent0:                 episode reward: -0.5685,                 loss: nan
agent1:                 episode reward: 0.5685,                 loss: 0.3584
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8835s / 876.5327 s
agent0:                 episode reward: -0.8414,                 loss: nan
agent1:                 episode reward: 0.8414,                 loss: 0.3585
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8940s / 877.4266 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.3596
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8902s / 878.3168 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.3592
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8975s / 879.2143 s
agent0:                 episode reward: -0.6968,                 loss: nan
agent1:                 episode reward: 0.6968,                 loss: 0.3591
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8879s / 880.1023 s
agent0:                 episode reward: -1.0477,                 loss: nan
agent1:                 episode reward: 1.0477,                 loss: 0.3583
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8844s / 880.9866 s
agent0:                 episode reward: -0.7821,                 loss: nan
agent1:                 episode reward: 0.7821,                 loss: 0.3595
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8944s / 881.8810 s
agent0:                 episode reward: -0.7755,                 loss: nan
agent1:                 episode reward: 0.7755,                 loss: 0.3599
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8797s / 882.7607 s
agent0:                 episode reward: -0.7928,                 loss: nan
agent1:                 episode reward: 0.7928,                 loss: 0.3559
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8912s / 883.6519 s
agent0:                 episode reward: -0.5995,                 loss: nan
agent1:                 episode reward: 0.5995,                 loss: 0.3596
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8853s / 884.5372 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.3586
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8982s / 885.4354 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.3594
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8991s / 886.3345 s
agent0:                 episode reward: -1.1785,                 loss: nan
agent1:                 episode reward: 1.1785,                 loss: 0.3592
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8975s / 887.2320 s
agent0:                 episode reward: -0.7984,                 loss: nan
agent1:                 episode reward: 0.7984,                 loss: 0.3597
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9113s / 888.1432 s
agent0:                 episode reward: -0.6112,                 loss: nan
agent1:                 episode reward: 0.6112,                 loss: 0.3594
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9000s / 889.0433 s
agent0:                 episode reward: -0.4396,                 loss: nan
agent1:                 episode reward: 0.4396,                 loss: 0.3586
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9034s / 889.9467 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.3738
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9209s / 890.8676 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.3753
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8939s / 891.7614 s
agent0:                 episode reward: -1.2804,                 loss: nan
agent1:                 episode reward: 1.2804,                 loss: 0.3768
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9125s / 892.6740 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.3758
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8947s / 893.5686 s
agent0:                 episode reward: -0.8141,                 loss: nan
agent1:                 episode reward: 0.8141,                 loss: 0.3782
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9040s / 894.4726 s
agent0:                 episode reward: -0.6990,                 loss: nan
agent1:                 episode reward: 0.6990,                 loss: 0.3740
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9112s / 895.3838 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.3762
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8911s / 896.2749 s
agent0:                 episode reward: -0.9027,                 loss: nan
agent1:                 episode reward: 0.9027,                 loss: 0.3753
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8924s / 897.1673 s
agent0:                 episode reward: -0.9895,                 loss: nan
agent1:                 episode reward: 0.9895,                 loss: 0.3766
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9049s / 898.0722 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.3775
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9150s / 898.9872 s
agent0:                 episode reward: -0.9052,                 loss: nan
agent1:                 episode reward: 0.9052,                 loss: 0.3760
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9043s / 899.8915 s
agent0:                 episode reward: -1.1475,                 loss: nan
agent1:                 episode reward: 1.1475,                 loss: 0.3758
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9079s / 900.7994 s
agent0:                 episode reward: -0.3709,                 loss: nan
agent1:                 episode reward: 0.3709,                 loss: 0.3769
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8921s / 901.6915 s
agent0:                 episode reward: -0.8271,                 loss: nan
agent1:                 episode reward: 0.8271,                 loss: 0.3763
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9103s / 902.6018 s
agent0:                 episode reward: -0.5474,                 loss: nan
agent1:                 episode reward: 0.5474,                 loss: 0.3747
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8929s / 903.4947 s
agent0:                 episode reward: -0.7301,                 loss: nan
agent1:                 episode reward: 0.7301,                 loss: 0.3757
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9100s / 904.4047 s
agent0:                 episode reward: -0.5550,                 loss: nan
agent1:                 episode reward: 0.5550,                 loss: 0.3766
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9081s / 905.3128 s
agent0:                 episode reward: -1.0434,                 loss: nan
agent1:                 episode reward: 1.0434,                 loss: 0.3716
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 906.2048 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3715
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8998s / 907.1046 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3691
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8863s / 907.9910 s
agent0:                 episode reward: -0.9314,                 loss: nan
agent1:                 episode reward: 0.9314,                 loss: 0.3705
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9040s / 908.8949 s
agent0:                 episode reward: -0.7990,                 loss: nan
agent1:                 episode reward: 0.7990,                 loss: 0.3727
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8889s / 909.7838 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.3696
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9042s / 910.6880 s
agent0:                 episode reward: -1.0688,                 loss: nan
agent1:                 episode reward: 1.0688,                 loss: 0.3716
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8951s / 911.5831 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.3718
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9031s / 912.4863 s
agent0:                 episode reward: -0.8084,                 loss: nan
agent1:                 episode reward: 0.8084,                 loss: 0.3689
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9095s / 913.3958 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.3682
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9188s / 914.3146 s
agent0:                 episode reward: -0.5944,                 loss: nan
agent1:                 episode reward: 0.5944,                 loss: 0.3708
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9000s / 915.2147 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.3689
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8987s / 916.1133 s
agent0:                 episode reward: -0.8029,                 loss: nan
agent1:                 episode reward: 0.8029,                 loss: 0.3701
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9158s / 917.0291 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.3673
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9024s / 917.9316 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.3714
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8950s / 918.8265 s
agent0:                 episode reward: -0.5327,                 loss: nan
agent1:                 episode reward: 0.5327,                 loss: 0.3699
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9067s / 919.7333 s
agent0:                 episode reward: -0.4411,                 loss: nan
agent1:                 episode reward: 0.4411,                 loss: 0.3684
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8967s / 920.6300 s
agent0:                 episode reward: -0.8692,                 loss: nan
agent1:                 episode reward: 0.8692,                 loss: 0.3612
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9033s / 921.5333 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.3621
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9142s / 922.4475 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3612
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8969s / 923.3444 s
agent0:                 episode reward: -0.7632,                 loss: nan
agent1:                 episode reward: 0.7632,                 loss: 0.3632
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8988s / 924.2431 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: 0.3617
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9054s / 925.1486 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.3596
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9059s / 926.0544 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: 0.3626
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9205s / 926.9749 s
agent0:                 episode reward: -0.8295,                 loss: nan
agent1:                 episode reward: 0.8295,                 loss: 0.3619
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9205s / 927.8955 s
agent0:                 episode reward: -1.0059,                 loss: nan
agent1:                 episode reward: 1.0059,                 loss: 0.3610
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9090s / 928.8044 s
agent0:                 episode reward: -0.5922,                 loss: nan
agent1:                 episode reward: 0.5922,                 loss: 0.3613
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9052s / 929.7097 s
agent0:                 episode reward: -0.9810,                 loss: nan
agent1:                 episode reward: 0.9810,                 loss: 0.3626
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9081s / 930.6178 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.3608
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9091s / 931.5269 s
agent0:                 episode reward: -0.8253,                 loss: nan
agent1:                 episode reward: 0.8253,                 loss: 0.3608
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9201s / 932.4470 s
agent0:                 episode reward: -0.7045,                 loss: nan
agent1:                 episode reward: 0.7045,                 loss: 0.3620
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9058s / 933.3528 s
agent0:                 episode reward: -0.4912,                 loss: nan
agent1:                 episode reward: 0.4912,                 loss: 0.3638
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9135s / 934.2663 s
agent0:                 episode reward: -0.9024,                 loss: nan
agent1:                 episode reward: 0.9024,                 loss: 0.3632
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9238s / 935.1901 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.3756
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9176s / 936.1077 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.3797
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9209s / 937.0286 s
agent0:                 episode reward: -0.3650,                 loss: nan
agent1:                 episode reward: 0.3650,                 loss: 0.3777
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9112s / 937.9398 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.3786
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9029s / 938.8427 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.3773
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9008s / 939.7435 s
agent0:                 episode reward: -1.0714,                 loss: nan
agent1:                 episode reward: 1.0714,                 loss: 0.3763
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9051s / 940.6485 s
agent0:                 episode reward: -0.4642,                 loss: nan
agent1:                 episode reward: 0.4642,                 loss: 0.3758
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9147s / 941.5633 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.3773
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9134s / 942.4767 s
agent0:                 episode reward: -0.1991,                 loss: nan
agent1:                 episode reward: 0.1991,                 loss: 0.3765
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9219s / 943.3986 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.3756
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9097s / 944.3083 s
agent0:                 episode reward: -0.7218,                 loss: nan
agent1:                 episode reward: 0.7218,                 loss: 0.3750
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9091s / 945.2174 s
agent0:                 episode reward: -0.4270,                 loss: nan
agent1:                 episode reward: 0.4270,                 loss: 0.3758
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9070s / 946.1243 s
agent0:                 episode reward: -0.7463,                 loss: nan
agent1:                 episode reward: 0.7463,                 loss: 0.3785
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9063s / 947.0306 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.3752
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9338s / 947.9644 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.3750
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9108s / 948.8753 s
agent0:                 episode reward: -0.7332,                 loss: nan
agent1:                 episode reward: 0.7332,                 loss: 0.3755
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9280s / 949.8032 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.3762
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9305s / 950.7337 s
agent0:                 episode reward: -0.4495,                 loss: nan
agent1:                 episode reward: 0.4495,                 loss: 0.3728
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9098s / 951.6435 s
agent0:                 episode reward: -1.0384,                 loss: nan
agent1:                 episode reward: 1.0384,                 loss: 0.3717
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9223s / 952.5658 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.3695
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9152s / 953.4810 s
agent0:                 episode reward: -0.5814,                 loss: nan
agent1:                 episode reward: 0.5814,                 loss: 0.3724
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9189s / 954.3999 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3697
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9267s / 955.3267 s
agent0:                 episode reward: -1.0242,                 loss: nan
agent1:                 episode reward: 1.0242,                 loss: 0.3728
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9143s / 956.2410 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: 0.3727
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9224s / 957.1634 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: 0.3712
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9156s / 958.0789 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.3689
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9273s / 959.0062 s
agent0:                 episode reward: -0.8124,                 loss: nan
agent1:                 episode reward: 0.8124,                 loss: 0.3703
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9311s / 959.9374 s
agent0:                 episode reward: -0.7529,                 loss: nan
agent1:                 episode reward: 0.7529,                 loss: 0.3722
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9324s / 960.8697 s
agent0:                 episode reward: -0.7245,                 loss: nan
agent1:                 episode reward: 0.7245,                 loss: 0.3697
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9121s / 961.7818 s
agent0:                 episode reward: -0.9865,                 loss: nan
agent1:                 episode reward: 0.9865,                 loss: 0.3727
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9502s / 962.7320 s
agent0:                 episode reward: -0.9058,                 loss: nan
agent1:                 episode reward: 0.9058,                 loss: 0.3725
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9270s / 963.6589 s
agent0:                 episode reward: -0.6576,                 loss: nan
agent1:                 episode reward: 0.6576,                 loss: 0.3720
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9310s / 964.5900 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.3706
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9349s / 965.5248 s
agent0:                 episode reward: -0.8283,                 loss: nan
agent1:                 episode reward: 0.8283,                 loss: 0.3669
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9370s / 966.4618 s
agent0:                 episode reward: -1.0387,                 loss: nan
agent1:                 episode reward: 1.0387,                 loss: 0.3609
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9179s / 967.3797 s
agent0:                 episode reward: -0.9095,                 loss: nan
agent1:                 episode reward: 0.9095,                 loss: 0.3615
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9121s / 968.2918 s
agent0:                 episode reward: -0.7916,                 loss: nan
agent1:                 episode reward: 0.7916,                 loss: 0.3587
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9473s / 969.2391 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.3596
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9197s / 970.1588 s
agent0:                 episode reward: -0.5803,                 loss: nan
agent1:                 episode reward: 0.5803,                 loss: 0.3605
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9278s / 971.0866 s
agent0:                 episode reward: -0.9130,                 loss: nan
agent1:                 episode reward: 0.9130,                 loss: 0.3617
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9369s / 972.0234 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.3591
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9383s / 972.9617 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.3602
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9272s / 973.8890 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.3624
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9376s / 974.8265 s
agent0:                 episode reward: -0.8621,                 loss: nan
agent1:                 episode reward: 0.8621,                 loss: 0.3610
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9374s / 975.7640 s
agent0:                 episode reward: -0.7931,                 loss: nan
agent1:                 episode reward: 0.7931,                 loss: 0.3624
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9291s / 976.6931 s
agent0:                 episode reward: -0.8498,                 loss: nan
agent1:                 episode reward: 0.8498,                 loss: 0.3596
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9332s / 977.6263 s
agent0:                 episode reward: -0.7247,                 loss: nan
agent1:                 episode reward: 0.7247,                 loss: 0.3579
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9323s / 978.5586 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.3599/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9274s / 979.4860 s
agent0:                 episode reward: -0.3804,                 loss: nan
agent1:                 episode reward: 0.3804,                 loss: 0.3608
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9386s / 980.4246 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.3606
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9331s / 981.3578 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.3764
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9608s / 982.3186 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.3767
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9589s / 983.2775 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.3763
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9299s / 984.2073 s
agent0:                 episode reward: -0.4150,                 loss: nan
agent1:                 episode reward: 0.4150,                 loss: 0.3730
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9393s / 985.1467 s
agent0:                 episode reward: -0.5098,                 loss: nan
agent1:                 episode reward: 0.5098,                 loss: 0.3763
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9264s / 986.0731 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.3767
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9490s / 987.0220 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.3782
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9461s / 987.9681 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: 0.3760
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9424s / 988.9105 s
agent0:                 episode reward: -0.7035,                 loss: nan
agent1:                 episode reward: 0.7035,                 loss: 0.3770
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9509s / 989.8614 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.3761
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9419s / 990.8033 s
agent0:                 episode reward: -0.3289,                 loss: nan
agent1:                 episode reward: 0.3289,                 loss: 0.3764
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9427s / 991.7460 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.3770
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9588s / 992.7048 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.3769
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9458s / 993.6506 s
agent0:                 episode reward: -0.7166,                 loss: nan
agent1:                 episode reward: 0.7166,                 loss: 0.3769
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9505s / 994.6011 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.3752
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9345s / 995.5356 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.3749
