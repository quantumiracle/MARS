pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
Load double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 848
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f67f8549470>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111]) array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125])]
Load checkpoints (policy family):  [list(['23', '90', '342', '555', '1225', '1908', '2617', '4059', '4631']) list(['44', '310', '525', '1084', '1538', '2527', '3197', '4296'])]
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220425_1813/pettingzoo_double_dunk_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 15, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220425_1813_exploit_first_50000/pettingzoo_double_dunk_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220425_1813_exploit_first_50000/pettingzoo_double_dunk_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 4.6596s / 4.6596 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.3826
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 61.6642s / 66.3238 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.1014
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.3477s / 128.6714 s
first_0:                 episode reward: -2.7500,                 loss: nan
second_0:                 episode reward: 2.7500,                 loss: 0.0547
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.8448s / 191.5163 s
first_0:                 episode reward: -2.3500,                 loss: nan
second_0:                 episode reward: 2.3500,                 loss: 0.0455
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.8317s / 254.3480 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0383
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 63.9974s / 318.3454 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0352
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.1570s / 382.5024 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0343
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.6928s / 447.1953 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0352
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.0680s / 512.2633 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0346
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.4726s / 577.7359 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0360
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.9354s / 643.6713 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0355
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.2088s / 709.8800 s
first_0:                 episode reward: -2.4500,                 loss: nan
second_0:                 episode reward: 2.4500,                 loss: 0.0333
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.5482s / 776.4282 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0307
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.8004s / 843.2286 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0288
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 67.4687s / 910.6973 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0265
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 67.8221s / 978.5194 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0253
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 68.5440s / 1047.0634 s
first_0:                 episode reward: -4.8500,                 loss: nanpygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
Load double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 478
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f1a866430f0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111]) array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125])]
Load checkpoints (policy family):  [list(['23', '90', '342', '555', '1225', '1908', '2617', '4059', '4631']) list(['44', '310', '525', '1084', '1538', '2527', '3197', '4296'])]
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220425_1813/pettingzoo_double_dunk_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 15, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220425_1813_exploit_first/pettingzoo_double_dunk_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220425_1813_exploit_first/pettingzoo_double_dunk_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.4571s / 5.4571 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.3387
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8676s / 85.3247 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0838
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 83.2725s / 168.5971 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0390
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.4150s / 253.0121 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0291
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.0857s / 338.0978 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0284
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6716s / 424.7695 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0261
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9921s / 511.7616 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0257
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.9720s / 600.7336 s
first_0:                 episode reward: -2.9000,                 loss: nan
second_0:                 episode reward: 2.9000,                 loss: 0.0232
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.4412s / 691.1748 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0234
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.4962s / 782.6710 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0224
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.6274s / 876.2984 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0222
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.5093s / 969.8077 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0216
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.8528s / 1065.6605 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0209
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5158s / 1163.1763 s
first_0:                 episode reward: -2.3000,                 loss: nan
second_0:                 episode reward: 2.3000,                 loss: 0.0209
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4434s / 1262.6196 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0203
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.1062s / 1364.7258 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0204
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4686s / 1469.1944 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0200
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6933s / 1575.8878 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0198
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8770s / 1682.7647 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0194
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4137s / 1788.1784 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0194
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1872s / 1893.3656 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0198
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3542s / 1998.7198 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0201
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7934s / 2104.5132 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0194
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6354s / 2211.1486 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0199
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9300s / 2316.0786 s
first_0:                 episode reward: -2.7500,                 loss: nan
second_0:                 episode reward: 2.7500,                 loss: 0.0196
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4735s / 2421.5521 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0190
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9324s / 2527.4845 s
first_0:                 episode reward: -3.2500,                 loss: nan
second_0:                 episode reward: 3.2500,                 loss: 0.0185
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0943s / 2632.5788 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0180
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7618s / 2739.3406 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0174
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9389s / 2845.2795 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0182
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9522s / 2951.2317 s
first_0:                 episode reward: -3.2500,                 loss: nan
second_0:                 episode reward: 3.2500,                 loss: 0.0180
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7727s / 3057.0044 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0181
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1141s / 3163.1185 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0181
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0696s / 3269.1881 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0178
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0575s / 3376.2456 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0174
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4816s / 3481.7272 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0173
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7462s / 3587.4734 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0172
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9864s / 3693.4598 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0168
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1139s / 3799.5737 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0172
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3843s / 3904.9579 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0165
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7836s / 4009.7416 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0163
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8253s / 4116.5668 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0165
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4042s / 4222.9710 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0164
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5906s / 4329.5616 s
first_0:                 episode reward: -2.6000,                 loss: nan
second_0:                 episode reward: 2.6000,                 loss: 0.0161
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6617s / 4435.2232 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0162
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6145s / 4540.8377 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0162
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0378s / 4645.8755 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0162
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0999s / 4752.9754 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0158
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0672s / 4859.0426 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0161
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5071s / 4965.5497 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0157
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3312s / 5071.8809 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0161
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8369s / 5177.7178 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0154
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8652s / 5284.5830 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0154
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2063s / 5390.7893 s
first_0:                 episode reward: -2.9000,                 loss: nan
second_0:                 episode reward: 2.9000,                 loss: 0.0155
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3520s / 5496.1413 s
first_0:                 episode reward: -2.3500,                 loss: nan
second_0:                 episode reward: 2.3500,                 loss: 0.0157
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9615s / 5602.1029 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0154
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7696s / 5708.8725 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0150
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7982s / 5814.6707 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0149
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8221s / 5920.4928 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0147
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1671s / 6026.6598 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0147
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3409s / 6134.0008 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0142
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4337s / 6241.4345 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0145
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7533s / 6348.1878 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0147
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3994s / 6455.5872 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0149
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0696s / 6562.6568 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0146
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5758s / 6669.2326 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0142
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5987s / 6775.8313 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0141
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6856s / 6883.5168 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0139
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2398s / 6989.7566 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0141
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1505s / 7096.9072 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0141
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8135s / 7203.7207 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0140
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0638s / 7310.7846 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0139
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2237s / 7418.0082 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0145
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1721s / 7525.1803 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0138
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0117s / 7632.1920 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0141
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0704s / 7738.2624 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0141
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9747s / 7844.2371 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0140
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0426s / 7951.2798 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0139
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1703s / 8058.4501 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0140
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1582s / 8166.6083 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0142
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5525s / 8273.1608 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0142
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6472s / 8379.8080 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0148
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1602s / 8486.9682 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0149
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9569s / 8594.9251 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0145
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6594s / 8701.5846 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0147
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7379s / 8808.3225 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0146
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5623s / 8914.8847 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0143
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.7334s / 9023.6182 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0147
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6617s / 9131.2799 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0148
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9966s / 9238.2764 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0149
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0151s / 9346.2915 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0145
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0606s / 9453.3521 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0147
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8233s / 9560.1755 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0151
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1542s / 9666.3296 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0152
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3401s / 9772.6697 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0151
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9320s / 9880.6017 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0150
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7474s / 9988.3491 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0147
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4123s / 10095.7614 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0144
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4916s / 10203.2530 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0143
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3319s / 10310.5849 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0142
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7080s / 10418.2929 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0145
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4252s / 10524.7181 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0143
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8813s / 10630.5994 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0144
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5496s / 10738.1491 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0146
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6003s / 10845.7494 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0143
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6257s / 10953.3751 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0145
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1017s / 11061.4768 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0152
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4633s / 11167.9401 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0152
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2020s / 11275.1422 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0149
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0901s / 11381.2323 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0152
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6063s / 11487.8385 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0151
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5986s / 11594.4371 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0152
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3307s / 11701.7678 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0150
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7889s / 11809.5567 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0152
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8561s / 11916.4128 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0153
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6423s / 12024.0551 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0151
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3868s / 12130.4419 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0151
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1886s / 12237.6305 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0155
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1178s / 12344.7484 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0153
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5751s / 12452.3235 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0153
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6507s / 12559.9742 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0150
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.4942s / 12668.4684 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0154
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8667s / 12776.3351 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0155
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1228s / 12884.4579 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0152
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4014s / 12991.8593 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0153
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3634s / 13098.2226 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0154
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0625s / 13205.2851 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0157
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1061s / 13312.3912 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0156
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0778s / 13419.4690 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0157
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0361s / 13526.5050 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0157
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.4017s / 13634.9068 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0157
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5545s / 13741.4612 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0159
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4262s / 13848.8874 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0159
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1084s / 13955.9958 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0155
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0294s / 14064.0252 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0154
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5858s / 14171.6109 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0157
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7700s / 14279.3809 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0152
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0548s / 14386.4358 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0156
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2903s / 14493.7261 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0156
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9565s / 14599.6826 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0157
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1530s / 14707.8356 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0159
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3797s / 14814.2153 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0162
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6154s / 14920.8307 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0161
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1220s / 15027.9527 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0163
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3475s / 15135.3002 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0165
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1833s / 15242.4835 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0166
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.3446s / 15350.8281 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0166
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4714s / 15458.2994 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0161
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2925s / 15564.5920 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0163
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7058s / 15672.2978 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0163
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1260s / 15779.4237 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0163
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7993s / 15887.2230 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0167
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2355s / 15993.4585 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0166
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.5543s / 16102.0128 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0166
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4295s / 16209.4423 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0163
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4216s / 16315.8640 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0165
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.0502s / 16424.9141 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0163
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7583s / 16531.6725 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0161
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6452s / 16639.3177 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0161
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5255s / 16745.8432 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0163
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7512s / 16852.5944 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0160
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0871s / 16959.6815 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0162
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4807s / 17066.1622 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0156
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2898s / 17173.4519 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0158
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2764s / 17280.7283 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0154
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4363s / 17387.1646 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0157
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8532s / 17494.0178 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0155
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9068s / 17601.9246 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0155
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.6010s / 17711.5256 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0153
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5338s / 17819.0593 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0152
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2748s / 17926.3341 s
first_0:                 episode reward: -6.1000,                 loss: nan
second_0:                 episode reward: 6.1000,                 loss: 0.0155
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7737s / 18034.1078 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0152
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6572s / 18140.7650 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0152
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0672s / 18247.8322 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0153
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8687s / 18354.7008 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0153
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.2448s / 18462.9456 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0152
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0460s / 18569.9917 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0150
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7180s / 18676.7097 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0152
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2774s / 18783.9871 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0152
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4373s / 18891.4244 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0150
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.2656s / 19000.6900 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0150
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0190s / 19108.7089 s
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.0150
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0690s / 19216.7779 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0151
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.2393s / 19325.0172 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0153
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.8996s / 19433.9168 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0153
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0399s / 19540.9567 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0155
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4658s / 19648.4225 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0158
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9254s / 19755.3479 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0152
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9065s / 19863.2544 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0157
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7900s / 19969.0444 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0156
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6084s / 20076.6529 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0157
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7460s / 20184.3988 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0154
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1583s / 20290.5571 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0153
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5818s / 20398.1390 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0157
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9623s / 20506.1012 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0163
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.4985s / 20614.5998 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0161
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9769s / 20722.5767 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0159
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4723s / 20830.0490 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0155
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0202s / 20937.0692 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0152
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8530s / 21043.9222 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0152
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3173s / 21150.2395 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0150
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.6569s / 21258.8964 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0151
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9565s / 21366.8529 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0154
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.8427s / 21475.6956 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0158
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0396s / 21583.7352 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0156
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7698s / 21691.5050 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0158
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3338s / 21798.8388 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0158
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6938s / 21906.5326 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0160
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9306s / 22014.4632 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0158
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9084s / 22122.3716 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0160
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5360s / 22229.9076 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0159
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7668s / 22337.6744 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0159
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1434s / 22445.8178 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0158
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1432s / 22552.9610 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0160
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8715s / 22660.8326 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0160
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1438s / 22767.9764 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0160
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7711s / 22875.7476 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0156
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4465s / 22983.1941 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0158
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3536s / 23090.5477 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0158
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1255s / 23198.6731 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0160
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.7555s / 23307.4287 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0158
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1533s / 23413.5819 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0157
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3086s / 23520.8905 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0160
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.5065s / 23629.3970 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0162
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4986s / 23736.8956 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0162
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2680s / 23844.1636 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0164
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6127s / 23950.7763 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0160
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.7737s / 24059.5499 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0165
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3006s / 24165.8505 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0165
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4671s / 24273.3175 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0163
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1647s / 24379.4823 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0159
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1993s / 24486.6816 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0161
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.7225s / 24595.4041 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0161
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0223s / 24702.4264 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0161
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0635s / 24809.4899 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0155
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3189s / 24916.8088 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0160
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.7511s / 25025.5599 s
first_0:                 episode reward: -6.6500,                 loss: nan
second_0:                 episode reward: 6.6500,                 loss: 0.0157
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.5935s / 25134.1534 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0156
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.8877s / 25243.0411 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0156
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6486s / 25350.6897 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0158
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.8639s / 25460.5536 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0155
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0742s / 25568.6278 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0157
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1243s / 25674.7521 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0156
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9699s / 25781.7220 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0155
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3859s / 25889.1079 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0153
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.0654s / 25997.1733 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0152
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5142s / 26104.6875 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0153
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.5008s / 26213.1884 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0156
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9916s / 26320.1799 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0157
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2084s / 26427.3883 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0155
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3712s / 26533.7595 s
first_0:                 episode reward: -6.3000,                 loss: nan
second_0:                 episode reward: 6.3000,                 loss: 0.0152
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.7282s / 26641.4877 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0149
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.1732s / 26749.6609 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0153
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8395s / 26857.5003 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0150
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1939s / 26963.6942 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0150
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2705s / 27069.9647 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0151
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7818s / 27175.7466 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0150
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8531s / 27281.5996 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0149
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4102s / 27387.0098 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0154
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6009s / 27492.6107 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0154
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4474s / 27600.0581 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0156
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8806s / 27704.9387 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0153
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7425s / 27810.6812 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0153
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1678s / 27915.8490 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0155
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1874s / 28023.0364 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0157
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2943s / 28129.3307 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0155
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4266s / 28234.7574 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0157
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4901s / 28341.2475 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0155
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8140s / 28449.0615 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0155
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2004s / 28555.2620 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0150
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6327s / 28662.8947 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0154
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8021s / 28768.6968 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0154
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4224s / 28875.1191 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0156
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7123s / 28981.8314 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0157
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7182s / 29087.5497 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0160
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2456s / 29194.7952 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0160
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4003s / 29300.1956 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0159
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9779s / 29407.1735 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0157
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5935s / 29513.7670 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0157
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4202s / 29621.1872 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0157
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7239s / 29726.9111 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0159
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0949s / 29833.0060 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0158
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8189s / 29939.8249 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0156
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0121s / 30046.8370 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0154
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2049s / 30153.0419 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0153
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4681s / 30259.5100 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0154
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6196s / 30366.1297 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0156
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5204s / 30472.6501 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0156
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1181s / 30579.7682 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0158
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0214s / 30686.7895 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0159
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5988s / 30792.3883 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0159
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.4904s / 30900.8787 s
first_0:                 episode reward: -6.1000,                 loss: nan
second_0:                 episode reward: 6.1000,                 loss: 0.0155
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9577s / 31006.8364 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0159
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6549s / 31113.4913 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0158
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0002s / 31220.4914 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0159
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6429s / 31327.1344 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0160
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5341s / 31432.6685 s
first_0:                 episode reward: -6.3000,                 loss: nan
second_0:                 episode reward: 6.3000,                 loss: 0.0161
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9456s / 31539.6141 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0162
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4874s / 31647.1016 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0163
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6329s / 31753.7344 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0167
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5705s / 31860.3049 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0167
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5256s / 31965.8304 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0165
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3330s / 32072.1634 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0163
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8001s / 32178.9635 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0167
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2549s / 32286.2185 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0169
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5903s / 32393.8087 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0166
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0095s / 32499.8182 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0163
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3145s / 32607.1328 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0163
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2424s / 32713.3751 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0167
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6977s / 32819.0728 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0169
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5930s / 32925.6658 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0174
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5710s / 33032.2369 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0172
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4173s / 33138.6542 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0171
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8734s / 33244.5276 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0170
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0975s / 33351.6251 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0166
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6256s / 33458.2506 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0167
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2660s / 33564.5166 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0165
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1342s / 33670.6508 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0164
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2249s / 33776.8757 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0169
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9321s / 33882.8078 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0173
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.6889s / 33990.4967 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0177
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4941s / 34097.9908 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0178
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4535s / 34204.4443 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0172
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3846s / 34311.8289 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0164
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1885s / 34419.0175 s
first_0:                 episode reward: -6.3000,                 loss: nan
second_0:                 episode reward: 6.3000,                 loss: 0.0165
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5273s / 34526.5448 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0167
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3636s / 34631.9084 s
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.0163
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6356s / 34738.5440 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0165
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3654s / 34844.9094 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0158
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0135s / 34951.9229 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0159
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5919s / 35057.5148 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0161
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6311s / 35164.1459 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0160
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8597s / 35271.0056 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0163
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9294s / 35376.9350 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0162
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5837s / 35483.5186 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0160
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6378s / 35588.1564 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0159
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5202s / 35694.6766 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0157
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6543s / 35800.3310 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0158
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7040s / 35907.0350 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0157
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9891s / 36014.0241 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0157
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4120s / 36119.4360 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0156
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.5315s / 36226.9676 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0155
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5586s / 36333.5261 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0157
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1828s / 36439.7089 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0158
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3930s / 36546.1019 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0158
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1612s / 36652.2631 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0159
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1410s / 36757.4042 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0160
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8217s / 36864.2258 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0161
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6050s / 36969.8308 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0162
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7109s / 37076.5417 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0159
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9890s / 37182.5307 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0162
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2893s / 37288.8200 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0159
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.2460s / 37396.0660 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0157
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0056s / 37502.0716 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0159
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2096s / 37608.2812 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0155
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7046s / 37714.9858 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0157
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4040s / 37820.3898 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0158
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9472s / 37920.3370 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0159
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7186s / 38019.0556 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0155
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3359s / 38116.3915 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0158
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3785s / 38215.7700 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0156
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2736s / 38315.0436 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0157
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1597s / 38414.2033 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0159
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7246s / 38513.9279 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0161
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9311s / 38613.8590 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0159
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8578s / 38712.7168 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0160
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7910s / 38812.5078 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0166
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9451s / 38911.4529 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0164
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6225s / 39012.0754 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0164
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2736s / 39111.3490 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0166
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1539s / 39209.5030 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0166
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8097s / 39309.3127 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0165
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6267s / 39406.9394 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0167
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2247s / 39507.1640 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0165
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4446s / 39605.6086 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0167
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7364s / 39705.3450 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0167
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6796s / 39805.0246 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0171
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5299s / 39905.5545 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0168
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7746s / 40006.3292 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0169
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1154s / 40106.4445 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0168
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2664s / 40204.7109 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0167
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7145s / 40303.4254 s
first_0:                 episode reward: -6.6000,                 loss: nan
second_0:                 episode reward: 6.6000,                 loss: 0.0168
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6663s / 40402.0917 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0168
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7478s / 40501.8395 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0168
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3357s / 40602.1752 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0166
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8050s / 40701.9802 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0159
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5100s / 40801.4902 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0161
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9043s / 40901.3944 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0165
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5716s / 41001.9660 s
first_0:                 episode reward: -2.6000,                 loss: nan
second_0:                 episode reward: 2.6000,                 loss: 0.0168
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0936s / 41101.0596 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0167
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9177s / 41200.9774 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0166
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6490s / 41300.6264 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0165
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4715s / 41399.0979 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0161
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0404s / 41498.1383 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0163
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2243s / 41596.3626 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0167
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4869s / 41695.8495 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0162
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.8202s / 41796.6697 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0167
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6148s / 41895.2845 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0162
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6841s / 41994.9686 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0164
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8002s / 42094.7688 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0165
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.1040s / 42195.8729 s
first_0:                 episode reward: -2.4500,                 loss: nan
second_0:                 episode reward: 2.4500,                 loss: 0.0169
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3614s / 42295.2343 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0168
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1191s / 42394.3534 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0168
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3738s / 42493.7271 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0172
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4062s / 42592.1333 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0171
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.9069s / 42693.0402 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0171
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0308s / 42794.0710 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0168
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2330s / 42892.3040 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0167
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2710s / 42989.5750 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0168
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5687s / 43089.1438 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0173
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6723s / 43187.8160 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0172
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0690s / 43286.8850 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0171
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2422s / 43386.1272 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0167
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0118s / 43485.1390 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0168
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0751s / 43583.2141 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0174
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2744s / 43682.4886 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0168
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4865s / 43780.9751 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0172
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6745s / 43881.6496 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0174
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2401s / 43981.8897 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0172
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2380s / 44081.1277 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0172
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4373s / 44180.5650 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0170
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3837s / 44279.9487 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0172
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4544s / 44380.4031 s
first_0:                 episode reward: -6.3500,                 loss: nan
second_0:                 episode reward: 6.3500,                 loss: 0.0172
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7143s / 44480.1174 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0174
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5791s / 44579.6965 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0177
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3997s / 44678.0962 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0190
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6443s / 44776.7405 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0208
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6705s / 44876.4110 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0206
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1767s / 44976.5877 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0194
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8383s / 45075.4260 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0193
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7760s / 45176.2020 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0185
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2921s / 45274.4941 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0179
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7611s / 45374.2552 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0174
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2636s / 45474.5189 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0171
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2926s / 45573.8115 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0172
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4023s / 45673.2137 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0169
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4032s / 45771.6169 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0171
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3425s / 45871.9594 s
first_0:                 episode reward: -6.2500,                 loss: nan
second_0:                 episode reward: 6.2500,                 loss: 0.0168
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6872s / 45970.6467 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0171
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5801s / 46070.2267 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0173
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.8915s / 46172.1183 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0171
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6319s / 46269.7502 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0170
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4135s / 46368.1637 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0168
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2165s / 46467.3802 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0166
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3898s / 46565.7700 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0172
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1439s / 46663.9139 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0167
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.6053s / 46764.5192 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0167
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3456s / 46862.8648 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0167
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8728s / 46961.7376 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0165
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1672s / 47061.9048 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0167
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1692s / 47161.0740 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0169
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1776s / 47260.2516 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0166
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2627s / 47360.5143 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0164
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.5695s / 47459.0838 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0164
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5253s / 47556.6091 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0164
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7081s / 47656.3171 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0163
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9093s / 47755.2264 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0166
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8806s / 47855.1070 s
first_0:                 episode reward: -6.3000,                 loss: nan
second_0:                 episode reward: 6.3000,                 loss: 0.0167
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3092s / 47954.4162 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0166
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1293s / 48054.5455 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0167
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1112s / 48153.6566 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0167
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.7733s / 48254.4299 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0166
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9890s / 48353.4189 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0165
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7127s / 48453.1317 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0166
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3038s / 48553.4355 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0164
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2661s / 48653.7016 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0167
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8837s / 48753.5853 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0164
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2872s / 48853.8725 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0164
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5409s / 48954.4133 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0166
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.0212s / 49055.4346 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0168
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7744s / 49155.2089 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0166
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9659s / 49254.1749 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0163
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2413s / 49354.4162 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0165
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4625s / 49454.8787 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0168
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1273s / 49553.0060 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0165
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9302s / 49651.9362 s/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0164
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5628s / 49751.4990 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0167
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1142s / 49851.6132 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0163
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6501s / 49951.2633 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0166
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3570s / 50050.6203 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0171
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0893s / 50148.7095 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0166
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2095s / 50247.9190 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0168
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7736s / 50347.6926 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0167
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0335s / 50447.7261 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0168
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0125s / 50547.7386 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0170
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1840s / 50645.9226 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0170
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7590s / 50744.6816 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0168
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8345s / 50842.5161 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0168
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2300s / 50941.7461 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0168
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7726s / 51041.5187 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0164
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8621s / 51139.3807 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0167
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6878s / 51237.0686 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0167
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5823s / 51334.6509 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0165
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.0381s / 51427.6890 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0162
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.6574s / 51522.3464 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0159
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.5087s / 51615.8551 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0157
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3448s / 51703.1999 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0155
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.1358s / 51788.3357 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0156
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5739s / 51865.9096 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0157
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 70.4026s / 51936.3122 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0155
