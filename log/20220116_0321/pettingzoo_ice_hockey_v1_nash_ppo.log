pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
ice_hockey_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [70, 76]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'ice_hockey_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220116_0321/pettingzoo_ice_hockey_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116_0321/pettingzoo_ice_hockey_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 2825.0,                last time consumption/overall running time: 37.5627s / 37.5627 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.4341
env0_second_0:                 episode reward: 3.0000,                 loss: -0.4443
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2843.25,                last time consumption/overall running time: 747.4307s / 784.9934 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4337
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4320
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2837.35,                last time consumption/overall running time: 744.3882s / 1529.3817 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4304
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4325
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2856.85,                last time consumption/overall running time: 753.4040s / 2282.7857 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.4310
env0_second_0:                 episode reward: 0.6500,                 loss: -0.4299
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2804.5,                last time consumption/overall running time: 737.1994s / 3019.9851 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4417
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4391
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2840.0,                last time consumption/overall running time: 745.4244s / 3765.4095 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4311
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4316
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2823.3,                last time consumption/overall running time: 745.2212s / 4510.6307 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4284
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4227
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2830.7,                last time consumption/overall running time: 746.9011s / 5257.5318 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4292
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4296
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2823.5,                last time consumption/overall running time: 738.6359s / 5996.1678 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4356
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4326
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2850.45,                last time consumption/overall running time: 749.1009s / 6745.2686 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4347
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4295
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2822.2,                last time consumption/overall running time: 741.1744s / 7486.4430 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4345
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4302
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2825.95,                last time consumption/overall running time: 741.0234s / 8227.4663 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.4380
env0_second_0:                 episode reward: 1.3000,                 loss: -0.4384
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 2851.15,                last time consumption/overall running time: 749.2022s / 8976.6685 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4347
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4345
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2848.75,                last time consumption/overall running time: 747.0411s / 9723.7097 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.4325
env0_second_0:                 episode reward: 0.9500,                 loss: -0.4306
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 2859.85,                last time consumption/overall running time: 746.8302s / 10470.5399 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4303
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4303
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2843.5,                last time consumption/overall running time: 744.5922s / 11215.1321 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4331
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4336
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2847.0,                last time consumption/overall running time: 747.8240s / 11962.9561 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4343
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4327
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 2857.0,                last time consumption/overall running time: 751.2536s / 12714.2098 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4359
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 2859.95,                last time consumption/overall running time: 749.1147s / 13463.3244 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4360
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4316
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 2847.55,                last time consumption/overall running time: 747.7998s / 14211.1242 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4344
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4361
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 2851.65,                last time consumption/overall running time: 747.0471s / 14958.1713 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4381
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4363
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 2835.45,                last time consumption/overall running time: 743.0053s / 15701.1766 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4344
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4338
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 2811.2,                last time consumption/overall running time: 734.9786s / 16436.1552 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4421
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4408
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 2838.4,                last time consumption/overall running time: 746.3171s / 17182.4723 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4385
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4398
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 2845.4,                last time consumption/overall running time: 747.9249s / 17930.3972 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.4344
env0_second_0:                 episode reward: 0.9000,                 loss: -0.4383
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 2825.9,                last time consumption/overall running time: 741.5667s / 18671.9640 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4440
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4417
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 2831.95,                last time consumption/overall running time: 741.7546s / 19413.7186 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4443
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 2843.6,                last time consumption/overall running time: 742.8730s / 20156.5915 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4373
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4423
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 2842.65,                last time consumption/overall running time: 746.3425s / 20902.9340 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4381
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4353
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 2820.15,                last time consumption/overall running time: 741.5398s / 21644.4738 s
env0_first_0:                 episode reward: -1.4000,                 loss: -0.4431
env0_second_0:                 episode reward: 1.4000,                 loss: -0.4389
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 2811.75,                last time consumption/overall running time: 734.0907s / 22378.5645 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4437
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4432
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 2829.4,                last time consumption/overall running time: 739.8349s / 23118.3994 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4383
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4332
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2855.0,                last time consumption/overall running time: 747.7374s / 23866.1368 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4348
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4313
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 2832.7,                last time consumption/overall running time: 742.9769s / 24609.1137 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4374
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4370
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 2873.05,                last time consumption/overall running time: 750.5915s / 25359.7052 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.4338
env0_second_0:                 episode reward: 1.0000,                 loss: -0.4342
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 2860.15,                last time consumption/overall running time: 750.2690s / 26109.9742 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4371
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4380
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2860.5,                last time consumption/overall running time: 748.5549s / 26858.5292 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4377
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4367
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2851.7,                last time consumption/overall running time: 747.9947s / 27606.5239 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4325
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4373
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2815.75,                last time consumption/overall running time: 739.8646s / 28346.3885 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4422
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4414
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2864.35,                last time consumption/overall running time: 752.3463s / 29098.7348 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.4376
env0_second_0:                 episode reward: -0.8000,                 loss: -0.4349
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2842.95,                last time consumption/overall running time: 746.3420s / 29845.0768 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4315
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4297
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2855.75,                last time consumption/overall running time: 747.5939s / 30592.6707 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4350
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4370
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2849.1,                last time consumption/overall running time: 747.6067s / 31340.2774 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4378
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2857.05,                last time consumption/overall running time: 748.0619s / 32088.3394 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4313
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4305
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2856.9,                last time consumption/overall running time: 749.0172s / 32837.3566 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4294
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4259
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2856.3,                last time consumption/overall running time: 749.7095s / 33587.0660 s
env0_first_0:                 episode reward: 1.8000,                 loss: -0.4303
env0_second_0:                 episode reward: -1.8000,                 loss: -0.4316
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2854.25,                last time consumption/overall running time: 750.7495s / 34337.8155 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4358
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4371
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2837.85,                last time consumption/overall running time: 745.2547s / 35083.0702 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4380
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4386
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2867.85,                last time consumption/overall running time: 754.4073s / 35837.4775 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4257
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4230
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2858.45,                last time consumption/overall running time: 749.7294s / 36587.2070 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4378
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4342
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2837.9,                last time consumption/overall running time: 744.6600s / 37331.8670 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4318
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4312
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2826.05,                last time consumption/overall running time: 739.5867s / 38071.4537 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4319
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4342
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2817.75,                last time consumption/overall running time: 734.4595s / 38805.9132 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4361
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4331
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 2856.15,                last time consumption/overall running time: 750.4680s / 39556.3812 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4331
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4353
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2859.35,                last time consumption/overall running time: 749.1941s / 40305.5753 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4305
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4296
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2827.8,                last time consumption/overall running time: 738.4441s / 41044.0194 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4404
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4407
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2806.05,                last time consumption/overall running time: 734.5805s / 41778.5999 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4452
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4395
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2796.7,                last time consumption/overall running time: 732.7801s / 42511.3800 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4413
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4411
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2838.45,                last time consumption/overall running time: 738.9777s / 43250.3576 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4284
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4239
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2859.65,                last time consumption/overall running time: 749.8285s / 44000.1862 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.4295
env0_second_0:                 episode reward: 1.3500,                 loss: -0.4247
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2852.35,                last time consumption/overall running time: 743.0590s / 44743.2452 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4363
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4379
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2825.05,                last time consumption/overall running time: 738.2808s / 45481.5260 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4401
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4410
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2796.9,                last time consumption/overall running time: 730.7843s / 46212.3103 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4427
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4426
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2799.65,                last time consumption/overall running time: 726.6413s / 46938.9517 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4431
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4422
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2852.0,                last time consumption/overall running time: 744.5984s / 47683.5501 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.4360
env0_second_0:                 episode reward: -1.4500,                 loss: -0.4325
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2868.95,                last time consumption/overall running time: 751.0169s / 48434.5670 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4304
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4271
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2869.05,                last time consumption/overall running time: 747.6432s / 49182.2102 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4253
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4234
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2850.8,                last time consumption/overall running time: 744.4082s / 49926.6184 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4314
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4260
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2849.5,                last time consumption/overall running time: 752.4987s / 50679.1171 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4209
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4151
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2852.75,                last time consumption/overall running time: 747.3799s / 51426.4970 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4289
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4269
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2826.15,                last time consumption/overall running time: 735.3001s / 52161.7971 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4327
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4286
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2816.1,                last time consumption/overall running time: 684.5132s / 52846.3103 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4399
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2837.8,                last time consumption/overall running time: 693.1512s / 53539.4615 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4353
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4344
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2878.9,                last time consumption/overall running time: 664.9436s / 54204.4051 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4293
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4286
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2901.9,                last time consumption/overall running time: 640.5663s / 54844.9714 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4281
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4261
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2824.8,                last time consumption/overall running time: 620.3928s / 55465.3642 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4389
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4376
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 2818.5,                last time consumption/overall running time: 594.8530s / 56060.2172 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4418
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4437
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2834.65,                last time consumption/overall running time: 576.9048s / 56637.1220 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4368
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4363
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2835.05,                last time consumption/overall running time: 574.5267s / 57211.6486 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4370
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4361
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2839.9,                last time consumption/overall running time: 567.1153s / 57778.7639 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4396
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4407
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2841.55,                last time consumption/overall running time: 573.8738s / 58352.6378 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4436
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4450
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 2845.4,                last time consumption/overall running time: 573.0693s / 58925.7070 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.4405
env0_second_0:                 episode reward: -1.7000,                 loss: -0.4431
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2803.5,                last time consumption/overall running time: 564.0588s / 59489.7658 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4468
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4484
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2808.9,                last time consumption/overall running time: 567.6979s / 60057.4637 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4422
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4413
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2850.6,                last time consumption/overall running time: 576.2708s / 60633.7345 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4343
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4368
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 2816.75,                last time consumption/overall running time: 564.1173s / 61197.8518 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4421
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4410
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2808.9,                last time consumption/overall running time: 564.1865s / 61762.0383 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4461
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4454
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2838.5,                last time consumption/overall running time: 573.4043s / 62335.4426 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4419
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4381
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2867.85,                last time consumption/overall running time: 579.1160s / 62914.5585 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4316
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4289
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2839.65,                last time consumption/overall running time: 574.9233s / 63489.4818 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4354
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4301
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2828.2,                last time consumption/overall running time: 573.4549s / 64062.9368 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4375
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4347
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2811.85,                last time consumption/overall running time: 563.8143s / 64626.7511 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4414
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4368
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2812.1,                last time consumption/overall running time: 564.8645s / 65191.6156 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4376
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4359
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2838.15,                last time consumption/overall running time: 553.6471s / 65745.2627 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4334
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4349
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2839.0,                last time consumption/overall running time: 512.9340s / 66258.1967 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4339
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4319
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2842.4,                last time consumption/overall running time: 524.5283s / 66782.7250 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4415
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4398
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2864.9,                last time consumption/overall running time: 526.4009s / 67309.1259 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4314
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4288
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2870.35,                last time consumption/overall running time: 520.0920s / 67829.2179 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4245
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4226
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2842.45,                last time consumption/overall running time: 517.4784s / 68346.6962 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4375
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4354
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2825.05,                last time consumption/overall running time: 516.4508s / 68863.1470 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4399
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4403
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2846.2,                last time consumption/overall running time: 516.9046s / 69380.0516 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4370
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4391
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2849.4,                last time consumption/overall running time: 519.8425s / 69899.8941 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.4363
env0_second_0:                 episode reward: 0.9000,                 loss: -0.4340
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2848.4,                last time consumption/overall running time: 515.8545s / 70415.7486 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4330
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4314
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2832.95,                last time consumption/overall running time: 514.5948s / 70930.3434 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4391
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4408
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2820.85,                last time consumption/overall running time: 514.5092s / 71444.8526 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4339
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4285
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2831.35,                last time consumption/overall running time: 515.4266s / 71960.2792 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4268
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4187
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2843.55,                last time consumption/overall running time: 513.7146s / 72473.9938 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4177
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4163
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2822.3,                last time consumption/overall running time: 511.6274s / 72985.6212 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4297
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4317
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2852.05,                last time consumption/overall running time: 517.1112s / 73502.7325 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4376
env0_second_0:                 episode reward: -1.0000,                 loss: -0.4363
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2809.4,                last time consumption/overall running time: 509.1206s / 74011.8531 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4432
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4403
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2861.3,                last time consumption/overall running time: 518.9026s / 74530.7557 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4361
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2859.95,                last time consumption/overall running time: 519.2903s / 75050.0459 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4371
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4328
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2841.1,                last time consumption/overall running time: 515.9439s / 75565.9898 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4425
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4455
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2833.25,                last time consumption/overall running time: 511.8425s / 76077.8322 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4449
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4423
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2863.2,                last time consumption/overall running time: 518.5202s / 76596.3525 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4359
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4355
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2805.8,                last time consumption/overall running time: 508.6145s / 77104.9670 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4447
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4434
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2845.4,                last time consumption/overall running time: 519.2611s / 77624.2281 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4319
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4279
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2830.45,                last time consumption/overall running time: 510.8095s / 78135.0376 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4364
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4308
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2830.65,                last time consumption/overall running time: 510.4562s / 78645.4939 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4426
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4398
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2833.0,                last time consumption/overall running time: 512.8902s / 79158.3840 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4376
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4383
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2827.0,                last time consumption/overall running time: 510.5711s / 79668.9551 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4381
env0_second_0:                 episode reward: -1.3500,                 loss: -0.4361
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2844.45,                last time consumption/overall running time: 511.8223s / 80180.7775 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4385
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4372
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2835.6,                last time consumption/overall running time: 511.3374s / 80692.1148 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4401
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4413
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2815.45,                last time consumption/overall running time: 510.2220s / 81202.3369 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4436
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4431
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2839.0,                last time consumption/overall running time: 510.3848s / 81712.7217 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4359
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2819.2,                last time consumption/overall running time: 508.9848s / 82221.7065 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4447
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4453
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2837.05,                last time consumption/overall running time: 510.5250s / 82732.2315 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4434
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4443
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2804.45,                last time consumption/overall running time: 510.0410s / 83242.2725 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4458
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4439
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2804.6,                last time consumption/overall running time: 522.2452s / 83764.5177 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4494
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4442
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2850.0,                last time consumption/overall running time: 521.1700s / 84285.6877 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4437
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4401
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2849.25,                last time consumption/overall running time: 515.2585s / 84800.9462 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4365
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4377
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2841.55,                last time consumption/overall running time: 513.8369s / 85314.7830 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4404
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4367
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2838.45,                last time consumption/overall running time: 514.5136s / 85829.2967 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.4368
env0_second_0:                 episode reward: -0.8000,                 loss: -0.4325
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2826.8,                last time consumption/overall running time: 512.8421s / 86342.1388 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4367
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4311
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2832.95,                last time consumption/overall running time: 509.2057s / 86851.3445 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4384
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4387
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2822.25,                last time consumption/overall running time: 504.8311s / 87356.1756 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4402
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4382
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 2839.5,                last time consumption/overall running time: 509.0215s / 87865.1970 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4376
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4307
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 2841.45,                last time consumption/overall running time: 512.9343s / 88378.1313 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4329
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4332
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2828.3,                last time consumption/overall running time: 507.7731s / 88885.9044 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4382
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4360
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2852.4,                last time consumption/overall running time: 515.1617s / 89401.0661 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4349
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4326
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2835.5,                last time consumption/overall running time: 510.4620s / 89911.5281 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4281
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4269
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2855.2,                last time consumption/overall running time: 513.1599s / 90424.6880 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4288
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4272
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2848.05,                last time consumption/overall running time: 512.8552s / 90937.5432 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4324
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4315
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2845.3,                last time consumption/overall running time: 512.4375s / 91449.9807 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4298
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4247
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2847.65,                last time consumption/overall running time: 508.0241s / 91958.0048 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4253
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4214
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2839.65,                last time consumption/overall running time: 510.5972s / 92468.6020 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4284
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4280
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2849.35,                last time consumption/overall running time: 514.2770s / 92982.8790 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4361
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4317
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2822.35,                last time consumption/overall running time: 509.2133s / 93492.0923 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4388
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4376
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2809.85,                last time consumption/overall running time: 505.7366s / 93997.8289 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4405
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4411
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2822.05,                last time consumption/overall running time: 507.0020s / 94504.8309 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4391
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4399
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2799.1,                last time consumption/overall running time: 502.1857s / 95007.0166 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4420
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4433
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2830.5,                last time consumption/overall running time: 508.0158s / 95515.0324 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4409
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4363
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 2829.95,                last time consumption/overall running time: 508.9124s / 96023.9447 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4378
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4331
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 2818.95,                last time consumption/overall running time: 509.2356s / 96533.1804 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4381
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4347
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 2835.95,                last time consumption/overall running time: 512.3884s / 97045.5688 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4376
env0_second_0:                 episode reward: -1.0000,                 loss: -0.4288
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2861.35,                last time consumption/overall running time: 518.0230s / 97563.5918 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4356
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4292
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 2842.4,                last time consumption/overall running time: 510.5142s / 98074.1060 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4371
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4287
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 2836.15,                last time consumption/overall running time: 509.5503s / 98583.6563 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4391
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4352
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2874.6,                last time consumption/overall running time: 517.7540s / 99101.4103 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4349
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4355
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2883.0,                last time consumption/overall running time: 520.8085s / 99622.2189 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4262
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4251
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2875.0,                last time consumption/overall running time: 520.3356s / 100142.5545 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4272
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4204
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 2880.4,                last time consumption/overall running time: 520.5267s / 100663.0811 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4240
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4204
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2865.0,                last time consumption/overall running time: 518.9878s / 101182.0689 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4201
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4162
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2868.75,                last time consumption/overall running time: 520.8418s / 101702.9107 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4257
env0_second_0:                 episode reward: -1.3500,                 loss: -0.4215
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2830.45,                last time consumption/overall running time: 507.4650s / 102210.3757 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4327
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4295
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2849.9,                last time consumption/overall running time: 516.5667s / 102726.9424 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4335
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4267
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2844.45,                last time consumption/overall running time: 512.2671s / 103239.2095 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4375
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4285
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2820.15,                last time consumption/overall running time: 512.3088s / 103751.5183 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4325
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4280
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 2860.45,                last time consumption/overall running time: 514.3891s / 104265.9074 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4289
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4254
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2878.2,                last time consumption/overall running time: 520.2294s / 104786.1367 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4272
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4236
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2839.95,                last time consumption/overall running time: 513.4357s / 105299.5724 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4292
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4245
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2822.0,                last time consumption/overall running time: 510.4568s / 105810.0292 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4325
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2826.8,                last time consumption/overall running time: 508.0806s / 106318.1098 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4396
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4401
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2819.1,                last time consumption/overall running time: 509.0459s / 106827.1557 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4368
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4402
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2836.3,                last time consumption/overall running time: 512.8255s / 107339.9812 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4357
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4344
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2850.5,                last time consumption/overall running time: 513.3400s / 107853.3212 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4314
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4310
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2832.9,                last time consumption/overall running time: 509.2847s / 108362.6059 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4420
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4387
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2820.55,                last time consumption/overall running time: 510.3550s / 108872.9609 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4393
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4341
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2839.05,                last time consumption/overall running time: 512.7399s / 109385.7008 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.4364
env0_second_0:                 episode reward: -1.4500,                 loss: -0.4348
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 2837.4,                last time consumption/overall running time: 513.4052s / 109899.1060 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4360
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4364
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 2863.75,                last time consumption/overall running time: 514.7063s / 110413.8123 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4297
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4231
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2840.55,                last time consumption/overall running time: 511.7434s / 110925.5557 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4302
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4289
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2837.9,                last time consumption/overall running time: 511.2012s / 111436.7569 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4371
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4310
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 2837.5,                last time consumption/overall running time: 511.3077s / 111948.0647 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4350
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4266
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2818.35,                last time consumption/overall running time: 508.4002s / 112456.4648 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4413
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4411
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2838.35,                last time consumption/overall running time: 510.3611s / 112966.8259 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4381
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4385
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2847.9,                last time consumption/overall running time: 511.2313s / 113478.0573 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4303
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2841.2,                last time consumption/overall running time: 512.1699s / 113990.2272 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4333
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4297
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 2842.1,                last time consumption/overall running time: 514.2035s / 114504.4307 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4397
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4395
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2850.6,                last time consumption/overall running time: 515.9188s / 115020.3496 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4368
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4317
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2841.0,                last time consumption/overall running time: 511.6412s / 115531.9908 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4429
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4442
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 2840.05,                last time consumption/overall running time: 508.5829s / 116040.5736 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4424
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4383
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2822.85,                last time consumption/overall running time: 510.3714s / 116550.9451 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4443
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4374
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2857.85,                last time consumption/overall running time: 490.9006s / 117041.8456 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4317
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4295
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2848.1,                last time consumption/overall running time: 483.3066s / 117525.1522 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4348
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4317
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2845.05,                last time consumption/overall running time: 478.6573s / 118003.8095 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4324
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4291
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 2856.15,                last time consumption/overall running time: 480.2742s / 118484.0837 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4331
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4265
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 2857.45,                last time consumption/overall running time: 483.8475s / 118967.9311 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4322
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4282
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 2846.3,                last time consumption/overall running time: 483.2161s / 119451.1473 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4317
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4228
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 2853.15,                last time consumption/overall running time: 479.7375s / 119930.8848 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4359
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4320
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2866.25,                last time consumption/overall running time: 489.9620s / 120420.8468 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4349
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4284
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 2834.7,                last time consumption/overall running time: 482.7796s / 120903.6264 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4318
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4231
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2878.85,                last time consumption/overall running time: 484.8781s / 121388.5045 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4324
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4275
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2890.95,                last time consumption/overall running time: 484.8631s / 121873.3676 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4261
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4190
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 2888.15,                last time consumption/overall running time: 492.2253s / 122365.5929 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4294
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4232
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2889.45,                last time consumption/overall running time: 485.6601s / 122851.2530 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4363
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4399
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2873.5,                last time consumption/overall running time: 496.1876s / 123347.4406 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4328
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2924.35,                last time consumption/overall running time: 497.3822s / 123844.8227 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4302
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4294
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2847.85,                last time consumption/overall running time: 485.2496s / 124330.0724 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.4322
env0_second_0:                 episode reward: -1.2500,                 loss: -0.4330
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 2868.55,                last time consumption/overall running time: 489.1503s / 124819.2227 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4319
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4283
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2869.95,                last time consumption/overall running time: 489.4645s / 125308.6871 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4269
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4225
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2868.8,                last time consumption/overall running time: 477.3796s / 125786.0667 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4308
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4244
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2846.7,                last time consumption/overall running time: 472.9966s / 126259.0633 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4329
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4284
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2864.1,                last time consumption/overall running time: 480.8732s / 126739.9365 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4326
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4278
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2868.6,                last time consumption/overall running time: 480.4878s / 127220.4244 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4335
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4315
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2830.8,                last time consumption/overall running time: 469.4486s / 127689.8730 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4380
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4347
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2856.8,                last time consumption/overall running time: 473.6080s / 128163.4810 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4380
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4315
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2844.45,                last time consumption/overall running time: 475.8265s / 128639.3075 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4356
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4294
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2853.4,                last time consumption/overall running time: 485.4038s / 129124.7113 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4357
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4293
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2846.1,                last time consumption/overall running time: 483.8091s / 129608.5205 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4323
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4297
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2828.15,                last time consumption/overall running time: 478.1473s / 130086.6677 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4306
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4221
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2893.85,                last time consumption/overall running time: 489.3355s / 130576.0032 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4150
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4123
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2868.65,                last time consumption/overall running time: 488.7446s / 131064.7479 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4122
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4054
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2872.75,                last time consumption/overall running time: 477.9618s / 131542.7097 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4192
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4062
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2822.1,                last time consumption/overall running time: 467.2576s / 132009.9673 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4223
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4168
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2829.05,                last time consumption/overall running time: 442.3715s / 132452.3388 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4201
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4154
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2851.05,                last time consumption/overall running time: 443.8554s / 132896.1942 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4198
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 2847.65,                last time consumption/overall running time: 443.5451s / 133339.7393 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4234
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4150
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 2872.05,                last time consumption/overall running time: 450.4552s / 133790.1946 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4187
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4137
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2866.65,                last time consumption/overall running time: 451.2102s / 134241.4048 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4135
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4070
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2907.05,                last time consumption/overall running time: 462.4071s / 134703.8119 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4020
env0_second_0:                 episode reward: -1.0000,                 loss: -0.3969
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 2848.0,                last time consumption/overall running time: 447.2196s / 135151.0314 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4147
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4086
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 2866.4,                last time consumption/overall running time: 446.0761s / 135597.1075 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4265
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4218
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2852.95,                last time consumption/overall running time: 452.6444s / 136049.7519 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4309
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4305
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2837.0,                last time consumption/overall running time: 452.6309s / 136502.3828 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4340
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4270
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 2838.4,                last time consumption/overall running time: 446.9225s / 136949.3053 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4327
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4282
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 2858.4,                last time consumption/overall running time: 450.5854s / 137399.8907 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4347
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4306
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 2847.75,                last time consumption/overall running time: 445.4280s / 137845.3188 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4369
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4324
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 2899.55,                last time consumption/overall running time: 454.5905s / 138299.9093 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4277
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4191
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2885.2,                last time consumption/overall running time: 452.5799s / 138752.4892 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4248
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4171
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 2882.25,                last time consumption/overall running time: 448.3236s / 139200.8128 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4237
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4173
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 2851.15,                last time consumption/overall running time: 447.1136s / 139647.9264 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4300
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4233
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2888.15,                last time consumption/overall running time: 449.0839s / 140097.0103 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4215
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4107
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 2828.2,                last time consumption/overall running time: 441.1902s / 140538.2005 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4287
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4177
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2846.9,                last time consumption/overall running time: 437.0088s / 140975.2093 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.4120
env0_second_0:                 episode reward: 0.9500,                 loss: -0.4082
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 2848.0,                last time consumption/overall running time: 417.6546s / 141392.8639 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4193
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4146
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 2868.0,                last time consumption/overall running time: 422.5355s / 141815.3993 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4234
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2848.7,                last time consumption/overall running time: 424.4110s / 142239.8103 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4203
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2837.0,                last time consumption/overall running time: 420.7429s / 142660.5533 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4190
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4095
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2853.7,                last time consumption/overall running time: 415.9484s / 143076.5017 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4310
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4262
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2892.5,                last time consumption/overall running time: 426.6951s / 143503.1968 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4269
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4198
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2869.2,                last time consumption/overall running time: 420.3887s / 143923.5854 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4276
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4153
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 2853.2,                last time consumption/overall running time: 426.3721s / 144349.9576 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4184
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2835.7,                last time consumption/overall running time: 424.1216s / 144774.0792 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4264
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4210
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2850.4,                last time consumption/overall running time: 432.2998s / 145206.3790 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4261
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4233
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 2847.6,                last time consumption/overall running time: 418.7213s / 145625.1003 s
env0_first_0:                 episode reward: 2.2000,                 loss: -0.4257
env0_second_0:                 episode reward: -2.2000,                 loss: -0.4200
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 2884.4,                last time consumption/overall running time: 434.3866s / 146059.4869 s
env0_first_0:                 episode reward: 1.4000,                 loss: -0.4282
env0_second_0:                 episode reward: -1.4000,                 loss: -0.4246
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2899.3,                last time consumption/overall running time: 441.0206s / 146500.5075 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4115
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4086
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2845.45,                last time consumption/overall running time: 414.6677s / 146915.1752 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.4225
env0_second_0:                 episode reward: -1.5000,                 loss: -0.4171
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 2863.7,                last time consumption/overall running time: 413.0807s / 147328.2558 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4320
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4264
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 2864.8,                last time consumption/overall running time: 424.9995s / 147753.2553 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4297
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4194
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 2828.85,                last time consumption/overall running time: 423.9897s / 148177.2451 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4361
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4188
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2843.25,                last time consumption/overall running time: 409.1649s / 148586.4099 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4388
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4337
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 2873.35,                last time consumption/overall running time: 418.8028s / 149005.2127 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4266
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4182
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 2894.9,                last time consumption/overall running time: 417.3782s / 149422.5910 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.4264
env0_second_0:                 episode reward: -1.2500,                 loss: -0.4175
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 2906.1,                last time consumption/overall running time: 427.0529s / 149849.6439 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4169
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4089
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 2920.0,                last time consumption/overall running time: 426.9701s / 150276.6140 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4127
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4004
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 2879.15,                last time consumption/overall running time: 418.3413s / 150694.9553 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4229
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4130
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2874.5,                last time consumption/overall running time: 419.2059s / 151114.1612 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4266
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4194
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2871.15,                last time consumption/overall running time: 419.6710s / 151533.8322 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4250
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4191
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 2835.55,                last time consumption/overall running time: 407.7197s / 151941.5519 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4308
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4227
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 2845.35,                last time consumption/overall running time: 418.3634s / 152359.9153 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4346
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4242
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 2862.2,                last time consumption/overall running time: 419.6565s / 152779.5718 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4285
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4226
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2866.3,                last time consumption/overall running time: 422.9121s / 153202.4839 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4250
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4146
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2882.4,                last time consumption/overall running time: 427.7665s / 153630.2504 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.4200
env0_second_0:                 episode reward: -1.6000,                 loss: -0.4099
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2871.85,                last time consumption/overall running time: 422.4184s / 154052.6688 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4187
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4131
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2906.65,                last time consumption/overall running time: 427.7273s / 154480.3962 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.4128
env0_second_0:                 episode reward: -1.5000,                 loss: -0.4058
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 2914.9,                last time consumption/overall running time: 428.3348s / 154908.7309 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4076
env0_second_0:                 episode reward: 0.3500,                 loss: -0.3992
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 2883.25,                last time consumption/overall running time: 426.0845s / 155334.8154 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4175
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4108
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 2927.25,                last time consumption/overall running time: 432.5462s / 155767.3617 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4075
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4023
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2896.35,                last time consumption/overall running time: 429.5318s / 156196.8935 s
env0_first_0:                 episode reward: 2.0000,                 loss: -0.4122
env0_second_0:                 episode reward: -2.0000,                 loss: -0.4060
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 2904.2,                last time consumption/overall running time: 425.6640s / 156622.5575 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4158
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4082
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2862.1,                last time consumption/overall running time: 421.3338s / 157043.8913 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4303
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4167
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2867.9,                last time consumption/overall running time: 422.7502s / 157466.6415 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4245
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4130
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 2910.25,                last time consumption/overall running time: 425.3137s / 157891.9552 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4178
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4080
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 2909.25,                last time consumption/overall running time: 425.1955s / 158317.1507 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4177
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4079
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 2915.95,                last time consumption/overall running time: 428.5672s / 158745.7179 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4080
env0_second_0:                 episode reward: 0.3000,                 loss: -0.3991
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 2894.45,                last time consumption/overall running time: 422.2024s / 159167.9203 s
env0_first_0:                 episode reward: 1.5500,                 loss: -0.4124
env0_second_0:                 episode reward: -1.5500,                 loss: -0.4016
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 2882.95,                last time consumption/overall running time: 426.2387s / 159594.1591 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4143
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4092
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 2899.05,                last time consumption/overall running time: 430.6434s / 160024.8025 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.4035
env0_second_0:                 episode reward: 1.5000,                 loss: -0.3957
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 2918.25,                last time consumption/overall running time: 433.4609s / 160458.2634 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4119
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4037
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 2864.6,                last time consumption/overall running time: 423.0930s / 160881.3563 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4226
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4137
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 2916.1,                last time consumption/overall running time: 431.8005s / 161313.1569 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.4178
env0_second_0:                 episode reward: 1.2000,                 loss: -0.4044
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 2903.75,                last time consumption/overall running time: 431.1737s / 161744.3306 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4283
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4144
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 2871.1,                last time consumption/overall running time: 419.1150s / 162163.4455 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4297
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4148
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 2891.75,                last time consumption/overall running time: 418.5030s / 162581.9485 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4270
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4169
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 2887.15,                last time consumption/overall running time: 422.8849s / 163004.8334 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4190
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4047
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 2901.0,                last time consumption/overall running time: 425.8102s / 163430.6436 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4169
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4032
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 2874.95,                last time consumption/overall running time: 423.2512s / 163853.8948 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.4274
env0_second_0:                 episode reward: -1.2000,                 loss: -0.4202
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2909.05,                last time consumption/overall running time: 437.5111s / 164291.4059 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4234
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4092
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2933.0,                last time consumption/overall running time: 439.8930s / 164731.2988 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4111
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4003
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2893.8,                last time consumption/overall running time: 640.8709s / 165372.1698 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4128
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4080
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2925.85,                last time consumption/overall running time: 666.7870s / 166038.9567 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.4120
env0_second_0:                 episode reward: 0.8500,                 loss: -0.3992
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 2869.9,                last time consumption/overall running time: 651.5087s / 166690.4655 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4187
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4076
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 2862.1,                last time consumption/overall running time: 646.1366s / 167336.6020 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4218
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4064
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 2844.3,                last time consumption/overall running time: 648.8940s / 167985.4961 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4269
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4168
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 2856.65,                last time consumption/overall running time: 648.1101s / 168633.6062 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.4249
env0_second_0:                 episode reward: -1.2000,                 loss: -0.4150
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 2854.35,                last time consumption/overall running time: 646.0645s / 169279.6707 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4228
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4049
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 2881.3,                last time consumption/overall running time: 654.9511s / 169934.6218 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4189
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4049
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 2882.95,                last time consumption/overall running time: 650.8107s / 170585.4325 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4144
env0_second_0:                 episode reward: -0.9500,                 loss: -0.3953
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 2907.15,                last time consumption/overall running time: 658.1130s / 171243.5455 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4158
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4010
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 2869.4,                last time consumption/overall running time: 649.7545s / 171893.3001 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4249
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4122
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 2870.75,                last time consumption/overall running time: 649.5626s / 172542.8627 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4261
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4144
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 2932.2,                last time consumption/overall running time: 663.2422s / 173206.1048 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4201
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4097
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 2910.55,                last time consumption/overall running time: 657.5223s / 173863.6271 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4231
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4152
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 2888.2,                last time consumption/overall running time: 652.1638s / 174515.7910 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4173
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4101
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 2878.35,                last time consumption/overall running time: 646.0850s / 175161.8760 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4262
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4192
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 2895.45,                last time consumption/overall running time: 654.6060s / 175816.4820 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.4301
env0_second_0:                 episode reward: -1.6000,                 loss: -0.4220
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 2902.9,                last time consumption/overall running time: 732.7229s / 176549.2049 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4294
env0_second_0:                 episode reward: -1.3500,                 loss: -0.4211
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 2883.25,                last time consumption/overall running time: 745.5078s / 177294.7127 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4252
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4180
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 2900.7,                last time consumption/overall running time: 744.7141s / 178039.4267 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4242
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 2934.35,                last time consumption/overall running time: 753.3632s / 178792.7900 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4066
env0_second_0:                 episode reward: -0.3500,                 loss: -0.3978
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 2927.5,                last time consumption/overall running time: 746.6971s / 179539.4871 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4031
env0_second_0:                 episode reward: -0.3500,                 loss: -0.3892
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 2935.85,                last time consumption/overall running time: 749.7057s / 180289.1928 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.4055
env0_second_0:                 episode reward: 0.8500,                 loss: -0.3937
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 2910.6,                last time consumption/overall running time: 742.0435s / 181031.2363 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.3991
env0_second_0:                 episode reward: -0.6000,                 loss: -0.3931
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 2900.65,                last time consumption/overall running time: 738.8721s / 181770.1084 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.3985
env0_second_0:                 episode reward: 1.8000,                 loss: -0.3878
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 2947.3,                last time consumption/overall running time: 752.7233s / 182522.8317 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.3816
env0_second_0:                 episode reward: 1.7000,                 loss: -0.3626
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 2943.7,                last time consumption/overall running time: 750.1223s / 183272.9540 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3795
env0_second_0:                 episode reward: -0.1000,                 loss: -0.3682
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 2940.55,                last time consumption/overall running time: 748.8354s / 184021.7894 s
env0_first_0:                 episode reward: -1.6500,                 loss: -0.3918
env0_second_0:                 episode reward: 1.6500,                 loss: -0.3819
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 2906.5,                last time consumption/overall running time: 757.3159s / 184779.1053 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.3913
env0_second_0:                 episode reward: 1.9500,                 loss: -0.3751
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 2929.9,                last time consumption/overall running time: 797.3747s / 185576.4800 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.3916
env0_second_0:                 episode reward: 1.3000,                 loss: -0.3711
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 2976.1,                last time consumption/overall running time: 807.2407s / 186383.7207 s
env0_first_0:                 episode reward: -2.1500,                 loss: -0.3968
env0_second_0:                 episode reward: 2.1500,                 loss: -0.3760
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3013.75,                last time consumption/overall running time: 821.3066s / 187205.0273 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3840
env0_second_0:                 episode reward: -0.2000,                 loss: -0.3651
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 2969.65,                last time consumption/overall running time: 808.8491s / 188013.8764 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3879
env0_second_0:                 episode reward: 0.0000,                 loss: -0.3727
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 2940.35,                last time consumption/overall running time: 801.4586s / 188815.3350 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.3866
env0_second_0:                 episode reward: 1.5000,                 loss: -0.3772
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2958.65,                last time consumption/overall running time: 804.0873s / 189619.4223 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.3771
env0_second_0:                 episode reward: 0.1500,                 loss: -0.3566
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 2904.85,                last time consumption/overall running time: 791.8811s / 190411.3034 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3863
env0_second_0:                 episode reward: -0.2000,                 loss: -0.3725
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2949.3,                last time consumption/overall running time: 803.9713s / 191215.2747 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.3884
env0_second_0:                 episode reward: -0.4500,                 loss: -0.3704
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2965.2,                last time consumption/overall running time: 803.7096s / 192018.9843 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.3940
env0_second_0:                 episode reward: -1.6000,                 loss: -0.3747
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 2889.6,                last time consumption/overall running time: 783.5071s / 192802.4914 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4183
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4056
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2970.7,                last time consumption/overall running time: 806.7922s / 193609.2835 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.3998
env0_second_0:                 episode reward: -1.3500,                 loss: -0.3840
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 2968.15,                last time consumption/overall running time: 801.9318s / 194411.2153 s
env0_first_0:                 episode reward: 1.7500,                 loss: -0.3899
env0_second_0:                 episode reward: -1.7500,                 loss: -0.3788
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 2943.35,                last time consumption/overall running time: 800.8918s / 195212.1071 s
env0_first_0:                 episode reward: 1.8500,                 loss: -0.3965
env0_second_0:                 episode reward: -1.8500,                 loss: -0.3779
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2915.45,                last time consumption/overall running time: 790.0341s / 196002.1413 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4036
env0_second_0:                 episode reward: -1.1000,                 loss: -0.3885
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 2894.1,                last time consumption/overall running time: 786.1827s / 196788.3240 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4128
env0_second_0:                 episode reward: -1.3500,                 loss: -0.3957
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 2919.6,                last time consumption/overall running time: 790.3188s / 197578.6428 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4065
env0_second_0:                 episode reward: -1.0500,                 loss: -0.3902
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 2877.45,                last time consumption/overall running time: 781.8366s / 198360.4794 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4216
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4081
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 2865.8,                last time consumption/overall running time: 773.3486s / 199133.8280 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4206
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4110
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 2922.4,                last time consumption/overall running time: 793.8955s / 199927.7235 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.4012
env0_second_0:                 episode reward: -0.8000,                 loss: -0.3949
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 2985.05,                last time consumption/overall running time: 812.5655s / 200740.2889 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.3969
env0_second_0:                 episode reward: 0.5000,                 loss: -0.3854
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2915.5,                last time consumption/overall running time: 790.7551s / 201531.0441 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4042
env0_second_0:                 episode reward: -1.0500,                 loss: -0.3843
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 2943.85,                last time consumption/overall running time: 796.1762s / 202327.2203 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.3911
env0_second_0:                 episode reward: -1.1500,                 loss: -0.3720
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2952.0,                last time consumption/overall running time: 799.8179s / 203127.0382 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.3969
env0_second_0:                 episode reward: -0.4500,                 loss: -0.3749
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2959.3,                last time consumption/overall running time: 799.0518s / 203926.0900 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4016
env0_second_0:                 episode reward: -1.1500,                 loss: -0.3817
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 2911.2,                last time consumption/overall running time: 785.1357s / 204711.2257 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4161
env0_second_0:                 episode reward: -0.8500,                 loss: -0.3997
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 2920.85,                last time consumption/overall running time: 790.5834s / 205501.8091 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4110
env0_second_0:                 episode reward: -0.3000,                 loss: -0.3951
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 2889.65,                last time consumption/overall running time: 780.1708s / 206281.9799 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4178
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4027
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 2892.6,                last time consumption/overall running time: 780.5536s / 207062.5335 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4079
env0_second_0:                 episode reward: -1.0000,                 loss: -0.3880
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 2941.0,                last time consumption/overall running time: 791.9908s / 207854.5243 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.3946
env0_second_0:                 episode reward: -1.2000,                 loss: -0.3683
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 2917.05,                last time consumption/overall running time: 781.8718s / 208636.3962 s
env0_first_0:                 episode reward: 2.2000,                 loss: -0.3976
env0_second_0:                 episode reward: -2.2000,                 loss: -0.3723
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 2918.45,                last time consumption/overall running time: 785.1072s / 209421.5034 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.3910
env0_second_0:                 episode reward: -0.4500,                 loss: -0.3641
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2970.15,                last time consumption/overall running time: 798.4831s / 210219.9865 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.3890
env0_second_0:                 episode reward: -1.7000,                 loss: -0.3646
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 2880.45,                last time consumption/overall running time: 770.9244s / 210990.9108 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4129
env0_second_0:                 episode reward: -0.9500,                 loss: -0.3974
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 2926.15,                last time consumption/overall running time: 784.8046s / 211775.7155 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4037
env0_second_0:                 episode reward: -0.7500,                 loss: -0.3881
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2938.0,                last time consumption/overall running time: 790.1894s / 212565.9048 s
env0_first_0:                 episode reward: 2.0000,                 loss: -0.4024
env0_second_0:                 episode reward: -2.0000,                 loss: -0.3861
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 2914.3,                last time consumption/overall running time: 781.2615s / 213347.1664 s
env0_first_0:                 episode reward: 2.6500,                 loss: -0.4046
env0_second_0:                 episode reward: -2.6500,                 loss: -0.3791
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 2915.25,                last time consumption/overall running time: 776.8011s / 214123.9674 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.4044
env0_second_0:                 episode reward: -1.4500,                 loss: -0.3863
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 2905.1,                last time consumption/overall running time: 774.0255s / 214897.9930 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4130
env0_second_0:                 episode reward: -0.6000,                 loss: -0.3942
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 2938.25,                last time consumption/overall running time: 784.9844s / 215682.9774 s
env0_first_0:                 episode reward: 3.0000,                 loss: -0.4001
env0_second_0:                 episode reward: -3.0000,                 loss: -0.3821
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 2916.95,                last time consumption/overall running time: 750.8478s / 216433.8252 s
env0_first_0:                 episode reward: 1.8000,                 loss: -0.4010
env0_second_0:                 episode reward: -1.8000,                 loss: -0.3821
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 2930.2,                last time consumption/overall running time: 730.1789s / 217164.0041 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4081
env0_second_0:                 episode reward: -1.1000,                 loss: -0.3956
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 2913.7,                last time consumption/overall running time: 727.3856s / 217891.3897 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4082
env0_second_0:                 episode reward: -1.3500,                 loss: -0.3916
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 2938.55,                last time consumption/overall running time: 729.4397s / 218620.8295 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.4078
env0_second_0:                 episode reward: -1.9000,                 loss: -0.3930
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 2940.2,                last time consumption/overall running time: 732.1580s / 219352.9875 s
env0_first_0:                 episode reward: 2.1500,                 loss: -0.4049
env0_second_0:                 episode reward: -2.1500,                 loss: -0.3896
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 2923.0,                last time consumption/overall running time: 727.3422s / 220080.3297 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4058
env0_second_0:                 episode reward: -0.7000,                 loss: -0.3908
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 2983.95,                last time consumption/overall running time: 742.8345s / 220823.1642 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.3866
env0_second_0:                 episode reward: -0.5500,                 loss: -0.3671
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 2935.1,                last time consumption/overall running time: 729.0536s / 221552.2178 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3908
env0_second_0:                 episode reward: 0.1000,                 loss: -0.3743
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 2964.85,                last time consumption/overall running time: 739.9389s / 222292.1567 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.3897
env0_second_0:                 episode reward: -1.6000,                 loss: -0.3720
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 2978.5,                last time consumption/overall running time: 739.8494s / 223032.0061 s
env0_first_0:                 episode reward: 3.0500,                 loss: -0.3876
env0_second_0:                 episode reward: -3.0500,                 loss: -0.3710
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 2961.55,                last time consumption/overall running time: 732.9417s / 223764.9478 s
env0_first_0:                 episode reward: 1.8000,                 loss: -0.3863
env0_second_0:                 episode reward: -1.8000,                 loss: -0.3687
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 2967.05,                last time consumption/overall running time: 739.4690s / 224504.4168 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.3823
env0_second_0:                 episode reward: -1.1000,                 loss: -0.3620
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 2953.05,                last time consumption/overall running time: 733.9828s / 225238.3996 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.3986
env0_second_0:                 episode reward: -0.5500,                 loss: -0.3850
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 2971.65,                last time consumption/overall running time: 736.8019s / 225975.2015 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.3896
env0_second_0:                 episode reward: 0.2000,                 loss: -0.3725
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 2995.35,                last time consumption/overall running time: 744.6284s / 226719.8299 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.3891
env0_second_0:                 episode reward: -1.1500,                 loss: -0.3717
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 2969.35,                last time consumption/overall running time: 741.2049s / 227461.0348 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.3999
env0_second_0:                 episode reward: -0.5500,                 loss: -0.3828
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 2977.5,                last time consumption/overall running time: 739.3505s / 228200.3853 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.3848
env0_second_0:                 episode reward: -1.6000,                 loss: -0.3665
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 2991.9,                last time consumption/overall running time: 743.0160s / 228943.4013 s
env0_first_0:                 episode reward: 2.1500,                 loss: -0.3820
env0_second_0:                 episode reward: -2.1500,                 loss: -0.3586
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 2967.8,                last time consumption/overall running time: 738.3917s / 229681.7930 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3786
env0_second_0:                 episode reward: -0.1000,                 loss: -0.3545
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 2920.45,                last time consumption/overall running time: 725.7682s / 230407.5612 s
env0_first_0:                 episode reward: 2.6500,                 loss: -0.3946
env0_second_0:                 episode reward: -2.6500,                 loss: -0.3624
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 2922.05,                last time consumption/overall running time: 726.4671s / 231134.0283 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4015
env0_second_0:                 episode reward: -0.3000,                 loss: -0.3676
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 2954.55,                last time consumption/overall running time: 737.6269s / 231871.6552 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.4034
env0_second_0:                 episode reward: -1.9000,                 loss: -0.3728
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 2934.55,                last time consumption/overall running time: 697.3512s / 232569.0064 s
env0_first_0:                 episode reward: 2.7000,                 loss: -0.3998
env0_second_0:                 episode reward: -2.7000,                 loss: -0.3703
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 2911.3,                last time consumption/overall running time: 671.6640s / 233240.6704 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4023
env0_second_0:                 episode reward: -1.0000,                 loss: -0.3659
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 2914.4,                last time consumption/overall running time: 677.2011s / 233917.8716 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.4059
env0_second_0:                 episode reward: -1.9000,                 loss: -0.3757
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 2926.85,                last time consumption/overall running time: 672.3462s / 234590.2177 s
env0_first_0:                 episode reward: 2.8000,                 loss: -0.3989
env0_second_0:                 episode reward: -2.8000,                 loss: -0.3696
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 2940.8,                last time consumption/overall running time: 681.3808s / 235271.5985 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.3995
env0_second_0:                 episode reward: -4.3000,                 loss: -0.3612
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 2867.2,                last time consumption/overall running time: 662.9836s / 235934.5822 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.4079
env0_second_0:                 episode reward: -1.5000,                 loss: -0.3740
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 2942.35,                last time consumption/overall running time: 683.2547s / 236617.8368 s
env0_first_0:                 episode reward: 3.6500,                 loss: -0.4024
env0_second_0:                 episode reward: -3.6500,                 loss: -0.3664
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 2943.3,                last time consumption/overall running time: 680.6967s / 237298.5336 s
env0_first_0:                 episode reward: 2.4500,                 loss: -0.4080
env0_second_0:                 episode reward: -2.4500,                 loss: -0.3689
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 2982.15,                last time consumption/overall running time: 689.9744s / 237988.5079 s
env0_first_0:                 episode reward: 3.1500,                 loss: -0.3967
env0_second_0:                 episode reward: -3.1500,                 loss: -0.3656
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 2926.85,                last time consumption/overall running time: 676.6048s / 238665.1128 s
env0_first_0:                 episode reward: 3.2500,                 loss: -0.4002
env0_second_0:                 episode reward: -3.2500,                 loss: -0.3796
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 2929.85,                last time consumption/overall running time: 676.3209s / 239341.4337 s
env0_first_0:                 episode reward: 3.4000,                 loss: -0.4073
env0_second_0:                 episode reward: -3.4000,                 loss: -0.3827
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 2937.05,                last time consumption/overall running time: 679.6046s / 240021.0383 s
env0_first_0:                 episode reward: 2.1500,                 loss: -0.4031
env0_second_0:                 episode reward: -2.1500,                 loss: -0.3826
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 2915.3,                last time consumption/overall running time: 674.1235s / 240695.1617 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.4040
env0_second_0:                 episode reward: -1.7000,                 loss: -0.3822
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 2938.7,                last time consumption/overall running time: 678.7224s / 241373.8841 s
env0_first_0:                 episode reward: 1.8500,                 loss: -0.4050
env0_second_0:                 episode reward: -1.8500,                 loss: -0.3728
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 2940.75,                last time consumption/overall running time: 670.2617s / 242044.1459 s
env0_first_0:                 episode reward: 2.0500,                 loss: -0.4042
env0_second_0:                 episode reward: -2.0500,                 loss: -0.3664
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 2904.05,                last time consumption/overall running time: 635.4358s / 242679.5817 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4038
env0_second_0:                 episode reward: -0.7500,                 loss: -0.3759
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 2938.1,                last time consumption/overall running time: 643.6952s / 243323.2768 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.4033
env0_second_0:                 episode reward: -1.6000,                 loss: -0.3728
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 2903.35,                last time consumption/overall running time: 637.4222s / 243960.6990 s
env0_first_0:                 episode reward: 3.0500,                 loss: -0.3992
env0_second_0:                 episode reward: -3.0500,                 loss: -0.3739
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 2911.55,                last time consumption/overall running time: 638.9050s / 244599.6040 s
env0_first_0:                 episode reward: 3.8000,                 loss: -0.4124
env0_second_0:                 episode reward: -3.8000,                 loss: -0.3852
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 2916.55,                last time consumption/overall running time: 637.8050s / 245237.4090 s
env0_first_0:                 episode reward: 2.0500,                 loss: -0.4156
env0_second_0:                 episode reward: -2.0500,                 loss: -0.3920
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 2905.2,                last time consumption/overall running time: 637.2497s / 245874.6587 s
env0_first_0:                 episode reward: 3.3000,                 loss: -0.4205
env0_second_0:                 episode reward: -3.3000,                 loss: -0.3981
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 2968.65,                last time consumption/overall running time: 649.9961s / 246524.6547 s
env0_first_0:                 episode reward: 2.1000,                 loss: -0.4051
env0_second_0:                 episode reward: -2.1000,                 loss: -0.3750
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 2947.6,                last time consumption/overall running time: 649.1312s / 247173.7860 s
env0_first_0:                 episode reward: 2.2500,                 loss: -0.4045
env0_second_0:                 episode reward: -2.2500,                 loss: -0.3733
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 2936.85,                last time consumption/overall running time: 646.4926s / 247820.2786 s
env0_first_0:                 episode reward: 3.6500,                 loss: -0.4030
env0_second_0:                 episode reward: -3.6500,                 loss: -0.3442
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 2916.25,                last time consumption/overall running time: 645.7134s / 248465.9920 s
env0_first_0:                 episode reward: 2.7000,                 loss: -0.4062
env0_second_0:                 episode reward: -2.7000,                 loss: -0.3640
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 2913.3,                last time consumption/overall running time: 671.3214s / 249137.3133 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4056
env0_second_0:                 episode reward: -1.1500,                 loss: -0.3736
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 2916.95,                last time consumption/overall running time: 674.1567s / 249811.4701 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.4074
env0_second_0:                 episode reward: -1.9000,                 loss: -0.3715
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 2907.8,                last time consumption/overall running time: 668.3195s / 250479.7896 s
env0_first_0:                 episode reward: 2.2000,                 loss: -0.4144
env0_second_0:                 episode reward: -2.2000,                 loss: -0.3949
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 2964.65,                last time consumption/overall running time: 682.3233s / 251162.1128 s
env0_first_0:                 episode reward: 3.1000,                 loss: -0.4074
env0_second_0:                 episode reward: -3.1000,                 loss: -0.3869
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 2934.0,                last time consumption/overall running time: 673.1409s / 251835.2537 s
env0_first_0:                 episode reward: 2.4500,                 loss: -0.4081
env0_second_0:                 episode reward: -2.4500,                 loss: -0.3827
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 2989.5,                last time consumption/overall running time: 690.4927s / 252525.7464 s
env0_first_0:                 episode reward: 3.5500,                 loss: -0.3930
env0_second_0:                 episode reward: -3.5500,                 loss: -0.3626
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 2985.1,                last time consumption/overall running time: 686.5221s / 253212.2685 s
env0_first_0:                 episode reward: 3.6000,                 loss: -0.3867
env0_second_0:                 episode reward: -3.6000,                 loss: -0.3436
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 2927.35,                last time consumption/overall running time: 669.6578s / 253881.9263 s
env0_first_0:                 episode reward: 4.3000,                 loss: -0.3988
env0_second_0:                 episode reward: -4.3000,                 loss: -0.3372
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 2895.85,                last time consumption/overall running time: 664.1717s / 254546.0980 s
env0_first_0:                 episode reward: 2.7000,                 loss: -0.4153
env0_second_0:                 episode reward: -2.7000,                 loss: -0.3724
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 2830.75,                last time consumption/overall running time: 650.2534s / 255196.3514 s
env0_first_0:                 episode reward: 2.0500,                 loss: -0.4302
env0_second_0:                 episode reward: -2.0500,                 loss: -0.4047
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 2873.95,                last time consumption/overall running time: 634.6067s / 255830.9581 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.4244
env0_second_0:                 episode reward: -1.6500,                 loss: -0.4070
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 2871.7,                last time consumption/overall running time: 613.3092s / 256444.2673 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4306
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4143
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 2846.5,                last time consumption/overall running time: 609.7090s / 257053.9763 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.4333
env0_second_0:                 episode reward: -1.6500,                 loss: -0.4089
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 2807.75,                last time consumption/overall running time: 604.9889s / 257658.9653 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.4276
env0_second_0:                 episode reward: -1.6500,                 loss: -0.3976
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 2879.45,                last time consumption/overall running time: 614.3180s / 258273.2833 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.4224
env0_second_0:                 episode reward: -1.7000,                 loss: -0.3796
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 2875.2,                last time consumption/overall running time: 591.3932s / 258864.6765 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4228
env0_second_0:                 episode reward: -1.3000,                 loss: -0.3948
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 2945.55,                last time consumption/overall running time: 537.0713s / 259401.7478 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.4056
env0_second_0:                 episode reward: -1.6500,                 loss: -0.3831
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 2959.25,                last time consumption/overall running time: 537.8923s / 259939.6401 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.3952
env0_second_0:                 episode reward: -1.0000,                 loss: -0.3728
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 2925.7,                last time consumption/overall running time: 533.0037s / 260472.6438 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.3918
env0_second_0:                 episode reward: -0.5500,                 loss: -0.3662
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 2950.95,                last time consumption/overall running time: 536.7379s / 261009.3817 s
env0_first_0:                 episode reward: 2.5000,                 loss: -0.3877
env0_second_0:                 episode reward: -2.5000,                 loss: -0.3563
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 2950.05,                last time consumption/overall running time: 536.5734s / 261545.9550 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.3949
env0_second_0:                 episode reward: -1.7000,                 loss: -0.3678
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 2953.0,                last time consumption/overall running time: 532.1783s / 262078.1333 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.3840
env0_second_0:                 episode reward: 0.4000,                 loss: -0.3420
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 2997.35,                last time consumption/overall running time: 486.6698s / 262564.8031 s
env0_first_0:                 episode reward: 1.8500,                 loss: -0.3729
env0_second_0:                 episode reward: -1.8500,                 loss: -0.3402