pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [981, 867, 135, 855, 182]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 7, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152/pettingzoo_tennis_v2_nxdo2.
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 947
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 4.6663s / 4.6663 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.1450
env0_second_0:                 episode reward: -6.0000,                 loss: nan
env1_first_0:                 episode reward: 6.0000,                 loss: nan
env1_second_0:                 episode reward: -6.0000,                 loss: nan
env2_first_0:                 episode reward: 6.0000,                 loss: nan
env2_second_0:                 episode reward: -6.0000,                 loss: nan
env3_first_0:                 episode reward: 6.0000,                 loss: nan
env3_second_0:                 episode reward: -6.0000,                 loss: nan
env4_first_0:                 episode reward: 6.0000,                 loss: nan
env4_second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.4095s / 70.0758 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.0711
env0_second_0:                 episode reward: -5.4000,                 loss: nan
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
env2_first_0:                 episode reward: 5.2000,                 loss: nan
env2_second_0:                 episode reward: -5.2000,                 loss: nan
env3_first_0:                 episode reward: 5.6500,                 loss: nan
env3_second_0:                 episode reward: -5.6500,                 loss: nan
env4_first_0:                 episode reward: 5.7000,                 loss: nan
env4_second_0:                 episode reward: -5.7000,                 loss: nan
Score delta: 10.6, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/21_0.
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8400s / 146.9158 s
env0_first_0:                 episode reward: 1.3500,                 loss: nan
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0775
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8018s / 226.7176 s
env0_first_0:                 episode reward: 1.6000,                 loss: nan
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0360
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.5036s / 311.2212 s
env0_first_0:                 episode reward: 2.3000,                 loss: nan
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0180
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8575s / 411.0787 s
env0_first_0:                 episode reward: 2.1500,                 loss: nan
env0_second_0:                 episode reward: -2.1500,                 loss: 0.0160
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 114.6801s / 525.7588 s
env0_first_0:                 episode reward: 2.1000,                 loss: nan
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0196
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 119.8104s / 645.5692 s
env0_first_0:                 episode reward: 1.8500,                 loss: nan
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0151
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 126.3340s / 771.9032 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 132.7129s / 904.6161 s
env0_first_0:                 episode reward: -0.4500,                 loss: nan
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.0666s / 1043.6828 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0151
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.5779s / 1187.2607 s
env0_first_0:                 episode reward: -0.3500,                 loss: nan
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0176
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.5400s / 1336.8007 s
env0_first_0:                 episode reward: -0.5500,                 loss: nan
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0157
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.4911s / 1494.2918 s
env0_first_0:                 episode reward: 2.1500,                 loss: nan
env0_second_0:                 episode reward: -2.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5948s / 1660.8866 s
env0_first_0:                 episode reward: 3.3500,                 loss: nan
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0125
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 173.0329s / 1833.9195 s
env0_first_0:                 episode reward: -0.6500,                 loss: nan
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0158
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 180.4199s / 2014.3394 s
env0_first_0:                 episode reward: -1.1500,                 loss: nan
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0155
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 187.8379s / 2202.1773 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0168
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 193.0926s / 2395.2699 s
env0_first_0:                 episode reward: -1.2500,                 loss: nan
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0159
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.2410s / 2591.5109 s
env0_first_0:                 episode reward: -3.0000,                 loss: nan
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0159
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -3.6000,                 loss: nan
env3_second_0:                 episode reward: 3.6000,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1603s / 2697.6712 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0344
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -3.9000,                 loss: nan
env2_second_0:                 episode reward: 3.9000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Score delta: 7.2, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/383_1.
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2279s / 2795.8991 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0354
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2339s / 2902.1330 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0315
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 113.2122s / 3015.3452 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0265
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -3.8500,                 loss: nan
env4_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 116.8991s / 3132.2443 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0227
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 123.4121s / 3255.6564 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0195
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -4.5500,                 loss: nan
env4_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 131.1833s / 3386.8397 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0199
env0_second_0:                 episode reward: 5.6500,                 loss: nan
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
env2_first_0:                 episode reward: -5.4000,                 loss: nan
env2_second_0:                 episode reward: 5.4000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 138.4303s / 3525.2700 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0200
env0_second_0:                 episode reward: 4.7000,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
env2_first_0:                 episode reward: -4.8500,                 loss: nan
env2_second_0:                 episode reward: 4.8500,                 loss: nan
env3_first_0:                 episode reward: -5.0000,                 loss: nan
env3_second_0:                 episode reward: 5.0000,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.3314s / 3670.6014 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0218
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.4000,                 loss: nan
env4_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.9496s / 3820.5510 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0260
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
env2_first_0:                 episode reward: -5.7000,                 loss: nan
env2_second_0:                 episode reward: 5.7000,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -5.7000,                 loss: nan
env4_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.8443s / 3979.3952 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0298
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -5.0000,                 loss: nan
env3_second_0:                 episode reward: 5.0000,                 loss: nan
env4_first_0:                 episode reward: -5.4500,                 loss: nan
env4_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1220s / 4145.5173 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0325
env0_second_0:                 episode reward: 3.7500,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.5500,                 loss: nan
env3_second_0:                 episode reward: 3.5500,                 loss: nan
env4_first_0:                 episode reward: -3.3000,                 loss: nan
env4_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 173.7102s / 4319.2275 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0309
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -3.8500,                 loss: nan
env4_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 182.3544s / 4501.5819 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0276
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -3.5000,                 loss: nan
env3_second_0:                 episode reward: 3.5000,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 188.8634s / 4690.4453 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0199
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -4.9000,                 loss: nan
env4_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 194.8690s / 4885.3143 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0176
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.3000,                 loss: nan
env2_second_0:                 episode reward: 5.3000,                 loss: nan
env3_first_0:                 episode reward: -5.4000,                 loss: nan
env3_second_0:                 episode reward: 5.4000,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.1526s / 5080.4669 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0171
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.3872s / 5276.8542 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0153
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.9500,                 loss: nan
env2_second_0:                 episode reward: 4.9500,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -5.0500,                 loss: nan
env4_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.8855s / 5472.7397 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0151
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.4000,                 loss: nan
env3_second_0:                 episode reward: 5.4000,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.6262s / 5668.3658 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0156
env0_second_0:                 episode reward: 5.9000,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -5.8000,                 loss: nan
env2_second_0:                 episode reward: 5.8000,                 loss: nan
env3_first_0:                 episode reward: -5.6000,                 loss: nan
env3_second_0:                 episode reward: 5.6000,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.2733s / 5864.6391 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0158
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -5.6000,                 loss: nan
env2_second_0:                 episode reward: 5.6000,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.7500,                 loss: nan
env4_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.0852s / 6059.7244 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0166
env0_second_0:                 episode reward: 5.8500,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
env2_first_0:                 episode reward: -5.9000,                 loss: nan
env2_second_0:                 episode reward: 5.9000,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.1555s / 6255.8799 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0163
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
env3_first_0:                 episode reward: -5.9000,                 loss: nan
env3_second_0:                 episode reward: 5.9000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.4791s / 6453.3590 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0180
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -5.8500,                 loss: nan
env3_second_0:                 episode reward: 5.8500,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.1218s / 6649.4808 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0187
env0_second_0:                 episode reward: 5.8500,                 loss: nan
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -5.8500,                 loss: nan
env3_second_0:                 episode reward: 5.8500,                 loss: nan
env4_first_0:                 episode reward: -5.9000,                 loss: nan
env4_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.8163s / 6845.2971 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0198
env0_second_0:                 episode reward: 5.4500,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -5.5000,                 loss: nan
env3_second_0:                 episode reward: 5.5000,                 loss: nan
env4_first_0:                 episode reward: -5.4500,                 loss: nan
env4_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.8499s / 7043.1471 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0227
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -4.4500,                 loss: nan
env4_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.3225s / 7238.4696 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0232
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.3187s / 7436.7883 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0200
env0_second_0:                 episode reward: 2.8000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.8878s / 7633.6761 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0170
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.9061s / 7831.5822 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0145
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.6761s / 8029.2583 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.0326s / 8227.2908 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0123
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3666s / 8426.6575 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0113
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.6308s / 8623.2882 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0112
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.9404s / 8820.2287 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0120
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.5212s / 9016.7499 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -3.6000,                 loss: nan
env3_second_0:                 episode reward: 3.6000,                 loss: nan
env4_first_0:                 episode reward: -3.4500,                 loss: nan
env4_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.8657s / 9213.6156 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0147
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -3.3000,                 loss: nan
env3_second_0:                 episode reward: 3.3000,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.7374s / 9411.3529 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0165
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.4569s / 9607.8098 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0171
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8379s / 9808.6477 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0172
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0142
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Score delta: 8.8, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/1183_0.
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.5542s / 10004.2020 s
env0_first_0:                 episode reward: -2.8000,                 loss: nan
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0145
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.4366s / 10201.6385 s
env0_first_0:                 episode reward: -2.6500,                 loss: nan
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0149
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.3687s / 10398.0073 s
env0_first_0:                 episode reward: -2.8500,                 loss: nan
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0158
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -2.4500,                 loss: nan
env4_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 204.1934s / 10602.2007 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0180
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0163
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.4500,                 loss: nan
env4_second_0:                 episode reward: 4.4500,                 loss: nan
Score delta: 7.4, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/1263_1.
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.9432s / 10800.1439 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0170
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -3.9000,                 loss: nan
env2_second_0:                 episode reward: 3.9000,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -3.9000,                 loss: nan
env4_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.4418s / 10999.5857 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0171
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.0433s / 11197.6289 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0173
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -4.8000,                 loss: nan
env3_second_0:                 episode reward: 4.8000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.6460s / 11396.2750 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0188
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.8298s / 11595.1048 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0188
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.1208s / 11793.2256 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0193
env0_second_0:                 episode reward: 3.9500,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.6202s / 11991.8458 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0198
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 204.5538s / 12196.3996 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0203
env0_second_0:                 episode reward: -2.9500,                 loss: 0.0170
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 2.9000,                 loss: nan
env3_second_0:                 episode reward: -2.9000,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Score delta: 7.4, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/1434_0.
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 195.8205s / 12392.2202 s
env0_first_0:                 episode reward: 2.9000,                 loss: nan
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0168
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.4334s / 12590.6536 s
env0_first_0:                 episode reward: -0.6000,                 loss: nan
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0166
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.9096s / 12787.5632 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0171
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.3745s / 12984.9377 s
env0_first_0:                 episode reward: -1.8000,                 loss: nan
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0166
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 209.7872s / 13194.7249 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0206
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0161
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Score delta: 7.4, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/1524_1.
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.7429s / 13393.4678 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0205
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.7076s / 13593.1755 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0192
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.6199s / 13792.7953 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0174
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.4496s / 13991.2449 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0166
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.9196s / 14191.1645 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0156
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3619s / 14390.5264 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0147
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8112s / 14591.3375 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0146
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.1447s / 14791.4823 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0159
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7840s / 14992.2663 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0163
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.1458s / 15193.4121 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0162
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.1367s / 15394.5488 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0162
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9927s / 15595.5415 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0176
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7981s / 15796.3395 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0169
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2463s / 15997.5858 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0169
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2571s / 16198.8429 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0177
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.7422s / 16398.5850 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0170
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.4409s / 16600.0259 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.0049s / 16801.0308 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0175
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -5.8000,                 loss: nan
env2_second_0:                 episode reward: 5.8000,                 loss: nan
env3_first_0:                 episode reward: -5.8000,                 loss: nan
env3_second_0:                 episode reward: 5.8000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9422s / 17001.9730 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0191
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -5.9000,                 loss: nan
env2_second_0:                 episode reward: 5.9000,                 loss: nan
env3_first_0:                 episode reward: -5.7500,                 loss: nan
env3_second_0:                 episode reward: 5.7500,                 loss: nan
env4_first_0:                 episode reward: -5.7500,                 loss: nan
env4_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.5601s / 17202.5331 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0185
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.4000,                 loss: nan
env2_second_0:                 episode reward: 5.4000,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.5756s / 17404.1087 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0174
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3989s / 17603.5076 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0152
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -3.6500,                 loss: nan
env3_second_0:                 episode reward: 3.6500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.6041s / 17804.1117 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0149
env0_second_0:                 episode reward: 4.8000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -4.8000,                 loss: nan
env3_second_0:                 episode reward: 4.8000,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.8185s / 18005.9302 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0157
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.1067s / 18208.0370 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0167
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.9361s / 18410.9731 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0158
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 207.2528s / 18618.2258 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0154
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 205.3239s / 18823.5497 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0152
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.7412s / 19027.2909 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0146
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.7750s / 19230.0658 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0147
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.9576s / 19430.0234 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0147
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -4.9500,                 loss: nan
env2_second_0:                 episode reward: 4.9500,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.7423s / 19629.7657 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0151
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7014s / 19830.4671 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0157
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9793s / 20032.4464 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0157
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.9716s / 20231.4180 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0158
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -3.6500,                 loss: nan
env3_second_0:                 episode reward: 3.6500,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2547s / 20432.6727 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0163
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.8659s / 20634.5386 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0164
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.8949s / 20837.4335 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0161
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 210.1795s / 21047.6130 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0153
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0172
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Score delta: 7.2, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/2320_0.
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 213.7060s / 21261.3189 s
env0_first_0:                 episode reward: -2.6500,                 loss: nan
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0172
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Score delta: 8.0, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/2341_1.
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.5101s / 21462.8290 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0345
env0_second_0:                 episode reward: 2.7500,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.1864s / 21662.0153 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0258
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.0500,                 loss: nan
env4_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.3934s / 21862.4088 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0193
env0_second_0:                 episode reward: 4.8000,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.7000,                 loss: nan
env4_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.1677s / 22062.5765 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0182
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
env2_first_0:                 episode reward: -5.3000,                 loss: nan
env2_second_0:                 episode reward: 5.3000,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3537s / 22264.9302 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0188
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -6.0000,                 loss: nan
env3_second_0:                 episode reward: 6.0000,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3920s / 22467.3221 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0170
env0_second_0:                 episode reward: 5.8500,                 loss: nan
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
env2_first_0:                 episode reward: -5.7500,                 loss: nan
env2_second_0:                 episode reward: 5.7500,                 loss: nan
env3_first_0:                 episode reward: -5.8500,                 loss: nan
env3_second_0:                 episode reward: 5.8500,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.7850s / 22667.1072 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0158
env0_second_0:                 episode reward: 5.4500,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
env2_first_0:                 episode reward: -5.4000,                 loss: nan
env2_second_0:                 episode reward: 5.4000,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.4915s / 22870.5987 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0143
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.2000,                 loss: nan
env3_second_0:                 episode reward: 5.2000,                 loss: nan
env4_first_0:                 episode reward: -5.1000,                 loss: nan
env4_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7611s / 23071.3597 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0133
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -5.0000,                 loss: nan
env2_second_0:                 episode reward: 5.0000,                 loss: nan
env3_first_0:                 episode reward: -4.9000,                 loss: nan
env3_second_0:                 episode reward: 4.9000,                 loss: nan
env4_first_0:                 episode reward: -4.9000,                 loss: nan
env4_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.1082s / 23272.4679 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0126
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -5.8000,                 loss: nan
env2_second_0:                 episode reward: 5.8000,                 loss: nan
env3_first_0:                 episode reward: -5.8000,                 loss: nan
env3_second_0:                 episode reward: 5.8000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.0429s / 23475.5108 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0122
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
env2_first_0:                 episode reward: -5.7000,                 loss: nan
env2_second_0:                 episode reward: 5.7000,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.7000,                 loss: nan
env4_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8214s / 23676.3322 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9857s / 23878.3179 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0118
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.7000,                 loss: nan
env3_second_0:                 episode reward: 3.7000,                 loss: nan
env4_first_0:                 episode reward: -3.4500,                 loss: nan
env4_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.3182s / 24078.6360 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0127
env0_second_0:                 episode reward: 4.2000,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.1500,                 loss: nan
env4_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.1319s / 24281.7680 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0128
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.5479s / 24484.3159 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0140
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.7741s / 24687.0900 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0159
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.2074s / 24889.2974 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0160
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3899s / 25091.6873 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0156
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.1382s / 25294.8255 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0163
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9949s / 25496.8204 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0172
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.6430s / 25698.4634 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0175
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.4637s / 25900.9271 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0186
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.8179s / 26103.7450 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0188
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.0861s / 26306.8311 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0190
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.6700s / 26508.5010 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0189
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.4703s / 26711.9714 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0185
env0_second_0:                 episode reward: 2.7500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3280s / 26914.2994 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0183
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.1221s / 27116.4214 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0164
env0_second_0:                 episode reward: 4.2000,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9374s / 27318.3588 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0151
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9092s / 27519.2680 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0138
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2224s / 27720.4905 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.8084s / 27923.2988 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2615s / 28124.5603 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9408s / 28326.5011 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.2064s / 28528.7075 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.9912s / 28731.6987 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.5059s / 28934.2047 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9680s / 29135.1727 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3473s / 29337.5200 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3510s / 29536.8710 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0135
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.3174s / 29739.1884 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0143
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.0220s / 29941.2104 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0145
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.7174s / 30138.9277 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0148
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.6463s / 30339.5741 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0145
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.8634s / 30541.4375 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.5691s / 30745.0066 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0157
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9466s / 30945.9533 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0161
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.5771s / 31146.5303 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0165
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.9148s / 31346.4451 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0164
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.0395s / 31546.4847 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0164
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.2442s / 31747.7289 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0166
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3295s / 31949.0584 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0167
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3592s / 32150.4176 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0166
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3277s / 32349.7453 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0161
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.0339s / 32552.7792 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0158
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.1655s / 32766.9447 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0151
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0259
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Score delta: 7.4, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/3473_0.
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 196.7980s / 32963.7426 s
env0_first_0:                 episode reward: -2.8000,                 loss: nan
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0214
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.5452s / 33179.2879 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0288
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0215
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.0000,                 loss: nan
env2_second_0:                 episode reward: 3.0000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Score delta: 7.8, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/3514_1.
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.5155s / 33381.8033 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0244
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -4.3500,                 loss: nan
env3_second_0:                 episode reward: 4.3500,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.1903s / 33583.9936 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0227
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.9964s / 33786.9900 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0206
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.3453s / 33990.3353 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0221
env0_second_0:                 episode reward: 2.3500,                 loss: nan
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.0979s / 34190.4333 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0226
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.1886s / 34390.6218 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0206
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -3.8500,                 loss: nan
env4_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.7676s / 34592.3894 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0193
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.8625s / 34794.2519 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0186
env0_second_0:                 episode reward: 2.7500,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8133s / 34995.0653 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0177
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -3.9000,                 loss: nan
env4_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.4589s / 35193.5241 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0174
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.5154s / 35394.0395 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0167
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7954s / 35594.8349 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0170
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.1500,                 loss: nan
env4_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3053s / 35796.1403 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0174
env0_second_0:                 episode reward: 4.6500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.6500,                 loss: nan
env3_second_0:                 episode reward: 4.6500,                 loss: nan
env4_first_0:                 episode reward: -4.6500,                 loss: nan
env4_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.6043s / 35997.7446 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0176
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.5000,                 loss: nan
env3_second_0:                 episode reward: 4.5000,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.8831s / 36199.6277 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0173
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9295s / 36401.5572 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0171
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.9000,                 loss: nan
env4_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.6479s / 36602.2051 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0168
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.2727s / 36805.4779 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0164
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.6591s / 37007.1370 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0166
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.7115s / 37207.8485 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0164
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.6748s / 37408.5233 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0161
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.0665s / 37611.5897 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0154
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.0758s / 37812.6655 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0165
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.5387s / 38014.2042 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0171
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.4420s / 38217.6462 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0169
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 198.1660s / 38415.8122 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0168
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.8017s / 38618.6140 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0171
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.7917s / 38821.4057 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0173
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8507s / 39022.2564 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0174
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.9188s / 39223.1752 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0171
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.1500,                 loss: nan
env4_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.8330s / 39423.0083 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0169
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.9000,                 loss: nan
env4_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.9254s / 39624.9337 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0169
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.7693s / 39826.7029 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0169
env0_second_0:                 episode reward: 4.1000,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.2500,                 loss: nan
env2_second_0:                 episode reward: 4.2500,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.5870s / 40026.2899 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0162
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.3500,                 loss: nan
env3_second_0:                 episode reward: 4.3500,                 loss: nan
env4_first_0:                 episode reward: -4.6000,                 loss: nan
env4_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.8133s / 40226.1032 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0156
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -3.3000,                 loss: nan
env4_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.8230s / 40426.9262 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.4000,                 loss: nan
env4_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.9525s / 40626.8787 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0137
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
env3_first_0:                 episode reward: -3.3500,                 loss: nan
env3_second_0:                 episode reward: 3.3500,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 200.6021s / 40827.4808 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0128
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.7000,                 loss: nan
env3_second_0:                 episode reward: 3.7000,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3259s / 41028.8067 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0123
env0_second_0:                 episode reward: 5.5500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.0824s / 41229.8891 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 199.7875s / 41429.6765 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0101
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.3500,                 loss: nan
env3_second_0:                 episode reward: 3.3500,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 202.5084s / 41632.1849 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3032s / 41833.4881 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0094
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 201.3118s / 42034.7999 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0091
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.8601s / 42238.6600 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0093
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 203.8399s / 42442.4999 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0093
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 197.2087s / 42639.7087 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 185.9198s / 42825.6285 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 180.4893s / 43006.1178 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.9645s / 43175.0824 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0106
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.9748s / 43343.0572 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0108
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.4115s / 43508.4687 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0108
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.8546s / 43675.3233 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8482s / 43841.1715 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0117
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5249s / 44006.6964 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0122
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7016s / 44171.3980 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0135
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.0999s / 44336.4979 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0139
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.0405s / 44502.5384 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0147
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6956s / 44668.2340 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0163
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.2362s / 44833.4703 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0164
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.1760s / 44997.6463 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0177
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7710s / 45162.4172 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0182
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.5410s / 45326.9582 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0174
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.2092s / 45492.1674 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0176
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6909s / 45657.8583 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0174
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8087s / 45823.6670 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0165
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5060s / 45990.1730 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0177
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1677s / 46156.3407 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0176
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8175s / 46322.1582 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0179
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5435s / 46488.7017 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0185
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1643s / 46654.8660 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0180
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8918s / 46820.7578 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0176
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.9863s / 46987.7441 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0173
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.0355s / 47153.7796 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0179
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.2821s / 47321.0617 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0193
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.3126s / 47487.3743 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0189
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1513s / 47653.5256 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0202
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1834s / 47819.7090 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0205
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3416s / 47985.0506 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0206
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3581s / 48150.4087 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0202
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5141s / 48316.9229 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0203
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.0307s / 48481.9536 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0210
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.4859s / 48648.4394 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0210
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8702s / 48814.3096 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0194
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.0840s / 48980.3936 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0175
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5270s / 49146.9206 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0162
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8908s / 49312.8115 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0155
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1303s / 49478.9418 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0151
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.2002s / 49646.1420 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0149
env0_second_0:                 episode reward: 4.6500,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -4.6000,                 loss: nan
env3_second_0:                 episode reward: 4.6000,                 loss: nan
env4_first_0:                 episode reward: -4.3500,                 loss: nan
env4_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.9310s / 49812.0730 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0150
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.1580s / 49977.2310 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0160
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -4.1000,                 loss: nan
env4_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5168s / 50142.7478 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0176
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.4739s / 50308.2217 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0190
env0_second_0:                 episode reward: 4.9500,                 loss: nan
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.6631s / 50474.8848 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0205
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.9701s / 50640.8549 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0196
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3576s / 50806.2125 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0178
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5801s / 50971.7926 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0147
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6932s / 51137.4858 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0128
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.7615s / 51303.2472 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0112
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.3735s / 51469.6207 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0102
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.0278s / 51635.6485 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0097
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5109s / 51802.1594 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0094
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.5053s / 51968.6647 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0093
env0_second_0:                 episode reward: 3.8000,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.8200s / 52135.4846 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0097
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -3.0000,                 loss: nan
env2_second_0:                 episode reward: 3.0000,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.9237s / 52302.4084 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0099
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.1971s / 52469.6055 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0106
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.1341s / 52636.7396 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.6190s / 52804.3586 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.1596s / 52972.5182 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.1342s / 53139.6524 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.5365s / 53308.1889 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0131
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.3485s / 53475.5374 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0137
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8087s / 53641.3461 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0150
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 171.2958s / 53812.6420 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0157
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.4426s / 53980.0845 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0159
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.0981s / 54144.1826 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0155
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.2498s / 54311.4325 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0148
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.9849s / 54478.4174 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0145
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3650s / 54643.7824 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0147
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.8380s / 54808.6204 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0156
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.6083s / 54975.2287 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0159
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2411s / 55141.4698 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0162
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6515s / 55307.1214 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0162
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7473s / 55471.8687 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0161
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6731s / 55637.5417 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0162
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6137s / 55803.1554 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0156
env0_second_0:                 episode reward: 2.8000,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -3.0500,                 loss: nan
env4_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.0800s / 55971.2354 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0149
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.9755s / 56136.2109 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0145
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.5321s / 56300.7430 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0142
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7851s / 56465.5281 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0145
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5065s / 56631.0346 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0145
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3500s / 56796.3846 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0146
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8624s / 56962.2469 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0146
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.7852s / 57130.0321 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0148
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.9457s / 57295.9778 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0144
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 180.3473s / 57476.3251 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0146
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0220
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.2000,                 loss: nan
env2_second_0:                 episode reward: -2.2000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Score delta: 7.2, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/6240_0.
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.6341s / 57643.9592 s
env0_first_0:                 episode reward: -2.9500,                 loss: nan
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0210
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -2.8500,                 loss: nan
env2_second_0:                 episode reward: 2.8500,                 loss: nan
env3_first_0:                 episode reward: -3.0500,                 loss: nan
env3_second_0:                 episode reward: 3.0500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 183.5603s / 57827.5195 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0184
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0224
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Score delta: 7.2, save the model to .//data/model/20220429_0152/pettingzoo_tennis_v2_nxdo2/6263_1.
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8497s / 57993.3692 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0174
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.0500,                 loss: nan
env4_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.1244s / 58157.4936 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0168
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -5.3500,                 loss: nan
env4_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1957s / 58323.6893 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0158
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.4000,                 loss: nan
env4_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.9290s / 58490.6183 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0161
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2433s / 58656.8616 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0162
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -4.8500,                 loss: nan
env3_second_0:                 episode reward: 4.8500,                 loss: nan
env4_first_0:                 episode reward: -4.5500,                 loss: nan
env4_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.2423s / 58822.1040 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0159
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.6500,                 loss: nan
env3_second_0:                 episode reward: 4.6500,                 loss: nan
env4_first_0:                 episode reward: -4.3500,                 loss: nan
env4_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2436s / 58988.3476 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -3.6500,                 loss: nan
env3_second_0:                 episode reward: 3.6500,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7104s / 59153.0579 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0165
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -5.0000,                 loss: nan
env2_second_0:                 episode reward: 5.0000,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.3370s / 59320.3949 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0158
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.3500,                 loss: nan
env3_second_0:                 episode reward: 4.3500,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2209s / 59486.6158 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0159
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.5500,                 loss: nan
env4_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8888s / 59652.5046 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0154
env0_second_0:                 episode reward: 4.4000,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.0500,                 loss: nan
env4_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.7396s / 59818.2442 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0149
env0_second_0:                 episode reward: 3.9500,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.1000,                 loss: nan
env4_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7512s / 59982.9954 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0152
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -3.9500,                 loss: nan
env4_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.1158s / 60150.1112 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0157
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -3.0500,                 loss: nan
env3_second_0:                 episode reward: 3.0500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1793s / 60316.2905 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0170
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.8731s / 60482.1636 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0179
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.0583s / 60647.2220 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0171
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.5946s / 60814.8165 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0159
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.1207s / 60979.9373 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0163
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5847s / 61145.5220 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0161
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.4854s / 61310.0074 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0166
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.9489s / 61477.9564 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0170
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.3171s / 61645.2735 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0176
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.9685s / 61809.2420 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0180
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
env3_first_0:                 episode reward: -3.7000,                 loss: nan
env3_second_0:                 episode reward: 3.7000,                 loss: nan
env4_first_0:                 episode reward: -3.6500,                 loss: nan
env4_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.9984s / 61976.2404 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0196
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.3854s / 62143.6258 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0206
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.7557s / 62310.3815 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0195
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -2.8500,                 loss: nan
env2_second_0:                 episode reward: 2.8500,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5132s / 62475.8947 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0197
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -5.2000,                 loss: nan
env3_second_0:                 episode reward: 5.2000,                 loss: nan
env4_first_0:                 episode reward: -4.9000,                 loss: nan
env4_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.0173s / 62643.9119 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0196
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.6000,                 loss: nan
env3_second_0:                 episode reward: 4.6000,                 loss: nan
env4_first_0:                 episode reward: -4.3500,                 loss: nan
env4_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.4649s / 62810.3768 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0186
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7465s / 62975.1233 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.0171
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.5000,                 loss: nan
env3_second_0:                 episode reward: 5.5000,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.0589s / 63141.1822 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0154
env0_second_0:                 episode reward: 4.8500,                 loss: nan
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.7864s / 63307.9687 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 5.4000,                 loss: nan
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -5.5000,                 loss: nan
env3_second_0:                 episode reward: 5.5000,                 loss: nan
env4_first_0:                 episode reward: -5.4000,                 loss: nan
env4_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.1361s / 63475.1048 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.1905s / 63640.2953 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6658s / 63805.9611 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0114
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.2013s / 63973.1625 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0111
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6682s / 64138.8307 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.6025s / 64306.4331 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.8960s / 64474.3292 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.6890s / 64642.0182 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.9636s / 64809.9818 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 168.0731s / 64978.0549 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2949s / 65144.3499 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.2480s / 65310.5978 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0142
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.4892s / 65477.0870 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0152
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.6604s / 65644.7474 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0165
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.3829s / 65811.1303 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0173
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5602s / 65976.6905 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0182
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.3247s / 66141.0151 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0188
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.1277s / 66307.1428 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0200
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.7987s / 66472.9415 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0195
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.9162s / 66638.8577 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0181
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.4333s / 66803.2910 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0177
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3479s / 66968.6389 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0177
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 167.4928s / 67136.1317 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0174
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.7650s / 67301.8967 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0168
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.1020s / 67465.9986 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0163
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.5444s / 67631.5430 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0165
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.4724s / 67796.0154 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0168
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.9189s / 67960.9343 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0166
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.3620s / 68126.2963 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0166
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.1257s / 68289.4220 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0154
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.0831s / 68453.5051 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0156
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.7594s / 68619.2644 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0162
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.5374s / 68782.8018 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0156
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.2003s / 68948.0021 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0151
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.9919s / 69112.9941 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0150
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.6523s / 69277.6463 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0152
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.9582s / 69443.6046 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0153
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.9610s / 69608.5656 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0158
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.3855s / 69770.9511 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.3993s / 69934.3504 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0160
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.6645s / 70100.0150 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0158
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.1027s / 70264.1177 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0155
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.8933s / 70427.0109 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.5511s / 70591.5620 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0154
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.7948s / 70756.3568 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0155
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.8575s / 70919.2144 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0157
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.8422s / 71082.0565 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0160
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.0001s / 71243.0566 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0171
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -1.9000,                 loss: nan
env4_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.7955s / 71404.8521 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0173
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.3538s / 71566.2058 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0174
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.0352s / 71727.2410 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0178
env0_second_0:                 episode reward: 5.4000,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -5.6000,                 loss: nan
env3_second_0:                 episode reward: 5.6000,                 loss: nan
env4_first_0:                 episode reward: -5.2500,                 loss: nan
env4_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.0444s / 71889.2855 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0170
env0_second_0:                 episode reward: 4.7000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.1500,                 loss: nan
env4_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.9919s / 72051.2773 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0161
env0_second_0:                 episode reward: 4.9500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -5.0500,                 loss: nan
env4_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.3930s / 72211.6703 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0161
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.6500,                 loss: nan
env4_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.7606s / 72372.4309 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0156
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -5.0000,                 loss: nan
env3_second_0:                 episode reward: 5.0000,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.1490s / 72534.5799 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0152
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -4.9000,                 loss: nan
env4_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 159.8913s / 72694.4712 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0143
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.1863s / 72855.6575 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.4795s / 73018.1370 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0143
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.0479s / 73178.1849 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0144
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 159.2512s / 73337.4361 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0144
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.4528s / 73497.8889 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0154
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.1002s / 73659.9890 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0155
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.1308s / 73820.1198 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0160
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.8421s / 73978.9619 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0157
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.7110s / 74139.6728 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0160
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.2170s / 74296.8898 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0174
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.2268s / 74455.1166 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0177
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.7922s / 74612.9088 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0187
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.1664s / 74771.0752 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0196
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.4335s / 74928.5087 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0187
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.7863s / 75084.2950 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0190
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.8559s / 75243.1509 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0192
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.7759s / 75400.9268 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0187
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 158.1910s / 75559.1178 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0181
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 157.9732s / 75717.0910 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0178
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7714s / 75871.8624 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0171
env0_second_0:                 episode reward: 4.1000,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -4.1000,                 loss: nan
env3_second_0:                 episode reward: 4.1000,                 loss: nan
env4_first_0:                 episode reward: -4.1000,                 loss: nan
env4_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 156.4273s / 76028.2898 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0167
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -4.8500,                 loss: nan
env4_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2357s / 76182.5255 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0166
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4158s / 76335.9413 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.7071s / 76488.6484 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0159
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.7056s / 76641.3540 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.5000,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7534s / 76796.1074 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0158
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.3359s / 76950.4433 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0161
env0_second_0:                 episode reward: 3.1500,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.9074s / 77105.3507 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0158
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.4703s / 77260.8210 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9363s / 77413.7573 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0156
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.4132s / 77568.1706 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0156
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7762s / 77722.9467 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0149
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5838s / 77876.5306 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0140
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.7998s / 78031.3304 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0144
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2641s / 78184.5945 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0141
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.2881s / 78339.8826 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0141
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0519s / 78493.9345 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6361s / 78649.5706 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.5603s / 78805.1308 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0721s / 78960.2029 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0141
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5711s / 79113.7740 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0141
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.0746s / 79265.8486 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0146
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.2000,                 loss: nan
env4_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.5928s / 79418.4414 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0143
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.6251s / 79571.0665 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5162s / 79724.5826 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0143
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.7785s / 79876.3612 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0143
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.8927s / 80030.2539 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0146
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.4975s / 80183.7514 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0149
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5458s / 80338.2972 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2936s / 80491.5908 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.3782s / 80642.9691 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0145
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.6749s / 80795.6439 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2410s / 80949.8850 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0153
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.0884s / 81104.9734 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0154
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -5.4000,                 loss: nan
env4_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.5918s / 81259.5651 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0141
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.8500,                 loss: nan
env2_second_0:                 episode reward: 4.8500,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.0311s / 81412.5963 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0133
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -5.3500,                 loss: nan
env4_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.2464s / 81565.8426 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0129
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0730s / 81719.9156 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0129
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.7776s / 81872.6932 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0131
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.7092s / 82026.4024 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2179s / 82180.6203 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9912s / 82333.6115 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.6793s / 82487.2908 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.7897s / 82643.0805 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.6553s / 82797.7358 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 155.6174s / 82953.3532 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.8291s / 83108.1822 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1174s / 83261.2996 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0133
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.5242s / 83413.8238 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.2736s / 83566.0974 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0137
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.0241s / 83720.1215 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0138
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.0711s / 83871.1926 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0146
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9656s / 84024.1581 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0143
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.3835s / 84177.5416 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0143
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.0664s / 84329.6080 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.6567s / 84482.2647 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.9879s / 84635.2526 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.1062s / 84787.3588 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0135
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.7176s / 84940.0764 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.0458s / 85093.1222 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0141
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.5664s / 85246.6887 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1370s / 85399.8257 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0141
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.8392s / 85551.6649 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0141
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 154.2976s / 85705.9625 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0147
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.8451s / 85858.8075 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.1573s / 86008.9648 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0144
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.2027s / 86158.1675 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0147
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.2736s / 86303.4410 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0147
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.6932s / 86444.1343 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0152
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.3679s / 86586.5022 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.7487s / 86730.2508 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0146
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.2671s / 86874.5179 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 141.1095s / 87015.6274 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0142
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nanLoad tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 137.7065s / 87153.3339 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0147
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.2517s / 87293.5856 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0149
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
