pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526/pettingzoo_tennis_v2_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526/pettingzoo_tennis_v2_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 209.4215s / 209.4215 s
env0_first_0:                 episode reward: 219.0000,                 loss: 0.0101
env0_second_0:                 episode reward: -219.0000,                 loss: nan
env1_first_0:                 episode reward: 219.0000,                 loss: nan
env1_second_0:                 episode reward: -219.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4446.0250s / 4655.4465 s
env0_first_0:                 episode reward: 217.7500,                 loss: 0.0097
env0_second_0:                 episode reward: -217.7500,                 loss: nan
env1_first_0:                 episode reward: 217.9500,                 loss: nan
env1_second_0:                 episode reward: -217.9500,                 loss: nan
Score delta: 437.8, update the opponent.
Episode: 41/10000 (0.4100%),                 avg. length: 6258.2,                last time consumption/overall running time: 2798.4208s / 7453.8673 s
env0_first_0:                 episode reward: -81.8000,                 loss: nan
env0_second_0:                 episode reward: 81.8000,                 loss: 0.0101
env1_first_0:                 episode reward: -105.3500,                 loss: nan
env1_second_0:                 episode reward: 105.3500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 4246.8,                last time consumption/overall running time: 1909.0401s / 9362.9074 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0089
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0098
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Score delta: 135.8, update the opponent.
Episode: 81/10000 (0.8100%),                 avg. length: 2788.8,                last time consumption/overall running time: 1257.0728s / 10619.9802 s
env0_first_0:                 episode reward: 31.4000,                 loss: 0.0076
env0_second_0:                 episode reward: -31.4000,                 loss: 0.0093
env1_first_0:                 episode reward: 33.8000,                 loss: nan
env1_second_0:                 episode reward: -33.8000,                 loss: nan
Score delta: 76.2, update the opponent.
Episode: 101/10000 (1.0100%),                 avg. length: 4012.45,                last time consumption/overall running time: 1807.4004s / 12427.3806 s
env0_first_0:                 episode reward: 3.7000,                 loss: nan
env0_second_0:                 episode reward: -3.7000,                 loss: 0.0056
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2782.75,                last time consumption/overall running time: 1252.1994s / 13679.5800 s
env0_first_0:                 episode reward: -15.0500,                 loss: nan
env0_second_0:                 episode reward: 15.0500,                 loss: 0.0039
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1847.1,                last time consumption/overall running time: 833.6803s / 14513.2603 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0033
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1947.05,                last time consumption/overall running time: 878.0680s / 15391.3283 s
env0_first_0:                 episode reward: -23.0500,                 loss: nan
env0_second_0:                 episode reward: 23.0500,                 loss: 0.0036
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1722.25,                last time consumption/overall running time: 776.0945s / 16167.4228 s
env0_first_0:                 episode reward: -23.5500,                 loss: nan
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0035
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1729.6,                last time consumption/overall running time: 779.5328s / 16946.9556 s
env0_first_0:                 episode reward: -23.4000,                 loss: nan
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0034
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1723.1,                last time consumption/overall running time: 776.3446s / 17723.3002 s
env0_first_0:                 episode reward: -22.8500,                 loss: nan
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0035
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1745.05,                last time consumption/overall running time: 786.6529s / 18509.9531 s
env0_first_0:                 episode reward: -22.4000,                 loss: nan
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0035
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1768.0,                last time consumption/overall running time: 796.4543s / 19306.4073 s
env0_first_0:                 episode reward: -23.2000,                 loss: nan
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0032
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 2064.05,                last time consumption/overall running time: 928.7666s / 20235.1740 s
env0_first_0:                 episode reward: -30.2500,                 loss: 0.0080
env0_second_0:                 episode reward: 30.2500,                 loss: 0.0031
env1_first_0:                 episode reward: -29.8500,                 loss: nan
env1_second_0:                 episode reward: 29.8500,                 loss: nan
Score delta: 50.6, update the opponent.
Episode: 301/10000 (3.0100%),                 avg. length: 3633.35,                last time consumption/overall running time: 1635.6633s / 21870.8373 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0078
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2174.5,                last time consumption/overall running time: 978.5072s / 22849.3445 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0046
env0_second_0:                 episode reward: -20.6000,                 loss: nan
env1_first_0:                 episode reward: 22.8500,                 loss: nan
env1_second_0:                 episode reward: -22.8500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 2071.1,                last time consumption/overall running time: 933.4596s / 23782.8041 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0034
env0_second_0:                 episode reward: -22.4000,                 loss: 0.0075
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
Score delta: 50.6, update the opponent.
Episode: 361/10000 (3.6100%),                 avg. length: 5467.7,                last time consumption/overall running time: 2461.5686s / 26244.3727 s
env0_first_0:                 episode reward: -8.4500,                 loss: nan
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 5011.1,                last time consumption/overall running time: 2255.5345s / 28499.9072 s
env0_first_0:                 episode reward: -35.7500,                 loss: 0.0079
env0_second_0:                 episode reward: 35.7500,                 loss: 0.0034
env1_first_0:                 episode reward: -42.3000,                 loss: nan
env1_second_0:                 episode reward: 42.3000,                 loss: nan
Score delta: 58.4, update the opponent.
Episode: 401/10000 (4.0100%),                 avg. length: 2584.3,                last time consumption/overall running time: 1162.9009s / 29662.8081 s
env0_first_0:                 episode reward: 15.2000,                 loss: 0.0052
env0_second_0:                 episode reward: -15.2000,                 loss: nan
env1_first_0:                 episode reward: 12.4000,                 loss: nan
env1_second_0:                 episode reward: -12.4000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 2092.7,                last time consumption/overall running time: 943.2114s / 30606.0195 s
env0_first_0:                 episode reward: 18.9000,                 loss: 0.0030
env0_second_0:                 episode reward: -18.9000,                 loss: nan
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 2045.75,                last time consumption/overall running time: 922.6894s / 31528.7089 s
env0_first_0:                 episode reward: 19.0000,                 loss: 0.0030
env0_second_0:                 episode reward: -19.0000,                 loss: nan
env1_first_0:                 episode reward: 16.5000,                 loss: nan
env1_second_0:                 episode reward: -16.5000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1941.3,                last time consumption/overall running time: 874.7214s / 32403.4303 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0031
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 19.1000,                 loss: nan
env1_second_0:                 episode reward: -19.1000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 2034.75,                last time consumption/overall running time: 916.5348s / 33319.9651 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0027
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1977.4,                last time consumption/overall running time: 890.5350s / 34210.5000 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0027
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.2500,                 loss: nan
env1_second_0:                 episode reward: -21.2500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 4439.8,                last time consumption/overall running time: 1997.1085s / 36207.6086 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0033
env0_second_0:                 episode reward: -20.7000,                 loss: 0.0130
env1_first_0:                 episode reward: 11.9500,                 loss: nan
env1_second_0:                 episode reward: -11.9500,                 loss: nan
Score delta: 51.6, update the opponent.
Episode: 541/10000 (5.4100%),                 avg. length: 7207.3,                last time consumption/overall running time: 3641.9389s / 39849.5474 s
env0_first_0:                 episode reward: -85.4500,                 loss: 0.0090
env0_second_0:                 episode reward: 85.4500,                 loss: 0.0116
env1_first_0:                 episode reward: -81.8000,                 loss: nan
env1_second_0:                 episode reward: 81.8000,                 loss: nan
Score delta: 256.2, update the opponent.
Episode: 561/10000 (5.6100%),                 avg. length: 5375.0,                last time consumption/overall running time: 2861.6655s / 42711.2129 s
env0_first_0:                 episode reward: -57.6000,                 loss: 0.0086
env0_second_0:                 episode reward: 57.6000,                 loss: nan
env1_first_0:                 episode reward: -65.2000,                 loss: nan
env1_second_0:                 episode reward: 65.2000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 2303.9,                last time consumption/overall running time: 1227.0983s / 43938.3113 s
env0_first_0:                 episode reward: 17.2500,                 loss: 0.0054
env0_second_0:                 episode reward: -17.2500,                 loss: nan
env1_first_0:                 episode reward: 17.3500,                 loss: nan
env1_second_0:                 episode reward: -17.3500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1911.0,                last time consumption/overall running time: 1018.0076s / 44956.3188 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.0039
env0_second_0:                 episode reward: -20.3000,                 loss: nan
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 2005.4,                last time consumption/overall running time: 1068.5030s / 46024.8218 s
env0_first_0:                 episode reward: 17.2000,                 loss: 0.0032
env0_second_0:                 episode reward: -17.2000,                 loss: nan
env1_first_0:                 episode reward: 19.2000,                 loss: nan
env1_second_0:                 episode reward: -19.2000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1863.0,                last time consumption/overall running time: 992.8899s / 47017.7117 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.0032
env0_second_0:                 episode reward: -20.0500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1832.9,                last time consumption/overall running time: 977.2535s / 47994.9652 s
env0_first_0:                 episode reward: 21.0500,                 loss: 0.0033
env0_second_0:                 episode reward: -21.0500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1817.35,                last time consumption/overall running time: 969.0919s / 48964.0571 s
env0_first_0:                 episode reward: 19.5500,                 loss: 0.0031
env0_second_0:                 episode reward: -19.5500,                 loss: nan
env1_first_0:                 episode reward: 24.7000,                 loss: nan
env1_second_0:                 episode reward: -24.7000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1710.9,                last time consumption/overall running time: 912.8887s / 49876.9457 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0031
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 22.0000,                 loss: nan
env1_second_0:                 episode reward: -22.0000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 3100.8,                last time consumption/overall running time: 1652.4811s / 51529.4268 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0033
env0_second_0:                 episode reward: -20.9000,                 loss: 0.0089
env1_first_0:                 episode reward: 22.2000,                 loss: nan
env1_second_0:                 episode reward: -22.2000,                 loss: nan
Score delta: 51.2, update the opponent.
Episode: 741/10000 (7.4100%),                 avg. length: 6089.45,                last time consumption/overall running time: 3243.1552s / 54772.5820 s
env0_first_0:                 episode reward: -57.4000,                 loss: 0.0079
env0_second_0:                 episode reward: 57.4000,                 loss: 0.0060
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
Score delta: 65.0, update the opponent.
Episode: 761/10000 (7.6100%),                 avg. length: 4764.15,                last time consumption/overall running time: 2537.4294s / 57310.0114 s
env0_first_0:                 episode reward: 46.6500,                 loss: 0.0060
env0_second_0:                 episode reward: -46.6500,                 loss: 0.0074
env1_first_0:                 episode reward: 42.6500,                 loss: nan
env1_second_0:                 episode reward: -42.6500,                 loss: nan
Score delta: 141.6, update the opponent.
Episode: 781/10000 (7.8100%),                 avg. length: 6195.7,                last time consumption/overall running time: 3299.5940s / 60609.6054 s
env0_first_0:                 episode reward: -2.5500,                 loss: nan
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 3532.3,                last time consumption/overall running time: 1882.8798s / 62492.4852 s
env0_first_0:                 episode reward: -20.4000,                 loss: nan
env0_second_0:                 episode reward: 20.4000,                 loss: 0.0023
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 3295.65,                last time consumption/overall running time: 1756.6838s / 64249.1690 s
env0_first_0:                 episode reward: -9.1500,                 loss: nan
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0037
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2728.85,                last time consumption/overall running time: 1453.8577s / 65703.0267 s
env0_first_0:                 episode reward: -16.9000,                 loss: nan
env0_second_0:                 episode reward: 16.9000,                 loss: 0.0033
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2576.0,                last time consumption/overall running time: 1372.3032s / 67075.3298 s
env0_first_0:                 episode reward: -32.5000,                 loss: 0.0094
env0_second_0:                 episode reward: 32.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Score delta: 53.0, update the opponent.
Episode: 881/10000 (8.8100%),                 avg. length: 5177.0,                last time consumption/overall running time: 2757.5533s / 69832.8832 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.0055
env0_second_0:                 episode reward: 16.4000,                 loss: nan
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 3243.85,                last time consumption/overall running time: 1727.4241s / 71560.3073 s
env0_first_0:                 episode reward: 12.1500,                 loss: 0.0028
env0_second_0:                 episode reward: -12.1500,                 loss: nan
env1_first_0:                 episode reward: 10.3500,                 loss: nan
env1_second_0:                 episode reward: -10.3500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 3157.5,                last time consumption/overall running time: 1681.1449s / 73241.4522 s
env0_first_0:                 episode reward: 13.1000,                 loss: 0.0021
env0_second_0:                 episode reward: -13.1000,                 loss: nan
env1_first_0:                 episode reward: 18.5500,                 loss: nan
env1_second_0:                 episode reward: -18.5500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2664.55,                last time consumption/overall running time: 1419.5762s / 74661.0284 s
env0_first_0:                 episode reward: 17.8500,                 loss: 0.0020
env0_second_0:                 episode reward: -17.8500,                 loss: nan
env1_first_0:                 episode reward: 16.6500,                 loss: nan
env1_second_0:                 episode reward: -16.6500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2424.85,                last time consumption/overall running time: 1291.4298s / 75952.4582 s
env0_first_0:                 episode reward: 19.0000,                 loss: 0.0024
env0_second_0:                 episode reward: -19.0000,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2473.95,                last time consumption/overall running time: 1318.7750s / 77271.2332 s
env0_first_0:                 episode reward: 16.4000,                 loss: 0.0024
env0_second_0:                 episode reward: -16.4000,                 loss: nan
env1_first_0:                 episode reward: 10.9000,                 loss: nan
env1_second_0:                 episode reward: -10.9000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2371.05,                last time consumption/overall running time: 1263.0031s / 78534.2363 s
env0_first_0:                 episode reward: 18.2500,                 loss: 0.0020
env0_second_0:                 episode reward: -18.2500,                 loss: nan
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2068.15,                last time consumption/overall running time: 1102.0294s / 79636.2657 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0021
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1742.95,                last time consumption/overall running time: 928.7283s / 80564.9940 s
env0_first_0:                 episode reward: 19.5000,                 loss: 0.0017
env0_second_0:                 episode reward: -19.5000,                 loss: nan
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1745.15,                last time consumption/overall running time: 929.7276s / 81494.7216 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0015
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 18.0000,                 loss: nan
env1_second_0:                 episode reward: -18.0000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1702.8,                last time consumption/overall running time: 907.5663s / 82402.2880 s
env0_first_0:                 episode reward: 22.2000,                 loss: 0.0013
env0_second_0:                 episode reward: -22.2000,                 loss: nan
env1_first_0:                 episode reward: 21.1500,                 loss: nan
env1_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1619.9,                last time consumption/overall running time: 863.3188s / 83265.6067 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.0012
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1593.6,                last time consumption/overall running time: 849.3482s / 84114.9550 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0013
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 19.7000,                 loss: nan
env1_second_0:                 episode reward: -19.7000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1588.05,                last time consumption/overall running time: 846.2951s / 84961.2500 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0012
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 22.8000,                 loss: nan
env1_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1579.7,                last time consumption/overall running time: 841.5685s / 85802.8186 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0012
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1614.15,                last time consumption/overall running time: 860.6005s / 86663.4191 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0011
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1703.35,                last time consumption/overall running time: 907.9158s / 87571.3349 s
env0_first_0:                 episode reward: 20.0000,                 loss: 0.0016
env0_second_0:                 episode reward: -20.0000,                 loss: nan
env1_first_0:                 episode reward: 18.5500,                 loss: nan
env1_second_0:                 episode reward: -18.5500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1627.75,                last time consumption/overall running time: 868.0253s / 88439.3602 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0016
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1527.9,                last time consumption/overall running time: 814.7330s / 89254.0932 s
env0_first_0:                 episode reward: 22.4500,                 loss: 0.0011
env0_second_0:                 episode reward: -22.4500,                 loss: nan
env1_first_0:                 episode reward: 23.3000,                 loss: nan
env1_second_0:                 episode reward: -23.3000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1673.7,                last time consumption/overall running time: 891.9126s / 90146.0058 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0009
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.3500,                 loss: nan
env1_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1564.45,                last time consumption/overall running time: 834.0696s / 90980.0754 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0012
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1597.9,                last time consumption/overall running time: 852.1506s / 91832.2260 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0012
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1772.1,                last time consumption/overall running time: 944.8689s / 92777.0949 s
env0_first_0:                 episode reward: 19.4500,                 loss: 0.0014
env0_second_0:                 episode reward: -19.4500,                 loss: nan
env1_first_0:                 episode reward: 19.7000,                 loss: nan
env1_second_0:                 episode reward: -19.7000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1588.65,                last time consumption/overall running time: 847.1119s / 93624.2068 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0017
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 22.7000,                 loss: nan
env1_second_0:                 episode reward: -22.7000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1523.35,                last time consumption/overall running time: 812.5773s / 94436.7841 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0010
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 22.1500,                 loss: nan
env1_second_0:                 episode reward: -22.1500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1524.6,                last time consumption/overall running time: 813.4260s / 95250.2101 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0008
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1617.0,                last time consumption/overall running time: 861.7788s / 96111.9889 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0010
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 22.2500,                 loss: nan
env1_second_0:                 episode reward: -22.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1622.1,                last time consumption/overall running time: 864.6557s / 96976.6445 s
env0_first_0:                 episode reward: 20.2000,                 loss: 0.0013
env0_second_0:                 episode reward: -20.2000,                 loss: nan
env1_first_0:                 episode reward: 22.7000,                 loss: nan
env1_second_0:                 episode reward: -22.7000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1654.4,                last time consumption/overall running time: 880.3833s / 97857.0278 s
env0_first_0:                 episode reward: 21.8500,                 loss: 0.0016
env0_second_0:                 episode reward: -21.8500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1558.35,                last time consumption/overall running time: 828.0777s / 98685.1055 s
env0_first_0:                 episode reward: 21.0500,                 loss: 0.0015
env0_second_0:                 episode reward: -21.0500,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1628.75,                last time consumption/overall running time: 866.3260s / 99551.4315 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0012
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1517.8,                last time consumption/overall running time: 807.8192s / 100359.2507 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0011
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 23.0500,                 loss: nan
env1_second_0:                 episode reward: -23.0500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1555.05,                last time consumption/overall running time: 826.9826s / 101186.2332 s
env0_first_0:                 episode reward: 21.9000,                 loss: 0.0009
env0_second_0:                 episode reward: -21.9000,                 loss: nan
env1_first_0:                 episode reward: 21.3500,                 loss: nan
env1_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1624.05,                last time consumption/overall running time: 864.1575s / 102050.3908 s
env0_first_0:                 episode reward: 22.2500,                 loss: 0.0012
env0_second_0:                 episode reward: -22.2500,                 loss: nan
env1_first_0:                 episode reward: 21.1500,                 loss: nan
env1_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1657.55,                last time consumption/overall running time: 882.2486s / 102932.6393 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0013
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1590.0,                last time consumption/overall running time: 845.4507s / 103778.0901 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0012
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1667.8,                last time consumption/overall running time: 887.5042s / 104665.5943 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0012
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1554.05,                last time consumption/overall running time: 827.0521s / 105492.6464 s
env0_first_0:                 episode reward: 22.5500,                 loss: 0.0014
env0_second_0:                 episode reward: -22.5500,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1691.65,                last time consumption/overall running time: 899.6698s / 106392.3162 s
env0_first_0:                 episode reward: 21.8000,                 loss: 0.0013
env0_second_0:                 episode reward: -21.8000,                 loss: nan
env1_first_0:                 episode reward: 22.4000,                 loss: nan
env1_second_0:                 episode reward: -22.4000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 4548.1,                last time consumption/overall running time: 2417.1168s / 108809.4330 s
env0_first_0:                 episode reward: -30.3000,                 loss: 0.0014
env0_second_0:                 episode reward: 30.3000,                 loss: 0.0084
env1_first_0:                 episode reward: -39.4000,                 loss: nan
env1_second_0:                 episode reward: 39.4000,                 loss: nan
Score delta: 50.4, update the opponent.
Episode: 1681/10000 (16.8100%),                 avg. length: 6970.75,                last time consumption/overall running time: 3703.4858s / 112512.9188 s
env0_first_0:                 episode reward: -112.7000,                 loss: 0.0071
env0_second_0:                 episode reward: 112.7000,                 loss: 0.0107
env1_first_0:                 episode reward: -116.3000,                 loss: nan
env1_second_0:                 episode reward: 116.3000,                 loss: nan
Score delta: 408.8, update the opponent.
Episode: 1701/10000 (17.0100%),                 avg. length: 1996.85,                last time consumption/overall running time: 1061.7694s / 113574.6882 s
env0_first_0:                 episode reward: 17.6000,                 loss: 0.0066
env0_second_0:                 episode reward: -17.6000,                 loss: nan
env1_first_0:                 episode reward: 16.8500,                 loss: nan
env1_second_0:                 episode reward: -16.8500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1807.0,                last time consumption/overall running time: 961.4464s / 114536.1346 s
env0_first_0:                 episode reward: 18.7500,                 loss: 0.0034
env0_second_0:                 episode reward: -18.7500,                 loss: nan
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1618.75,                last time consumption/overall running time: 861.3379s / 115397.4725 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1987.9,                last time consumption/overall running time: 1057.5811s / 116455.0536 s
env0_first_0:                 episode reward: 13.0000,                 loss: 0.0029
env0_second_0:                 episode reward: -13.0000,                 loss: nan
env1_first_0:                 episode reward: 13.5500,                 loss: nan
env1_second_0:                 episode reward: -13.5500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1622.8,                last time consumption/overall running time: 863.3612s / 117318.4148 s
env0_first_0:                 episode reward: 21.8500,                 loss: 0.0035
env0_second_0:                 episode reward: -21.8500,                 loss: nan
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1519.8,                last time consumption/overall running time: 807.9584s / 118126.3732 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0023
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1578.8,                last time consumption/overall running time: 838.6433s / 118965.0165 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0019
env0_second_0:                 episode reward: -20.9000,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1563.95,                last time consumption/overall running time: 831.5970s / 119796.6135 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0016
env0_second_0:                 episode reward: -20.4000,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1470.0,                last time consumption/overall running time: 781.5320s / 120578.1455 s
env0_first_0:                 episode reward: 22.7000,                 loss: 0.0016
env0_second_0:                 episode reward: -22.7000,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2244.4,                last time consumption/overall running time: 1193.5326s / 121771.6782 s
env0_first_0:                 episode reward: 30.4500,                 loss: 0.0018
env0_second_0:                 episode reward: -30.4500,                 loss: 0.0109
env1_first_0:                 episode reward: 31.2500,                 loss: nan
env1_second_0:                 episode reward: -31.2500,                 loss: nan
Score delta: 82.6, update the opponent.
Episode: 1901/10000 (19.0100%),                 avg. length: 6714.5,                last time consumption/overall running time: 3568.0117s / 125339.6899 s
env0_first_0:                 episode reward: 47.2000,                 loss: nan
env0_second_0:                 episode reward: -47.2000,                 loss: 0.0052
env1_first_0:                 episode reward: 32.1000,                 loss: nan
env1_second_0:                 episode reward: -32.1000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 5352.95,                last time consumption/overall running time: 2845.1823s / 128184.8722 s
env0_first_0:                 episode reward: -13.2500,                 loss: nan
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 4430.9,                last time consumption/overall running time: 2355.8170s / 130540.6892 s
env0_first_0:                 episode reward: -13.8000,                 loss: nan
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 3861.0,                last time consumption/overall running time: 2052.2487s / 132592.9379 s
env0_first_0:                 episode reward: -11.5500,                 loss: nan
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 3729.45,                last time consumption/overall running time: 1983.9045s / 134576.8423 s
env0_first_0:                 episode reward: -16.4500,                 loss: nan
env0_second_0:                 episode reward: 16.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 3355.05,                last time consumption/overall running time: 1784.2346s / 136361.0769 s
env0_first_0:                 episode reward: -16.5500,                 loss: nan
env0_second_0:                 episode reward: 16.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 3048.65,                last time consumption/overall running time: 1622.2687s / 137983.3457 s
env0_first_0:                 episode reward: -15.8000,                 loss: nan
env0_second_0:                 episode reward: 15.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2844.4,                last time consumption/overall running time: 1513.4016s / 139496.7473 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2855.4,                last time consumption/overall running time: 1518.0902s / 141014.8375 s
env0_first_0:                 episode reward: -18.6000,                 loss: nan
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2751.65,                last time consumption/overall running time: 1463.0013s / 142477.8388 s
env0_first_0:                 episode reward: -20.1000,                 loss: nan
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2614.6,                last time consumption/overall running time: 1390.8004s / 143868.6392 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2411.25,                last time consumption/overall running time: 1281.6418s / 145150.2811 s
env0_first_0:                 episode reward: -23.6500,                 loss: nan
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0031
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2516.2,                last time consumption/overall running time: 1336.9100s / 146487.1911 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0032
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2414.55,                last time consumption/overall running time: 1282.4075s / 147769.5986 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0035
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1937.2,                last time consumption/overall running time: 1029.3981s / 148798.9967 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0086
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0034
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Score delta: 51.4, update the opponent.
Episode: 2201/10000 (22.0100%),                 avg. length: 3951.0,                last time consumption/overall running time: 2098.1201s / 150897.1167 s
env0_first_0:                 episode reward: -29.8500,                 loss: 0.0076
env0_second_0:                 episode reward: 29.8500,                 loss: nan
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 7474.65,                last time consumption/overall running time: 3967.7740s / 154864.8907 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 16.9000,                 loss: nan
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 4409.65,                last time consumption/overall running time: 2340.6100s / 157205.5007 s
env0_first_0:                 episode reward: 13.7500,                 loss: 0.0034
env0_second_0:                 episode reward: -13.7500,                 loss: nan
env1_first_0:                 episode reward: 14.5500,                 loss: nan
env1_second_0:                 episode reward: -14.5500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 3977.8,                last time consumption/overall running time: 2112.0403s / 159317.5411 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0032
env0_second_0:                 episode reward: -22.3500,                 loss: 0.0123
env1_first_0:                 episode reward: 19.2000,                 loss: nan
env1_second_0:                 episode reward: -19.2000,                 loss: nan
Score delta: 50.6, update the opponent.
Episode: 2281/10000 (22.8100%),                 avg. length: 3781.8,                last time consumption/overall running time: 2009.4319s / 161326.9729 s
env0_first_0:                 episode reward: 33.0500,                 loss: nan
env0_second_0:                 episode reward: -33.0500,                 loss: 0.0076
env1_first_0:                 episode reward: 31.5500,                 loss: nan
env1_second_0:                 episode reward: -31.5500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 8961.8,                last time consumption/overall running time: 4755.8331s / 166082.8060 s
env0_first_0:                 episode reward: 9.6000,                 loss: nan
env0_second_0:                 episode reward: -9.6000,                 loss: 0.0049
env1_first_0:                 episode reward: 13.8500,                 loss: nan
env1_second_0:                 episode reward: -13.8500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 6489.85,                last time consumption/overall running time: 3443.2386s / 169526.0446 s
env0_first_0:                 episode reward: -33.6000,                 loss: 0.0074
env0_second_0:                 episode reward: 33.6000,                 loss: 0.0036
env1_first_0:                 episode reward: -31.5500,                 loss: nan
env1_second_0:                 episode reward: 31.5500,                 loss: nan
Score delta: 51.8, update the opponent.
Episode: 2341/10000 (23.4100%),                 avg. length: 5478.25,                last time consumption/overall running time: 2903.8194s / 172429.8641 s
env0_first_0:                 episode reward: 7.3500,                 loss: 0.0038
env0_second_0:                 episode reward: -7.3500,                 loss: nan
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 3730.45,                last time consumption/overall running time: 1978.9223s / 174408.7864 s
env0_first_0:                 episode reward: 14.8500,                 loss: 0.0025
env0_second_0:                 episode reward: -14.8500,                 loss: nan
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 3422.05,                last time consumption/overall running time: 1815.2315s / 176224.0179 s
env0_first_0:                 episode reward: 15.8000,                 loss: 0.0025
env0_second_0:                 episode reward: -15.8000,                 loss: nan
env1_first_0:                 episode reward: 15.6000,                 loss: nan
env1_second_0:                 episode reward: -15.6000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 3305.4,                last time consumption/overall running time: 1752.8183s / 177976.8362 s
env0_first_0:                 episode reward: 13.6000,                 loss: 0.0028
env0_second_0:                 episode reward: -13.6000,                 loss: nan
env1_first_0:                 episode reward: 15.9000,                 loss: nan
env1_second_0:                 episode reward: -15.9000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 3036.3,                last time consumption/overall running time: 1609.1222s / 179585.9584 s
env0_first_0:                 episode reward: 17.1500,                 loss: 0.0024
env0_second_0:                 episode reward: -17.1500,                 loss: nan
env1_first_0:                 episode reward: 18.8000,                 loss: nan
env1_second_0:                 episode reward: -18.8000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2858.3,                last time consumption/overall running time: 1514.9183s / 181100.8767 s
env0_first_0:                 episode reward: 17.6500,                 loss: 0.0024
env0_second_0:                 episode reward: -17.6500,                 loss: nan
env1_first_0:                 episode reward: 16.9500,                 loss: nan
env1_second_0:                 episode reward: -16.9500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2706.5,                last time consumption/overall running time: 1434.9126s / 182535.7893 s
env0_first_0:                 episode reward: 17.8000,                 loss: 0.0021
env0_second_0:                 episode reward: -17.8000,                 loss: nan
env1_first_0:                 episode reward: 19.1000,                 loss: nan
env1_second_0:                 episode reward: -19.1000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2480.9,                last time consumption/overall running time: 1314.4438s / 183850.2331 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0023
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 19.4000,                 loss: nan
env1_second_0:                 episode reward: -19.4000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2537.95,                last time consumption/overall running time: 1345.4400s / 185195.6731 s
env0_first_0:                 episode reward: 18.8500,                 loss: 0.0024
env0_second_0:                 episode reward: -18.8500,                 loss: nan
env1_first_0:                 episode reward: 17.8500,                 loss: nan
env1_second_0:                 episode reward: -17.8500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2198.45,                last time consumption/overall running time: 1165.9023s / 186361.5754 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0026
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2262.7,                last time consumption/overall running time: 1198.4263s / 187560.0017 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0024
env0_second_0:                 episode reward: -20.6500,                 loss: nan
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2172.85,                last time consumption/overall running time: 1151.0682s / 188711.0699 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0024
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2174.6,                last time consumption/overall running time: 1152.1417s / 189863.2116 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0023
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 23.3000,                 loss: nan
env1_second_0:                 episode reward: -23.3000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2202.15,                last time consumption/overall running time: 1166.1357s / 191029.3473 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2096.4,                last time consumption/overall running time: 1109.7932s / 192139.1404 s
env0_first_0:                 episode reward: 21.5500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.5500,                 loss: nan
env1_first_0:                 episode reward: 22.6000,                 loss: nan
env1_second_0:                 episode reward: -22.6000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1979.05,                last time consumption/overall running time: 1046.5915s / 193185.7320 s
env0_first_0:                 episode reward: 23.0500,                 loss: 0.0028
env0_second_0:                 episode reward: -23.0500,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2102.2,                last time consumption/overall running time: 1111.6265s / 194297.3585 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0026
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2270.25,                last time consumption/overall running time: 1200.8475s / 195498.2059 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0026
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 23.4000,                 loss: nan
env1_second_0:                 episode reward: -23.4000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 5385.8,                last time consumption/overall running time: 2846.0105s / 198344.2164 s
env0_first_0:                 episode reward: -45.7000,                 loss: 0.0021
env0_second_0:                 episode reward: 45.7000,                 loss: 0.0090
env1_first_0:                 episode reward: -42.8000,                 loss: nan
env1_second_0:                 episode reward: 42.8000,                 loss: nan
Score delta: 50.2, update the opponent.
Episode: 2721/10000 (27.2100%),                 avg. length: 4631.0,                last time consumption/overall running time: 2443.1935s / 200787.4099 s
env0_first_0:                 episode reward: -62.2500,                 loss: 0.0067
env0_second_0:                 episode reward: 62.2500,                 loss: 0.0089
env1_first_0:                 episode reward: -65.8500,                 loss: nan
env1_second_0:                 episode reward: 65.8500,                 loss: nan
Score delta: 250.6, update the opponent.
Episode: 2741/10000 (27.4100%),                 avg. length: 4229.2,                last time consumption/overall running time: 2229.8489s / 203017.2588 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0068
env0_second_0:                 episode reward: 18.9500,                 loss: nan
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 3143.75,                last time consumption/overall running time: 1658.3837s / 204675.6425 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0059
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2276.15,                last time consumption/overall running time: 1200.9769s / 205876.6194 s
env0_first_0:                 episode reward: 12.7000,                 loss: 0.0049
env0_second_0:                 episode reward: -12.7000,                 loss: nan
env1_first_0:                 episode reward: 14.4000,                 loss: nan
env1_second_0:                 episode reward: -14.4000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2508.8,                last time consumption/overall running time: 1323.7028s / 207200.3222 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0045
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1944.3,                last time consumption/overall running time: 1026.0800s / 208226.4022 s
env0_first_0:                 episode reward: 18.5500,                 loss: 0.0043
env0_second_0:                 episode reward: -18.5500,                 loss: nan
env1_first_0:                 episode reward: 17.0000,                 loss: nan
env1_second_0:                 episode reward: -17.0000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1841.65,                last time consumption/overall running time: 972.0491s / 209198.4513 s
env0_first_0:                 episode reward: 19.3000,                 loss: 0.0032
env0_second_0:                 episode reward: -19.3000,                 loss: nan
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1809.0,                last time consumption/overall running time: 954.9206s / 210153.3720 s
env0_first_0:                 episode reward: 19.7500,                 loss: 0.0030
env0_second_0:                 episode reward: -19.7500,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1766.55,                last time consumption/overall running time: 932.2556s / 211085.6276 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0028
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 20.1000,                 loss: nan
env1_second_0:                 episode reward: -20.1000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1923.75,                last time consumption/overall running time: 1015.6762s / 212101.3038 s
env0_first_0:                 episode reward: 17.3500,                 loss: 0.0034
env0_second_0:                 episode reward: -17.3500,                 loss: nan
env1_first_0:                 episode reward: 16.5000,                 loss: nan
env1_second_0:                 episode reward: -16.5000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1825.8,                last time consumption/overall running time: 963.9501s / 213065.2539 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0035
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1892.35,                last time consumption/overall running time: 999.1126s / 214064.3665 s
env0_first_0:                 episode reward: 19.3500,                 loss: 0.0032
env0_second_0:                 episode reward: -19.3500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1801.6,                last time consumption/overall running time: 950.7644s / 215015.1310 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0031
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1705.8,                last time consumption/overall running time: 899.9369s / 215915.0679 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0029
env0_second_0:                 episode reward: -20.7500,                 loss: nan
env1_first_0:                 episode reward: 22.1500,                 loss: nan
env1_second_0:                 episode reward: -22.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1713.3,                last time consumption/overall running time: 903.6785s / 216818.7464 s
env0_first_0:                 episode reward: 21.4500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.4500,                 loss: nan
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1766.2,                last time consumption/overall running time: 931.0787s / 217749.8251 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 20.2500,                 loss: nan
env1_second_0:                 episode reward: -20.2500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1812.65,                last time consumption/overall running time: 956.0140s / 218705.8391 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0032
env0_second_0:                 episode reward: -20.6000,                 loss: nan
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1606.4,                last time consumption/overall running time: 846.9011s / 219552.7401 s
env0_first_0:                 episode reward: 22.6500,                 loss: 0.0028
env0_second_0:                 episode reward: -22.6500,                 loss: nan
env1_first_0:                 episode reward: 22.8000,                 loss: nan
env1_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1605.1,                last time consumption/overall running time: 845.9294s / 220398.6696 s
env0_first_0:                 episode reward: 23.2500,                 loss: 0.0021
env0_second_0:                 episode reward: -23.2500,                 loss: nan
env1_first_0:                 episode reward: 22.6000,                 loss: nan
env1_second_0:                 episode reward: -22.6000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1626.5,                last time consumption/overall running time: 857.3899s / 221256.0595 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0023
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1631.15,                last time consumption/overall running time: 860.3224s / 222116.3819 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 22.8000,                 loss: nan
env1_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1790.1,                last time consumption/overall running time: 943.2637s / 223059.6456 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0030
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1651.75,                last time consumption/overall running time: 870.9208s / 223930.5664 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.0029
env0_second_0:                 episode reward: -20.0500,                 loss: nan
env1_first_0:                 episode reward: 22.6000,                 loss: nan
env1_second_0:                 episode reward: -22.6000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1637.65,                last time consumption/overall running time: 863.2051s / 224793.7715 s
env0_first_0:                 episode reward: 22.5500,                 loss: 0.0026
env0_second_0:                 episode reward: -22.5500,                 loss: nan
env1_first_0:                 episode reward: 22.5000,                 loss: nan
env1_second_0:                 episode reward: -22.5000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1593.45,                last time consumption/overall running time: 839.6749s / 225633.4463 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0027
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1623.6,                last time consumption/overall running time: 855.5082s / 226488.9546 s
env0_first_0:                 episode reward: 19.8500,                 loss: 0.0028
env0_second_0:                 episode reward: -19.8500,                 loss: nan
env1_first_0:                 episode reward: 23.0500,                 loss: nan
env1_second_0:                 episode reward: -23.0500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1624.7,                last time consumption/overall running time: 855.9546s / 227344.9092 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0025
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1622.6,                last time consumption/overall running time: 855.0254s / 228199.9346 s
env0_first_0:                 episode reward: 23.1000,                 loss: 0.0025
env0_second_0:                 episode reward: -23.1000,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1488.75,                last time consumption/overall running time: 783.9968s / 228983.9314 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0023
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 24.7500,                 loss: nan
env1_second_0:                 episode reward: -24.7500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1592.25,                last time consumption/overall running time: 838.6874s / 229822.6188 s
env0_first_0:                 episode reward: 23.1000,                 loss: 0.0020
env0_second_0:                 episode reward: -23.1000,                 loss: nan
env1_first_0:                 episode reward: 23.2000,                 loss: nan
env1_second_0:                 episode reward: -23.2000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1573.55,                last time consumption/overall running time: 828.0751s / 230650.6939 s
env0_first_0:                 episode reward: 24.0500,                 loss: 0.0023
env0_second_0:                 episode reward: -24.0500,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1595.05,                last time consumption/overall running time: 840.3822s / 231491.0761 s
env0_first_0:                 episode reward: 22.2500,                 loss: 0.0021
env0_second_0:                 episode reward: -22.2500,                 loss: nan
env1_first_0:                 episode reward: 24.4000,                 loss: nan
env1_second_0:                 episode reward: -24.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1642.3,                last time consumption/overall running time: 864.4443s / 232355.5204 s
env0_first_0:                 episode reward: 23.0500,                 loss: 0.0025
env0_second_0:                 episode reward: -23.0500,                 loss: nan
env1_first_0:                 episode reward: 22.3000,                 loss: nan
env1_second_0:                 episode reward: -22.3000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1604.75,                last time consumption/overall running time: 844.3898s / 233199.9102 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0026
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1556.6,                last time consumption/overall running time: 819.3462s / 234019.2564 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0025
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1515.55,                last time consumption/overall running time: 798.3517s / 234817.6081 s
env0_first_0:                 episode reward: 22.8000,                 loss: 0.0023
env0_second_0:                 episode reward: -22.8000,                 loss: nan
env1_first_0:                 episode reward: 22.9500,                 loss: nan
env1_second_0:                 episode reward: -22.9500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1579.0,                last time consumption/overall running time: 831.4301s / 235649.0382 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0024
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 23.4000,                 loss: nan
env1_second_0:                 episode reward: -23.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1563.95,                last time consumption/overall running time: 823.4990s / 236472.5372 s
env0_first_0:                 episode reward: 23.5000,                 loss: 0.0024
env0_second_0:                 episode reward: -23.5000,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1570.1,                last time consumption/overall running time: 826.3025s / 237298.8397 s
env0_first_0:                 episode reward: 24.1500,                 loss: 0.0022
env0_second_0:                 episode reward: -24.1500,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1588.6,                last time consumption/overall running time: 835.9654s / 238134.8051 s
env0_first_0:                 episode reward: 22.2500,                 loss: 0.0023
env0_second_0:                 episode reward: -22.2500,                 loss: nan
env1_first_0:                 episode reward: 23.5000,                 loss: nan
env1_second_0:                 episode reward: -23.5000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1568.1,                last time consumption/overall running time: 825.3581s / 238960.1633 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0024
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.4500,                 loss: nan
env1_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1504.95,                last time consumption/overall running time: 792.8901s / 239753.0533 s
env0_first_0:                 episode reward: 24.0500,                 loss: 0.0022
env0_second_0:                 episode reward: -24.0500,                 loss: nan
env1_first_0:                 episode reward: 24.0000,                 loss: nan
env1_second_0:                 episode reward: -24.0000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1571.75,                last time consumption/overall running time: 827.6403s / 240580.6936 s
env0_first_0:                 episode reward: 23.2500,                 loss: 0.0022
env0_second_0:                 episode reward: -23.2500,                 loss: nan
env1_first_0:                 episode reward: 22.4500,                 loss: nan
env1_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1461.6,                last time consumption/overall running time: 769.6258s / 241350.3195 s
env0_first_0:                 episode reward: 23.5000,                 loss: 0.0020
env0_second_0:                 episode reward: -23.5000,                 loss: nan
env1_first_0:                 episode reward: 24.4500,                 loss: nan
env1_second_0:                 episode reward: -24.4500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1544.6,                last time consumption/overall running time: 813.3229s / 242163.6424 s
env0_first_0:                 episode reward: 23.8500,                 loss: 0.0017
env0_second_0:                 episode reward: -23.8500,                 loss: nan
env1_first_0:                 episode reward: 23.0000,                 loss: nan
env1_second_0:                 episode reward: -23.0000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1796.3,                last time consumption/overall running time: 946.0362s / 243109.6785 s
env0_first_0:                 episode reward: 17.6500,                 loss: 0.0022
env0_second_0:                 episode reward: -17.6500,                 loss: nan
env1_first_0:                 episode reward: 16.2000,                 loss: nan
env1_second_0:                 episode reward: -16.2000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1525.7,                last time consumption/overall running time: 803.3822s / 243913.0608 s
env0_first_0:                 episode reward: 23.2500,                 loss: 0.0032
env0_second_0:                 episode reward: -23.2500,                 loss: nan
env1_first_0:                 episode reward: 23.4000,                 loss: nan
env1_second_0:                 episode reward: -23.4000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1545.0,                last time consumption/overall running time: 813.0414s / 244726.1022 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0027
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 23.9500,                 loss: nan
env1_second_0:                 episode reward: -23.9500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1576.1,                last time consumption/overall running time: 829.8466s / 245555.9488 s
env0_first_0:                 episode reward: 23.2000,                 loss: 0.0023
env0_second_0:                 episode reward: -23.2000,                 loss: nan
env1_first_0:                 episode reward: 23.0000,                 loss: nan
env1_second_0:                 episode reward: -23.0000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1562.15,                last time consumption/overall running time: 822.8868s / 246378.8356 s
env0_first_0:                 episode reward: 24.0500,                 loss: 0.0025
env0_second_0:                 episode reward: -24.0500,                 loss: nan
env1_first_0:                 episode reward: 22.4500,                 loss: nan
env1_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1589.5,                last time consumption/overall running time: 837.2385s / 247216.0741 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0024
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 23.3500,                 loss: nan
env1_second_0:                 episode reward: -23.3500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1561.6,                last time consumption/overall running time: 822.0187s / 248038.0928 s
env0_first_0:                 episode reward: 23.1500,                 loss: 0.0022
env0_second_0:                 episode reward: -23.1500,                 loss: nan
env1_first_0:                 episode reward: 23.1000,                 loss: nan
env1_second_0:                 episode reward: -23.1000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1570.55,                last time consumption/overall running time: 827.2784s / 248865.3712 s
env0_first_0:                 episode reward: 23.4000,                 loss: 0.0020
env0_second_0:                 episode reward: -23.4000,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1543.9,                last time consumption/overall running time: 812.5959s / 249677.9670 s
env0_first_0:                 episode reward: 23.5000,                 loss: 0.0022
env0_second_0:                 episode reward: -23.5000,                 loss: nan
env1_first_0:                 episode reward: 23.1000,                 loss: nan
env1_second_0:                 episode reward: -23.1000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1643.75,                last time consumption/overall running time: 865.5007s / 250543.4677 s
env0_first_0:                 episode reward: 23.6000,                 loss: 0.0024
env0_second_0:                 episode reward: -23.6000,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1654.4,                last time consumption/overall running time: 871.2872s / 251414.7549 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0026
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 23.6500,                 loss: nan
env1_second_0:                 episode reward: -23.6500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1579.35,                last time consumption/overall running time: 831.4085s / 252246.1634 s
env0_first_0:                 episode reward: 23.6000,                 loss: 0.0023
env0_second_0:                 episode reward: -23.6000,                 loss: nan
env1_first_0:                 episode reward: 23.5500,                 loss: nan
env1_second_0:                 episode reward: -23.5500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1456.1,                last time consumption/overall running time: 766.4174s / 253012.5808 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0019
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 24.1500,                 loss: nan
env1_second_0:                 episode reward: -24.1500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1552.3,                last time consumption/overall running time: 816.9455s / 253829.5263 s
env0_first_0:                 episode reward: 23.0500,                 loss: 0.0020
env0_second_0:                 episode reward: -23.0500,                 loss: nan
env1_first_0:                 episode reward: 22.8000,                 loss: nan
env1_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1563.6,                last time consumption/overall running time: 822.7101s / 254652.2364 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0022
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 22.2500,                 loss: nan
env1_second_0:                 episode reward: -22.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1633.25,                last time consumption/overall running time: 859.2358s / 255511.4722 s
env0_first_0:                 episode reward: 21.8500,                 loss: 0.0026
env0_second_0:                 episode reward: -21.8500,                 loss: nan
env1_first_0:                 episode reward: 22.9000,                 loss: nan
env1_second_0:                 episode reward: -22.9000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1557.15,                last time consumption/overall running time: 819.0611s / 256330.5333 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0023
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 23.1500,                 loss: nan
env1_second_0:                 episode reward: -23.1500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1484.75,                last time consumption/overall running time: 781.0621s / 257111.5954 s
env0_first_0:                 episode reward: 24.2500,                 loss: 0.0020
env0_second_0:                 episode reward: -24.2500,                 loss: nan
env1_first_0:                 episode reward: 23.1000,                 loss: nan
env1_second_0:                 episode reward: -23.1000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1839.15,                last time consumption/overall running time: 967.1764s / 258078.7718 s
env0_first_0:                 episode reward: 16.8000,                 loss: 0.0018
env0_second_0:                 episode reward: -16.8000,                 loss: nan
env1_first_0:                 episode reward: 17.6500,                 loss: nan
env1_second_0:                 episode reward: -17.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1587.75,                last time consumption/overall running time: 834.5482s / 258913.3200 s
env0_first_0:                 episode reward: 23.4000,                 loss: 0.0032
env0_second_0:                 episode reward: -23.4000,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1662.5,                last time consumption/overall running time: 873.5876s / 259786.9076 s
env0_first_0:                 episode reward: 23.4500,                 loss: 0.0028
env0_second_0:                 episode reward: -23.4500,                 loss: nan
env1_first_0:                 episode reward: 23.0000,                 loss: nan
env1_second_0:                 episode reward: -23.0000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2299.1,                last time consumption/overall running time: 1207.7179s / 260994.6256 s
env0_first_0:                 episode reward: 29.0000,                 loss: 0.0022
env0_second_0:                 episode reward: -29.0000,                 loss: 0.0135
env1_first_0:                 episode reward: 28.8000,                 loss: nan
env1_second_0:                 episode reward: -28.8000,                 loss: nan
Score delta: 50.2, update the opponent.
Episode: 4061/10000 (40.6100%),                 avg. length: 2992.5,                last time consumption/overall running time: 1571.7663s / 262566.3918 s
env0_first_0:                 episode reward: -5.2000,                 loss: nan
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0062
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 2030.65,                last time consumption/overall running time: 1066.7652s / 263633.1570 s
env0_first_0:                 episode reward: -20.1000,                 loss: nan
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0034
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1827.55,                last time consumption/overall running time: 960.3890s / 264593.5461 s
env0_first_0:                 episode reward: -21.3000,                 loss: nan
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1754.55,                last time consumption/overall running time: 921.7832s / 265515.3292 s
env0_first_0:                 episode reward: -21.3000,                 loss: nan
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1739.55,                last time consumption/overall running time: 914.6405s / 266429.9697 s
env0_first_0:                 episode reward: -22.8000,                 loss: nan
env0_second_0:                 episode reward: 22.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1666.5,                last time consumption/overall running time: 876.1161s / 267306.0858 s
env0_first_0:                 episode reward: -22.6000,                 loss: nan
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1617.1,                last time consumption/overall running time: 849.8354s / 268155.9212 s
env0_first_0:                 episode reward: -23.1000,                 loss: nan
env0_second_0:                 episode reward: 23.1000,                 loss: 0.0027
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1658.15,                last time consumption/overall running time: 871.3753s / 269027.2965 s
env0_first_0:                 episode reward: -21.6000,                 loss: nan
env0_second_0:                 episode reward: 21.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1672.55,                last time consumption/overall running time: 879.2831s / 269906.5796 s
env0_first_0:                 episode reward: -22.5000,                 loss: nan
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0030
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2242.8,                last time consumption/overall running time: 1178.3221s / 271084.9017 s
env0_first_0:                 episode reward: -29.2000,                 loss: 0.0084
env0_second_0:                 episode reward: 29.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -27.3000,                 loss: nan
env1_second_0:                 episode reward: 27.3000,                 loss: nan
Score delta: 50.4, update the opponent.
Episode: 4261/10000 (42.6100%),                 avg. length: 4351.45,                last time consumption/overall running time: 2284.1661s / 273369.0678 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0084
env0_second_0:                 episode reward: 6.2000,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2509.4,                last time consumption/overall running time: 1317.6584s / 274686.7263 s
env0_first_0:                 episode reward: 19.8500,                 loss: 0.0050
env0_second_0:                 episode reward: -19.8500,                 loss: nan
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2225.75,                last time consumption/overall running time: 1169.4696s / 275856.1958 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0036
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2061.95,                last time consumption/overall running time: 1083.2695s / 276939.4653 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0029
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.4500,                 loss: nan
env1_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2416.05,                last time consumption/overall running time: 1268.7737s / 278208.2390 s
env0_first_0:                 episode reward: 30.2000,                 loss: 0.0031
env0_second_0:                 episode reward: -30.2000,                 loss: nan
env1_first_0:                 episode reward: 29.1000,                 loss: nan
env1_second_0:                 episode reward: -29.1000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 3399.95,                last time consumption/overall running time: 1784.0658s / 279992.3048 s
env0_first_0:                 episode reward: 30.7000,                 loss: 0.0042
env0_second_0:                 episode reward: -30.7000,                 loss: 0.0079
env1_first_0:                 episode reward: 28.1000,                 loss: nan
env1_second_0:                 episode reward: -28.1000,                 loss: nan
Score delta: 78.0, update the opponent.
Episode: 4381/10000 (43.8100%),                 avg. length: 4378.4,                last time consumption/overall running time: 2296.7827s / 282289.0875 s
env0_first_0:                 episode reward: 3.5000,                 loss: nan
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0050
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 3075.75,                last time consumption/overall running time: 1613.7337s / 283902.8212 s
env0_first_0:                 episode reward: -10.2000,                 loss: nan
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0047
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2224.4,                last time consumption/overall running time: 1168.2241s / 285071.0454 s
env0_first_0:                 episode reward: -17.8000,                 loss: nan
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0037
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2592.05,                last time consumption/overall running time: 1360.6206s / 286431.6659 s
env0_first_0:                 episode reward: -13.9500,                 loss: nan
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0036
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2344.2,                last time consumption/overall running time: 1230.2882s / 287661.9542 s
env0_first_0:                 episode reward: -18.2500,                 loss: nan
env0_second_0:                 episode reward: 18.2500,                 loss: 0.0033
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2460.85,                last time consumption/overall running time: 1291.5051s / 288953.4592 s
env0_first_0:                 episode reward: -11.5500,                 loss: nan
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0040
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2085.35,                last time consumption/overall running time: 1054.8445s / 290008.3037 s
env0_first_0:                 episode reward: -19.1500,                 loss: nan
env0_second_0:                 episode reward: 19.1500,                 loss: 0.0031
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2126.7,                last time consumption/overall running time: 1060.6701s / 291068.9738 s
env0_first_0:                 episode reward: -18.8000,                 loss: nan
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 2010.25,                last time consumption/overall running time: 1002.4852s / 292071.4590 s
env0_first_0:                 episode reward: -18.5500,                 loss: nan
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1932.55,                last time consumption/overall running time: 963.5703s / 293035.0293 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0025
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1923.5,                last time consumption/overall running time: 958.3065s / 293993.3358 s
env0_first_0:                 episode reward: -19.2500,                 loss: nan
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0022
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2249.1,                last time consumption/overall running time: 1120.6685s / 295114.0043 s
env0_first_0:                 episode reward: -20.4000,                 loss: nan
env0_second_0:                 episode reward: 20.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1884.95,                last time consumption/overall running time: 939.4661s / 296053.4704 s
env0_first_0:                 episode reward: -20.8500,                 loss: nan
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0026
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1792.4,                last time consumption/overall running time: 893.4419s / 296946.9123 s
env0_first_0:                 episode reward: -21.0500,                 loss: nan
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0023
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1898.25,                last time consumption/overall running time: 945.5416s / 297892.4540 s
env0_first_0:                 episode reward: -19.9500,                 loss: nan
env0_second_0:                 episode reward: 19.9500,                 loss: 0.0021
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1830.35,                last time consumption/overall running time: 868.0329s / 298760.4869 s
env0_first_0:                 episode reward: -20.1500,                 loss: nan
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0020
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1774.2,                last time consumption/overall running time: 836.4064s / 299596.8933 s
env0_first_0:                 episode reward: -22.0000,                 loss: nan
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0020
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1764.15,                last time consumption/overall running time: 831.8029s / 300428.6962 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0018
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1787.2,                last time consumption/overall running time: 842.5089s / 301271.2050 s
env0_first_0:                 episode reward: -20.3000,                 loss: nan
env0_second_0:                 episode reward: 20.3000,                 loss: 0.0019
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1740.8,                last time consumption/overall running time: 820.8046s / 302092.0096 s
env0_first_0:                 episode reward: -20.5000,                 loss: nan
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0020
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1949.9,                last time consumption/overall running time: 920.1121s / 303012.1217 s
env0_first_0:                 episode reward: -19.7000,                 loss: nan
env0_second_0:                 episode reward: 19.7000,                 loss: 0.0019
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1825.45,                last time consumption/overall running time: 860.2326s / 303872.3543 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0024
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1763.75,                last time consumption/overall running time: 831.3543s / 304703.7086 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0021
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1882.65,                last time consumption/overall running time: 887.8237s / 305591.5323 s
env0_first_0:                 episode reward: -20.4000,                 loss: nan
env0_second_0:                 episode reward: 20.4000,                 loss: 0.0020
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1828.2,                last time consumption/overall running time: 861.9220s / 306453.4543 s
env0_first_0:                 episode reward: -20.5500,                 loss: nan
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0020
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1997.95,                last time consumption/overall running time: 941.7775s / 307395.2318 s
env0_first_0:                 episode reward: -17.0000,                 loss: nan
env0_second_0:                 episode reward: 17.0000,                 loss: 0.0026
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1884.1,                last time consumption/overall running time: 886.9830s / 308282.2149 s
env0_first_0:                 episode reward: -20.7500,                 loss: nan
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1785.0,                last time consumption/overall running time: 840.0719s / 309122.2868 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0021
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1696.55,                last time consumption/overall running time: 793.0671s / 309915.3539 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0017
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1781.15,                last time consumption/overall running time: 792.6385s / 310707.9924 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1920.85,                last time consumption/overall running time: 853.8670s / 311561.8593 s
env0_first_0:                 episode reward: -21.0500,                 loss: nan
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0018
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1771.0,                last time consumption/overall running time: 787.0162s / 312348.8755 s
env0_first_0:                 episode reward: -20.4500,                 loss: nan
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0017
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1746.25,                last time consumption/overall running time: 776.7596s / 313125.6351 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1676.65,                last time consumption/overall running time: 745.6826s / 313871.3178 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1740.55,                last time consumption/overall running time: 773.3504s / 314644.6682 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0016
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2130.85,                last time consumption/overall running time: 947.2361s / 315591.9043 s
env0_first_0:                 episode reward: -14.7000,                 loss: nan
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0029
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1819.75,                last time consumption/overall running time: 790.8697s / 316382.7741 s
env0_first_0:                 episode reward: -21.4000,                 loss: nan
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0021
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1754.45,                last time consumption/overall running time: 736.1893s / 317118.9633 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1953.8,                last time consumption/overall running time: 779.6763s / 317898.6396 s
env0_first_0:                 episode reward: -19.1000,                 loss: nan
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0016
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1723.15,                last time consumption/overall running time: 677.2197s / 318575.8593 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1698.2,                last time consumption/overall running time: 668.2170s / 319244.0763 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0017
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1754.75,                last time consumption/overall running time: 689.8125s / 319933.8888 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1797.3,                last time consumption/overall running time: 707.4013s / 320641.2901 s
env0_first_0:                 episode reward: -21.4500,                 loss: nan
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1745.4,                last time consumption/overall running time: 686.2583s / 321327.5484 s
env0_first_0:                 episode reward: -19.3000,                 loss: nan
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0016
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1731.4,                last time consumption/overall running time: 680.4850s / 322008.0334 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0017
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1931.05,                last time consumption/overall running time: 758.5669s / 322766.6003 s
env0_first_0:                 episode reward: -17.6500,                 loss: nan
env0_second_0:                 episode reward: 17.6500,                 loss: 0.0021
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1938.8,                last time consumption/overall running time: 761.6269s / 323528.2272 s
env0_first_0:                 episode reward: -17.0000,                 loss: nan
env0_second_0:                 episode reward: 17.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1855.35,                last time consumption/overall running time: 728.7847s / 324257.0119 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0024
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1775.65,                last time consumption/overall running time: 697.3795s / 324954.3913 s
env0_first_0:                 episode reward: -20.1000,                 loss: nan
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0018
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1701.55,                last time consumption/overall running time: 668.0566s / 325622.4480 s
env0_first_0:                 episode reward: -20.9500,                 loss: nan
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0017
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1709.4,                last time consumption/overall running time: 671.1003s / 326293.5483 s
env0_first_0:                 episode reward: -20.2500,                 loss: nan
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1701.25,                last time consumption/overall running time: 668.3275s / 326961.8758 s
env0_first_0:                 episode reward: -20.1500,                 loss: nan
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1735.05,                last time consumption/overall running time: 681.3950s / 327643.2708 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1649.35,                last time consumption/overall running time: 648.2768s / 328291.5475 s
env0_first_0:                 episode reward: -21.9500,                 loss: nan
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1642.15,                last time consumption/overall running time: 645.4541s / 328937.0017 s
env0_first_0:                 episode reward: -23.1500,                 loss: nan
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0012
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1624.0,                last time consumption/overall running time: 637.7274s / 329574.7291 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0010
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1699.95,                last time consumption/overall running time: 668.2349s / 330242.9640 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1687.75,                last time consumption/overall running time: 662.9823s / 330905.9463 s
env0_first_0:                 episode reward: -20.1500,                 loss: nan
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0014
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1659.9,                last time consumption/overall running time: 651.0582s / 331557.0045 s
env0_first_0:                 episode reward: -21.7000,                 loss: nan
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0016
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1838.05,                last time consumption/overall running time: 722.5820s / 332279.5864 s
env0_first_0:                 episode reward: -18.8000,                 loss: nan
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0016
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1736.4,                last time consumption/overall running time: 682.4737s / 332962.0601 s
env0_first_0:                 episode reward: -19.2000,                 loss: nan
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1709.7,                last time consumption/overall running time: 670.6277s / 333632.6878 s
env0_first_0:                 episode reward: -22.2000,                 loss: nan
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0018
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1736.1,                last time consumption/overall running time: 640.9357s / 334273.6234 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1699.6,                last time consumption/overall running time: 625.5410s / 334899.1644 s
env0_first_0:                 episode reward: -21.3500,                 loss: nan
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0016
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1868.25,                last time consumption/overall running time: 687.8772s / 335587.0416 s
env0_first_0:                 episode reward: -17.5500,                 loss: nan
env0_second_0:                 episode reward: 17.5500,                 loss: 0.0018
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1917.2,                last time consumption/overall running time: 704.6682s / 336291.7099 s
env0_first_0:                 episode reward: -19.3000,                 loss: nan
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1843.3,                last time consumption/overall running time: 678.8150s / 336970.5249 s
env0_first_0:                 episode reward: -17.8000,                 loss: nan
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1698.5,                last time consumption/overall running time: 624.6310s / 337595.1558 s
env0_first_0:                 episode reward: -20.5500,                 loss: nan
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0022
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1714.1,                last time consumption/overall running time: 630.2846s / 338225.4405 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1694.35,                last time consumption/overall running time: 622.2276s / 338847.6681 s
env0_first_0:                 episode reward: -22.4000,                 loss: nan
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0016
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1698.8,                last time consumption/overall running time: 624.9367s / 339472.6047 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1874.1,                last time consumption/overall running time: 688.6214s / 340161.2262 s
env0_first_0:                 episode reward: -18.7500,                 loss: nan
env0_second_0:                 episode reward: 18.7500,                 loss: 0.0020
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1775.1,                last time consumption/overall running time: 651.3680s / 340812.5942 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0018
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1796.0,                last time consumption/overall running time: 661.4537s / 341474.0479 s
env0_first_0:                 episode reward: -18.5000,                 loss: nan
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0021
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1741.25,                last time consumption/overall running time: 639.7881s / 342113.8360 s
env0_first_0:                 episode reward: -20.9500,                 loss: nan
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0020
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 2716.5,                last time consumption/overall running time: 999.4084s / 343113.2443 s
env0_first_0:                 episode reward: -0.9500,                 loss: nan
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0036
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1691.0,                last time consumption/overall running time: 622.1994s / 343735.4437 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0038
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1678.15,                last time consumption/overall running time: 615.2885s / 344350.7322 s
env0_first_0:                 episode reward: -22.2000,                 loss: nan
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0015
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1931.95,                last time consumption/overall running time: 677.4679s / 345028.2001 s
env0_first_0:                 episode reward: -14.5000,                 loss: nan
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0017
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1662.25,                last time consumption/overall running time: 559.1480s / 345587.3481 s
env0_first_0:                 episode reward: -22.6000,                 loss: nan
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1570.6,                last time consumption/overall running time: 529.6866s / 346117.0348 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1605.6,                last time consumption/overall running time: 538.9272s / 346655.9620 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1571.45,                last time consumption/overall running time: 528.8538s / 347184.8158 s
env0_first_0:                 episode reward: -22.6500,                 loss: nan
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1617.0,                last time consumption/overall running time: 543.0152s / 347727.8310 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0011
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1526.35,                last time consumption/overall running time: 513.2120s / 348241.0430 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1617.75,                last time consumption/overall running time: 544.0332s / 348785.0762 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1640.45,                last time consumption/overall running time: 552.4356s / 349337.5119 s
env0_first_0:                 episode reward: -20.1500,                 loss: nan
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1729.9,                last time consumption/overall running time: 582.4143s / 349919.9262 s
env0_first_0:                 episode reward: -19.6000,                 loss: nan
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0018
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1667.25,                last time consumption/overall running time: 559.6209s / 350479.5471 s
env0_first_0:                 episode reward: -21.3000,                 loss: nan
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0017
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1663.75,                last time consumption/overall running time: 558.8528s / 351038.3999 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0015
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1588.3,                last time consumption/overall running time: 533.5459s / 351571.9457 s
env0_first_0:                 episode reward: -20.7500,                 loss: nan
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1649.55,                last time consumption/overall running time: 554.0689s / 352126.0147 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0014
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1797.35,                last time consumption/overall running time: 604.2657s / 352730.2803 s
env0_first_0:                 episode reward: -18.8500,                 loss: nan
env0_second_0:                 episode reward: 18.8500,                 loss: 0.0016
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1568.0,                last time consumption/overall running time: 527.3061s / 353257.5865 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0019
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1620.0,                last time consumption/overall running time: 544.5828s / 353802.1692 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0015
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1598.3,                last time consumption/overall running time: 537.2929s / 354339.4621 s
env0_first_0:                 episode reward: -20.6500,                 loss: nan
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1650.5,                last time consumption/overall running time: 554.8621s / 354894.3243 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1621.3,                last time consumption/overall running time: 545.0610s / 355439.3852 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0016
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1587.15,                last time consumption/overall running time: 533.4391s / 355972.8244 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1544.45,                last time consumption/overall running time: 518.8880s / 356491.7123 s
env0_first_0:                 episode reward: -21.7000,                 loss: nan
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0012
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1654.85,                last time consumption/overall running time: 555.5757s / 357047.2880 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1766.15,                last time consumption/overall running time: 593.8107s / 357641.0987 s
env0_first_0:                 episode reward: -19.1000,                 loss: nan
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0020
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1687.35,                last time consumption/overall running time: 566.4085s / 358207.5072 s
env0_first_0:                 episode reward: -21.3500,                 loss: nan
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0020
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1663.45,                last time consumption/overall running time: 558.8177s / 358766.3249 s
env0_first_0:                 episode reward: -20.2500,                 loss: nan
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1643.6,                last time consumption/overall running time: 552.6032s / 359318.9281 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0013
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1610.45,                last time consumption/overall running time: 541.1600s / 359860.0881 s
env0_first_0:                 episode reward: -20.6500,                 loss: nan
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1623.4,                last time consumption/overall running time: 545.3401s / 360405.4282 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0013
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1726.35,                last time consumption/overall running time: 579.6416s / 360985.0698 s
env0_first_0:                 episode reward: -20.8000,                 loss: nan
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0015
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 2118.25,                last time consumption/overall running time: 710.5568s / 361695.6266 s
env0_first_0:                 episode reward: -10.1500,                 loss: nan
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1702.75,                last time consumption/overall running time: 570.3951s / 362266.0216 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1719.7,                last time consumption/overall running time: 576.8077s / 362842.8294 s
env0_first_0:                 episode reward: -18.9000,                 loss: nan
env0_second_0:                 episode reward: 18.9000,                 loss: 0.0019
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1653.85,                last time consumption/overall running time: 556.3569s / 363399.1863 s
env0_first_0:                 episode reward: -20.0500,                 loss: nan
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0014
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1598.15,                last time consumption/overall running time: 536.1836s / 363935.3699 s
env0_first_0:                 episode reward: -21.3500,                 loss: nan
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1748.35,                last time consumption/overall running time: 586.7165s / 364522.0864 s
env0_first_0:                 episode reward: -19.2000,                 loss: nan
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0017
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1619.7,                last time consumption/overall running time: 544.1496s / 365066.2360 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0018
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1577.6,                last time consumption/overall running time: 528.5132s / 365594.7493 s
env0_first_0:                 episode reward: -22.6000,                 loss: nan
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0014
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1814.15,                last time consumption/overall running time: 608.5453s / 366203.2945 s
env0_first_0:                 episode reward: -16.3000,                 loss: nan
env0_second_0:                 episode reward: 16.3000,                 loss: 0.0014
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1567.35,                last time consumption/overall running time: 524.3369s / 366727.6314 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0023
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1553.65,                last time consumption/overall running time: 471.7563s / 367199.3878 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1625.25,                last time consumption/overall running time: 494.6604s / 367694.0482 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1670.8,                last time consumption/overall running time: 508.2722s / 368202.3203 s
env0_first_0:                 episode reward: -21.0000,                 loss: nan
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0016
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2059.1,                last time consumption/overall running time: 627.1582s / 368829.4786 s
env0_first_0:                 episode reward: -12.4500,                 loss: nan
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1755.35,                last time consumption/overall running time: 534.2094s / 369363.6880 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1654.0,                last time consumption/overall running time: 502.2014s / 369865.8894 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0019
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1640.75,                last time consumption/overall running time: 498.9101s / 370364.7995 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1656.05,                last time consumption/overall running time: 503.1636s / 370867.9631 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0014
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1626.0,                last time consumption/overall running time: 495.1205s / 371363.0836 s
env0_first_0:                 episode reward: -20.7500,                 loss: nan
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1631.95,                last time consumption/overall running time: 459.3499s / 371822.4335 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0015
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1789.55,                last time consumption/overall running time: 501.2010s / 372323.6345 s
env0_first_0:                 episode reward: -18.8500,                 loss: nan
env0_second_0:                 episode reward: 18.8500,                 loss: 0.0018
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1719.55,                last time consumption/overall running time: 481.5805s / 372805.2150 s
env0_first_0:                 episode reward: -21.4500,                 loss: nan
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0020
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1612.45,                last time consumption/overall running time: 451.0449s / 373256.2599 s
env0_first_0:                 episode reward: -22.6000,                 loss: nan
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0016
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1684.05,                last time consumption/overall running time: 472.0189s / 373728.2788 s
env0_first_0:                 episode reward: -19.5000,                 loss: nan
env0_second_0:                 episode reward: 19.5000,                 loss: 0.0014
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1654.9,                last time consumption/overall running time: 430.8251s / 374159.1038 s
env0_first_0:                 episode reward: -20.2500,                 loss: nan
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1667.5,                last time consumption/overall running time: 414.3232s / 374573.4271 s
env0_first_0:                 episode reward: -19.2000,                 loss: nan
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0018
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1631.95,                last time consumption/overall running time: 405.4767s / 374978.9038 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1527.25,                last time consumption/overall running time: 380.2320s / 375359.1357 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1626.5,                last time consumption/overall running time: 401.3434s / 375760.4791 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0010
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1612.8,                last time consumption/overall running time: 399.0423s / 376159.5215 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1608.25,                last time consumption/overall running time: 397.3699s / 376556.8914 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1604.8,                last time consumption/overall running time: 397.5237s / 376954.4150 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0014
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1542.8,                last time consumption/overall running time: 382.8815s / 377337.2966 s
env0_first_0:                 episode reward: -22.7500,                 loss: nan
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.8000,                 loss: nan
env1_second_0:                 episode reward: 22.8000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1645.0,                last time consumption/overall running time: 406.8832s / 377744.1797 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0012
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1623.35,                last time consumption/overall running time: 405.9697s / 378150.1494 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0015
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1647.6,                last time consumption/overall running time: 408.6466s / 378558.7961 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0014
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1775.1,                last time consumption/overall running time: 438.0805s / 378996.8766 s
env0_first_0:                 episode reward: -18.0500,                 loss: nan
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0016
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1646.15,                last time consumption/overall running time: 409.2905s / 379406.1671 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0020
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1542.8,                last time consumption/overall running time: 382.2640s / 379788.4311 s
env0_first_0:                 episode reward: -22.4500,                 loss: nan
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1562.45,                last time consumption/overall running time: 387.1975s / 380175.6286 s
env0_first_0:                 episode reward: -22.0000,                 loss: nan
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0011
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1595.75,                last time consumption/overall running time: 396.6186s / 380572.2472 s
env0_first_0:                 episode reward: -22.7000,                 loss: nan
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0010
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1697.45,                last time consumption/overall running time: 419.1723s / 380991.4195 s
env0_first_0:                 episode reward: -19.8500,                 loss: nan
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0013
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1717.35,                last time consumption/overall running time: 423.9876s / 381415.4070 s
env0_first_0:                 episode reward: -22.0000,                 loss: nan
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0017
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1526.35,                last time consumption/overall running time: 377.5551s / 381792.9622 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0014
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1558.3,                last time consumption/overall running time: 384.9731s / 382177.9352 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0010
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1725.2,                last time consumption/overall running time: 428.1464s / 382606.0816 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0014
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1595.65,                last time consumption/overall running time: 395.0420s / 383001.1236 s
env0_first_0:                 episode reward: -21.9500,                 loss: nan
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1569.25,                last time consumption/overall running time: 388.3419s / 383389.4655 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1638.55,                last time consumption/overall running time: 406.5297s / 383795.9952 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0014
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1622.95,                last time consumption/overall running time: 402.2479s / 384198.2431 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1517.9,                last time consumption/overall running time: 377.6000s / 384575.8431 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1585.1,                last time consumption/overall running time: 394.2259s / 384970.0690 s
env0_first_0:                 episode reward: -22.9500,                 loss: nan
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0009
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1572.05,                last time consumption/overall running time: 485.7499s / 385455.8189 s
env0_first_0:                 episode reward: -19.5500,                 loss: nan
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0012
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1635.35,                last time consumption/overall running time: 578.2487s / 386034.0676 s
env0_first_0:                 episode reward: -21.3000,                 loss: nan
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0013
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1618.9,                last time consumption/overall running time: 572.6402s / 386606.7078 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0012
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1582.1,                last time consumption/overall running time: 560.2238s / 387166.9317 s
env0_first_0:                 episode reward: -20.4500,                 loss: nan
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0016
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 2026.7,                last time consumption/overall running time: 717.0542s / 387883.9859 s
env0_first_0:                 episode reward: -19.2000,                 loss: nan
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1901.3,                last time consumption/overall running time: 673.5777s / 388557.5636 s
env0_first_0:                 episode reward: -19.4000,                 loss: nan
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0023
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1726.7,                last time consumption/overall running time: 610.2468s / 389167.8103 s
env0_first_0:                 episode reward: -19.0500,                 loss: nan
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0022
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1662.2,                last time consumption/overall running time: 587.1372s / 389754.9476 s
env0_first_0:                 episode reward: -21.3500,                 loss: nan
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0018
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1626.75,                last time consumption/overall running time: 575.8866s / 390330.8341 s
env0_first_0:                 episode reward: -21.9500,                 loss: nan
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1614.7,                last time consumption/overall running time: 569.8282s / 390900.6623 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0013
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1651.3,                last time consumption/overall running time: 584.0668s / 391484.7291 s
env0_first_0:                 episode reward: -22.2000,                 loss: nan
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0011
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1678.75,                last time consumption/overall running time: 593.9786s / 392078.7077 s
env0_first_0:                 episode reward: -20.8500,                 loss: nan
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0014
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1645.6,                last time consumption/overall running time: 582.2708s / 392660.9785 s
env0_first_0:                 episode reward: -21.7500,                 loss: nan
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0016
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1640.95,                last time consumption/overall running time: 580.0699s / 393241.0484 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1588.6,                last time consumption/overall running time: 560.9500s / 393801.9984 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1614.65,                last time consumption/overall running time: 569.0304s / 394371.0288 s
env0_first_0:                 episode reward: -22.6500,                 loss: nan
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1685.2,                last time consumption/overall running time: 594.3376s / 394965.3664 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0013
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1574.15,                last time consumption/overall running time: 556.4197s / 395521.7861 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1618.35,                last time consumption/overall running time: 570.0083s / 396091.7944 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0014
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1594.7,                last time consumption/overall running time: 563.9142s / 396655.7087 s
env0_first_0:                 episode reward: -21.7000,                 loss: nan
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0013
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1602.6,                last time consumption/overall running time: 565.1811s / 397220.8897 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0012
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1625.45,                last time consumption/overall running time: 574.2959s / 397795.1856 s
env0_first_0:                 episode reward: -21.2500,                 loss: nan
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1585.6,                last time consumption/overall running time: 530.3082s / 398325.4938 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0014
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1516.45,                last time consumption/overall running time: 501.5175s / 398827.0114 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0012
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1737.75,                last time consumption/overall running time: 573.6175s / 399400.6288 s
env0_first_0:                 episode reward: -18.3000,                 loss: nan
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0012
env1_first_0:                 episode reward: -18.9500,                 loss: nan
env1_second_0:                 episode reward: 18.9500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1534.5,                last time consumption/overall running time: 508.8702s / 399909.4990 s
env0_first_0:                 episode reward: -22.1000,                 loss: nan
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0018
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1532.05,                last time consumption/overall running time: 507.5298s / 400417.0288 s
env0_first_0:                 episode reward: -22.6000,                 loss: nan
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0014
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1621.95,                last time consumption/overall running time: 535.7356s / 400952.7644 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0011
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1521.8,                last time consumption/overall running time: 504.6613s / 401457.4257 s
env0_first_0:                 episode reward: -22.5000,                 loss: nan
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0010
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1561.75,                last time consumption/overall running time: 518.4106s / 401975.8363 s
env0_first_0:                 episode reward: -22.8500,                 loss: nan
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0011
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1716.75,                last time consumption/overall running time: 568.2384s / 402544.0747 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0014
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1591.75,                last time consumption/overall running time: 527.7309s / 403071.8057 s
env0_first_0:                 episode reward: -22.4500,                 loss: nan
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1839.3,                last time consumption/overall running time: 609.3756s / 403681.1813 s
env0_first_0:                 episode reward: -16.1500,                 loss: nan
env0_second_0:                 episode reward: 16.1500,                 loss: 0.0013
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1590.45,                last time consumption/overall running time: 527.2975s / 404208.4788 s
env0_first_0:                 episode reward: -22.5000,                 loss: nan
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0021
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1576.3,                last time consumption/overall running time: 523.4145s / 404731.8932 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1623.25,                last time consumption/overall running time: 527.7314s / 405259.6247 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0013
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1633.4,                last time consumption/overall running time: 507.0815s / 405766.7062 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0013
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1644.5,                last time consumption/overall running time: 512.0447s / 406278.7509 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1589.4,                last time consumption/overall running time: 494.7164s / 406773.4673 s
env0_first_0:                 episode reward: -21.9500,                 loss: nan
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0011
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1715.6,                last time consumption/overall running time: 531.4178s / 407304.8851 s
env0_first_0:                 episode reward: -21.3000,                 loss: nan
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0011
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1824.5,                last time consumption/overall running time: 568.2194s / 407873.1045 s
env0_first_0:                 episode reward: -16.9000,                 loss: nan
env0_second_0:                 episode reward: 16.9000,                 loss: 0.0015
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1644.2,                last time consumption/overall running time: 512.5718s / 408385.6763 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0022
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1555.55,                last time consumption/overall running time: 469.8580s / 408855.5343 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0013
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1605.45,                last time consumption/overall running time: 466.6496s / 409322.1839 s
env0_first_0:                 episode reward: -22.1000,                 loss: nan
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0011
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1617.2,                last time consumption/overall running time: 468.5627s / 409790.7467 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0011
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1611.3,                last time consumption/overall running time: 468.4963s / 410259.2429 s
env0_first_0:                 episode reward: -21.8000,                 loss: nan
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0012
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1676.8,                last time consumption/overall running time: 485.8310s / 410745.0740 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1693.0,                last time consumption/overall running time: 492.9957s / 411238.0696 s
env0_first_0:                 episode reward: -20.9000,                 loss: nan
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0013
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1723.1,                last time consumption/overall running time: 500.1041s / 411738.1737 s
env0_first_0:                 episode reward: -20.7500,                 loss: nan
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0016
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1629.65,                last time consumption/overall running time: 474.8241s / 412212.9978 s
env0_first_0:                 episode reward: -19.6500,                 loss: nan
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0017
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 2100.7,                last time consumption/overall running time: 613.5597s / 412826.5575 s
env0_first_0:                 episode reward: -12.9500,                 loss: nan
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0020
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1682.3,                last time consumption/overall running time: 487.9209s / 413314.4785 s
env0_first_0:                 episode reward: -20.2000,                 loss: nan
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0036
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1799.45,                last time consumption/overall running time: 522.5275s / 413837.0060 s
env0_first_0:                 episode reward: -18.8000,                 loss: nan
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1576.55,                last time consumption/overall running time: 460.1270s / 414297.1330 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0018
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1647.7,                last time consumption/overall running time: 479.5817s / 414776.7146 s
env0_first_0:                 episode reward: -20.8500,                 loss: nan
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1663.95,                last time consumption/overall running time: 483.5298s / 415260.2444 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0016
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1559.85,                last time consumption/overall running time: 453.1916s / 415713.4360 s
env0_first_0:                 episode reward: -22.7500,                 loss: nan
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0013
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1591.15,                last time consumption/overall running time: 461.6740s / 416175.1100 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0011
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1581.6,                last time consumption/overall running time: 461.2753s / 416636.3853 s
env0_first_0:                 episode reward: -22.4000,                 loss: nan
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0011
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1650.2,                last time consumption/overall running time: 479.5491s / 417115.9345 s
env0_first_0:                 episode reward: -22.0000,                 loss: nan
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0012
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1531.3,                last time consumption/overall running time: 446.1857s / 417562.1201 s
env0_first_0:                 episode reward: -22.4000,                 loss: nan
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0012
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1690.55,                last time consumption/overall running time: 492.2547s / 418054.3748 s
env0_first_0:                 episode reward: -20.6000,                 loss: nan
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0010
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1757.85,                last time consumption/overall running time: 511.1079s / 418565.4826 s
env0_first_0:                 episode reward: -19.7000,                 loss: nan
env0_second_0:                 episode reward: 19.7000,                 loss: 0.0017
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1751.3,                last time consumption/overall running time: 509.4854s / 419074.9681 s
env0_first_0:                 episode reward: -18.8000,                 loss: nan
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0022
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1646.05,                last time consumption/overall running time: 479.8725s / 419554.8406 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0019
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1623.65,                last time consumption/overall running time: 474.9422s / 420029.7827 s
env0_first_0:                 episode reward: -22.5000,                 loss: nan
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0013
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1607.3,                last time consumption/overall running time: 469.6311s / 420499.4139 s
env0_first_0:                 episode reward: -21.7000,                 loss: nan
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0012
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1549.9,                last time consumption/overall running time: 451.0978s / 420950.5117 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1617.3,                last time consumption/overall running time: 469.5437s / 421420.0554 s
env0_first_0:                 episode reward: -21.7500,                 loss: nan
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0012
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1637.05,                last time consumption/overall running time: 474.5726s / 421894.6281 s
env0_first_0:                 episode reward: -20.6000,                 loss: nan
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0014
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1552.5,                last time consumption/overall running time: 443.7694s / 422338.3974 s
env0_first_0:                 episode reward: -22.5000,                 loss: nan
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0012
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1565.05,                last time consumption/overall running time: 424.0836s / 422762.4810 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0009
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1678.7,                last time consumption/overall running time: 458.7529s / 423221.2340 s
env0_first_0:                 episode reward: -21.3500,                 loss: nan
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0012
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1691.4,                last time consumption/overall running time: 459.6780s / 423680.9120 s
env0_first_0:                 episode reward: -20.5500,                 loss: nan
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0019
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1633.65,                last time consumption/overall running time: 442.5220s / 424123.4340 s
env0_first_0:                 episode reward: -22.3000,                 loss: nan
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0015
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1552.3,                last time consumption/overall running time: 422.9493s / 424546.3834 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1553.4,                last time consumption/overall running time: 420.7027s / 424967.0860 s
env0_first_0:                 episode reward: -22.4500,                 loss: nan
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0010
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1696.9,                last time consumption/overall running time: 463.5042s / 425430.5902 s
env0_first_0:                 episode reward: -18.9000,                 loss: nan
env0_second_0:                 episode reward: 18.9000,                 loss: 0.0011
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1525.2,                last time consumption/overall running time: 410.7062s / 425841.2964 s
env0_first_0:                 episode reward: -22.6500,                 loss: nan
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1665.85,                last time consumption/overall running time: 451.9872s / 426293.2836 s
env0_first_0:                 episode reward: -20.0500,                 loss: nan
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1746.0,                last time consumption/overall running time: 473.2909s / 426766.5746 s
env0_first_0:                 episode reward: -20.5000,                 loss: nan
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0016
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1611.6,                last time consumption/overall running time: 437.7566s / 427204.3311 s
env0_first_0:                 episode reward: -22.7000,                 loss: nan
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0015
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 2059.75,                last time consumption/overall running time: 562.5914s / 427766.9225 s
env0_first_0:                 episode reward: -12.3500,                 loss: nan
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0022
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1654.1,                last time consumption/overall running time: 449.9488s / 428216.8713 s
env0_first_0:                 episode reward: -21.1000,                 loss: nan
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1532.75,                last time consumption/overall running time: 417.7125s / 428634.5838 s
env0_first_0:                 episode reward: -21.9000,                 loss: nan
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0012
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1563.75,                last time consumption/overall running time: 426.1235s / 429060.7073 s
env0_first_0:                 episode reward: -22.1000,                 loss: nan
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0009
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1692.2,                last time consumption/overall running time: 460.9968s / 429521.7041 s
env0_first_0:                 episode reward: -19.8000,                 loss: nan
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0011
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1567.1,                last time consumption/overall running time: 426.5878s / 429948.2919 s
env0_first_0:                 episode reward: -21.4500,                 loss: nan
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0016
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1534.1,                last time consumption/overall running time: 416.0349s / 430364.3269 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1738.0,                last time consumption/overall running time: 471.5489s / 430835.8757 s
env0_first_0:                 episode reward: -19.3500,                 loss: nan
env0_second_0:                 episode reward: 19.3500,                 loss: 0.0017
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1615.65,                last time consumption/overall running time: 436.1510s / 431272.0267 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0016
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1596.4,                last time consumption/overall running time: 431.7298s / 431703.7565 s
env0_first_0:                 episode reward: -20.2500,                 loss: nan
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0015
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1600.9,                last time consumption/overall running time: 434.7290s / 432138.4855 s
env0_first_0:                 episode reward: -21.1500,                 loss: nan
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0015
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 2093.5,                last time consumption/overall running time: 567.1363s / 432705.6217 s
env0_first_0:                 episode reward: -10.4000,                 loss: nan
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1727.85,                last time consumption/overall running time: 469.5789s / 433175.2006 s
env0_first_0:                 episode reward: -19.8000,                 loss: nan
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1663.5,                last time consumption/overall running time: 452.2781s / 433627.4787 s
env0_first_0:                 episode reward: -21.4000,                 loss: nan
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0017
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1639.8,                last time consumption/overall running time: 446.6653s / 434074.1440 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0015
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1630.75,                last time consumption/overall running time: 440.6576s / 434514.8016 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0014
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1909.4,                last time consumption/overall running time: 516.8194s / 435031.6211 s
env0_first_0:                 episode reward: -15.9500,                 loss: nan
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0021
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1593.35,                last time consumption/overall running time: 432.2660s / 435463.8871 s
env0_first_0:                 episode reward: -20.9000,                 loss: nan
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0022
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1803.7,                last time consumption/overall running time: 487.6917s / 435951.5788 s
env0_first_0:                 episode reward: -16.3000,                 loss: nan
env0_second_0:                 episode reward: 16.3000,                 loss: 0.0014
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1604.35,                last time consumption/overall running time: 434.7348s / 436386.3136 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0021
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1743.9,                last time consumption/overall running time: 475.1651s / 436861.4787 s
env0_first_0:                 episode reward: -17.4500,                 loss: nan
env0_second_0:                 episode reward: 17.4500,                 loss: 0.0018
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1726.5,                last time consumption/overall running time: 470.9912s / 437332.4700 s
env0_first_0:                 episode reward: -21.5000,                 loss: nan
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0020
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1661.2,                last time consumption/overall running time: 457.9859s / 437790.4559 s
env0_first_0:                 episode reward: -20.0000,                 loss: nan
env0_second_0:                 episode reward: 20.0000,                 loss: 0.0017
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1509.9,                last time consumption/overall running time: 415.9521s / 438206.4080 s
env0_first_0:                 episode reward: -22.9500,                 loss: nan
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0015
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1635.4,                last time consumption/overall running time: 450.3843s / 438656.7923 s
env0_first_0:                 episode reward: -20.9500,                 loss: nan
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0012
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1798.95,                last time consumption/overall running time: 493.1982s / 439149.9904 s
env0_first_0:                 episode reward: -20.3500,                 loss: nanLoad tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_second_0:                 episode reward: 20.3500,                 loss: 0.0016
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1665.6,                last time consumption/overall running time: 458.1826s / 439608.1730 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0017
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1710.6,                last time consumption/overall running time: 472.3667s / 440080.5398 s
env0_first_0:                 episode reward: -19.3000,                 loss: nan
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0015
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1741.0,                last time consumption/overall running time: 478.3058s / 440558.8456 s
env0_first_0:                 episode reward: -20.0000,                 loss: nan
env0_second_0:                 episode reward: 20.0000,                 loss: 0.0018
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1737.15,                last time consumption/overall running time: 476.3848s / 441035.2304 s
env0_first_0:                 episode reward: -20.0500,                 loss: nan
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0018
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1586.65,                last time consumption/overall running time: 433.1444s / 441468.3748 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0017
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1526.85,                last time consumption/overall running time: 418.4034s / 441886.7782 s
env0_first_0:                 episode reward: -22.2500,                 loss: nan
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0012
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1574.25,                last time consumption/overall running time: 431.9468s / 442318.7250 s
env0_first_0:                 episode reward: -21.7000,                 loss: nan
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0008
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1555.4,                last time consumption/overall running time: 429.6533s / 442748.3783 s
env0_first_0:                 episode reward: -21.4500,                 loss: nan
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0010
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1594.35,                last time consumption/overall running time: 436.5081s / 443184.8864 s
env0_first_0:                 episode reward: -21.6500,                 loss: nan
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0011
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1592.6,                last time consumption/overall running time: 439.3697s / 443624.2561 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0013
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1624.1,                last time consumption/overall running time: 444.1352s / 444068.3913 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0012
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1937.7,                last time consumption/overall running time: 529.7852s / 444598.1764 s
env0_first_0:                 episode reward: -15.8000,                 loss: nan
env0_second_0:                 episode reward: 15.8000,                 loss: 0.0021
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1598.8,                last time consumption/overall running time: 438.1447s / 445036.3211 s
env0_first_0:                 episode reward: -22.2000,                 loss: nan
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0021
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
