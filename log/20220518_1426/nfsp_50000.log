pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f19b77b9ba8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/50000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_50000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_50000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6808s / 0.6808 s
agent0:                 episode reward: 1.3458,                 loss: nan
agent1:                 episode reward: -1.3458,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 0.8797 s
agent0:                 episode reward: 0.2544,                 loss: nan
agent1:                 episode reward: -0.2544,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 1.0772 s
agent0:                 episode reward: 0.6625,                 loss: nan
agent1:                 episode reward: -0.6625,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 1.2714 s
agent0:                 episode reward: 0.4071,                 loss: nan
agent1:                 episode reward: -0.4071,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 1.4691 s
agent0:                 episode reward: 0.0961,                 loss: nan
agent1:                 episode reward: -0.0961,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 1.6697 s
agent0:                 episode reward: 0.3675,                 loss: nan
agent1:                 episode reward: -0.3675,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 1.8683 s
agent0:                 episode reward: -0.1114,                 loss: nan
agent1:                 episode reward: 0.1114,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 2.0706 s
agent0:                 episode reward: 0.0174,                 loss: nan
agent1:                 episode reward: -0.0174,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 2.2670 s
agent0:                 episode reward: 0.1266,                 loss: nan
agent1:                 episode reward: -0.1266,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 2.4664 s
agent0:                 episode reward: 0.3981,                 loss: nan
agent1:                 episode reward: -0.3981,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 2.6644 s
agent0:                 episode reward: 0.2188,                 loss: nan
agent1:                 episode reward: -0.2188,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 2.8652 s
agent0:                 episode reward: 0.5286,                 loss: nan
agent1:                 episode reward: -0.5286,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 3.0636 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 3.2632 s
agent0:                 episode reward: 0.0252,                 loss: nan
agent1:                 episode reward: -0.0252,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 3.4629 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 3.6621 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 3.8549 s
agent0:                 episode reward: 0.0987,                 loss: nan
agent1:                 episode reward: -0.0987,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 4.0553 s
agent0:                 episode reward: 0.0831,                 loss: nan
agent1:                 episode reward: -0.0831,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 4.2541 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 4.4482 s
agent0:                 episode reward: 0.3143,                 loss: nan
agent1:                 episode reward: -0.3143,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 4.6477 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 4.8457 s
agent0:                 episode reward: 0.0535,                 loss: nan
agent1:                 episode reward: -0.0535,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 5.0477 s
agent0:                 episode reward: 0.3112,                 loss: nan
agent1:                 episode reward: -0.3112,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 5.2476 s
agent0:                 episode reward: 0.1842,                 loss: nan
agent1:                 episode reward: -0.1842,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 5.4486 s
agent0:                 episode reward: 0.3723,                 loss: nan
agent1:                 episode reward: -0.3723,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 5.6497 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 5.8504 s
agent0:                 episode reward: 0.1961,                 loss: nan
agent1:                 episode reward: -0.1961,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 6.0537 s
agent0:                 episode reward: 0.2347,                 loss: nan
agent1:                 episode reward: -0.2347,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 6.2550 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.4549 s
agent0:                 episode reward: 0.2772,                 loss: nan
agent1:                 episode reward: -0.2772,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 6.6491 s
agent0:                 episode reward: 0.1906,                 loss: nan
agent1:                 episode reward: -0.1906,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 6.8470 s
agent0:                 episode reward: 0.1176,                 loss: nan
agent1:                 episode reward: -0.1176,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 7.0476 s
agent0:                 episode reward: 0.5403,                 loss: nan
agent1:                 episode reward: -0.5403,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 7.2484 s
agent0:                 episode reward: 0.2320,                 loss: nan
agent1:                 episode reward: -0.2320,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 7.4465 s
agent0:                 episode reward: -0.0011,                 loss: nan
agent1:                 episode reward: 0.0011,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 7.6400 s
agent0:                 episode reward: -0.1171,                 loss: nan
agent1:                 episode reward: 0.1171,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 7.8385 s
agent0:                 episode reward: 0.5366,                 loss: nan
agent1:                 episode reward: -0.5366,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 8.0377 s
agent0:                 episode reward: 0.2625,                 loss: nan
agent1:                 episode reward: -0.2625,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 8.2349 s
agent0:                 episode reward: 0.4544,                 loss: nan
agent1:                 episode reward: -0.4544,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 8.4336 s
agent0:                 episode reward: 0.2809,                 loss: nan
agent1:                 episode reward: -0.2809,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 8.6294 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 8.8266 s
agent0:                 episode reward: 0.4700,                 loss: nan
agent1:                 episode reward: -0.4700,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 9.0308 s
agent0:                 episode reward: 0.0734,                 loss: nan
agent1:                 episode reward: -0.0734,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 9.2294 s
agent0:                 episode reward: -0.0004,                 loss: nan
agent1:                 episode reward: 0.0004,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 9.4291 s
agent0:                 episode reward: 0.3604,                 loss: nan
agent1:                 episode reward: -0.3604,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 9.6303 s
agent0:                 episode reward: 0.5017,                 loss: nan
agent1:                 episode reward: -0.5017,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 9.8277 s
agent0:                 episode reward: 0.0181,                 loss: nan
agent1:                 episode reward: -0.0181,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 10.0251 s
agent0:                 episode reward: 0.2839,                 loss: nan
agent1:                 episode reward: -0.2839,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 10.2242 s
agent0:                 episode reward: 0.4862,                 loss: nan
agent1:                 episode reward: -0.4862,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 10.4220 s
agent0:                 episode reward: 0.6305,                 loss: nan
agent1:                 episode reward: -0.6305,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 10.6247 s
agent0:                 episode reward: 0.2742,                 loss: nan
agent1:                 episode reward: -0.2742,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 10.8275 s
agent0:                 episode reward: 0.3411,                 loss: nan
agent1:                 episode reward: -0.3411,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 11.0289 s
agent0:                 episode reward: 0.4154,                 loss: nan
agent1:                 episode reward: -0.4154,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 11.2252 s
agent0:                 episode reward: 0.1730,                 loss: nan
agent1:                 episode reward: -0.1730,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 11.4366 s
agent0:                 episode reward: 0.4762,                 loss: nan
agent1:                 episode reward: -0.4762,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 11.6407 s
agent0:                 episode reward: 0.4335,                 loss: nan
agent1:                 episode reward: -0.4335,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 11.8397 s
agent0:                 episode reward: 0.0340,                 loss: nan
agent1:                 episode reward: -0.0340,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 12.0403 s
agent0:                 episode reward: 0.2861,                 loss: nan
agent1:                 episode reward: -0.2861,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 12.2405 s
agent0:                 episode reward: 0.6321,                 loss: nan
agent1:                 episode reward: -0.6321,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 12.4412 s
agent0:                 episode reward: 0.1762,                 loss: nan
agent1:                 episode reward: -0.1762,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 12.6374 s
agent0:                 episode reward: -0.0451,                 loss: nan
agent1:                 episode reward: 0.0451,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 12.8347 s
agent0:                 episode reward: 0.3491,                 loss: nan
agent1:                 episode reward: -0.3491,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 13.0340 s
agent0:                 episode reward: 0.3087,                 loss: nan
agent1:                 episode reward: -0.3087,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 13.2319 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 13.4270 s
agent0:                 episode reward: 0.0093,                 loss: nan
agent1:                 episode reward: -0.0093,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 13.6267 s
agent0:                 episode reward: 0.4906,                 loss: nan
agent1:                 episode reward: -0.4906,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 13.8255 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 14.0253 s
agent0:                 episode reward: 0.2132,                 loss: nan
agent1:                 episode reward: -0.2132,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 14.2290 s
agent0:                 episode reward: 0.3005,                 loss: nan
agent1:                 episode reward: -0.3005,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 14.4296 s
agent0:                 episode reward: 0.5105,                 loss: nan
agent1:                 episode reward: -0.5105,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 14.6315 s
agent0:                 episode reward: 0.2309,                 loss: nan
agent1:                 episode reward: -0.2309,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 14.8312 s
agent0:                 episode reward: 0.3692,                 loss: nan
agent1:                 episode reward: -0.3692,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 15.0355 s
agent0:                 episode reward: 0.5900,                 loss: nan
agent1:                 episode reward: -0.5900,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 15.2319 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.4303 s
agent0:                 episode reward: 0.5897,                 loss: nan
agent1:                 episode reward: -0.5897,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 15.6322 s
agent0:                 episode reward: 0.3900,                 loss: nan
agent1:                 episode reward: -0.3900,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.8306 s
agent0:                 episode reward: 0.2217,                 loss: nan
agent1:                 episode reward: -0.2217,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 16.0266 s
agent0:                 episode reward: 0.2366,                 loss: nan
agent1:                 episode reward: -0.2366,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 16.2287 s
agent0:                 episode reward: 0.3826,                 loss: nan
agent1:                 episode reward: -0.3826,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 16.4268 s
agent0:                 episode reward: 0.2015,                 loss: nan
agent1:                 episode reward: -0.2015,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 16.6278 s
agent0:                 episode reward: 0.1820,                 loss: nan
agent1:                 episode reward: -0.1820,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 16.8289 s
agent0:                 episode reward: 0.5597,                 loss: nan
agent1:                 episode reward: -0.5597,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 17.0283 s
agent0:                 episode reward: 0.4351,                 loss: nan
agent1:                 episode reward: -0.4351,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 17.2283 s
agent0:                 episode reward: 0.2938,                 loss: nan
agent1:                 episode reward: -0.2938,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 17.4319 s
agent0:                 episode reward: 0.4075,                 loss: nan
agent1:                 episode reward: -0.4075,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 17.6305 s
agent0:                 episode reward: 0.1486,                 loss: nan
agent1:                 episode reward: -0.1486,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 17.8299 s
agent0:                 episode reward: 0.0488,                 loss: nan
agent1:                 episode reward: -0.0488,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 18.0298 s
agent0:                 episode reward: 0.3362,                 loss: nan
agent1:                 episode reward: -0.3362,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 18.2327 s
agent0:                 episode reward: 0.4495,                 loss: nan
agent1:                 episode reward: -0.4495,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 18.4321 s
agent0:                 episode reward: 0.5711,                 loss: nan
agent1:                 episode reward: -0.5711,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 18.6325 s
agent0:                 episode reward: 0.2159,                 loss: nan
agent1:                 episode reward: -0.2159,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 18.8346 s
agent0:                 episode reward: 0.1496,                 loss: nan
agent1:                 episode reward: -0.1496,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 19.0313 s
agent0:                 episode reward: -0.0735,                 loss: nan
agent1:                 episode reward: 0.0735,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.2309 s
agent0:                 episode reward: 0.5201,                 loss: nan
agent1:                 episode reward: -0.5201,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 19.4295 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 19.6287 s
agent0:                 episode reward: 0.1365,                 loss: nan
agent1:                 episode reward: -0.1365,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 19.8243 s
agent0:                 episode reward: 0.5354,                 loss: nan
agent1:                 episode reward: -0.5354,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 20.0190 s
agent0:                 episode reward: 0.3384,                 loss: nan
agent1:                 episode reward: -0.3384,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 20.2225 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 20.4246 s
agent0:                 episode reward: 0.2892,                 loss: nan
agent1:                 episode reward: -0.2892,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 20.6179 s
agent0:                 episode reward: 0.5144,                 loss: nan
agent1:                 episode reward: -0.5144,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 20.8278 s
agent0:                 episode reward: 0.4372,                 loss: nan
agent1:                 episode reward: -0.4372,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 21.0279 s
agent0:                 episode reward: 0.1855,                 loss: nan
agent1:                 episode reward: -0.1855,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 21.2276 s
agent0:                 episode reward: 0.3923,                 loss: nan
agent1:                 episode reward: -0.3923,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 21.4264 s
agent0:                 episode reward: 0.6026,                 loss: nan
agent1:                 episode reward: -0.6026,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 21.6304 s
agent0:                 episode reward: 0.1550,                 loss: nan
agent1:                 episode reward: -0.1550,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 21.8305 s
agent0:                 episode reward: 0.0883,                 loss: nan
agent1:                 episode reward: -0.0883,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 22.0290 s
agent0:                 episode reward: -0.1877,                 loss: nan
agent1:                 episode reward: 0.1877,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 22.2309 s
agent0:                 episode reward: 0.3069,                 loss: nan
agent1:                 episode reward: -0.3069,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 22.4307 s
agent0:                 episode reward: 0.0855,                 loss: nan
agent1:                 episode reward: -0.0855,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 22.6315 s
agent0:                 episode reward: 0.1666,                 loss: nan
agent1:                 episode reward: -0.1666,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 22.8330 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 23.0349 s
agent0:                 episode reward: 0.3245,                 loss: nan
agent1:                 episode reward: -0.3245,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 23.2337 s
agent0:                 episode reward: 0.2251,                 loss: nan
agent1:                 episode reward: -0.2251,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 23.4348 s
agent0:                 episode reward: 0.5186,                 loss: nan
agent1:                 episode reward: -0.5186,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 23.6328 s
agent0:                 episode reward: 0.1975,                 loss: nan
agent1:                 episode reward: -0.1975,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 23.8341 s
agent0:                 episode reward: 0.4742,                 loss: nan
agent1:                 episode reward: -0.4742,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 24.0352 s
agent0:                 episode reward: 0.4330,                 loss: nan
agent1:                 episode reward: -0.4330,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 24.2392 s
agent0:                 episode reward: 0.2661,                 loss: nan
agent1:                 episode reward: -0.2661,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 24.4412 s
agent0:                 episode reward: 0.3074,                 loss: nan
agent1:                 episode reward: -0.3074,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 24.6411 s
agent0:                 episode reward: 0.5563,                 loss: nan
agent1:                 episode reward: -0.5563,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 24.8376 s
agent0:                 episode reward: 0.4180,                 loss: nan
agent1:                 episode reward: -0.4180,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 25.0376 s
agent0:                 episode reward: -0.1914,                 loss: nan
agent1:                 episode reward: 0.1914,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 25.2392 s
agent0:                 episode reward: 0.0264,                 loss: nan
agent1:                 episode reward: -0.0264,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 25.4339 s
agent0:                 episode reward: 0.1117,                 loss: nan
agent1:                 episode reward: -0.1117,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 25.6344 s
agent0:                 episode reward: 0.5973,                 loss: nan
agent1:                 episode reward: -0.5973,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 25.8356 s
agent0:                 episode reward: 0.2697,                 loss: nan
agent1:                 episode reward: -0.2697,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 26.0318 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 26.2300 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 26.4313 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 26.6281 s
agent0:                 episode reward: 0.2948,                 loss: nan
agent1:                 episode reward: -0.2948,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 26.8251 s
agent0:                 episode reward: 0.1936,                 loss: nan
agent1:                 episode reward: -0.1936,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 27.0174 s
agent0:                 episode reward: 0.4363,                 loss: nan
agent1:                 episode reward: -0.4363,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 27.2122 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 27.4144 s
agent0:                 episode reward: 0.3268,                 loss: nan
agent1:                 episode reward: -0.3268,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 27.6155 s
agent0:                 episode reward: 0.2700,                 loss: nan
agent1:                 episode reward: -0.2700,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 27.8117 s
agent0:                 episode reward: 0.4773,                 loss: nan
agent1:                 episode reward: -0.4773,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1624s / 27.9741 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 28.2079 s
agent0:                 episode reward: 0.0088,                 loss: nan
agent1:                 episode reward: -0.0088,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 28.4050 s
agent0:                 episode reward: 0.4045,                 loss: nan
agent1:                 episode reward: -0.4045,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 28.6014 s
agent0:                 episode reward: -0.2337,                 loss: nan
agent1:                 episode reward: 0.2337,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 28.8025 s
agent0:                 episode reward: 0.3878,                 loss: nan
agent1:                 episode reward: -0.3878,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 29.0008 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 29.1992 s
agent0:                 episode reward: 0.4158,                 loss: nan
agent1:                 episode reward: -0.4158,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 29.3980 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 29.5979 s
agent0:                 episode reward: 0.1733,                 loss: nan
agent1:                 episode reward: -0.1733,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2067s / 29.8047 s
agent0:                 episode reward: 0.0881,                 loss: nan
agent1:                 episode reward: -0.0881,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 30.0040 s
agent0:                 episode reward: 0.0696,                 loss: nan
agent1:                 episode reward: -0.0696,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 30.2049 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 30.4038 s
agent0:                 episode reward: 0.4297,                 loss: nan
agent1:                 episode reward: -0.4297,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 30.6024 s
agent0:                 episode reward: 0.4348,                 loss: nan
agent1:                 episode reward: -0.4348,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 30.8032 s
agent0:                 episode reward: 0.5547,                 loss: nan
agent1:                 episode reward: -0.5547,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 31.0012 s
agent0:                 episode reward: 0.3775,                 loss: nan
agent1:                 episode reward: -0.3775,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 31.2064 s
agent0:                 episode reward: 0.3378,                 loss: nan
agent1:                 episode reward: -0.3378,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 31.4038 s
agent0:                 episode reward: 0.3140,                 loss: nan
agent1:                 episode reward: -0.3140,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 31.6035 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 31.8030 s
agent0:                 episode reward: 0.4174,                 loss: nan
agent1:                 episode reward: -0.4174,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 32.0018 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 32.2042 s
agent0:                 episode reward: 0.2724,                 loss: nan
agent1:                 episode reward: -0.2724,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 32.4026 s
agent0:                 episode reward: 0.0044,                 loss: nan
agent1:                 episode reward: -0.0044,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2057s / 32.6083 s
agent0:                 episode reward: 0.0303,                 loss: nan
agent1:                 episode reward: -0.0303,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 32.8088 s
agent0:                 episode reward: 0.2884,                 loss: nan
agent1:                 episode reward: -0.2884,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 33.0110 s
agent0:                 episode reward: 0.4149,                 loss: nan
agent1:                 episode reward: -0.4149,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 33.2094 s
agent0:                 episode reward: 0.4169,                 loss: nan
agent1:                 episode reward: -0.4169,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 33.4092 s
agent0:                 episode reward: -0.0208,                 loss: nan
agent1:                 episode reward: 0.0208,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 33.6081 s
agent0:                 episode reward: 0.5096,                 loss: nan
agent1:                 episode reward: -0.5096,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 33.8020 s
agent0:                 episode reward: 0.5821,                 loss: nan
agent1:                 episode reward: -0.5821,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3340s / 34.1360 s
agent0:                 episode reward: -0.2367,                 loss: nan
agent1:                 episode reward: 0.2367,                 loss: 0.4457
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 34.7214 s
agent0:                 episode reward: 0.2227,                 loss: nan
agent1:                 episode reward: -0.2227,                 loss: 0.4455
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 35.3008 s
agent0:                 episode reward: 0.2021,                 loss: nan
agent1:                 episode reward: -0.2021,                 loss: 0.4441
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5781s / 35.8789 s
agent0:                 episode reward: 0.4200,                 loss: nan
agent1:                 episode reward: -0.4200,                 loss: 0.4419
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 36.4656 s
agent0:                 episode reward: 0.3099,                 loss: nan
agent1:                 episode reward: -0.3099,                 loss: 0.4402
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 37.0536 s
agent0:                 episode reward: 0.2527,                 loss: nan
agent1:                 episode reward: -0.2527,                 loss: 0.4374
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 37.6355 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.4333
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 38.2158 s
agent0:                 episode reward: -0.2191,                 loss: nan
agent1:                 episode reward: 0.2191,                 loss: 0.4285
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 38.7964 s
agent0:                 episode reward: 0.3769,                 loss: nan
agent1:                 episode reward: -0.3769,                 loss: 0.4237
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 39.3776 s
agent0:                 episode reward: -0.1901,                 loss: nan
agent1:                 episode reward: 0.1901,                 loss: 0.4159
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 39.9604 s
agent0:                 episode reward: 0.0652,                 loss: nan
agent1:                 episode reward: -0.0652,                 loss: 0.4097
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 40.5452 s
agent0:                 episode reward: -0.3294,                 loss: nan
agent1:                 episode reward: 0.3294,                 loss: 0.4024
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 41.1276 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3952
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 41.7074 s
agent0:                 episode reward: -0.1404,                 loss: nan
agent1:                 episode reward: 0.1404,                 loss: 0.3921
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 42.2864 s
agent0:                 episode reward: 0.1472,                 loss: nan
agent1:                 episode reward: -0.1472,                 loss: 0.3871
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 42.8762 s
agent0:                 episode reward: -0.1032,                 loss: nan
agent1:                 episode reward: 0.1032,                 loss: 0.3864
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 43.4649 s
agent0:                 episode reward: -0.0015,                 loss: nan
agent1:                 episode reward: 0.0015,                 loss: 0.3832
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5780s / 44.0430 s
agent0:                 episode reward: -0.2142,                 loss: nan
agent1:                 episode reward: 0.2142,                 loss: 0.3592
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 44.6323 s
agent0:                 episode reward: -0.3266,                 loss: nan
agent1:                 episode reward: 0.3266,                 loss: 0.3471
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 45.2232 s
agent0:                 episode reward: -0.2877,                 loss: nan
agent1:                 episode reward: 0.2877,                 loss: 0.3467
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 45.8172 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.3479
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 46.4000 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.3464
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 46.9812 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.3468
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 47.5693 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.3447
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 48.1522 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.3481
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 48.7376 s
agent0:                 episode reward: -0.6464,                 loss: nan
agent1:                 episode reward: 0.6464,                 loss: 0.3470
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 49.3291 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.3476
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 49.9245 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.3455
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 50.5099 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.3436
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 51.0967 s
agent0:                 episode reward: -0.2915,                 loss: nan
agent1:                 episode reward: 0.2915,                 loss: 0.3443
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 51.6805 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.3427
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 52.2691 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.3422
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 52.8606 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.3454
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 53.4527 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.3429
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 54.0399 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.3253
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 54.6205 s
agent0:                 episode reward: -0.0049,                 loss: nan
agent1:                 episode reward: 0.0049,                 loss: 0.3220
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 55.2073 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.3257
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 55.7929 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.3247
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 56.3775 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.3239
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 56.9593 s
agent0:                 episode reward: -0.0607,                 loss: nan
agent1:                 episode reward: 0.0607,                 loss: 0.3228
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 57.5497 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: 0.3223
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 58.1320 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3197
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 58.7142 s
agent0:                 episode reward: 0.0132,                 loss: nan
agent1:                 episode reward: -0.0132,                 loss: 0.3203
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 59.3069 s
agent0:                 episode reward: 0.0119,                 loss: nan
agent1:                 episode reward: -0.0119,                 loss: 0.3213
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 59.8978 s
agent0:                 episode reward: -0.0100,                 loss: nan
agent1:                 episode reward: 0.0100,                 loss: 0.3226
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 60.4863 s
agent0:                 episode reward: -0.3855,                 loss: nan
agent1:                 episode reward: 0.3855,                 loss: 0.3231
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 61.0827 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: 0.3230
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 61.6726 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.3217
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 62.2652 s
agent0:                 episode reward: -0.1039,                 loss: nan
agent1:                 episode reward: 0.1039,                 loss: 0.3199
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 62.8584 s
agent0:                 episode reward: -0.1225,                 loss: nan
agent1:                 episode reward: 0.1225,                 loss: 0.3211
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 63.4515 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3345
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 64.0445 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.3549
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 64.6302 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.3543
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 65.2240 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.3550
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 65.8153 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.3507
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 66.4101 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3546
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 67.0019 s
agent0:                 episode reward: -0.4694,                 loss: nan
agent1:                 episode reward: 0.4694,                 loss: 0.3520
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 67.5907 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.3511
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 68.1831 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.3529
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 68.7768 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.3536
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 69.3724 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.3495
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 69.9674 s
agent0:                 episode reward: -0.3144,                 loss: nan
agent1:                 episode reward: 0.3144,                 loss: 0.3492
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 70.5628 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.3538
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 71.1579 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.3501
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 71.7553 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.3477
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 72.3469 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.3526
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 72.9377 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.3490
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 73.5237 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.3531
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 74.1073 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3529
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 74.6975 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.3516
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 75.2813 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.3526
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5796s / 75.8609 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.3505
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 76.4508 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.3536
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 77.0338 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.3480
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 77.6268 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.3512
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 78.2168 s
agent0:                 episode reward: -0.1783,                 loss: nan
agent1:                 episode reward: 0.1783,                 loss: 0.3486
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 78.8026 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.3487
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 79.3966 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.3508
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 79.9803 s
agent0:                 episode reward: -0.5092,                 loss: nan
agent1:                 episode reward: 0.5092,                 loss: 0.3490
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 80.5581 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.3491
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 81.1459 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: 0.3487
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 81.7296 s
agent0:                 episode reward: -0.0029,                 loss: nan
agent1:                 episode reward: 0.0029,                 loss: 0.3492
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 82.3143 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.3511
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 82.8962 s
agent0:                 episode reward: -0.5804,                 loss: nan
agent1:                 episode reward: 0.5804,                 loss: 0.3495
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 83.4809 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.3392
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 84.0628 s
agent0:                 episode reward: -0.4299,                 loss: nan
agent1:                 episode reward: 0.4299,                 loss: 0.3398
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 84.6475 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.3408
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 85.2426 s
agent0:                 episode reward: 0.0632,                 loss: nan
agent1:                 episode reward: -0.0632,                 loss: 0.3409
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 85.8281 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.3367
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 86.4175 s
agent0:                 episode reward: -0.7505,                 loss: nan
agent1:                 episode reward: 0.7505,                 loss: 0.3391
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 87.0143 s
agent0:                 episode reward: -0.5274,                 loss: nan
agent1:                 episode reward: 0.5274,                 loss: 0.3415
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 87.5997 s
agent0:                 episode reward: -0.6871,                 loss: nan
agent1:                 episode reward: 0.6871,                 loss: 0.3401
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 88.1936 s
agent0:                 episode reward: -0.3089,                 loss: nan
agent1:                 episode reward: 0.3089,                 loss: 0.3396
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 88.7818 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.3402
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 89.3712 s
agent0:                 episode reward: 0.1484,                 loss: nan
agent1:                 episode reward: -0.1484,                 loss: 0.3367
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 89.9571 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.3395
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 90.5505 s
agent0:                 episode reward: -0.2304,                 loss: nan
agent1:                 episode reward: 0.2304,                 loss: 0.3382
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 91.1412 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.3380
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 91.7305 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.3385
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 92.3187 s
agent0:                 episode reward: -0.7989,                 loss: nan
agent1:                 episode reward: 0.7989,                 loss: 0.3367
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 92.9090 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.3423
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 93.5012 s
agent0:                 episode reward: -0.8358,                 loss: nan
agent1:                 episode reward: 0.8358,                 loss: 0.3462
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 94.0877 s
agent0:                 episode reward: -0.7675,                 loss: nan
agent1:                 episode reward: 0.7675,                 loss: 0.3428
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 94.6689 s
agent0:                 episode reward: -0.6431,                 loss: nan
agent1:                 episode reward: 0.6431,                 loss: 0.3432
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 95.2571 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.3433
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 95.8506 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.3478
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 96.4397 s
agent0:                 episode reward: -0.5186,                 loss: nan
agent1:                 episode reward: 0.5186,                 loss: 0.3430
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 97.0240 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.3440
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 97.6117 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3457
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 98.1960 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.3407
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 98.7837 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3454
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 99.3701 s
agent0:                 episode reward: -0.3009,                 loss: nan
agent1:                 episode reward: 0.3009,                 loss: 0.3447
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 99.9623 s
agent0:                 episode reward: -0.7462,                 loss: nan
agent1:                 episode reward: 0.7462,                 loss: 0.3437
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 100.5533 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3414
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 101.1408 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3437
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 101.7236 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.3469
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 102.3208 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.3430
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 102.9145 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.3389
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 103.5131 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.3371
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 104.1059 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3355
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 104.6989 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.3348
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 105.2919 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.3352
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 105.8874 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3343
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 106.4911 s
agent0:                 episode reward: -0.5896,                 loss: nan
agent1:                 episode reward: 0.5896,                 loss: 0.3393
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 107.0870 s
agent0:                 episode reward: -0.8460,                 loss: nan
agent1:                 episode reward: 0.8460,                 loss: 0.3363
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 107.6755 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3376
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 108.2695 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.3361
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 108.8579 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.3363
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 109.4477 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.3371
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 110.0411 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3335
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 110.6266 s
agent0:                 episode reward: -0.4652,                 loss: nan
agent1:                 episode reward: 0.4652,                 loss: 0.3348
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 111.2212 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.3357
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 111.8120 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.3328
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 112.3988 s
agent0:                 episode reward: -0.9472,                 loss: nan
agent1:                 episode reward: 0.9472,                 loss: 0.3338
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 113.0006 s
agent0:                 episode reward: -0.4825,                 loss: nan
agent1:                 episode reward: 0.4825,                 loss: 0.3349
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 113.5924 s
agent0:                 episode reward: -0.4614,                 loss: nan
agent1:                 episode reward: 0.4614,                 loss: 0.3293
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 114.1855 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3304
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 114.7809 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.3287
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 115.3784 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.3321
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 115.9742 s
agent0:                 episode reward: -0.2991,                 loss: nan
agent1:                 episode reward: 0.2991,                 loss: 0.3300
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 116.5676 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.3303
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 117.1528 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3307
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 117.7484 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.3296
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 118.3469 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: 0.3312
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 118.9392 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.3331
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 119.5475 s
agent0:                 episode reward: -0.8816,                 loss: nan
agent1:                 episode reward: 0.8816,                 loss: 0.3292
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 120.1463 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.3254
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 120.7469 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.3310
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 121.3398 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.3281
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 121.9347 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.3320
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 122.5344 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.3373
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 123.1370 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.3514
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 123.7336 s
agent0:                 episode reward: -0.1329,                 loss: nan
agent1:                 episode reward: 0.1329,                 loss: 0.3524
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 124.3302 s
agent0:                 episode reward: -0.3664,                 loss: nan
agent1:                 episode reward: 0.3664,                 loss: 0.3542
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 124.9305 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.3517
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 125.5299 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.3514
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 126.1279 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.3536
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 126.7322 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.3508
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 127.3348 s
agent0:                 episode reward: -0.7677,                 loss: nan
agent1:                 episode reward: 0.7677,                 loss: 0.3547
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 127.9331 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.3537
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 128.5240 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.3528
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 129.1355 s
agent0:                 episode reward: -0.3058,                 loss: nan
agent1:                 episode reward: 0.3058,                 loss: 0.3547
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 129.7434 s
agent0:                 episode reward: -0.9040,                 loss: nan
agent1:                 episode reward: 0.9040,                 loss: 0.3536
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 130.3509 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.3514
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 130.9544 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3497
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 131.5591 s
agent0:                 episode reward: -1.0704,                 loss: nan
agent1:                 episode reward: 1.0704,                 loss: 0.3509
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 132.1675 s
agent0:                 episode reward: -0.7127,                 loss: nan
agent1:                 episode reward: 0.7127,                 loss: 0.3482
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 132.7830 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3294
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 133.3907 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.3231
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 134.0012 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.3241
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 134.6102 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.3279
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 135.2254 s
agent0:                 episode reward: -0.4988,                 loss: nan
agent1:                 episode reward: 0.4988,                 loss: 0.3258
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 135.8401 s
agent0:                 episode reward: -0.7320,                 loss: nan
agent1:                 episode reward: 0.7320,                 loss: 0.3248
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 136.4522 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.3220
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 137.0572 s
agent0:                 episode reward: -0.8271,                 loss: nan
agent1:                 episode reward: 0.8271,                 loss: 0.3227
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 137.6733 s
agent0:                 episode reward: -0.4534,                 loss: nan
agent1:                 episode reward: 0.4534,                 loss: 0.3268
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 138.2892 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.3252
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 138.9015 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.3255
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6160s / 139.5175 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3215
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 140.1345 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3219
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 140.7512 s
agent0:                 episode reward: -0.7261,                 loss: nan
agent1:                 episode reward: 0.7261,                 loss: 0.3202
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 141.3619 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: 0.3248
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 141.9664 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.3234
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 142.5770 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.3231
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 143.1818 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3351
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 143.7774 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.3326
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 144.3730 s
agent0:                 episode reward: -0.8303,                 loss: nan
agent1:                 episode reward: 0.8303,                 loss: 0.3363
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 144.9685 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.3359
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 145.5666 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.3346
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 146.1682 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.3338
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 146.7737 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.3329
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 147.3701 s
agent0:                 episode reward: -0.6716,                 loss: nan
agent1:                 episode reward: 0.6716,                 loss: 0.3339
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 147.9773 s
agent0:                 episode reward: -0.5213,                 loss: nan
agent1:                 episode reward: 0.5213,                 loss: 0.3338
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 148.5785 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: 0.3361
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 149.1791 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.3336
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 149.7791 s
agent0:                 episode reward: -0.6621,                 loss: nan
agent1:                 episode reward: 0.6621,                 loss: 0.3347
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 150.3781 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.3356
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 150.9713 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.3339
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 151.5567 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.3319
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 152.1437 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.3358
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 152.7455 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.3312
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 153.3375 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.3289
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 153.9317 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.3285
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 154.5249 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: 0.3269
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 155.1354 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.3269
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 155.7482 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.3301
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 156.3551 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.3284
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 156.9497 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.3258
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 157.5510 s
agent0:                 episode reward: -0.3085,                 loss: nan
agent1:                 episode reward: 0.3085,                 loss: 0.3291
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 158.1508 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.3266
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 158.7482 s
agent0:                 episode reward: -0.5131,                 loss: nan
agent1:                 episode reward: 0.5131,                 loss: 0.3285
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 159.3472 s
agent0:                 episode reward: -0.5937,                 loss: nan
agent1:                 episode reward: 0.5937,                 loss: 0.3299
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 159.9538 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.3296
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 160.5540 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3302
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 161.1624 s
agent0:                 episode reward: -0.2714,                 loss: nan
agent1:                 episode reward: 0.2714,                 loss: 0.3252