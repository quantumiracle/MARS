pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 717
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f4f7c58a358>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=5, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=5, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.045 0.045 0.045 ... 0.045 0.045 0.045]
 [0.045 0.045 0.045 ... 0.045 0.045 0.045]]
Load checkpoints (policy family):  [['21' '554' '960' ... '6644' '6828' '7746']
 ['222' '763' '1130' ... '6701' '6852' '7769']]
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220425_1813/pettingzoo_surround_v1_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220425_1813_exploit_first_50000/pettingzoo_surround_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220425_1813_exploit_first_50000/pettingzoo_surround_v1_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 4.6117s / 4.6117 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.1559
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 61.5434s / 66.1551 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0492
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.2609s / 128.4159 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0228
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.7246s / 191.1405 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0215
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 62.7253s / 253.8658 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0208
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 63.8621s / 317.7279 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0208
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.0727s / 381.8006 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0209
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.6170s / 446.4176 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0207
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.9562s / 511.3738 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0204
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.3227s / 576.6964 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0203
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 65.7454s / 642.4418 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0206
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.0360s / 708.4778 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0205
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.3730s / 774.8507 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0207
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 66.5294s / 841.3802 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0207
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 67.2720s / 908.6521 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0212
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 67.6853s / 976.3374 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0213
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 68.1846s / 1044.5220 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0205
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 68.8952s / 1113.4172 spygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 509
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fd72b803470>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=5, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=5, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.045 0.045 0.045 ... 0.045 0.045 0.045]
 [0.045 0.045 0.045 ... 0.045 0.045 0.045]]
Load checkpoints (policy family):  [['21' '554' '960' ... '6644' '6828' '7746']
 ['222' '763' '1130' ... '6701' '6852' '7769']]
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220425_1813/pettingzoo_surround_v1_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220425_1813_exploit_first/pettingzoo_surround_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220425_1813_exploit_first/pettingzoo_surround_v1_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.2024s / 5.2024 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.1514
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5747s / 84.7771 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0686
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.8570s / 166.6341 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0380
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 83.0340s / 249.6682 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0300
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.4716s / 334.1398 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0227
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.4511s / 419.5909 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0188
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9725s / 506.5634 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0179
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8503s / 594.4137 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0187
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.6768s / 684.0905 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0236
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.7172s / 774.8077 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0238
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.2490s / 867.0567 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0248
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.0246s / 961.0813 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0236
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.4119s / 1056.4932 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0247
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.6846s / 1153.1778 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0254
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6018s / 1251.7796 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0236
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 101.8797s / 1353.6593 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0233
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.9223s / 1456.5816 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0218
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8703s / 1561.4519 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0211
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5859s / 1667.0377 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0215
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1162s / 1773.1540 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0220
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4358s / 1878.5898 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0230
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3275s / 1982.9174 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0236
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6235s / 2088.5408 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0256
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3230s / 2192.8639 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0262
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4137s / 2298.2776 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0245
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1504s / 2403.4279 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0244
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8086s / 2509.2365 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0236
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5195s / 2614.7560 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0235
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4841s / 2721.2401 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0222
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7819s / 2828.0220 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0221
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0358s / 2935.0578 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0220
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.2415s / 3043.2994 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0218
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9398s / 3150.2392 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0215
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.4782s / 3257.7174 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0213
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9320s / 3364.6494 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0211
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8534s / 3472.5028 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0206
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8445s / 3577.3473 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0204
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.6766s / 3680.0239 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0208
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0521s / 3785.0760 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0209
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0345s / 3889.1105 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0208
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1961s / 3993.3066 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0203
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1296s / 4097.4362 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0194
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9691s / 4201.4053 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0191
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2147s / 4305.6200 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0191
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1737s / 4409.7937 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0188
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9646s / 4514.7583 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0188
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.9625s / 4617.7208 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0193
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7333s / 4722.4541 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0188
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0441s / 4826.4982 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0198
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3826s / 4930.8807 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0194
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5783s / 5034.4590 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0191
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6121s / 5138.0711 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0190
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6697s / 5242.7408 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0190
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6199s / 5347.3607 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0193
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.7313s / 5451.0920 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0205
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7409s / 5555.8329 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0185
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4553s / 5660.2882 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0181
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5215s / 5763.8097 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0181
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1560s / 5867.9657 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0185
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.8729s / 5971.8387 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0185
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3735s / 6076.2122 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0181
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1208s / 6181.3329 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0178
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8342s / 6286.1671 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0182
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0615s / 6391.2286 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0179
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6813s / 6496.9099 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0177
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4745s / 6602.3843 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0178
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1860s / 6707.5704 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0170
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3260s / 6811.8963 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0171
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9408s / 6915.8371 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0168
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3507s / 7021.1878 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0185
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9250s / 7126.1128 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0183
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5399s / 7231.6527 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0198
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5683s / 7336.2210 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0186
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0820s / 7440.3030 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0180
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8071s / 7545.1101 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0173
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2062s / 7650.3163 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0178
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6265s / 7755.9428 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0174
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4010s / 7860.3438 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0174
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9941s / 7964.3378 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0180
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3314s / 8068.6692 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0170
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4527s / 8173.1219 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0170
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3548s / 8279.4767 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0168
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1114s / 8383.5881 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0179
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7675s / 8490.3556 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0181
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3047s / 8595.6603 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0174
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4983s / 8700.1586 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0168
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2511s / 8805.4097 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0172
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6332s / 8909.0430 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0175
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4314s / 9013.4743 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0167
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9716s / 9118.4459 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0168
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1631s / 9223.6090 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0167
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1618s / 9327.7708 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0180
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1459s / 9431.9167 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0161
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0724s / 9535.9892 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0154
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4062s / 9640.3954 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0149
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8728s / 9745.2682 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0153
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0607s / 9849.3289 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0160
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5217s / 9953.8506 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0158
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9204s / 10057.7710 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0159
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3404s / 10162.1115 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0157
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4308s / 10266.5422 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0171
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3506s / 10370.8929 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0183
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1874s / 10476.0803 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0202
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0587s / 10582.1390 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0200
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3711s / 10686.5101 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0196
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9377s / 10791.4478 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0190
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0332s / 10896.4810 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0179
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7657s / 11002.2467 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0181
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7749s / 11107.0216 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0189
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5291s / 11211.5507 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0196
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7553s / 11317.3060 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0209
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3352s / 11421.6412 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0202
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2453s / 11526.8865 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0191
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.8576s / 11634.7441 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0183
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9106s / 11739.6547 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0171
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4558s / 11845.1105 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0162
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0028s / 11950.1133 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0165
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9937s / 12055.1071 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0158
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1042s / 12161.2112 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0149
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2937s / 12267.5049 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0149
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7866s / 12374.2914 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0159
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7075s / 12479.9989 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0161
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5717s / 12586.5706 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0163
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8536s / 12693.4242 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0157
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5022s / 12799.9264 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0159
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7498s / 12904.6761 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0152
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3417s / 13010.0178 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0162
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3560s / 13114.3738 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0162
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9178s / 13220.2916 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0168
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1338s / 13325.4254 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0175
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1725s / 13430.5979 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0184
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3322s / 13535.9301 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0179
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3567s / 13641.2868 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0177
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9181s / 13746.2049 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0175
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9231s / 13851.1280 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0177
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6539s / 13955.7819 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0171
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0033s / 14062.7852 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0168
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1155s / 14166.9006 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0168
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6977s / 14271.5983 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0168
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4436s / 14377.0419 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0176
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5052s / 14482.5472 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0168
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3125s / 14586.8597 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0152
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3503s / 14692.2100 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0153
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3167s / 14797.5267 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0143
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6771s / 14903.2038 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0142
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9106s / 15008.1144 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0137
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0989s / 15113.2133 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0142
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2732s / 15219.4865 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0154
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8023s / 15325.2888 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0166
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1158s / 15432.4046 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0167
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8891s / 15537.2937 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0163
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9323s / 15643.2261 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0169
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1062s / 15747.3323 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0174
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7879s / 15853.1202 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0173
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5030s / 15957.6232 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0173
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8581s / 16062.4814 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0165
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5560s / 16168.0374 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0162
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3179s / 16274.3553 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0156
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5368s / 16379.8920 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0156
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.4301s / 16486.3221 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0158
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2885s / 16592.6106 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0161
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7943s / 16698.4050 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0166
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2735s / 16803.6785 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0170
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0184s / 16908.6969 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0171
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1273s / 17013.8242 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0176
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2681s / 17118.0923 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0160
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4972s / 17222.5895 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0157
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2601s / 17327.8496 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0145
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6455s / 17433.4951 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0141
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6254s / 17538.1206 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0143
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3811s / 17643.5017 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0159
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6943s / 17749.1959 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0166
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7681s / 17853.9641 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0171
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0130s / 17958.9771 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0168
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0115s / 18064.9886 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0165
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5998s / 18169.5884 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0161
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9463s / 18274.5347 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0160
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7156s / 18380.2503 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0159
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3343s / 18485.5845 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0155
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6442s / 18590.2287 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0156
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9734s / 18696.2021 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0151
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6516s / 18802.8537 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0153
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.0970s / 18908.9507 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0158
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8773s / 19014.8281 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0170
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5821s / 19120.4102 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0178
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.4889s / 19223.8990 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0176
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9375s / 19328.8365 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0168
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1367s / 19433.9732 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0157
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3961s / 19541.3694 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0149
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9222s / 19648.2916 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0149
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2099s / 19752.5015 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0144
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7547s / 19857.2562 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0144
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5489s / 19962.8051 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0145
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2208s / 20069.0259 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0145
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7781s / 20174.8040 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0160
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5266s / 20280.3306 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0170
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4799s / 20384.8105 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0178
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7042s / 20490.5147 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0178
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3399s / 20595.8546 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0172
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9820s / 20700.8366 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0167
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.6871s / 20807.5237 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0165
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1557s / 20912.6793 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0172
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0105s / 21016.6898 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0174
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.9061s / 21123.5959 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0173
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1834s / 21229.7792 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0167
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8256s / 21336.6049 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0166
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9426s / 21441.5475 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0164
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3516s / 21547.8990 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0169
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3667s / 21652.2657 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0168
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4471s / 21757.7128 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0166
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3126s / 21865.0254 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0170
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6741s / 21970.6995 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0166
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6654s / 22076.3649 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0160
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4639s / 22181.8288 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0151
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9370s / 22286.7658 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0149
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5186s / 22392.2844 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0146
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5667s / 22497.8511 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0139
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6652s / 22603.5163 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0135
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6182s / 22709.1345 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0135
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7284s / 22813.8629 s
first_0:                 episode reward: -2.1500,                 loss: nan
second_0:                 episode reward: 2.1500,                 loss: 0.0135
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1143s / 22919.9772 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0137
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.3675s / 23027.3447 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0145
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5601s / 23133.9048 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0149
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8409s / 23238.7457 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0146
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0808s / 23343.8265 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0146
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6883s / 23449.5148 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0148
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3368s / 23554.8516 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0157
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4104s / 23659.2620 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0166
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8278s / 23766.0899 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0176
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5196s / 23871.6095 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0169
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.8634s / 23977.4729 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0164
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6074s / 24083.0804 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0165
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.7098s / 24189.7902 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0164
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.5994s / 24296.3896 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0159
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.9955s / 24404.3851 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0162
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4830s / 24509.8681 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0161
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2850s / 24616.1531 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0163
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3622s / 24722.5153 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0162
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1832s / 24826.6984 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0164
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8763s / 24933.5747 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0171
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4242s / 25038.9990 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0172
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9042s / 25144.9032 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0174
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1377s / 25250.0409 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0179
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2082s / 25355.2491 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0173
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5681s / 25459.8172 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0163
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.1749s / 25565.9921 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0153
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7047s / 25671.6969 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0140
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.1523s / 25778.8491 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0130
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7093s / 25884.5584 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0132
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7988s / 25989.3572 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0160
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9863s / 26094.3435 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0168
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2416s / 26198.5852 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0161
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.8254s / 26305.4105 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0163
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 107.0194s / 26412.4299 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0171
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5506s / 26517.9805 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0172
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.8368s / 26621.8173 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0180
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.7031s / 26727.5204 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0180
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5706s / 26833.0910 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0190
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.4252s / 26936.5162 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0190
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.2725s / 27039.7887 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0184
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.9706s / 27142.7593 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0189
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9808s / 27246.7401 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0187
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.1224s / 27349.8625 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0168
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7273s / 27454.5898 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0165
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.3678s / 27560.9577 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0165
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0836s / 27665.0412 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0168
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.9067s / 27767.9479 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0169
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0188s / 27871.9668 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0170
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5711s / 27976.5378 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0178
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.3338s / 28079.8716 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0177
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6383s / 28183.5100 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0175
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.7848s / 28287.2947 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0171
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6829s / 28390.9777 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0163
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.9148s / 28494.8924 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0162
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.7097s / 28598.6021 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0174
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2005s / 28703.8026 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0179
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3943s / 28809.1969 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0170
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1400s / 28913.3369 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0172
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6729s / 29018.0098 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0169
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9747s / 29122.9844 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0177
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3613s / 29227.3457 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0167
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2557s / 29331.6014 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0168
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9145s / 29436.5159 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0170
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2661s / 29540.7821 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0164
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 102.3601s / 29643.1421 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0161
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5465s / 29747.6886 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0159
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5841s / 29851.2728 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0154
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1581s / 29955.4309 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0155
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8070s / 30060.2379 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0154
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2628s / 30164.5007 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0158
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2676s / 30268.7683 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0157
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.7936s / 30372.5619 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0158
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8527s / 30477.4145 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0160
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1306s / 30581.5452 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0156
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3990s / 30685.9442 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0156
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3221s / 30791.2663 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0154
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.8538s / 30895.1201 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0157
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7877s / 30999.9078 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0158
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6658s / 31103.5736 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0154
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5702s / 31208.1437 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0150
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.0615s / 31311.2052 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0153
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9116s / 31416.1167 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0159
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.1617s / 31519.2784 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0161
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0775s / 31624.3560 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0167
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8640s / 31729.2200 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0164
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.4874s / 31832.7074 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0162
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6604s / 31937.3678 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0163
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.2692s / 32040.6369 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0162
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5120s / 32144.1489 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0160
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6857s / 32247.8346 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0159
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1735s / 32352.0081 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0155
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5462s / 32455.5542 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0150
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.0997s / 32558.6539 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0155
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.8702s / 32663.5241 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0153
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.7476s / 32767.2717 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0150
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5474s / 32872.8191 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0152
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2659s / 32977.0850 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0151
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7134s / 33081.7984 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0154
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.2599s / 33187.0583 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0158
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3739s / 33292.4321 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0157
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.0043s / 33396.4364 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0154
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5030s / 33500.9394 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0155
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7334s / 33605.6728 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0160
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3338s / 33711.0066 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0167
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6097s / 33815.6163 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0173
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.6258s / 33919.2421 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0166
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.1852s / 34024.4273 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0168
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.6516s / 34130.0789 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0166
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 106.2406s / 34236.3195 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0168
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5454s / 34341.8649 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0173
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7380s / 34446.6029 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0179
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4285s / 34551.0315 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0173
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7374s / 34655.7689 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0159
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4188s / 34761.1877 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0155
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7858s / 34865.9735 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0161
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4778s / 34970.4513 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0159
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.1057s / 35074.5570 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0158
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.4206s / 35179.9775 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0161
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.0498s / 35283.0273 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0164
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4161s / 35387.4434 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0161
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3240s / 35492.7674 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0161
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.5818s / 35598.3492 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0162
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.9247s / 35704.2739 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0160
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.3186s / 35809.5925 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0158
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6316s / 35914.2242 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0157
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3002s / 36018.5243 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0159
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4245s / 36122.9488 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0160
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.3458s / 36226.2947 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0158
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6479s / 36330.9426 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0156
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5036s / 36435.4462 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0150
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.9532s / 36540.3995 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0151
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 105.0387s / 36645.4382 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0152
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.7739s / 36750.2121 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0158
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5879s / 36854.8000 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0159
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4268s / 36959.2268 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0160
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.5305s / 37063.7573 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0161
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.2966s / 37168.0539 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0157
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.2262s / 37271.2801 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0159
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 103.5781s / 37374.8583 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0160
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.6337s / 37479.4920 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0162
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3308s / 37583.8228 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0160
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.3292s / 37688.1520 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0157
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 104.4152s / 37792.5672 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0154
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5886s / 37893.1558 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0157
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.5793s / 37991.7351 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0156
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7056s / 38089.4406 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0159
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1606s / 38186.6012 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0160
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.0199s / 38283.6211 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0151
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0152s / 38381.6363 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0144
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4381s / 38479.0743 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0144
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2481s / 38576.3224 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0140
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6995s / 38675.0220 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0140
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0105s / 38773.0324 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0141
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3940s / 38870.4264 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0146
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4538s / 38968.8802 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0143
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6406s / 39066.5208 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0140
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0829s / 39164.6037 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0138
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.7897s / 39261.3934 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0140
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.7980s / 39358.1914 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0140
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4920s / 39455.6835 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0144
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.8572s / 39552.5407 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0147
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5390s / 39650.0797 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0150
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6635s / 39747.7431 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0155
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9547s / 39844.6979 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0154
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7891s / 39942.4869 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0155
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2795s / 40040.7664 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0161
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4768s / 40138.2432 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0157
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4510s / 40235.6942 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0159
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6768s / 40334.3710 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0166
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7926s / 40433.1636 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0166
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1407s / 40531.3043 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0167
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.5243s / 40629.8285 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0167
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5843s / 40727.4128 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0166
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9109s / 40825.3237 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0166
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5000s / 40924.8237 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0159
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4006s / 41022.2243 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0157
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4271s / 41120.6514 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0153
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8103s / 41218.4617 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0149
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9502s / 41315.4119 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0149
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7105s / 41414.1223 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0148
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.6871s / 41510.8094 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0154
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4434s / 41608.2528 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0157
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9671s / 41705.2199 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0158
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4685s / 41803.6883 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0153
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.0955s / 41900.7839 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0154
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2619s / 41998.0458 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0157
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8141s / 42095.8599 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0158
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9621s / 42194.8220 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0152
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.5213s / 42291.3433 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0153
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0538s / 42389.3971 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0156
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8549s / 42487.2520 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0154
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4897s / 42584.7417 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0146
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1210s / 42681.8626 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0142
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5722s / 42779.4348 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0139
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3659s / 42876.8008 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0141
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2789s / 42974.0797 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0139
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3768s / 43071.4565 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0142
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.3048s / 43167.7613 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0142
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9230s / 43264.6844 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0147
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3889s / 43362.0732 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0147
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3263s / 43459.3995 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0150
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2683s / 43556.6678 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0151
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9969s / 43653.6647 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0151
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.9565s / 43749.6212 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0156
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8375s / 43847.4588 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0159
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1791s / 43944.6379 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0160
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1474s / 44042.7852 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0156
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1525s / 44139.9378 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0156
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0399s / 44238.9776 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0154
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.8690s / 44335.8466 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0156
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3321s / 44434.1787 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0158
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6772s / 44531.8560 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0159
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6256s / 44629.4816 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0156
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8905s / 44728.3721 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0157
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1275s / 44826.4996 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0158
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2039s / 44923.7036 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0155
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4065s / 45021.1101 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0153
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.3176s / 45117.4277 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0153
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9894s / 45215.4171 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0159
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7732s / 45313.1903 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0157
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.7963s / 45409.9867 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0162
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4758s / 45509.4625 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0157
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1389s / 45608.6014 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0153
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9178s / 45706.5192 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0150
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1259s / 45804.6451 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0148
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6781s / 45902.3232 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0154
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5719s / 45999.8951 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0154
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9087s / 46096.8038 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0160
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3878s / 46194.1916 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0159
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1707s / 46292.3624 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0149
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8259s / 46390.1882 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0145
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9637s / 46488.1519 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0141
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.2951s / 46584.4470 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0141
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6075s / 46682.0545 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0141
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5493s / 46779.6038 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0138
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7684s / 46877.3723 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0138
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7998s / 46975.1721 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0134
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.1109s / 47073.2830 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0135
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5522s / 47170.8352 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0136
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4148s / 47269.2500 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0136
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7795s / 47367.0294 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0137
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3468s / 47464.3763 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0143
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9997s / 47561.3760 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0142
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.6035s / 47657.9795 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0148
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9950s / 47754.9744 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0148
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5481s / 47852.5225 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0147
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.7297s / 47949.2522 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0154
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.3369s / 48045.5892 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0158
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.4062s / 48141.9954 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0153
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.3456s / 48237.3410 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0148
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0456s / 48335.3866 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0148
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9022s / 48432.2888 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0149
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5872s / 48529.8760 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0152
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.5995s / 48627.4754 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0148
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4932s / 48724.9686 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0147
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1108s / 48822.0794 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0145
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.0992s / 48919.1786 s/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0148
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4739s / 49016.6526 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0148
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1779s / 49113.8305 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0146
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9184s / 49211.7489 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0149
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3338s / 49309.0827 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0148
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.7335s / 49405.8161 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0148
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4496s / 49504.2657 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0151
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.4548s / 49600.7205 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0147
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4895s / 49698.2100 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0141
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0568s / 49796.2668 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0138
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4632s / 49893.7300 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0139
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3177s / 49991.0477 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0139
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.9126s / 50087.9604 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0140
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.6125s / 50186.5729 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0141
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.8102s / 50284.3831 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0145
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1989s / 50381.5820 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0141
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.6921s / 50479.2741 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0140
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.6977s / 50575.9718 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0139
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.5317s / 50672.5035 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0139
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.5054s / 50766.0089 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0134
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.9676s / 50857.9764 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0136
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.3016s / 50951.2780 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0137
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9445s / 51039.2225 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0141
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2838s / 51127.5064 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0140
