agent_args:
  algorithm: PPO
  algorithm_spec:
    episodic_update: true
    gamma: 0.99
    lambda: 0.95
    eps_clip: 0.2
    K_epoch: 4
    GAE: true
train_args:
  batch_size: 128
  max_episodes: 30000
  max_steps_per_episode: 10000
  train_start_frame: 0
  optimizer: adam
  learning_rate: 1e-4
  device: gpu
  update_itr: 1
  log_avg_window: 20
  log_interval: 20
  net_architecture:
    feature:
        hidden_dim_list:
        - 64
        hidden_activation: ReLU
        output_activation: false  
    policy:
      hidden_dim_list:
      - 64
      - 64
      - 64
      hidden_activation: ReLU
      output_activation: Softmax
    value:
      hidden_dim_list:
      - 64
      - 64
      - 64
      hidden_activation: ReLU
      output_activation: false