pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_1518/slimevolley_SlimeVolley-v0_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_1518/slimevolley_SlimeVolley-v0_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 507.0,                last time consumption/overall running time: 16.6935s / 16.6935 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0277
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0302
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 572.0,                last time consumption/overall running time: 486.7100s / 503.4036 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0213
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0211
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 586.05,                last time consumption/overall running time: 516.3323s / 1019.7358 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0255
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 523.0,                last time consumption/overall running time: 480.9021s / 1500.6379 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0253
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 577.25,                last time consumption/overall running time: 551.8096s / 2052.4475 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0251
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 589.6,                last time consumption/overall running time: 589.1797s / 2641.6272 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0248
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 607.8,                last time consumption/overall running time: 635.9180s / 3277.5452 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0245
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 521.95,                last time consumption/overall running time: 570.0863s / 3847.6315 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0238
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 548.35,                last time consumption/overall running time: 627.7265s / 4475.3580 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 590.5,                last time consumption/overall running time: 704.4906s / 5179.8486 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 553.6,                last time consumption/overall running time: 668.1589s / 5848.0075 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 585.6,                last time consumption/overall running time: 709.1374s / 6557.1449 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 547.55,                last time consumption/overall running time: 665.7905s / 7222.9354 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0242
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 591.65,                last time consumption/overall running time: 716.6703s / 7939.6057 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0248
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 602.75,                last time consumption/overall running time: 730.8330s / 8670.4387 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0248
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 557.7,                last time consumption/overall running time: 674.1517s / 9344.5904 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 603.65,                last time consumption/overall running time: 729.0960s / 10073.6864 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 607.6,                last time consumption/overall running time: 734.5237s / 10808.2102 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0248
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 580.6,                last time consumption/overall running time: 702.2226s / 11510.4327 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0250
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 631.75,                last time consumption/overall running time: 763.6269s / 12274.0596 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 552.25,                last time consumption/overall running time: 668.7127s / 12942.7723 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0249
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 626.5,                last time consumption/overall running time: 763.6555s / 13706.4278 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0248
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 614.7,                last time consumption/overall running time: 749.0540s / 14455.4818 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0253
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 548.75,                last time consumption/overall running time: 675.8280s / 15131.3098 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0249
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0250
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 551.05,                last time consumption/overall running time: 677.2192s / 15808.5289 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0250
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0252
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 589.6,                last time consumption/overall running time: 725.3835s / 16533.9124 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0249
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 571.15,                last time consumption/overall running time: 695.2004s / 17229.1129 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0249
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0249
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 619.95,                last time consumption/overall running time: 758.7023s / 17987.8152 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0243
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 603.45,                last time consumption/overall running time: 732.5204s / 18720.3356 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 604.4,                last time consumption/overall running time: 738.4128s / 19458.7484 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 594.8,                last time consumption/overall running time: 727.3058s / 20186.0542 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 636.45,                last time consumption/overall running time: 781.5234s / 20967.5776 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 612.05,                last time consumption/overall running time: 748.9458s / 21716.5234 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0236
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 658.7,                last time consumption/overall running time: 809.1790s / 22525.7024 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0236
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0239
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 608.75,                last time consumption/overall running time: 746.4211s / 23272.1235 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0237
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 622.35,                last time consumption/overall running time: 764.1385s / 24036.2620 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 593.2,                last time consumption/overall running time: 729.1859s / 24765.4479 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0238
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 593.6,                last time consumption/overall running time: 729.0030s / 25494.4510 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0240
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 622.05,                last time consumption/overall running time: 765.6543s / 26260.1052 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0239
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 627.5,                last time consumption/overall running time: 772.8622s / 27032.9674 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0244
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0238
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 610.6,                last time consumption/overall running time: 751.9850s / 27784.9524 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0243
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0235
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 639.55,                last time consumption/overall running time: 788.7983s / 28573.7507 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0238
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 611.85,                last time consumption/overall running time: 753.2991s / 29327.0498 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0231
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0238
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 633.85,                last time consumption/overall running time: 777.2348s / 30104.2847 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0238
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0231
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 668.75,                last time consumption/overall running time: 831.9281s / 30936.2128 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0235
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0239
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 629.95,                last time consumption/overall running time: 781.3794s / 31717.5922 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0233
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0236
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 653.85,                last time consumption/overall running time: 812.5151s / 32530.1074 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0230
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0239
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 654.6,                last time consumption/overall running time: 810.3153s / 33340.4226 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0232
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0241
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 643.05,                last time consumption/overall running time: 793.9858s / 34134.4084 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0235
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0240
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 684.1,                last time consumption/overall running time: 846.4180s / 34980.8265 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0239
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 625.45,                last time consumption/overall running time: 776.5368s / 35757.3632 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0237
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0235
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 617.7,                last time consumption/overall running time: 767.8397s / 36525.2030 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0227
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0232
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 646.75,                last time consumption/overall running time: 800.7625s / 37325.9655 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0224
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0230
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 625.35,                last time consumption/overall running time: 774.7345s / 38100.7000 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0231
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0233
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 607.85,                last time consumption/overall running time: 754.5196s / 38855.2195 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0226
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0228
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 668.05,                last time consumption/overall running time: 832.3127s / 39687.5323 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0223
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0231
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 638.8,                last time consumption/overall running time: 789.8479s / 40477.3802 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0223
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0233
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 675.95,                last time consumption/overall running time: 841.2522s / 41318.6324 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0224
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0226
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 643.5,                last time consumption/overall running time: 798.0174s / 42116.6498 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0225
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0229
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 577.75,                last time consumption/overall running time: 717.8020s / 42834.4518 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0223
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0228
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 603.15,                last time consumption/overall running time: 751.3520s / 43585.8038 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0218
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0223
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 640.2,                last time consumption/overall running time: 800.9769s / 44386.7808 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0222
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0226
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 595.3,                last time consumption/overall running time: 740.0015s / 45126.7823 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0214
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0225
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 632.8,                last time consumption/overall running time: 786.1499s / 45912.9322 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0218
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0221
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 634.75,                last time consumption/overall running time: 790.6300s / 46703.5622 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0215
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0219
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 717.7,                last time consumption/overall running time: 897.3274s / 47600.8896 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0213
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0217
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 680.05,                last time consumption/overall running time: 852.2727s / 48453.1623 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0213
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0218
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 618.1,                last time consumption/overall running time: 770.8066s / 49223.9690 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0214
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0216
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 620.95,                last time consumption/overall running time: 771.1240s / 49995.0929 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0212
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0216
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 654.75,                last time consumption/overall running time: 818.0642s / 50813.1571 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0217
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0213
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 565.75,                last time consumption/overall running time: 705.8458s / 51519.0029 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0208
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0206
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 635.35,                last time consumption/overall running time: 789.1006s / 52308.1034 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0214
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0209
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 719.1,                last time consumption/overall running time: 893.8641s / 53201.9676 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0214
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0206
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 543.1,                last time consumption/overall running time: 679.6464s / 53881.6140 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0206
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0204
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 597.95,                last time consumption/overall running time: 748.6690s / 54630.2830 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0205
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0208
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 619.35,                last time consumption/overall running time: 778.8410s / 55409.1240 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0197
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0199
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 572.1,                last time consumption/overall running time: 721.2519s / 56130.3760 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0197
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0198
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 580.1,                last time consumption/overall running time: 731.1628s / 56861.5387 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0194
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0193
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 567.05,                last time consumption/overall running time: 711.0780s / 57572.6167 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0191
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0197
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 590.65,                last time consumption/overall running time: 738.1414s / 58310.7581 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0194
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0200
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 606.45,                last time consumption/overall running time: 760.3987s / 59071.1569 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0192
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0194
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 628.7,                last time consumption/overall running time: 789.0200s / 59860.1769 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0192
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0196
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 650.85,                last time consumption/overall running time: 821.4361s / 60681.6130 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0192
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0196
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 658.15,                last time consumption/overall running time: 823.2274s / 61504.8404 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0189
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0196
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 596.6,                last time consumption/overall running time: 743.0662s / 62247.9066 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0187
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0197
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 598.15,                last time consumption/overall running time: 752.8925s / 63000.7991 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0187
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0194
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 599.45,                last time consumption/overall running time: 752.5113s / 63753.3103 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0188
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0193
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 564.8,                last time consumption/overall running time: 708.4950s / 64461.8053 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0188
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0192
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 618.3,                last time consumption/overall running time: 776.2688s / 65238.0741 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0189
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0190
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 630.45,                last time consumption/overall running time: 789.1142s / 66027.1884 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0183
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0195
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 597.8,                last time consumption/overall running time: 748.2380s / 66775.4263 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0187
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0199
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 610.65,                last time consumption/overall running time: 765.6824s / 67541.1087 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0187
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0196
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 601.8,                last time consumption/overall running time: 763.1435s / 68304.2522 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0187
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0192
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 618.15,                last time consumption/overall running time: 785.7147s / 69089.9669 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0188
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0191
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 605.2,                last time consumption/overall running time: 766.0332s / 69856.0001 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0186
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0186
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 610.4,                last time consumption/overall running time: 771.4355s / 70627.4356 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0187
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0189
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 614.9,                last time consumption/overall running time: 776.5604s / 71403.9961 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0185
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0187
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 711.35,                last time consumption/overall running time: 892.2587s / 72296.2547 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0178
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0185
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 639.0,                last time consumption/overall running time: 806.3905s / 73102.6452 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0177
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0187
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 642.1,                last time consumption/overall running time: 808.4565s / 73911.1017 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0181
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0188
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 657.45,                last time consumption/overall running time: 826.8793s / 74737.9810 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0183
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0186
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 651.5,                last time consumption/overall running time: 814.1705s / 75552.1514 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0187
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0190
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 605.65,                last time consumption/overall running time: 758.3318s / 76310.4832 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0193
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0191
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 667.2,                last time consumption/overall running time: 839.4917s / 77149.9749 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0189
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0194
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 571.75,                last time consumption/overall running time: 725.1480s / 77875.1229 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0189
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0193
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 631.95,                last time consumption/overall running time: 794.2592s / 78669.3821 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0187
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0194
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 634.9,                last time consumption/overall running time: 798.9604s / 79468.3425 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0191
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0197
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 619.65,                last time consumption/overall running time: 783.1153s / 80251.4578 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0185
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0191
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 599.35,                last time consumption/overall running time: 754.8359s / 81006.2937 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0187
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0192
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 642.65,                last time consumption/overall running time: 810.0342s / 81816.3279 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0182
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0187
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 664.9,                last time consumption/overall running time: 832.2239s / 82648.5518 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0185
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0185
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 632.05,                last time consumption/overall running time: 798.5908s / 83447.1425 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0183
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0183
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 626.05,                last time consumption/overall running time: 794.6084s / 84241.7509 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0179
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0185
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 652.5,                last time consumption/overall running time: 826.3893s / 85068.1402 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0181
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0188
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 614.05,                last time consumption/overall running time: 780.4904s / 85848.6306 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0180
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0185
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 574.85,                last time consumption/overall running time: 730.9000s / 86579.5306 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0178
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0187
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 622.1,                last time consumption/overall running time: 786.2245s / 87365.7551 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0180
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0189
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 614.8,                last time consumption/overall running time: 781.4778s / 88147.2329 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0180
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0188
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 619.9,                last time consumption/overall running time: 783.2766s / 88930.5095 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0179
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0186
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 655.8,                last time consumption/overall running time: 827.9858s / 89758.4954 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0182
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0186
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 586.1,                last time consumption/overall running time: 739.9977s / 90498.4931 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0179
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0185
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 709.15,                last time consumption/overall running time: 896.5602s / 91395.0533 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0179
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0181
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 647.25,                last time consumption/overall running time: 820.1109s / 92215.1643 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0180
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0180
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 699.6,                last time consumption/overall running time: 884.0337s / 93099.1980 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0186
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0185
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 651.7,                last time consumption/overall running time: 826.6320s / 93925.8300 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0181
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0190
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 627.65,                last time consumption/overall running time: 792.3519s / 94718.1819 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0185
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0194
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 617.95,                last time consumption/overall running time: 776.5328s / 95494.7147 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0185
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0189
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 606.35,                last time consumption/overall running time: 767.5629s / 96262.2775 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0186
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0188
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 584.05,                last time consumption/overall running time: 737.6723s / 96999.9498 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0187
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0186
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 628.05,                last time consumption/overall running time: 794.6524s / 97794.6022 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0183
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0186
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 635.5,                last time consumption/overall running time: 800.7810s / 98595.3832 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0183
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0185
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 608.95,                last time consumption/overall running time: 770.7194s / 99366.1026 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0180
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0182
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 660.7,                last time consumption/overall running time: 837.4293s / 100203.5319 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0178
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0180
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 646.25,                last time consumption/overall running time: 823.7579s / 101027.2898 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0176
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0178
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 697.4,                last time consumption/overall running time: 886.0651s / 101913.3548 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0174
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 655.8,                last time consumption/overall running time: 834.9162s / 102748.2710 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0167
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0172
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 673.55,                last time consumption/overall running time: 846.3213s / 103594.5923 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0165
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0171
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 609.35,                last time consumption/overall running time: 768.8846s / 104363.4770 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0165
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0170
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 594.1,                last time consumption/overall running time: 750.2084s / 105113.6854 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0163
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0167
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 619.1,                last time consumption/overall running time: 782.5609s / 105896.2463 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0161
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0167
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 646.35,                last time consumption/overall running time: 816.1777s / 106712.4240 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0166
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0167
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 667.45,                last time consumption/overall running time: 844.9578s / 107557.3818 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0169
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0168
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 617.1,                last time consumption/overall running time: 780.3813s / 108337.7631 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0168
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0170
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 631.15,                last time consumption/overall running time: 800.1978s / 109137.9609 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0167
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0167
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 716.7,                last time consumption/overall running time: 900.5142s / 110038.4751 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0169
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0170
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 669.05,                last time consumption/overall running time: 843.1736s / 110881.6488 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0171
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0175
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 698.6,                last time consumption/overall running time: 881.8356s / 111763.4844 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0169
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0176
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 718.5,                last time consumption/overall running time: 907.3294s / 112670.8137 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0174
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 658.45,                last time consumption/overall running time: 836.1615s / 113506.9753 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0168
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0170
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 668.3,                last time consumption/overall running time: 846.6672s / 114353.6425 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0164
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0169
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 642.9,                last time consumption/overall running time: 808.8737s / 115162.5162 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0163
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0167
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 683.45,                last time consumption/overall running time: 863.1944s / 116025.7106 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0167
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0174
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 620.7,                last time consumption/overall running time: 786.3131s / 116812.0237 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0166
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0169
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 688.3,                last time consumption/overall running time: 864.0299s / 117676.0536 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0171
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0170
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 622.3,                last time consumption/overall running time: 786.4948s / 118462.5484 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0172
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0172
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 690.0,                last time consumption/overall running time: 876.7028s / 119339.2512 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0166
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0175
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 694.1,                last time consumption/overall running time: 879.6219s / 120218.8731 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0169
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0171
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 634.4,                last time consumption/overall running time: 800.3498s / 121019.2228 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0170
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0174
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 635.3,                last time consumption/overall running time: 803.7207s / 121822.9435 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0173
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0175
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 641.75,                last time consumption/overall running time: 812.1665s / 122635.1100 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0172
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0173
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 653.35,                last time consumption/overall running time: 829.8894s / 123464.9995 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0171
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 627.85,                last time consumption/overall running time: 792.3646s / 124257.3641 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0167
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0171
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 625.45,                last time consumption/overall running time: 793.3646s / 125050.7287 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0168
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0172
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 639.0,                last time consumption/overall running time: 806.2352s / 125856.9639 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0170
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0176
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 710.95,                last time consumption/overall running time: 901.9787s / 126758.9425 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0168
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0174
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 642.45,                last time consumption/overall running time: 809.1577s / 127568.1002 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0171
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0172
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 663.45,                last time consumption/overall running time: 834.0810s / 128402.1812 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0171
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0174
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 629.15,                last time consumption/overall running time: 790.4920s / 129192.6732 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0173
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0169
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 653.5,                last time consumption/overall running time: 830.0764s / 130022.7496 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0172
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0169
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 630.35,                last time consumption/overall running time: 793.6766s / 130816.4262 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0168
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0170
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 705.9,                last time consumption/overall running time: 889.0873s / 131705.5136 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0166
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0168
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 709.85,                last time consumption/overall running time: 895.1169s / 132600.6305 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0166
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0169
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 714.7,                last time consumption/overall running time: 900.2826s / 133500.9130 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0165
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0168
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 692.95,                last time consumption/overall running time: 871.9613s / 134372.8743 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0159
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0166
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 677.45,                last time consumption/overall running time: 852.4515s / 135225.3258 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0161
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0166
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 690.7,                last time consumption/overall running time: 866.7434s / 136092.0692 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0157
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0165
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 669.6,                last time consumption/overall running time: 842.8753s / 136934.9445 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0161
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0165
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 662.85,                last time consumption/overall running time: 835.5465s / 137770.4910 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0162
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0162
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 704.05,                last time consumption/overall running time: 886.4350s / 138656.9259 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0159
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 681.3,                last time consumption/overall running time: 858.3345s / 139515.2604 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0162
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0159
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 698.65,                last time consumption/overall running time: 884.8257s / 140400.0861 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0165
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0161
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 635.85,                last time consumption/overall running time: 805.3388s / 141205.4249 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0161
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0162
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 621.4,                last time consumption/overall running time: 785.9316s / 141991.3565 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0159
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0158
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 702.85,                last time consumption/overall running time: 889.3045s / 142880.6610 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0159
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0160
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 697.4,                last time consumption/overall running time: 883.3965s / 143764.0575 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0156
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0159
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 639.25,                last time consumption/overall running time: 807.7254s / 144571.7828 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0151
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0154
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 639.55,                last time consumption/overall running time: 810.9349s / 145382.7177 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0154
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0156
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 670.15,                last time consumption/overall running time: 845.4763s / 146228.1940 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0152
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0151
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 664.4,                last time consumption/overall running time: 842.2567s / 147070.4507 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0148
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0152
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 629.15,                last time consumption/overall running time: 791.5779s / 147862.0286 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0155
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0155
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 704.4,                last time consumption/overall running time: 886.8189s / 148748.8475 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0156
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0153
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 649.5,                last time consumption/overall running time: 816.0015s / 149564.8490 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0153
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0153
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 707.55,                last time consumption/overall running time: 888.8693s / 150453.7183 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0157
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0155
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 629.65,                last time consumption/overall running time: 792.7531s / 151246.4714 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0159
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0157
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 773.8,                last time consumption/overall running time: 971.1292s / 152217.6006 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0158
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 637.95,                last time consumption/overall running time: 802.7316s / 153020.3322 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0158
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0160
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 694.2,                last time consumption/overall running time: 873.0275s / 153893.3597 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0160
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 675.1,                last time consumption/overall running time: 853.6777s / 154747.0374 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0157
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0162
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 704.65,                last time consumption/overall running time: 894.7106s / 155641.7479 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0159
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0161
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 675.8,                last time consumption/overall running time: 856.5536s / 156498.3015 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0160
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0161
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 721.8,                last time consumption/overall running time: 912.0700s / 157410.3715 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0157
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0160
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 686.05,                last time consumption/overall running time: 862.9858s / 158273.3574 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0152
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0161
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 703.7,                last time consumption/overall running time: 887.0221s / 159160.3794 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0155
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0160
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 700.8,                last time consumption/overall running time: 883.9291s / 160044.3085 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0154
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0159
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 648.4,                last time consumption/overall running time: 823.0692s / 160867.3778 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0151
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0155
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 647.5,                last time consumption/overall running time: 817.5376s / 161684.9153 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0151
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0156
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 653.6,                last time consumption/overall running time: 824.1996s / 162509.1149 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0149
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0153
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 665.35,                last time consumption/overall running time: 836.6334s / 163345.7483 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0152
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0151
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 705.45,                last time consumption/overall running time: 886.4755s / 164232.2238 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0151
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 657.25,                last time consumption/overall running time: 827.2682s / 165059.4920 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0147
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0152
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 656.8,                last time consumption/overall running time: 827.8127s / 165887.3047 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0148
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0149
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 651.1,                last time consumption/overall running time: 815.0080s / 166702.3127 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0146
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0146
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 717.05,                last time consumption/overall running time: 898.3256s / 167600.6383 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0149
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 693.2,                last time consumption/overall running time: 870.1048s / 168470.7431 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0147
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 675.3,                last time consumption/overall running time: 851.3395s / 169322.0825 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0151
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 706.2,                last time consumption/overall running time: 890.9671s / 170213.0497 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 651.55,                last time consumption/overall running time: 825.9032s / 171038.9528 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0149
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 674.8,                last time consumption/overall running time: 854.9311s / 171893.8839 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0147
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0147
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 668.45,                last time consumption/overall running time: 845.7755s / 172739.6594 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0147
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 692.35,                last time consumption/overall running time: 870.8915s / 173610.5509 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0152
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 600.5,                last time consumption/overall running time: 755.0458s / 174365.5967 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0150
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 687.05,                last time consumption/overall running time: 865.1468s / 175230.7435 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0151
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0151
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 686.45,                last time consumption/overall running time: 864.9424s / 176095.6860 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0146
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0147
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 749.7,                last time consumption/overall running time: 947.6565s / 177043.3425 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0146
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 642.15,                last time consumption/overall running time: 807.2610s / 177850.6035 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0149
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0149
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 712.25,                last time consumption/overall running time: 896.5718s / 178747.1753 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0150
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0148
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 706.95,                last time consumption/overall running time: 887.8997s / 179635.0749 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0149
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0146
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 675.5,                last time consumption/overall running time: 848.9593s / 180484.0342 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0148
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0147
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 707.35,                last time consumption/overall running time: 888.4566s / 181372.4908 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0147
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0148
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 704.45,                last time consumption/overall running time: 889.2151s / 182261.7059 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0148
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0153
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 698.95,                last time consumption/overall running time: 884.9093s / 183146.6152 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0147
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 682.7,                last time consumption/overall running time: 864.5315s / 184011.1467 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0146
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0147
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 725.75,                last time consumption/overall running time: 916.3976s / 184927.5443 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0145
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 716.95,                last time consumption/overall running time: 900.4210s / 185827.9653 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0144
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 682.25,                last time consumption/overall running time: 861.4494s / 186689.4147 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0143
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 686.0,                last time consumption/overall running time: 859.1187s / 187548.5334 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0140
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 768.6,                last time consumption/overall running time: 966.8364s / 188515.3697 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0140
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 697.25,                last time consumption/overall running time: 883.8039s / 189399.1736 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0143
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 668.25,                last time consumption/overall running time: 840.8153s / 190239.9889 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0145
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0149
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 655.9,                last time consumption/overall running time: 822.0614s / 191062.0502 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0148
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0153
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 632.35,                last time consumption/overall running time: 787.1370s / 191849.1872 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0152
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0155
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 662.4,                last time consumption/overall running time: 828.7632s / 192677.9504 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0151
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0153
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 674.2,                last time consumption/overall running time: 837.2920s / 193515.2424 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0154
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 654.0,                last time consumption/overall running time: 813.4089s / 194328.6512 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0151
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 728.8,                last time consumption/overall running time: 910.7418s / 195239.3930 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0146
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0146
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 684.05,                last time consumption/overall running time: 858.7488s / 196098.1419 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0144
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0144
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 725.2,                last time consumption/overall running time: 916.3683s / 197014.5102 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0143
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 692.6,                last time consumption/overall running time: 866.9569s / 197881.4671 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0142
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0139
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 752.85,                last time consumption/overall running time: 944.1313s / 198825.5984 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0145
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0143
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 678.75,                last time consumption/overall running time: 852.6789s / 199678.2774 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0143
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 726.25,                last time consumption/overall running time: 900.8880s / 200579.1654 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0144
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 678.45,                last time consumption/overall running time: 847.7270s / 201426.8924 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 714.6,                last time consumption/overall running time: 893.7060s / 202320.5984 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0144
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 657.7,                last time consumption/overall running time: 823.1496s / 203143.7480 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0139
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0145
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 678.65,                last time consumption/overall running time: 850.7312s / 203994.4792 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0146
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 700.15,                last time consumption/overall running time: 876.9773s / 204871.4565 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0145
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0145
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 676.1,                last time consumption/overall running time: 843.2191s / 205714.6756 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0149
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 749.55,                last time consumption/overall running time: 932.2460s / 206646.9216 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0147
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 622.6,                last time consumption/overall running time: 774.5385s / 207421.4601 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0148
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 681.15,                last time consumption/overall running time: 848.9905s / 208270.4505 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0142
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 711.15,                last time consumption/overall running time: 892.4057s / 209162.8563 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0145
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 688.3,                last time consumption/overall running time: 853.9949s / 210016.8511 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0144
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 710.2,                last time consumption/overall running time: 887.3163s / 210904.1674 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0145
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 675.8,                last time consumption/overall running time: 848.3219s / 211752.4893 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0145
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0148
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 701.25,                last time consumption/overall running time: 885.7355s / 212638.2248 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0149
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0150
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 766.3,                last time consumption/overall running time: 953.7509s / 213591.9757 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0148
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0150
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 694.45,                last time consumption/overall running time: 864.8234s / 214456.7991 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0154
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0152
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 711.6,                last time consumption/overall running time: 890.8968s / 215347.6959 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0153
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 672.2,                last time consumption/overall running time: 846.1985s / 216193.8944 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0152
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0154
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 670.25,                last time consumption/overall running time: 836.9719s / 217030.8663 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0152
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0152
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 653.45,                last time consumption/overall running time: 829.9320s / 217860.7983 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 693.55,                last time consumption/overall running time: 873.6872s / 218734.4855 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0146
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0147
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 717.65,                last time consumption/overall running time: 895.9444s / 219630.4299 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0147
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 642.1,                last time consumption/overall running time: 792.5603s / 220422.9902 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0144
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 609.9,                last time consumption/overall running time: 752.0402s / 221175.0304 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0143
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0144
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 649.9,                last time consumption/overall running time: 800.1899s / 221975.2203 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0140
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 645.45,                last time consumption/overall running time: 791.1177s / 222766.3380 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 699.65,                last time consumption/overall running time: 864.1273s / 223630.4653 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0142
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0144
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 623.8,                last time consumption/overall running time: 765.8374s / 224396.3027 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0142
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 713.4,                last time consumption/overall running time: 876.1395s / 225272.4421 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0139
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 663.9,                last time consumption/overall running time: 810.2051s / 226082.6472 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0138
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 678.4,                last time consumption/overall running time: 833.2498s / 226915.8970 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0136
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 659.3,                last time consumption/overall running time: 809.7345s / 227725.6315 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0135
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 729.75,                last time consumption/overall running time: 896.4393s / 228622.0709 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0137
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 705.4,                last time consumption/overall running time: 859.5300s / 229481.6009 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 625.4,                last time consumption/overall running time: 761.7200s / 230243.3208 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0137
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 673.15,                last time consumption/overall running time: 830.7405s / 231074.0614 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 659.15,                last time consumption/overall running time: 812.6293s / 231886.6907 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0140
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0137
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 675.2,                last time consumption/overall running time: 832.6154s / 232719.3061 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0144
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0138
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 635.45,                last time consumption/overall running time: 781.7992s / 233501.1053 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0142
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 703.05,                last time consumption/overall running time: 859.7918s / 234360.8971 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0138
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 725.65,                last time consumption/overall running time: 891.2443s / 235252.1414 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0144
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 743.25,                last time consumption/overall running time: 910.5342s / 236162.6756 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0140
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 706.45,                last time consumption/overall running time: 861.0094s / 237023.6849 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 636.1,                last time consumption/overall running time: 779.9239s / 237803.6088 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0145
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 641.65,                last time consumption/overall running time: 790.6406s / 238594.2494 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 678.3,                last time consumption/overall running time: 830.5541s / 239424.8036 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0148
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0145
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 653.75,                last time consumption/overall running time: 800.8310s / 240225.6346 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0150
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0149
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 678.45,                last time consumption/overall running time: 850.7584s / 241076.3930 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0148
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 675.55,                last time consumption/overall running time: 830.6386s / 241907.0316 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0147
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0144
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 596.65,                last time consumption/overall running time: 731.3552s / 242638.3868 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0146
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0147
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 621.2,                last time consumption/overall running time: 756.8415s / 243395.2283 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 686.35,                last time consumption/overall running time: 837.2882s / 244232.5165 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 725.0,                last time consumption/overall running time: 891.1411s / 245123.6576 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 659.25,                last time consumption/overall running time: 821.1763s / 245944.8340 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 768.5,                last time consumption/overall running time: 941.9213s / 246886.7553 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 656.9,                last time consumption/overall running time: 810.2928s / 247697.0480 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0132
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 669.95,                last time consumption/overall running time: 816.6954s / 248513.7434 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0132
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 626.95,                last time consumption/overall running time: 771.7186s / 249285.4620 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0129
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0129
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 721.95,                last time consumption/overall running time: 881.2861s / 250166.7482 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0129
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 690.15,                last time consumption/overall running time: 847.6448s / 251014.3929 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0128
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 725.75,                last time consumption/overall running time: 882.0659s / 251896.4588 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0130
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 605.1,                last time consumption/overall running time: 737.6934s / 252634.1522 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0130
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0128
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 634.05,                last time consumption/overall running time: 774.2585s / 253408.4107 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 685.45,                last time consumption/overall running time: 841.3073s / 254249.7179 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0136
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0131
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 715.5,                last time consumption/overall running time: 877.8728s / 255127.5908 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0136
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 707.8,                last time consumption/overall running time: 867.7527s / 255995.3434 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0134
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 650.55,                last time consumption/overall running time: 794.3020s / 256789.6454 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0143
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0137
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 691.3,                last time consumption/overall running time: 840.7366s / 257630.3821 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0140
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 674.15,                last time consumption/overall running time: 825.0664s / 258455.4485 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0138
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 684.8,                last time consumption/overall running time: 834.3132s / 259289.7617 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 698.25,                last time consumption/overall running time: 849.4601s / 260139.2218 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 644.4,                last time consumption/overall running time: 792.0888s / 260931.3106 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0138
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 693.35,                last time consumption/overall running time: 849.0824s / 261780.3930 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 689.6,                last time consumption/overall running time: 842.2867s / 262622.6798 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0134
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 727.1,                last time consumption/overall running time: 895.6834s / 263518.3632 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0132
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0130
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 736.15,                last time consumption/overall running time: 927.0067s / 264445.3699 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0129
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0127
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 689.05,                last time consumption/overall running time: 846.6002s / 265291.9701 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0129
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0126
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 636.0,                last time consumption/overall running time: 784.8216s / 266076.7917 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0125
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0125
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 677.25,                last time consumption/overall running time: 839.7709s / 266916.5627 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0124
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0123
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 652.9,                last time consumption/overall running time: 807.1485s / 267723.7112 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0126
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0126
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 673.6,                last time consumption/overall running time: 850.7232s / 268574.4344 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0124
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0128
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 700.5,                last time consumption/overall running time: 853.9397s / 269428.3742 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0124
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0124
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 733.6,                last time consumption/overall running time: 895.1816s / 270323.5558 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0127
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0128
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 669.3,                last time consumption/overall running time: 818.3656s / 271141.9213 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0132
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 703.25,                last time consumption/overall running time: 858.2945s / 272000.2158 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0135
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0136
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 689.3,                last time consumption/overall running time: 839.7852s / 272840.0011 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0133
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 662.3,                last time consumption/overall running time: 833.0808s / 273673.0819 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 656.5,                last time consumption/overall running time: 829.8402s / 274502.9220 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 692.1,                last time consumption/overall running time: 848.1529s / 275351.0750 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0142
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0143
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 662.2,                last time consumption/overall running time: 813.9723s / 276165.0473 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0144
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 676.4,                last time consumption/overall running time: 823.9821s / 276989.0294 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0144
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0143
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 682.45,                last time consumption/overall running time: 826.3207s / 277815.3501 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0145
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0144
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 670.3,                last time consumption/overall running time: 814.0879s / 278629.4379 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0147
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0145
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 648.75,                last time consumption/overall running time: 786.0377s / 279415.4757 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0144
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 691.25,                last time consumption/overall running time: 840.4991s / 280255.9748 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0145
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0140
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 718.2,                last time consumption/overall running time: 881.2524s / 281137.2272 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0142
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0143
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 607.5,                last time consumption/overall running time: 760.0340s / 281897.2613 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0139
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0141
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 621.9,                last time consumption/overall running time: 756.1460s / 282653.4073 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0137
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0140
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 671.2,                last time consumption/overall running time: 815.1718s / 283468.5791 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0135
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 706.6,                last time consumption/overall running time: 855.6642s / 284324.2433 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 722.7,                last time consumption/overall running time: 875.1775s / 285199.4209 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0134
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0132
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 706.0,                last time consumption/overall running time: 870.4550s / 286069.8758 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 717.8,                last time consumption/overall running time: 886.6608s / 286956.5366 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0134
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 654.6,                last time consumption/overall running time: 800.1562s / 287756.6929 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0132
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 663.1,                last time consumption/overall running time: 810.1215s / 288566.8144 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0135
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 651.05,                last time consumption/overall running time: 793.7940s / 289360.6083 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0136
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 694.0,                last time consumption/overall running time: 852.7227s / 290213.3311 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 696.15,                last time consumption/overall running time: 858.2506s / 291071.5817 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 678.95,                last time consumption/overall running time: 827.6333s / 291899.2150 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0135
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0139
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 714.5,                last time consumption/overall running time: 865.8812s / 292765.0962 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0133
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0133
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 672.05,                last time consumption/overall running time: 832.1938s / 293597.2900 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0131
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0130
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 721.6,                last time consumption/overall running time: 888.9202s / 294486.2103 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 735.3,                last time consumption/overall running time: 911.1704s / 295397.3806 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0130
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 667.1,                last time consumption/overall running time: 815.0153s / 296212.3959 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0129
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 706.85,                last time consumption/overall running time: 881.7272s / 297094.1231 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0131
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0124
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 647.2,                last time consumption/overall running time: 797.8454s / 297891.9685 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0126
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 668.3,                last time consumption/overall running time: 823.0110s / 298714.9795 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0125
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 672.6,                last time consumption/overall running time: 852.2897s / 299567.2692 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0136
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0129
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 688.8,                last time consumption/overall running time: 856.5205s / 300423.7897 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 666.0,                last time consumption/overall running time: 821.4668s / 301245.2566 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0131
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0132
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 719.45,                last time consumption/overall running time: 882.7827s / 302128.0393 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0132
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 656.75,                last time consumption/overall running time: 802.2308s / 302930.2701 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0130
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0131
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 678.95,                last time consumption/overall running time: 846.1871s / 303776.4572 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0131
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 639.45,                last time consumption/overall running time: 834.5179s / 304610.9751 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0131
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0131
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 694.8,                last time consumption/overall running time: 855.7874s / 305466.7625 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0128
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0129
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 643.5,                last time consumption/overall running time: 786.2995s / 306253.0620 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0128
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0126
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 657.8,                last time consumption/overall running time: 810.8801s / 307063.9421 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0130
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 692.05,                last time consumption/overall running time: 848.9748s / 307912.9170 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0128
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0127
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 659.15,                last time consumption/overall running time: 802.8923s / 308715.8093 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0124
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 689.2,                last time consumption/overall running time: 848.2846s / 309564.0939 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0131
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 699.1,                last time consumption/overall running time: 853.0604s / 310417.1543 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0127
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 712.5,                last time consumption/overall running time: 875.2627s / 311292.4170 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0127
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 720.45,                last time consumption/overall running time: 889.4103s / 312181.8273 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 724.4,                last time consumption/overall running time: 899.8531s / 313081.6804 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0134
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 670.35,                last time consumption/overall running time: 824.6289s / 313906.3093 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0137
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 700.4,                last time consumption/overall running time: 851.2400s / 314757.5493 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0140
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0137
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 733.1,                last time consumption/overall running time: 901.5431s / 315659.0924 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0142
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 712.35,                last time consumption/overall running time: 881.0256s / 316540.1180 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 741.7,                last time consumption/overall running time: 907.4860s / 317447.6041 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0138
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 638.85,                last time consumption/overall running time: 789.3050s / 318236.9090 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0136
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0134
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 740.8,                last time consumption/overall running time: 903.2339s / 319140.1429 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0138
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0139
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 689.7,                last time consumption/overall running time: 843.8278s / 319983.9707 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 662.2,                last time consumption/overall running time: 805.2741s / 320789.2447 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0138
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0138
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 664.4,                last time consumption/overall running time: 809.2837s / 321598.5284 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0137
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 742.4,                last time consumption/overall running time: 908.8588s / 322507.3873 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0136
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 738.0,                last time consumption/overall running time: 903.0790s / 323410.4663 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 654.8,                last time consumption/overall running time: 807.4621s / 324217.9284 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0133
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 709.75,                last time consumption/overall running time: 868.2590s / 325086.1874 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0128
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 671.6,                last time consumption/overall running time: 817.5263s / 325903.7137 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0132
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 777.8,                last time consumption/overall running time: 943.7590s / 326847.4727 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 714.15,                last time consumption/overall running time: 878.8681s / 327726.3408 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 619.7,                last time consumption/overall running time: 759.7139s / 328486.0546 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 689.95,                last time consumption/overall running time: 846.4036s / 329332.4582 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0128
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 728.5,                last time consumption/overall running time: 889.3917s / 330221.8499 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0136
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0134
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 650.95,                last time consumption/overall running time: 807.8631s / 331029.7130 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0136
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0132
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 602.5,                last time consumption/overall running time: 730.6536s / 331760.3666 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0134
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 654.1,                last time consumption/overall running time: 794.1164s / 332554.4830 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 700.2,                last time consumption/overall running time: 850.7764s / 333405.2594 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 706.8,                last time consumption/overall running time: 861.5401s / 334266.7995 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0135
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0139
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 628.8,                last time consumption/overall running time: 776.4738s / 335043.2733 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0140
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 738.9,                last time consumption/overall running time: 914.3496s / 335957.6229 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0138
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 641.8,                last time consumption/overall running time: 785.2709s / 336742.8938 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0139
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0138
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 740.5,                last time consumption/overall running time: 909.8684s / 337652.7622 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0142
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 661.4,                last time consumption/overall running time: 811.3655s / 338464.1277 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0138
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0140
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 725.2,                last time consumption/overall running time: 896.2858s / 339360.4135 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0137
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 736.25,                last time consumption/overall running time: 909.1020s / 340269.5155 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0133
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0132
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 706.65,                last time consumption/overall running time: 877.9412s / 341147.4567 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0131
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 683.75,                last time consumption/overall running time: 844.0604s / 341991.5171 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0134
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 711.55,                last time consumption/overall running time: 902.2436s / 342893.7607 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0134
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 762.65,                last time consumption/overall running time: 936.2545s / 343830.0153 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0130
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0130
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 671.65,                last time consumption/overall running time: 817.5595s / 344647.5747 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0129
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 644.0,                last time consumption/overall running time: 783.4261s / 345431.0009 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0128
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 643.75,                last time consumption/overall running time: 781.3214s / 346212.3223 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0130
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 717.35,                last time consumption/overall running time: 879.1426s / 347091.4648 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0131
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 720.85,                last time consumption/overall running time: 886.6763s / 347978.1411 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 666.3,                last time consumption/overall running time: 827.6244s / 348805.7654 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0138
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0137
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 655.65,                last time consumption/overall running time: 804.8950s / 349610.6604 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0143
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0138
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 720.85,                last time consumption/overall running time: 901.2764s / 350511.9368 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0140
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 669.65,                last time consumption/overall running time: 814.9270s / 351326.8639 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0139
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0141
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 689.2,                last time consumption/overall running time: 845.3996s / 352172.2635 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0141
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 709.15,                last time consumption/overall running time: 903.4440s / 353075.7075 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0143
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 652.05,                last time consumption/overall running time: 814.9763s / 353890.6839 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0143
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 733.35,                last time consumption/overall running time: 911.8543s / 354802.5382 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0137
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 717.2,                last time consumption/overall running time: 896.7784s / 355699.3166 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0134
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 705.4,                last time consumption/overall running time: 877.8360s / 356577.1526 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 709.3,                last time consumption/overall running time: 873.4141s / 357450.5667 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0129
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 702.45,                last time consumption/overall running time: 857.8354s / 358308.4021 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0130
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 651.1,                last time consumption/overall running time: 793.6581s / 359102.0602 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0132
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 655.55,                last time consumption/overall running time: 802.2500s / 359904.3102 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0130
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0133
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 661.0,                last time consumption/overall running time: 814.4108s / 360718.7210 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0132
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 632.55,                last time consumption/overall running time: 773.6513s / 361492.3723 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0131
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 694.9,                last time consumption/overall running time: 848.7389s / 362341.1112 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0127
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 732.95,                last time consumption/overall running time: 893.6622s / 363234.7734 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0131
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 672.6,                last time consumption/overall running time: 819.5452s / 364054.3186 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 684.9,                last time consumption/overall running time: 841.0193s / 364895.3380 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0128
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 634.2,                last time consumption/overall running time: 783.4542s / 365678.7921 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0129
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0130
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 683.7,                last time consumption/overall running time: 837.2377s / 366516.0299 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 655.3,                last time consumption/overall running time: 798.9948s / 367315.0246 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0132
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 717.55,                last time consumption/overall running time: 870.7320s / 368185.7567 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0135
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0134
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 698.5,                last time consumption/overall running time: 854.1798s / 369039.9365 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 674.55,                last time consumption/overall running time: 824.6478s / 369864.5842 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0136
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 657.45,                last time consumption/overall running time: 802.8595s / 370667.4437 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 646.9,                last time consumption/overall running time: 794.9419s / 371462.3856 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0131
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 724.85,                last time consumption/overall running time: 889.7647s / 372352.1503 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0130
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0134
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 639.15,                last time consumption/overall running time: 788.4321s / 373140.5824 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0127
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 697.05,                last time consumption/overall running time: 854.8278s / 373995.4102 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0136
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 635.05,                last time consumption/overall running time: 777.1800s / 374772.5902 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0127
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0133
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 625.7,                last time consumption/overall running time: 770.2372s / 375542.8274 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0126
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0131
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 609.45,                last time consumption/overall running time: 749.9001s / 376292.7275 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0126
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0130
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 662.15,                last time consumption/overall running time: 814.2602s / 377106.9877 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0126
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0132
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 650.25,                last time consumption/overall running time: 804.7354s / 377911.7230 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0128
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0132
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 668.15,                last time consumption/overall running time: 819.9021s / 378731.6251 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0134
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 671.25,                last time consumption/overall running time: 817.6896s / 379549.3147 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 653.35,                last time consumption/overall running time: 802.5866s / 380351.9013 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0131
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 672.6,                last time consumption/overall running time: 821.1400s / 381173.0413 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0133
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 696.0,                last time consumption/overall running time: 861.5652s / 382034.6064 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0133
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 644.85,                last time consumption/overall running time: 789.3895s / 382823.9959 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0134
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 663.05,                last time consumption/overall running time: 812.1853s / 383636.1812 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0132
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0136
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 707.75,                last time consumption/overall running time: 863.6578s / 384499.8390 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 695.0,                last time consumption/overall running time: 847.4331s / 385347.2721 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0135
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 619.7,                last time consumption/overall running time: 756.2748s / 386103.5470 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0132
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0139
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 652.15,                last time consumption/overall running time: 794.1417s / 386897.6887 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0131
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0139
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 630.7,                last time consumption/overall running time: 765.0498s / 387662.7385 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0133
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 648.95,                last time consumption/overall running time: 792.5979s / 388455.3364 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0130
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0135
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 705.4,                last time consumption/overall running time: 866.1509s / 389321.4873 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0132
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0135
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 660.4,                last time consumption/overall running time: 811.8717s / 390133.3590 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0133
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 679.55,                last time consumption/overall running time: 822.5470s / 390955.9060 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0137
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 697.9,                last time consumption/overall running time: 847.1912s / 391803.0972 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 673.15,                last time consumption/overall running time: 825.0867s / 392628.1839 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0134
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 705.65,                last time consumption/overall running time: 863.4065s / 393491.5903 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0138
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 733.2,                last time consumption/overall running time: 889.1261s / 394380.7164 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0135
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0138
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 732.05,                last time consumption/overall running time: 899.0309s / 395279.7473 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0138
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 674.95,                last time consumption/overall running time: 816.3609s / 396096.1082 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0141
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0138
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 691.05,                last time consumption/overall running time: 833.9686s / 396930.0767 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0140
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 698.35,                last time consumption/overall running time: 838.2539s / 397768.3307 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0143
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0146
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 685.3,                last time consumption/overall running time: 826.3865s / 398594.7171 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0148
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0144
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 807.1,                last time consumption/overall running time: 981.1197s / 399575.8369 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0148
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0146
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 710.25,                last time consumption/overall running time: 865.5696s / 400441.4065 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0146
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0145
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 747.25,                last time consumption/overall running time: 907.8291s / 401349.2356 sLoad SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -3.8500,                 loss: 0.0147
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0146
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 717.8,                last time consumption/overall running time: 866.4258s / 402215.6614 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0141
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0144
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 758.0,                last time consumption/overall running time: 915.5385s / 403131.1999 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0144
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0142
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 732.55,                last time consumption/overall running time: 881.8232s / 404013.0231 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0140
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0137
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 688.15,                last time consumption/overall running time: 831.0197s / 404844.0428 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0141
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0138
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 748.9,                last time consumption/overall running time: 903.5179s / 405747.5607 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0138
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0136
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 721.75,                last time consumption/overall running time: 870.0625s / 406617.6232 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0133
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0130
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 699.7,                last time consumption/overall running time: 845.0069s / 407462.6301 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0129
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 723.4,                last time consumption/overall running time: 871.4345s / 408334.0646 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0130
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0129
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 740.05,                last time consumption/overall running time: 907.0982s / 409241.1628 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0125
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 665.8,                last time consumption/overall running time: 803.1047s / 410044.2674 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0126
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
