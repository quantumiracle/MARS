2022-05-10 23:39:16.908860: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:39:16.908940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:39:16.908946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 140
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd8a4f54588>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_8000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_8000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8188s / 0.8188 s
agent0:                 episode reward: -0.2334,                 loss: nan
agent1:                 episode reward: 0.2334,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1098s / 0.9287 s
agent0:                 episode reward: 1.2308,                 loss: nan
agent1:                 episode reward: -1.2308,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1167s / 1.0453 s
agent0:                 episode reward: 0.9948,                 loss: nan
agent1:                 episode reward: -0.9948,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1148s / 1.1601 s
agent0:                 episode reward: -0.6020,                 loss: nan
agent1:                 episode reward: 0.6020,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1131s / 1.2732 s
agent0:                 episode reward: 0.3443,                 loss: nan
agent1:                 episode reward: -0.3443,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1068s / 1.3800 s
agent0:                 episode reward: 0.8715,                 loss: nan
agent1:                 episode reward: -0.8715,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1132s / 1.4932 s
agent0:                 episode reward: 1.4194,                 loss: nan
agent1:                 episode reward: -1.4194,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3421s / 1.8354 s
agent0:                 episode reward: 0.4163,                 loss: nan
agent1:                 episode reward: -0.4163,                 loss: 0.5201
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4385s / 2.2738 s
agent0:                 episode reward: 1.3608,                 loss: nan
agent1:                 episode reward: -1.3608,                 loss: 0.4367
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4409s / 2.7147 s
agent0:                 episode reward: 0.4581,                 loss: nan
agent1:                 episode reward: -0.4581,                 loss: 0.4202
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4417s / 3.1564 s
agent0:                 episode reward: 0.5764,                 loss: nan
agent1:                 episode reward: -0.5764,                 loss: 0.4158
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4406s / 3.5970 s
agent0:                 episode reward: 0.8797,                 loss: nan
agent1:                 episode reward: -0.8797,                 loss: 0.4094
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4435s / 4.0405 s
agent0:                 episode reward: 0.4322,                 loss: nan
agent1:                 episode reward: -0.4322,                 loss: 0.4043
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4646s / 4.5051 s
agent0:                 episode reward: 1.3716,                 loss: nan
agent1:                 episode reward: -1.3716,                 loss: 0.3995
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4495s / 4.9546 s
agent0:                 episode reward: 1.9913,                 loss: nan
agent1:                 episode reward: -1.9913,                 loss: 0.3969
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4834s / 5.4379 s
agent0:                 episode reward: 0.7019,                 loss: nan
agent1:                 episode reward: -0.7019,                 loss: 0.3961
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4536s / 5.8916 s
agent0:                 episode reward: 1.0891,                 loss: nan
agent1:                 episode reward: -1.0891,                 loss: 0.3950
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4469s / 6.3384 s
agent0:                 episode reward: 0.9909,                 loss: nan
agent1:                 episode reward: -0.9909,                 loss: 0.4223
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4496s / 6.7880 s
agent0:                 episode reward: 1.3347,                 loss: nan
agent1:                 episode reward: -1.3347,                 loss: 0.4327
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4557s / 7.2438 s
agent0:                 episode reward: 1.1634,                 loss: nan
agent1:                 episode reward: -1.1634,                 loss: 0.4317
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4519s / 7.6957 s
agent0:                 episode reward: 0.7035,                 loss: nan
agent1:                 episode reward: -0.7035,                 loss: 0.4304
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4537s / 8.1493 s
agent0:                 episode reward: 1.6778,                 loss: nan
agent1:                 episode reward: -1.6778,                 loss: 0.4304
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4414s / 8.5907 s
agent0:                 episode reward: 1.4440,                 loss: nan
agent1:                 episode reward: -1.4440,                 loss: 0.4284
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4507s / 9.0414 s
agent0:                 episode reward: 1.2782,                 loss: nan
agent1:                 episode reward: -1.2782,                 loss: 0.4273
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4591s / 9.5005 s
agent0:                 episode reward: 1.4970,                 loss: nan
agent1:                 episode reward: -1.4970,                 loss: 0.4267
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4545s / 9.9550 s
agent0:                 episode reward: 0.8804,                 loss: nan
agent1:                 episode reward: -0.8804,                 loss: 0.4258
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4705s / 10.4255 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.4250
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4514s / 10.8769 s
agent0:                 episode reward: 0.5330,                 loss: nan
agent1:                 episode reward: -0.5330,                 loss: 0.4454
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4909s / 11.3679 s
agent0:                 episode reward: 1.2443,                 loss: nan
agent1:                 episode reward: -1.2443,                 loss: 0.4524
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4630s / 11.8308 s
agent0:                 episode reward: 1.1689,                 loss: nan
agent1:                 episode reward: -1.1689,                 loss: 0.4506
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4609s / 12.2918 s
agent0:                 episode reward: 1.2466,                 loss: nan
agent1:                 episode reward: -1.2466,                 loss: 0.4494
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4744s / 12.7662 s
agent0:                 episode reward: 2.0751,                 loss: nan
agent1:                 episode reward: -2.0751,                 loss: 0.4491
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4670s / 13.2332 s
agent0:                 episode reward: 1.1425,                 loss: nan
agent1:                 episode reward: -1.1425,                 loss: 0.4480
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4589s / 13.6921 s
agent0:                 episode reward: 2.0090,                 loss: nan
agent1:                 episode reward: -2.0090,                 loss: 0.4470
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4682s / 14.1603 s
agent0:                 episode reward: 1.6685,                 loss: nan
agent1:                 episode reward: -1.6685,                 loss: 0.4455
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4673s / 14.6276 s
agent0:                 episode reward: 1.5621,                 loss: nan
agent1:                 episode reward: -1.5621,                 loss: 0.4458
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4567s / 15.0843 s
agent0:                 episode reward: 1.8882,                 loss: nan
agent1:                 episode reward: -1.8882,                 loss: 0.4456
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5034s / 15.5877 s
agent0:                 episode reward: 1.0712,                 loss: nan
agent1:                 episode reward: -1.0712,                 loss: 0.4507
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4750s / 16.0627 s
agent0:                 episode reward: 1.1224,                 loss: nan
agent1:                 episode reward: -1.1224,                 loss: 0.4486
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4836s / 16.5462 s
agent0:                 episode reward: 0.8178,                 loss: nan
agent1:                 episode reward: -0.8178,                 loss: 0.4443
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4706s / 17.0169 s
agent0:                 episode reward: 1.1313,                 loss: nan
agent1:                 episode reward: -1.1313,                 loss: 0.4443
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4567s / 17.4736 s
agent0:                 episode reward: 0.8289,                 loss: nan
agent1:                 episode reward: -0.8289,                 loss: 0.4434
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4721s / 17.9457 s
agent0:                 episode reward: 0.4004,                 loss: nan
agent1:                 episode reward: -0.4004,                 loss: 0.4399
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4656s / 18.4113 s
agent0:                 episode reward: 1.4296,                 loss: nan
agent1:                 episode reward: -1.4296,                 loss: 0.4388
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4708s / 18.8820 s
agent0:                 episode reward: 0.8074,                 loss: nan
agent1:                 episode reward: -0.8074,                 loss: 0.4384
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4659s / 19.3480 s
agent0:                 episode reward: 0.9778,                 loss: nan
agent1:                 episode reward: -0.9778,                 loss: 0.4384
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4745s / 19.8225 s
agent0:                 episode reward: 1.3446,                 loss: nan
agent1:                 episode reward: -1.3446,                 loss: 0.4370
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5071s / 20.3296 s
agent0:                 episode reward: 0.9647,                 loss: nan
agent1:                 episode reward: -0.9647,                 loss: 0.4120
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4731s / 20.8027 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.3964
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5014s / 21.3041 s
agent0:                 episode reward: -0.1650,                 loss: nan
agent1:                 episode reward: 0.1650,                 loss: 0.3909
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4876s / 21.7916 s
agent0:                 episode reward: 0.7896,                 loss: nan
agent1:                 episode reward: -0.7896,                 loss: 0.3876
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4976s / 22.2893 s
agent0:                 episode reward: 0.3047,                 loss: nan
agent1:                 episode reward: -0.3047,                 loss: 0.3851
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4883s / 22.7775 s
agent0:                 episode reward: 0.7724,                 loss: nan
agent1:                 episode reward: -0.7724,                 loss: 0.3853
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4786s / 23.2561 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: 0.3833
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4702s / 23.7263 s
agent0:                 episode reward: 1.1901,                 loss: nan
agent1:                 episode reward: -1.1901,                 loss: 0.3820
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4801s / 24.2063 s
agent0:                 episode reward: 1.1405,                 loss: nan
agent1:                 episode reward: -1.1405,                 loss: 0.3798
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4859s / 24.6923 s
agent0:                 episode reward: 0.3538,                 loss: nan
agent1:                 episode reward: -0.3538,                 loss: 0.3792
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4926s / 25.1848 s
agent0:                 episode reward: 1.3118,                 loss: nan
agent1:                 episode reward: -1.3118,                 loss: 0.3280
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4894s / 25.6743 s
agent0:                 episode reward: 1.4536,                 loss: nan
agent1:                 episode reward: -1.4536,                 loss: 0.2996
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5266s / 26.2009 s
agent0:                 episode reward: 0.5119,                 loss: nan
agent1:                 episode reward: -0.5119,                 loss: 0.2935
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4836s / 26.6844 s
agent0:                 episode reward: 0.1468,                 loss: nan
agent1:                 episode reward: -0.1468,                 loss: 0.2919
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4960s / 27.1805 s
agent0:                 episode reward: 0.8923,                 loss: nan
agent1:                 episode reward: -0.8923,                 loss: 0.2898
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4890s / 27.6694 s
agent0:                 episode reward: 1.2695,                 loss: nan
agent1:                 episode reward: -1.2695,                 loss: 0.2877
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5088s / 28.1783 s
agent0:                 episode reward: 1.1460,                 loss: nan
agent1:                 episode reward: -1.1460,                 loss: 0.2876
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4948s / 28.6731 s
agent0:                 episode reward: 1.8311,                 loss: nan
agent1:                 episode reward: -1.8311,                 loss: 0.2883
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4855s / 29.1586 s
agent0:                 episode reward: 0.3655,                 loss: nan
agent1:                 episode reward: -0.3655,                 loss: 0.2896
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4983s / 29.6569 s
agent0:                 episode reward: 0.7435,                 loss: nan
agent1:                 episode reward: -0.7435,                 loss: 0.2861
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4784s / 30.1353 s
agent0:                 episode reward: 2.0905,                 loss: nan
agent1:                 episode reward: -2.0905,                 loss: 0.2644
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5062s / 30.6415 s
agent0:                 episode reward: 1.3826,                 loss: nan
agent1:                 episode reward: -1.3826,                 loss: 0.2494
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4910s / 31.1325 s
agent0:                 episode reward: 1.1462,                 loss: nan
agent1:                 episode reward: -1.1462,                 loss: 0.2477
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4874s / 31.6199 s
agent0:                 episode reward: 0.6759,                 loss: nan
agent1:                 episode reward: -0.6759,                 loss: 0.2483
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4931s / 32.1130 s
agent0:                 episode reward: 1.2193,                 loss: nan
agent1:                 episode reward: -1.2193,                 loss: 0.2483
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4854s / 32.5984 s
agent0:                 episode reward: 1.5441,                 loss: nan
agent1:                 episode reward: -1.5441,                 loss: 0.2455
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4927s / 33.0911 s
agent0:                 episode reward: 1.0096,                 loss: nan
agent1:                 episode reward: -1.0096,                 loss: 0.2432
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4912s / 33.5823 s
agent0:                 episode reward: 0.7926,                 loss: nan
agent1:                 episode reward: -0.7926,                 loss: 0.2438
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4936s / 34.0759 s
agent0:                 episode reward: 1.0458,                 loss: nan
agent1:                 episode reward: -1.0458,                 loss: 0.2417
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5044s / 34.5803 s
agent0:                 episode reward: 0.9034,                 loss: nan
agent1:                 episode reward: -0.9034,                 loss: 0.2449
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4924s / 35.0726 s
agent0:                 episode reward: 1.4330,                 loss: nan
agent1:                 episode reward: -1.4330,                 loss: 0.2539
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4900s / 35.5627 s
agent0:                 episode reward: 0.8716,                 loss: nan
agent1:                 episode reward: -0.8716,                 loss: 0.2567
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5342s / 36.0968 s
agent0:                 episode reward: 1.3888,                 loss: nan
agent1:                 episode reward: -1.3888,                 loss: 0.2549
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5014s / 36.5982 s
agent0:                 episode reward: 0.3612,                 loss: nan
agent1:                 episode reward: -0.3612,                 loss: 0.2553
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4960s / 37.0941 s
agent0:                 episode reward: 1.5968,                 loss: nan
agent1:                 episode reward: -1.5968,                 loss: 0.2549
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5144s / 37.6086 s
agent0:                 episode reward: 0.9381,                 loss: nan
agent1:                 episode reward: -0.9381,                 loss: 0.2565
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5024s / 38.1110 s
agent0:                 episode reward: 1.8966,                 loss: nan
agent1:                 episode reward: -1.8966,                 loss: 0.2556
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4993s / 38.6103 s
agent0:                 episode reward: 1.1657,                 loss: nan
agent1:                 episode reward: -1.1657,                 loss: 0.2512
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4894s / 39.0998 s
agent0:                 episode reward: 1.0848,                 loss: nan
agent1:                 episode reward: -1.0848,                 loss: 0.2545
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5006s / 39.6003 s
agent0:                 episode reward: 1.0811,                 loss: nan
agent1:                 episode reward: -1.0811,                 loss: 0.2514
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4995s / 40.0998 s
agent0:                 episode reward: 1.6436,                 loss: nan
agent1:                 episode reward: -1.6436,                 loss: 0.2722
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5142s / 40.6140 s
agent0:                 episode reward: 1.6161,                 loss: nan
agent1:                 episode reward: -1.6161,                 loss: 0.2782
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5192s / 41.1332 s
agent0:                 episode reward: 0.4388,                 loss: nan
agent1:                 episode reward: -0.4388,                 loss: 0.2796
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5089s / 41.6421 s
agent0:                 episode reward: 1.6583,                 loss: nan
agent1:                 episode reward: -1.6583,                 loss: 0.2791
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5120s / 42.1541 s
agent0:                 episode reward: 1.1211,                 loss: nan
agent1:                 episode reward: -1.1211,                 loss: 0.2753
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5083s / 42.6624 s
agent0:                 episode reward: -0.4309,                 loss: nan
agent1:                 episode reward: 0.4309,                 loss: 0.2759
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5013s / 43.1638 s
agent0:                 episode reward: 1.8149,                 loss: nan
agent1:                 episode reward: -1.8149,                 loss: 0.2779
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5112s / 43.6749 s
agent0:                 episode reward: 0.9121,                 loss: nan
agent1:                 episode reward: -0.9121,                 loss: 0.2761
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5015s / 44.1765 s
agent0:                 episode reward: 2.0474,                 loss: nan
agent1:                 episode reward: -2.0474,                 loss: 0.2761
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5180s / 44.6945 s
agent0:                 episode reward: 1.2387,                 loss: nan
agent1:                 episode reward: -1.2387,                 loss: 0.2750
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5427s / 45.2372 s
agent0:                 episode reward: 0.0559,                 loss: nan
agent1:                 episode reward: -0.0559,                 loss: 0.2985
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5182s / 45.7554 s
agent0:                 episode reward: 1.2218,                 loss: nan
agent1:                 episode reward: -1.2218,                 loss: 0.2992
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5639s / 46.3193 s
agent0:                 episode reward: 0.9137,                 loss: nan
agent1:                 episode reward: -0.9137,                 loss: 0.3009
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5310s / 46.8502 s
agent0:                 episode reward: 0.9403,                 loss: nan
agent1:                 episode reward: -0.9403,                 loss: 0.3000
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5035s / 47.3538 s
agent0:                 episode reward: 1.1071,                 loss: nan
agent1:                 episode reward: -1.1071,                 loss: 0.2991
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5091s / 47.8629 s
agent0:                 episode reward: 0.8306,                 loss: nan
agent1:                 episode reward: -0.8306,                 loss: 0.2993
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5054s / 48.3683 s
agent0:                 episode reward: 0.9003,                 loss: nan
agent1:                 episode reward: -0.9003,                 loss: 0.3002
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5082s / 48.8765 s
agent0:                 episode reward: 1.2652,                 loss: nan
agent1:                 episode reward: -1.2652,                 loss: 0.2991
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5178s / 49.3943 s
agent0:                 episode reward: 0.9432,                 loss: nan
agent1:                 episode reward: -0.9432,                 loss: 0.2990
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5107s / 49.9050 s
agent0:                 episode reward: 0.2985,                 loss: nan
agent1:                 episode reward: -0.2985,                 loss: 0.2991
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5160s / 50.4210 s
agent0:                 episode reward: 0.9754,                 loss: nan
agent1:                 episode reward: -0.9754,                 loss: 0.3160
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5122s / 50.9332 s
agent0:                 episode reward: -0.1063,                 loss: nan
agent1:                 episode reward: 0.1063,                 loss: 0.3220
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5054s / 51.4386 s
agent0:                 episode reward: 1.7785,                 loss: nan
agent1:                 episode reward: -1.7785,                 loss: 0.3203
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5046s / 51.9432 s
agent0:                 episode reward: 1.0546,                 loss: nan
agent1:                 episode reward: -1.0546,                 loss: 0.3210
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5203s / 52.4635 s
agent0:                 episode reward: 0.9310,                 loss: nan
agent1:                 episode reward: -0.9310,                 loss: 0.3186
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5188s / 52.9823 s
agent0:                 episode reward: 1.3409,                 loss: nan
agent1:                 episode reward: -1.3409,                 loss: 0.3200
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5117s / 53.4939 s
agent0:                 episode reward: 2.0184,                 loss: nan
agent1:                 episode reward: -2.0184,                 loss: 0.3185
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5011s / 53.9950 s
agent0:                 episode reward: 1.8910,                 loss: nan
agent1:                 episode reward: -1.8910,                 loss: 0.3171
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5358s / 54.5308 s
agent0:                 episode reward: 1.4079,                 loss: nan
agent1:                 episode reward: -1.4079,                 loss: 0.3181
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5055s / 55.0363 s
agent0:                 episode reward: 1.6613,                 loss: nan
agent1:                 episode reward: -1.6613,                 loss: 0.3188
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5240s / 55.5603 s
agent0:                 episode reward: -0.1967,                 loss: nan
agent1:                 episode reward: 0.1967,                 loss: 0.3334
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4958s / 56.0561 s
agent0:                 episode reward: 0.7816,                 loss: nan
agent1:                 episode reward: -0.7816,                 loss: 0.3370
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5617s / 56.6178 s
agent0:                 episode reward: 1.3296,                 loss: nan
agent1:                 episode reward: -1.3296,                 loss: 0.3342
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5123s / 57.1301 s
agent0:                 episode reward: 0.8610,                 loss: nan
agent1:                 episode reward: -0.8610,                 loss: 0.3356
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5380s / 57.6681 s
agent0:                 episode reward: 1.0789,                 loss: nan
agent1:                 episode reward: -1.0789,                 loss: 0.3347
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5127s / 58.1807 s
agent0:                 episode reward: 1.5706,                 loss: nan
agent1:                 episode reward: -1.5706,                 loss: 0.3340
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5142s / 58.6949 s
agent0:                 episode reward: 0.4808,                 loss: nan
agent1:                 episode reward: -0.4808,                 loss: 0.3352
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5064s / 59.2013 s
agent0:                 episode reward: 0.8174,                 loss: nan
agent1:                 episode reward: -0.8174,                 loss: 0.3341
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5098s / 59.7111 s
agent0:                 episode reward: 1.5607,                 loss: nan
agent1:                 episode reward: -1.5607,                 loss: 0.3334
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5077s / 60.2188 s
agent0:                 episode reward: 1.2493,                 loss: nan
agent1:                 episode reward: -1.2493,                 loss: 0.3329
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5155s / 60.7343 s
agent0:                 episode reward: 0.2650,                 loss: nan
agent1:                 episode reward: -0.2650,                 loss: 0.3447
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4978s / 61.2321 s
agent0:                 episode reward: 0.7814,                 loss: nan
agent1:                 episode reward: -0.7814,                 loss: 0.3485
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5269s / 61.7589 s
agent0:                 episode reward: 1.5521,                 loss: nan
agent1:                 episode reward: -1.5521,                 loss: 0.3471
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5107s / 62.2696 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.3463
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5350s / 62.8046 s
agent0:                 episode reward: 1.4888,                 loss: nan
agent1:                 episode reward: -1.4888,                 loss: 0.3453
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5099s / 63.3145 s
agent0:                 episode reward: 1.0883,                 loss: nan
agent1:                 episode reward: -1.0883,                 loss: 0.3447
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5142s / 63.8286 s
agent0:                 episode reward: 0.8683,                 loss: nan
agent1:                 episode reward: -0.8683,                 loss: 0.3434
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5178s / 64.3465 s
agent0:                 episode reward: 0.7872,                 loss: nan
agent1:                 episode reward: -0.7872,                 loss: 0.3441
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5316s / 64.8781 s
agent0:                 episode reward: 1.2001,                 loss: nan
agent1:                 episode reward: -1.2001,                 loss: 0.3435
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5137s / 65.3917 s
agent0:                 episode reward: 1.7952,                 loss: nan
agent1:                 episode reward: -1.7952,                 loss: 0.3418
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5275s / 65.9192 s
agent0:                 episode reward: 0.8509,                 loss: nan
agent1:                 episode reward: -0.8509,                 loss: 0.3568
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5156s / 66.4347 s
agent0:                 episode reward: 1.0600,                 loss: nan
agent1:                 episode reward: -1.0600,                 loss: 0.3606
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 67.0180 s
agent0:                 episode reward: 0.8982,                 loss: nan
agent1:                 episode reward: -0.8982,                 loss: 0.3588
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5390s / 67.5570 s
agent0:                 episode reward: 0.6249,                 loss: nan
agent1:                 episode reward: -0.6249,                 loss: 0.3608
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5284s / 68.0855 s
agent0:                 episode reward: 0.5221,                 loss: nan
agent1:                 episode reward: -0.5221,                 loss: 0.3590
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5127s / 68.5982 s
agent0:                 episode reward: 0.9023,                 loss: nan
agent1:                 episode reward: -0.9023,                 loss: 0.3558
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5171s / 69.1153 s
agent0:                 episode reward: 2.0417,                 loss: nan
agent1:                 episode reward: -2.0417,                 loss: 0.3577
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5152s / 69.6305 s
agent0:                 episode reward: 1.1564,                 loss: nan
agent1:                 episode reward: -1.1564,                 loss: 0.3579
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5292s / 70.1597 s
agent0:                 episode reward: 1.1351,                 loss: nan
agent1:                 episode reward: -1.1351,                 loss: 0.3564
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5359s / 70.6956 s
agent0:                 episode reward: 1.0315,                 loss: nan
agent1:                 episode reward: -1.0315,                 loss: 0.3567
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5518s / 71.2473 s
agent0:                 episode reward: 0.7553,                 loss: nan
agent1:                 episode reward: -0.7553,                 loss: 0.3727
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5188s / 71.7661 s
agent0:                 episode reward: 1.1773,                 loss: nan
agent1:                 episode reward: -1.1773,                 loss: 0.3783
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5278s / 72.2939 s
agent0:                 episode reward: 0.4238,                 loss: nan
agent1:                 episode reward: -0.4238,                 loss: 0.3791
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5252s / 72.8191 s
agent0:                 episode reward: 1.2299,                 loss: nan
agent1:                 episode reward: -1.2299,                 loss: 0.3775
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5238s / 73.3429 s
agent0:                 episode reward: 0.1774,                 loss: nan
agent1:                 episode reward: -0.1774,                 loss: 0.3758
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5391s / 73.8820 s
agent0:                 episode reward: -0.0318,                 loss: nan
agent1:                 episode reward: 0.0318,                 loss: 0.3771
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5313s / 74.4133 s
agent0:                 episode reward: 1.5002,                 loss: nan
agent1:                 episode reward: -1.5002,                 loss: 0.3745
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5264s / 74.9397 s
agent0:                 episode reward: 1.4767,                 loss: nan
agent1:                 episode reward: -1.4767,                 loss: 0.3739
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5367s / 75.4764 s
agent0:                 episode reward: 1.1548,                 loss: nan
agent1:                 episode reward: -1.1548,                 loss: 0.3741
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5409s / 76.0173 s
agent0:                 episode reward: 0.5601,                 loss: nan
agent1:                 episode reward: -0.5601,                 loss: 0.3726
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5367s / 76.5540 s
agent0:                 episode reward: 1.3056,                 loss: nan
agent1:                 episode reward: -1.3056,                 loss: 0.3911
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5863s / 77.1403 s
agent0:                 episode reward: 1.8113,                 loss: nan
agent1:                 episode reward: -1.8113,                 loss: 0.3945
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5384s / 77.6787 s
agent0:                 episode reward: 1.2489,                 loss: nan
agent1:                 episode reward: -1.2489,                 loss: 0.3956
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5356s / 78.2143 s
agent0:                 episode reward: 0.2178,                 loss: nan
agent1:                 episode reward: -0.2178,                 loss: 0.3944
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5306s / 78.7449 s
agent0:                 episode reward: 1.4891,                 loss: nan
agent1:                 episode reward: -1.4891,                 loss: 0.3948
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5515s / 79.2964 s
agent0:                 episode reward: 1.2706,                 loss: nan
agent1:                 episode reward: -1.2706,                 loss: 0.3954
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5445s / 79.8409 s
agent0:                 episode reward: 0.3950,                 loss: nan
agent1:                 episode reward: -0.3950,                 loss: 0.3938
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5427s / 80.3836 s
agent0:                 episode reward: 0.8127,                 loss: nan
agent1:                 episode reward: -0.8127,                 loss: 0.3922
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5479s / 80.9315 s
agent0:                 episode reward: 0.2017,                 loss: nan
agent1:                 episode reward: -0.2017,                 loss: 0.3930
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5401s / 81.4715 s
agent0:                 episode reward: 0.4619,                 loss: nan
agent1:                 episode reward: -0.4619,                 loss: 0.3928
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5516s / 82.0232 s
agent0:                 episode reward: 1.5742,                 loss: nan
agent1:                 episode reward: -1.5742,                 loss: 0.4096
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5570s / 82.5801 s
agent0:                 episode reward: 0.8128,                 loss: nan
agent1:                 episode reward: -0.8128,                 loss: 0.4143
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5468s / 83.1270 s
agent0:                 episode reward: 0.6347,                 loss: nan
agent1:                 episode reward: -0.6347,                 loss: 0.4146
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5349s / 83.6619 s
agent0:                 episode reward: 0.2027,                 loss: nan
agent1:                 episode reward: -0.2027,                 loss: 0.4134
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5490s / 84.2109 s
agent0:                 episode reward: 1.0878,                 loss: nan
agent1:                 episode reward: -1.0878,                 loss: 0.4135
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5531s / 84.7641 s
agent0:                 episode reward: 0.9387,                 loss: nan
agent1:                 episode reward: -0.9387,                 loss: 0.4127
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5525s / 85.3166 s
agent0:                 episode reward: 1.0603,                 loss: nan
agent1:                 episode reward: -1.0603,                 loss: 0.4137
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5569s / 85.8735 s
agent0:                 episode reward: 0.6374,                 loss: nan
agent1:                 episode reward: -0.6374,                 loss: 0.4109
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5484s / 86.4219 s
agent0:                 episode reward: 0.3350,                 loss: nan
agent1:                 episode reward: -0.3350,                 loss: 0.4123
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5528s / 86.9746 s
agent0:                 episode reward: 0.3108,                 loss: nan
agent1:                 episode reward: -0.3108,                 loss: 0.4113
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6371s / 87.6117 s
agent0:                 episode reward: 1.3727,                 loss: nan
agent1:                 episode reward: -1.3727,                 loss: 0.4166
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5427s / 88.1545 s
agent0:                 episode reward: 1.6336,                 loss: nan
agent1:                 episode reward: -1.6336,                 loss: 0.4152
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5536s / 88.7081 s
agent0:                 episode reward: 1.7895,                 loss: nan
agent1:                 episode reward: -1.7895,                 loss: 0.4114
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5419s / 89.2500 s
agent0:                 episode reward: 1.0545,                 loss: nan
agent1:                 episode reward: -1.0545,                 loss: 0.4137
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5529s / 89.8029 s
agent0:                 episode reward: 0.7430,                 loss: nan
agent1:                 episode reward: -0.7430,                 loss: 0.4127
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5436s / 90.3465 s
agent0:                 episode reward: 0.9745,                 loss: nan
agent1:                 episode reward: -0.9745,                 loss: 0.4121
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5549s / 90.9014 s
agent0:                 episode reward: 0.1111,                 loss: nan
agent1:                 episode reward: -0.1111,                 loss: 0.4127
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5635s / 91.4649 s
agent0:                 episode reward: 0.8665,                 loss: nan
agent1:                 episode reward: -0.8665,                 loss: 0.4100
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5640s / 92.0288 s
agent0:                 episode reward: 0.8147,                 loss: nan
agent1:                 episode reward: -0.8147,                 loss: 0.4088
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5423s / 92.5711 s
agent0:                 episode reward: 1.1946,                 loss: nan
agent1:                 episode reward: -1.1946,                 loss: 0.4111
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5584s / 93.1295 s
agent0:                 episode reward: 1.4316,                 loss: nan
agent1:                 episode reward: -1.4316,                 loss: 0.3929
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5650s / 93.6945 s
agent0:                 episode reward: 1.2642,                 loss: nan
agent1:                 episode reward: -1.2642,                 loss: 0.3842
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5638s / 94.2583 s
agent0:                 episode reward: 0.9175,                 loss: nan
agent1:                 episode reward: -0.9175,                 loss: 0.3802
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5680s / 94.8263 s
agent0:                 episode reward: 1.1218,                 loss: nan
agent1:                 episode reward: -1.1218,                 loss: 0.3808
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5601s / 95.3864 s
agent0:                 episode reward: -0.1945,                 loss: nan
agent1:                 episode reward: 0.1945,                 loss: 0.3809
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5829s / 95.9693 s
agent0:                 episode reward: 1.5421,                 loss: nan
agent1:                 episode reward: -1.5421,                 loss: 0.3817
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5589s / 96.5282 s
agent0:                 episode reward: 1.7092,                 loss: nan
agent1:                 episode reward: -1.7092,                 loss: 0.3800
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5614s / 97.0896 s
agent0:                 episode reward: 0.3958,                 loss: nan
agent1:                 episode reward: -0.3958,                 loss: 0.3783
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6141s / 97.7037 s
agent0:                 episode reward: 0.2272,                 loss: nan
agent1:                 episode reward: -0.2272,                 loss: 0.3792
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5658s / 98.2696 s
agent0:                 episode reward: 0.3679,                 loss: nan
agent1:                 episode reward: -0.3679,                 loss: 0.3782
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5581s / 98.8277 s
agent0:                 episode reward: 1.9553,                 loss: nan
agent1:                 episode reward: -1.9553,                 loss: 0.3519
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5667s / 99.3944 s
agent0:                 episode reward: 1.1970,                 loss: nan
agent1:                 episode reward: -1.1970,                 loss: 0.3404
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5632s / 99.9576 s
agent0:                 episode reward: -0.0478,                 loss: nan
agent1:                 episode reward: 0.0478,                 loss: 0.3401
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5919s / 100.5495 s
agent0:                 episode reward: 1.8184,                 loss: nan
agent1:                 episode reward: -1.8184,                 loss: 0.3397
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5862s / 101.1356 s
agent0:                 episode reward: 0.4129,                 loss: nan
agent1:                 episode reward: -0.4129,                 loss: 0.3368
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5933s / 101.7290 s
agent0:                 episode reward: 1.4032,                 loss: nan
agent1:                 episode reward: -1.4032,                 loss: 0.3369
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5709s / 102.2998 s
agent0:                 episode reward: 0.0561,                 loss: nan
agent1:                 episode reward: -0.0561,                 loss: 0.3385
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5608s / 102.8606 s
agent0:                 episode reward: 1.7931,                 loss: nan
agent1:                 episode reward: -1.7931,                 loss: 0.3388
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5838s / 103.4443 s
agent0:                 episode reward: 0.6849,                 loss: nan
agent1:                 episode reward: -0.6849,                 loss: 0.3361
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5953s / 104.0396 s
agent0:                 episode reward: 0.7871,                 loss: nan
agent1:                 episode reward: -0.7871,                 loss: 0.3374
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5895s / 104.6292 s
agent0:                 episode reward: 0.3254,                 loss: nan
agent1:                 episode reward: -0.3254,                 loss: 0.3345
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5644s / 105.1936 s
agent0:                 episode reward: 0.9859,                 loss: nan
agent1:                 episode reward: -0.9859,                 loss: 0.3283
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5744s / 105.7680 s
agent0:                 episode reward: 0.5461,                 loss: nan
agent1:                 episode reward: -0.5461,                 loss: 0.3266
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5852s / 106.3532 s
agent0:                 episode reward: 0.6481,                 loss: nan
agent1:                 episode reward: -0.6481,                 loss: 0.3260
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5877s / 106.9409 s
agent0:                 episode reward: 1.4225,                 loss: nan
agent1:                 episode reward: -1.4225,                 loss: 0.3260
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5594s / 107.5003 s
agent0:                 episode reward: 0.7784,                 loss: nan
agent1:                 episode reward: -0.7784,                 loss: 0.3246
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6391s / 108.1394 s
agent0:                 episode reward: 0.7031,                 loss: nan
agent1:                 episode reward: -0.7031,                 loss: 0.3224
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5685s / 108.7078 s
agent0:                 episode reward: 1.4933,                 loss: nan
agent1:                 episode reward: -1.4933,                 loss: 0.3237
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5790s / 109.2868 s
agent0:                 episode reward: 1.9302,                 loss: nan
agent1:                 episode reward: -1.9302,                 loss: 0.3261
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5717s / 109.8586 s
agent0:                 episode reward: 1.2336,                 loss: nan
agent1:                 episode reward: -1.2336,                 loss: 0.3227
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5766s / 110.4352 s
agent0:                 episode reward: 1.0619,                 loss: nan
agent1:                 episode reward: -1.0619,                 loss: 0.3272
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5736s / 111.0088 s
agent0:                 episode reward: 1.3087,                 loss: nan
agent1:                 episode reward: -1.3087,                 loss: 0.3282
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5819s / 111.5906 s
agent0:                 episode reward: 0.9690,                 loss: nan
agent1:                 episode reward: -0.9690,                 loss: 0.3255
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5751s / 112.1657 s
agent0:                 episode reward: 0.9823,                 loss: nan
agent1:                 episode reward: -0.9823,                 loss: 0.3281
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6165s / 112.7822 s
agent0:                 episode reward: 2.3101,                 loss: nan
agent1:                 episode reward: -2.3101,                 loss: 0.3283
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6248s / 113.4069 s
agent0:                 episode reward: 1.2989,                 loss: nan
agent1:                 episode reward: -1.2989,                 loss: 0.3298
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5704s / 113.9774 s
agent0:                 episode reward: 0.5655,                 loss: nan
agent1:                 episode reward: -0.5655,                 loss: 0.3269
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5788s / 114.5562 s
agent0:                 episode reward: 0.8732,                 loss: nan
agent1:                 episode reward: -0.8732,                 loss: 0.3253
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5793s / 115.1355 s
agent0:                 episode reward: -0.0966,                 loss: nan
agent1:                 episode reward: 0.0966,                 loss: 0.3240
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5941s / 115.7296 s
agent0:                 episode reward: 0.6192,                 loss: nan
agent1:                 episode reward: -0.6192,                 loss: 0.3241
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5812s / 116.3108 s
agent0:                 episode reward: -0.0601,                 loss: nan
agent1:                 episode reward: 0.0601,                 loss: 0.3419
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5765s / 116.8873 s
agent0:                 episode reward: 1.7771,                 loss: nan
agent1:                 episode reward: -1.7771,                 loss: 0.3441
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5786s / 117.4659 s
agent0:                 episode reward: 0.5487,                 loss: nan
agent1:                 episode reward: -0.5487,                 loss: 0.3449
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6303s / 118.0962 s
agent0:                 episode reward: 0.5209,                 loss: nan
agent1:                 episode reward: -0.5209,                 loss: 0.3438
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5945s / 118.6907 s
agent0:                 episode reward: 0.7945,                 loss: nan
agent1:                 episode reward: -0.7945,                 loss: 0.3424
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5845s / 119.2752 s
agent0:                 episode reward: 0.1922,                 loss: nan
agent1:                 episode reward: -0.1922,                 loss: 0.3432
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5841s / 119.8593 s
agent0:                 episode reward: 2.0480,                 loss: nan
agent1:                 episode reward: -2.0480,                 loss: 0.3422
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5790s / 120.4383 s
agent0:                 episode reward: 1.0152,                 loss: nan
agent1:                 episode reward: -1.0152,                 loss: 0.3409
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6028s / 121.0411 s
agent0:                 episode reward: 1.3320,                 loss: nan
agent1:                 episode reward: -1.3320,                 loss: 0.3425
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6012s / 121.6423 s
agent0:                 episode reward: 1.0612,                 loss: nan
agent1:                 episode reward: -1.0612,                 loss: 0.3438
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5909s / 122.2332 s
agent0:                 episode reward: 0.0258,                 loss: nan
agent1:                 episode reward: -0.0258,                 loss: 0.3617
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5976s / 122.8308 s
agent0:                 episode reward: 0.5633,                 loss: nan
agent1:                 episode reward: -0.5633,                 loss: 0.3549
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5881s / 123.4189 s
agent0:                 episode reward: 0.9414,                 loss: nan
agent1:                 episode reward: -0.9414,                 loss: 0.3554
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5880s / 124.0069 s
agent0:                 episode reward: 0.0279,                 loss: nan
agent1:                 episode reward: -0.0279,                 loss: 0.3561
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5812s / 124.5882 s
agent0:                 episode reward: 0.8108,                 loss: nan
agent1:                 episode reward: -0.8108,                 loss: 0.3568
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5872s / 125.1753 s
agent0:                 episode reward: 1.7132,                 loss: nan
agent1:                 episode reward: -1.7132,                 loss: 0.3544
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5912s / 125.7665 s
agent0:                 episode reward: 0.9559,                 loss: nan
agent1:                 episode reward: -0.9559,                 loss: 0.3565
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5879s / 126.3544 s
agent0:                 episode reward: 0.2263,                 loss: nan
agent1:                 episode reward: -0.2263,                 loss: 0.3571
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5824s / 126.9368 s
agent0:                 episode reward: 1.9216,                 loss: nan
agent1:                 episode reward: -1.9216,                 loss: 0.3552
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6291s / 127.5659 s
agent0:                 episode reward: 0.4112,                 loss: nan
agent1:                 episode reward: -0.4112,                 loss: 0.3552
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6084s / 128.1743 s
agent0:                 episode reward: 0.5206,                 loss: nan
agent1:                 episode reward: -0.5206,                 loss: 0.3757
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6297s / 128.8039 s
agent0:                 episode reward: 0.7253,                 loss: nan
agent1:                 episode reward: -0.7253,                 loss: 0.3738
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6090s / 129.4130 s
agent0:                 episode reward: 0.8821,                 loss: nan
agent1:                 episode reward: -0.8821,                 loss: 0.3722
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5887s / 130.0017 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.3689
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5938s / 130.5954 s
agent0:                 episode reward: 0.9875,                 loss: nan
agent1:                 episode reward: -0.9875,                 loss: 0.3695
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6046s / 131.2000 s
agent0:                 episode reward: 1.1244,                 loss: nan
agent1:                 episode reward: -1.1244,                 loss: 0.3692
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5988s / 131.7989 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.3706
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5935s / 132.3923 s
agent0:                 episode reward: 1.9385,                 loss: nan
agent1:                 episode reward: -1.9385,                 loss: 0.3673
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5948s / 132.9871 s
agent0:                 episode reward: 0.8489,                 loss: nan
agent1:                 episode reward: -0.8489,                 loss: 0.3671
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5941s / 133.5812 s
agent0:                 episode reward: 0.5728,                 loss: nan
agent1:                 episode reward: -0.5728,                 loss: 0.3671
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6153s / 134.1966 s
agent0:                 episode reward: 0.5537,                 loss: nan
agent1:                 episode reward: -0.5537,                 loss: 0.3925
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5986s / 134.7952 s
agent0:                 episode reward: 0.8503,                 loss: nan
agent1:                 episode reward: -0.8503,                 loss: 0.3955
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5958s / 135.3910 s
agent0:                 episode reward: 1.3713,                 loss: nan
agent1:                 episode reward: -1.3713,                 loss: 0.3947
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6044s / 135.9954 s
agent0:                 episode reward: 0.1754,                 loss: nan
agent1:                 episode reward: -0.1754,                 loss: 0.3923
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5958s / 136.5912 s
agent0:                 episode reward: 0.4411,                 loss: nan
agent1:                 episode reward: -0.4411,                 loss: 0.3906
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6127s / 137.2039 s
agent0:                 episode reward: 1.4653,                 loss: nan
agent1:                 episode reward: -1.4653,                 loss: 0.3909
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6331s / 137.8370 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: 0.3898
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5970s / 138.4340 s
agent0:                 episode reward: 1.1445,                 loss: nan
agent1:                 episode reward: -1.1445,                 loss: 0.3904
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6428s / 139.0768 s
agent0:                 episode reward: 1.1102,                 loss: nan
agent1:                 episode reward: -1.1102,                 loss: 0.3902
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5942s / 139.6710 s
agent0:                 episode reward: 0.7501,                 loss: nan
agent1:                 episode reward: -0.7501,                 loss: 0.3879
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6054s / 140.2765 s
agent0:                 episode reward: 0.8446,                 loss: nan
agent1:                 episode reward: -0.8446,                 loss: 0.3878
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5991s / 140.8755 s
agent0:                 episode reward: 1.4776,                 loss: nan
agent1:                 episode reward: -1.4776,                 loss: 0.3764
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6000s / 141.4755 s
agent0:                 episode reward: 0.6873,                 loss: nan
agent1:                 episode reward: -0.6873,                 loss: 0.3745
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6041s / 142.0796 s
agent0:                 episode reward: 0.3131,                 loss: nan
agent1:                 episode reward: -0.3131,                 loss: 0.3707
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6056s / 142.6852 s
agent0:                 episode reward: 0.4983,                 loss: nan
agent1:                 episode reward: -0.4983,                 loss: 0.3704
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6053s / 143.2905 s
agent0:                 episode reward: 0.4218,                 loss: nan
agent1:                 episode reward: -0.4218,                 loss: 0.3743
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5948s / 143.8853 s
agent0:                 episode reward: 1.2133,                 loss: nan
agent1:                 episode reward: -1.2133,                 loss: 0.3710
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6097s / 144.4950 s
agent0:                 episode reward: 1.1402,                 loss: nan
agent1:                 episode reward: -1.1402,                 loss: 0.3710
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6026s / 145.0976 s
agent0:                 episode reward: 1.2154,                 loss: nan
agent1:                 episode reward: -1.2154,                 loss: 0.3697
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6277s / 145.7253 s
agent0:                 episode reward: 1.7479,                 loss: nan
agent1:                 episode reward: -1.7479,                 loss: 0.3680
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6124s / 146.3378 s
agent0:                 episode reward: 0.1093,                 loss: nan
agent1:                 episode reward: -0.1093,                 loss: 0.3085
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6041s / 146.9418 s
agent0:                 episode reward: 1.2902,                 loss: nan
agent1:                 episode reward: -1.2902,                 loss: 0.2651
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6016s / 147.5435 s
agent0:                 episode reward: 0.4488,                 loss: nan
agent1:                 episode reward: -0.4488,                 loss: 0.2635
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6041s / 148.1476 s
agent0:                 episode reward: 0.9586,                 loss: nan
agent1:                 episode reward: -0.9586,                 loss: 0.2615
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6448s / 148.7923 s
agent0:                 episode reward: 2.1294,                 loss: nan
agent1:                 episode reward: -2.1294,                 loss: 0.2628
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6187s / 149.4111 s
agent0:                 episode reward: -0.0970,                 loss: nan
agent1:                 episode reward: 0.0970,                 loss: 0.2611
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6067s / 150.0178 s
agent0:                 episode reward: 1.7633,                 loss: nan
agent1:                 episode reward: -1.7633,                 loss: 0.2619
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6078s / 150.6255 s
agent0:                 episode reward: 1.1382,                 loss: nan
agent1:                 episode reward: -1.1382,                 loss: 0.2606
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6045s / 151.2301 s
agent0:                 episode reward: 1.1420,                 loss: nan
agent1:                 episode reward: -1.1420,                 loss: 0.2599
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6223s / 151.8524 s
agent0:                 episode reward: -0.0412,                 loss: nan
agent1:                 episode reward: 0.0412,                 loss: 0.2602
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6048s / 152.4572 s
agent0:                 episode reward: 0.2499,                 loss: nan
agent1:                 episode reward: -0.2499,                 loss: 0.2218
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6082s / 153.0654 s
agent0:                 episode reward: -0.1161,                 loss: nan
agent1:                 episode reward: 0.1161,                 loss: 0.1925
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6153s / 153.6807 s
agent0:                 episode reward: 0.5576,                 loss: nan
agent1:                 episode reward: -0.5576,                 loss: 0.1924
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6290s / 154.3097 s
agent0:                 episode reward: 0.5150,                 loss: nan
agent1:                 episode reward: -0.5150,                 loss: 0.1908
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6171s / 154.9268 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.1915
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6137s / 155.5405 s
agent0:                 episode reward: 1.9359,                 loss: nan
agent1:                 episode reward: -1.9359,                 loss: 0.1918
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6185s / 156.1590 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: 0.1910
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6099s / 156.7689 s
agent0:                 episode reward: 0.8684,                 loss: nan
agent1:                 episode reward: -0.8684,                 loss: 0.1919
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6135s / 157.3824 s
agent0:                 episode reward: 0.4551,                 loss: nan
agent1:                 episode reward: -0.4551,                 loss: 0.1885
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6272s / 158.0096 s
agent0:                 episode reward: 1.7805,                 loss: nan
agent1:                 episode reward: -1.7805,                 loss: 0.1902
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6184s / 158.6280 s
agent0:                 episode reward: 0.4956,                 loss: nan
agent1:                 episode reward: -0.4956,                 loss: 0.2009
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6545s / 159.2824 s
agent0:                 episode reward: 0.7697,                 loss: nan
agent1:                 episode reward: -0.7697,                 loss: 0.1990
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6240s / 159.9064 s
agent0:                 episode reward: 0.5472,                 loss: nan
agent1:                 episode reward: -0.5472,                 loss: 0.1991
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6207s / 160.5272 s
agent0:                 episode reward: 1.5970,                 loss: nan
agent1:                 episode reward: -1.5970,                 loss: 0.1975
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6292s / 161.1564 s
agent0:                 episode reward: 0.9752,                 loss: nan
agent1:                 episode reward: -0.9752,                 loss: 0.1993
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6129s / 161.7693 s
agent0:                 episode reward: 0.9971,                 loss: nan
agent1:                 episode reward: -0.9971,                 loss: 0.1997
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6454s / 162.4147 s
agent0:                 episode reward: 1.5676,                 loss: nan
agent1:                 episode reward: -1.5676,                 loss: 0.1961
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6163s / 163.0310 s
agent0:                 episode reward: 0.5428,                 loss: nan
agent1:                 episode reward: -0.5428,                 loss: 0.1959
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6216s / 163.6526 s
agent0:                 episode reward: 0.9883,                 loss: nan
agent1:                 episode reward: -0.9883,                 loss: 0.1954
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6317s / 164.2843 s
agent0:                 episode reward: 1.8897,                 loss: nan
agent1:                 episode reward: -1.8897,                 loss: 0.1966
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6225s / 164.9068 s
agent0:                 episode reward: 0.3828,                 loss: nan
agent1:                 episode reward: -0.3828,                 loss: 0.2294
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6157s / 165.5225 s
agent0:                 episode reward: 1.2949,                 loss: nan
agent1:                 episode reward: -1.2949,                 loss: 0.2361
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6257s / 166.1483 s
agent0:                 episode reward: 0.7191,                 loss: nan
agent1:                 episode reward: -0.7191,                 loss: 0.2323
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6213s / 166.7696 s
agent0:                 episode reward: 0.8262,                 loss: nan
agent1:                 episode reward: -0.8262,                 loss: 0.2315
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6319s / 167.4014 s
agent0:                 episode reward: 1.7982,                 loss: nan
agent1:                 episode reward: -1.7982,                 loss: 0.2327
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6244s / 168.0258 s
agent0:                 episode reward: 0.6734,                 loss: nan
agent1:                 episode reward: -0.6734,                 loss: 0.2339
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6441s / 168.6699 s
agent0:                 episode reward: -0.1696,                 loss: nan
agent1:                 episode reward: 0.1696,                 loss: 0.2324
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6597s / 169.3296 s
agent0:                 episode reward: -0.2547,                 loss: nan
agent1:                 episode reward: 0.2547,                 loss: 0.2306
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6302s / 169.9598 s
agent0:                 episode reward: 0.6532,                 loss: nan
agent1:                 episode reward: -0.6532,                 loss: 0.2305
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6460s / 170.6058 s
agent0:                 episode reward: 0.3593,                 loss: nan
agent1:                 episode reward: -0.3593,                 loss: 0.2315
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6257s / 171.2315 s
agent0:                 episode reward: -0.1418,                 loss: nan
agent1:                 episode reward: 0.1418,                 loss: 0.2704
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6223s / 171.8538 s
agent0:                 episode reward: 0.9605,                 loss: nan
agent1:                 episode reward: -0.9605,                 loss: 0.2773
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6385s / 172.4922 s
agent0:                 episode reward: -0.1366,                 loss: nan
agent1:                 episode reward: 0.1366,                 loss: 0.2771
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6492s / 173.1414 s
agent0:                 episode reward: 0.4617,                 loss: nan
agent1:                 episode reward: -0.4617,                 loss: 0.2768
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6249s / 173.7663 s
agent0:                 episode reward: 0.7671,                 loss: nan
agent1:                 episode reward: -0.7671,                 loss: 0.2743
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6303s / 174.3967 s
agent0:                 episode reward: -0.7158,                 loss: nan
agent1:                 episode reward: 0.7158,                 loss: 0.2753
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6317s / 175.0284 s
agent0:                 episode reward: 0.9035,                 loss: nan
agent1:                 episode reward: -0.9035,                 loss: 0.2742
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6292s / 175.6576 s
agent0:                 episode reward: 0.8509,                 loss: nan
agent1:                 episode reward: -0.8509,                 loss: 0.2743
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6307s / 176.2883 s
agent0:                 episode reward: 0.9092,                 loss: nan
agent1:                 episode reward: -0.9092,                 loss: 0.2745
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6364s / 176.9247 s
agent0:                 episode reward: -0.3343,                 loss: nan
agent1:                 episode reward: 0.3343,                 loss: 0.2732
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6297s / 177.5544 s
agent0:                 episode reward: 0.8862,                 loss: nan
agent1:                 episode reward: -0.8862,                 loss: 0.3015
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6227s / 178.1771 s
agent0:                 episode reward: 1.8086,                 loss: nan
agent1:                 episode reward: -1.8086,                 loss: 0.2996
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6522s / 178.8293 s
agent0:                 episode reward: 2.0400,                 loss: nan
agent1:                 episode reward: -2.0400,                 loss: 0.2968
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6768s / 179.5061 s
agent0:                 episode reward: 1.1339,                 loss: nan
agent1:                 episode reward: -1.1339,                 loss: 0.2963
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6555s / 180.1616 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.2981
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6406s / 180.8021 s
agent0:                 episode reward: -0.2815,                 loss: nan
agent1:                 episode reward: 0.2815,                 loss: 0.2981
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6401s / 181.4422 s
agent0:                 episode reward: 1.3003,                 loss: nan
agent1:                 episode reward: -1.3003,                 loss: 0.2965
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6448s / 182.0870 s
agent0:                 episode reward: 0.2771,                 loss: nan
agent1:                 episode reward: -0.2771,                 loss: 0.2963
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6384s / 182.7254 s
agent0:                 episode reward: 1.0114,                 loss: nan
agent1:                 episode reward: -1.0114,                 loss: 0.2959
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6394s / 183.3648 s
agent0:                 episode reward: 1.0093,                 loss: nan
agent1:                 episode reward: -1.0093,                 loss: 0.2933
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6449s / 184.0096 s
agent0:                 episode reward: 0.5258,                 loss: nan
agent1:                 episode reward: -0.5258,                 loss: 0.3016
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6346s / 184.6442 s
agent0:                 episode reward: 0.8546,                 loss: nan
agent1:                 episode reward: -0.8546,                 loss: 0.2919
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6463s / 185.2906 s
agent0:                 episode reward: 1.6276,                 loss: nan
agent1:                 episode reward: -1.6276,                 loss: 0.2869
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6466s / 185.9372 s
agent0:                 episode reward: 0.5593,                 loss: nan
agent1:                 episode reward: -0.5593,                 loss: 0.2871
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6336s / 186.5708 s
agent0:                 episode reward: 1.3128,                 loss: nan
agent1:                 episode reward: -1.3128,                 loss: 0.2877
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6525s / 187.2233 s
agent0:                 episode reward: 0.6703,                 loss: nan
agent1:                 episode reward: -0.6703,                 loss: 0.2865
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6396s / 187.8629 s
agent0:                 episode reward: 2.3924,                 loss: nan
agent1:                 episode reward: -2.3924,                 loss: 0.2890
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6504s / 188.5133 s
agent0:                 episode reward: 1.7988,                 loss: nan
agent1:                 episode reward: -1.7988,                 loss: 0.2873
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6971s / 189.2104 s
agent0:                 episode reward: 0.5829,                 loss: nan
agent1:                 episode reward: -0.5829,                 loss: 0.2852
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6918s / 189.9022 s
agent0:                 episode reward: 1.5861,                 loss: nan
agent1:                 episode reward: -1.5861,                 loss: 0.2844
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6515s / 190.5537 s
agent0:                 episode reward: 0.1335,                 loss: nan
agent1:                 episode reward: -0.1335,                 loss: 0.2985
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6645s / 191.2182 s
agent0:                 episode reward: 0.8270,                 loss: nan
agent1:                 episode reward: -0.8270,                 loss: 0.2928
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6447s / 191.8629 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.2907
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6544s / 192.5173 s
agent0:                 episode reward: 0.5701,                 loss: nan
agent1:                 episode reward: -0.5701,                 loss: 0.2903
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6438s / 193.1611 s
agent0:                 episode reward: -0.3876,                 loss: nan
agent1:                 episode reward: 0.3876,                 loss: 0.2907
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6431s / 193.8042 s
agent0:                 episode reward: 0.9464,                 loss: nan
agent1:                 episode reward: -0.9464,                 loss: 0.2923
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6660s / 194.4703 s
agent0:                 episode reward: 1.4701,                 loss: nan
agent1:                 episode reward: -1.4701,                 loss: 0.2890
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6435s / 195.1138 s
agent0:                 episode reward: 1.1323,                 loss: nan
agent1:                 episode reward: -1.1323,                 loss: 0.2904
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6611s / 195.7748 s
agent0:                 episode reward: 0.4762,                 loss: nan
agent1:                 episode reward: -0.4762,                 loss: 0.2886
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6450s / 196.4199 s
agent0:                 episode reward: 1.3275,                 loss: nan
agent1:                 episode reward: -1.3275,                 loss: 0.2879
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6515s / 197.0714 s
agent0:                 episode reward: 1.4814,                 loss: nan
agent1:                 episode reward: -1.4814,                 loss: 0.3246
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6439s / 197.7153 s
agent0:                 episode reward: 1.7643,                 loss: nan
agent1:                 episode reward: -1.7643,                 loss: 0.3307
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6547s / 198.3701 s
agent0:                 episode reward: 2.3740,                 loss: nan
agent1:                 episode reward: -2.3740,                 loss: 0.3278
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6514s / 199.0215 s
agent0:                 episode reward: 0.5948,                 loss: nan
agent1:                 episode reward: -0.5948,                 loss: 0.3282
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6475s / 199.6690 s
agent0:                 episode reward: 0.5703,                 loss: nan
agent1:                 episode reward: -0.5703,                 loss: 0.3274
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 200.3708 s
agent0:                 episode reward: 1.0546,                 loss: nan
agent1:                 episode reward: -1.0546,                 loss: 0.3258
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6528s / 201.0236 s
agent0:                 episode reward: 0.6974,                 loss: nan
agent1:                 episode reward: -0.6974,                 loss: 0.3265
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6545s / 201.6781 s
agent0:                 episode reward: 1.2196,                 loss: nan
agent1:                 episode reward: -1.2196,                 loss: 0.3253
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6551s / 202.3332 s
agent0:                 episode reward: 0.7643,                 loss: nan
agent1:                 episode reward: -0.7643,                 loss: 0.3281
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6666s / 202.9998 s
agent0:                 episode reward: 0.8337,                 loss: nan
agent1:                 episode reward: -0.8337,                 loss: 0.3240
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6513s / 203.6511 s
agent0:                 episode reward: 1.1795,                 loss: nan
agent1:                 episode reward: -1.1795,                 loss: 0.3473
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6782s / 204.3293 s
agent0:                 episode reward: 1.9422,                 loss: nan
agent1:                 episode reward: -1.9422,                 loss: 0.3339
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6547s / 204.9840 s
agent0:                 episode reward: 0.3801,                 loss: nan
agent1:                 episode reward: -0.3801,                 loss: 0.3319
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6689s / 205.6529 s
agent0:                 episode reward: 1.0850,                 loss: nan
agent1:                 episode reward: -1.0850,                 loss: 0.3306
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6554s / 206.3083 s
agent0:                 episode reward: 0.5799,                 loss: nan
agent1:                 episode reward: -0.5799,                 loss: 0.3252
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6608s / 206.9691 s
agent0:                 episode reward: 1.1613,                 loss: nan
agent1:                 episode reward: -1.1613,                 loss: 0.3263
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6573s / 207.6264 s
agent0:                 episode reward: -0.1226,                 loss: nan
agent1:                 episode reward: 0.1226,                 loss: 0.3295
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6561s / 208.2825 s
agent0:                 episode reward: 1.8107,                 loss: nan
agent1:                 episode reward: -1.8107,                 loss: 0.3269
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6601s / 208.9426 s
agent0:                 episode reward: 0.6839,                 loss: nan
agent1:                 episode reward: -0.6839,                 loss: 0.3249
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6853s / 209.6280 s
agent0:                 episode reward: 0.6017,                 loss: nan
agent1:                 episode reward: -0.6017,                 loss: 0.3256
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6964s / 210.3244 s
agent0:                 episode reward: 1.3311,                 loss: nan
agent1:                 episode reward: -1.3311,                 loss: 0.3043
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6724s / 210.9968 s
agent0:                 episode reward: 0.8630,                 loss: nan
agent1:                 episode reward: -0.8630,                 loss: 0.2576
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6679s / 211.6647 s
agent0:                 episode reward: 0.2904,                 loss: nan
agent1:                 episode reward: -0.2904,                 loss: 0.2486
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6751s / 212.3398 s
agent0:                 episode reward: 0.9847,                 loss: nan
agent1:                 episode reward: -0.9847,                 loss: 0.2483
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6927s / 213.0325 s
agent0:                 episode reward: 1.3900,                 loss: nan
agent1:                 episode reward: -1.3900,                 loss: 0.2469
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6679s / 213.7004 s
agent0:                 episode reward: 0.6761,                 loss: nan
agent1:                 episode reward: -0.6761,                 loss: 0.2445
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6578s / 214.3582 s
agent0:                 episode reward: 1.4154,                 loss: nan
agent1:                 episode reward: -1.4154,                 loss: 0.2449
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6656s / 215.0238 s
agent0:                 episode reward: 0.7773,                 loss: nan
agent1:                 episode reward: -0.7773,                 loss: 0.2438
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6713s / 215.6951 s
agent0:                 episode reward: 0.2773,                 loss: nan
agent1:                 episode reward: -0.2773,                 loss: 0.2436
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6654s / 216.3606 s
agent0:                 episode reward: 0.3135,                 loss: nan
agent1:                 episode reward: -0.3135,                 loss: 0.2422
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6658s / 217.0264 s
agent0:                 episode reward: 0.1941,                 loss: nan
agent1:                 episode reward: -0.1941,                 loss: 0.2262
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6704s / 217.6968 s
agent0:                 episode reward: 1.0351,                 loss: nan
agent1:                 episode reward: -1.0351,                 loss: 0.2001
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6757s / 218.3725 s
agent0:                 episode reward: 1.3404,                 loss: nan
agent1:                 episode reward: -1.3404,                 loss: 0.1981
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6599s / 219.0324 s
agent0:                 episode reward: 0.1598,                 loss: nan
agent1:                 episode reward: -0.1598,                 loss: 0.1934
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6660s / 219.6984 s
agent0:                 episode reward: 1.4938,                 loss: nan
agent1:                 episode reward: -1.4938,                 loss: 0.1923
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7247s / 220.4231 s
agent0:                 episode reward: 0.5940,                 loss: nan
agent1:                 episode reward: -0.5940,                 loss: 0.1922
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7050s / 221.1281 s
agent0:                 episode reward: 0.2889,                 loss: nan
agent1:                 episode reward: -0.2889,                 loss: 0.1904
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6761s / 221.8042 s
agent0:                 episode reward: 1.0052,                 loss: nan
agent1:                 episode reward: -1.0052,                 loss: 0.1884
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6732s / 222.4774 s
agent0:                 episode reward: 0.2972,                 loss: nan
agent1:                 episode reward: -0.2972,                 loss: 0.1896
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6735s / 223.1510 s
agent0:                 episode reward: 0.9955,                 loss: nan
agent1:                 episode reward: -0.9955,                 loss: 0.1912
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6725s / 223.8235 s
agent0:                 episode reward: 0.6727,                 loss: nan
agent1:                 episode reward: -0.6727,                 loss: 0.2193
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6886s / 224.5121 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.2288
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6675s / 225.1795 s
agent0:                 episode reward: 1.0884,                 loss: nan
agent1:                 episode reward: -1.0884,                 loss: 0.2271
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6762s / 225.8558 s
agent0:                 episode reward: -0.1988,                 loss: nan
agent1:                 episode reward: 0.1988,                 loss: 0.2248
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6808s / 226.5365 s
agent0:                 episode reward: 0.0759,                 loss: nan
agent1:                 episode reward: -0.0759,                 loss: 0.2263
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6710s / 227.2075 s
agent0:                 episode reward: 0.8737,                 loss: nan
agent1:                 episode reward: -0.8737,                 loss: 0.2221
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6858s / 227.8933 s
agent0:                 episode reward: 0.8774,                 loss: nan
agent1:                 episode reward: -0.8774,                 loss: 0.2218
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6818s / 228.5751 s
agent0:                 episode reward: 1.5101,                 loss: nan
agent1:                 episode reward: -1.5101,                 loss: 0.2214
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6888s / 229.2638 s
agent0:                 episode reward: -0.0196,                 loss: nan
agent1:                 episode reward: 0.0196,                 loss: 0.2204
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6802s / 229.9441 s
agent0:                 episode reward: 1.3089,                 loss: nan
agent1:                 episode reward: -1.3089,                 loss: 0.2211
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6902s / 230.6343 s
agent0:                 episode reward: 0.9485,                 loss: nan
agent1:                 episode reward: -0.9485,                 loss: 0.2515
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7122s / 231.3465 s
agent0:                 episode reward: 0.9233,                 loss: nan
agent1:                 episode reward: -0.9233,                 loss: 0.2641
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6833s / 232.0298 s
agent0:                 episode reward: 0.7637,                 loss: nan
agent1:                 episode reward: -0.7637,                 loss: 0.2621
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6872s / 232.7170 s
agent0:                 episode reward: 1.2223,                 loss: nan
agent1:                 episode reward: -1.2223,                 loss: 0.2607
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6950s / 233.4121 s
agent0:                 episode reward: 0.5054,                 loss: nan
agent1:                 episode reward: -0.5054,                 loss: 0.2592
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6823s / 234.0943 s
agent0:                 episode reward: 0.9893,                 loss: nan
agent1:                 episode reward: -0.9893,                 loss: 0.2586
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6881s / 234.7824 s
agent0:                 episode reward: 0.6606,                 loss: nan
agent1:                 episode reward: -0.6606,                 loss: 0.2593
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6960s / 235.4784 s
agent0:                 episode reward: 0.9684,                 loss: nan
agent1:                 episode reward: -0.9684,                 loss: 0.2593
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6839s / 236.1622 s
agent0:                 episode reward: -0.1324,                 loss: nan
agent1:                 episode reward: 0.1324,                 loss: 0.2586
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6925s / 236.8547 s
agent0:                 episode reward: 1.0522,                 loss: nan
agent1:                 episode reward: -1.0522,                 loss: 0.2591
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7017s / 237.5565 s
agent0:                 episode reward: 0.3553,                 loss: nan
agent1:                 episode reward: -0.3553,                 loss: 0.2917
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6842s / 238.2406 s
agent0:                 episode reward: 0.9045,                 loss: nan
agent1:                 episode reward: -0.9045,                 loss: 0.2963
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6885s / 238.9291 s
agent0:                 episode reward: 1.5520,                 loss: nan
agent1:                 episode reward: -1.5520,                 loss: 0.2968
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7004s / 239.6294 s
agent0:                 episode reward: 1.2159,                 loss: nan
agent1:                 episode reward: -1.2159,                 loss: 0.2972
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6825s / 240.3119 s
agent0:                 episode reward: 0.4143,                 loss: nan
agent1:                 episode reward: -0.4143,                 loss: 0.2949
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7264s / 241.0383 s
agent0:                 episode reward: 0.7419,                 loss: nan
agent1:                 episode reward: -0.7419,                 loss: 0.2937
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7009s / 241.7392 s
agent0:                 episode reward: 1.5073,                 loss: nan
agent1:                 episode reward: -1.5073,                 loss: 0.2938
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6957s / 242.4350 s
agent0:                 episode reward: 0.9012,                 loss: nan
agent1:                 episode reward: -0.9012,                 loss: 0.2936
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7111s / 243.1460 s
agent0:                 episode reward: 1.1183,                 loss: nan
agent1:                 episode reward: -1.1183,                 loss: 0.2935
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6985s / 243.8445 s
agent0:                 episode reward: 0.9618,                 loss: nan
agent1:                 episode reward: -0.9618,                 loss: 0.2935
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6832s / 244.5278 s
agent0:                 episode reward: 0.7370,                 loss: nan
agent1:                 episode reward: -0.7370,                 loss: 0.3138
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 245.2297 s
agent0:                 episode reward: 0.2958,                 loss: nan
agent1:                 episode reward: -0.2958,                 loss: 0.3140
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7045s / 245.9342 s
agent0:                 episode reward: 0.8983,                 loss: nan
agent1:                 episode reward: -0.8983,                 loss: 0.3140
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6830s / 246.6172 s
agent0:                 episode reward: 0.8139,                 loss: nan
agent1:                 episode reward: -0.8139,                 loss: 0.3141
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6915s / 247.3087 s
agent0:                 episode reward: 1.2319,                 loss: nan
agent1:                 episode reward: -1.2319,                 loss: 0.3112
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6913s / 248.0000 s
agent0:                 episode reward: 0.8954,                 loss: nan
agent1:                 episode reward: -0.8954,                 loss: 0.3122
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6981s / 248.6981 s
agent0:                 episode reward: 1.3527,                 loss: nan
agent1:                 episode reward: -1.3527,                 loss: 0.3116
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6900s / 249.3881 s
agent0:                 episode reward: 0.6119,                 loss: nan
agent1:                 episode reward: -0.6119,                 loss: 0.3125
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6923s / 250.0804 s
agent0:                 episode reward: -0.1375,                 loss: nan
agent1:                 episode reward: 0.1375,                 loss: 0.3113
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6965s / 250.7769 s
agent0:                 episode reward: 0.9715,                 loss: nan
agent1:                 episode reward: -0.9715,                 loss: 0.3101
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7470s / 251.5239 s
agent0:                 episode reward: 1.4013,                 loss: nan
agent1:                 episode reward: -1.4013,                 loss: 0.3228
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6974s / 252.2213 s
agent0:                 episode reward: 0.9208,                 loss: nan
agent1:                 episode reward: -0.9208,                 loss: 0.3228
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6923s / 252.9136 s
agent0:                 episode reward: -0.3113,                 loss: nan
agent1:                 episode reward: 0.3113,                 loss: 0.3214
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7140s / 253.6277 s
agent0:                 episode reward: 0.2757,                 loss: nan
agent1:                 episode reward: -0.2757,                 loss: 0.3185
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7043s / 254.3320 s
agent0:                 episode reward: 1.3604,                 loss: nan
agent1:                 episode reward: -1.3604,                 loss: 0.3178
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6959s / 255.0279 s
agent0:                 episode reward: 0.6965,                 loss: nan
agent1:                 episode reward: -0.6965,                 loss: 0.3188
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6984s / 255.7263 s
agent0:                 episode reward: 1.0955,                 loss: nan
agent1:                 episode reward: -1.0955,                 loss: 0.3158
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7024s / 256.4287 s
agent0:                 episode reward: 0.4363,                 loss: nan
agent1:                 episode reward: -0.4363,                 loss: 0.3162
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7218s / 257.1505 s
agent0:                 episode reward: 0.1845,                 loss: nan
agent1:                 episode reward: -0.1845,                 loss: 0.3147
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6986s / 257.8491 s
agent0:                 episode reward: 1.1413,                 loss: nan
agent1:                 episode reward: -1.1413,                 loss: 0.3169
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6984s / 258.5475 s
agent0:                 episode reward: 0.4424,                 loss: nan
agent1:                 episode reward: -0.4424,                 loss: 0.3294
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7006s / 259.2481 s
agent0:                 episode reward: 0.2782,                 loss: nan
agent1:                 episode reward: -0.2782,                 loss: 0.3291
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6969s / 259.9449 s
agent0:                 episode reward: 1.7580,                 loss: nan
agent1:                 episode reward: -1.7580,                 loss: 0.3253
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7192s / 260.6641 s
agent0:                 episode reward: 0.1485,                 loss: nan
agent1:                 episode reward: -0.1485,                 loss: 0.3262
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7083s / 261.3724 s
agent0:                 episode reward: 0.7806,                 loss: nan
agent1:                 episode reward: -0.7806,                 loss: 0.3259
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7513s / 262.1236 s
agent0:                 episode reward: 0.3925,                 loss: nan
agent1:                 episode reward: -0.3925,                 loss: 0.3232
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7054s / 262.8290 s
agent0:                 episode reward: 1.0751,                 loss: nan
agent1:                 episode reward: -1.0751,                 loss: 0.3205
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7108s / 263.5398 s
agent0:                 episode reward: 1.1338,                 loss: nan
agent1:                 episode reward: -1.1338,                 loss: 0.3234
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7060s / 264.2458 s
agent0:                 episode reward: 1.0321,                 loss: nan
agent1:                 episode reward: -1.0321,                 loss: 0.3214
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7048s / 264.9506 s
agent0:                 episode reward: 0.9038,                 loss: nan
agent1:                 episode reward: -0.9038,                 loss: 0.3202
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7115s / 265.6622 s
agent0:                 episode reward: 1.1011,                 loss: nan
agent1:                 episode reward: -1.1011,                 loss: 0.3507
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7158s / 266.3779 s
agent0:                 episode reward: 1.3495,                 loss: nan
agent1:                 episode reward: -1.3495,                 loss: 0.3599
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7142s / 267.0921 s
agent0:                 episode reward: 0.7847,                 loss: nan
agent1:                 episode reward: -0.7847,                 loss: 0.3577
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6936s / 267.7857 s
agent0:                 episode reward: 1.0086,                 loss: nan
agent1:                 episode reward: -1.0086,                 loss: 0.3554
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7039s / 268.4896 s
agent0:                 episode reward: 0.9603,                 loss: nan
agent1:                 episode reward: -0.9603,                 loss: 0.3544
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7025s / 269.1921 s
agent0:                 episode reward: 0.2629,                 loss: nan
agent1:                 episode reward: -0.2629,                 loss: 0.3535
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7055s / 269.8976 s
agent0:                 episode reward: 0.6023,                 loss: nan
agent1:                 episode reward: -0.6023,                 loss: 0.3554
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7245s / 270.6220 s
agent0:                 episode reward: 0.2774,                 loss: nan
agent1:                 episode reward: -0.2774,                 loss: 0.3552
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7082s / 271.3302 s
agent0:                 episode reward: 1.2461,                 loss: nan
agent1:                 episode reward: -1.2461,                 loss: 0.3547
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7367s / 272.0669 s
agent0:                 episode reward: 1.7003,                 loss: nan
agent1:                 episode reward: -1.7003,                 loss: 0.3560
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7199s / 272.7869 s
agent0:                 episode reward: 1.2279,                 loss: nan
agent1:                 episode reward: -1.2279,                 loss: 0.3907
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7084s / 273.4953 s
agent0:                 episode reward: 0.9154,                 loss: nan
agent1:                 episode reward: -0.9154,                 loss: 0.3943
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7119s / 274.2072 s
agent0:                 episode reward: 1.0957,                 loss: nan
agent1:                 episode reward: -1.0957,                 loss: 0.3929
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7118s / 274.9190 s
agent0:                 episode reward: 1.6385,                 loss: nan
agent1:                 episode reward: -1.6385,                 loss: 0.3919
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7255s / 275.6445 s
agent0:                 episode reward: 0.9104,                 loss: nan
agent1:                 episode reward: -0.9104,                 loss: 0.3900
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7066s / 276.3511 s
agent0:                 episode reward: 0.0597,                 loss: nan
agent1:                 episode reward: -0.0597,                 loss: 0.3911
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7147s / 277.0658 s
agent0:                 episode reward: 1.3623,                 loss: nan
agent1:                 episode reward: -1.3623,                 loss: 0.3887
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7163s / 277.7821 s
agent0:                 episode reward: 0.4984,                 loss: nan
agent1:                 episode reward: -0.4984,                 loss: 0.3893
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7632s / 278.5452 s
agent0:                 episode reward: 0.9554,                 loss: nan
agent1:                 episode reward: -0.9554,                 loss: 0.3889
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7145s / 279.2597 s
agent0:                 episode reward: 0.2213,                 loss: nan
agent1:                 episode reward: -0.2213,                 loss: 0.3901
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7170s / 279.9767 s
agent0:                 episode reward: 0.3941,                 loss: nan
agent1:                 episode reward: -0.3941,                 loss: 0.3827
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7138s / 280.6905 s
agent0:                 episode reward: 1.5266,                 loss: nan
agent1:                 episode reward: -1.5266,                 loss: 0.3706
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7200s / 281.4105 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.3669
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7664s / 282.1768 s
agent0:                 episode reward: -0.3959,                 loss: nan
agent1:                 episode reward: 0.3959,                 loss: 0.3677
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7167s / 282.8936 s
agent0:                 episode reward: 0.7906,                 loss: nan
agent1:                 episode reward: -0.7906,                 loss: 0.3654
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7284s / 283.6219 s
agent0:                 episode reward: 1.1664,                 loss: nan
agent1:                 episode reward: -1.1664,                 loss: 0.3681
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7146s / 284.3366 s
agent0:                 episode reward: 0.6252,                 loss: nan
agent1:                 episode reward: -0.6252,                 loss: 0.3674
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7316s / 285.0681 s
agent0:                 episode reward: -0.0743,                 loss: nan
agent1:                 episode reward: 0.0743,                 loss: 0.3655
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7210s / 285.7891 s
agent0:                 episode reward: 0.6010,                 loss: nan
agent1:                 episode reward: -0.6010,                 loss: 0.3676
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7158s / 286.5049 s
agent0:                 episode reward: 1.0695,                 loss: nan
agent1:                 episode reward: -1.0695,                 loss: 0.3676
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7384s / 287.2433 s
agent0:                 episode reward: -0.0074,                 loss: nan
agent1:                 episode reward: 0.0074,                 loss: 0.3127
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7326s / 287.9759 s
agent0:                 episode reward: 0.1306,                 loss: nan
agent1:                 episode reward: -0.1306,                 loss: 0.2798
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7163s / 288.6922 s
agent0:                 episode reward: 1.1521,                 loss: nan
agent1:                 episode reward: -1.1521,                 loss: 0.2709
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7168s / 289.4091 s
agent0:                 episode reward: 0.4109,                 loss: nan
agent1:                 episode reward: -0.4109,                 loss: 0.2695
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7264s / 290.1355 s
agent0:                 episode reward: 0.7543,                 loss: nan
agent1:                 episode reward: -0.7543,                 loss: 0.2716
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7393s / 290.8747 s
agent0:                 episode reward: 0.9290,                 loss: nan
agent1:                 episode reward: -0.9290,                 loss: 0.2707
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7547s / 291.6294 s
agent0:                 episode reward: 1.6850,                 loss: nan
agent1:                 episode reward: -1.6850,                 loss: 0.2695
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7799s / 292.4094 s
agent0:                 episode reward: 0.2494,                 loss: nan
agent1:                 episode reward: -0.2494,                 loss: 0.2682
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7214s / 293.1308 s
agent0:                 episode reward: 0.9688,                 loss: nan
agent1:                 episode reward: -0.9688,                 loss: 0.2665
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7372s / 293.8679 s
agent0:                 episode reward: 0.4446,                 loss: nan
agent1:                 episode reward: -0.4446,                 loss: 0.2653
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7320s / 294.5999 s
agent0:                 episode reward: 0.5288,                 loss: nan
agent1:                 episode reward: -0.5288,                 loss: 0.2366
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7348s / 295.3347 s
agent0:                 episode reward: 1.2970,                 loss: nan
agent1:                 episode reward: -1.2970,                 loss: 0.2150
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7253s / 296.0600 s
agent0:                 episode reward: 0.9403,                 loss: nan
agent1:                 episode reward: -0.9403,                 loss: 0.2128
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7433s / 296.8034 s
agent0:                 episode reward: 0.2292,                 loss: nan
agent1:                 episode reward: -0.2292,                 loss: 0.2122
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7325s / 297.5358 s
agent0:                 episode reward: 1.0983,                 loss: nan
agent1:                 episode reward: -1.0983,                 loss: 0.2131
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7331s / 298.2689 s
agent0:                 episode reward: 0.4476,                 loss: nan
agent1:                 episode reward: -0.4476,                 loss: 0.2105
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7421s / 299.0110 s
agent0:                 episode reward: 1.7083,                 loss: nan
agent1:                 episode reward: -1.7083,                 loss: 0.2117
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7378s / 299.7488 s
agent0:                 episode reward: 1.1297,                 loss: nan
agent1:                 episode reward: -1.1297,                 loss: 0.2100
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7652s / 300.5140 s
agent0:                 episode reward: 0.1731,                 loss: nan
agent1:                 episode reward: -0.1731,                 loss: 0.2113
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7353s / 301.2493 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.2127
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 301.9816 s
agent0:                 episode reward: 0.7291,                 loss: nan
agent1:                 episode reward: -0.7291,                 loss: 0.2226
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7691s / 302.7507 s
agent0:                 episode reward: 0.1004,                 loss: nan
agent1:                 episode reward: -0.1004,                 loss: 0.2159
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7451s / 303.4958 s
agent0:                 episode reward: 1.0324,                 loss: nan
agent1:                 episode reward: -1.0324,                 loss: 0.2145
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7568s / 304.2526 s
agent0:                 episode reward: 0.8179,                 loss: nan
agent1:                 episode reward: -0.8179,                 loss: 0.2144
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7454s / 304.9980 s
agent0:                 episode reward: 0.6399,                 loss: nan
agent1:                 episode reward: -0.6399,                 loss: 0.2140
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7958s / 305.7937 s
agent0:                 episode reward: 1.0129,                 loss: nan
agent1:                 episode reward: -1.0129,                 loss: 0.2148
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7520s / 306.5457 s
agent0:                 episode reward: 0.4592,                 loss: nan
agent1:                 episode reward: -0.4592,                 loss: 0.2141
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7414s / 307.2872 s
agent0:                 episode reward: 0.1603,                 loss: nan
agent1:                 episode reward: -0.1603,                 loss: 0.2137
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7373s / 308.0244 s
agent0:                 episode reward: 0.5461,                 loss: nan
agent1:                 episode reward: -0.5461,                 loss: 0.2113
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7568s / 308.7812 s
agent0:                 episode reward: 0.4471,                 loss: nan
agent1:                 episode reward: -0.4471,                 loss: 0.2123
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7322s / 309.5134 s
agent0:                 episode reward: 0.4601,                 loss: nan
agent1:                 episode reward: -0.4601,                 loss: 0.2369
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7283s / 310.2417 s
agent0:                 episode reward: 0.4094,                 loss: nan
agent1:                 episode reward: -0.4094,                 loss: 0.2424
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7383s / 310.9800 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: 0.2436
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7586s / 311.7387 s
agent0:                 episode reward: 1.2530,                 loss: nan
agent1:                 episode reward: -1.2530,                 loss: 0.2433
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7451s / 312.4838 s
agent0:                 episode reward: 0.6437,                 loss: nan
agent1:                 episode reward: -0.6437,                 loss: 0.2448
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7869s / 313.2707 s
agent0:                 episode reward: 0.1113,                 loss: nan
agent1:                 episode reward: -0.1113,                 loss: 0.2422
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7328s / 314.0035 s
agent0:                 episode reward: 0.6143,                 loss: nan
agent1:                 episode reward: -0.6143,                 loss: 0.2436
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7727s / 314.7762 s
agent0:                 episode reward: -0.0886,                 loss: nan
agent1:                 episode reward: 0.0886,                 loss: 0.2411
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7633s / 315.5395 s
agent0:                 episode reward: 0.8977,                 loss: nan
agent1:                 episode reward: -0.8977,                 loss: 0.2417
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7387s / 316.2782 s
agent0:                 episode reward: 0.8335,                 loss: nan
agent1:                 episode reward: -0.8335,                 loss: 0.2425
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7419s / 317.0201 s
agent0:                 episode reward: 0.6391,                 loss: nan
agent1:                 episode reward: -0.6391,                 loss: 0.2708
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 317.7687 s
agent0:                 episode reward: 1.5875,                 loss: nan
agent1:                 episode reward: -1.5875,                 loss: 0.2779
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7394s / 318.5081 s
agent0:                 episode reward: 0.8770,                 loss: nan
agent1:                 episode reward: -0.8770,                 loss: 0.2777
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7477s / 319.2558 s
agent0:                 episode reward: 0.7921,                 loss: nan
agent1:                 episode reward: -0.7921,                 loss: 0.2761
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7594s / 320.0153 s
agent0:                 episode reward: 0.3291,                 loss: nan
agent1:                 episode reward: -0.3291,                 loss: 0.2766
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7557s / 320.7710 s
agent0:                 episode reward: 0.6165,                 loss: nan
agent1:                 episode reward: -0.6165,                 loss: 0.2746
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7495s / 321.5205 s
agent0:                 episode reward: 0.5154,                 loss: nan
agent1:                 episode reward: -0.5154,                 loss: 0.2748
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7447s / 322.2652 s
agent0:                 episode reward: 0.6355,                 loss: nan
agent1:                 episode reward: -0.6355,                 loss: 0.2712
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7859s / 323.0511 s
agent0:                 episode reward: 1.0668,                 loss: nan
agent1:                 episode reward: -1.0668,                 loss: 0.2733
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7714s / 323.8225 s
agent0:                 episode reward: 1.0622,                 loss: nan
agent1:                 episode reward: -1.0622,                 loss: 0.2740
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7978s / 324.6203 s
agent0:                 episode reward: 0.8339,                 loss: nan
agent1:                 episode reward: -0.8339,                 loss: 0.3049
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7487s / 325.3690 s
agent0:                 episode reward: 0.6692,                 loss: nan
agent1:                 episode reward: -0.6692,                 loss: 0.3088
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 326.1218 s
agent0:                 episode reward: 1.0347,                 loss: nan
agent1:                 episode reward: -1.0347,                 loss: 0.3043
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7549s / 326.8767 s
agent0:                 episode reward: 0.8111,                 loss: nan
agent1:                 episode reward: -0.8111,                 loss: 0.3036
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7524s / 327.6292 s
agent0:                 episode reward: 0.7034,                 loss: nan
agent1:                 episode reward: -0.7034,                 loss: 0.2993
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8027s / 328.4319 s
agent0:                 episode reward: 0.7143,                 loss: nan
agent1:                 episode reward: -0.7143,                 loss: 0.3017
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7921s / 329.2240 s
agent0:                 episode reward: 1.4452,                 loss: nan
agent1:                 episode reward: -1.4452,                 loss: 0.2981
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7665s / 329.9905 s
agent0:                 episode reward: 1.0081,                 loss: nan
agent1:                 episode reward: -1.0081,                 loss: 0.2969
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7495s / 330.7400 s
agent0:                 episode reward: 0.9578,                 loss: nan
agent1:                 episode reward: -0.9578,                 loss: 0.2934
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7604s / 331.5005 s
agent0:                 episode reward: -0.3239,                 loss: nan
agent1:                 episode reward: 0.3239,                 loss: 0.2933
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7705s / 332.2710 s
agent0:                 episode reward: 1.2335,                 loss: nan
agent1:                 episode reward: -1.2335,                 loss: 0.3010
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8144s / 333.0853 s
agent0:                 episode reward: 0.4194,                 loss: nan
agent1:                 episode reward: -0.4194,                 loss: 0.2967
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7643s / 333.8496 s
agent0:                 episode reward: 0.3171,                 loss: nan
agent1:                 episode reward: -0.3171,                 loss: 0.2958
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7723s / 334.6219 s
agent0:                 episode reward: 0.1924,                 loss: nan
agent1:                 episode reward: -0.1924,                 loss: 0.2948
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8114s / 335.4334 s
agent0:                 episode reward: 0.7089,                 loss: nan
agent1:                 episode reward: -0.7089,                 loss: 0.2933
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7740s / 336.2073 s
agent0:                 episode reward: 0.3343,                 loss: nan
agent1:                 episode reward: -0.3343,                 loss: 0.2923
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7811s / 336.9885 s
agent0:                 episode reward: 0.8566,                 loss: nan
agent1:                 episode reward: -0.8566,                 loss: 0.2936
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7616s / 337.7501 s
agent0:                 episode reward: 0.3706,                 loss: nan
agent1:                 episode reward: -0.3706,                 loss: 0.2933
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7661s / 338.5161 s
agent0:                 episode reward: 0.2700,                 loss: nan
agent1:                 episode reward: -0.2700,                 loss: 0.2951
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7742s / 339.2903 s
agent0:                 episode reward: 1.8041,                 loss: nan
agent1:                 episode reward: -1.8041,                 loss: 0.2946
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7699s / 340.0602 s
agent0:                 episode reward: 1.0036,                 loss: nan
agent1:                 episode reward: -1.0036,                 loss: 0.3059
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7712s / 340.8314 s
agent0:                 episode reward: 0.6239,                 loss: nan
agent1:                 episode reward: -0.6239,                 loss: 0.2997
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7634s / 341.5948 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.2955
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7865s / 342.3813 s
agent0:                 episode reward: 0.7554,                 loss: nan
agent1:                 episode reward: -0.7554,                 loss: 0.2963
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7608s / 343.1421 s
agent0:                 episode reward: 0.4610,                 loss: nan
agent1:                 episode reward: -0.4610,                 loss: 0.2959
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8147s / 343.9568 s
agent0:                 episode reward: 0.5652,                 loss: nan
agent1:                 episode reward: -0.5652,                 loss: 0.2946
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7854s / 344.7422 s
agent0:                 episode reward: 0.8096,                 loss: nan
agent1:                 episode reward: -0.8096,                 loss: 0.2915
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7799s / 345.5221 s
agent0:                 episode reward: 1.5614,                 loss: nan
agent1:                 episode reward: -1.5614,                 loss: 0.2919
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 346.3002 s
agent0:                 episode reward: 0.8620,                 loss: nan
agent1:                 episode reward: -0.8620,                 loss: 0.2918
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7963s / 347.0965 s
agent0:                 episode reward: 1.2378,                 loss: nan
agent1:                 episode reward: -1.2378,                 loss: 0.2920
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7846s / 347.8811 s
agent0:                 episode reward: 0.1941,                 loss: nan
agent1:                 episode reward: -0.1941,                 loss: 0.3203
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7725s / 348.6536 s
agent0:                 episode reward: 1.9552,                 loss: nan
agent1:                 episode reward: -1.9552,                 loss: 0.3192
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7805s / 349.4341 s
agent0:                 episode reward: 1.4540,                 loss: nan
agent1:                 episode reward: -1.4540,                 loss: 0.3183
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7752s / 350.2093 s
agent0:                 episode reward: 0.5434,                 loss: nan
agent1:                 episode reward: -0.5434,                 loss: 0.3172
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7847s / 350.9940 s
agent0:                 episode reward: -0.1642,                 loss: nan
agent1:                 episode reward: 0.1642,                 loss: 0.3145
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7708s / 351.7648 s
agent0:                 episode reward: 0.8978,                 loss: nan
agent1:                 episode reward: -0.8978,                 loss: 0.3168
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7735s / 352.5383 s
agent0:                 episode reward: 1.7851,                 loss: nan
agent1:                 episode reward: -1.7851,                 loss: 0.3153
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8069s / 353.3452 s
agent0:                 episode reward: 0.3169,                 loss: nan
agent1:                 episode reward: -0.3169,                 loss: 0.3130
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8242s / 354.1694 s
agent0:                 episode reward: 0.5937,                 loss: nan
agent1:                 episode reward: -0.5937,                 loss: 0.3133
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7892s / 354.9586 s
agent0:                 episode reward: 2.0367,                 loss: nan
agent1:                 episode reward: -2.0367,                 loss: 0.3119
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7777s / 355.7363 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.3384
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7785s / 356.5148 s
agent0:                 episode reward: 0.4969,                 loss: nan
agent1:                 episode reward: -0.4969,                 loss: 0.3323
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7886s / 357.3034 s
agent0:                 episode reward: 1.4087,                 loss: nan
agent1:                 episode reward: -1.4087,                 loss: 0.3319
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 358.0813 s
agent0:                 episode reward: 0.3237,                 loss: nan
agent1:                 episode reward: -0.3237,                 loss: 0.3341
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7827s / 358.8640 s
agent0:                 episode reward: 1.0163,                 loss: nan
agent1:                 episode reward: -1.0163,                 loss: 0.3298
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7761s / 359.6402 s
agent0:                 episode reward: 2.6865,                 loss: nan
agent1:                 episode reward: -2.6865,                 loss: 0.3290
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7824s / 360.4226 s
agent0:                 episode reward: 1.0924,                 loss: nan
agent1:                 episode reward: -1.0924,                 loss: 0.3303
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7820s / 361.2046 s
agent0:                 episode reward: 0.2968,                 loss: nan
agent1:                 episode reward: -0.2968,                 loss: 0.3305
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7906s / 361.9952 s
agent0:                 episode reward: 0.1522,                 loss: nan
agent1:                 episode reward: -0.1522,                 loss: 0.3300
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7839s / 362.7792 s
agent0:                 episode reward: 0.7073,                 loss: nan
agent1:                 episode reward: -0.7073,                 loss: 0.3285
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7822s / 363.5614 s
agent0:                 episode reward: 1.2147,                 loss: nan
agent1:                 episode reward: -1.2147,                 loss: 0.2795
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8208s / 364.3822 s
agent0:                 episode reward: 1.0734,                 loss: nan
agent1:                 episode reward: -1.0734,                 loss: 0.2317
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7932s / 365.1754 s
agent0:                 episode reward: 1.4574,                 loss: nan
agent1:                 episode reward: -1.4574,                 loss: 0.2308
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7891s / 365.9644 s
agent0:                 episode reward: -0.0192,                 loss: nan
agent1:                 episode reward: 0.0192,                 loss: 0.2317
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7848s / 366.7492 s
agent0:                 episode reward: 1.4659,                 loss: nan
agent1:                 episode reward: -1.4659,                 loss: 0.2293
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7843s / 367.5335 s
agent0:                 episode reward: 1.0868,                 loss: nan
agent1:                 episode reward: -1.0868,                 loss: 0.2296
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7807s / 368.3142 s
agent0:                 episode reward: 0.9996,                 loss: nan
agent1:                 episode reward: -0.9996,                 loss: 0.2286
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7967s / 369.1109 s
agent0:                 episode reward: 0.9548,                 loss: nan
agent1:                 episode reward: -0.9548,                 loss: 0.2289
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7991s / 369.9100 s
agent0:                 episode reward: 0.2219,                 loss: nan
agent1:                 episode reward: -0.2219,                 loss: 0.2273
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7995s / 370.7095 s
agent0:                 episode reward: -0.8979,                 loss: nan
agent1:                 episode reward: 0.8979,                 loss: 0.2253
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7968s / 371.5063 s
agent0:                 episode reward: 0.5449,                 loss: nan
agent1:                 episode reward: -0.5449,                 loss: 0.2012
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8049s / 372.3111 s
agent0:                 episode reward: 1.1037,                 loss: nan
agent1:                 episode reward: -1.1037,                 loss: 0.1762
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7854s / 373.0965 s
agent0:                 episode reward: -0.1998,                 loss: nan
agent1:                 episode reward: 0.1998,                 loss: 0.1724
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7869s / 373.8835 s
agent0:                 episode reward: 0.9518,                 loss: nan
agent1:                 episode reward: -0.9518,                 loss: 0.1722
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8425s / 374.7260 s
agent0:                 episode reward: 0.4009,                 loss: nan
agent1:                 episode reward: -0.4009,                 loss: 0.1714
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8264s / 375.5524 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.1701
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7940s / 376.3464 s
agent0:                 episode reward: 0.5566,                 loss: nan
agent1:                 episode reward: -0.5566,                 loss: 0.1709
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7913s / 377.1377 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.1665
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7954s / 377.9331 s
agent0:                 episode reward: 0.9772,                 loss: nan
agent1:                 episode reward: -0.9772,                 loss: 0.1688
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8063s / 378.7394 s
agent0:                 episode reward: 0.3449,                 loss: nan
agent1:                 episode reward: -0.3449,                 loss: 0.1658
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7953s / 379.5347 s
agent0:                 episode reward: 1.0053,                 loss: nan
agent1:                 episode reward: -1.0053,                 loss: 0.1974
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7916s / 380.3263 s
agent0:                 episode reward: 1.2442,                 loss: nan
agent1:                 episode reward: -1.2442,                 loss: 0.2037
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7965s / 381.1228 s
agent0:                 episode reward: 0.2659,                 loss: nan
agent1:                 episode reward: -0.2659,                 loss: 0.2023
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7996s / 381.9224 s
agent0:                 episode reward: 0.6665,                 loss: nan
agent1:                 episode reward: -0.6665,                 loss: 0.2026
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8032s / 382.7256 s
agent0:                 episode reward: 1.3502,                 loss: nan
agent1:                 episode reward: -1.3502,                 loss: 0.2041
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7986s / 383.5242 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: 0.2055
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8487s / 384.3729 s
agent0:                 episode reward: 0.4952,                 loss: nan
agent1:                 episode reward: -0.4952,                 loss: 0.2031
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8094s / 385.1823 s
agent0:                 episode reward: 0.2443,                 loss: nan
agent1:                 episode reward: -0.2443,                 loss: 0.2040
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8051s / 385.9874 s
agent0:                 episode reward: 0.1268,                 loss: nan
agent1:                 episode reward: -0.1268,                 loss: 0.2037
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8208s / 386.8082 s
agent0:                 episode reward: 0.3277,                 loss: nan
agent1:                 episode reward: -0.3277,                 loss: 0.2036
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7963s / 387.6045 s
agent0:                 episode reward: 0.0453,                 loss: nan
agent1:                 episode reward: -0.0453,                 loss: 0.2335
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8027s / 388.4072 s
agent0:                 episode reward: 1.1281,                 loss: nan
agent1:                 episode reward: -1.1281,                 loss: 0.2418
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7994s / 389.2067 s
agent0:                 episode reward: -0.0562,                 loss: nan
agent1:                 episode reward: 0.0562,                 loss: 0.2387
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8148s / 390.0215 s
agent0:                 episode reward: 1.1203,                 loss: nan
agent1:                 episode reward: -1.1203,                 loss: 0.2378
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8037s / 390.8252 s
agent0:                 episode reward: 0.5541,                 loss: nan
agent1:                 episode reward: -0.5541,                 loss: 0.2351
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7998s / 391.6250 s
agent0:                 episode reward: 1.2317,                 loss: nan
agent1:                 episode reward: -1.2317,                 loss: 0.2377
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8063s / 392.4313 s
agent0:                 episode reward: 1.3431,                 loss: nan
agent1:                 episode reward: -1.3431,                 loss: 0.2382
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8120s / 393.2434 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: 0.2374
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8035s / 394.0469 s
agent0:                 episode reward: -0.1905,                 loss: nan
agent1:                 episode reward: 0.1905,                 loss: 0.2371
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8708s / 394.9177 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.2386
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8153s / 395.7329 s
agent0:                 episode reward: 0.6785,                 loss: nan
agent1:                 episode reward: -0.6785,                 loss: 0.2701
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8154s / 396.5483 s
agent0:                 episode reward: 0.5764,                 loss: nan
agent1:                 episode reward: -0.5764,                 loss: 0.2787
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8080s / 397.3563 s
agent0:                 episode reward: 0.8044,                 loss: nan
agent1:                 episode reward: -0.8044,                 loss: 0.2796
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8045s / 398.1607 s
agent0:                 episode reward: 0.6382,                 loss: nan
agent1:                 episode reward: -0.6382,                 loss: 0.2761
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8133s / 398.9741 s
agent0:                 episode reward: 0.1245,                 loss: nan
agent1:                 episode reward: -0.1245,                 loss: 0.2753
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8031s / 399.7772 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.2757
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8136s / 400.5907 s
agent0:                 episode reward: 0.5029,                 loss: nan
agent1:                 episode reward: -0.5029,                 loss: 0.2745
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8156s / 401.4063 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.2742
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8337s / 402.2400 s
agent0:                 episode reward: -0.1089,                 loss: nan
agent1:                 episode reward: 0.1089,                 loss: 0.2722
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8492s / 403.0892 s
agent0:                 episode reward: 0.8649,                 loss: nan
agent1:                 episode reward: -0.8649,                 loss: 0.2730
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8706s / 403.9598 s
agent0:                 episode reward: 0.8983,                 loss: nan
agent1:                 episode reward: -0.8983,                 loss: 0.2954
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8563s / 404.8161 s
agent0:                 episode reward: 0.8583,                 loss: nan
agent1:                 episode reward: -0.8583,                 loss: 0.2931
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8450s / 405.6611 s
agent0:                 episode reward: 0.6389,                 loss: nan
agent1:                 episode reward: -0.6389,                 loss: 0.2920
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8113s / 406.4724 s
agent0:                 episode reward: 0.3859,                 loss: nan
agent1:                 episode reward: -0.3859,                 loss: 0.2937
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8152s / 407.2876 s
agent0:                 episode reward: 1.3363,                 loss: nan
agent1:                 episode reward: -1.3363,                 loss: 0.2925
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8170s / 408.1046 s
agent0:                 episode reward: 0.2062,                 loss: nan
agent1:                 episode reward: -0.2062,                 loss: 0.2890
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8164s / 408.9210 s
agent0:                 episode reward: 0.8957,                 loss: nan
agent1:                 episode reward: -0.8957,                 loss: 0.2900
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8188s / 409.7398 s
agent0:                 episode reward: 1.2359,                 loss: nan
agent1:                 episode reward: -1.2359,                 loss: 0.2885
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8068s / 410.5466 s
agent0:                 episode reward: 0.4059,                 loss: nan
agent1:                 episode reward: -0.4059,                 loss: 0.2903
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8555s / 411.4021 s
agent0:                 episode reward: 0.8210,                 loss: nan
agent1:                 episode reward: -0.8210,                 loss: 0.2891
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8273s / 412.2294 s
agent0:                 episode reward: 1.1876,                 loss: nan
agent1:                 episode reward: -1.1876,                 loss: 0.3013
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8251s / 413.0545 s
agent0:                 episode reward: 1.4226,                 loss: nan
agent1:                 episode reward: -1.4226,                 loss: 0.2921
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8284s / 413.8829 s
agent0:                 episode reward: 0.0364,                 loss: nan
agent1:                 episode reward: -0.0364,                 loss: 0.2861
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8243s / 414.7072 s
agent0:                 episode reward: 2.0864,                 loss: nan
agent1:                 episode reward: -2.0864,                 loss: 0.2882
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8775s / 415.5847 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.2873
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8264s / 416.4112 s
agent0:                 episode reward: 0.8186,                 loss: nan
agent1:                 episode reward: -0.8186,                 loss: 0.2872
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8303s / 417.2414 s
agent0:                 episode reward: 1.4969,                 loss: nan
agent1:                 episode reward: -1.4969,                 loss: 0.2866
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8413s / 418.0827 s
agent0:                 episode reward: 0.8896,                 loss: nan
agent1:                 episode reward: -0.8896,                 loss: 0.2859
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8202s / 418.9029 s
agent0:                 episode reward: 0.8066,                 loss: nan
agent1:                 episode reward: -0.8066,                 loss: 0.2869
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8451s / 419.7480 s
agent0:                 episode reward: 0.4606,                 loss: nan
agent1:                 episode reward: -0.4606,                 loss: 0.2901
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8422s / 420.5902 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.2957
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8287s / 421.4189 s
agent0:                 episode reward: 0.7966,                 loss: nan
agent1:                 episode reward: -0.7966,                 loss: 0.2833
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8300s / 422.2489 s
agent0:                 episode reward: 1.2596,                 loss: nan
agent1:                 episode reward: -1.2596,                 loss: 0.2832
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8505s / 423.0994 s
agent0:                 episode reward: 0.4231,                 loss: nan
agent1:                 episode reward: -0.4231,                 loss: 0.2822
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8323s / 423.9316 s
agent0:                 episode reward: -0.1964,                 loss: nan
agent1:                 episode reward: 0.1964,                 loss: 0.2796
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8727s / 424.8043 s
agent0:                 episode reward: 0.3875,                 loss: nan
agent1:                 episode reward: -0.3875,                 loss: 0.2804
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8887s / 425.6931 s
agent0:                 episode reward: 2.2689,                 loss: nan
agent1:                 episode reward: -2.2689,                 loss: 0.2791
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8468s / 426.5398 s
agent0:                 episode reward: 0.9543,                 loss: nan
agent1:                 episode reward: -0.9543,                 loss: 0.2783
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8296s / 427.3695 s
agent0:                 episode reward: 1.2042,                 loss: nan
agent1:                 episode reward: -1.2042,                 loss: 0.2798
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8472s / 428.2166 s
agent0:                 episode reward: 0.6903,                 loss: nan
agent1:                 episode reward: -0.6903,                 loss: 0.2802
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8425s / 429.0592 s
agent0:                 episode reward: 0.7456,                 loss: nan
agent1:                 episode reward: -0.7456,                 loss: 0.3116
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8417s / 429.9009 s
agent0:                 episode reward: 0.6295,                 loss: nan
agent1:                 episode reward: -0.6295,                 loss: 0.3136
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8352s / 430.7361 s
agent0:                 episode reward: 0.9022,                 loss: nan
agent1:                 episode reward: -0.9022,                 loss: 0.3115
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8303s / 431.5664 s
agent0:                 episode reward: 0.9388,                 loss: nan
agent1:                 episode reward: -0.9388,                 loss: 0.3133
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8413s / 432.4077 s
agent0:                 episode reward: 0.4489,                 loss: nan
agent1:                 episode reward: -0.4489,                 loss: 0.3106
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8331s / 433.2408 s
agent0:                 episode reward: 0.4504,                 loss: nan
agent1:                 episode reward: -0.4504,                 loss: 0.3098
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8368s / 434.0777 s
agent0:                 episode reward: 0.3652,                 loss: nan
agent1:                 episode reward: -0.3652,                 loss: 0.3094
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8403s / 434.9179 s
agent0:                 episode reward: 0.6949,                 loss: nan
agent1:                 episode reward: -0.6949,                 loss: 0.3114
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8960s / 435.8139 s
agent0:                 episode reward: 0.7318,                 loss: nan
agent1:                 episode reward: -0.7318,                 loss: 0.3116
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8756s / 436.6895 s
agent0:                 episode reward: 1.2530,                 loss: nan
agent1:                 episode reward: -1.2530,                 loss: 0.3094
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8406s / 437.5301 s
agent0:                 episode reward: 0.5531,                 loss: nan
agent1:                 episode reward: -0.5531,                 loss: 0.3130
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8578s / 438.3879 s
agent0:                 episode reward: 0.4633,                 loss: nan
agent1:                 episode reward: -0.4633,                 loss: 0.2943
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8512s / 439.2391 s
agent0:                 episode reward: 1.4519,                 loss: nan
agent1:                 episode reward: -1.4519,                 loss: 0.2950
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8497s / 440.0888 s
agent0:                 episode reward: -0.0748,                 loss: nan
agent1:                 episode reward: 0.0748,                 loss: 0.2920
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8503s / 440.9391 s
agent0:                 episode reward: 0.9454,                 loss: nan
agent1:                 episode reward: -0.9454,                 loss: 0.2914
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8358s / 441.7749 s
agent0:                 episode reward: 0.9758,                 loss: nan
agent1:                 episode reward: -0.9758,                 loss: 0.2908
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8487s / 442.6236 s
agent0:                 episode reward: 0.1589,                 loss: nan
agent1:                 episode reward: -0.1589,                 loss: 0.2900
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8495s / 443.4731 s
agent0:                 episode reward: 0.7633,                 loss: nan
agent1:                 episode reward: -0.7633,                 loss: 0.2895
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 444.3379 s
agent0:                 episode reward: 0.4746,                 loss: nan
agent1:                 episode reward: -0.4746,                 loss: 0.2901
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8570s / 445.1948 s
agent0:                 episode reward: 0.7719,                 loss: nan
agent1:                 episode reward: -0.7719,                 loss: 0.2902
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8880s / 446.0828 s
agent0:                 episode reward: 0.6488,                 loss: nan
agent1:                 episode reward: -0.6488,                 loss: 0.2453
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8472s / 446.9299 s
agent0:                 episode reward: 0.8422,                 loss: nan
agent1:                 episode reward: -0.8422,                 loss: 0.2085
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8630s / 447.7930 s
agent0:                 episode reward: 0.5785,                 loss: nan
agent1:                 episode reward: -0.5785,                 loss: 0.2073
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8535s / 448.6465 s
agent0:                 episode reward: 0.2940,                 loss: nan
agent1:                 episode reward: -0.2940,                 loss: 0.2053
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8541s / 449.5006 s
agent0:                 episode reward: -0.0552,                 loss: nan
agent1:                 episode reward: 0.0552,                 loss: 0.2044
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8507s / 450.3513 s
agent0:                 episode reward: 0.3813,                 loss: nan
agent1:                 episode reward: -0.3813,                 loss: 0.2050
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8594s / 451.2106 s
agent0:                 episode reward: 0.3933,                 loss: nan
agent1:                 episode reward: -0.3933,                 loss: 0.2019
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8551s / 452.0657 s
agent0:                 episode reward: 1.2618,                 loss: nan
agent1:                 episode reward: -1.2618,                 loss: 0.2016
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8694s / 452.9351 s
agent0:                 episode reward: 0.2503,                 loss: nan
agent1:                 episode reward: -0.2503,                 loss: 0.2012
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8880s / 453.8231 s
agent0:                 episode reward: 0.7383,                 loss: nan
agent1:                 episode reward: -0.7383,                 loss: 0.2015
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8567s / 454.6798 s
agent0:                 episode reward: 0.6548,                 loss: nan
agent1:                 episode reward: -0.6548,                 loss: 0.1911
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8565s / 455.5364 s
agent0:                 episode reward: -0.3892,                 loss: nan
agent1:                 episode reward: 0.3892,                 loss: 0.1739
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9151s / 456.4515 s
agent0:                 episode reward: 0.6837,                 loss: nan
agent1:                 episode reward: -0.6837,                 loss: 0.1753
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 457.3163 s
agent0:                 episode reward: 0.7543,                 loss: nan
agent1:                 episode reward: -0.7543,                 loss: 0.1735
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8590s / 458.1753 s
agent0:                 episode reward: 0.8748,                 loss: nan
agent1:                 episode reward: -0.8748,                 loss: 0.1718
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8702s / 459.0455 s
agent0:                 episode reward: 0.0926,                 loss: nan
agent1:                 episode reward: -0.0926,                 loss: 0.1719
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8573s / 459.9027 s
agent0:                 episode reward: -1.1501,                 loss: nan
agent1:                 episode reward: 1.1501,                 loss: 0.1728
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8522s / 460.7549 s
agent0:                 episode reward: 0.1455,                 loss: nan
agent1:                 episode reward: -0.1455,                 loss: 0.1722
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8832s / 461.6381 s
agent0:                 episode reward: 0.2806,                 loss: nan
agent1:                 episode reward: -0.2806,                 loss: 0.1712
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8697s / 462.5078 s
agent0:                 episode reward: 0.8973,                 loss: nan
agent1:                 episode reward: -0.8973,                 loss: 0.1733
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 463.3737 s
agent0:                 episode reward: 0.3343,                 loss: nan
agent1:                 episode reward: -0.3343,                 loss: 0.2034
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8619s / 464.2356 s
agent0:                 episode reward: 1.1863,                 loss: nan
agent1:                 episode reward: -1.1863,                 loss: 0.2104
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8876s / 465.1232 s
agent0:                 episode reward: -0.3456,                 loss: nan
agent1:                 episode reward: 0.3456,                 loss: 0.2103
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8652s / 465.9884 s
agent0:                 episode reward: 1.0365,                 loss: nan
agent1:                 episode reward: -1.0365,                 loss: 0.2062
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9553s / 466.9437 s
agent0:                 episode reward: 1.0490,                 loss: nan
agent1:                 episode reward: -1.0490,                 loss: 0.2096
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8735s / 467.8172 s
agent0:                 episode reward: 0.1963,                 loss: nan
agent1:                 episode reward: -0.1963,                 loss: 0.2076
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8820s / 468.6992 s
agent0:                 episode reward: 1.2385,                 loss: nan
agent1:                 episode reward: -1.2385,                 loss: 0.2102
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8862s / 469.5854 s
agent0:                 episode reward: -0.0568,                 loss: nan
agent1:                 episode reward: 0.0568,                 loss: 0.2094
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8659s / 470.4513 s
agent0:                 episode reward: 0.8626,                 loss: nan
agent1:                 episode reward: -0.8626,                 loss: 0.2107
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8801s / 471.3314 s
agent0:                 episode reward: 0.8142,                 loss: nan
agent1:                 episode reward: -0.8142,                 loss: 0.2077
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8731s / 472.2045 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.2392
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8969s / 473.1014 s
agent0:                 episode reward: -0.0188,                 loss: nan
agent1:                 episode reward: 0.0188,                 loss: 0.2501
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8715s / 473.9729 s
agent0:                 episode reward: 0.3397,                 loss: nan
agent1:                 episode reward: -0.3397,                 loss: 0.2459
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8797s / 474.8526 s
agent0:                 episode reward: -0.0652,                 loss: nan
agent1:                 episode reward: 0.0652,                 loss: 0.2493
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8707s / 475.7232 s
agent0:                 episode reward: 0.5420,                 loss: nan
agent1:                 episode reward: -0.5420,                 loss: 0.2462
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9162s / 476.6394 s
agent0:                 episode reward: 1.7826,                 loss: nan
agent1:                 episode reward: -1.7826,                 loss: 0.2468
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8726s / 477.5120 s
agent0:                 episode reward: 0.3614,                 loss: nan
agent1:                 episode reward: -0.3614,                 loss: 0.2464
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8959s / 478.4079 s
agent0:                 episode reward: 1.4138,                 loss: nan
agent1:                 episode reward: -1.4138,                 loss: 0.2459
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8712s / 479.2791 s
agent0:                 episode reward: 1.1753,                 loss: nan
agent1:                 episode reward: -1.1753,                 loss: 0.2465
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8818s / 480.1609 s
agent0:                 episode reward: 0.5343,                 loss: nan
agent1:                 episode reward: -0.5343,                 loss: 0.2475
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8738s / 481.0346 s
agent0:                 episode reward: 0.5773,                 loss: nan
agent1:                 episode reward: -0.5773,                 loss: 0.2802
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9262s / 481.9608 s
agent0:                 episode reward: 0.7605,                 loss: nan
agent1:                 episode reward: -0.7605,                 loss: 0.2877
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8770s / 482.8378 s
agent0:                 episode reward: 0.3243,                 loss: nan
agent1:                 episode reward: -0.3243,                 loss: 0.2895
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8789s / 483.7167 s
agent0:                 episode reward: 1.1401,                 loss: nan
agent1:                 episode reward: -1.1401,                 loss: 0.2871
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8912s / 484.6080 s
agent0:                 episode reward: 0.1965,                 loss: nan
agent1:                 episode reward: -0.1965,                 loss: 0.2874
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8709s / 485.4788 s
agent0:                 episode reward: -0.1241,                 loss: nan
agent1:                 episode reward: 0.1241,                 loss: 0.2867
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9044s / 486.3833 s
agent0:                 episode reward: 0.0522,                 loss: nan
agent1:                 episode reward: -0.0522,                 loss: 0.2856
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9215s / 487.3048 s
agent0:                 episode reward: 0.4328,                 loss: nan
agent1:                 episode reward: -0.4328,                 loss: 0.2862
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8764s / 488.1812 s
agent0:                 episode reward: 0.7377,                 loss: nan
agent1:                 episode reward: -0.7377,                 loss: 0.2881
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8793s / 489.0605 s
agent0:                 episode reward: 1.0752,                 loss: nan
agent1:                 episode reward: -1.0752,                 loss: 0.2860
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8912s / 489.9517 s
agent0:                 episode reward: 0.5326,                 loss: nan
agent1:                 episode reward: -0.5326,                 loss: 0.3082
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8812s / 490.8329 s
agent0:                 episode reward: 0.1760,                 loss: nan
agent1:                 episode reward: -0.1760,                 loss: 0.3078
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8709s / 491.7038 s
agent0:                 episode reward: 0.7504,                 loss: nan
agent1:                 episode reward: -0.7504,                 loss: 0.3080
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8852s / 492.5889 s
agent0:                 episode reward: 0.6311,                 loss: nan
agent1:                 episode reward: -0.6311,                 loss: 0.3073
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8841s / 493.4731 s
agent0:                 episode reward: 0.5729,                 loss: nan
agent1:                 episode reward: -0.5729,                 loss: 0.3072
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8925s / 494.3655 s
agent0:                 episode reward: 0.3427,                 loss: nan
agent1:                 episode reward: -0.3427,                 loss: 0.3045
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8926s / 495.2581 s
agent0:                 episode reward: 0.5896,                 loss: nan
agent1:                 episode reward: -0.5896,                 loss: 0.3061
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8794s / 496.1375 s
agent0:                 episode reward: 0.7678,                 loss: nan
agent1:                 episode reward: -0.7678,                 loss: 0.3068
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9311s / 497.0687 s
agent0:                 episode reward: 0.9441,                 loss: nan
agent1:                 episode reward: -0.9441,                 loss: 0.3036
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8873s / 497.9560 s
agent0:                 episode reward: 0.6701,                 loss: nan
agent1:                 episode reward: -0.6701,                 loss: 0.3056
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8938s / 498.8498 s
agent0:                 episode reward: 0.3266,                 loss: nan
agent1:                 episode reward: -0.3266,                 loss: 0.3049
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9036s / 499.7534 s
agent0:                 episode reward: 1.8297,                 loss: nan
agent1:                 episode reward: -1.8297,                 loss: 0.2925
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8796s / 500.6330 s
agent0:                 episode reward: 1.4729,                 loss: nan
agent1:                 episode reward: -1.4729,                 loss: 0.2899
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8953s / 501.5283 s
agent0:                 episode reward: 1.4480,                 loss: nan
agent1:                 episode reward: -1.4480,                 loss: 0.2907
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8949s / 502.4232 s
agent0:                 episode reward: 1.0977,                 loss: nan
agent1:                 episode reward: -1.0977,                 loss: 0.2896
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8993s / 503.3225 s
agent0:                 episode reward: 0.5162,                 loss: nan
agent1:                 episode reward: -0.5162,                 loss: 0.2897
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8900s / 504.2125 s
agent0:                 episode reward: 0.5346,                 loss: nan
agent1:                 episode reward: -0.5346,                 loss: 0.2910
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9146s / 505.1271 s
agent0:                 episode reward: 1.2030,                 loss: nan
agent1:                 episode reward: -1.2030,                 loss: 0.2897
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9034s / 506.0305 s
agent0:                 episode reward: 0.4026,                 loss: nan
agent1:                 episode reward: -0.4026,                 loss: 0.2891
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9087s / 506.9392 s
agent0:                 episode reward: 1.0141,                 loss: nan
agent1:                 episode reward: -1.0141,                 loss: 0.2896
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9457s / 507.8849 s
agent0:                 episode reward: 0.5069,                 loss: nan
agent1:                 episode reward: -0.5069,                 loss: 0.2994
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8947s / 508.7797 s
agent0:                 episode reward: 0.2749,                 loss: nan
agent1:                 episode reward: -0.2749,                 loss: 0.2952
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9075s / 509.6871 s
agent0:                 episode reward: 0.0936,                 loss: nan
agent1:                 episode reward: -0.0936,                 loss: 0.2945
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9107s / 510.5978 s
agent0:                 episode reward: 0.3015,                 loss: nan
agent1:                 episode reward: -0.3015,                 loss: 0.2935
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9124s / 511.5102 s
agent0:                 episode reward: 0.4460,                 loss: nan
agent1:                 episode reward: -0.4460,                 loss: 0.2927
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9066s / 512.4169 s
agent0:                 episode reward: 0.9766,                 loss: nan
agent1:                 episode reward: -0.9766,                 loss: 0.2947
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8912s / 513.3081 s
agent0:                 episode reward: 0.8484,                 loss: nan
agent1:                 episode reward: -0.8484,                 loss: 0.2952
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9091s / 514.2172 s
agent0:                 episode reward: 0.3892,                 loss: nan
agent1:                 episode reward: -0.3892,                 loss: 0.2948
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 515.1279 s
agent0:                 episode reward: 0.8091,                 loss: nan
agent1:                 episode reward: -0.8091,                 loss: 0.2936
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9028s / 516.0308 s
agent0:                 episode reward: 0.5306,                 loss: nan
agent1:                 episode reward: -0.5306,                 loss: 0.2937
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9163s / 516.9471 s
agent0:                 episode reward: 0.7088,                 loss: nan
agent1:                 episode reward: -0.7088,                 loss: 0.3167
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9505s / 517.8976 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.3199
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9190s / 518.8166 s
agent0:                 episode reward: 0.7889,                 loss: nan
agent1:                 episode reward: -0.7889,                 loss: 0.3196
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9426s / 519.7592 s
agent0:                 episode reward: 0.4315,                 loss: nan
agent1:                 episode reward: -0.4315,                 loss: 0.3173
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9430s / 520.7022 s
agent0:                 episode reward: 0.9388,                 loss: nan
agent1:                 episode reward: -0.9388,                 loss: 0.3173
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9061s / 521.6083 s
agent0:                 episode reward: 1.5729,                 loss: nan
agent1:                 episode reward: -1.5729,                 loss: 0.3179
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9103s / 522.5186 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.3172
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8955s / 523.4141 s
agent0:                 episode reward: 0.6385,                 loss: nan
agent1:                 episode reward: -0.6385,                 loss: 0.3162
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9117s / 524.3258 s
agent0:                 episode reward: 1.3618,                 loss: nan
agent1:                 episode reward: -1.3618,                 loss: 0.3168
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9070s / 525.2328 s
agent0:                 episode reward: 0.7989,                 loss: nan
agent1:                 episode reward: -0.7989,                 loss: 0.3184
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9204s / 526.1532 s
agent0:                 episode reward: 1.1672,                 loss: nan
agent1:                 episode reward: -1.1672,                 loss: 0.3335
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9178s / 527.0709 s
agent0:                 episode reward: -0.4852,                 loss: nan
agent1:                 episode reward: 0.4852,                 loss: 0.3277
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9706s / 528.0415 s
agent0:                 episode reward: 1.5253,                 loss: nan
agent1:                 episode reward: -1.5253,                 loss: 0.3249
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9561s / 528.9976 s
agent0:                 episode reward: 0.4600,                 loss: nan
agent1:                 episode reward: -0.4600,                 loss: 0.3244
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9050s / 529.9026 s
agent0:                 episode reward: 0.6194,                 loss: nan
agent1:                 episode reward: -0.6194,                 loss: 0.3253
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9210s / 530.8236 s
agent0:                 episode reward: 0.0218,                 loss: nan
agent1:                 episode reward: -0.0218,                 loss: 0.3233
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9126s / 531.7362 s
agent0:                 episode reward: 0.4695,                 loss: nan
agent1:                 episode reward: -0.4695,                 loss: 0.3232
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9205s / 532.6566 s
agent0:                 episode reward: 0.6266,                 loss: nan
agent1:                 episode reward: -0.6266,                 loss: 0.3220
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9102s / 533.5669 s
agent0:                 episode reward: 1.1432,                 loss: nan
agent1:                 episode reward: -1.1432,                 loss: 0.3214
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9322s / 534.4991 s
agent0:                 episode reward: 0.4506,                 loss: nan
agent1:                 episode reward: -0.4506,                 loss: 0.3193
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9187s / 535.4178 s
agent0:                 episode reward: 0.8785,                 loss: nan
agent1:                 episode reward: -0.8785,                 loss: 0.2870
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9229s / 536.3408 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: 0.2469
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9347s / 537.2755 s
agent0:                 episode reward: 1.2060,                 loss: nan
agent1:                 episode reward: -1.2060,                 loss: 0.2462
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9626s / 538.2381 s
agent0:                 episode reward: 0.7328,                 loss: nan
agent1:                 episode reward: -0.7328,                 loss: 0.2434
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9270s / 539.1651 s
agent0:                 episode reward: 0.2526,                 loss: nan
agent1:                 episode reward: -0.2526,                 loss: 0.2426
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9137s / 540.0788 s
agent0:                 episode reward: 0.2898,                 loss: nan
agent1:                 episode reward: -0.2898,                 loss: 0.2410
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9323s / 541.0112 s
agent0:                 episode reward: 0.2171,                 loss: nan
agent1:                 episode reward: -0.2171,                 loss: 0.2386
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9163s / 541.9274 s
agent0:                 episode reward: 0.7034,                 loss: nan
agent1:                 episode reward: -0.7034,                 loss: 0.2403
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9215s / 542.8489 s
agent0:                 episode reward: 0.4631,                 loss: nan
agent1:                 episode reward: -0.4631,                 loss: 0.2403
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9266s / 543.7755 s
agent0:                 episode reward: 0.3200,                 loss: nan
agent1:                 episode reward: -0.3200,                 loss: 0.2377
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9736s / 544.7491 s
agent0:                 episode reward: 0.1677,                 loss: nan
agent1:                 episode reward: -0.1677,                 loss: 0.2084
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9358s / 545.6849 s
agent0:                 episode reward: -0.1596,                 loss: nan
agent1:                 episode reward: 0.1596,                 loss: 0.1843
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9308s / 546.6157 s
agent0:                 episode reward: 1.4079,                 loss: nan
agent1:                 episode reward: -1.4079,                 loss: 0.1815
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9345s / 547.5502 s
agent0:                 episode reward: 1.1305,                 loss: nan
agent1:                 episode reward: -1.1305,                 loss: 0.1815
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9729s / 548.5232 s
agent0:                 episode reward: 0.5584,                 loss: nan
agent1:                 episode reward: -0.5584,                 loss: 0.1819
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9489s / 549.4721 s
agent0:                 episode reward: 0.4999,                 loss: nan
agent1:                 episode reward: -0.4999,                 loss: 0.1783
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9416s / 550.4137 s
agent0:                 episode reward: 0.2466,                 loss: nan
agent1:                 episode reward: -0.2466,                 loss: 0.1800
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9389s / 551.3526 s
agent0:                 episode reward: 0.1221,                 loss: nan
agent1:                 episode reward: -0.1221,                 loss: 0.1783
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9592s / 552.3118 s
agent0:                 episode reward: 0.1907,                 loss: nan
agent1:                 episode reward: -0.1907,                 loss: 0.1799
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9451s / 553.2569 s
agent0:                 episode reward: 1.3176,                 loss: nan
agent1:                 episode reward: -1.3176,                 loss: 0.1797
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9434s / 554.2004 s
agent0:                 episode reward: 0.4794,                 loss: nan
agent1:                 episode reward: -0.4794,                 loss: 0.2127
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9475s / 555.1478 s
agent0:                 episode reward: 0.6129,                 loss: nan
agent1:                 episode reward: -0.6129,                 loss: 0.2238
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9386s / 556.0864 s
agent0:                 episode reward: 0.9238,                 loss: nan
agent1:                 episode reward: -0.9238,                 loss: 0.2221
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9443s / 557.0307 s
agent0:                 episode reward: 0.8755,                 loss: nan
agent1:                 episode reward: -0.8755,                 loss: 0.2209
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9512s / 557.9819 s
agent0:                 episode reward: 0.9136,                 loss: nan
agent1:                 episode reward: -0.9136,                 loss: 0.2218
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9983s / 558.9802 s
agent0:                 episode reward: 1.1171,                 loss: nan
agent1:                 episode reward: -1.1171,                 loss: 0.2214
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9487s / 559.9290 s
agent0:                 episode reward: 0.8800,                 loss: nan
agent1:                 episode reward: -0.8800,                 loss: 0.2199
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9571s / 560.8861 s
agent0:                 episode reward: 1.0885,                 loss: nan
agent1:                 episode reward: -1.0885,                 loss: 0.2212
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0094s / 561.8955 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.2187
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9719s / 562.8675 s
agent0:                 episode reward: 0.6522,                 loss: nan
agent1:                 episode reward: -0.6522,                 loss: 0.2196
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9605s / 563.8280 s
agent0:                 episode reward: 0.5235,                 loss: nan
agent1:                 episode reward: -0.5235,                 loss: 0.2467
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9699s / 564.7979 s
agent0:                 episode reward: 0.5007,                 loss: nan
agent1:                 episode reward: -0.5007,                 loss: 0.2519
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9470s / 565.7450 s
agent0:                 episode reward: 0.8254,                 loss: nan
agent1:                 episode reward: -0.8254,                 loss: 0.2501
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9503s / 566.6952 s
agent0:                 episode reward: 1.1622,                 loss: nan
agent1:                 episode reward: -1.1622,                 loss: 0.2488
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9560s / 567.6513 s
agent0:                 episode reward: 1.1865,                 loss: nan
agent1:                 episode reward: -1.1865,                 loss: 0.2506
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0024s / 568.6536 s
agent0:                 episode reward: 0.2197,                 loss: nan
agent1:                 episode reward: -0.2197,                 loss: 0.2507
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0118s / 569.6655 s
agent0:                 episode reward: 0.1280,                 loss: nan
agent1:                 episode reward: -0.1280,                 loss: 0.2513
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9552s / 570.6207 s
agent0:                 episode reward: 0.1357,                 loss: nan
agent1:                 episode reward: -0.1357,                 loss: 0.2503
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9585s / 571.5793 s
agent0:                 episode reward: 0.9847,                 loss: nan
agent1:                 episode reward: -0.9847,                 loss: 0.2501
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9531s / 572.5323 s
agent0:                 episode reward: 0.8770,                 loss: nan
agent1:                 episode reward: -0.8770,                 loss: 0.2515
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9464s / 573.4788 s
agent0:                 episode reward: 0.6093,                 loss: nan
agent1:                 episode reward: -0.6093,                 loss: 0.2898
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9639s / 574.4427 s
agent0:                 episode reward: 0.5945,                 loss: nan
agent1:                 episode reward: -0.5945,                 loss: 0.2980
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9473s / 575.3900 s
agent0:                 episode reward: 0.4009,                 loss: nan
agent1:                 episode reward: -0.4009,                 loss: 0.2987
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9634s / 576.3535 s
agent0:                 episode reward: 0.1874,                 loss: nan
agent1:                 episode reward: -0.1874,                 loss: 0.2957
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9845s / 577.3380 s
agent0:                 episode reward: -0.2558,                 loss: nan
agent1:                 episode reward: 0.2558,                 loss: 0.2927
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9668s / 578.3048 s
agent0:                 episode reward: 1.4832,                 loss: nan
agent1:                 episode reward: -1.4832,                 loss: 0.2933
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0049s / 579.3097 s
agent0:                 episode reward: 0.9473,                 loss: nan
agent1:                 episode reward: -0.9473,                 loss: 0.2917
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9861s / 580.2958 s
agent0:                 episode reward: 0.2591,                 loss: nan
agent1:                 episode reward: -0.2591,                 loss: 0.2911
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9761s / 581.2719 s
agent0:                 episode reward: 0.5930,                 loss: nan
agent1:                 episode reward: -0.5930,                 loss: 0.2933
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9716s / 582.2435 s
agent0:                 episode reward: 0.9824,                 loss: nan
agent1:                 episode reward: -0.9824,                 loss: 0.2915
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9700s / 583.2135 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: 0.3080
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9657s / 584.1792 s
agent0:                 episode reward: 0.6582,                 loss: nan
agent1:                 episode reward: -0.6582,                 loss: 0.3105
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9863s / 585.1655 s
agent0:                 episode reward: 0.7204,                 loss: nan
agent1:                 episode reward: -0.7204,                 loss: 0.3048
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0292s / 586.1947 s
agent0:                 episode reward: 0.2179,                 loss: nan
agent1:                 episode reward: -0.2179,                 loss: 0.3037
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9738s / 587.1685 s
agent0:                 episode reward: 0.6340,                 loss: nan
agent1:                 episode reward: -0.6340,                 loss: 0.3043
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9858s / 588.1543 s
agent0:                 episode reward: 0.5892,                 loss: nan
agent1:                 episode reward: -0.5892,                 loss: 0.3055
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0179s / 589.1722 s
agent0:                 episode reward: -0.1195,                 loss: nan
agent1:                 episode reward: 0.1195,                 loss: 0.3008
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9646s / 590.1368 s
agent0:                 episode reward: -0.2026,                 loss: nan
agent1:                 episode reward: 0.2026,                 loss: 0.3023
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 591.1099 s
agent0:                 episode reward: 0.9848,                 loss: nan
agent1:                 episode reward: -0.9848,                 loss: 0.3008
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9875s / 592.0974 s
agent0:                 episode reward: 0.9398,                 loss: nan
agent1:                 episode reward: -0.9398,                 loss: 0.2999
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9720s / 593.0694 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.3033
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 594.0581 s
agent0:                 episode reward: 1.2952,                 loss: nan
agent1:                 episode reward: -1.2952,                 loss: 0.2935
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9982s / 595.0562 s
agent0:                 episode reward: 0.6482,                 loss: nan
agent1:                 episode reward: -0.6482,                 loss: 0.2940
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9688s / 596.0250 s
agent0:                 episode reward: 0.2921,                 loss: nan
agent1:                 episode reward: -0.2921,                 loss: 0.2916
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9630s / 596.9880 s
agent0:                 episode reward: 0.7918,                 loss: nan
agent1:                 episode reward: -0.7918,                 loss: 0.2938
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9755s / 597.9635 s
agent0:                 episode reward: 0.8949,                 loss: nan
agent1:                 episode reward: -0.8949,                 loss: 0.2918
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9764s / 598.9399 s
agent0:                 episode reward: 1.0515,                 loss: nan
agent1:                 episode reward: -1.0515,                 loss: 0.2899
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0278s / 599.9677 s
agent0:                 episode reward: 0.6615,                 loss: nan
agent1:                 episode reward: -0.6615,                 loss: 0.2907
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0199s / 600.9876 s
agent0:                 episode reward: -0.0128,                 loss: nan
agent1:                 episode reward: 0.0128,                 loss: 0.2919
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0234s / 602.0110 s
agent0:                 episode reward: 0.2298,                 loss: nan
agent1:                 episode reward: -0.2298,                 loss: 0.2907
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0103s / 603.0213 s
agent0:                 episode reward: 1.0952,                 loss: nan
agent1:                 episode reward: -1.0952,                 loss: 0.2954
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0114s / 604.0327 s
agent0:                 episode reward: 0.2583,                 loss: nan
agent1:                 episode reward: -0.2583,                 loss: 0.2782
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9869s / 605.0196 s
agent0:                 episode reward: -0.1574,                 loss: nan
agent1:                 episode reward: 0.1574,                 loss: 0.2770
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9812s / 606.0008 s
agent0:                 episode reward: 1.0648,                 loss: nan
agent1:                 episode reward: -1.0648,                 loss: 0.2768
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0054s / 607.0062 s
agent0:                 episode reward: 1.0638,                 loss: nan
agent1:                 episode reward: -1.0638,                 loss: 0.2768
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9897s / 607.9959 s
agent0:                 episode reward: 0.5615,                 loss: nan
agent1:                 episode reward: -0.5615,                 loss: 0.2743
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9907s / 608.9866 s
agent0:                 episode reward: 1.1014,                 loss: nan
agent1:                 episode reward: -1.1014,                 loss: 0.2768
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0308s / 610.0175 s
agent0:                 episode reward: 0.0002,                 loss: nan
agent1:                 episode reward: -0.0002,                 loss: 0.2759
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0174s / 611.0349 s
agent0:                 episode reward: 1.6039,                 loss: nan
agent1:                 episode reward: -1.6039,                 loss: 0.2776
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9872s / 612.0221 s
agent0:                 episode reward: 1.0600,                 loss: nan
agent1:                 episode reward: -1.0600,                 loss: 0.2772
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0321s / 613.0542 s
agent0:                 episode reward: 0.0334,                 loss: nan
agent1:                 episode reward: -0.0334,                 loss: 0.3122
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0129s / 614.0672 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.3180
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0099s / 615.0771 s
agent0:                 episode reward: 1.2989,                 loss: nan
agent1:                 episode reward: -1.2989,                 loss: 0.3142
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0118s / 616.0889 s
agent0:                 episode reward: 1.2242,                 loss: nan
agent1:                 episode reward: -1.2242,                 loss: 0.3161
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0109s / 617.0998 s
agent0:                 episode reward: 0.1352,                 loss: nan
agent1:                 episode reward: -0.1352,                 loss: 0.3141
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9821s / 618.0819 s
agent0:                 episode reward: 0.5418,                 loss: nan
agent1:                 episode reward: -0.5418,                 loss: 0.3153
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0209s / 619.1028 s
agent0:                 episode reward: 0.1576,                 loss: nan
agent1:                 episode reward: -0.1576,                 loss: 0.3141
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0361s / 620.1390 s
agent0:                 episode reward: 1.3786,                 loss: nan
agent1:                 episode reward: -1.3786,                 loss: 0.3139
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0208s / 621.1597 s
agent0:                 episode reward: 0.3458,                 loss: nan
agent1:                 episode reward: -0.3458,                 loss: 0.3123
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 622.1807 s
agent0:                 episode reward: 1.9848,                 loss: nan
agent1:                 episode reward: -1.9848,                 loss: 0.3116
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0049s / 623.1856 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.3353
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9963s / 624.1819 s
agent0:                 episode reward: 0.4789,                 loss: nan
agent1:                 episode reward: -0.4789,                 loss: 0.3310
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0190s / 625.2009 s
agent0:                 episode reward: 0.9463,                 loss: nan
agent1:                 episode reward: -0.9463,                 loss: 0.3298
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0191s / 626.2199 s
agent0:                 episode reward: 0.0653,                 loss: nan
agent1:                 episode reward: -0.0653,                 loss: 0.3297
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0563s / 627.2763 s
agent0:                 episode reward: -0.3163,                 loss: nan
agent1:                 episode reward: 0.3163,                 loss: 0.3295
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0256s / 628.3019 s
agent0:                 episode reward: -0.3246,                 loss: nan
agent1:                 episode reward: 0.3246,                 loss: 0.3259
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0369s / 629.3388 s
agent0:                 episode reward: 0.5702,                 loss: nan
agent1:                 episode reward: -0.5702,                 loss: 0.3281
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1085s / 630.4473 s
agent0:                 episode reward: 2.0669,                 loss: nan
agent1:                 episode reward: -2.0669,                 loss: 0.3270
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0242s / 631.4715 s
agent0:                 episode reward: 0.0403,                 loss: nan
agent1:                 episode reward: -0.0403,                 loss: 0.3258
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9992s / 632.4707 s
agent0:                 episode reward: 0.9490,                 loss: nan
agent1:                 episode reward: -0.9490,                 loss: 0.3270
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0117s / 633.4824 s
agent0:                 episode reward: 0.1690,                 loss: nan
agent1:                 episode reward: -0.1690,                 loss: 0.2910
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0072s / 634.4896 s
agent0:                 episode reward: 0.8468,                 loss: nan
agent1:                 episode reward: -0.8468,                 loss: 0.2546
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0447s / 635.5343 s
agent0:                 episode reward: -0.1395,                 loss: nan
agent1:                 episode reward: 0.1395,                 loss: 0.2553
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0234s / 636.5577 s
agent0:                 episode reward: 0.5671,                 loss: nan
agent1:                 episode reward: -0.5671,                 loss: 0.2509
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0378s / 637.5955 s
agent0:                 episode reward: 0.7088,                 loss: nan
agent1:                 episode reward: -0.7088,                 loss: 0.2521
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0284s / 638.6238 s
agent0:                 episode reward: 0.6179,                 loss: nan
agent1:                 episode reward: -0.6179,                 loss: 0.2507
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0115s / 639.6354 s
agent0:                 episode reward: 0.1556,                 loss: nan
agent1:                 episode reward: -0.1556,                 loss: 0.2478
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0431s / 640.6785 s
agent0:                 episode reward: 0.8918,                 loss: nan
agent1:                 episode reward: -0.8918,                 loss: 0.2478
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0408s / 641.7193 s
agent0:                 episode reward: 0.2798,                 loss: nan
agent1:                 episode reward: -0.2798,                 loss: 0.2492
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0133s / 642.7326 s
agent0:                 episode reward: 1.1266,                 loss: nan
agent1:                 episode reward: -1.1266,                 loss: 0.2472
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0382s / 643.7708 s
agent0:                 episode reward: -0.2617,                 loss: nan
agent1:                 episode reward: 0.2617,                 loss: 0.2103
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0152s / 644.7861 s
agent0:                 episode reward: 0.5547,                 loss: nan
agent1:                 episode reward: -0.5547,                 loss: 0.1859
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0296s / 645.8157 s
agent0:                 episode reward: 0.8777,                 loss: nan
agent1:                 episode reward: -0.8777,                 loss: 0.1801
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0266s / 646.8422 s
agent0:                 episode reward: 0.0598,                 loss: nan
agent1:                 episode reward: -0.0598,                 loss: 0.1830
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0142s / 647.8564 s
agent0:                 episode reward: 1.3472,                 loss: nan
agent1:                 episode reward: -1.3472,                 loss: 0.1821
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0269s / 648.8833 s
agent0:                 episode reward: 0.8097,                 loss: nan
agent1:                 episode reward: -0.8097,                 loss: 0.1814
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0222s / 649.9055 s
agent0:                 episode reward: 0.5953,                 loss: nan
agent1:                 episode reward: -0.5953,                 loss: 0.1798
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0673s / 650.9728 s
agent0:                 episode reward: 0.9332,                 loss: nan
agent1:                 episode reward: -0.9332,                 loss: 0.1806
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0240s / 651.9968 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: 0.1802
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0281s / 653.0249 s
agent0:                 episode reward: 0.5373,                 loss: nan
agent1:                 episode reward: -0.5373,                 loss: 0.1818
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0343s / 654.0592 s
agent0:                 episode reward: 0.8614,                 loss: nan
agent1:                 episode reward: -0.8614,                 loss: 0.2080
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0338s / 655.0929 s
agent0:                 episode reward: 0.8281,                 loss: nan
agent1:                 episode reward: -0.8281,                 loss: 0.2162
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0371s / 656.1300 s
agent0:                 episode reward: 0.0590,                 loss: nan
agent1:                 episode reward: -0.0590,                 loss: 0.2166
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9884s / 657.1184 s
agent0:                 episode reward: 0.5049,                 loss: nan
agent1:                 episode reward: -0.5049,                 loss: 0.2172
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9932s / 658.1116 s
agent0:                 episode reward: 0.1419,                 loss: nan
agent1:                 episode reward: -0.1419,                 loss: 0.2154
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0238s / 659.1353 s
agent0:                 episode reward: -0.1001,                 loss: nan
agent1:                 episode reward: 0.1001,                 loss: 0.2156
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0329s / 660.1682 s
agent0:                 episode reward: 0.3096,                 loss: nan
agent1:                 episode reward: -0.3096,                 loss: 0.2135
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0878s / 661.2560 s
agent0:                 episode reward: 0.4369,                 loss: nan
agent1:                 episode reward: -0.4369,                 loss: 0.2167
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0146s / 662.2706 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.2145
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0513s / 663.3218 s
agent0:                 episode reward: 0.9367,                 loss: nan
agent1:                 episode reward: -0.9367,                 loss: 0.2136
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0217s / 664.3435 s
agent0:                 episode reward: 0.5418,                 loss: nan
agent1:                 episode reward: -0.5418,                 loss: 0.2421
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0242s / 665.3677 s
agent0:                 episode reward: 0.4110,                 loss: nan
agent1:                 episode reward: -0.4110,                 loss: 0.2526
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0236s / 666.3914 s
agent0:                 episode reward: 0.4760,                 loss: nan
agent1:                 episode reward: -0.4760,                 loss: 0.2512
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0610s / 667.4524 s
agent0:                 episode reward: 0.1571,                 loss: nan
agent1:                 episode reward: -0.1571,                 loss: 0.2503
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0357s / 668.4880 s
agent0:                 episode reward: 0.5297,                 loss: nan
agent1:                 episode reward: -0.5297,                 loss: 0.2506
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0476s / 669.5357 s
agent0:                 episode reward: 0.9974,                 loss: nan
agent1:                 episode reward: -0.9974,                 loss: 0.2497
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0460s / 670.5816 s
agent0:                 episode reward: 0.2798,                 loss: nan
agent1:                 episode reward: -0.2798,                 loss: 0.2508
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0424s / 671.6241 s
agent0:                 episode reward: 1.4805,                 loss: nan
agent1:                 episode reward: -1.4805,                 loss: 0.2487
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0336s / 672.6577 s
agent0:                 episode reward: -0.1928,                 loss: nan
agent1:                 episode reward: 0.1928,                 loss: 0.2501
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0640s / 673.7217 s
agent0:                 episode reward: 0.2600,                 loss: nan
agent1:                 episode reward: -0.2600,                 loss: 0.2499
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0706s / 674.7922 s
agent0:                 episode reward: -0.1875,                 loss: nan
agent1:                 episode reward: 0.1875,                 loss: 0.2866
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0139s / 675.8061 s
agent0:                 episode reward: 0.6585,                 loss: nan
agent1:                 episode reward: -0.6585,                 loss: 0.2947
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0267s / 676.8328 s
agent0:                 episode reward: 0.6212,                 loss: nan
agent1:                 episode reward: -0.6212,                 loss: 0.2956
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0522s / 677.8850 s
agent0:                 episode reward: 1.4825,                 loss: nan
agent1:                 episode reward: -1.4825,                 loss: 0.2942
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0310s / 678.9160 s
agent0:                 episode reward: 0.3297,                 loss: nan
agent1:                 episode reward: -0.3297,                 loss: 0.2965
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0930s / 680.0090 s
agent0:                 episode reward: -0.6623,                 loss: nan
agent1:                 episode reward: 0.6623,                 loss: 0.2940
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0619s / 681.0709 s
agent0:                 episode reward: 0.9778,                 loss: nan
agent1:                 episode reward: -0.9778,                 loss: 0.2936
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0864s / 682.1573 s
agent0:                 episode reward: -0.1175,                 loss: nan
agent1:                 episode reward: 0.1175,                 loss: 0.2922
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0571s / 683.2144 s
agent0:                 episode reward: 0.3330,                 loss: nan
agent1:                 episode reward: -0.3330,                 loss: 0.2935
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0585s / 684.2729 s
agent0:                 episode reward: 1.2168,                 loss: nan
agent1:                 episode reward: -1.2168,                 loss: 0.2936
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0430s / 685.3159 s
agent0:                 episode reward: 1.5353,                 loss: nan
agent1:                 episode reward: -1.5353,                 loss: 0.3210
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0925s / 686.4084 s
agent0:                 episode reward: 0.8233,                 loss: nan
agent1:                 episode reward: -0.8233,                 loss: 0.3256
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0780s / 687.4864 s
agent0:                 episode reward: 0.7619,                 loss: nan
agent1:                 episode reward: -0.7619,                 loss: 0.3264
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0746s / 688.5610 s
agent0:                 episode reward: 0.1760,                 loss: nan
agent1:                 episode reward: -0.1760,                 loss: 0.3231
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0691s / 689.6301 s
agent0:                 episode reward: 0.6018,                 loss: nan
agent1:                 episode reward: -0.6018,                 loss: 0.3256
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0793s / 690.7094 s
agent0:                 episode reward: 0.3757,                 loss: nan
agent1:                 episode reward: -0.3757,                 loss: 0.3224
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1247s / 691.8341 s
agent0:                 episode reward: 1.2336,                 loss: nan
agent1:                 episode reward: -1.2336,                 loss: 0.3238
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0659s / 692.9000 s
agent0:                 episode reward: -0.3059,                 loss: nan
agent1:                 episode reward: 0.3059,                 loss: 0.3259
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0902s / 693.9902 s
agent0:                 episode reward: 0.0727,                 loss: nan
agent1:                 episode reward: -0.0727,                 loss: 0.3232
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0847s / 695.0750 s
agent0:                 episode reward: 0.8424,                 loss: nan
agent1:                 episode reward: -0.8424,                 loss: 0.3241
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0714s / 696.1464 s
agent0:                 episode reward: 0.1246,                 loss: nan
agent1:                 episode reward: -0.1246,                 loss: 0.3284
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0621s / 697.2085 s
agent0:                 episode reward: 1.1632,                 loss: nan
agent1:                 episode reward: -1.1632,                 loss: 0.3258
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0798s / 698.2883 s
agent0:                 episode reward: 1.6010,                 loss: nan
agent1:                 episode reward: -1.6010,                 loss: 0.3288
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0783s / 699.3666 s
agent0:                 episode reward: 1.3588,                 loss: nan
agent1:                 episode reward: -1.3588,                 loss: 0.3287
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 700.4474 s
agent0:                 episode reward: 1.0864,                 loss: nan
agent1:                 episode reward: -1.0864,                 loss: 0.3248
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1167s / 701.5641 s
agent0:                 episode reward: -0.2031,                 loss: nan
agent1:                 episode reward: 0.2031,                 loss: 0.3251
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0898s / 702.6538 s
agent0:                 episode reward: 0.6091,                 loss: nan
agent1:                 episode reward: -0.6091,                 loss: 0.3274
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0957s / 703.7495 s
agent0:                 episode reward: -0.1383,                 loss: nan
agent1:                 episode reward: 0.1383,                 loss: 0.3253
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1069s / 704.8564 s
agent0:                 episode reward: 0.9304,                 loss: nan
agent1:                 episode reward: -0.9304,                 loss: 0.3257
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0783s / 705.9348 s
agent0:                 episode reward: 0.5863,                 loss: nan
agent1:                 episode reward: -0.5863,                 loss: 0.3259
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0921s / 707.0269 s
agent0:                 episode reward: 0.6548,                 loss: nan
agent1:                 episode reward: -0.6548,                 loss: 0.3359
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0780s / 708.1049 s
agent0:                 episode reward: 1.3525,                 loss: nan
agent1:                 episode reward: -1.3525,                 loss: 0.3338
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0852s / 709.1901 s
agent0:                 episode reward: 0.6010,                 loss: nan
agent1:                 episode reward: -0.6010,                 loss: 0.3337
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1185s / 710.3086 s
agent0:                 episode reward: 0.1766,                 loss: nan
agent1:                 episode reward: -0.1766,                 loss: 0.3338
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0852s / 711.3938 s
agent0:                 episode reward: 0.3606,                 loss: nan
agent1:                 episode reward: -0.3606,                 loss: 0.3328
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1217s / 712.5156 s
agent0:                 episode reward: 1.0001,                 loss: nan
agent1:                 episode reward: -1.0001,                 loss: 0.3325
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0905s / 713.6060 s
agent0:                 episode reward: 0.3639,                 loss: nan
agent1:                 episode reward: -0.3639,                 loss: 0.3317
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0860s / 714.6920 s
agent0:                 episode reward: -0.1657,                 loss: nan
agent1:                 episode reward: 0.1657,                 loss: 0.3332
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0761s / 715.7681 s
agent0:                 episode reward: -0.6478,                 loss: nan
agent1:                 episode reward: 0.6478,                 loss: 0.3321
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0810s / 716.8491 s
agent0:                 episode reward: 0.2948,                 loss: nan
agent1:                 episode reward: -0.2948,                 loss: 0.3312
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0862s / 717.9353 s
agent0:                 episode reward: 0.7247,                 loss: nan
agent1:                 episode reward: -0.7247,                 loss: 0.3482
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0898s / 719.0251 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.3526
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0765s / 720.1016 s
agent0:                 episode reward: 0.8446,                 loss: nan
agent1:                 episode reward: -0.8446,                 loss: 0.3497
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0905s / 721.1921 s
agent0:                 episode reward: 2.1687,                 loss: nan
agent1:                 episode reward: -2.1687,                 loss: 0.3516
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1219s / 722.3140 s
agent0:                 episode reward: 0.5115,                 loss: nan
agent1:                 episode reward: -0.5115,                 loss: 0.3505
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 723.4067 s
agent0:                 episode reward: 1.3262,                 loss: nan
agent1:                 episode reward: -1.3262,                 loss: 0.3526
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0798s / 724.4865 s
agent0:                 episode reward: 0.5381,                 loss: nan
agent1:                 episode reward: -0.5381,                 loss: 0.3515
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0771s / 725.5636 s
agent0:                 episode reward: 0.8655,                 loss: nan
agent1:                 episode reward: -0.8655,                 loss: 0.3492
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1021s / 726.6657 s
agent0:                 episode reward: 0.6882,                 loss: nan
agent1:                 episode reward: -0.6882,                 loss: 0.3506
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0886s / 727.7543 s
agent0:                 episode reward: 1.1631,                 loss: nan
agent1:                 episode reward: -1.1631,                 loss: 0.3499
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0840s / 728.8383 s
agent0:                 episode reward: 0.1187,                 loss: nan
agent1:                 episode reward: -0.1187,                 loss: 0.3775
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1030s / 729.9413 s
agent0:                 episode reward: 0.1079,                 loss: nan
agent1:                 episode reward: -0.1079,                 loss: 0.3854
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1003s / 731.0416 s
agent0:                 episode reward: 0.6564,                 loss: nan
agent1:                 episode reward: -0.6564,                 loss: 0.3828
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0867s / 732.1283 s
agent0:                 episode reward: -0.0644,                 loss: nan
agent1:                 episode reward: 0.0644,                 loss: 0.3826
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1503s / 733.2786 s
agent0:                 episode reward: -0.3124,                 loss: nan
agent1:                 episode reward: 0.3124,                 loss: 0.3816
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0841s / 734.3627 s
agent0:                 episode reward: 0.7798,                 loss: nan
agent1:                 episode reward: -0.7798,                 loss: 0.3824
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1061s / 735.4688 s
agent0:                 episode reward: -0.0926,                 loss: nan
agent1:                 episode reward: 0.0926,                 loss: 0.3841
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0955s / 736.5642 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: 0.5796,                 loss: nan
agent1:                 episode reward: -0.5796,                 loss: 0.3811
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0904s / 737.6547 s
agent0:                 episode reward: -0.3806,                 loss: nan
agent1:                 episode reward: 0.3806,                 loss: 0.3807
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0803s / 738.7350 s
agent0:                 episode reward: 1.4005,                 loss: nan
agent1:                 episode reward: -1.4005,                 loss: 0.3805
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0974s / 739.8324 s
agent0:                 episode reward: 0.4737,                 loss: nan
agent1:                 episode reward: -0.4737,                 loss: 0.3542
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1117s / 740.9441 s
agent0:                 episode reward: -0.2528,                 loss: nan
agent1:                 episode reward: 0.2528,                 loss: 0.3317
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0943s / 742.0384 s
agent0:                 episode reward: 0.7600,                 loss: nan
agent1:                 episode reward: -0.7600,                 loss: 0.3321
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1386s / 743.1771 s
agent0:                 episode reward: 1.0476,                 loss: nan
agent1:                 episode reward: -1.0476,                 loss: 0.3291
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0885s / 744.2656 s
agent0:                 episode reward: 1.0304,                 loss: nan
agent1:                 episode reward: -1.0304,                 loss: 0.3291
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0935s / 745.3591 s
agent0:                 episode reward: 1.0780,                 loss: nan
agent1:                 episode reward: -1.0780,                 loss: 0.3292
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0885s / 746.4476 s
agent0:                 episode reward: 1.0120,                 loss: nan
agent1:                 episode reward: -1.0120,                 loss: 0.3290
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0888s / 747.5364 s
agent0:                 episode reward: -0.2815,                 loss: nan
agent1:                 episode reward: 0.2815,                 loss: 0.3271
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1325s / 748.6689 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: 0.3272
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1087s / 749.7776 s
agent0:                 episode reward: 0.1783,                 loss: nan
agent1:                 episode reward: -0.1783,                 loss: 0.3260
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1119s / 750.8895 s
agent0:                 episode reward: 0.9213,                 loss: nan
agent1:                 episode reward: -0.9213,                 loss: 0.2656
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1185s / 752.0081 s
agent0:                 episode reward: 0.1228,                 loss: nan
agent1:                 episode reward: -0.1228,                 loss: 0.2296
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1495s / 753.1576 s
agent0:                 episode reward: 1.2493,                 loss: nan
agent1:                 episode reward: -1.2493,                 loss: 0.2285
