pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fa16d676668>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.037 0.037 0.037 ... 0.037 0.037 0.037]
 [0.037 0.037 0.037 ... 0.037 0.037 0.037]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '18640' '19318' '19446']
 ['193' '5289' '7712' ... '18710' '19358' '19474']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_20000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220117153310_exploit_20000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220117153310_exploit_20000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0271s / 0.0271 s
agent0:                 episode reward: -0.7690,                 loss: nan
agent1:                 episode reward: 0.7690,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0527s / 0.0798 s
agent0:                 episode reward: 0.0388,                 loss: nan
agent1:                 episode reward: -0.0388,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0428s / 0.1226 s
agent0:                 episode reward: -0.2810,                 loss: nan
agent1:                 episode reward: 0.2810,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0447s / 0.1673 s
agent0:                 episode reward: 0.2237,                 loss: nan
agent1:                 episode reward: -0.2237,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0452s / 0.2125 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0427s / 0.2552 s
agent0:                 episode reward: 0.1325,                 loss: nan
agent1:                 episode reward: -0.1325,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0425s / 0.2976 s
agent0:                 episode reward: -0.3770,                 loss: nan
agent1:                 episode reward: 0.3770,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0423s / 0.3400 s
agent0:                 episode reward: -0.0627,                 loss: nan
agent1:                 episode reward: 0.0627,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0409s / 0.3809 s
agent0:                 episode reward: 0.2163,                 loss: nan
agent1:                 episode reward: -0.2163,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0418s / 0.4227 s
agent0:                 episode reward: 0.3151,                 loss: nan
agent1:                 episode reward: -0.3151,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0436s / 0.4663 s
agent0:                 episode reward: 0.1127,                 loss: nan
agent1:                 episode reward: -0.1127,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1021s / 0.5684 s
agent0:                 episode reward: 0.1582,                 loss: nan
agent1:                 episode reward: -0.1582,                 loss: 0.1679
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1556s / 0.7240 s
agent0:                 episode reward: -0.0855,                 loss: nan
agent1:                 episode reward: 0.0855,                 loss: 0.1627
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1657s / 0.8897 s
agent0:                 episode reward: 0.1747,                 loss: nan
agent1:                 episode reward: -0.1747,                 loss: 0.1561
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1597s / 1.0494 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.1522
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1623s / 1.2117 s
agent0:                 episode reward: 0.0632,                 loss: nan
agent1:                 episode reward: -0.0632,                 loss: 0.1476
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1639s / 1.3756 s
agent0:                 episode reward: 0.0295,                 loss: nan
agent1:                 episode reward: -0.0295,                 loss: 0.1449
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1545s / 1.5302 s
agent0:                 episode reward: 0.2037,                 loss: nan
agent1:                 episode reward: -0.2037,                 loss: 0.1437
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1549s / 1.6851 s
agent0:                 episode reward: 0.0981,                 loss: nan
agent1:                 episode reward: -0.0981,                 loss: 0.1426
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1568s / 1.8419 s
agent0:                 episode reward: 0.2099,                 loss: nan
agent1:                 episode reward: -0.2099,                 loss: 0.1428
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1837s / 2.0256 s
agent0:                 episode reward: -0.1877,                 loss: nan
agent1:                 episode reward: 0.1877,                 loss: 0.1412
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1572s / 2.1828 s
agent0:                 episode reward: -0.4446,                 loss: nan
agent1:                 episode reward: 0.4446,                 loss: 0.1405
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1620s / 2.3448 s
agent0:                 episode reward: -0.2139,                 loss: nan
agent1:                 episode reward: 0.2139,                 loss: 0.1405
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1566s / 2.5014 s
agent0:                 episode reward: -0.0002,                 loss: nan
agent1:                 episode reward: 0.0002,                 loss: 0.1408
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1587s / 2.6601 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: 0.1422
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1587s / 2.8187 s
agent0:                 episode reward: 0.5006,                 loss: nan
agent1:                 episode reward: -0.5006,                 loss: 0.1420
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1556s / 2.9744 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1417
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 3.1294 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.1402
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1660s / 3.2954 s
agent0:                 episode reward: -0.0615,                 loss: nan
agent1:                 episode reward: 0.0615,                 loss: 0.1421
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1629s / 3.4583 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.1392
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1670s / 3.6253 s
agent0:                 episode reward: -0.0415,                 loss: nan
agent1:                 episode reward: 0.0415,                 loss: 0.1394
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1632s / 3.7885 s
agent0:                 episode reward: 0.1347,                 loss: nan
agent1:                 episode reward: -0.1347,                 loss: 0.1383
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1590s / 3.9475 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.1382
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1615s / 4.1090 s
agent0:                 episode reward: -0.0200,                 loss: nan
agent1:                 episode reward: 0.0200,                 loss: 0.1366
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 4.2818 s
agent0:                 episode reward: -0.0180,                 loss: nan
agent1:                 episode reward: 0.0180,                 loss: 0.1372
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1541s / 4.4359 s
agent0:                 episode reward: 0.0895,                 loss: nan
agent1:                 episode reward: -0.0895,                 loss: 0.1356
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1556s / 4.5915 s
agent0:                 episode reward: 0.0932,                 loss: nan
agent1:                 episode reward: -0.0932,                 loss: 0.1351
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1553s / 4.7468 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: 0.1341
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1589s / 4.9057 s
agent0:                 episode reward: 0.1587,                 loss: nan
agent1:                 episode reward: -0.1587,                 loss: 0.1352
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1587s / 5.0645 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.1353
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1592s / 5.2236 s
agent0:                 episode reward: 0.2460,                 loss: nan
agent1:                 episode reward: -0.2460,                 loss: 0.1359
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1639s / 5.3875 s
agent0:                 episode reward: 0.3161,                 loss: nan
agent1:                 episode reward: -0.3161,                 loss: 0.1346
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1626s / 5.5501 s
agent0:                 episode reward: -0.1748,                 loss: nan
agent1:                 episode reward: 0.1748,                 loss: 0.1347
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1609s / 5.7110 s
agent0:                 episode reward: -0.2993,                 loss: nan
agent1:                 episode reward: 0.2993,                 loss: 0.1335
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1564s / 5.8674 s
agent0:                 episode reward: 0.0547,                 loss: nan
agent1:                 episode reward: -0.0547,                 loss: 0.1342
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1540s / 6.0214 s
agent0:                 episode reward: 0.0471,                 loss: nan
agent1:                 episode reward: -0.0471,                 loss: 0.1354
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1559s / 6.1773 s
agent0:                 episode reward: 0.3561,                 loss: nan
agent1:                 episode reward: -0.3561,                 loss: 0.1350
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1608s / 6.3381 s
agent0:                 episode reward: -0.0960,                 loss: nan
agent1:                 episode reward: 0.0960,                 loss: 0.1356
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1692s / 6.5072 s
agent0:                 episode reward: -0.1041,                 loss: nan
agent1:                 episode reward: 0.1041,                 loss: 0.1356
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 6.6783 s
agent0:                 episode reward: -0.1200,                 loss: nan
agent1:                 episode reward: 0.1200,                 loss: 0.1350
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1537s / 6.8320 s
agent0:                 episode reward: -0.1712,                 loss: nan
agent1:                 episode reward: 0.1712,                 loss: 0.1346
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1544s / 6.9864 s
agent0:                 episode reward: -0.3641,                 loss: nan
agent1:                 episode reward: 0.3641,                 loss: 0.1354
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1569s / 7.1433 s
agent0:                 episode reward: 0.2248,                 loss: nan
agent1:                 episode reward: -0.2248,                 loss: 0.1349
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1606s / 7.3039 s
agent0:                 episode reward: 0.1179,                 loss: nan
agent1:                 episode reward: -0.1179,                 loss: 0.1369
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1595s / 7.4634 s
agent0:                 episode reward: -0.3053,                 loss: nan
agent1:                 episode reward: 0.3053,                 loss: 0.1369
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1571s / 7.6205 s
agent0:                 episode reward: -0.1632,                 loss: nan
agent1:                 episode reward: 0.1632,                 loss: 0.1368
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1608s / 7.7813 s
agent0:                 episode reward: 0.3613,                 loss: nan
agent1:                 episode reward: -0.3613,                 loss: 0.1352
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1596s / 7.9410 s
agent0:                 episode reward: 0.1903,                 loss: nan
agent1:                 episode reward: -0.1903,                 loss: 0.1359
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1582s / 8.0992 s
agent0:                 episode reward: -0.4416,                 loss: nan
agent1:                 episode reward: 0.4416,                 loss: 0.1352
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1584s / 8.2576 s
agent0:                 episode reward: -0.1097,                 loss: nan
agent1:                 episode reward: 0.1097,                 loss: 0.1362
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1611s / 8.4187 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.1356
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1602s / 8.5789 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.1348
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1626s / 8.7415 s
agent0:                 episode reward: 0.1784,                 loss: nan
agent1:                 episode reward: -0.1784,                 loss: 0.1371
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1625s / 8.9040 s
agent0:                 episode reward: 0.2302,                 loss: nan
agent1:                 episode reward: -0.2302,                 loss: 0.1378
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1618s / 9.0658 s
agent0:                 episode reward: -0.3257,                 loss: nan
agent1:                 episode reward: 0.3257,                 loss: 0.1373
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1645s / 9.2303 s
agent0:                 episode reward: 0.0790,                 loss: nan
agent1:                 episode reward: -0.0790,                 loss: 0.1362
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1661s / 9.3964 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1370
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1773s / 9.5737 s
agent0:                 episode reward: 0.0988,                 loss: nan
agent1:                 episode reward: -0.0988,                 loss: 0.1354
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1765s / 9.7502 s
agent0:                 episode reward: -0.4914,                 loss: nan
agent1:                 episode reward: 0.4914,                 loss: 0.1362
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1606s / 9.9108 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: 0.1371
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1650s / 10.0759 s
agent0:                 episode reward: 0.1660,                 loss: nan
agent1:                 episode reward: -0.1660,                 loss: 0.1376
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1673s / 10.2432 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: 0.1375
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1702s / 10.4134 s
agent0:                 episode reward: 0.0936,                 loss: nan
agent1:                 episode reward: -0.0936,                 loss: 0.1366
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1706s / 10.5840 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.1354
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1674s / 10.7513 s
agent0:                 episode reward: -0.0939,                 loss: nan
agent1:                 episode reward: 0.0939,                 loss: 0.1360
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1708s / 10.9222 s
agent0:                 episode reward: 0.0523,                 loss: nan
agent1:                 episode reward: -0.0523,                 loss: 0.1349
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1665s / 11.0887 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: 0.1369
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1662s / 11.2548 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.1349
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1699s / 11.4247 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.1352
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1665s / 11.5912 s
agent0:                 episode reward: 0.4240,                 loss: nan
agent1:                 episode reward: -0.4240,                 loss: 0.1346
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1683s / 11.7595 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.1340
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1675s / 11.9270 s
agent0:                 episode reward: -0.5973,                 loss: nan
agent1:                 episode reward: 0.5973,                 loss: 0.1349
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 12.0980 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1333
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1659s / 12.2639 s
agent0:                 episode reward: -0.5082,                 loss: nan
agent1:                 episode reward: 0.5082,                 loss: 0.1345
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1676s / 12.4315 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.1331
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 12.6380 s
agent0:                 episode reward: -0.0606,                 loss: nan
agent1:                 episode reward: 0.0606,                 loss: 0.1336
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 12.8267 s
agent0:                 episode reward: -0.0333,                 loss: nan
agent1:                 episode reward: 0.0333,                 loss: 0.1330
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1675s / 12.9942 s
agent0:                 episode reward: -0.0890,                 loss: nan
agent1:                 episode reward: 0.0890,                 loss: 0.1344
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1670s / 13.1612 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: 0.1336
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1677s / 13.3289 s
agent0:                 episode reward: 0.1076,                 loss: nan
agent1:                 episode reward: -0.1076,                 loss: 0.1320
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1720s / 13.5009 s
agent0:                 episode reward: 0.4744,                 loss: nan
agent1:                 episode reward: -0.4744,                 loss: 0.1334
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1702s / 13.6711 s
agent0:                 episode reward: 0.0226,                 loss: nan
agent1:                 episode reward: -0.0226,                 loss: 0.1327
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1613s / 13.8323 s
agent0:                 episode reward: -0.5013,                 loss: nan
agent1:                 episode reward: 0.5013,                 loss: 0.1319
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1640s / 13.9964 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.1319
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1666s / 14.1629 s
agent0:                 episode reward: -0.2072,                 loss: nan
agent1:                 episode reward: 0.2072,                 loss: 0.1331
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1650s / 14.3279 s
agent0:                 episode reward: 0.0385,                 loss: nan
agent1:                 episode reward: -0.0385,                 loss: 0.1306
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1627s / 14.4906 s
agent0:                 episode reward: -0.3584,                 loss: nan
agent1:                 episode reward: 0.3584,                 loss: 0.1322
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1706s / 14.6612 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1327
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1704s / 14.8316 s
agent0:                 episode reward: -0.3179,                 loss: nan
agent1:                 episode reward: 0.3179,                 loss: 0.1321
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1667s / 14.9983 s
agent0:                 episode reward: 0.0023,                 loss: nan
agent1:                 episode reward: -0.0023,                 loss: 0.1307
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1695s / 15.1677 s
agent0:                 episode reward: -0.1044,                 loss: nan
agent1:                 episode reward: 0.1044,                 loss: 0.1320
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1724s / 15.3402 s
agent0:                 episode reward: 0.0016,                 loss: nan
agent1:                 episode reward: -0.0016,                 loss: 0.1305
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1733s / 15.5135 s
agent0:                 episode reward: -0.0004,                 loss: nan
agent1:                 episode reward: 0.0004,                 loss: 0.1310
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 15.7104 s
agent0:                 episode reward: -0.5524,                 loss: nan
agent1:                 episode reward: 0.5524,                 loss: 0.1302
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1815s / 15.8919 s
agent0:                 episode reward: -0.1103,                 loss: nan
agent1:                 episode reward: 0.1103,                 loss: 0.1300
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1738s / 16.0657 s
agent0:                 episode reward: 0.1168,                 loss: nan
agent1:                 episode reward: -0.1168,                 loss: 0.1299
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1721s / 16.2378 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: 0.1287
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1734s / 16.4111 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.1283
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1730s / 16.5841 s
agent0:                 episode reward: 0.1420,                 loss: nan
agent1:                 episode reward: -0.1420,                 loss: 0.1291
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1749s / 16.7590 s
agent0:                 episode reward: -0.0690,                 loss: nan
agent1:                 episode reward: 0.0690,                 loss: 0.1301
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 16.9322 s
agent0:                 episode reward: -0.4581,                 loss: nan
agent1:                 episode reward: 0.4581,                 loss: 0.1287
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1766s / 17.1088 s
agent0:                 episode reward: 0.1546,                 loss: nan
agent1:                 episode reward: -0.1546,                 loss: 0.1291
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1740s / 17.2828 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.1302
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1722s / 17.4550 s
agent0:                 episode reward: -0.0375,                 loss: nan
agent1:                 episode reward: 0.0375,                 loss: 0.1297
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1742s / 17.6292 s
agent0:                 episode reward: -0.0358,                 loss: nan
agent1:                 episode reward: 0.0358,                 loss: 0.1296
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1737s / 17.8029 s
agent0:                 episode reward: -0.1459,                 loss: nan
agent1:                 episode reward: 0.1459,                 loss: 0.1292
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 17.9739 s
agent0:                 episode reward: -0.0966,                 loss: nan
agent1:                 episode reward: 0.0966,                 loss: 0.1291
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1712s / 18.1451 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: 0.1288
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 18.3176 s
agent0:                 episode reward: -0.0596,                 loss: nan
agent1:                 episode reward: 0.0596,                 loss: 0.1289
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1723s / 18.4899 s
agent0:                 episode reward: 0.1927,                 loss: nan
agent1:                 episode reward: -0.1927,                 loss: 0.1281
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 18.6629 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.1296
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 18.8339 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.1293
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1711s / 19.0051 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: 0.1283
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1686s / 19.1736 s
agent0:                 episode reward: -0.0220,                 loss: nan
agent1:                 episode reward: 0.0220,                 loss: 0.1290
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1638s / 19.3375 s
agent0:                 episode reward: -0.6994,                 loss: nan
agent1:                 episode reward: 0.6994,                 loss: 0.1272
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1628s / 19.5002 s
agent0:                 episode reward: 0.2231,                 loss: nan
agent1:                 episode reward: -0.2231,                 loss: 0.1295
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1648s / 19.6650 s
agent0:                 episode reward: -0.1816,                 loss: nan
agent1:                 episode reward: 0.1816,                 loss: 0.1288
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1701s / 19.8351 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: 0.1294
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1636s / 19.9988 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1278
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1645s / 20.1632 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1281
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1640s / 20.3272 s
agent0:                 episode reward: -0.2074,                 loss: nan
agent1:                 episode reward: 0.2074,                 loss: 0.1283
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1633s / 20.4906 s
agent0:                 episode reward: -0.0684,                 loss: nan
agent1:                 episode reward: 0.0684,                 loss: 0.1284
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1660s / 20.6565 s
agent0:                 episode reward: 0.1593,                 loss: nan
agent1:                 episode reward: -0.1593,                 loss: 0.1289
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1767s / 20.8333 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: 0.1280
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1846s / 21.0179 s
agent0:                 episode reward: 0.1380,                 loss: nan
agent1:                 episode reward: -0.1380,                 loss: 0.1277
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1892s / 21.2071 s
agent0:                 episode reward: -0.1082,                 loss: nan
agent1:                 episode reward: 0.1082,                 loss: 0.1279
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 21.4078 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.1283
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1873s / 21.5951 s
agent0:                 episode reward: -0.5843,                 loss: nan
agent1:                 episode reward: 0.5843,                 loss: 0.1274
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1771s / 21.7722 s
agent0:                 episode reward: -0.0125,                 loss: nan
agent1:                 episode reward: 0.0125,                 loss: 0.1261
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 21.9519 s
agent0:                 episode reward: -0.0910,                 loss: nan
agent1:                 episode reward: 0.0910,                 loss: 0.1272
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 22.1592 s
agent0:                 episode reward: -0.3214,                 loss: nan
agent1:                 episode reward: 0.3214,                 loss: 0.1287
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1787s / 22.3379 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.1297
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1814s / 22.5193 s
agent0:                 episode reward: -0.3403,                 loss: nan
agent1:                 episode reward: 0.3403,                 loss: 0.1273
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1758s / 22.6951 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.1279
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1781s / 22.8732 s
agent0:                 episode reward: -0.1001,                 loss: nan
agent1:                 episode reward: 0.1001,                 loss: 0.1281
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1785s / 23.0517 s
agent0:                 episode reward: -0.0873,                 loss: nan
agent1:                 episode reward: 0.0873,                 loss: 0.1307
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1784s / 23.2300 s
agent0:                 episode reward: -0.3603,                 loss: nan
agent1:                 episode reward: 0.3603,                 loss: 0.1292
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1814s / 23.4114 s
agent0:                 episode reward: 0.1662,                 loss: nan
agent1:                 episode reward: -0.1662,                 loss: 0.1300
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1809s / 23.5923 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.1303
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1875s / 23.7798 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.1290
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 23.9685 s
agent0:                 episode reward: 0.0616,                 loss: nan
agent1:                 episode reward: -0.0616,                 loss: 0.1308
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1898s / 24.1583 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: 0.1314
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2116s / 24.3698 s
agent0:                 episode reward: -0.1169,                 loss: nan
agent1:                 episode reward: 0.1169,                 loss: 0.1290
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 24.5846 s
agent0:                 episode reward: -0.2233,                 loss: nan
agent1:                 episode reward: 0.2233,                 loss: 0.1295
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1714s / 24.7560 s
agent0:                 episode reward: -0.1671,                 loss: nan
agent1:                 episode reward: 0.1671,                 loss: 0.1302
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1711s / 24.9271 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: 0.1296
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1713s / 25.0984 s
agent0:                 episode reward: -0.1894,                 loss: nan
agent1:                 episode reward: 0.1894,                 loss: 0.1298
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 25.2700 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: 0.1289
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1783s / 25.4482 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: 0.1293
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1792s / 25.6274 s
agent0:                 episode reward: -0.0481,                 loss: nan
agent1:                 episode reward: 0.0481,                 loss: 0.1298
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1734s / 25.8009 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.1282
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1730s / 25.9739 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.1307
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1735s / 26.1474 s
agent0:                 episode reward: -0.4477,                 loss: nan
agent1:                 episode reward: 0.4477,                 loss: 0.1318
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1765s / 26.3239 s
agent0:                 episode reward: 0.1321,                 loss: nan
agent1:                 episode reward: -0.1321,                 loss: 0.1306
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 26.5017 s
agent0:                 episode reward: -0.2478,                 loss: nan
agent1:                 episode reward: 0.2478,                 loss: 0.1302
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1748s / 26.6765 s
agent0:                 episode reward: 0.1251,                 loss: nan
agent1:                 episode reward: -0.1251,                 loss: 0.1310
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1706s / 26.8471 s
agent0:                 episode reward: 0.3032,                 loss: nan
agent1:                 episode reward: -0.3032,                 loss: 0.1303
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1711s / 27.0183 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.1301
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1697s / 27.1879 s
agent0:                 episode reward: -0.1125,                 loss: nan
agent1:                 episode reward: 0.1125,                 loss: 0.1298
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 27.3607 s
agent0:                 episode reward: -0.4071,                 loss: nan
agent1:                 episode reward: 0.4071,                 loss: 0.1299
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1747s / 27.5354 s
agent0:                 episode reward: 0.0230,                 loss: nan
agent1:                 episode reward: -0.0230,                 loss: 0.1308
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1724s / 27.7078 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.1287
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1718s / 27.8796 s
agent0:                 episode reward: 0.1698,                 loss: nan
agent1:                 episode reward: -0.1698,                 loss: 0.1305
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1691s / 28.0487 s
agent0:                 episode reward: -0.6754,                 loss: nan
agent1:                 episode reward: 0.6754,                 loss: 0.1284
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1713s / 28.2200 s
agent0:                 episode reward: -0.0458,                 loss: nan
agent1:                 episode reward: 0.0458,                 loss: 0.1292
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1756s / 28.3956 s
agent0:                 episode reward: -0.0289,                 loss: nan
agent1:                 episode reward: 0.0289,                 loss: 0.1299
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 28.5687 s
agent0:                 episode reward: -0.2762,                 loss: nan
agent1:                 episode reward: 0.2762,                 loss: 0.1293
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 28.7419 s
agent0:                 episode reward: 0.0340,                 loss: nan
agent1:                 episode reward: -0.0340,                 loss: 0.1304
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1766s / 28.9185 s
agent0:                 episode reward: -0.1833,                 loss: nan
agent1:                 episode reward: 0.1833,                 loss: 0.1309
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1837s / 29.1021 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: 0.1303
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 29.2979 s
agent0:                 episode reward: -0.0560,                 loss: nan
agent1:                 episode reward: 0.0560,                 loss: 0.1318
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1831s / 29.4810 s
agent0:                 episode reward: 0.0464,                 loss: nan
agent1:                 episode reward: -0.0464,                 loss: 0.1316
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1795s / 29.6605 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1321
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1755s / 29.8360 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.1315
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1723s / 30.0083 s
agent0:                 episode reward: 0.0805,                 loss: nan
agent1:                 episode reward: -0.0805,                 loss: 0.1314
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 30.2029 s
agent0:                 episode reward: 0.0771,                 loss: nan
agent1:                 episode reward: -0.0771,                 loss: 0.1333
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2132s / 30.4161 s
agent0:                 episode reward: 0.0704,                 loss: nan
agent1:                 episode reward: -0.0704,                 loss: 0.1305
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 30.5985 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.1322
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 30.7806 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.1307
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1800s / 30.9606 s
agent0:                 episode reward: -0.2419,                 loss: nan
agent1:                 episode reward: 0.2419,                 loss: 0.1301
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1816s / 31.1422 s
agent0:                 episode reward: 0.0530,                 loss: nan
agent1:                 episode reward: -0.0530,                 loss: 0.1307
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1781s / 31.3203 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: 0.1322
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 31.4997 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.1329
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1787s / 31.6784 s
agent0:                 episode reward: 0.1037,                 loss: nan
agent1:                 episode reward: -0.1037,                 loss: 0.1318
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 31.8620 s
agent0:                 episode reward: 0.4386,                 loss: nan
agent1:                 episode reward: -0.4386,                 loss: 0.1324
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 32.0454 s
agent0:                 episode reward: -0.0603,                 loss: nan
agent1:                 episode reward: 0.0603,                 loss: 0.1335
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1806s / 32.2259 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.1323
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1807s / 32.4066 s
agent0:                 episode reward: -0.2487,                 loss: nan
agent1:                 episode reward: 0.2487,                 loss: 0.1318
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 32.5909 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.1330
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 32.7772 s
agent0:                 episode reward: -0.1658,                 loss: nan
agent1:                 episode reward: 0.1658,                 loss: 0.1340
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 32.9655 s
agent0:                 episode reward: 0.1290,                 loss: nan
agent1:                 episode reward: -0.1290,                 loss: 0.1324
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 33.1642 s
agent0:                 episode reward: -0.7174,                 loss: nan
agent1:                 episode reward: 0.7174,                 loss: 0.1310
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 33.3678 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.1329
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 33.5688 s
agent0:                 episode reward: -0.1452,                 loss: nan
agent1:                 episode reward: 0.1452,                 loss: 0.1318
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 33.7636 s
agent0:                 episode reward: -0.3201,                 loss: nan
agent1:                 episode reward: 0.3201,                 loss: 0.1309
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 33.9592 s
agent0:                 episode reward: 0.0437,                 loss: nan
agent1:                 episode reward: -0.0437,                 loss: 0.1329
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 34.1542 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.1314
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1881s / 34.3423 s
agent0:                 episode reward: -0.6076,                 loss: nan
agent1:                 episode reward: 0.6076,                 loss: 0.1326
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 34.5310 s
agent0:                 episode reward: 0.0260,                 loss: nan
agent1:                 episode reward: -0.0260,                 loss: 0.1331
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1793s / 34.7103 s
agent0:                 episode reward: -0.3783,                 loss: nan
agent1:                 episode reward: 0.3783,                 loss: 0.1323
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1812s / 34.8915 s
agent0:                 episode reward: -0.0540,                 loss: nan
agent1:                 episode reward: 0.0540,                 loss: 0.1305
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1817s / 35.0732 s
agent0:                 episode reward: 0.3783,                 loss: nan
agent1:                 episode reward: -0.3783,                 loss: 0.1312
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 35.2574 s
agent0:                 episode reward: -0.4244,                 loss: nan
agent1:                 episode reward: 0.4244,                 loss: 0.1328
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 35.4483 s
agent0:                 episode reward: -0.6736,                 loss: nan
agent1:                 episode reward: 0.6736,                 loss: 0.1309
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 35.6544 s
agent0:                 episode reward: -0.0409,                 loss: nan
agent1:                 episode reward: 0.0409,                 loss: 0.1302
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2060s / 35.8604 s
agent0:                 episode reward: -0.2509,                 loss: nan
agent1:                 episode reward: 0.2509,                 loss: 0.1328
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 36.0553 s
agent0:                 episode reward: -0.6371,                 loss: nan
agent1:                 episode reward: 0.6371,                 loss: 0.1328
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 36.2482 s
agent0:                 episode reward: 0.3159,                 loss: nan
agent1:                 episode reward: -0.3159,                 loss: 0.1314
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 36.4585 s
agent0:                 episode reward: -0.6990,                 loss: nan
agent1:                 episode reward: 0.6990,                 loss: 0.1317
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1915s / 36.6500 s
agent0:                 episode reward: -0.6272,                 loss: nan
agent1:                 episode reward: 0.6272,                 loss: 0.1315
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1780s / 36.8280 s
agent0:                 episode reward: -0.0174,                 loss: nan
agent1:                 episode reward: 0.0174,                 loss: 0.1309
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1817s / 37.0097 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: 0.1296
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1800s / 37.1897 s
agent0:                 episode reward: -0.0889,                 loss: nan
agent1:                 episode reward: 0.0889,                 loss: 0.1307
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1788s / 37.3685 s
agent0:                 episode reward: -0.0392,                 loss: nan
agent1:                 episode reward: 0.0392,                 loss: 0.1313
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 37.5680 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.1318
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1868s / 37.7548 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.1314
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1876s / 37.9425 s
agent0:                 episode reward: 0.0139,                 loss: nan
agent1:                 episode reward: -0.0139,                 loss: 0.1301
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1878s / 38.1302 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: 0.1312
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 38.3288 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.1312
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 38.5168 s
agent0:                 episode reward: -0.0105,                 loss: nan
agent1:                 episode reward: 0.0105,                 loss: 0.1307
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1892s / 38.7060 s
agent0:                 episode reward: -0.1337,                 loss: nan
agent1:                 episode reward: 0.1337,                 loss: 0.1310
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 38.9055 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1315
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 39.0994 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.1299
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 39.3015 s
agent0:                 episode reward: 0.0680,                 loss: nan
agent1:                 episode reward: -0.0680,                 loss: 0.1313
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 39.5326 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.1301
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2096s / 39.7422 s
agent0:                 episode reward: 0.0166,                 loss: nan
agent1:                 episode reward: -0.0166,                 loss: 0.1292
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 39.9368 s
agent0:                 episode reward: 0.2156,                 loss: nan
agent1:                 episode reward: -0.2156,                 loss: 0.1308
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 40.1286 s
agent0:                 episode reward: -0.3048,                 loss: nan
agent1:                 episode reward: 0.3048,                 loss: 0.1298
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1864s / 40.3149 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.1303
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1894s / 40.5044 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1311
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 40.6983 s
agent0:                 episode reward: -0.1385,                 loss: nan
agent1:                 episode reward: 0.1385,                 loss: 0.1307
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1856s / 40.8839 s
agent0:                 episode reward: -0.3158,                 loss: nan
agent1:                 episode reward: 0.3158,                 loss: 0.1306
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1895s / 41.0734 s
agent0:                 episode reward: -0.8297,                 loss: nan
agent1:                 episode reward: 0.8297,                 loss: 0.1303
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1862s / 41.2597 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.1293
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1866s / 41.4462 s
agent0:                 episode reward: -0.5782,                 loss: nan
agent1:                 episode reward: 0.5782,                 loss: 0.1272
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1870s / 41.6333 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.1301
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 41.8202 s
agent0:                 episode reward: -0.7632,                 loss: nan
agent1:                 episode reward: 0.7632,                 loss: 0.1287
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 42.0071 s
agent0:                 episode reward: -0.3102,                 loss: nan
agent1:                 episode reward: 0.3102,                 loss: 0.1300
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1859s / 42.1930 s
agent0:                 episode reward: -0.3943,                 loss: nan
agent1:                 episode reward: 0.3943,                 loss: 0.1295
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 42.4023 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.1309
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 42.6083 s
agent0:                 episode reward: -0.1988,                 loss: nan
agent1:                 episode reward: 0.1988,                 loss: 0.1291
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1818s / 42.7902 s
agent0:                 episode reward: -0.0572,                 loss: nan
agent1:                 episode reward: 0.0572,                 loss: 0.1296
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1829s / 42.9730 s
agent0:                 episode reward: -0.1096,                 loss: nan
agent1:                 episode reward: 0.1096,                 loss: 0.1297
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 43.1552 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.1298
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 43.3380 s
agent0:                 episode reward: -0.4180,                 loss: nan
agent1:                 episode reward: 0.4180,                 loss: 0.1294
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 43.5222 s
agent0:                 episode reward: -0.3869,                 loss: nan
agent1:                 episode reward: 0.3869,                 loss: 0.1294
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 43.7064 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.1302
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 43.8925 s
agent0:                 episode reward: -0.2328,                 loss: nan
agent1:                 episode reward: 0.2328,                 loss: 0.1303
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1805s / 44.0731 s
agent0:                 episode reward: -0.0452,                 loss: nan
agent1:                 episode reward: 0.0452,                 loss: 0.1287
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 44.2527 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1274
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 44.4321 s
agent0:                 episode reward: -0.2161,                 loss: nan
agent1:                 episode reward: 0.2161,                 loss: 0.1307
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1835s / 44.6157 s
agent0:                 episode reward: -0.4761,                 loss: nan
agent1:                 episode reward: 0.4761,                 loss: 0.1301
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 44.8018 s
agent0:                 episode reward: -0.1488,                 loss: nan
agent1:                 episode reward: 0.1488,                 loss: 0.1296
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 44.9851 s
agent0:                 episode reward: -0.0582,                 loss: nan
agent1:                 episode reward: 0.0582,                 loss: 0.1298
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 45.1837 s
agent0:                 episode reward: -0.0178,                 loss: nan
agent1:                 episode reward: 0.0178,                 loss: 0.1290
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 45.3756 s
agent0:                 episode reward: -0.3992,                 loss: nan
agent1:                 episode reward: 0.3992,                 loss: 0.1280
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2175s / 45.5930 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: 0.1303
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2266s / 45.8196 s
agent0:                 episode reward: -0.1726,                 loss: nan
agent1:                 episode reward: 0.1726,                 loss: 0.1294
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 46.0209 s
agent0:                 episode reward: 0.0499,                 loss: nan
agent1:                 episode reward: -0.0499,                 loss: 0.1288
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 46.2165 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: 0.1296
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 46.4105 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.1286
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 46.6050 s
agent0:                 episode reward: -0.2132,                 loss: nan
agent1:                 episode reward: 0.2132,                 loss: 0.1293
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1910s / 46.7961 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: 0.1312
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 46.9895 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.1274
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1867s / 47.1762 s
agent0:                 episode reward: -0.3208,                 loss: nan
agent1:                 episode reward: 0.3208,                 loss: 0.1298
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1855s / 47.3617 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.1294
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2210s / 47.5826 s
agent0:                 episode reward: -0.6394,                 loss: nan
agent1:                 episode reward: 0.6394,                 loss: 0.1284
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 47.7781 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1274
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 47.9798 s
agent0:                 episode reward: -0.0849,                 loss: nan
agent1:                 episode reward: 0.0849,                 loss: 0.1272
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 48.1808 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.1290
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 48.3836 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: 0.1279
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 48.6138 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.1280
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 48.8392 s
agent0:                 episode reward: -0.5670,                 loss: nan
agent1:                 episode reward: 0.5670,                 loss: 0.1278
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2057s / 49.0449 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.1279
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 49.2444 s
agent0:                 episode reward: -0.0979,                 loss: nan
agent1:                 episode reward: 0.0979,                 loss: 0.1265
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 49.4486 s
agent0:                 episode reward: -0.5539,                 loss: nan
agent1:                 episode reward: 0.5539,                 loss: 0.1271
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 49.6533 s
agent0:                 episode reward: -0.2361,                 loss: nan
agent1:                 episode reward: 0.2361,                 loss: 0.1283
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 49.8550 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.1294
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 50.0573 s
agent0:                 episode reward: -0.3790,                 loss: nan
agent1:                 episode reward: 0.3790,                 loss: 0.1287
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 50.2571 s
agent0:                 episode reward: -0.1070,                 loss: nan
agent1:                 episode reward: 0.1070,                 loss: 0.1289
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 50.4591 s
agent0:                 episode reward: -0.3411,                 loss: nan
agent1:                 episode reward: 0.3411,                 loss: 0.1282
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 50.6685 s
agent0:                 episode reward: -0.3213,                 loss: nan
agent1:                 episode reward: 0.3213,                 loss: 0.1268
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 50.8719 s
agent0:                 episode reward: -0.4606,                 loss: nan
agent1:                 episode reward: 0.4606,                 loss: 0.1271
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 51.0758 s
agent0:                 episode reward: -0.2691,                 loss: nan
agent1:                 episode reward: 0.2691,                 loss: 0.1289
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2096s / 51.2854 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.1264
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 51.4912 s
agent0:                 episode reward: -0.2885,                 loss: nan
agent1:                 episode reward: 0.2885,                 loss: 0.1256
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 51.7312 s
agent0:                 episode reward: -0.8532,                 loss: nan
agent1:                 episode reward: 0.8532,                 loss: 0.1251
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 51.9607 s
agent0:                 episode reward: 0.2084,                 loss: nan
agent1:                 episode reward: -0.2084,                 loss: 0.1261
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 52.1543 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1267
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 52.3484 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.1254
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 52.5430 s
agent0:                 episode reward: -0.7477,                 loss: nan
agent1:                 episode reward: 0.7477,                 loss: 0.1268
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 52.7389 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.1246
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 52.9342 s
agent0:                 episode reward: -0.4353,                 loss: nan
agent1:                 episode reward: 0.4353,                 loss: 0.1266
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 53.1321 s
agent0:                 episode reward: -0.4471,                 loss: nan
agent1:                 episode reward: 0.4471,                 loss: 0.1260
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 53.3206 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.1263
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1896s / 53.5101 s
agent0:                 episode reward: -0.6250,                 loss: nan
agent1:                 episode reward: 0.6250,                 loss: 0.1248
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 53.7066 s
agent0:                 episode reward: -0.2591,                 loss: nan
agent1:                 episode reward: 0.2591,                 loss: 0.1257
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 53.9075 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.1263
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 54.1245 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.1265
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 54.3278 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1254
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 54.5290 s
agent0:                 episode reward: -0.6864,                 loss: nan
agent1:                 episode reward: 0.6864,                 loss: 0.1269
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2241s / 54.7532 s
agent0:                 episode reward: -0.3151,                 loss: nan
agent1:                 episode reward: 0.3151,                 loss: 0.1278
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 54.9680 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: 0.1292
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 55.1665 s
agent0:                 episode reward: -0.3682,                 loss: nan
agent1:                 episode reward: 0.3682,                 loss: 0.1276
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 55.3716 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.1281
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 55.5762 s
agent0:                 episode reward: -0.3550,                 loss: nan
agent1:                 episode reward: 0.3550,                 loss: 0.1280
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 55.7776 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: 0.1277
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 55.9769 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.1273
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1930s / 56.1699 s
agent0:                 episode reward: -0.2095,                 loss: nan
agent1:                 episode reward: 0.2095,                 loss: 0.1265
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 56.3678 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.1287
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 56.5647 s
agent0:                 episode reward: -0.3793,                 loss: nan
agent1:                 episode reward: 0.3793,                 loss: 0.1282
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 56.7649 s
agent0:                 episode reward: 0.0733,                 loss: nan
agent1:                 episode reward: -0.0733,                 loss: 0.1262
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 56.9649 s
agent0:                 episode reward: -0.5489,                 loss: nan
agent1:                 episode reward: 0.5489,                 loss: 0.1262
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 57.1588 s
agent0:                 episode reward: -0.0610,                 loss: nan
agent1:                 episode reward: 0.0610,                 loss: 0.1274
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 57.3560 s
agent0:                 episode reward: -0.4532,                 loss: nan
agent1:                 episode reward: 0.4532,                 loss: 0.1272
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 57.5562 s
agent0:                 episode reward: -0.1327,                 loss: nan
agent1:                 episode reward: 0.1327,                 loss: 0.1280
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 57.7788 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.1292
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 58.0048 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.1276
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 58.2119 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.1264
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 58.4154 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.1275
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 58.6195 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.1296
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 58.8260 s
agent0:                 episode reward: -0.2181,                 loss: nan
agent1:                 episode reward: 0.2181,                 loss: 0.1287
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 59.0270 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.1273
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 59.2215 s
agent0:                 episode reward: -0.0486,                 loss: nan
agent1:                 episode reward: 0.0486,                 loss: 0.1266
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 59.4373 s
agent0:                 episode reward: -0.0474,                 loss: nan
agent1:                 episode reward: 0.0474,                 loss: 0.1284
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 59.6386 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.1281
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 59.8381 s
agent0:                 episode reward: -0.3969,                 loss: nan
agent1:                 episode reward: 0.3969,                 loss: 0.1270
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 60.0322 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1278
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 60.2274 s
agent0:                 episode reward: -0.1332,                 loss: nan
agent1:                 episode reward: 0.1332,                 loss: 0.1282
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 60.4225 s
agent0:                 episode reward: -0.4252,                 loss: nan
agent1:                 episode reward: 0.4252,                 loss: 0.1274
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 60.6219 s
agent0:                 episode reward: -0.0188,                 loss: nan
agent1:                 episode reward: 0.0188,                 loss: 0.1272
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 60.8552 s
agent0:                 episode reward: -0.1081,                 loss: nan
agent1:                 episode reward: 0.1081,                 loss: 0.1289
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 61.0806 s
agent0:                 episode reward: -0.4274,                 loss: nan
agent1:                 episode reward: 0.4274,                 loss: 0.1277
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 61.2789 s
agent0:                 episode reward: 0.2113,                 loss: nan
agent1:                 episode reward: -0.2113,                 loss: 0.1266
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 61.4946 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.1282
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 61.7015 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.1295
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 61.9149 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: 0.1291
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 62.1242 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: 0.1289
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2116s / 62.3358 s
agent0:                 episode reward: -0.3007,                 loss: nan
agent1:                 episode reward: 0.3007,                 loss: 0.1312
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2277s / 62.5635 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.1275
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 62.7691 s
agent0:                 episode reward: -0.5315,                 loss: nan
agent1:                 episode reward: 0.5315,                 loss: 0.1293
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 62.9736 s
agent0:                 episode reward: 0.1896,                 loss: nan
agent1:                 episode reward: -0.1896,                 loss: 0.1272
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 63.1721 s
agent0:                 episode reward: -0.0636,                 loss: nan
agent1:                 episode reward: 0.0636,                 loss: 0.1295
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 63.3754 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1294
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 63.5810 s
agent0:                 episode reward: -0.0743,                 loss: nan
agent1:                 episode reward: 0.0743,                 loss: 0.1279
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2222s / 63.8032 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: 0.1281
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 64.0396 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1293
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 64.2433 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: 0.1285
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 64.4524 s
agent0:                 episode reward: -0.1675,                 loss: nan
agent1:                 episode reward: 0.1675,                 loss: 0.1306
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 64.6616 s
agent0:                 episode reward: -0.1607,                 loss: nan
agent1:                 episode reward: 0.1607,                 loss: 0.1281
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 64.8647 s
agent0:                 episode reward: -0.1377,                 loss: nan
agent1:                 episode reward: 0.1377,                 loss: 0.1293
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 65.0630 s
agent0:                 episode reward: -0.4721,                 loss: nan
agent1:                 episode reward: 0.4721,                 loss: 0.1261
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 65.2632 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.1261
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 65.4676 s
agent0:                 episode reward: -0.4234,                 loss: nan
agent1:                 episode reward: 0.4234,                 loss: 0.1263
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 65.6686 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1270
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 65.8648 s
agent0:                 episode reward: -0.7655,                 loss: nan
agent1:                 episode reward: 0.7655,                 loss: 0.1274
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 66.0616 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: 0.1281
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 66.2593 s
agent0:                 episode reward: -0.4310,                 loss: nan
agent1:                 episode reward: 0.4310,                 loss: 0.1245
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 66.4522 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.1273
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 66.6468 s
agent0:                 episode reward: -0.4305,                 loss: nan
agent1:                 episode reward: 0.4305,                 loss: 0.1250
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 66.8462 s
agent0:                 episode reward: -0.1896,                 loss: nan
agent1:                 episode reward: 0.1896,                 loss: 0.1276
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2334s / 67.0796 s
agent0:                 episode reward: -0.4595,                 loss: nan
agent1:                 episode reward: 0.4595,                 loss: 0.1255
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2063s / 67.2860 s
agent0:                 episode reward: -0.5327,                 loss: nan
agent1:                 episode reward: 0.5327,                 loss: 0.1264
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 67.4827 s
agent0:                 episode reward: -0.4191,                 loss: nan
agent1:                 episode reward: 0.4191,                 loss: 0.1248
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 67.6788 s
agent0:                 episode reward: -0.5789,                 loss: nan
agent1:                 episode reward: 0.5789,                 loss: 0.1263
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 67.8774 s
agent0:                 episode reward: -0.2615,                 loss: nan
agent1:                 episode reward: 0.2615,                 loss: 0.1261
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 68.0814 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1263
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 68.2847 s
agent0:                 episode reward: -0.2522,                 loss: nan
agent1:                 episode reward: 0.2522,                 loss: 0.1244
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 68.4832 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.1284
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 68.6845 s
agent0:                 episode reward: 0.0671,                 loss: nan
agent1:                 episode reward: -0.0671,                 loss: 0.1281
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 68.8923 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.1285
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 69.0954 s
agent0:                 episode reward: -0.6359,                 loss: nan
agent1:                 episode reward: 0.6359,                 loss: 0.1279
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 69.2976 s
agent0:                 episode reward: -0.1448,                 loss: nan
agent1:                 episode reward: 0.1448,                 loss: 0.1288
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2057s / 69.5033 s
agent0:                 episode reward: -0.2500,                 loss: nan
agent1:                 episode reward: 0.2500,                 loss: 0.1271
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 69.7307 s
agent0:                 episode reward: -0.2455,                 loss: nan
agent1:                 episode reward: 0.2455,                 loss: 0.1271
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 69.9691 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: 0.1284
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 70.1955 s
agent0:                 episode reward: -0.0012,                 loss: nan
agent1:                 episode reward: 0.0012,                 loss: 0.1271
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 70.4024 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: 0.1268
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2145s / 70.6168 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: 0.1251
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 70.8557 s
agent0:                 episode reward: -0.2669,                 loss: nan
agent1:                 episode reward: 0.2669,                 loss: 0.1273
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 71.0658 s
agent0:                 episode reward: -0.4249,                 loss: nan
agent1:                 episode reward: 0.4249,                 loss: 0.1272
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 71.2748 s
agent0:                 episode reward: -0.9570,                 loss: nan
agent1:                 episode reward: 0.9570,                 loss: 0.1265
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 71.4822 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1274
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 71.6852 s
agent0:                 episode reward: -0.0816,                 loss: nan
agent1:                 episode reward: 0.0816,                 loss: 0.1261
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 71.8943 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.1281
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2100s / 72.1042 s
agent0:                 episode reward: -0.1537,                 loss: nan
agent1:                 episode reward: 0.1537,                 loss: 0.1274
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 72.3093 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.1279
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 72.5193 s
agent0:                 episode reward: -0.6810,                 loss: nan
agent1:                 episode reward: 0.6810,                 loss: 0.1279
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2129s / 72.7322 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.1273
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 72.9422 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.1274
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2415s / 73.1838 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.1253
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2208s / 73.4045 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: 0.1279
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2130s / 73.6175 s
agent0:                 episode reward: -0.3351,                 loss: nan
agent1:                 episode reward: 0.3351,                 loss: 0.1261
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 73.8266 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.1269
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2127s / 74.0393 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.1282
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 74.2502 s
agent0:                 episode reward: 0.0382,                 loss: nan
agent1:                 episode reward: -0.0382,                 loss: 0.1276
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 74.4596 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.1270
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 74.6693 s
agent0:                 episode reward: -0.7578,                 loss: nan
agent1:                 episode reward: 0.7578,                 loss: 0.1261
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 74.8781 s
agent0:                 episode reward: -0.3878,                 loss: nan
agent1:                 episode reward: 0.3878,                 loss: 0.1272
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 75.0855 s
agent0:                 episode reward: -0.2197,                 loss: nan
agent1:                 episode reward: 0.2197,                 loss: 0.1274
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 75.2826 s
agent0:                 episode reward: -0.5948,                 loss: nan
agent1:                 episode reward: 0.5948,                 loss: 0.1268
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 75.4856 s
agent0:                 episode reward: -0.0896,                 loss: nan
agent1:                 episode reward: 0.0896,                 loss: 0.1272
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 75.7006 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.1253
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 75.9062 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.1267
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2245s / 76.1307 s
agent0:                 episode reward: -0.7512,                 loss: nan
agent1:                 episode reward: 0.7512,                 loss: 0.1257
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 76.3703 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1256
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 76.5806 s
agent0:                 episode reward: -0.5241,                 loss: nan
agent1:                 episode reward: 0.5241,                 loss: 0.1262
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 76.7824 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: 0.1254
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 76.9869 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.1256
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 77.1880 s
agent0:                 episode reward: -0.8056,                 loss: nan
agent1:                 episode reward: 0.8056,                 loss: 0.1252
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 77.3990 s
agent0:                 episode reward: 0.0748,                 loss: nan
agent1:                 episode reward: -0.0748,                 loss: 0.1257
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 77.6061 s
agent0:                 episode reward: -0.1265,                 loss: nan
agent1:                 episode reward: 0.1265,                 loss: 0.1246
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 77.8150 s
agent0:                 episode reward: -0.1283,                 loss: nan
agent1:                 episode reward: 0.1283,                 loss: 0.1252
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 78.0151 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.1242
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 78.2544 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.1261
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 78.4596 s
agent0:                 episode reward: 0.0376,                 loss: nan
agent1:                 episode reward: -0.0376,                 loss: 0.1249
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 78.6618 s
agent0:                 episode reward: -0.4061,                 loss: nan
agent1:                 episode reward: 0.4061,                 loss: 0.1261
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 78.8647 s
agent0:                 episode reward: -0.7396,                 loss: nan
agent1:                 episode reward: 0.7396,                 loss: 0.1259
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 79.0670 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.1261
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 79.2908 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.1252
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2106s / 79.5013 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.1259
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 79.7215 s
agent0:                 episode reward: -0.6413,                 loss: nan
agent1:                 episode reward: 0.6413,                 loss: 0.1261
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 79.9466 s
agent0:                 episode reward: -0.2438,                 loss: nan
agent1:                 episode reward: 0.2438,                 loss: 0.1272
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 80.1747 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1259
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 80.4049 s
agent0:                 episode reward: -0.7159,                 loss: nan
agent1:                 episode reward: 0.7159,                 loss: 0.1267
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 80.6327 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.1248
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2169s / 80.8496 s
agent0:                 episode reward: -0.3757,                 loss: nan
agent1:                 episode reward: 0.3757,                 loss: 0.1257
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 81.0619 s
agent0:                 episode reward: -0.2649,                 loss: nan
agent1:                 episode reward: 0.2649,                 loss: 0.1264
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2097s / 81.2716 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.1256
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 81.4829 s
agent0:                 episode reward: -0.3817,                 loss: nan
agent1:                 episode reward: 0.3817,                 loss: 0.1264
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 81.7208 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.1259
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 81.9575 s
agent0:                 episode reward: -0.2492,                 loss: nan
agent1:                 episode reward: 0.2492,                 loss: 0.1269
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2205s / 82.1779 s
agent0:                 episode reward: -0.5059,                 loss: nan
agent1:                 episode reward: 0.5059,                 loss: 0.1265
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2166s / 82.3945 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.1257
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 82.6035 s
agent0:                 episode reward: -0.3518,                 loss: nan
agent1:                 episode reward: 0.3518,                 loss: 0.1252
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 82.8159 s
agent0:                 episode reward: -0.6276,                 loss: nan
agent1:                 episode reward: 0.6276,                 loss: 0.1250
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2141s / 83.0299 s
agent0:                 episode reward: -0.6603,                 loss: nan
agent1:                 episode reward: 0.6603,                 loss: 0.1260
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2136s / 83.2436 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: 0.1269
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2168s / 83.4604 s
agent0:                 episode reward: -0.3001,                 loss: nan
agent1:                 episode reward: 0.3001,                 loss: 0.1268
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2166s / 83.6769 s
agent0:                 episode reward: -0.6307,                 loss: nan
agent1:                 episode reward: 0.6307,                 loss: 0.1248
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 83.8892 s
agent0:                 episode reward: -0.6243,                 loss: nan
agent1:                 episode reward: 0.6243,                 loss: 0.1254
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2124s / 84.1016 s
agent0:                 episode reward: -0.3523,                 loss: nan
agent1:                 episode reward: 0.3523,                 loss: 0.1257
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2121s / 84.3137 s
agent0:                 episode reward: -1.0037,                 loss: nan
agent1:                 episode reward: 1.0037,                 loss: 0.1247
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 84.5260 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.1266
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 84.7459 s
agent0:                 episode reward: 0.0233,                 loss: nan
agent1:                 episode reward: -0.0233,                 loss: 0.1261
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 84.9833 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.1262
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2228s / 85.2061 s
agent0:                 episode reward: -0.4317,                 loss: nan
agent1:                 episode reward: 0.4317,                 loss: 0.1264
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 85.4268 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: 0.1264
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2142s / 85.6410 s
agent0:                 episode reward: -0.7049,                 loss: nan
agent1:                 episode reward: 0.7049,                 loss: 0.1258
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 85.8549 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.1259
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2145s / 86.0694 s
agent0:                 episode reward: -0.7294,                 loss: nan
agent1:                 episode reward: 0.7294,                 loss: 0.1258
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2182s / 86.2876 s
agent0:                 episode reward: -0.7198,                 loss: nan
agent1:                 episode reward: 0.7198,                 loss: 0.1261
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 86.5052 s
agent0:                 episode reward: -0.6162,                 loss: nan
agent1:                 episode reward: 0.6162,                 loss: 0.1275
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2167s / 86.7219 s
agent0:                 episode reward: -0.6996,                 loss: nan
agent1:                 episode reward: 0.6996,                 loss: 0.1284
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 86.9421 s
agent0:                 episode reward: -0.2457,                 loss: nan
agent1:                 episode reward: 0.2457,                 loss: 0.1257
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 87.1641 s
agent0:                 episode reward: -0.2964,                 loss: nan
agent1:                 episode reward: 0.2964,                 loss: 0.1264
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 87.3725 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1262
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 87.6056 s
agent0:                 episode reward: -0.6092,                 loss: nan
agent1:                 episode reward: 0.6092,                 loss: 0.1270
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2249s / 87.8305 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.1283
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 88.0714 s
agent0:                 episode reward: -0.4310,                 loss: nan
agent1:                 episode reward: 0.4310,                 loss: 0.1257
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 88.2817 s
agent0:                 episode reward: -0.6188,                 loss: nan
agent1:                 episode reward: 0.6188,                 loss: 0.1281
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 88.4974 s
agent0:                 episode reward: -0.3835,                 loss: nan
agent1:                 episode reward: 0.3835,                 loss: 0.1270
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2189s / 88.7163 s
agent0:                 episode reward: -0.6344,                 loss: nan
agent1:                 episode reward: 0.6344,                 loss: 0.1268
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 88.9344 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.1256
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 89.1546 s
agent0:                 episode reward: -0.6102,                 loss: nan
agent1:                 episode reward: 0.6102,                 loss: 0.1265
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 89.3696 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.1284
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 89.5877 s
agent0:                 episode reward: -0.4923,                 loss: nan
agent1:                 episode reward: 0.4923,                 loss: 0.1274
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2135s / 89.8012 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.1270
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2047s / 90.0059 s
agent0:                 episode reward: -0.3268,                 loss: nan
agent1:                 episode reward: 0.3268,                 loss: 0.1258
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 90.2152 s
agent0:                 episode reward: -0.0238,                 loss: nan
agent1:                 episode reward: 0.0238,                 loss: 0.1240
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2178s / 90.4330 s
agent0:                 episode reward: -0.5477,                 loss: nan
agent1:                 episode reward: 0.5477,                 loss: 0.1276
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2155s / 90.6484 s
agent0:                 episode reward: -0.3834,                 loss: nan
agent1:                 episode reward: 0.3834,                 loss: 0.1274
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 90.8649 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.1250
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 91.1057 s
agent0:                 episode reward: -0.6535,                 loss: nan
agent1:                 episode reward: 0.6535,                 loss: 0.1273
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 91.3330 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.1256
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 91.5478 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.1256
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 91.7627 s
agent0:                 episode reward: -0.4991,                 loss: nan
agent1:                 episode reward: 0.4991,                 loss: 0.1266
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 91.9843 s
agent0:                 episode reward: -0.7817,                 loss: nan
agent1:                 episode reward: 0.7817,                 loss: 0.1256
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 92.2053 s
agent0:                 episode reward: 0.0358,                 loss: nan
agent1:                 episode reward: -0.0358,                 loss: 0.1245
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2186s / 92.4239 s
agent0:                 episode reward: -0.7249,                 loss: nan
agent1:                 episode reward: 0.7249,                 loss: 0.1272
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 92.6439 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.1264
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 92.8641 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1267
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 93.0873 s
agent0:                 episode reward: -0.6881,                 loss: nan
agent1:                 episode reward: 0.6881,                 loss: 0.1265
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 93.3065 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: 0.1271
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 93.5351 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.1251
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2174s / 93.7525 s
agent0:                 episode reward: -0.0245,                 loss: nan
agent1:                 episode reward: 0.0245,                 loss: 0.1260
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2250s / 93.9775 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.1260
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 94.2189 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.1252
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2247s / 94.4436 s
agent0:                 episode reward: -0.6254,                 loss: nan
agent1:                 episode reward: 0.6254,                 loss: 0.1254
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 94.6629 s
agent0:                 episode reward: -0.4748,                 loss: nan
agent1:                 episode reward: 0.4748,                 loss: 0.1250
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2206s / 94.8835 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.1257
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2195s / 95.1030 s
agent0:                 episode reward: -0.1929,                 loss: nan
agent1:                 episode reward: 0.1929,                 loss: 0.1256
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 95.3200 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1243
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2224s / 95.5424 s
agent0:                 episode reward: -0.3024,                 loss: nan
agent1:                 episode reward: 0.3024,                 loss: 0.1243
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 95.7647 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.1243
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 96.0108 s
agent0:                 episode reward: -0.3227,                 loss: nan
agent1:                 episode reward: 0.3227,                 loss: 0.1245
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2231s / 96.2339 s
agent0:                 episode reward: -0.4853,                 loss: nan
agent1:                 episode reward: 0.4853,                 loss: 0.1244
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 96.4594 s
agent0:                 episode reward: -0.6328,                 loss: nan
agent1:                 episode reward: 0.6328,                 loss: 0.1241
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2208s / 96.6802 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.1248
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 96.9045 s
agent0:                 episode reward: -0.4255,                 loss: nan
agent1:                 episode reward: 0.4255,                 loss: 0.1244
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 97.1541 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: 0.1237
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 97.3980 s
agent0:                 episode reward: -0.0072,                 loss: nan
agent1:                 episode reward: 0.0072,                 loss: 0.1249
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 97.6173 s
agent0:                 episode reward: -0.2896,                 loss: nan
agent1:                 episode reward: 0.2896,                 loss: 0.1232
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 97.8455 s
agent0:                 episode reward: -0.5678,                 loss: nan
agent1:                 episode reward: 0.5678,                 loss: 0.1236
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 98.0701 s
agent0:                 episode reward: -0.4503,                 loss: nan
agent1:                 episode reward: 0.4503,                 loss: 0.1225
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 98.2969 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.1240
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 98.5256 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: 0.1242
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2258s / 98.7514 s
agent0:                 episode reward: -0.4108,                 loss: nan
agent1:                 episode reward: 0.4108,                 loss: 0.1239
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2239s / 98.9753 s
agent0:                 episode reward: -0.7370,                 loss: nan
agent1:                 episode reward: 0.7370,                 loss: 0.1235
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 99.2053 s
agent0:                 episode reward: -0.5529,                 loss: nan
agent1:                 episode reward: 0.5529,                 loss: 0.1236
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 99.4305 s
agent0:                 episode reward: -0.4430,                 loss: nan
agent1:                 episode reward: 0.4430,                 loss: 0.1234
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 99.6572 s
agent0:                 episode reward: -0.1383,                 loss: nan
agent1:                 episode reward: 0.1383,                 loss: 0.1235
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 99.8839 s
agent0:                 episode reward: -0.4013,                 loss: nan
agent1:                 episode reward: 0.4013,                 loss: 0.1232
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2433s / 100.1272 s
agent0:                 episode reward: -0.3191,                 loss: nan
agent1:                 episode reward: 0.3191,                 loss: 0.1243
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 100.3725 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.1235
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 100.5970 s
agent0:                 episode reward: -0.7482,                 loss: nan
agent1:                 episode reward: 0.7482,                 loss: 0.1235
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 100.8484 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.1223
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 101.0952 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.1232
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 101.3238 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: 0.1244
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2249s / 101.5486 s
agent0:                 episode reward: -0.1758,                 loss: nan
agent1:                 episode reward: 0.1758,                 loss: 0.1242
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2289s / 101.7775 s
agent0:                 episode reward: -0.2764,                 loss: nan
agent1:                 episode reward: 0.2764,                 loss: 0.1250
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 102.0018 s
agent0:                 episode reward: -0.5456,                 loss: nan
agent1:                 episode reward: 0.5456,                 loss: 0.1257
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 102.2229 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.1239
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2251s / 102.4479 s
agent0:                 episode reward: -0.4975,                 loss: nan
agent1:                 episode reward: 0.4975,                 loss: 0.1248
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 102.6758 s
agent0:                 episode reward: -0.3048,                 loss: nan
agent1:                 episode reward: 0.3048,                 loss: 0.1246
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 102.9038 s
agent0:                 episode reward: -0.3356,                 loss: nan
agent1:                 episode reward: 0.3356,                 loss: 0.1243
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 103.1441 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1240
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 103.4070 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.1254
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2219s / 103.6289 s
agent0:                 episode reward: -0.4469,                 loss: nan
agent1:                 episode reward: 0.4469,                 loss: 0.1241
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2189s / 103.8478 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.1238
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 104.0678 s
agent0:                 episode reward: -0.7975,                 loss: nan
agent1:                 episode reward: 0.7975,                 loss: 0.1229
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2522s / 104.3200 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.1240
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2298s / 104.5498 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.1232
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 104.7814 s
agent0:                 episode reward: -0.3289,                 loss: nan
agent1:                 episode reward: 0.3289,                 loss: 0.1243
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 105.0057 s
agent0:                 episode reward: -0.2838,                 loss: nan
agent1:                 episode reward: 0.2838,                 loss: 0.1231
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 105.2361 s
agent0:                 episode reward: -0.2756,                 loss: nan
agent1:                 episode reward: 0.2756,                 loss: 0.1238
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2476s / 105.4837 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1245
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2457s / 105.7294 s
agent0:                 episode reward: -0.1816,                 loss: nan
agent1:                 episode reward: 0.1816,                 loss: 0.1258
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2305s / 105.9599 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.1236
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 106.1976 s
agent0:                 episode reward: -0.2229,                 loss: nan
agent1:                 episode reward: 0.2229,                 loss: 0.1235
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 106.4487 s
agent0:                 episode reward: -0.0201,                 loss: nan
agent1:                 episode reward: 0.0201,                 loss: 0.1229
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 106.6773 s
agent0:                 episode reward: -0.3000,                 loss: nan
agent1:                 episode reward: 0.3000,                 loss: 0.1237
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 106.8972 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.1222
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2205s / 107.1177 s
agent0:                 episode reward: -0.5182,                 loss: nan
agent1:                 episode reward: 0.5182,                 loss: 0.1239
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 107.3347 s
agent0:                 episode reward: -0.2592,                 loss: nan
agent1:                 episode reward: 0.2592,                 loss: 0.1233
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2179s / 107.5526 s
agent0:                 episode reward: -0.0597,                 loss: nan
agent1:                 episode reward: 0.0597,                 loss: 0.1233
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 107.7786 s
agent0:                 episode reward: -0.8606,                 loss: nan
agent1:                 episode reward: 0.8606,                 loss: 0.1245
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 108.0000 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: 0.1240
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 108.2188 s
agent0:                 episode reward: -0.6815,                 loss: nan
agent1:                 episode reward: 0.6815,                 loss: 0.1240
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2189s / 108.4377 s
agent0:                 episode reward: -0.9476,                 loss: nan
agent1:                 episode reward: 0.9476,                 loss: 0.1243
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 108.6576 s
agent0:                 episode reward: -0.5576,                 loss: nan
agent1:                 episode reward: 0.5576,                 loss: 0.1248
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 108.8815 s
agent0:                 episode reward: -0.6992,                 loss: nan
agent1:                 episode reward: 0.6992,                 loss: 0.1236
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2196s / 109.1011 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.1247
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 109.3334 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1242
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 109.5760 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.1231
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2203s / 109.7963 s
agent0:                 episode reward: -0.3541,                 loss: nan
agent1:                 episode reward: 0.3541,                 loss: 0.1242
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2205s / 110.0168 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.1238
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 110.2380 s
agent0:                 episode reward: -0.6853,                 loss: nan
agent1:                 episode reward: 0.6853,                 loss: 0.1220
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2225s / 110.4605 s
agent0:                 episode reward: -0.8632,                 loss: nan
agent1:                 episode reward: 0.8632,                 loss: 0.1253
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2265s / 110.6870 s
agent0:                 episode reward: -0.7249,                 loss: nan
agent1:                 episode reward: 0.7249,                 loss: 0.1241
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 110.9173 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.1227
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 111.1609 s
agent0:                 episode reward: -0.4892,                 loss: nan
agent1:                 episode reward: 0.4892,                 loss: 0.1235
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2418s / 111.4028 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.1237
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 111.6437 s
agent0:                 episode reward: -0.3400,                 loss: nan
agent1:                 episode reward: 0.3400,                 loss: 0.1225
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2391s / 111.8827 s
agent0:                 episode reward: -0.7114,                 loss: nan
agent1:                 episode reward: 0.7114,                 loss: 0.1231
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2339s / 112.1166 s
agent0:                 episode reward: -0.8444,                 loss: nan
agent1:                 episode reward: 0.8444,                 loss: 0.1237
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 112.3589 s
agent0:                 episode reward: -0.4436,                 loss: nan
agent1:                 episode reward: 0.4436,                 loss: 0.1226
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 112.6275 s
agent0:                 episode reward: -0.4107,                 loss: nan
agent1:                 episode reward: 0.4107,                 loss: 0.1236
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 112.8708 s
agent0:                 episode reward: -0.4562,                 loss: nan
agent1:                 episode reward: 0.4562,                 loss: 0.1235
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2294s / 113.1002 s
agent0:                 episode reward: -0.9546,                 loss: nan
agent1:                 episode reward: 0.9546,                 loss: 0.1235
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 113.3325 s
agent0:                 episode reward: -0.5783,                 loss: nan
agent1:                 episode reward: 0.5783,                 loss: 0.1219
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 113.5606 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.1220
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 113.7941 s
agent0:                 episode reward: -0.3273,                 loss: nan
agent1:                 episode reward: 0.3273,                 loss: 0.1223
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 114.0271 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.1215
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 114.2587 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.1244
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 114.4942 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.1229
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 114.7284 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1234
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2307s / 114.9591 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.1235
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 115.1918 s
agent0:                 episode reward: -0.4694,                 loss: nan
agent1:                 episode reward: 0.4694,                 loss: 0.1212
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2479s / 115.4397 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1227
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 115.7081 s
agent0:                 episode reward: -0.3512,                 loss: nan
agent1:                 episode reward: 0.3512,                 loss: 0.1211
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2328s / 115.9409 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.1212
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 116.2079 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.1225
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2229s / 116.4308 s
agent0:                 episode reward: -0.3610,                 loss: nan
agent1:                 episode reward: 0.3610,                 loss: 0.1222
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 116.6589 s
agent0:                 episode reward: -0.8196,                 loss: nan
agent1:                 episode reward: 0.8196,                 loss: 0.1218
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 116.8841 s
agent0:                 episode reward: -0.4681,                 loss: nan
agent1:                 episode reward: 0.4681,                 loss: 0.1224
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2256s / 117.1097 s
agent0:                 episode reward: -0.4752,                 loss: nan
agent1:                 episode reward: 0.4752,                 loss: 0.1231
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 117.3476 s
agent0:                 episode reward: -0.5793,                 loss: nan
agent1:                 episode reward: 0.5793,                 loss: 0.1221
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 117.5912 s
agent0:                 episode reward: -0.9270,                 loss: nan
agent1:                 episode reward: 0.9270,                 loss: 0.1229
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 117.8281 s
agent0:                 episode reward: -0.8583,                 loss: nan
agent1:                 episode reward: 0.8583,                 loss: 0.1251
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2353s / 118.0634 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1231
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 118.2999 s
agent0:                 episode reward: -0.6623,                 loss: nan
agent1:                 episode reward: 0.6623,                 loss: 0.1225
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 118.5568 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.1239
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 118.8097 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.1226
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2325s / 119.0422 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.1237
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 119.2733 s
agent0:                 episode reward: -0.4456,                 loss: nan
agent1:                 episode reward: 0.4456,                 loss: 0.1235
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2266s / 119.4998 s
agent0:                 episode reward: -0.7664,                 loss: nan
agent1:                 episode reward: 0.7664,                 loss: 0.1239
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 119.7278 s
agent0:                 episode reward: -0.3080,                 loss: nan
agent1:                 episode reward: 0.3080,                 loss: 0.1234
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 119.9530 s
agent0:                 episode reward: -0.2291,                 loss: nan
agent1:                 episode reward: 0.2291,                 loss: 0.1228
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 120.1833 s
agent0:                 episode reward: -0.4925,                 loss: nan
agent1:                 episode reward: 0.4925,                 loss: 0.1212
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 120.4233 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.1228
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 120.6899 s
agent0:                 episode reward: -0.0899,                 loss: nan
agent1:                 episode reward: 0.0899,                 loss: 0.1212
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 120.9449 s
agent0:                 episode reward: -0.5492,                 loss: nan
agent1:                 episode reward: 0.5492,                 loss: 0.1208
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2341s / 121.1790 s
agent0:                 episode reward: -0.3560,                 loss: nan
agent1:                 episode reward: 0.3560,                 loss: 0.1231
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 121.4193 s
agent0:                 episode reward: -0.8441,                 loss: nan
agent1:                 episode reward: 0.8441,                 loss: 0.1219
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2575s / 121.6769 s
agent0:                 episode reward: -0.3997,                 loss: nan
agent1:                 episode reward: 0.3997,                 loss: 0.1237
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 121.9348 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.1229
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 122.1792 s
agent0:                 episode reward: -0.3499,                 loss: nan
agent1:                 episode reward: 0.3499,                 loss: 0.1210
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 122.4255 s
agent0:                 episode reward: -0.4149,                 loss: nan
agent1:                 episode reward: 0.4149,                 loss: 0.1203
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 122.6700 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.1229
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 122.9141 s
agent0:                 episode reward: -0.4995,                 loss: nan
agent1:                 episode reward: 0.4995,                 loss: 0.1225
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2469s / 123.1610 s
agent0:                 episode reward: -0.5126,                 loss: nan
agent1:                 episode reward: 0.5126,                 loss: 0.1220
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 123.3961 s
agent0:                 episode reward: -0.3647,                 loss: nan
agent1:                 episode reward: 0.3647,                 loss: 0.1230
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 123.6329 s
agent0:                 episode reward: -0.2955,                 loss: nan
agent1:                 episode reward: 0.2955,                 loss: 0.1229
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 123.8662 s
agent0:                 episode reward: -0.2662,                 loss: nan
agent1:                 episode reward: 0.2662,                 loss: 0.1229
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 124.1063 s
agent0:                 episode reward: -0.5881,                 loss: nan
agent1:                 episode reward: 0.5881,                 loss: 0.1216
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 124.3466 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.1235
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2499s / 124.5965 s
agent0:                 episode reward: -0.5085,                 loss: nan
agent1:                 episode reward: 0.5085,                 loss: 0.1207
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 124.8584 s
agent0:                 episode reward: -0.8167,                 loss: nan
agent1:                 episode reward: 0.8167,                 loss: 0.1218
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2324s / 125.0908 s
agent0:                 episode reward: -0.1687,                 loss: nan
agent1:                 episode reward: 0.1687,                 loss: 0.1225
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2372s / 125.3280 s
agent0:                 episode reward: -0.4048,                 loss: nan
agent1:                 episode reward: 0.4048,                 loss: 0.1231
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2494s / 125.5774 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.1219
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2476s / 125.8250 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.1221
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 126.0663 s
agent0:                 episode reward: -0.1207,                 loss: nan
agent1:                 episode reward: 0.1207,                 loss: 0.1215
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 126.3038 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1220
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 126.5406 s
agent0:                 episode reward: -0.3255,                 loss: nan
agent1:                 episode reward: 0.3255,                 loss: 0.1201
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 126.7709 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.1202
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 127.0065 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.1194
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2320s / 127.2384 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.1215
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2294s / 127.4678 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.1218
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 127.7138 s
agent0:                 episode reward: -0.3781,                 loss: nan
agent1:                 episode reward: 0.3781,                 loss: 0.1211
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2513s / 127.9651 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.1227
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 128.2071 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.1230
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2341s / 128.4412 s
agent0:                 episode reward: -0.3137,                 loss: nan
agent1:                 episode reward: 0.3137,                 loss: 0.1217
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 128.6814 s
agent0:                 episode reward: -0.3866,                 loss: nan
agent1:                 episode reward: 0.3866,                 loss: 0.1217
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2489s / 128.9303 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1230
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 129.1903 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.1221
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 129.4492 s
agent0:                 episode reward: -0.5989,                 loss: nan
agent1:                 episode reward: 0.5989,                 loss: 0.1224
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2454s / 129.6946 s
agent0:                 episode reward: -0.3754,                 loss: nan
agent1:                 episode reward: 0.3754,                 loss: 0.1209
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 129.9416 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: 0.1234
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 130.1841 s
agent0:                 episode reward: -0.0491,                 loss: nan
agent1:                 episode reward: 0.0491,                 loss: 0.1220
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 130.4286 s
agent0:                 episode reward: -0.7270,                 loss: nan
agent1:                 episode reward: 0.7270,                 loss: 0.1212
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 130.6727 s
agent0:                 episode reward: -0.7963,                 loss: nan
agent1:                 episode reward: 0.7963,                 loss: 0.1217
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2663s / 130.9389 s
agent0:                 episode reward: -0.6531,                 loss: nan
agent1:                 episode reward: 0.6531,                 loss: 0.1239
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2502s / 131.1891 s
agent0:                 episode reward: -0.3592,                 loss: nan
agent1:                 episode reward: 0.3592,                 loss: 0.1220
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2443s / 131.4334 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.1197
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 131.6740 s
agent0:                 episode reward: -0.5311,                 loss: nan
agent1:                 episode reward: 0.5311,                 loss: 0.1221
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 131.9190 s
agent0:                 episode reward: -0.5102,                 loss: nan
agent1:                 episode reward: 0.5102,                 loss: 0.1226
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2491s / 132.1681 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.1224
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 132.4166 s
agent0:                 episode reward: -0.7303,                 loss: nan
agent1:                 episode reward: 0.7303,                 loss: 0.1223
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2424s / 132.6590 s
agent0:                 episode reward: -0.5091,                 loss: nan
agent1:                 episode reward: 0.5091,                 loss: 0.1218
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2467s / 132.9057 s
agent0:                 episode reward: -0.5274,                 loss: nan
agent1:                 episode reward: 0.5274,                 loss: 0.1223
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2402s / 133.1459 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1230
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 133.3862 s
agent0:                 episode reward: -0.1633,                 loss: nan
agent1:                 episode reward: 0.1633,                 loss: 0.1212
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 133.6473 s
agent0:                 episode reward: -0.8717,                 loss: nan
agent1:                 episode reward: 0.8717,                 loss: 0.1217
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 133.9225 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.1221
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 134.1810 s
agent0:                 episode reward: -0.4547,                 loss: nan
agent1:                 episode reward: 0.4547,                 loss: 0.1217
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 134.4126 s
agent0:                 episode reward: -0.7373,                 loss: nan
agent1:                 episode reward: 0.7373,                 loss: 0.1205
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 134.6515 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.1227
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 134.8962 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.1219
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2384s / 135.1345 s
agent0:                 episode reward: -0.6162,                 loss: nan
agent1:                 episode reward: 0.6162,                 loss: 0.1221
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 135.3733 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.1224
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 135.6108 s
agent0:                 episode reward: -0.6412,                 loss: nan
agent1:                 episode reward: 0.6412,                 loss: 0.1218
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2391s / 135.8499 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1218
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 136.0948 s
agent0:                 episode reward: -0.4417,                 loss: nan
agent1:                 episode reward: 0.4417,                 loss: 0.1218
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 136.3349 s
agent0:                 episode reward: -0.4374,                 loss: nan
agent1:                 episode reward: 0.4374,                 loss: 0.1233
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 136.5780 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1226
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 136.8364 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.1205
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 137.1035 s
agent0:                 episode reward: -0.0013,                 loss: nan
agent1:                 episode reward: 0.0013,                 loss: 0.1225
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2476s / 137.3511 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.1206
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 137.6199 s
agent0:                 episode reward: -0.6460,                 loss: nan
agent1:                 episode reward: 0.6460,                 loss: 0.1209
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2556s / 137.8755 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.1219
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 138.1396 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.1205
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 138.4050 s
agent0:                 episode reward: -0.9096,                 loss: nan
agent1:                 episode reward: 0.9096,                 loss: 0.1224
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 138.6416 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.1208
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 138.8886 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.1204
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 139.1368 s
agent0:                 episode reward: -0.4846,                 loss: nan
agent1:                 episode reward: 0.4846,                 loss: 0.1205
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 139.3874 s
agent0:                 episode reward: -0.2650,                 loss: nan
agent1:                 episode reward: 0.2650,                 loss: 0.1211
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2434s / 139.6308 s
agent0:                 episode reward: -0.4681,                 loss: nan
agent1:                 episode reward: 0.4681,                 loss: 0.1209
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2811s / 139.9118 s
agent0:                 episode reward: -0.5904,                 loss: nan
agent1:                 episode reward: 0.5904,                 loss: 0.1224
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 140.1822 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.1204
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 140.4304 s
agent0:                 episode reward: -1.0008,                 loss: nan
agent1:                 episode reward: 1.0008,                 loss: 0.1199
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2458s / 140.6762 s
agent0:                 episode reward: -0.5017,                 loss: nan
agent1:                 episode reward: 0.5017,                 loss: 0.1215
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2479s / 140.9242 s
agent0:                 episode reward: -0.7021,                 loss: nan
agent1:                 episode reward: 0.7021,                 loss: 0.1208
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 141.1747 s
agent0:                 episode reward: -0.6734,                 loss: nan
agent1:                 episode reward: 0.6734,                 loss: 0.1215
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 141.4192 s
agent0:                 episode reward: -0.4600,                 loss: nan
agent1:                 episode reward: 0.4600,                 loss: 0.1224
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 141.6674 s
agent0:                 episode reward: -0.9208,                 loss: nan
agent1:                 episode reward: 0.9208,                 loss: 0.1224
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2457s / 141.9131 s
agent0:                 episode reward: -0.3411,                 loss: nan
agent1:                 episode reward: 0.3411,                 loss: 0.1233
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 142.1688 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.1232
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 142.4166 s
agent0:                 episode reward: -0.5626,                 loss: nan
agent1:                 episode reward: 0.5626,                 loss: 0.1223
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 142.6631 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.1233
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 142.9151 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.1247
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2825s / 143.1976 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.1223
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2560s / 143.4536 s
agent0:                 episode reward: -0.8932,                 loss: nan
agent1:                 episode reward: 0.8932,                 loss: 0.1221
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 143.7001 s
agent0:                 episode reward: -0.5995,                 loss: nan
agent1:                 episode reward: 0.5995,                 loss: 0.1239
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 143.9446 s
agent0:                 episode reward: -0.5686,                 loss: nan
agent1:                 episode reward: 0.5686,                 loss: 0.1232
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 144.1898 s
agent0:                 episode reward: -0.9661,                 loss: nan
agent1:                 episode reward: 0.9661,                 loss: 0.1234
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 144.4307 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.1212
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 144.6769 s
agent0:                 episode reward: -0.4044,                 loss: nan
agent1:                 episode reward: 0.4044,                 loss: 0.1258
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2495s / 144.9264 s
agent0:                 episode reward: -0.5129,                 loss: nan
agent1:                 episode reward: 0.5129,                 loss: 0.1228
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 145.1709 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.1220
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 145.4182 s
agent0:                 episode reward: -0.3055,                 loss: nan
agent1:                 episode reward: 0.3055,                 loss: 0.1219
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 145.6733 s
agent0:                 episode reward: -0.2089,                 loss: nan
agent1:                 episode reward: 0.2089,                 loss: 0.1204
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 145.9387 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.1200
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2646s / 146.2033 s
agent0:                 episode reward: -0.6648,                 loss: nan
agent1:                 episode reward: 0.6648,                 loss: 0.1200
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 146.4592 s
agent0:                 episode reward: -0.1853,                 loss: nan
agent1:                 episode reward: 0.1853,                 loss: 0.1208
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 146.6998 s
agent0:                 episode reward: -0.7278,                 loss: nan
agent1:                 episode reward: 0.7278,                 loss: 0.1211
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2454s / 146.9452 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1208
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 147.1976 s
agent0:                 episode reward: -0.4104,                 loss: nan
agent1:                 episode reward: 0.4104,                 loss: 0.1199
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 147.4472 s
agent0:                 episode reward: -0.4497,                 loss: nan
agent1:                 episode reward: 0.4497,                 loss: 0.1196
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2509s / 147.6981 s
agent0:                 episode reward: -0.9208,                 loss: nan
agent1:                 episode reward: 0.9208,                 loss: 0.1211
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 147.9516 s
agent0:                 episode reward: -0.6342,                 loss: nan
agent1:                 episode reward: 0.6342,                 loss: 0.1212
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 148.2019 s
agent0:                 episode reward: -0.5679,                 loss: nan
agent1:                 episode reward: 0.5679,                 loss: 0.1205
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 148.4529 s
agent0:                 episode reward: -0.5290,                 loss: nan
agent1:                 episode reward: 0.5290,                 loss: 0.1205
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 148.7083 s
agent0:                 episode reward: -0.3098,                 loss: nan
agent1:                 episode reward: 0.3098,                 loss: 0.1208
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 148.9640 s
agent0:                 episode reward: -0.6025,                 loss: nan
agent1:                 episode reward: 0.6025,                 loss: 0.1207
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 149.2456 s
agent0:                 episode reward: -0.3631,                 loss: nan
agent1:                 episode reward: 0.3631,                 loss: 0.1193
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 149.5075 s
agent0:                 episode reward: -0.9240,                 loss: nan
agent1:                 episode reward: 0.9240,                 loss: 0.1203
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 149.7622 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1214
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 150.0206 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: 0.1197
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 150.2793 s
agent0:                 episode reward: -0.4008,                 loss: nan
agent1:                 episode reward: 0.4008,                 loss: 0.1204
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 150.5505 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.1199
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2649s / 150.8155 s
agent0:                 episode reward: -0.4774,                 loss: nan
agent1:                 episode reward: 0.4774,                 loss: 0.1197
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2578s / 151.0733 s
agent0:                 episode reward: -0.1811,                 loss: nan
agent1:                 episode reward: 0.1811,                 loss: 0.1215
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 151.3247 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.1210
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 151.5799 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.1210
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 151.8218 s
agent0:                 episode reward: -0.3920,                 loss: nan
agent1:                 episode reward: 0.3920,                 loss: 0.1204
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2423s / 152.0641 s
agent0:                 episode reward: -0.5664,                 loss: nan
agent1:                 episode reward: 0.5664,                 loss: 0.1202
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 152.3436 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.1193
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 152.6021 s
agent0:                 episode reward: -0.1841,                 loss: nan
agent1:                 episode reward: 0.1841,                 loss: 0.1208
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2604s / 152.8625 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.1197
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 153.1208 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: 0.1217
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 153.3747 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.1209
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 153.6232 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.1207
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 153.8797 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.1204
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2544s / 154.1340 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.1208
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 154.4147 s
agent0:                 episode reward: -0.5430,                 loss: nan
agent1:                 episode reward: 0.5430,                 loss: 0.1191
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 154.6816 s
agent0:                 episode reward: -0.7332,                 loss: nan
agent1:                 episode reward: 0.7332,                 loss: 0.1210
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2558s / 154.9374 s
agent0:                 episode reward: -0.5024,                 loss: nan
agent1:                 episode reward: 0.5024,                 loss: 0.1191
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 155.2054 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.1196
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 155.4818 s
agent0:                 episode reward: -0.8422,                 loss: nan
agent1:                 episode reward: 0.8422,                 loss: 0.1202
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2575s / 155.7393 s
agent0:                 episode reward: -0.3776,                 loss: nan
agent1:                 episode reward: 0.3776,                 loss: 0.1204
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 155.9988 s
agent0:                 episode reward: -0.6837,                 loss: nan
agent1:                 episode reward: 0.6837,                 loss: 0.1196
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 156.2682 s
agent0:                 episode reward: -0.8921,                 loss: nan
agent1:                 episode reward: 0.8921,                 loss: 0.1189
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 156.5390 s
agent0:                 episode reward: -0.8413,                 loss: nan
agent1:                 episode reward: 0.8413,                 loss: 0.1180
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2710s / 156.8100 s
agent0:                 episode reward: -0.3627,                 loss: nan
agent1:                 episode reward: 0.3627,                 loss: 0.1180
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 157.0654 s
agent0:                 episode reward: -0.7935,                 loss: nan
agent1:                 episode reward: 0.7935,                 loss: 0.1213
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 157.3173 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.1181
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 157.5738 s
agent0:                 episode reward: -0.6113,                 loss: nan
agent1:                 episode reward: 0.6113,                 loss: 0.1202
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 157.8391 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: 0.1211
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 158.0972 s
agent0:                 episode reward: -0.4397,                 loss: nan
agent1:                 episode reward: 0.4397,                 loss: 0.1209
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 158.3751 s
agent0:                 episode reward: -0.9541,                 loss: nan
agent1:                 episode reward: 0.9541,                 loss: 0.1194
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 158.6472 s
agent0:                 episode reward: -0.9084,                 loss: nan
agent1:                 episode reward: 0.9084,                 loss: 0.1180
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 158.9071 s
agent0:                 episode reward: -0.6021,                 loss: nan
agent1:                 episode reward: 0.6021,                 loss: 0.1203
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 159.1633 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.1188
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 159.4211 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.1189
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 159.6799 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.1201
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 159.9365 s
agent0:                 episode reward: -0.5911,                 loss: nan
agent1:                 episode reward: 0.5911,                 loss: 0.1206
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 160.1915 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1199
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 160.4476 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.1200
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 160.7083 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.1204
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 160.9568 s
agent0:                 episode reward: -0.7619,                 loss: nan
agent1:                 episode reward: 0.7619,                 loss: 0.1198
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 161.2051 s
agent0:                 episode reward: -0.4353,                 loss: nan
agent1:                 episode reward: 0.4353,                 loss: 0.1207
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 161.4764 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1206
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 161.7404 s
agent0:                 episode reward: -0.3636,                 loss: nan
agent1:                 episode reward: 0.3636,                 loss: 0.1190
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2477s / 161.9881 s
agent0:                 episode reward: -0.7530,                 loss: nan
agent1:                 episode reward: 0.7530,                 loss: 0.1183
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 162.2401 s
agent0:                 episode reward: -0.6122,                 loss: nan
agent1:                 episode reward: 0.6122,                 loss: 0.1197
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 162.4915 s
agent0:                 episode reward: -0.6038,                 loss: nan
agent1:                 episode reward: 0.6038,                 loss: 0.1207
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 162.7659 s
agent0:                 episode reward: -0.4329,                 loss: nan
agent1:                 episode reward: 0.4329,                 loss: 0.1193
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 163.0169 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.1207
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2888s / 163.3057 s
agent0:                 episode reward: -0.5610,                 loss: nan
agent1:                 episode reward: 0.5610,                 loss: 0.1201
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 163.5496 s
agent0:                 episode reward: -0.4522,                 loss: nan
agent1:                 episode reward: 0.4522,                 loss: 0.1194
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 163.7948 s
agent0:                 episode reward: -0.3069,                 loss: nan
agent1:                 episode reward: 0.3069,                 loss: 0.1196
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 164.0379 s
agent0:                 episode reward: -0.5241,                 loss: nan
agent1:                 episode reward: 0.5241,                 loss: 0.1197
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2471s / 164.2850 s
agent0:                 episode reward: -0.8312,                 loss: nan
agent1:                 episode reward: 0.8312,                 loss: 0.1194
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 164.5616 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.1195
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 164.8210 s
agent0:                 episode reward: -0.5885,                 loss: nan
agent1:                 episode reward: 0.5885,                 loss: 0.1181
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 165.0724 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: 0.1200
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2537s / 165.3261 s
agent0:                 episode reward: -0.5737,                 loss: nan
agent1:                 episode reward: 0.5737,                 loss: 0.1186
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2549s / 165.5809 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.1198
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 165.8406 s
agent0:                 episode reward: -0.6652,                 loss: nan
agent1:                 episode reward: 0.6652,                 loss: 0.1181
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 166.0957 s
agent0:                 episode reward: -0.4852,                 loss: nan
agent1:                 episode reward: 0.4852,                 loss: 0.1205
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2558s / 166.3515 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.1182
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 166.6095 s
agent0:                 episode reward: -0.7140,                 loss: nan
agent1:                 episode reward: 0.7140,                 loss: 0.1193
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 166.8747 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: 0.1196
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2636s / 167.1383 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: 0.1207
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 167.4044 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.1181
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3006s / 167.7050 s
agent0:                 episode reward: -0.8299,                 loss: nan
agent1:                 episode reward: 0.8299,                 loss: 0.1189
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 167.9859 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1184
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 168.2477 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.1186
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 168.5010 s
agent0:                 episode reward: -0.2371,                 loss: nan
agent1:                 episode reward: 0.2371,                 loss: 0.1191
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2617s / 168.7627 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.1198
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 169.0225 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.1180
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 169.2782 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.1202
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 169.5358 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.1191
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 169.7932 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.1185
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 170.0538 s
agent0:                 episode reward: -0.5610,                 loss: nan
agent1:                 episode reward: 0.5610,                 loss: 0.1204
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 170.3127 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1186
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 170.5927 s
agent0:                 episode reward: -0.8426,                 loss: nan
agent1:                 episode reward: 0.8426,                 loss: 0.1187
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 170.9037 s
agent0:                 episode reward: -0.7253,                 loss: nan
agent1:                 episode reward: 0.7253,                 loss: 0.1194
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 171.1701 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.1202
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 171.4404 s
agent0:                 episode reward: -1.0934,                 loss: nan
agent1:                 episode reward: 1.0934,                 loss: 0.1194
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 171.7108 s
agent0:                 episode reward: -0.7950,                 loss: nan
agent1:                 episode reward: 0.7950,                 loss: 0.1199
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 171.9692 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.1185
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 172.2393 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.1181
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 172.5108 s
agent0:                 episode reward: -0.8731,                 loss: nan
agent1:                 episode reward: 0.8731,                 loss: 0.1193
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 172.7895 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.1194
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2677s / 173.0572 s
agent0:                 episode reward: -0.9927,                 loss: nan
agent1:                 episode reward: 0.9927,                 loss: 0.1186
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 173.3202 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.1168
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 173.5999 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: 0.1198
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2800s / 173.8799 s
agent0:                 episode reward: -0.1768,                 loss: nan
agent1:                 episode reward: 0.1768,                 loss: 0.1175
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 174.1433 s
agent0:                 episode reward: -0.7756,                 loss: nan
agent1:                 episode reward: 0.7756,                 loss: 0.1184
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2663s / 174.4097 s
agent0:                 episode reward: -0.6058,                 loss: nan
agent1:                 episode reward: 0.6058,                 loss: 0.1194
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 174.6649 s
agent0:                 episode reward: -0.7485,                 loss: nan
agent1:                 episode reward: 0.7485,                 loss: 0.1185
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 174.9245 s
agent0:                 episode reward: 0.0437,                 loss: nan
agent1:                 episode reward: -0.0437,                 loss: 0.1167
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 175.1813 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1192
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 175.4392 s
agent0:                 episode reward: -0.9416,                 loss: nan
agent1:                 episode reward: 0.9416,                 loss: 0.1173
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 175.6984 s
agent0:                 episode reward: -0.7083,                 loss: nan
agent1:                 episode reward: 0.7083,                 loss: 0.1194
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2616s / 175.9600 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.1196
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 176.2207 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1185
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 176.4799 s
agent0:                 episode reward: -0.8538,                 loss: nan
agent1:                 episode reward: 0.8538,                 loss: 0.1196
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 176.7556 s
agent0:                 episode reward: -0.8070,                 loss: nan
agent1:                 episode reward: 0.8070,                 loss: 0.1186
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 177.0429 s
agent0:                 episode reward: -0.3285,                 loss: nan
agent1:                 episode reward: 0.3285,                 loss: 0.1176
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 177.3026 s
agent0:                 episode reward: -0.5446,                 loss: nan
agent1:                 episode reward: 0.5446,                 loss: 0.1179
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 177.5638 s
agent0:                 episode reward: -0.9152,                 loss: nan
agent1:                 episode reward: 0.9152,                 loss: 0.1202
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 177.8260 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.1175
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2682s / 178.0943 s
agent0:                 episode reward: -0.4576,                 loss: nan
agent1:                 episode reward: 0.4576,                 loss: 0.1190
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 178.3609 s
agent0:                 episode reward: -0.8339,                 loss: nan
agent1:                 episode reward: 0.8339,                 loss: 0.1177
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 178.6336 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.1177
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2637s / 178.8973 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: 0.1186
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 179.1627 s
agent0:                 episode reward: -0.6122,                 loss: nan
agent1:                 episode reward: 0.6122,                 loss: 0.1173
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 179.4507 s
agent0:                 episode reward: -0.3061,                 loss: nan
agent1:                 episode reward: 0.3061,                 loss: 0.1178
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 179.7162 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.1189
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 179.9802 s
agent0:                 episode reward: -0.8234,                 loss: nan
agent1:                 episode reward: 0.8234,                 loss: 0.1174
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 180.2426 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.1188
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 180.5095 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.1183
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2699s / 180.7794 s
agent0:                 episode reward: -0.7807,                 loss: nan
agent1:                 episode reward: 0.7807,                 loss: 0.1191
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 181.0472 s
agent0:                 episode reward: -0.8157,                 loss: nan
agent1:                 episode reward: 0.8157,                 loss: 0.1204
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 181.3126 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: 0.1184
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 181.5814 s
agent0:                 episode reward: -0.4629,                 loss: nan
agent1:                 episode reward: 0.4629,                 loss: 0.1189
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 181.8458 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.1193
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 182.1098 s
agent0:                 episode reward: -0.2554,                 loss: nan
agent1:                 episode reward: 0.2554,                 loss: 0.1195
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2705s / 182.3803 s
agent0:                 episode reward: -0.3834,                 loss: nan
agent1:                 episode reward: 0.3834,                 loss: 0.1180
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 182.6671 s
agent0:                 episode reward: -0.9247,                 loss: nan
agent1:                 episode reward: 0.9247,                 loss: 0.1195
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2586s / 182.9257 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.1177
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 183.1817 s
agent0:                 episode reward: -0.6412,                 loss: nan
agent1:                 episode reward: 0.6412,                 loss: 0.1185
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 183.4381 s
agent0:                 episode reward: -0.5549,                 loss: nan
agent1:                 episode reward: 0.5549,                 loss: 0.1172
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 183.6962 s
agent0:                 episode reward: -0.1857,                 loss: nan
agent1:                 episode reward: 0.1857,                 loss: 0.1177
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 183.9590 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.1186
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2616s / 184.2206 s
agent0:                 episode reward: -0.7341,                 loss: nan
agent1:                 episode reward: 0.7341,                 loss: 0.1190
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2553s / 184.4759 s
agent0:                 episode reward: -0.5703,                 loss: nan
agent1:                 episode reward: 0.5703,                 loss: 0.1185
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2591s / 184.7350 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.1176
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2698s / 185.0048 s
agent0:                 episode reward: -0.3758,                 loss: nan
agent1:                 episode reward: 0.3758,                 loss: 0.1177
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 185.2769 s
agent0:                 episode reward: -0.6012,                 loss: nan
agent1:                 episode reward: 0.6012,                 loss: 0.1178
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 185.5586 s
agent0:                 episode reward: -0.6195,                 loss: nan
agent1:                 episode reward: 0.6195,                 loss: 0.1166
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 185.8564 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.1174
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 186.1290 s
agent0:                 episode reward: -0.8110,                 loss: nan
agent1:                 episode reward: 0.8110,                 loss: 0.1182
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 186.3916 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.1173
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 186.6561 s
agent0:                 episode reward: -0.4939,                 loss: nan
agent1:                 episode reward: 0.4939,                 loss: 0.1186
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 186.9193 s
agent0:                 episode reward: -0.6436,                 loss: nan
agent1:                 episode reward: 0.6436,                 loss: 0.1163
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 187.1851 s
agent0:                 episode reward: -0.3733,                 loss: nan
agent1:                 episode reward: 0.3733,                 loss: 0.1177
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 187.4513 s
agent0:                 episode reward: -0.6019,                 loss: nan
agent1:                 episode reward: 0.6019,                 loss: 0.1169
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 187.7409 s
agent0:                 episode reward: -0.6857,                 loss: nan
agent1:                 episode reward: 0.6857,                 loss: 0.1189
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 188.0120 s
agent0:                 episode reward: -0.4718,                 loss: nan
agent1:                 episode reward: 0.4718,                 loss: 0.1176
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 188.2898 s
agent0:                 episode reward: -0.2903,                 loss: nan
agent1:                 episode reward: 0.2903,                 loss: 0.1174
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 188.5676 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.1169
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3003s / 188.8679 s
agent0:                 episode reward: -0.9890,                 loss: nan
agent1:                 episode reward: 0.9890,                 loss: 0.1166
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2770s / 189.1449 s
agent0:                 episode reward: -0.6139,                 loss: nan
agent1:                 episode reward: 0.6139,                 loss: 0.1146
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 189.4171 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.1170
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2759s / 189.6929 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.1161
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2623s / 189.9552 s
agent0:                 episode reward: -0.5806,                 loss: nan
agent1:                 episode reward: 0.5806,                 loss: 0.1159
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 190.2106 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.1158
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 190.4827 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.1162
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2738s / 190.7565 s
agent0:                 episode reward: -0.9340,                 loss: nan
agent1:                 episode reward: 0.9340,                 loss: 0.1161
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 191.0289 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.1174
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 191.2955 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.1167
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 191.5695 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.1146
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 191.8819 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.1160
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 192.1634 s
agent0:                 episode reward: -0.8032,                 loss: nan
agent1:                 episode reward: 0.8032,                 loss: 0.1167
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2768s / 192.4402 s
agent0:                 episode reward: -0.8364,                 loss: nan
agent1:                 episode reward: 0.8364,                 loss: 0.1136
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 192.7164 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.1154
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2723s / 192.9886 s
agent0:                 episode reward: -0.4240,                 loss: nan
agent1:                 episode reward: 0.4240,                 loss: 0.1140
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2695s / 193.2581 s
agent0:                 episode reward: -0.5106,                 loss: nan
agent1:                 episode reward: 0.5106,                 loss: 0.1166
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 193.5209 s
agent0:                 episode reward: -0.4246,                 loss: nan
agent1:                 episode reward: 0.4246,                 loss: 0.1155
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 193.7865 s
agent0:                 episode reward: -0.6277,                 loss: nan
agent1:                 episode reward: 0.6277,                 loss: 0.1153
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2571s / 194.0437 s
agent0:                 episode reward: -0.6363,                 loss: nan
agent1:                 episode reward: 0.6363,                 loss: 0.1177
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2553s / 194.2989 s
agent0:                 episode reward: -0.2428,                 loss: nan
agent1:                 episode reward: 0.2428,                 loss: 0.1174
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 194.5553 s
agent0:                 episode reward: -0.6979,                 loss: nan
agent1:                 episode reward: 0.6979,                 loss: 0.1179
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2804s / 194.8358 s
agent0:                 episode reward: -0.5757,                 loss: nan
agent1:                 episode reward: 0.5757,                 loss: 0.1194
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2697s / 195.1054 s
agent0:                 episode reward: -0.9357,                 loss: nan
agent1:                 episode reward: 0.9357,                 loss: 0.1182
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 195.3755 s
agent0:                 episode reward: -0.6206,                 loss: nan
agent1:                 episode reward: 0.6206,                 loss: 0.1178
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 195.6512 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.1175
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2823s / 195.9335 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1169
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 196.2142 s
agent0:                 episode reward: -0.4727,                 loss: nan
agent1:                 episode reward: 0.4727,                 loss: 0.1177
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 196.4961 s
agent0:                 episode reward: -0.7205,                 loss: nan
agent1:                 episode reward: 0.7205,                 loss: 0.1169
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2878s / 196.7838 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.1174
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 197.0549 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.1161
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 197.3381 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.1174
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 197.6031 s
agent0:                 episode reward: -0.6590,                 loss: nan
agent1:                 episode reward: 0.6590,                 loss: 0.1204
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 197.8891 s
agent0:                 episode reward: -0.5212,                 loss: nan
agent1:                 episode reward: 0.5212,                 loss: 0.1166
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2874s / 198.1764 s
agent0:                 episode reward: -0.7915,                 loss: nan
agent1:                 episode reward: 0.7915,                 loss: 0.1173
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2737s / 198.4501 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.1168
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2663s / 198.7164 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1167
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 198.9865 s
agent0:                 episode reward: -0.7781,                 loss: nan
agent1:                 episode reward: 0.7781,                 loss: 0.1177
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 199.2604 s
agent0:                 episode reward: -0.4753,                 loss: nan
agent1:                 episode reward: 0.4753,                 loss: 0.1160
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 199.5305 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.1166
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 199.8006 s
agent0:                 episode reward: -0.5323,                 loss: nan
agent1:                 episode reward: 0.5323,                 loss: 0.1169
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 200.0713 s
agent0:                 episode reward: -0.4661,                 loss: nan
agent1:                 episode reward: 0.4661,                 loss: 0.1176
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 200.3434 s
agent0:                 episode reward: -0.5330,                 loss: nan
agent1:                 episode reward: 0.5330,                 loss: 0.1160
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2699s / 200.6133 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.1173
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 200.8987 s
agent0:                 episode reward: -0.8807,                 loss: nan
agent1:                 episode reward: 0.8807,                 loss: 0.1171
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 201.1914 s
agent0:                 episode reward: -0.2934,                 loss: nan
agent1:                 episode reward: 0.2934,                 loss: 0.1183
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2710s / 201.4624 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1165
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 201.7381 s
agent0:                 episode reward: -0.7644,                 loss: nan
agent1:                 episode reward: 0.7644,                 loss: 0.1170
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 202.0193 s
agent0:                 episode reward: -0.8863,                 loss: nan
agent1:                 episode reward: 0.8863,                 loss: 0.1168
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 202.2985 s
agent0:                 episode reward: -0.7284,                 loss: nan
agent1:                 episode reward: 0.7284,                 loss: 0.1163
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2825s / 202.5810 s
agent0:                 episode reward: -0.3144,                 loss: nan
agent1:                 episode reward: 0.3144,                 loss: 0.1165
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2815s / 202.8625 s
agent0:                 episode reward: -0.8539,                 loss: nan
agent1:                 episode reward: 0.8539,                 loss: 0.1167
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 203.1433 s
agent0:                 episode reward: -0.5176,                 loss: nan
agent1:                 episode reward: 0.5176,                 loss: 0.1158
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2787s / 203.4221 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.1181
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 203.7029 s
agent0:                 episode reward: -0.6371,                 loss: nan
agent1:                 episode reward: 0.6371,                 loss: 0.1133
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 203.9983 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: 0.1157
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 204.3021 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.1156
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 204.5813 s
agent0:                 episode reward: -0.7847,                 loss: nan
agent1:                 episode reward: 0.7847,                 loss: 0.1158
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 204.8646 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1160
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 205.1481 s
agent0:                 episode reward: -0.8772,                 loss: nan
agent1:                 episode reward: 0.8772,                 loss: 0.1165
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 205.4312 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.1160
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2930s / 205.7242 s
agent0:                 episode reward: -0.4011,                 loss: nan
agent1:                 episode reward: 0.4011,                 loss: 0.1162
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 206.0147 s
agent0:                 episode reward: -0.7568,                 loss: nan
agent1:                 episode reward: 0.7568,                 loss: 0.1155
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 206.2975 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.1165
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 206.5869 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.1155
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 206.8701 s
agent0:                 episode reward: -0.9329,                 loss: nan
agent1:                 episode reward: 0.9329,                 loss: 0.1144
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 207.1594 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.1169
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 207.4461 s
agent0:                 episode reward: -0.9659,                 loss: nan
agent1:                 episode reward: 0.9659,                 loss: 0.1146
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 207.7255 s
agent0:                 episode reward: -0.6260,                 loss: nan
agent1:                 episode reward: 0.6260,                 loss: 0.1167
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 208.0041 s
agent0:                 episode reward: -0.7624,                 loss: nan
agent1:                 episode reward: 0.7624,                 loss: 0.1169
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 208.2756 s
agent0:                 episode reward: -0.5534,                 loss: nan
agent1:                 episode reward: 0.5534,                 loss: 0.1172
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 208.5571 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.1153
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 208.8323 s
agent0:                 episode reward: -0.5047,                 loss: nan
agent1:                 episode reward: 0.5047,                 loss: 0.1145
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 209.1056 s
agent0:                 episode reward: -1.0480,                 loss: nan
agent1:                 episode reward: 1.0480,                 loss: 0.1160
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 209.3792 s
agent0:                 episode reward: -0.6494,                 loss: nan
agent1:                 episode reward: 0.6494,                 loss: 0.1162
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 209.6564 s
agent0:                 episode reward: -0.6026,                 loss: nan
agent1:                 episode reward: 0.6026,                 loss: 0.1174
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 209.9594 s
agent0:                 episode reward: -0.7913,                 loss: nan
agent1:                 episode reward: 0.7913,                 loss: 0.1158
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 210.2370 s
agent0:                 episode reward: -0.1195,                 loss: nan
agent1:                 episode reward: 0.1195,                 loss: 0.1174
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 210.5135 s
agent0:                 episode reward: -0.9229,                 loss: nan
agent1:                 episode reward: 0.9229,                 loss: 0.1152
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2804s / 210.7939 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.1149
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 211.0727 s
agent0:                 episode reward: -0.4854,                 loss: nan
agent1:                 episode reward: 0.4854,                 loss: 0.1160
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 211.3554 s
agent0:                 episode reward: -0.7727,                 loss: nan
agent1:                 episode reward: 0.7727,                 loss: 0.1168
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2845s / 211.6399 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.1160
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2763s / 211.9163 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.1156
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 212.2025 s
agent0:                 episode reward: -0.5990,                 loss: nan
agent1:                 episode reward: 0.5990,                 loss: 0.1163
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 212.4827 s
agent0:                 episode reward: -0.5544,                 loss: nan
agent1:                 episode reward: 0.5544,                 loss: 0.1153
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3076s / 212.7903 s
agent0:                 episode reward: -0.9333,                 loss: nan
agent1:                 episode reward: 0.9333,                 loss: 0.1173
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 213.1174 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.1163
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 213.3962 s
agent0:                 episode reward: -0.4712,                 loss: nan
agent1:                 episode reward: 0.4712,                 loss: 0.1176
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 213.6765 s
agent0:                 episode reward: -0.8943,                 loss: nan
agent1:                 episode reward: 0.8943,                 loss: 0.1176
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 213.9602 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1168
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 214.2436 s
agent0:                 episode reward: -0.5666,                 loss: nan
agent1:                 episode reward: 0.5666,                 loss: 0.1167
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2826s / 214.5261 s
agent0:                 episode reward: -0.6911,                 loss: nan
agent1:                 episode reward: 0.6911,                 loss: 0.1182
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 214.8066 s
agent0:                 episode reward: -0.4068,                 loss: nan
agent1:                 episode reward: 0.4068,                 loss: 0.1170
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 215.0869 s
agent0:                 episode reward: -0.8173,                 loss: nan
agent1:                 episode reward: 0.8173,                 loss: 0.1182
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2821s / 215.3690 s
agent0:                 episode reward: -0.9999,                 loss: nan
agent1:                 episode reward: 0.9999,                 loss: 0.1162
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 215.6581 s
agent0:                 episode reward: -0.8446,                 loss: nan
agent1:                 episode reward: 0.8446,                 loss: 0.1173
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 215.9656 s
agent0:                 episode reward: -0.6415,                 loss: nan
agent1:                 episode reward: 0.6415,                 loss: 0.1185
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 216.2556 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.1167
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 216.5395 s
agent0:                 episode reward: -0.6913,                 loss: nan
agent1:                 episode reward: 0.6913,                 loss: 0.1180
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2793s / 216.8187 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.1160
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2845s / 217.1033 s
agent0:                 episode reward: -0.5809,                 loss: nan
agent1:                 episode reward: 0.5809,                 loss: 0.1167
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 217.3831 s
agent0:                 episode reward: -0.7161,                 loss: nan
agent1:                 episode reward: 0.7161,                 loss: 0.1169
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 217.6623 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.1143
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 217.9491 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.1152
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 218.2394 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.1169
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2850s / 218.5245 s
agent0:                 episode reward: -0.9813,                 loss: nan
agent1:                 episode reward: 0.9813,                 loss: 0.1165
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 218.8084 s
agent0:                 episode reward: -0.9072,                 loss: nan
agent1:                 episode reward: 0.9072,                 loss: 0.1166
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3049s / 219.1133 s
agent0:                 episode reward: -0.8110,                 loss: nan
agent1:                 episode reward: 0.8110,                 loss: 0.1161
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 219.4096 s
agent0:                 episode reward: -0.7295,                 loss: nan
agent1:                 episode reward: 0.7295,                 loss: 0.1161
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 219.6996 s
agent0:                 episode reward: -0.8664,                 loss: nan
agent1:                 episode reward: 0.8664,                 loss: 0.1140
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 219.9868 s
agent0:                 episode reward: -0.4798,                 loss: nan
agent1:                 episode reward: 0.4798,                 loss: 0.1163
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 220.3219 s
agent0:                 episode reward: -0.8065,                 loss: nan
agent1:                 episode reward: 0.8065,                 loss: 0.1138
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 220.6050 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.1131
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2885s / 220.8935 s
agent0:                 episode reward: -0.9735,                 loss: nan
agent1:                 episode reward: 0.9735,                 loss: 0.1148
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 221.1930 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1165
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 221.4743 s
agent0:                 episode reward: -0.6597,                 loss: nan
agent1:                 episode reward: 0.6597,                 loss: 0.1154
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 221.7602 s
agent0:                 episode reward: -0.6984,                 loss: nan
agent1:                 episode reward: 0.6984,                 loss: 0.1145
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2976s / 222.0578 s
agent0:                 episode reward: -1.0596,                 loss: nan
agent1:                 episode reward: 1.0596,                 loss: 0.1147
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 222.3742 s
agent0:                 episode reward: -0.5296,                 loss: nan
agent1:                 episode reward: 0.5296,                 loss: 0.1153
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2882s / 222.6624 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.1134
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2875s / 222.9499 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.1142
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 223.2365 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.1134
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 223.5272 s
agent0:                 episode reward: -0.6483,                 loss: nan
agent1:                 episode reward: 0.6483,                 loss: 0.1133
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 223.8165 s
agent0:                 episode reward: -0.7507,                 loss: nan
agent1:                 episode reward: 0.7507,                 loss: 0.1146
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 224.0955 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.1151
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2804s / 224.3760 s
agent0:                 episode reward: -0.5354,                 loss: nan
agent1:                 episode reward: 0.5354,                 loss: 0.1156
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 224.6577 s
agent0:                 episode reward: -1.0862,                 loss: nan
agent1:                 episode reward: 1.0862,                 loss: 0.1153
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2815s / 224.9392 s
agent0:                 episode reward: -0.5350,                 loss: nan
agent1:                 episode reward: 0.5350,                 loss: 0.1150
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 225.2437 s
agent0:                 episode reward: -0.7836,                 loss: nan
agent1:                 episode reward: 0.7836,                 loss: 0.1142
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 225.5342 s
agent0:                 episode reward: -1.0755,                 loss: nan
agent1:                 episode reward: 1.0755,                 loss: 0.1156
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2838s / 225.8180 s
agent0:                 episode reward: -0.3296,                 loss: nan
agent1:                 episode reward: 0.3296,                 loss: 0.1135
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2777s / 226.0957 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.1145
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2781s / 226.3738 s
agent0:                 episode reward: -0.9068,                 loss: nan
agent1:                 episode reward: 0.9068,                 loss: 0.1147
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 226.6630 s
agent0:                 episode reward: -0.4641,                 loss: nan
agent1:                 episode reward: 0.4641,                 loss: 0.1136
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 226.9530 s
agent0:                 episode reward: -0.5465,                 loss: nan
agent1:                 episode reward: 0.5465,                 loss: 0.1160
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 227.2437 s
agent0:                 episode reward: -0.4343,                 loss: nan
agent1:                 episode reward: 0.4343,                 loss: 0.1155
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2914s / 227.5351 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: 0.1141
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 227.8339 s
agent0:                 episode reward: -0.9931,                 loss: nan
agent1:                 episode reward: 0.9931,                 loss: 0.1144
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2980s / 228.1320 s
agent0:                 episode reward: -0.6649,                 loss: nan
agent1:                 episode reward: 0.6649,                 loss: 0.1153
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 228.4472 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.1154
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2919s / 228.7391 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.1149
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 229.0284 s
agent0:                 episode reward: -0.5864,                 loss: nan
agent1:                 episode reward: 0.5864,                 loss: 0.1166
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 229.3310 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1128
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 229.6164 s
agent0:                 episode reward: -0.6925,                 loss: nan
agent1:                 episode reward: 0.6925,                 loss: 0.1151
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 229.9114 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.1147
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 230.2097 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.1133
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 230.5074 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.1153
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 230.8028 s
agent0:                 episode reward: -0.6909,                 loss: nan
agent1:                 episode reward: 0.6909,                 loss: 0.1161
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 231.0962 s
agent0:                 episode reward: -0.6522,                 loss: nan
agent1:                 episode reward: 0.6522,                 loss: 0.1136
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 231.4276 s
agent0:                 episode reward: -0.6769,                 loss: nan
agent1:                 episode reward: 0.6769,                 loss: 0.1142
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3021s / 231.7297 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.1159
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 232.0229 s
agent0:                 episode reward: -0.3792,                 loss: nan
agent1:                 episode reward: 0.3792,                 loss: 0.1156
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2966s / 232.3196 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.1176
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 232.6171 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.1147
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 232.9047 s
agent0:                 episode reward: -0.4129,                 loss: nan
agent1:                 episode reward: 0.4129,                 loss: 0.1142
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2841s / 233.1888 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.1177
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2865s / 233.4753 s
agent0:                 episode reward: -0.9265,                 loss: nan
agent1:                 episode reward: 0.9265,                 loss: 0.1169
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2928s / 233.7682 s
agent0:                 episode reward: -0.6394,                 loss: nan
agent1:                 episode reward: 0.6394,                 loss: 0.1141
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2969s / 234.0651 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.1149
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3153s / 234.3804 s
agent0:                 episode reward: -0.7006,                 loss: nan
agent1:                 episode reward: 0.7006,                 loss: 0.1153
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2960s / 234.6764 s
agent0:                 episode reward: -0.4708,                 loss: nan
agent1:                 episode reward: 0.4708,                 loss: 0.1156
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 234.9767 s
agent0:                 episode reward: -0.6352,                 loss: nan
agent1:                 episode reward: 0.6352,                 loss: 0.1150
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 235.2643 s
agent0:                 episode reward: -0.8365,                 loss: nan
agent1:                 episode reward: 0.8365,                 loss: 0.1161
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 235.5562 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.1151
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 235.8456 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1152
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 236.1351 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.1150
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 236.4193 s
agent0:                 episode reward: -0.6473,                 loss: nan
agent1:                 episode reward: 0.6473,                 loss: 0.1146
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 236.7065 s
agent0:                 episode reward: -0.6720,                 loss: nan
agent1:                 episode reward: 0.6720,                 loss: 0.1148
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 236.9905 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: 0.1140
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 237.2825 s
agent0:                 episode reward: -0.5481,                 loss: nan
agent1:                 episode reward: 0.5481,                 loss: 0.1153
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3218s / 237.6042 s
agent0:                 episode reward: -0.8047,                 loss: nan
agent1:                 episode reward: 0.8047,                 loss: 0.1139
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2991s / 237.9034 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.1156
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 238.1973 s
agent0:                 episode reward: -0.6423,                 loss: nan
agent1:                 episode reward: 0.6423,                 loss: 0.1168
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 238.4809 s
agent0:                 episode reward: -0.9591,                 loss: nan
agent1:                 episode reward: 0.9591,                 loss: 0.1135
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 238.7585 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.1176
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 239.0421 s
agent0:                 episode reward: -0.8293,                 loss: nan
agent1:                 episode reward: 0.8293,                 loss: 0.1145
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2864s / 239.3284 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.1158
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 239.6126 s
agent0:                 episode reward: -0.5956,                 loss: nan
agent1:                 episode reward: 0.5956,                 loss: 0.1149
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 239.8985 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.1143
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 240.1813 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.1141
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 240.4858 s
agent0:                 episode reward: -0.5724,                 loss: nan
agent1:                 episode reward: 0.5724,                 loss: 0.1161
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 240.7822 s
agent0:                 episode reward: -0.5161,                 loss: nan
agent1:                 episode reward: 0.5161,                 loss: 0.1140
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 241.0586 s
agent0:                 episode reward: -0.5511,                 loss: nan
agent1:                 episode reward: 0.5511,                 loss: 0.1155
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 241.3423 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.1149
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 241.6189 s
agent0:                 episode reward: -0.4928,                 loss: nan
agent1:                 episode reward: 0.4928,                 loss: 0.1153
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 241.8983 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.1145
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 242.1795 s
agent0:                 episode reward: -0.4627,                 loss: nan
agent1:                 episode reward: 0.4627,                 loss: 0.1144
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 242.4609 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.1138
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 242.7436 s
agent0:                 episode reward: -0.8571,                 loss: nan
agent1:                 episode reward: 0.8571,                 loss: 0.1142
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2796s / 243.0232 s
agent0:                 episode reward: -0.7893,                 loss: nan
agent1:                 episode reward: 0.7893,                 loss: 0.1138
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 243.3182 s
agent0:                 episode reward: -0.6965,                 loss: nan
agent1:                 episode reward: 0.6965,                 loss: 0.1143
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 243.6251 s
agent0:                 episode reward: -1.1211,                 loss: nan
agent1:                 episode reward: 1.1211,                 loss: 0.1132
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2919s / 243.9170 s
agent0:                 episode reward: -0.7013,                 loss: nan
agent1:                 episode reward: 0.7013,                 loss: 0.1146
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2961s / 244.2130 s
agent0:                 episode reward: -0.5050,                 loss: nan
agent1:                 episode reward: 0.5050,                 loss: 0.1134
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 244.5073 s
agent0:                 episode reward: -0.1918,                 loss: nan
agent1:                 episode reward: 0.1918,                 loss: 0.1132
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 244.7986 s
agent0:                 episode reward: -0.4689,                 loss: nan
agent1:                 episode reward: 0.4689,                 loss: 0.1149
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 245.0891 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.1155
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 245.3831 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.1148
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 245.6734 s
agent0:                 episode reward: -1.0748,                 loss: nan
agent1:                 episode reward: 1.0748,                 loss: 0.1144
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 245.9760 s
agent0:                 episode reward: -1.0160,                 loss: nan
agent1:                 episode reward: 1.0160,                 loss: 0.1156
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 246.2739 s
agent0:                 episode reward: -0.7802,                 loss: nan
agent1:                 episode reward: 0.7802,                 loss: 0.1150
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 246.5775 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.1139
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 246.8819 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: 0.1149
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 247.1713 s
agent0:                 episode reward: -0.6339,                 loss: nan
agent1:                 episode reward: 0.6339,                 loss: 0.1137
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2957s / 247.4670 s
agent0:                 episode reward: -0.4827,                 loss: nan
agent1:                 episode reward: 0.4827,                 loss: 0.1142
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 247.7703 s
agent0:                 episode reward: -0.7787,                 loss: nan
agent1:                 episode reward: 0.7787,                 loss: 0.1139
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 248.0737 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: 0.1132
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 248.3737 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.1125
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 248.6734 s
agent0:                 episode reward: -0.8295,                 loss: nan
agent1:                 episode reward: 0.8295,                 loss: 0.1130
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 248.9561 s
agent0:                 episode reward: -0.6935,                 loss: nan
agent1:                 episode reward: 0.6935,                 loss: 0.1143
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2843s / 249.2403 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.1127
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 249.5277 s
agent0:                 episode reward: -0.4738,                 loss: nan
agent1:                 episode reward: 0.4738,                 loss: 0.1137
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 249.8471 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.1122
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 250.1300 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.1142
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 250.4186 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.1139
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2990s / 250.7176 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.1142
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 251.0155 s
agent0:                 episode reward: -0.7955,                 loss: nan
agent1:                 episode reward: 0.7955,                 loss: 0.1141
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 251.3152 s
agent0:                 episode reward: -0.4837,                 loss: nan
agent1:                 episode reward: 0.4837,                 loss: 0.1135
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 251.6102 s
agent0:                 episode reward: -0.5491,                 loss: nan
agent1:                 episode reward: 0.5491,                 loss: 0.1134
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 251.9104 s
agent0:                 episode reward: -0.7792,                 loss: nan
agent1:                 episode reward: 0.7792,                 loss: 0.1147
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 252.2149 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.1146
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 252.5145 s
agent0:                 episode reward: -0.6743,                 loss: nan
agent1:                 episode reward: 0.6743,                 loss: 0.1128
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 252.8176 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.1139
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 253.1180 s
agent0:                 episode reward: -0.8337,                 loss: nan
agent1:                 episode reward: 0.8337,                 loss: 0.1150
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 253.4188 s
agent0:                 episode reward: -0.3582,                 loss: nan
agent1:                 episode reward: 0.3582,                 loss: 0.1152
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 253.7271 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.1145
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 254.0317 s
agent0:                 episode reward: -0.8715,                 loss: nan
agent1:                 episode reward: 0.8715,                 loss: 0.1146
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 254.3350 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.1133
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 254.6428 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.1151
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 254.9452 s
agent0:                 episode reward: -0.4227,                 loss: nan
agent1:                 episode reward: 0.4227,                 loss: 0.1134
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 255.2580 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.1127
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 255.5756 s
agent0:                 episode reward: -0.7316,                 loss: nan
agent1:                 episode reward: 0.7316,                 loss: 0.1141
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 255.8781 s
agent0:                 episode reward: -0.6344,                 loss: nan
agent1:                 episode reward: 0.6344,                 loss: 0.1129
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 256.1798 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.1141
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 256.4892 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.1139
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3055s / 256.7948 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.1147
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 257.0985 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.1134
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2976s / 257.3961 s
agent0:                 episode reward: -0.8549,                 loss: nan
agent1:                 episode reward: 0.8549,                 loss: 0.1150
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 257.6998 s
agent0:                 episode reward: -0.6206,                 loss: nan
agent1:                 episode reward: 0.6206,                 loss: 0.1154
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3457s / 258.0455 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.1137
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 258.3860 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.1147
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3158s / 258.7018 s
agent0:                 episode reward: -0.3468,                 loss: nan
agent1:                 episode reward: 0.3468,                 loss: 0.1152
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 259.0107 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.1144
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3021s / 259.3127 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.1144
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 259.6128 s
agent0:                 episode reward: -0.5290,                 loss: nan
agent1:                 episode reward: 0.5290,                 loss: 0.1155
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 259.9167 s
agent0:                 episode reward: -0.6012,                 loss: nan
agent1:                 episode reward: 0.6012,                 loss: 0.1134
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3075s / 260.2243 s
agent0:                 episode reward: -0.5651,                 loss: nan
agent1:                 episode reward: 0.5651,                 loss: 0.1134
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 260.5266 s
agent0:                 episode reward: -0.8987,                 loss: nan
agent1:                 episode reward: 0.8987,                 loss: 0.1142
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 260.8349 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.1142
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3076s / 261.1425 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.1139
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 261.4668 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.1118
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 261.7837 s
agent0:                 episode reward: -0.5110,                 loss: nan
agent1:                 episode reward: 0.5110,                 loss: 0.1146
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 262.0826 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.1163
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 262.3753 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: 0.1138
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 262.6655 s
agent0:                 episode reward: -0.9311,                 loss: nan
agent1:                 episode reward: 0.9311,                 loss: 0.1152
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3157s / 262.9812 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: 0.1141
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3093s / 263.2905 s
agent0:                 episode reward: -0.3389,                 loss: nan
agent1:                 episode reward: 0.3389,                 loss: 0.1137
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3015s / 263.5920 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.1141
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 263.9014 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1129
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 264.2058 s
agent0:                 episode reward: -0.6502,                 loss: nan
agent1:                 episode reward: 0.6502,                 loss: 0.1136
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 264.5346 s
agent0:                 episode reward: -0.5177,                 loss: nan
agent1:                 episode reward: 0.5177,                 loss: 0.1137
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3262s / 264.8608 s
agent0:                 episode reward: -0.4628,                 loss: nan
agent1:                 episode reward: 0.4628,                 loss: 0.1144
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 265.1687 s
agent0:                 episode reward: -1.0036,                 loss: nan
agent1:                 episode reward: 1.0036,                 loss: 0.1135
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 265.4792 s
agent0:                 episode reward: -0.8513,                 loss: nan
agent1:                 episode reward: 0.8513,                 loss: 0.1149
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3094s / 265.7886 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.1147
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 266.0955 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.1142
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3072s / 266.4027 s
agent0:                 episode reward: -0.7087,                 loss: nan
agent1:                 episode reward: 0.7087,                 loss: 0.1147
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 266.7063 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.1127
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3035s / 267.0098 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.1146
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 267.3157 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1136
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3328s / 267.6485 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.1121
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 267.9612 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.1141
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 268.2657 s
agent0:                 episode reward: -0.9610,                 loss: nan
agent1:                 episode reward: 0.9610,                 loss: 0.1135
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3065s / 268.5722 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.1139
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 268.8819 s
agent0:                 episode reward: -0.8078,                 loss: nan
agent1:                 episode reward: 0.8078,                 loss: 0.1137
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3077s / 269.1897 s
agent0:                 episode reward: -0.6270,                 loss: nan
agent1:                 episode reward: 0.6270,                 loss: 0.1138
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 269.4994 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.1135
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 269.8135 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.1153
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3099s / 270.1233 s
agent0:                 episode reward: -0.6364,                 loss: nan
agent1:                 episode reward: 0.6364,                 loss: 0.1142
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 270.4345 s
agent0:                 episode reward: -0.6169,                 loss: nan
agent1:                 episode reward: 0.6169,                 loss: 0.1133
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 270.7827 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.1144
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 271.1193 s
agent0:                 episode reward: -0.5774,                 loss: nan
agent1:                 episode reward: 0.5774,                 loss: 0.1154
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 271.4313 s
agent0:                 episode reward: -0.4352,                 loss: nan
agent1:                 episode reward: 0.4352,                 loss: 0.1133
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 271.7437 s
agent0:                 episode reward: -1.1521,                 loss: nan
agent1:                 episode reward: 1.1521,                 loss: 0.1148
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 272.0555 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.1144
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 272.3660 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.1159
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 272.6738 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.1121
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2954s / 272.9692 s
agent0:                 episode reward: -0.6834,                 loss: nan
agent1:                 episode reward: 0.6834,                 loss: 0.1145
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3017s / 273.2709 s
agent0:                 episode reward: -0.3676,                 loss: nan
agent1:                 episode reward: 0.3676,                 loss: 0.1156
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3175s / 273.5884 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1144
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 273.9215 s
agent0:                 episode reward: -0.6685,                 loss: nan
agent1:                 episode reward: 0.6685,                 loss: 0.1145
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 274.2303 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.1143
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 274.5423 s
agent0:                 episode reward: -0.8560,                 loss: nan
agent1:                 episode reward: 0.8560,                 loss: 0.1134
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3177s / 274.8600 s
agent0:                 episode reward: -0.8968,                 loss: nan
agent1:                 episode reward: 0.8968,                 loss: 0.1134
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3075s / 275.1675 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.1155
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3101s / 275.4776 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.1150
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3123s / 275.7899 s
agent0:                 episode reward: -0.6708,                 loss: nan
agent1:                 episode reward: 0.6708,                 loss: 0.1151
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 276.1010 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.1145
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3077s / 276.4087 s
agent0:                 episode reward: -0.4508,                 loss: nan
agent1:                 episode reward: 0.4508,                 loss: 0.1142
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 276.7461 s
agent0:                 episode reward: -0.6473,                 loss: nan
agent1:                 episode reward: 0.6473,                 loss: 0.1136
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 277.0893 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.1142
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 277.4099 s
agent0:                 episode reward: -0.9541,                 loss: nan
agent1:                 episode reward: 0.9541,                 loss: 0.1137
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 277.7279 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.1136
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 278.0457 s
agent0:                 episode reward: -0.6523,                 loss: nan
agent1:                 episode reward: 0.6523,                 loss: 0.1144
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 278.3651 s
agent0:                 episode reward: -0.1590,                 loss: nan
agent1:                 episode reward: 0.1590,                 loss: 0.1158
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3175s / 278.6825 s
agent0:                 episode reward: -0.8658,                 loss: nan
agent1:                 episode reward: 0.8658,                 loss: 0.1156
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 279.0055 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.1126
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 279.3240 s
agent0:                 episode reward: -0.8964,                 loss: nan
agent1:                 episode reward: 0.8964,                 loss: 0.1152
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3385s / 279.6625 s
agent0:                 episode reward: -0.7019,                 loss: nan
agent1:                 episode reward: 0.7019,                 loss: 0.1152
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 280.0055 s
agent0:                 episode reward: -0.8362,                 loss: nan
agent1:                 episode reward: 0.8362,                 loss: 0.1135
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 280.3198 s
agent0:                 episode reward: -0.8012,                 loss: nan
agent1:                 episode reward: 0.8012,                 loss: 0.1129
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 280.6334 s
agent0:                 episode reward: -0.5406,                 loss: nan
agent1:                 episode reward: 0.5406,                 loss: 0.1143
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 280.9464 s
agent0:                 episode reward: -0.9117,                 loss: nan
agent1:                 episode reward: 0.9117,                 loss: 0.1142
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 281.2596 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.1154
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3101s / 281.5697 s
agent0:                 episode reward: -0.8826,                 loss: nan
agent1:                 episode reward: 0.8826,                 loss: 0.1152
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 281.8780 s
agent0:                 episode reward: -0.5200,                 loss: nan
agent1:                 episode reward: 0.5200,                 loss: 0.1155
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 282.1883 s
agent0:                 episode reward: -0.6927,                 loss: nan
agent1:                 episode reward: 0.6927,                 loss: 0.1133
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3158s / 282.5042 s
agent0:                 episode reward: -0.8635,                 loss: nan
agent1:                 episode reward: 0.8635,                 loss: 0.1125
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 282.8246 s
agent0:                 episode reward: -0.7502,                 loss: nan
agent1:                 episode reward: 0.7502,                 loss: 0.1112
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 283.1504 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.1136
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3003s / 283.4507 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.1129
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 283.7531 s
agent0:                 episode reward: -0.5604,                 loss: nan
agent1:                 episode reward: 0.5604,                 loss: 0.1121
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3010s / 284.0542 s
agent0:                 episode reward: -0.6709,                 loss: nan
agent1:                 episode reward: 0.6709,                 loss: 0.1133
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 284.3513 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.1129
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 284.6537 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.1114
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3123s / 284.9660 s
agent0:                 episode reward: -0.3078,                 loss: nan
agent1:                 episode reward: 0.3078,                 loss: 0.1124
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 285.2758 s
agent0:                 episode reward: -0.3102,                 loss: nan
agent1:                 episode reward: 0.3102,                 loss: 0.1131
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 285.5879 s
agent0:                 episode reward: -0.9368,                 loss: nan
agent1:                 episode reward: 0.9368,                 loss: 0.1128
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3211s / 285.9090 s
agent0:                 episode reward: -0.9641,                 loss: nan
agent1:                 episode reward: 0.9641,                 loss: 0.1116
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 286.2354 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.1125
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 286.5458 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.1119
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 286.8541 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.1125
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 287.1714 s
agent0:                 episode reward: -0.6359,                 loss: nan
agent1:                 episode reward: 0.6359,                 loss: 0.1130
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 287.4776 s
agent0:                 episode reward: -0.7799,                 loss: nan
agent1:                 episode reward: 0.7799,                 loss: 0.1125
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 287.8065 s
agent0:                 episode reward: -0.2905,                 loss: nan
agent1:                 episode reward: 0.2905,                 loss: 0.1119
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3160s / 288.1225 s
agent0:                 episode reward: -0.2612,                 loss: nan
agent1:                 episode reward: 0.2612,                 loss: 0.1145
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 288.4361 s
agent0:                 episode reward: -0.7930,                 loss: nan
agent1:                 episode reward: 0.7930,                 loss: 0.1145
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 288.7467 s
agent0:                 episode reward: -0.7099,                 loss: nan
agent1:                 episode reward: 0.7099,                 loss: 0.1139
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3529s / 289.0997 s
agent0:                 episode reward: -0.8125,                 loss: nan
agent1:                 episode reward: 0.8125,                 loss: 0.1128
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 289.4300 s
agent0:                 episode reward: -0.6366,                 loss: nan
agent1:                 episode reward: 0.6366,                 loss: 0.1133
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 289.7436 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.1123
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 290.0572 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.1142
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 290.3716 s
agent0:                 episode reward: -0.8597,                 loss: nan
agent1:                 episode reward: 0.8597,                 loss: 0.1133
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3715s / 290.7431 s
agent0:                 episode reward: -0.7443,                 loss: nan
agent1:                 episode reward: 0.7443,                 loss: 0.1113
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3123s / 291.0554 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.1136
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 291.3579 s
agent0:                 episode reward: -0.5489,                 loss: nan
agent1:                 episode reward: 0.5489,                 loss: 0.1111
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 291.6860 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.1110
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 292.0117 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.1134
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 292.3380 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.1124
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 292.6432 s
agent0:                 episode reward: -0.6941,                 loss: nan
agent1:                 episode reward: 0.6941,                 loss: 0.1128
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 292.9414 s
agent0:                 episode reward: -0.6666,                 loss: nan
agent1:                 episode reward: 0.6666,                 loss: 0.1129
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 293.2427 s
agent0:                 episode reward: -0.7629,                 loss: nan
agent1:                 episode reward: 0.7629,                 loss: 0.1115
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3014s / 293.5441 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.1132
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 293.8486 s
agent0:                 episode reward: -0.2937,                 loss: nan
agent1:                 episode reward: 0.2937,                 loss: 0.1121
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 294.1504 s
agent0:                 episode reward: -0.5335,                 loss: nan
agent1:                 episode reward: 0.5335,                 loss: 0.1117
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 294.4556 s
agent0:                 episode reward: -0.8112,                 loss: nan
agent1:                 episode reward: 0.8112,                 loss: 0.1130
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 294.7564 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.1133
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 295.0734 s
agent0:                 episode reward: -0.6114,                 loss: nan
agent1:                 episode reward: 0.6114,                 loss: 0.1131
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3193s / 295.3927 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.1126
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 295.6996 s
agent0:                 episode reward: -0.6990,                 loss: nan
agent1:                 episode reward: 0.6990,                 loss: 0.1128
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 296.0119 s
agent0:                 episode reward: -0.2977,                 loss: nan
agent1:                 episode reward: 0.2977,                 loss: 0.1133
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 296.3376 s
agent0:                 episode reward: -0.6375,                 loss: nan
agent1:                 episode reward: 0.6375,                 loss: 0.1131
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 296.6472 s
agent0:                 episode reward: -0.8432,                 loss: nan
agent1:                 episode reward: 0.8432,                 loss: 0.1110
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 296.9597 s
agent0:                 episode reward: -0.8445,                 loss: nan
agent1:                 episode reward: 0.8445,                 loss: 0.1126
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 297.2732 s
agent0:                 episode reward: -0.7938,                 loss: nan
agent1:                 episode reward: 0.7938,                 loss: 0.1135
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 297.5815 s
agent0:                 episode reward: -0.5543,                 loss: nan
agent1:                 episode reward: 0.5543,                 loss: 0.1120
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3048s / 297.8863 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.1122
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 298.2196 s
agent0:                 episode reward: -0.5456,                 loss: nan
agent1:                 episode reward: 0.5456,                 loss: 0.1138
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 298.5432 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1115
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 298.8617 s
agent0:                 episode reward: -0.7870,                 loss: nan
agent1:                 episode reward: 0.7870,                 loss: 0.1123
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 299.1815 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.1110
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3150s / 299.4965 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.1121
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 299.8137 s
agent0:                 episode reward: -0.2811,                 loss: nan
agent1:                 episode reward: 0.2811,                 loss: 0.1124
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3160s / 300.1297 s
agent0:                 episode reward: -0.9931,                 loss: nan
agent1:                 episode reward: 0.9931,                 loss: 0.1129
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 300.4476 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.1124
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 300.7734 s
agent0:                 episode reward: -0.4352,                 loss: nan
agent1:                 episode reward: 0.4352,                 loss: 0.1127
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 301.1011 s
agent0:                 episode reward: -0.9262,                 loss: nan
agent1:                 episode reward: 0.9262,                 loss: 0.1130
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3648s / 301.4659 s
agent0:                 episode reward: -1.0016,                 loss: nan
agent1:                 episode reward: 1.0016,                 loss: 0.1131
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3508s / 301.8167 s
agent0:                 episode reward: -0.9279,                 loss: nan
agent1:                 episode reward: 0.9279,                 loss: 0.1125
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 302.1396 s
agent0:                 episode reward: -0.7232,                 loss: nan
agent1:                 episode reward: 0.7232,                 loss: 0.1114
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3196s / 302.4592 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.1124
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3209s / 302.7801 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.1137
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 303.1032 s
agent0:                 episode reward: -0.7134,                 loss: nan
agent1:                 episode reward: 0.7134,                 loss: 0.1110
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 303.4274 s
agent0:                 episode reward: -0.6376,                 loss: nan
agent1:                 episode reward: 0.6376,                 loss: 0.1133
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 303.7512 s
agent0:                 episode reward: -0.2887,                 loss: nan
agent1:                 episode reward: 0.2887,                 loss: 0.1124
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 304.0741 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.1123
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3641s / 304.4382 s
agent0:                 episode reward: -0.8982,                 loss: nan
agent1:                 episode reward: 0.8982,                 loss: 0.1114
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3183s / 304.7566 s
agent0:                 episode reward: -0.4004,                 loss: nan
agent1:                 episode reward: 0.4004,                 loss: 0.1116
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3171s / 305.0736 s
agent0:                 episode reward: -0.7677,                 loss: nan
agent1:                 episode reward: 0.7677,                 loss: 0.1108
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 305.3940 s
agent0:                 episode reward: -0.9535,                 loss: nan
agent1:                 episode reward: 0.9535,                 loss: 0.1126
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 305.7113 s
agent0:                 episode reward: -0.8560,                 loss: nan
agent1:                 episode reward: 0.8560,                 loss: 0.1110
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3386s / 306.0498 s
agent0:                 episode reward: -0.3976,                 loss: nan
agent1:                 episode reward: 0.3976,                 loss: 0.1127
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3561s / 306.4059 s
agent0:                 episode reward: -0.6772,                 loss: nan
agent1:                 episode reward: 0.6772,                 loss: 0.1125
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3423s / 306.7483 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: 0.1129
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 307.0781 s
agent0:                 episode reward: -0.8537,                 loss: nan
agent1:                 episode reward: 0.8537,                 loss: 0.1120
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 307.4049 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.1119
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 307.7285 s
agent0:                 episode reward: -0.9331,                 loss: nan
agent1:                 episode reward: 0.9331,                 loss: 0.1115
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 308.0533 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.1116
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 308.3803 s
agent0:                 episode reward: -0.8563,                 loss: nan
agent1:                 episode reward: 0.8563,                 loss: 0.1125
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 308.7044 s
agent0:                 episode reward: -0.4649,                 loss: nan
agent1:                 episode reward: 0.4649,                 loss: 0.1115
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 309.0260 s
agent0:                 episode reward: -0.8243,                 loss: nan
agent1:                 episode reward: 0.8243,                 loss: 0.1115
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 309.3524 s
agent0:                 episode reward: -0.5688,                 loss: nan
agent1:                 episode reward: 0.5688,                 loss: 0.1109
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3080s / 309.6605 s
agent0:                 episode reward: -1.1519,                 loss: nan
agent1:                 episode reward: 1.1519,                 loss: 0.1106
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3084s / 309.9688 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.1100
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 310.3102 s
agent0:                 episode reward: -0.9078,                 loss: nan
agent1:                 episode reward: 0.9078,                 loss: 0.1123
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 310.6280 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1123
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3171s / 310.9451 s
agent0:                 episode reward: -0.9346,                 loss: nan
agent1:                 episode reward: 0.9346,                 loss: 0.1112
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 311.2553 s
agent0:                 episode reward: -0.8483,                 loss: nan
agent1:                 episode reward: 0.8483,                 loss: 0.1127
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3114s / 311.5667 s
agent0:                 episode reward: -0.6532,                 loss: nan
agent1:                 episode reward: 0.6532,                 loss: 0.1129
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 311.8765 s
agent0:                 episode reward: -0.8413,                 loss: nan
agent1:                 episode reward: 0.8413,                 loss: 0.1125
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3061s / 312.1826 s
agent0:                 episode reward: -0.9602,                 loss: nan
agent1:                 episode reward: 0.9602,                 loss: 0.1132
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 312.5108 s
agent0:                 episode reward: -1.0252,                 loss: nan
agent1:                 episode reward: 1.0252,                 loss: 0.1120
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 312.8500 s
agent0:                 episode reward: -0.5799,                 loss: nan
agent1:                 episode reward: 0.5799,                 loss: 0.1121
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3436s / 313.1936 s
agent0:                 episode reward: -0.7668,                 loss: nan
agent1:                 episode reward: 0.7668,                 loss: 0.1122
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3253s / 313.5190 s
agent0:                 episode reward: -0.6969,                 loss: nan
agent1:                 episode reward: 0.6969,                 loss: 0.1124
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 313.8707 s
agent0:                 episode reward: -0.6096,                 loss: nan
agent1:                 episode reward: 0.6096,                 loss: 0.1109
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3505s / 314.2212 s
agent0:                 episode reward: -0.6301,                 loss: nan
agent1:                 episode reward: 0.6301,                 loss: 0.1132
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 314.5354 s
agent0:                 episode reward: -0.6176,                 loss: nan
agent1:                 episode reward: 0.6176,                 loss: 0.1120
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3187s / 314.8541 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: 0.1116
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 315.1719 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.1114
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 315.4856 s
agent0:                 episode reward: -0.7730,                 loss: nan
agent1:                 episode reward: 0.7730,                 loss: 0.1128
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 315.7974 s
agent0:                 episode reward: -0.4880,                 loss: nan
agent1:                 episode reward: 0.4880,                 loss: 0.1121
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 316.1118 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.1109
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3327s / 316.4445 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.1130
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 316.7552 s
agent0:                 episode reward: -0.8049,                 loss: nan
agent1:                 episode reward: 0.8049,                 loss: 0.1113
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 317.0674 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.1119
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 317.3778 s
agent0:                 episode reward: -0.6460,                 loss: nan
agent1:                 episode reward: 0.6460,                 loss: 0.1107
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 317.6927 s
agent0:                 episode reward: -0.4050,                 loss: nan
agent1:                 episode reward: 0.4050,                 loss: 0.1114
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 318.0091 s
agent0:                 episode reward: -0.6359,                 loss: nan
agent1:                 episode reward: 0.6359,                 loss: 0.1119
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 318.3226 s
agent0:                 episode reward: -0.7146,                 loss: nan
agent1:                 episode reward: 0.7146,                 loss: 0.1127
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 318.6327 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.1125
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 318.9471 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.1100
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 319.2779 s
agent0:                 episode reward: -0.7683,                 loss: nan
agent1:                 episode reward: 0.7683,                 loss: 0.1113
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 319.6050 s
agent0:                 episode reward: -0.7197,                 loss: nan
agent1:                 episode reward: 0.7197,                 loss: 0.1110
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 319.9203 s
agent0:                 episode reward: -0.7228,                 loss: nan
agent1:                 episode reward: 0.7228,                 loss: 0.1109
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 320.2339 s
agent0:                 episode reward: -1.0138,                 loss: nan
agent1:                 episode reward: 1.0138,                 loss: 0.1122
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3160s / 320.5499 s
agent0:                 episode reward: -0.9177,                 loss: nan
agent1:                 episode reward: 0.9177,                 loss: 0.1135
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3122s / 320.8621 s
agent0:                 episode reward: -0.8050,                 loss: nan
agent1:                 episode reward: 0.8050,                 loss: 0.1127
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 321.1949 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.1136
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 321.5253 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.1131
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3255s / 321.8508 s
agent0:                 episode reward: -0.7978,                 loss: nan
agent1:                 episode reward: 0.7978,                 loss: 0.1127
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 322.1820 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.1133
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3565s / 322.5385 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.1122
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 322.8726 s
agent0:                 episode reward: -0.9754,                 loss: nan
agent1:                 episode reward: 0.9754,                 loss: 0.1112
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 323.2037 s
agent0:                 episode reward: -0.2956,                 loss: nan
agent1:                 episode reward: 0.2956,                 loss: 0.1116
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3285s / 323.5322 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.1109
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 323.8653 s
agent0:                 episode reward: -0.7955,                 loss: nan
agent1:                 episode reward: 0.7955,                 loss: 0.1131
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 324.1957 s
agent0:                 episode reward: -0.6398,                 loss: nan
agent1:                 episode reward: 0.6398,                 loss: 0.1113
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 324.5234 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.1126
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 324.8649 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.1122
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 325.1965 s
agent0:                 episode reward: -0.8726,                 loss: nan
agent1:                 episode reward: 0.8726,                 loss: 0.1120
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3658s / 325.5623 s
agent0:                 episode reward: -0.3632,                 loss: nan
agent1:                 episode reward: 0.3632,                 loss: 0.1110
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 325.8931 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.1115
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 326.2246 s
agent0:                 episode reward: -0.7694,                 loss: nan
agent1:                 episode reward: 0.7694,                 loss: 0.1108
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3327s / 326.5573 s
agent0:                 episode reward: -0.3112,                 loss: nan
agent1:                 episode reward: 0.3112,                 loss: 0.1123
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 326.8870 s
agent0:                 episode reward: -0.8305,                 loss: nan
agent1:                 episode reward: 0.8305,                 loss: 0.1110
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 327.2012 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.1111
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3165s / 327.5177 s
agent0:                 episode reward: -0.6692,                 loss: nan
agent1:                 episode reward: 0.6692,                 loss: 0.1106
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 327.8317 s
agent0:                 episode reward: -0.8684,                 loss: nan
agent1:                 episode reward: 0.8684,                 loss: 0.1113
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 328.1450 s
agent0:                 episode reward: -0.8352,                 loss: nan
agent1:                 episode reward: 0.8352,                 loss: 0.1129
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3619s / 328.5069 s
agent0:                 episode reward: -0.5905,                 loss: nan
agent1:                 episode reward: 0.5905,                 loss: 0.1114
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3660s / 328.8729 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1112
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 329.2044 s
agent0:                 episode reward: -0.8126,                 loss: nan
agent1:                 episode reward: 0.8126,                 loss: 0.1122
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3525s / 329.5569 s
agent0:                 episode reward: -0.7078,                 loss: nan
agent1:                 episode reward: 0.7078,                 loss: 0.1129
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3278s / 329.8847 s
agent0:                 episode reward: -0.8065,                 loss: nan
agent1:                 episode reward: 0.8065,                 loss: 0.1113
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 330.2133 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.1114
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3294s / 330.5427 s
agent0:                 episode reward: -0.8558,                 loss: nan
agent1:                 episode reward: 0.8558,                 loss: 0.1117
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 330.8756 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.1112
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 331.2127 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.1109
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3524s / 331.5650 s
agent0:                 episode reward: -0.4705,                 loss: nan
agent1:                 episode reward: 0.4705,                 loss: 0.1118
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3368s / 331.9018 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: 0.1112
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 332.2418 s
agent0:                 episode reward: -0.6692,                 loss: nan
agent1:                 episode reward: 0.6692,                 loss: 0.1119
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 332.5695 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.1103
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 332.9068 s
agent0:                 episode reward: -0.5730,                 loss: nan
agent1:                 episode reward: 0.5730,                 loss: 0.1120
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 333.2410 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1122
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 333.5779 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.1109
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3425s / 333.9204 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.1115
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 334.2644 s
agent0:                 episode reward: -1.0922,                 loss: nan
agent1:                 episode reward: 1.0922,                 loss: 0.1106
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3534s / 334.6178 s
agent0:                 episode reward: -0.8345,                 loss: nan
agent1:                 episode reward: 0.8345,                 loss: 0.1108
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 334.9655 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.1119
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 335.2979 s
agent0:                 episode reward: -0.7440,                 loss: nan
agent1:                 episode reward: 0.7440,                 loss: 0.1124
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 335.6352 s
agent0:                 episode reward: -0.5812,                 loss: nan
agent1:                 episode reward: 0.5812,                 loss: 0.1115
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 335.9681 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.1116
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3326s / 336.3006 s
agent0:                 episode reward: -0.8765,                 loss: nan
agent1:                 episode reward: 0.8765,                 loss: 0.1113
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 336.6337 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.1112
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3328s / 336.9666 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.1111
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 337.3023 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.1101
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3471s / 337.6493 s
agent0:                 episode reward: -0.6659,                 loss: nan
agent1:                 episode reward: 0.6659,                 loss: 0.1106
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3707s / 338.0200 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.1117
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 338.3595 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.1117
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 338.6999 s
agent0:                 episode reward: -0.9359,                 loss: nan
agent1:                 episode reward: 0.9359,                 loss: 0.1112
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3347s / 339.0346 s
agent0:                 episode reward: -0.7193,                 loss: nan
agent1:                 episode reward: 0.7193,                 loss: 0.1119
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 339.3664 s
agent0:                 episode reward: -0.8260,                 loss: nan
agent1:                 episode reward: 0.8260,                 loss: 0.1131
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 339.6994 s
agent0:                 episode reward: -0.7963,                 loss: nan
agent1:                 episode reward: 0.7963,                 loss: 0.1132
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 340.0313 s
agent0:                 episode reward: -0.9223,                 loss: nan
agent1:                 episode reward: 0.9223,                 loss: 0.1107
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 340.3662 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.1103
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3419s / 340.7081 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.1117
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3814s / 341.0895 s
agent0:                 episode reward: -0.7200,                 loss: nan
agent1:                 episode reward: 0.7200,                 loss: 0.1109
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 341.4132 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.1127
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 341.7355 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.1115
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 342.0596 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.1123
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 342.3833 s
agent0:                 episode reward: -0.3852,                 loss: nan
agent1:                 episode reward: 0.3852,                 loss: 0.1106
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 342.7064 s
agent0:                 episode reward: -0.9143,                 loss: nan
agent1:                 episode reward: 0.9143,                 loss: 0.1090
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3202s / 343.0266 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.1092
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3198s / 343.3464 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.1104
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3199s / 343.6664 s
agent0:                 episode reward: -0.7638,                 loss: nan
agent1:                 episode reward: 0.7638,                 loss: 0.1089
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3467s / 344.0131 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.1105
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 344.3332 s
agent0:                 episode reward: -0.7775,                 loss: nan
agent1:                 episode reward: 0.7775,                 loss: 0.1099
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 344.6578 s
agent0:                 episode reward: -0.6978,                 loss: nan
agent1:                 episode reward: 0.6978,                 loss: 0.1107
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 344.9820 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.1095
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3183s / 345.3002 s
agent0:                 episode reward: -0.9389,                 loss: nan
agent1:                 episode reward: 0.9389,                 loss: 0.1108
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 345.6259 s
agent0:                 episode reward: -0.8715,                 loss: nan
agent1:                 episode reward: 0.8715,                 loss: 0.1098
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3208s / 345.9467 s
agent0:                 episode reward: -0.4230,                 loss: nan
agent1:                 episode reward: 0.4230,                 loss: 0.1105
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3436s / 346.2903 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.1101
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 346.6321 s
agent0:                 episode reward: -0.8291,                 loss: nan
agent1:                 episode reward: 0.8291,                 loss: 0.1107
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 347.0056 s
agent0:                 episode reward: -1.0554,                 loss: nan
agent1:                 episode reward: 1.0554,                 loss: 0.1104
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3521s / 347.3577 s
agent0:                 episode reward: -0.7847,                 loss: nan
agent1:                 episode reward: 0.7847,                 loss: 0.1103
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3353s / 347.6930 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.1114
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3440s / 348.0370 s
agent0:                 episode reward: -0.6932,                 loss: nan
agent1:                 episode reward: 0.6932,                 loss: 0.1102
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 348.3867 s
agent0:                 episode reward: -0.6209,                 loss: nan
agent1:                 episode reward: 0.6209,                 loss: 0.1110
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 348.7237 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1122
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3402s / 349.0639 s
agent0:                 episode reward: -0.8137,                 loss: nan
agent1:                 episode reward: 0.8137,                 loss: 0.1114
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 349.4034 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.1112
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 349.7423 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.1105
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 350.1029 s
agent0:                 episode reward: -0.8498,                 loss: nan
agent1:                 episode reward: 0.8498,                 loss: 0.1103
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3345s / 350.4374 s
agent0:                 episode reward: -0.7126,                 loss: nan
agent1:                 episode reward: 0.7126,                 loss: 0.1113
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 350.7802 s
agent0:                 episode reward: -0.5043,                 loss: nan
agent1:                 episode reward: 0.5043,                 loss: 0.1109
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3372s / 351.1174 s
agent0:                 episode reward: -0.5735,                 loss: nan
agent1:                 episode reward: 0.5735,                 loss: 0.1109
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3467s / 351.4642 s
agent0:                 episode reward: -0.7804,                 loss: nan
agent1:                 episode reward: 0.7804,                 loss: 0.1107
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3410s / 351.8051 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.1115
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3398s / 352.1450 s
agent0:                 episode reward: -0.8110,                 loss: nan
agent1:                 episode reward: 0.8110,                 loss: 0.1106
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3403s / 352.4853 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.1094
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 352.8334 s
agent0:                 episode reward: -0.6300,                 loss: nan
agent1:                 episode reward: 0.6300,                 loss: 0.1094
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3711s / 353.2045 s
agent0:                 episode reward: -0.7339,                 loss: nan
agent1:                 episode reward: 0.7339,                 loss: 0.1094
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 353.5471 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.1121
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3452s / 353.8923 s
agent0:                 episode reward: -0.8064,                 loss: nan
agent1:                 episode reward: 0.8064,                 loss: 0.1109
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3385s / 354.2308 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.1107
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3602s / 354.5910 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.1112
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 354.9328 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.1109
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 355.2693 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.1102
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3424s / 355.6117 s
agent0:                 episode reward: -1.1389,                 loss: nan
agent1:                 episode reward: 1.1389,                 loss: 0.1104
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3414s / 355.9531 s
agent0:                 episode reward: -0.3372,                 loss: nan
agent1:                 episode reward: 0.3372,                 loss: 0.1096
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 356.3076 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.1111
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 356.6426 s
agent0:                 episode reward: -0.7719,                 loss: nan
agent1:                 episode reward: 0.7719,                 loss: 0.1107
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3379s / 356.9805 s
agent0:                 episode reward: -1.0857,                 loss: nan
agent1:                 episode reward: 1.0857,                 loss: 0.1125
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3360s / 357.3164 s
agent0:                 episode reward: -0.8128,                 loss: nan
agent1:                 episode reward: 0.8128,                 loss: 0.1109
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 357.6534 s
agent0:                 episode reward: -0.7958,                 loss: nan
agent1:                 episode reward: 0.7958,                 loss: 0.1088
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3454s / 357.9988 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.1106
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3459s / 358.3447 s
agent0:                 episode reward: -0.7246,                 loss: nan
agent1:                 episode reward: 0.7246,                 loss: 0.1118
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3427s / 358.6875 s
agent0:                 episode reward: -0.6098,                 loss: nan
agent1:                 episode reward: 0.6098,                 loss: 0.1106
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3552s / 359.0427 s
agent0:                 episode reward: -0.7824,                 loss: nan
agent1:                 episode reward: 0.7824,                 loss: 0.1101
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3604s / 359.4031 s
agent0:                 episode reward: -0.2170,                 loss: nan
agent1:                 episode reward: 0.2170,                 loss: 0.1110
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3384s / 359.7415 s
agent0:                 episode reward: -0.9434,                 loss: nan
agent1:                 episode reward: 0.9434,                 loss: 0.1102
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 360.0778 s
agent0:                 episode reward: -0.3335,                 loss: nan
agent1:                 episode reward: 0.3335,                 loss: 0.1117
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 360.4168 s
agent0:                 episode reward: -0.7927,                 loss: nan
agent1:                 episode reward: 0.7927,                 loss: 0.1119
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3456s / 360.7623 s
agent0:                 episode reward: -0.7197,                 loss: nan
agent1:                 episode reward: 0.7197,                 loss: 0.1110
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3450s / 361.1073 s
agent0:                 episode reward: -0.6002,                 loss: nan
agent1:                 episode reward: 0.6002,                 loss: 0.1110
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 361.4499 s
agent0:                 episode reward: -0.8344,                 loss: nan
agent1:                 episode reward: 0.8344,                 loss: 0.1116
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 361.7896 s
agent0:                 episode reward: -1.0985,                 loss: nan
agent1:                 episode reward: 1.0985,                 loss: 0.1105
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3377s / 362.1273 s
agent0:                 episode reward: -0.6133,                 loss: nan
agent1:                 episode reward: 0.6133,                 loss: 0.1104
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3597s / 362.4870 s
agent0:                 episode reward: -0.4562,                 loss: nan
agent1:                 episode reward: 0.4562,                 loss: 0.1108
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3624s / 362.8494 s
agent0:                 episode reward: -0.5520,                 loss: nan
agent1:                 episode reward: 0.5520,                 loss: 0.1111
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 363.1845 s
agent0:                 episode reward: -0.9824,                 loss: nan
agent1:                 episode reward: 0.9824,                 loss: 0.1108
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 363.5326 s
agent0:                 episode reward: -0.8037,                 loss: nan
agent1:                 episode reward: 0.8037,                 loss: 0.1116
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3457s / 363.8783 s
agent0:                 episode reward: -0.3905,                 loss: nan
agent1:                 episode reward: 0.3905,                 loss: 0.1124
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3500s / 364.2283 s
agent0:                 episode reward: -0.8312,                 loss: nan
agent1:                 episode reward: 0.8312,                 loss: 0.1105
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3464s / 364.5747 s
agent0:                 episode reward: -0.6909,                 loss: nan
agent1:                 episode reward: 0.6909,                 loss: 0.1110
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 364.9182 s
agent0:                 episode reward: -0.6996,                 loss: nan
agent1:                 episode reward: 0.6996,                 loss: 0.1105
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3617s / 365.2799 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.1105
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3675s / 365.6473 s
agent0:                 episode reward: -0.6059,                 loss: nan
agent1:                 episode reward: 0.6059,                 loss: 0.1113
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3409s / 365.9883 s
agent0:                 episode reward: -0.7002,                 loss: nan
agent1:                 episode reward: 0.7002,                 loss: 0.1104
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 366.3288 s
agent0:                 episode reward: -0.7018,                 loss: nan
agent1:                 episode reward: 0.7018,                 loss: 0.1110
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3425s / 366.6713 s
agent0:                 episode reward: -0.8466,                 loss: nan
agent1:                 episode reward: 0.8466,                 loss: 0.1101
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 367.0118 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.1114
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3535s / 367.3652 s
agent0:                 episode reward: -0.6494,                 loss: nan
agent1:                 episode reward: 0.6494,                 loss: 0.1107
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3546s / 367.7198 s
agent0:                 episode reward: -0.6889,                 loss: nan
agent1:                 episode reward: 0.6889,                 loss: 0.1102
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3580s / 368.0778 s
agent0:                 episode reward: -0.4151,                 loss: nan
agent1:                 episode reward: 0.4151,                 loss: 0.1106
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3565s / 368.4343 s
agent0:                 episode reward: -0.9232,                 loss: nan
agent1:                 episode reward: 0.9232,                 loss: 0.1112
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 368.7774 s
agent0:                 episode reward: -0.7884,                 loss: nan
agent1:                 episode reward: 0.7884,                 loss: 0.1119
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3457s / 369.1231 s
agent0:                 episode reward: -0.5591,                 loss: nan
agent1:                 episode reward: 0.5591,                 loss: 0.1117
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3470s / 369.4700 s
agent0:                 episode reward: -0.6114,                 loss: nan
agent1:                 episode reward: 0.6114,                 loss: 0.1099
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3433s / 369.8133 s
agent0:                 episode reward: -0.6668,                 loss: nan
agent1:                 episode reward: 0.6668,                 loss: 0.1113
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3460s / 370.1593 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: 0.1119
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3433s / 370.5026 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.1098
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 370.8426 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.1119
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3652s / 371.2079 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.1095
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3424s / 371.5503 s
agent0:                 episode reward: -0.9778,                 loss: nan
agent1:                 episode reward: 0.9778,                 loss: 0.1108
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 371.8969 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.1106
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 372.2437 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.1102
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 372.5955 s
agent0:                 episode reward: -0.6184,                 loss: nan
agent1:                 episode reward: 0.6184,                 loss: 0.1105
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3564s / 372.9519 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.1078
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3459s / 373.2978 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.1092
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3576s / 373.6555 s
agent0:                 episode reward: -0.8205,                 loss: nan
agent1:                 episode reward: 0.8205,                 loss: 0.1088
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3809s / 374.0364 s
agent0:                 episode reward: -1.0162,                 loss: nan
agent1:                 episode reward: 1.0162,                 loss: 0.1097
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 374.3917 s
agent0:                 episode reward: -0.8554,                 loss: nan
agent1:                 episode reward: 0.8554,                 loss: 0.1099
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 374.7391 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.1091
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 375.0859 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.1092
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3443s / 375.4302 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.1082
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3489s / 375.7791 s
agent0:                 episode reward: -0.7323,                 loss: nan
agent1:                 episode reward: 0.7323,                 loss: 0.1100
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3478s / 376.1269 s
agent0:                 episode reward: -0.6062,                 loss: nan
agent1:                 episode reward: 0.6062,                 loss: 0.1097
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3478s / 376.4747 s
agent0:                 episode reward: -0.9431,                 loss: nan
agent1:                 episode reward: 0.9431,                 loss: 0.1093
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3453s / 376.8200 s
agent0:                 episode reward: -0.7790,                 loss: nan
agent1:                 episode reward: 0.7790,                 loss: 0.1112
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3682s / 377.1882 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.1092
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4079s / 377.5960 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.1118
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 377.9472 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.1111
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 378.2900 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.1101
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3469s / 378.6369 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1096
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3492s / 378.9861 s/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -0.5896,                 loss: nan
agent1:                 episode reward: 0.5896,                 loss: 0.1105
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3473s / 379.3334 s
agent0:                 episode reward: -0.7342,                 loss: nan
agent1:                 episode reward: 0.7342,                 loss: 0.1102
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3614s / 379.6947 s
agent0:                 episode reward: -0.9175,                 loss: nan
agent1:                 episode reward: 0.9175,                 loss: 0.1099
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 380.0674 s
agent0:                 episode reward: -0.5008,                 loss: nan
agent1:                 episode reward: 0.5008,                 loss: 0.1119
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3647s / 380.4322 s
agent0:                 episode reward: -1.1240,                 loss: nan
agent1:                 episode reward: 1.1240,                 loss: 0.1108
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3598s / 380.7920 s
agent0:                 episode reward: -1.0197,                 loss: nan
agent1:                 episode reward: 1.0197,                 loss: 0.1119
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3671s / 381.1590 s
agent0:                 episode reward: -0.9439,                 loss: nan
agent1:                 episode reward: 0.9439,                 loss: 0.1098
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 381.5140 s
agent0:                 episode reward: -1.0713,                 loss: nan
agent1:                 episode reward: 1.0713,                 loss: 0.1127
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3581s / 381.8721 s
agent0:                 episode reward: -0.8664,                 loss: nan
agent1:                 episode reward: 0.8664,                 loss: 0.1111
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3429s / 382.2149 s
agent0:                 episode reward: -0.7223,                 loss: nan
agent1:                 episode reward: 0.7223,                 loss: 0.1114
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3523s / 382.5672 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.1109
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3590s / 382.9261 s
agent0:                 episode reward: -0.7116,                 loss: nan
agent1:                 episode reward: 0.7116,                 loss: 0.1089
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3739s / 383.3001 s
agent0:                 episode reward: -0.7277,                 loss: nan
agent1:                 episode reward: 0.7277,                 loss: 0.1103
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 383.6349 s
agent0:                 episode reward: -0.9247,                 loss: nan
agent1:                 episode reward: 0.9247,                 loss: 0.1114
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 383.9720 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.1097
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3431s / 384.3151 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.1100
