/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 437
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f7d87ce3b70>
discrete_policy 6 Discrete(6)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 20, in __init__
    super().__init__(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 38, in _init_model
    self.normal_nashQ = NashDQNBase(env, args.net_architecture, args.num_envs, two_side_obs = args.marl_spec['global_state']).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 258
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fefbb647fd0>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/202209201541/slimevolley_SlimeVolley-v0_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nash_dqn_exploiter. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nash_dqn_exploiter.
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 45, in launch
    rollout(env, model, exploitation_args, save_id = str(args.load_id)+f'_exploit_{to_exploit}') # save results of exploitation in a separate folder
  File "/data/zihan/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/data/zihan/research/MARS/mars/rollout.py", line 128, in rollout_normal
    obs_, reward, done, info = env.step(action)  # required action shape: (envs, agents, dim)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 535, in step
    obs, rewards, dones, infos = self.env.step(actions)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 475, in step
    obs0, reward, done, info = self.env.step(*actions_)  # gym!=0.18 will break this line
TypeError: step() takes 2 positional arguments but 3 were given
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
random seed: 252
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fa06f839ac8>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/202209201541/slimevolley_SlimeVolley-v0_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nash_dqn_exploiter. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nash_dqn_exploiter.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 8.26s / 8.26 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.8614
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.49s / 144.75 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.2094
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 138.03s / 282.78 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0599
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 138.68s / 421.46 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0481
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 139.10s / 560.56 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0476
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 140.32s / 700.88 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0505
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 140.05s / 840.93 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0527
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 140.59s / 981.52 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0483
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 140.73s / 1122.26 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0472
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 141.36s / 1263.62 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0458
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 141.58s / 1405.20 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0459
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 142.24s / 1547.45 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0461
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 142.94s / 1690.38 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0468
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 143.41s / 1833.79 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0446
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 143.67s / 1977.47 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0453
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 144.02s / 2121.48 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0454
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 144.05s / 2265.53 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0455
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 143.90s / 2409.43 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0448
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 144.66s / 2554.09 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0457
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 145.38s / 2699.48 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0453
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 145.60s / 2845.07 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0421
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 145.82s / 2990.89 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0431
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 145.57s / 3136.46 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0434
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 147.35s / 3283.81 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0429
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 147.80s / 3431.61 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0444
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 147.97s / 3579.58 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0445
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 148.89s / 3728.46 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0440
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 148.18s / 3876.64 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0425
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 148.21s / 4024.85 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0444
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 147.85s / 4172.69 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0432
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 148.32s / 4321.01 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0424
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 148.28s / 4469.29 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0421
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 149.48s / 4618.77 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0440
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 149.39s / 4768.16 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0446
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 149.83s / 4917.99 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0432
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 149.75s / 5067.74 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0434
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 149.44s / 5217.18 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0447
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 149.54s / 5366.72 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0412
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.26s / 5516.98 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0434
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 149.81s / 5666.79 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0421
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 149.61s / 5816.40 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0409
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.28s / 5966.68 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0406
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 149.76s / 6116.44 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0399
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 6267.88 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0399
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.39s / 6418.27 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0415
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.46s / 6568.73 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0402
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.32s / 6719.05 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0411
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.24s / 6869.30 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0395
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 149.96s / 7019.25 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0381
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.47s / 7169.72 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0390
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.23s / 7319.95 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0389
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.77s / 7470.73 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0385
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.91s / 7621.63 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0378
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.32s / 7771.95 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0386
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.46s / 7922.41 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0378
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.90s / 8073.31 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0381
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.00s / 8224.31 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0392
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.12s / 8375.43 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0385
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.96s / 8527.39 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0406
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.78s / 8679.16 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0394
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 8830.65 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0392
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.18s / 8981.84 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0394
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.63s / 9133.47 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0407
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.42s / 9284.89 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0397
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.70s / 9435.59 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0399
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.84s / 9586.44 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0408
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.09s / 9737.53 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0396
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.90s / 9888.43 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0384
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.89s / 10039.32 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0389
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.99s / 10190.31 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0395
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.84s / 10341.16 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0395
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 10492.53 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0382
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.48s / 10643.01 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0383
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.21s / 10794.22 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0388
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.00s / 10945.22 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0392
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.95s / 11096.17 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0376
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 11247.52 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0399
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.83s / 11398.35 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0390
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.76s / 11550.11 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0392
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.52s / 11700.63 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0380
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.04s / 11851.67 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0376
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.87s / 12002.54 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0368
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.71s / 12153.25 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0388
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.62s / 12303.87 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0389
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.07s / 12454.94 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0383
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.93s / 12605.87 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0388
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.72s / 12756.59 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0385
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 12907.79 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0385
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.52s / 13059.31 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0383
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 13210.83 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0386
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.22s / 13362.06 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0380
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 13513.41 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0383
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.92s / 13664.34 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0378
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.04s / 13815.38 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0390
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.81s / 13966.18 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0370
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.14s / 14117.33 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0386
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.91s / 14268.24 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0391
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.94s / 14419.18 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0392
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.44s / 14571.62 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0374
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.13s / 14722.75 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0381
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 14873.96 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0374
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.47s / 15025.42 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0386
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.91s / 15177.34 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0389
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.99s / 15328.33 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0390
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.48s / 15479.81 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0400
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.71s / 15632.52 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0391
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.22s / 15783.73 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0402
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 15935.05 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0387
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.75s / 16085.80 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0391
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.75s / 16237.55 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0386
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.54s / 16389.09 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0384
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 16540.53 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0384
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.32s / 16692.85 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0381
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.29s / 16844.14 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0388
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.05s / 16995.19 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0381
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.30s / 17146.49 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0379
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.21s / 17297.71 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0383
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.04s / 17448.74 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0393
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.42s / 17600.16 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0392
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.31s / 17751.47 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0383
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.48s / 17902.95 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0384
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.96s / 18054.91 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0396
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.11s / 18206.02 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0392
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.68s / 18357.70 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0392
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.79s / 18508.48 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0392
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.62s / 18661.10 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0387
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.19s / 18813.29 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0384
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.30s / 18965.59 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0387
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.79s / 19117.38 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0399
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.26s / 19269.65 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0392
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.70s / 19421.34 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0390
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.88s / 19572.22 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0386
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.59s / 19723.81 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0379
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.34s / 19875.15 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0380
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.52s / 20026.68 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0386
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.05s / 20177.73 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0375
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.25s / 20329.98 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0379
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 20481.48 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0378
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.29s / 20633.77 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0383
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.35s / 20785.11 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0379
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.30s / 20936.41 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0376
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 21087.91 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0362
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.48s / 21239.39 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0365
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 21391.12 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0364
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.26s / 21542.38 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0373
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.47s / 21693.85 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0366
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 21845.17 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0363
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.29s / 21997.46 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0385
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.25s / 22149.72 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0383
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.00s / 22301.72 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0381
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 22453.22 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0385
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.55s / 22604.77 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0377
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.16s / 22756.93 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0366
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.99s / 22908.91 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0389
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.43s / 23060.35 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0382
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 23211.84 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0388
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.84s / 23362.69 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0385
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 23513.97 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0381
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.09s / 23665.06 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0386
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.87s / 23816.93 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0389
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.59s / 23968.52 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0388
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.10s / 24120.62 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0389
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.13s / 24271.75 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0379
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.85s / 24423.59 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0385
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 24574.79 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0395
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 24726.12 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0392
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.45s / 24877.57 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0371
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.34s / 25028.91 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0388
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.01s / 25179.92 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0377
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.10s / 25331.02 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0385
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.01s / 25482.03 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0387
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.35s / 25633.38 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0394
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.68s / 25785.07 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0384
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 25936.90 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0386
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.79s / 26088.69 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0395
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.40s / 26241.08 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0392
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.43s / 26392.51 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0393
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.19s / 26543.70 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0404
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.35s / 26695.05 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0404
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.74s / 26847.78 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0410
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.08s / 26999.86 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0398
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.82s / 27151.69 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0388
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.86s / 27303.54 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0398
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 27455.25 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0401
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 27606.85 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0400
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.27s / 27759.12 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0399
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 27910.50 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0395
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.77s / 28062.26 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0404
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 28213.80 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0405
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 150.79s / 28364.59 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0410
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.07s / 28516.66 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0411
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.96s / 28667.63 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0399
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.02s / 28818.65 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0391
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.85s / 28970.50 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0400
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.41s / 29122.91 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0401
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.40s / 29275.31 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0388
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.47s / 29426.78 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0410
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.24s / 29578.02 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0409
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.48s / 29729.49 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0412
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.51s / 29882.00 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0387
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.98s / 30033.98 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0387
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.31s / 30185.29 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0389
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.35s / 30336.64 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0404
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 30488.29 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0404
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.55s / 30639.85 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0400
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.61s / 30791.45 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0408
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 30942.99 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0401
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.00s / 31094.99 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0389
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.62s / 31246.61 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0409
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.79s / 31398.40 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0396
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.82s / 31551.21 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0397
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 31702.71 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0398
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.39s / 31854.10 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0403
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.88s / 32005.98 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0402
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.70s / 32157.68 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0393
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.79s / 32309.48 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0406
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 32460.79 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0413
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.04s / 32611.83 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0422
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.38s / 32764.21 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0422
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.20s / 32916.41 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0417
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.76s / 33068.17 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0407
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.48s / 33220.64 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0414
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.03s / 33372.67 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0411
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.78s / 33524.45 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0414
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.09s / 33675.54 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0421
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.56s / 33827.10 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0422
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.99s / 33978.08 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0403
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.45s / 34129.53 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0398
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 34281.13 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0423
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 34432.78 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0421
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.16s / 34583.94 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0417
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.18s / 34735.13 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0418
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.58s / 34886.70 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0412
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.29s / 35038.99 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0405
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.09s / 35191.08 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0403
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 35342.73 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0418
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 35494.22 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0414
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 35645.72 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0415
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.55s / 35797.27 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0411
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.98s / 35949.25 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0403
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.37s / 36101.62 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0418
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.07s / 36253.69 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0411
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.04s / 36405.73 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0425
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.51s / 36558.24 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0432
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.88s / 36710.12 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0416
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.56s / 36861.68 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0411
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 37013.40 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0404
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.56s / 37164.97 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0404
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 37316.25 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0403
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 37467.61 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0413
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.88s / 37619.49 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0417
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.45s / 37771.94 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0404
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 37923.47 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0397
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.30s / 38074.78 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0392
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 38226.14 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0392
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.59s / 38377.74 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0395
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.45s / 38529.18 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0399
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.05s / 38680.23 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0404
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 38831.76 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0402
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 38983.41 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0410
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.29s / 39134.70 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0408
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.07s / 39285.77 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0399
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.64s / 39437.41 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0395
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 39589.01 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0409
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 39740.33 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0411
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.31s / 39892.64 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0416
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.45s / 40044.10 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0404
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 40195.60 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0415
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.38s / 40346.98 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0413
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.22s / 40499.20 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0416
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.09s / 40651.28 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0417
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.43s / 40803.71 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0412
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 40955.42 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0413
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.01s / 41107.43 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0420
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 41258.64 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0416
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.17s / 41409.80 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0411
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.72s / 41561.53 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0420
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 41712.85 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0415
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.58s / 41864.43 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0416
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.92s / 42016.35 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0410
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 42167.72 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0411
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.01s / 42319.73 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0409
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.57s / 42471.30 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0419
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.61s / 42622.91 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0401
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.75s / 42774.66 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0403
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.25s / 42926.91 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0412
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.97s / 43077.88 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0404
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.42s / 43229.30 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0405
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 43380.74 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0417
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.40s / 43532.14 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0402
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 43683.67 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0404
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.52s / 43835.19 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0405
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.85s / 43987.04 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0422
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 44138.74 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0416
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.27s / 44291.01 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0409
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 44442.46 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0401
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 44593.83 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0418
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.09s / 44744.92 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0398
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.24s / 44896.16 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0392
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.76s / 45047.91 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0400
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.36s / 45200.27 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0409
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.56s / 45352.84 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0417
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.18s / 45504.02 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0415
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.58s / 45656.60 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0425
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.21s / 45807.80 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0399
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 45959.12 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0397
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.67s / 46110.79 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0400
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.01s / 46262.80 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0413
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.67s / 46415.47 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0407
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.06s / 46566.53 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0419
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.33s / 46718.86 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0409
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.02s / 46870.88 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0407
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.35s / 47023.23 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0408
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.08s / 47175.31 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0423
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 47326.80 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0415
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.40s / 47479.19 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0422
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.34s / 47631.54 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0438
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.54s / 47783.08 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0414
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.33s / 47934.41 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0430
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.00s / 48086.40 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0423
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.82s / 48238.22 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0421
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.13s / 48389.36 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0425
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.70s / 48541.05 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0420
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.82s / 48693.87 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0414
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.23s / 48845.10 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0415
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.43s / 48996.53 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0423
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.44s / 49148.97 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0424
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.51s / 49300.48 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0399
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 49451.97 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0416
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.24s / 49604.21 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0427
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.31s / 49756.52 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0431
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 49908.17 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0409
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.96s / 50060.14 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0408
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.17s / 50212.31 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0424
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 50363.80 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0402
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.94s / 50514.74 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0404
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.08s / 50665.82 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0410
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.18s / 50818.00 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0410
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 50969.82 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0415
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.30s / 51122.12 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0420
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 51273.73 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0427
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 51425.44 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0423
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 51577.16 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0426
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.30s / 51728.46 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0420
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 51879.83 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0427
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.57s / 52032.40 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0439
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.61s / 52184.01 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0429
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 52335.74 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0439
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.28s / 52488.03 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0421
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.37s / 52640.40 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0427
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.03s / 52792.43 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0423
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.62s / 52944.05 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0416
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 53095.33 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0446
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.54s / 53246.86 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0429
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.86s / 53398.72 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0437
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.85s / 53550.57 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0439
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.41s / 53701.98 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0450
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 150.97s / 53852.95 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0453
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.96s / 54004.91 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0441
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 54156.74 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0429
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.48s / 54309.22 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0435
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.83s / 54460.05 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0443
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.02s / 54612.07 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0419
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.57s / 54764.64 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0421
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.65s / 54917.29 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0424
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.95s / 55069.24 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0440
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.46s / 55220.70 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0429
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.78s / 55372.48 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0426
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.69s / 55524.17 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0423
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.93s / 55676.09 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0417
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.63s / 55827.73 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0413
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.47s / 55979.20 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0420
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.61s / 56130.81 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0413
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.07s / 56281.89 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0410
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 56433.17 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0422
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 150.91s / 56584.08 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0426
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.82s / 56735.91 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0426
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.46s / 56887.37 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0422
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 57039.20 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0409
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.00s / 57191.20 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0416
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.01s / 57343.20 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0415
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 57494.91 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0411
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.77s / 57646.68 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0393
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.42s / 57798.10 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0401
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 57949.30 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0407
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.26s / 58100.56 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0412
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 58252.39 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0415
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.16s / 58404.56 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0413
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 58556.09 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0401
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.32s / 58708.41 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0414
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.34s / 58859.75 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0420
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.93s / 59011.67 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0419
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.00s / 59163.68 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0426
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.33s / 59315.00 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0421
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.04s / 59466.04 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0428
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.74s / 59617.78 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0430
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.12s / 59769.91 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0431
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.06s / 59921.97 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0424
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.30s / 60073.26 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0426
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.94s / 60225.21 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0434
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.51s / 60376.72 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0424
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 150.85s / 60527.57 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0425
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.51s / 60679.08 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0426
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 150.75s / 60829.83 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0422
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.35s / 60981.18 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0418
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.21s / 61133.38 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0432
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.67s / 61285.06 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0419
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.66s / 61436.72 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0437
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.05s / 61588.77 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0441
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.93s / 61740.70 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0429
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 61892.20 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0433
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.59s / 62043.79 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0433
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.24s / 62196.03 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0454
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.43s / 62347.47 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0431
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 62499.20 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0423
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.38s / 62650.57 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0419
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.80s / 62802.37 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0421
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.80s / 62954.17 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0415
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.90s / 63106.07 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0414
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.40s / 63257.47 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0414
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.43s / 63408.90 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0412
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.92s / 63560.82 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0429
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.09s / 63712.91 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0408
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.31s / 63864.23 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0416
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.88s / 64016.11 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0418
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.46s / 64167.57 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0407
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.24s / 64319.81 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0407
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.34s / 64472.15 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0398
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.80s / 64623.95 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0409
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.65s / 64775.60 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0411
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.38s / 64926.98 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0420
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.01s / 65078.99 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0420
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.42s / 65230.41 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0418
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.11s / 65381.52 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0420
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.90s / 65533.42 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0413
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.40s / 65684.82 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0419
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.86s / 65836.68 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0399
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.95s / 65988.62 s
first_0:                 episode reward: -1.4500,                 loss: nan
second_0:                 episode reward: 1.4500,                 loss: 0.0396
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 66140.06 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0386
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.10s / 66292.16 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0397
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.02s / 66444.18 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0399
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.55s / 66595.73 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0397
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 152.28s / 66748.01 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0400
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.07s / 66900.08 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0417
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.27s / 67052.35 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0405
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.19s / 67204.53 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0392
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.29s / 67355.83 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0392
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.08s / 67506.91 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0415
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.05s / 67658.95 s
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0413
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.75s / 67810.71 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0407
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.05s / 67962.75 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0398
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.91s / 68114.67 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0407
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.55s / 68266.22 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0420
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 152.35s / 68418.57 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0405
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.70s / 68570.26 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0413
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 68721.87 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0396
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.26s / 68873.13 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0389
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.57s / 69024.70 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0397
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.58s / 69176.29 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0401
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 69327.77 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0392
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.38s / 69479.15 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0401
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 69630.88 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0400
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.87s / 69782.75 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0400
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.64s / 69934.39 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0397
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.87s / 70086.26 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0397
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 70237.61 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0394
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 70389.45 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0405
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.34s / 70540.78 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0401
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.49s / 70692.27 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0398
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 151.94s / 70844.21 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0408
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.64s / 70995.85 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0408
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.16s / 71148.01 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0409
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.71s / 71299.72 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0415
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.60s / 71451.32 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0423
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.49s / 71603.80 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0422
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 152.74s / 71756.54 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0423
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 151.25s / 71907.78 s
first_0:                 episode reward: -0.9500,                 loss: nan