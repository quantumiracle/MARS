pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f1c068cb518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/20000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/20000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_20000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_20000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.4426s / 7.4426 s
agent0:                 episode reward: 0.0392,                 loss: nan
agent1:                 episode reward: -0.0392,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4016s / 7.8442 s
agent0:                 episode reward: 0.4782,                 loss: nan
agent1:                 episode reward: -0.4782,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3970s / 8.2412 s
agent0:                 episode reward: 0.6269,                 loss: nan
agent1:                 episode reward: -0.6269,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3992s / 8.6403 s
agent0:                 episode reward: 0.1193,                 loss: nan
agent1:                 episode reward: -0.1193,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3980s / 9.0384 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3974s / 9.4358 s
agent0:                 episode reward: 0.2346,                 loss: nan
agent1:                 episode reward: -0.2346,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4013s / 9.8371 s
agent0:                 episode reward: 0.3287,                 loss: nan
agent1:                 episode reward: -0.3287,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3975s / 10.2345 s
agent0:                 episode reward: 0.1592,                 loss: nan
agent1:                 episode reward: -0.1592,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3940s / 10.6285 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 11.0228 s
agent0:                 episode reward: 0.6840,                 loss: nan
agent1:                 episode reward: -0.6840,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3984s / 11.4211 s
agent0:                 episode reward: -0.0387,                 loss: nan
agent1:                 episode reward: 0.0387,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3999s / 11.8210 s
agent0:                 episode reward: -0.0565,                 loss: nan
agent1:                 episode reward: 0.0565,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4016s / 12.2226 s
agent0:                 episode reward: 0.0431,                 loss: nan
agent1:                 episode reward: -0.0431,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 12.6150 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 13.0085 s
agent0:                 episode reward: 0.2926,                 loss: nan
agent1:                 episode reward: -0.2926,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3926s / 13.4012 s
agent0:                 episode reward: 0.2665,                 loss: nan
agent1:                 episode reward: -0.2665,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 13.7918 s
agent0:                 episode reward: 0.5558,                 loss: nan
agent1:                 episode reward: -0.5558,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 14.1860 s
agent0:                 episode reward: -0.1338,                 loss: nan
agent1:                 episode reward: 0.1338,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3890s / 14.5751 s
agent0:                 episode reward: -0.3589,                 loss: nan
agent1:                 episode reward: 0.3589,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3859s / 14.9609 s
agent0:                 episode reward: -0.0442,                 loss: nan
agent1:                 episode reward: 0.0442,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3903s / 15.3513 s
agent0:                 episode reward: 0.7212,                 loss: nan
agent1:                 episode reward: -0.7212,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3908s / 15.7421 s
agent0:                 episode reward: 0.8685,                 loss: nan
agent1:                 episode reward: -0.8685,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 16.1351 s
agent0:                 episode reward: 0.5723,                 loss: nan
agent1:                 episode reward: -0.5723,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3937s / 16.5289 s
agent0:                 episode reward: 0.4227,                 loss: nan
agent1:                 episode reward: -0.4227,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3975s / 16.9263 s
agent0:                 episode reward: 0.0711,                 loss: nan
agent1:                 episode reward: -0.0711,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3968s / 17.3231 s
agent0:                 episode reward: 0.0213,                 loss: nan
agent1:                 episode reward: -0.0213,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3989s / 17.7220 s
agent0:                 episode reward: 0.3219,                 loss: nan
agent1:                 episode reward: -0.3219,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 18.1178 s
agent0:                 episode reward: -0.0875,                 loss: nan
agent1:                 episode reward: 0.0875,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 18.5133 s
agent0:                 episode reward: 0.7221,                 loss: nan
agent1:                 episode reward: -0.7221,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3987s / 18.9120 s
agent0:                 episode reward: 0.6707,                 loss: nan
agent1:                 episode reward: -0.6707,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 19.3081 s
agent0:                 episode reward: 0.4772,                 loss: nan
agent1:                 episode reward: -0.4772,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3926s / 19.7008 s
agent0:                 episode reward: 0.2457,                 loss: nan
agent1:                 episode reward: -0.2457,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3870s / 20.0878 s
agent0:                 episode reward: 0.2025,                 loss: nan
agent1:                 episode reward: -0.2025,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3991s / 20.4869 s
agent0:                 episode reward: 0.1537,                 loss: nan
agent1:                 episode reward: -0.1537,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3966s / 20.8836 s
agent0:                 episode reward: -0.1704,                 loss: nan
agent1:                 episode reward: 0.1704,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4010s / 21.2846 s
agent0:                 episode reward: 0.2930,                 loss: nan
agent1:                 episode reward: -0.2930,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3894s / 21.6740 s
agent0:                 episode reward: 0.4069,                 loss: nan
agent1:                 episode reward: -0.4069,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3929s / 22.0669 s
agent0:                 episode reward: 0.5882,                 loss: nan
agent1:                 episode reward: -0.5882,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3815s / 22.4483 s
agent0:                 episode reward: -0.1037,                 loss: nan
agent1:                 episode reward: 0.1037,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3968s / 22.8451 s
agent0:                 episode reward: 0.2219,                 loss: nan
agent1:                 episode reward: -0.2219,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3895s / 23.2346 s
agent0:                 episode reward: 0.5939,                 loss: nan
agent1:                 episode reward: -0.5939,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3980s / 23.6327 s
agent0:                 episode reward: 0.0672,                 loss: nan
agent1:                 episode reward: -0.0672,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 24.0270 s
agent0:                 episode reward: 0.0243,                 loss: nan
agent1:                 episode reward: -0.0243,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3894s / 24.4164 s
agent0:                 episode reward: -0.0888,                 loss: nan
agent1:                 episode reward: 0.0888,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3906s / 24.8071 s
agent0:                 episode reward: -0.1807,                 loss: nan
agent1:                 episode reward: 0.1807,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 25.2016 s
agent0:                 episode reward: 0.5325,                 loss: nan
agent1:                 episode reward: -0.5325,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3929s / 25.5945 s
agent0:                 episode reward: 0.1363,                 loss: nan
agent1:                 episode reward: -0.1363,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3895s / 25.9840 s
agent0:                 episode reward: -0.1375,                 loss: nan
agent1:                 episode reward: 0.1375,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3993s / 26.3834 s
agent0:                 episode reward: -0.0929,                 loss: nan
agent1:                 episode reward: 0.0929,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3875s / 26.7709 s
agent0:                 episode reward: 0.6200,                 loss: nan
agent1:                 episode reward: -0.6200,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4005s / 27.1714 s
agent0:                 episode reward: -0.6084,                 loss: nan
agent1:                 episode reward: 0.6084,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 27.5656 s
agent0:                 episode reward: 1.0379,                 loss: nan
agent1:                 episode reward: -1.0379,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3983s / 27.9639 s
agent0:                 episode reward: 0.2834,                 loss: nan
agent1:                 episode reward: -0.2834,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3920s / 28.3559 s
agent0:                 episode reward: 0.3683,                 loss: nan
agent1:                 episode reward: -0.3683,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 28.7517 s
agent0:                 episode reward: 0.5197,                 loss: nan
agent1:                 episode reward: -0.5197,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4011s / 29.1528 s
agent0:                 episode reward: 0.3264,                 loss: nan
agent1:                 episode reward: -0.3264,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 29.5462 s
agent0:                 episode reward: 0.7080,                 loss: nan
agent1:                 episode reward: -0.7080,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3873s / 29.9335 s
agent0:                 episode reward: 0.4970,                 loss: nan
agent1:                 episode reward: -0.4970,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 30.3297 s
agent0:                 episode reward: 0.2400,                 loss: nan
agent1:                 episode reward: -0.2400,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 30.7231 s
agent0:                 episode reward: 0.6486,                 loss: nan
agent1:                 episode reward: -0.6486,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3979s / 31.1211 s
agent0:                 episode reward: 0.3558,                 loss: nan
agent1:                 episode reward: -0.3558,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 31.5145 s
agent0:                 episode reward: -0.1811,                 loss: nan
agent1:                 episode reward: 0.1811,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3932s / 31.9077 s
agent0:                 episode reward: 0.0452,                 loss: nan
agent1:                 episode reward: -0.0452,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 32.3007 s
agent0:                 episode reward: 0.3456,                 loss: nan
agent1:                 episode reward: -0.3456,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 32.6965 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3988s / 33.0953 s
agent0:                 episode reward: 0.3412,                 loss: nan
agent1:                 episode reward: -0.3412,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3937s / 33.4890 s
agent0:                 episode reward: 0.0122,                 loss: nan
agent1:                 episode reward: -0.0122,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3922s / 33.8811 s
agent0:                 episode reward: 0.4124,                 loss: nan
agent1:                 episode reward: -0.4124,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3910s / 34.2722 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 34.6645 s
agent0:                 episode reward: -0.1154,                 loss: nan
agent1:                 episode reward: 0.1154,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3840s / 35.0485 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3914s / 35.4399 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3963s / 35.8362 s
agent0:                 episode reward: 0.5554,                 loss: nan
agent1:                 episode reward: -0.5554,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3829s / 36.2191 s
agent0:                 episode reward: 0.5121,                 loss: nan
agent1:                 episode reward: -0.5121,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3896s / 36.6087 s
agent0:                 episode reward: 0.0321,                 loss: nan
agent1:                 episode reward: -0.0321,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3918s / 37.0005 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3431s / 37.3436 s
agent0:                 episode reward: 0.1691,                 loss: nan
agent1:                 episode reward: -0.1691,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4265s / 37.7701 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3904s / 38.1605 s
agent0:                 episode reward: 0.2610,                 loss: nan
agent1:                 episode reward: -0.2610,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3901s / 38.5506 s
agent0:                 episode reward: 1.0189,                 loss: nan
agent1:                 episode reward: -1.0189,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3905s / 38.9411 s
agent0:                 episode reward: 0.5418,                 loss: nan
agent1:                 episode reward: -0.5418,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3911s / 39.3322 s
agent0:                 episode reward: 0.2562,                 loss: nan
agent1:                 episode reward: -0.2562,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 39.7256 s
agent0:                 episode reward: 0.2660,                 loss: nan
agent1:                 episode reward: -0.2660,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3200s / 40.0456 s
agent0:                 episode reward: 0.1293,                 loss: nan
agent1:                 episode reward: -0.1293,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.0398s / 42.0854 s
agent0:                 episode reward: 0.2275,                 loss: nan
agent1:                 episode reward: -0.2275,                 loss: 0.4532
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1580s / 43.2434 s
agent0:                 episode reward: 0.3985,                 loss: nan
agent1:                 episode reward: -0.3985,                 loss: 0.4015
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1712s / 44.4145 s
agent0:                 episode reward: 0.2049,                 loss: nan
agent1:                 episode reward: -0.2049,                 loss: 0.3854
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1377s / 45.5522 s
agent0:                 episode reward: 0.7795,                 loss: nan
agent1:                 episode reward: -0.7795,                 loss: 0.3696
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1380s / 46.6902 s
agent0:                 episode reward: 0.1948,                 loss: nan
agent1:                 episode reward: -0.1948,                 loss: 0.3512
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1332s / 47.8235 s
agent0:                 episode reward: 0.5608,                 loss: nan
agent1:                 episode reward: -0.5608,                 loss: 0.3303
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1345s / 48.9580 s
agent0:                 episode reward: 0.2289,                 loss: nan
agent1:                 episode reward: -0.2289,                 loss: 0.3143
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1456s / 50.1036 s
agent0:                 episode reward: 0.3237,                 loss: nan
agent1:                 episode reward: -0.3237,                 loss: 0.2987
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1459s / 51.2495 s
agent0:                 episode reward: 0.2114,                 loss: nan
agent1:                 episode reward: -0.2114,                 loss: 0.3357
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1480s / 52.3975 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.3982
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1357s / 53.5332 s
agent0:                 episode reward: 0.3295,                 loss: nan
agent1:                 episode reward: -0.3295,                 loss: 0.3952
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1395s / 54.6727 s
agent0:                 episode reward: -0.3688,                 loss: nan
agent1:                 episode reward: 0.3688,                 loss: 0.3933
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1424s / 55.8151 s
agent0:                 episode reward: 0.0418,                 loss: nan
agent1:                 episode reward: -0.0418,                 loss: 0.3915
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1409s / 56.9560 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.3927
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1431s / 58.0991 s
agent0:                 episode reward: 0.4962,                 loss: nan
agent1:                 episode reward: -0.4962,                 loss: 0.3917
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1291s / 59.2282 s
agent0:                 episode reward: 0.1664,                 loss: nan
agent1:                 episode reward: -0.1664,                 loss: 0.3904
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1438s / 60.3720 s
agent0:                 episode reward: -0.0391,                 loss: nan
agent1:                 episode reward: 0.0391,                 loss: 0.3928
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1575s / 61.5295 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.4186
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1556s / 62.6850 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.4101
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1521s / 63.8371 s
agent0:                 episode reward: 0.2918,                 loss: nan