pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 492.0,                last time consumption/overall running time: 4.1580s / 4.1580 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0204
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0033
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 567.25,                last time consumption/overall running time: 63.1895s / 67.3475 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0202
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 585.05,                last time consumption/overall running time: 64.4575s / 131.8049 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1504
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1597
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 578.55,                last time consumption/overall running time: 86.9314s / 218.7364 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.1702
env0_second_0:                 episode reward: -1.5000,                 loss: 0.1737
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 578.8,                last time consumption/overall running time: 126.1323s / 344.8687 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1786
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1743
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 616.1,                last time consumption/overall running time: 184.1493s / 529.0179 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.1988
env0_second_0:                 episode reward: -0.6500,                 loss: 0.1911
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 585.3,                last time consumption/overall running time: 175.6782s / 704.6962 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.1664
env0_second_0:                 episode reward: -0.9500,                 loss: 0.1507
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 582.1,                last time consumption/overall running time: 175.9107s / 880.6069 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.1934
env0_second_0:                 episode reward: -0.9500,                 loss: 0.1946
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 543.6,                last time consumption/overall running time: 165.4458s / 1046.0527 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.1976
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1925
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 556.8,                last time consumption/overall running time: 169.4863s / 1215.5391 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2118
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2152
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 569.6,                last time consumption/overall running time: 171.9140s / 1387.4530 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2142
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2074
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 558.2,                last time consumption/overall running time: 168.6912s / 1556.1442 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2129
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2107
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 554.65,                last time consumption/overall running time: 170.6138s / 1726.7580 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2190
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2239
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 577.7,                last time consumption/overall running time: 174.1542s / 1900.9122 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2276
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2349
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 612.1,                last time consumption/overall running time: 183.5098s / 2084.4220 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2217
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2221
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 568.0,                last time consumption/overall running time: 170.9475s / 2255.3695 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2061
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2188
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 552.1,                last time consumption/overall running time: 167.4610s / 2422.8305 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2245
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2296
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 597.75,                last time consumption/overall running time: 177.8279s / 2600.6584 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1929
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2075
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 576.45,                last time consumption/overall running time: 175.0102s / 2775.6686 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1987
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2001
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 576.75,                last time consumption/overall running time: 173.1214s / 2948.7900 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2275
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2239
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 577.1,                last time consumption/overall running time: 173.7604s / 3122.5505 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2348
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2417
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 585.0,                last time consumption/overall running time: 175.6977s / 3298.2482 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2257
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2234
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 575.45,                last time consumption/overall running time: 174.4322s / 3472.6803 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2241
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2290
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 586.1,                last time consumption/overall running time: 177.5890s / 3650.2693 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2431
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2537
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 578.05,                last time consumption/overall running time: 173.5914s / 3823.8607 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2647
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2629
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 550.5,                last time consumption/overall running time: 167.3334s / 3991.1941 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2588
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2695
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 587.9,                last time consumption/overall running time: 177.0656s / 4168.2597 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2351
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2320
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 555.4,                last time consumption/overall running time: 167.5318s / 4335.7915 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2375
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2369
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 585.8,                last time consumption/overall running time: 176.8009s / 4512.5924 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2522
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2489
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 586.55,                last time consumption/overall running time: 176.4850s / 4689.0773 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2269
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2295
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 578.65,                last time consumption/overall running time: 174.7159s / 4863.7933 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2386
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2373
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 606.2,                last time consumption/overall running time: 182.2465s / 5046.0398 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2521
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2513
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 543.65,                last time consumption/overall running time: 167.0376s / 5213.0774 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2507
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2556
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 570.05,                last time consumption/overall running time: 171.2211s / 5384.2985 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2470
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2600
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 577.25,                last time consumption/overall running time: 174.8401s / 5559.1386 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2599
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2661
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 554.55,                last time consumption/overall running time: 169.4297s / 5728.5683 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2637
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2699
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 550.1,                last time consumption/overall running time: 167.4611s / 5896.0294 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2303
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2292
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 624.5,                last time consumption/overall running time: 186.4811s / 6082.5105 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2417
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2476
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 563.5,                last time consumption/overall running time: 172.2975s / 6254.8081 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2320
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2368
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 567.65,                last time consumption/overall running time: 171.4861s / 6426.2942 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2210
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2280
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 614.7,                last time consumption/overall running time: 184.9391s / 6611.2333 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2425
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2414
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 593.25,                last time consumption/overall running time: 178.4121s / 6789.6453 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2183
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2236
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 591.2,                last time consumption/overall running time: 178.0283s / 6967.6737 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2451
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2565
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 588.85,                last time consumption/overall running time: 176.8830s / 7144.5567 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2237
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2204
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 614.25,                last time consumption/overall running time: 184.2199s / 7328.7765 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2557
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2450
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 594.45,                last time consumption/overall running time: 181.3633s / 7510.1399 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2421
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2486
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 611.75,                last time consumption/overall running time: 182.0181s / 7692.1580 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2554
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2472
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 603.2,                last time consumption/overall running time: 181.3336s / 7873.4916 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2492
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2530
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 588.15,                last time consumption/overall running time: 178.6335s / 8052.1251 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2231
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2263
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 603.9,                last time consumption/overall running time: 180.5929s / 8232.7179 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2407
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2356
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 568.55,                last time consumption/overall running time: 171.4703s / 8404.1883 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2406
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2422
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 577.7,                last time consumption/overall running time: 174.7207s / 8578.9090 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2505
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2499
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 580.55,                last time consumption/overall running time: 175.0012s / 8753.9101 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2498
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2575
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 582.25,                last time consumption/overall running time: 175.1308s / 8929.0409 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2308
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2388
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 604.6,                last time consumption/overall running time: 180.8957s / 9109.9366 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2477
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2458
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 574.7,                last time consumption/overall running time: 171.6188s / 9281.5554 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2440
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2478
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 591.6,                last time consumption/overall running time: 177.6128s / 9459.1681 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2299
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2416
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 580.2,                last time consumption/overall running time: 175.1279s / 9634.2960 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2593
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2815
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 633.15,                last time consumption/overall running time: 190.2219s / 9824.5179 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2521
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 605.65,                last time consumption/overall running time: 181.2908s / 10005.8087 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2402
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2369
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 568.2,                last time consumption/overall running time: 171.0794s / 10176.8881 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2299
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2324
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 574.25,                last time consumption/overall running time: 173.2863s / 10350.1744 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2409
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2390
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 577.4,                last time consumption/overall running time: 174.0052s / 10524.1796 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2307
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2313
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 547.9,                last time consumption/overall running time: 166.5818s / 10690.7614 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2493
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2456
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 561.7,                last time consumption/overall running time: 169.7832s / 10860.5446 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2497
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2733
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 574.25,                last time consumption/overall running time: 172.3205s / 11032.8651 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2485
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2563
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 572.35,                last time consumption/overall running time: 173.4791s / 11206.3442 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2444
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2442
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 583.25,                last time consumption/overall running time: 177.6868s / 11384.0310 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2340
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2471
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 555.9,                last time consumption/overall running time: 166.9784s / 11551.0094 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2482
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2430
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 578.05,                last time consumption/overall running time: 175.2528s / 11726.2622 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2624
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2641
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 561.05,                last time consumption/overall running time: 167.2936s / 11893.5558 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2541
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2597
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 595.35,                last time consumption/overall running time: 179.1098s / 12072.6656 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2405
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2546
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 563.4,                last time consumption/overall running time: 167.7575s / 12240.4231 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.2424
env0_second_0:                 episode reward: -1.3500,                 loss: 0.2410
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 538.95,                last time consumption/overall running time: 165.2804s / 12405.7035 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2667
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2681
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 561.95,                last time consumption/overall running time: 169.1171s / 12574.8207 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2505
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2497
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 583.4,                last time consumption/overall running time: 173.7675s / 12748.5882 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2689
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2840
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 574.65,                last time consumption/overall running time: 172.1194s / 12920.7076 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2730
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2785
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 578.55,                last time consumption/overall running time: 173.6658s / 13094.3734 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2695
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2605
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 544.45,                last time consumption/overall running time: 163.1616s / 13257.5350 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2628
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2625
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 565.9,                last time consumption/overall running time: 171.0182s / 13428.5532 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2393
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2614
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 568.2,                last time consumption/overall running time: 172.6431s / 13601.1963 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2657
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2731
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 573.3,                last time consumption/overall running time: 171.5958s / 13772.7921 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2310
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2303
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 553.25,                last time consumption/overall running time: 166.4529s / 13939.2450 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2590
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2715
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 570.85,                last time consumption/overall running time: 171.5396s / 14110.7846 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2593
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2526
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 568.7,                last time consumption/overall running time: 172.2785s / 14283.0631 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2556
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2495
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 580.1,                last time consumption/overall running time: 173.3475s / 14456.4106 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2685
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2816
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 564.95,                last time consumption/overall running time: 169.6940s / 14626.1046 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2664
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2736
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 554.65,                last time consumption/overall running time: 167.1408s / 14793.2455 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2430
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2529
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 561.9,                last time consumption/overall running time: 169.5249s / 14962.7704 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2672
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2656
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 545.65,                last time consumption/overall running time: 163.7862s / 15126.5566 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2473
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2495
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 553.05,                last time consumption/overall running time: 166.6708s / 15293.2274 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2450
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2384
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 572.4,                last time consumption/overall running time: 172.4446s / 15465.6721 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2897
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2900
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 553.75,                last time consumption/overall running time: 165.4980s / 15631.1701 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2737
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2825
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 552.7,                last time consumption/overall running time: 167.7200s / 15798.8901 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2721
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2767
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 569.15,                last time consumption/overall running time: 171.6965s / 15970.5866 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2659
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2719
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 598.65,                last time consumption/overall running time: 179.7932s / 16150.3798 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2706
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2711
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 580.0,                last time consumption/overall running time: 173.9235s / 16324.3032 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2798
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2889
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 540.25,                last time consumption/overall running time: 163.5606s / 16487.8638 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2637
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2740
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 545.75,                last time consumption/overall running time: 163.8267s / 16651.6905 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2671
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2694
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 619.3,                last time consumption/overall running time: 185.2605s / 16836.9511 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2700
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2699
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 559.7,                last time consumption/overall running time: 166.8709s / 17003.8220 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2836
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2763
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 603.5,                last time consumption/overall running time: 181.9422s / 17185.7642 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2721
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2822
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 564.55,                last time consumption/overall running time: 170.0808s / 17355.8450 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2710
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2852
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 583.05,                last time consumption/overall running time: 174.5435s / 17530.3885 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2512
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2597
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 558.5,                last time consumption/overall running time: 167.6054s / 17697.9939 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2737
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2738
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 587.0,                last time consumption/overall running time: 175.6897s / 17873.6835 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2523
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2521
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 556.7,                last time consumption/overall running time: 167.4792s / 18041.1627 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2682
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2752
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 548.9,                last time consumption/overall running time: 165.2873s / 18206.4500 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2686
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2714
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 578.75,                last time consumption/overall running time: 175.4188s / 18381.8688 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2566
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2587
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 548.8,                last time consumption/overall running time: 163.8188s / 18545.6876 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2836
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2825
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 585.65,                last time consumption/overall running time: 174.1417s / 18719.8293 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2742
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2720
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 580.0,                last time consumption/overall running time: 176.5456s / 18896.3749 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2796
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2808
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 585.05,                last time consumption/overall running time: 175.2551s / 19071.6300 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2642
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2669
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 556.3,                last time consumption/overall running time: 166.5319s / 19238.1620 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2533
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2584
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 575.85,                last time consumption/overall running time: 172.7438s / 19410.9057 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2418
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2470
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 598.4,                last time consumption/overall running time: 179.2868s / 19590.1925 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2826
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2815
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 570.3,                last time consumption/overall running time: 171.4897s / 19761.6822 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2692
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2851
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 555.25,                last time consumption/overall running time: 167.2493s / 19928.9315 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2486
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2574
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 578.5,                last time consumption/overall running time: 173.7722s / 20102.7037 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2802
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2843
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 572.25,                last time consumption/overall running time: 169.7679s / 20272.4716 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2489
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2572
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 562.45,                last time consumption/overall running time: 168.9476s / 20441.4193 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2415
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2407
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 580.9,                last time consumption/overall running time: 172.7468s / 20614.1661 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2765
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2799
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 556.7,                last time consumption/overall running time: 167.6515s / 20781.8176 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2651
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2787
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 557.2,                last time consumption/overall running time: 167.8544s / 20949.6720 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2583
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2626
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 582.0,                last time consumption/overall running time: 174.6919s / 21124.3638 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2563
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2684
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 531.4,                last time consumption/overall running time: 161.4870s / 21285.8508 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2624
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2672
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 567.95,                last time consumption/overall running time: 170.3599s / 21456.2107 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2739
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2777
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 572.75,                last time consumption/overall running time: 171.5827s / 21627.7934 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2767
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2785
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 624.85,                last time consumption/overall running time: 184.3830s / 21812.1765 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2875
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2802
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 597.35,                last time consumption/overall running time: 178.8299s / 21991.0064 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2585
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2654
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 586.1,                last time consumption/overall running time: 175.7681s / 22166.7745 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2445
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2465
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 584.3,                last time consumption/overall running time: 174.4527s / 22341.2272 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2523
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2420
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 589.1,                last time consumption/overall running time: 176.6598s / 22517.8869 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2638
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2741
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 581.0,                last time consumption/overall running time: 174.0846s / 22691.9716 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2496
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2483
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 600.8,                last time consumption/overall running time: 179.1268s / 22871.0984 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2602
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2692
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 569.9,                last time consumption/overall running time: 171.4828s / 23042.5811 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2667
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2644
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 588.75,                last time consumption/overall running time: 176.2911s / 23218.8722 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2535
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2666
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 559.9,                last time consumption/overall running time: 167.2517s / 23386.1239 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2760
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2763
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 561.95,                last time consumption/overall running time: 168.2534s / 23554.3773 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2699
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2740
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 548.3,                last time consumption/overall running time: 165.6643s / 23720.0416 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2896
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2869
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 556.65,                last time consumption/overall running time: 167.1627s / 23887.2043 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2648
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2697
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 544.1,                last time consumption/overall running time: 165.1962s / 24052.4006 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2741
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2837
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 557.45,                last time consumption/overall running time: 167.2859s / 24219.6865 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2684
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2717
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 558.8,                last time consumption/overall running time: 169.6344s / 24389.3209 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2508
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2513
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 575.9,                last time consumption/overall running time: 174.4103s / 24563.7312 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2678
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2734
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 571.45,                last time consumption/overall running time: 169.5205s / 24733.2516 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2600
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2697
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 574.35,                last time consumption/overall running time: 171.3670s / 24904.6186 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2513
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2616
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 561.7,                last time consumption/overall running time: 169.8335s / 25074.4521 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2633
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2632
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 572.75,                last time consumption/overall running time: 169.8554s / 25244.3075 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2733
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2732
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 560.2,                last time consumption/overall running time: 168.3920s / 25412.6995 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2516
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2531
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 556.3,                last time consumption/overall running time: 170.6312s / 25583.3307 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2647
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2634
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 559.6,                last time consumption/overall running time: 166.4049s / 25749.7356 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2662
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2680
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 579.6,                last time consumption/overall running time: 174.3997s / 25924.1353 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2563
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2716
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 553.3,                last time consumption/overall running time: 165.4097s / 26089.5450 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2493
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2488
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 543.8,                last time consumption/overall running time: 163.9231s / 26253.4681 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2589
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2757
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 588.65,                last time consumption/overall running time: 174.9687s / 26428.4368 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2635
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2556
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 564.35,                last time consumption/overall running time: 168.4343s / 26596.8710 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2663
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2738
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 578.75,                last time consumption/overall running time: 173.4972s / 26770.3683 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2737
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2694
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 561.55,                last time consumption/overall running time: 167.7855s / 26938.1537 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2469
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2636
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 626.5,                last time consumption/overall running time: 187.2315s / 27125.3853 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2374
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2630
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 589.15,                last time consumption/overall running time: 175.6042s / 27300.9895 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2770
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2808
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 541.05,                last time consumption/overall running time: 162.5117s / 27463.5011 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2618
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2682
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 565.05,                last time consumption/overall running time: 168.4999s / 27632.0010 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2466
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2546
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 576.4,                last time consumption/overall running time: 173.8182s / 27805.8193 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2527
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2618
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 571.75,                last time consumption/overall running time: 171.3910s / 27977.2103 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2855
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3072
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 568.35,                last time consumption/overall running time: 169.2159s / 28146.4262 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2731
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 589.75,                last time consumption/overall running time: 177.2337s / 28323.6600 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2498
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2557
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 576.0,                last time consumption/overall running time: 171.9363s / 28495.5962 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2531
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2544
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 565.35,                last time consumption/overall running time: 169.7150s / 28665.3113 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2551
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2688
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 564.05,                last time consumption/overall running time: 169.3736s / 28834.6848 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2695
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2725
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 589.1,                last time consumption/overall running time: 174.6838s / 29009.3686 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2835
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2893
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 613.45,                last time consumption/overall running time: 182.7773s / 29192.1459 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2584
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2641
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 556.45,                last time consumption/overall running time: 166.9961s / 29359.1421 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2744
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2861
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 534.3,                last time consumption/overall running time: 162.3911s / 29521.5332 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2508
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2549
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 578.8,                last time consumption/overall running time: 172.6737s / 29694.2069 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2429
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2536
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 569.15,                last time consumption/overall running time: 171.7913s / 29865.9983 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2631
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2721
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 596.25,                last time consumption/overall running time: 177.3172s / 30043.3154 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2680
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 561.15,                last time consumption/overall running time: 168.8107s / 30212.1262 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2446
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2462
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 599.5,                last time consumption/overall running time: 177.0502s / 30389.1764 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2553
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2734
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 563.25,                last time consumption/overall running time: 168.1473s / 30557.3237 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2790
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2739
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 578.2,                last time consumption/overall running time: 173.5955s / 30730.9191 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2615
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2601
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 614.05,                last time consumption/overall running time: 182.9479s / 30913.8670 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2906
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2953
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 568.05,                last time consumption/overall running time: 170.9791s / 31084.8461 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2872
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2935
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 562.25,                last time consumption/overall running time: 169.2311s / 31254.0773 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2891
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2929
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 567.5,                last time consumption/overall running time: 170.1681s / 31424.2453 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2628
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2814
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 575.1,                last time consumption/overall running time: 172.3415s / 31596.5868 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2734
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3016
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 565.2,                last time consumption/overall running time: 169.1228s / 31765.7096 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2639
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2902
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 567.4,                last time consumption/overall running time: 169.1720s / 31934.8816 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2638
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2562
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 581.25,                last time consumption/overall running time: 173.6278s / 32108.5094 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2743
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2705
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 530.1,                last time consumption/overall running time: 160.2049s / 32268.7143 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2644
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2732
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 537.7,                last time consumption/overall running time: 162.1085s / 32430.8228 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2570
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2725
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 544.35,                last time consumption/overall running time: 163.0917s / 32593.9145 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2614
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2612
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 542.05,                last time consumption/overall running time: 163.7732s / 32757.6877 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2617
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2664
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 589.1,                last time consumption/overall running time: 177.2075s / 32934.8952 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2617
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2636
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 543.75,                last time consumption/overall running time: 164.6411s / 33099.5362 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2392
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2286
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 571.75,                last time consumption/overall running time: 170.8359s / 33270.3721 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2804
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2783
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 559.25,                last time consumption/overall running time: 166.4035s / 33436.7756 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2617
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2582
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 561.0,                last time consumption/overall running time: 167.5075s / 33604.2831 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2491
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2591
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 584.65,                last time consumption/overall running time: 173.9603s / 33778.2433 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2573
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2623
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 555.25,                last time consumption/overall running time: 166.8485s / 33945.0918 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2444
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2440
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 615.25,                last time consumption/overall running time: 183.0520s / 34128.1439 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2387
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2462
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 583.8,                last time consumption/overall running time: 174.7215s / 34302.8654 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2518
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2538
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 592.65,                last time consumption/overall running time: 178.6528s / 34481.5182 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2455
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2487
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 624.35,                last time consumption/overall running time: 183.8416s / 34665.3598 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2365
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2439
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 575.8,                last time consumption/overall running time: 172.7031s / 34838.0629 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2522
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2549
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 586.45,                last time consumption/overall running time: 173.7058s / 35011.7688 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2464
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2431
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 573.75,                last time consumption/overall running time: 173.0700s / 35184.8388 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2721
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2988
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 588.1,                last time consumption/overall running time: 174.9546s / 35359.7934 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2707
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2887
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 589.1,                last time consumption/overall running time: 173.8766s / 35533.6700 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2799
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3061
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 601.35,                last time consumption/overall running time: 178.9743s / 35712.6442 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2597
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2765
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 596.1,                last time consumption/overall running time: 178.7489s / 35891.3931 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2453
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2736
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 587.1,                last time consumption/overall running time: 174.9628s / 36066.3559 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2648
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2758
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 626.2,                last time consumption/overall running time: 184.6304s / 36250.9864 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2311
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2469
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 595.2,                last time consumption/overall running time: 177.6271s / 36428.6134 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2503
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2634
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 560.4,                last time consumption/overall running time: 168.1597s / 36596.7731 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2814
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2951
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 566.7,                last time consumption/overall running time: 171.5956s / 36768.3687 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2888
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2997
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 578.4,                last time consumption/overall running time: 173.6263s / 36941.9950 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3030
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3241
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 541.0,                last time consumption/overall running time: 162.1008s / 37104.0958 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2902
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3024
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 558.85,                last time consumption/overall running time: 168.9597s / 37273.0555 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2947
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3086
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 542.2,                last time consumption/overall running time: 169.9815s / 37443.0369 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3101
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3364
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 583.0,                last time consumption/overall running time: 198.2942s / 37641.3312 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2894
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3098
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 570.55,                last time consumption/overall running time: 195.8220s / 37837.1531 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2895
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2974
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 597.5,                last time consumption/overall running time: 215.4725s / 38052.6256 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2874
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3095
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 556.3,                last time consumption/overall running time: 203.4279s / 38256.0536 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2809
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2916
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 547.35,                last time consumption/overall running time: 201.7020s / 38457.7555 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2858
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2935
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 529.55,                last time consumption/overall running time: 192.0895s / 38649.8450 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2812
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2821
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 585.4,                last time consumption/overall running time: 212.2752s / 38862.1202 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2912
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3015
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 531.15,                last time consumption/overall running time: 194.9014s / 39057.0216 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2902
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2965
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 543.45,                last time consumption/overall running time: 199.1224s / 39256.1440 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2697
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2758
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 574.4,                last time consumption/overall running time: 210.7586s / 39466.9026 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2810
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3032
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 589.55,                last time consumption/overall running time: 213.4362s / 39680.3388 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2740
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2866
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 542.45,                last time consumption/overall running time: 199.0813s / 39879.4201 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2475
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2615
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 549.0,                last time consumption/overall running time: 199.7872s / 40079.2073 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2523
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2800
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 556.5,                last time consumption/overall running time: 202.8623s / 40282.0697 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2747
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2998
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 602.15,                last time consumption/overall running time: 216.0724s / 40498.1421 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2851
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3001
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 568.85,                last time consumption/overall running time: 210.0853s / 40708.2273 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2860
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3002
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 571.85,                last time consumption/overall running time: 207.9787s / 40916.2061 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2925
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3073
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 548.95,                last time consumption/overall running time: 199.6144s / 41115.8205 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2889
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3015
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 595.15,                last time consumption/overall running time: 214.7130s / 41330.5335 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3010
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3306
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 585.0,                last time consumption/overall running time: 212.0038s / 41542.5374 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2986
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3115
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 534.15,                last time consumption/overall running time: 194.7449s / 41737.2823 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2807
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3074
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 575.95,                last time consumption/overall running time: 209.7704s / 41947.0527 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2852
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3058
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 590.35,                last time consumption/overall running time: 214.5609s / 42161.6136 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2871
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3011
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 582.65,                last time consumption/overall running time: 211.7864s / 42373.4000 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2881
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3022
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 581.5,                last time consumption/overall running time: 212.1080s / 42585.5080 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3008
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3102
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 569.5,                last time consumption/overall running time: 208.8244s / 42794.3324 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2934
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3056
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 544.95,                last time consumption/overall running time: 199.6833s / 42994.0157 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2677
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2770
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 555.8,                last time consumption/overall running time: 201.4899s / 43195.5056 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3053
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3141
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 566.85,                last time consumption/overall running time: 206.7041s / 43402.2096 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3132
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3276
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 595.25,                last time consumption/overall running time: 215.0717s / 43617.2814 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3036
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3189
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 559.05,                last time consumption/overall running time: 204.0638s / 43821.3452 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2823
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2991
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 565.05,                last time consumption/overall running time: 207.0195s / 44028.3648 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3069
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3154
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 509.0,                last time consumption/overall running time: 187.9254s / 44216.2902 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2658
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2898
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 545.55,                last time consumption/overall running time: 199.7788s / 44416.0690 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2759
env0_second_0:                 episode reward: 1.4500,                 loss: 0.2919
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 538.95,                last time consumption/overall running time: 198.5649s / 44614.6339 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2797
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2965
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 558.4,                last time consumption/overall running time: 204.7240s / 44819.3579 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2888
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3082
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 542.55,                last time consumption/overall running time: 197.8631s / 45017.2211 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3036
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3102
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 588.3,                last time consumption/overall running time: 213.3531s / 45230.5742 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2962
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 556.3,                last time consumption/overall running time: 202.3428s / 45432.9170 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2981
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3092
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 551.1,                last time consumption/overall running time: 200.8408s / 45633.7578 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3036
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3130
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 531.65,                last time consumption/overall running time: 194.7743s / 45828.5321 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2804
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2920
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 549.9,                last time consumption/overall running time: 202.6772s / 46031.2093 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2762
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2768
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 583.45,                last time consumption/overall running time: 211.9450s / 46243.1543 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2977
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2966
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 577.6,                last time consumption/overall running time: 209.2305s / 46452.3848 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2709
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2746
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 581.8,                last time consumption/overall running time: 211.6277s / 46664.0126 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2814
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2857
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 534.05,                last time consumption/overall running time: 195.0264s / 46859.0389 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2897
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2951
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 576.6,                last time consumption/overall running time: 207.9746s / 47067.0136 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2848
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2946
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 562.9,                last time consumption/overall running time: 205.9169s / 47272.9305 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2880
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2979
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 586.3,                last time consumption/overall running time: 212.5941s / 47485.5246 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2866
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2943
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 533.85,                last time consumption/overall running time: 195.8544s / 47681.3791 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2916
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3003
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 589.1,                last time consumption/overall running time: 213.6613s / 47895.0404 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2701
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2896
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 561.35,                last time consumption/overall running time: 204.4072s / 48099.4475 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2799
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2876
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 576.2,                last time consumption/overall running time: 209.8389s / 48309.2865 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2660
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2700
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 569.45,                last time consumption/overall running time: 208.0827s / 48517.3691 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2965
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 530.6,                last time consumption/overall running time: 194.0065s / 48711.3756 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2572
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2649
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 577.0,                last time consumption/overall running time: 208.1886s / 48919.5642 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2702
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2804
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 535.3,                last time consumption/overall running time: 196.1072s / 49115.6714 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2558
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2513
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 526.95,                last time consumption/overall running time: 193.7601s / 49309.4315 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2757
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2807
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 594.3,                last time consumption/overall running time: 215.0434s / 49524.4749 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2461
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2587
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 591.25,                last time consumption/overall running time: 213.5964s / 49738.0713 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2671
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2894
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 559.25,                last time consumption/overall running time: 202.6546s / 49940.7259 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2687
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2848
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 590.9,                last time consumption/overall running time: 213.3579s / 50154.0838 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2759
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2898
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 582.1,                last time consumption/overall running time: 211.7977s / 50365.8815 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2757
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2902
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 604.6,                last time consumption/overall running time: 219.4108s / 50585.2923 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2609
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2636
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 535.35,                last time consumption/overall running time: 194.5064s / 50779.7987 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2683
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2823
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 589.4,                last time consumption/overall running time: 214.3663s / 50994.1650 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3047
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3068
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 570.65,                last time consumption/overall running time: 207.6335s / 51201.7985 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2639
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2737
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 591.1,                last time consumption/overall running time: 216.9468s / 51418.7453 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2992
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2973
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 583.5,                last time consumption/overall running time: 209.5033s / 51628.2486 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2553
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2661
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 546.1,                last time consumption/overall running time: 197.8568s / 51826.1054 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2413
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2499
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 571.1,                last time consumption/overall running time: 207.8734s / 52033.9788 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2913
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3049
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 580.6,                last time consumption/overall running time: 212.2096s / 52246.1885 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2624
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2628
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 513.4,                last time consumption/overall running time: 189.1707s / 52435.3592 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2630
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2753
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 540.35,                last time consumption/overall running time: 197.1652s / 52632.5244 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2814
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2966
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 553.5,                last time consumption/overall running time: 201.0583s / 52833.5827 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2768
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3024
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 583.0,                last time consumption/overall running time: 210.3750s / 53043.9577 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2737
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2774
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 581.95,                last time consumption/overall running time: 211.6270s / 53255.5847 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2834
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2942
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 557.1,                last time consumption/overall running time: 202.9259s / 53458.5106 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2631
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2690
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 598.65,                last time consumption/overall running time: 216.5634s / 53675.0740 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2562
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2753
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 552.0,                last time consumption/overall running time: 201.7244s / 53876.7984 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2762
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2824
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 571.15,                last time consumption/overall running time: 207.6962s / 54084.4945 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2712
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2895
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 572.2,                last time consumption/overall running time: 206.0757s / 54290.5702 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2969
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2903
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 579.8,                last time consumption/overall running time: 211.3629s / 54501.9331 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2700
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2762
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 610.0,                last time consumption/overall running time: 221.8854s / 54723.8184 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2953
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2878
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 558.3,                last time consumption/overall running time: 204.3216s / 54928.1400 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2669
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2644
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 575.15,                last time consumption/overall running time: 209.4626s / 55137.6026 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2783
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2837
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 583.75,                last time consumption/overall running time: 211.8871s / 55349.4897 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2894
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2976
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 580.75,                last time consumption/overall running time: 209.8482s / 55559.3379 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2748
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2818
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 583.7,                last time consumption/overall running time: 209.6846s / 55769.0225 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2833
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2982
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 543.3,                last time consumption/overall running time: 198.0030s / 55967.0255 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2797
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2795
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 564.3,                last time consumption/overall running time: 205.3414s / 56172.3669 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2976
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3098
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 540.9,                last time consumption/overall running time: 198.0084s / 56370.3753 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2827
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2846
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 591.7,                last time consumption/overall running time: 214.8158s / 56585.1911 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2736
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2871
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 544.15,                last time consumption/overall running time: 199.0508s / 56784.2419 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2842
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2926
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 551.8,                last time consumption/overall running time: 203.2633s / 56987.5052 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2664
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2768
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 535.6,                last time consumption/overall running time: 197.8658s / 57185.3710 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2912
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3099
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 598.8,                last time consumption/overall running time: 218.1161s / 57403.4871 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2727
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2770
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 536.1,                last time consumption/overall running time: 195.6835s / 57599.1707 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2783
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2855
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 557.45,                last time consumption/overall running time: 204.1086s / 57803.2792 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2890
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3036
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 591.55,                last time consumption/overall running time: 215.5242s / 58018.8035 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2888
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3036
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 602.8,                last time consumption/overall running time: 218.1710s / 58236.9744 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2977
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3105
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 552.45,                last time consumption/overall running time: 201.2598s / 58438.2342 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2790
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2828
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 590.15,                last time consumption/overall running time: 214.5787s / 58652.8129 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2901
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3003
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 540.75,                last time consumption/overall running time: 198.6855s / 58851.4984 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2751
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2830
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 559.95,                last time consumption/overall running time: 204.6953s / 59056.1938 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2878
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3041
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 571.6,                last time consumption/overall running time: 207.7041s / 59263.8979 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2937
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3126
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 601.4,                last time consumption/overall running time: 217.1435s / 59481.0413 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2888
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3035
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 543.25,                last time consumption/overall running time: 198.3550s / 59679.3963 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2695
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2868
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 571.7,                last time consumption/overall running time: 208.4896s / 59887.8859 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3044
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3173
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 566.4,                last time consumption/overall running time: 205.8754s / 60093.7613 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2808
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2959
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 578.55,                last time consumption/overall running time: 209.2094s / 60302.9707 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2923
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3159
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 613.4,                last time consumption/overall running time: 220.6931s / 60523.6638 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2923
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3030
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 563.3,                last time consumption/overall running time: 205.4186s / 60729.0824 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2871
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3072
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 520.6,                last time consumption/overall running time: 190.4924s / 60919.5748 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2889
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3100
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 546.7,                last time consumption/overall running time: 200.2043s / 61119.7791 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3053
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3170
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 566.45,                last time consumption/overall running time: 208.3464s / 61328.1255 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3014
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3222
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 547.65,                last time consumption/overall running time: 199.5843s / 61527.7097 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2961
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3060
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 587.0,                last time consumption/overall running time: 214.5605s / 61742.2702 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3024
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3186
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 606.1,                last time consumption/overall running time: 218.4226s / 61960.6929 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2978
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3123
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 559.85,                last time consumption/overall running time: 204.7187s / 62165.4116 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2954
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3093
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 577.7,                last time consumption/overall running time: 208.7881s / 62374.1997 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2842
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3096
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 559.55,                last time consumption/overall running time: 202.6698s / 62576.8696 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2994
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3225
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 563.25,                last time consumption/overall running time: 206.7703s / 62783.6398 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2734
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2948
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 559.4,                last time consumption/overall running time: 203.0017s / 62986.6415 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2924
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3118
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 602.95,                last time consumption/overall running time: 218.3061s / 63204.9476 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2996
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3146
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 582.25,                last time consumption/overall running time: 211.3218s / 63416.2694 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2825
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3017
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 544.5,                last time consumption/overall running time: 200.8498s / 63617.1192 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3064
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3221
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 567.05,                last time consumption/overall running time: 206.9654s / 63824.0846 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2815
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3057
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 581.5,                last time consumption/overall running time: 210.9533s / 64035.0379 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2841
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2965
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 566.2,                last time consumption/overall running time: 208.3632s / 64243.4011 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2695
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2830
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 542.1,                last time consumption/overall running time: 198.2864s / 64441.6875 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3043
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3203
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 560.85,                last time consumption/overall running time: 205.1520s / 64646.8395 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2929
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3144
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 575.0,                last time consumption/overall running time: 207.7242s / 64854.5636 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3004
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3156
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 595.85,                last time consumption/overall running time: 215.8671s / 65070.4307 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2899
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3004
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 595.3,                last time consumption/overall running time: 215.4871s / 65285.9178 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2951
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3158
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 559.5,                last time consumption/overall running time: 204.9052s / 65490.8230 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2940
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3197
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 561.65,                last time consumption/overall running time: 207.0532s / 65697.8762 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2917
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3001
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 589.25,                last time consumption/overall running time: 212.2021s / 65910.0783 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2853
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3017
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 521.15,                last time consumption/overall running time: 192.7231s / 66102.8014 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3079
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3276
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 593.1,                last time consumption/overall running time: 213.8298s / 66316.6312 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2908
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3075
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 577.35,                last time consumption/overall running time: 211.5596s / 66528.1908 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3028
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3242
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 597.5,                last time consumption/overall running time: 216.9011s / 66745.0918 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2960
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3121
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 607.15,                last time consumption/overall running time: 218.6096s / 66963.7014 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2977
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3170
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 551.85,                last time consumption/overall running time: 202.2202s / 67165.9216 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2972
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3196
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 556.2,                last time consumption/overall running time: 203.1630s / 67369.0846 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2889
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3050
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 573.2,                last time consumption/overall running time: 209.0426s / 67578.1272 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3030
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3207
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 545.6,                last time consumption/overall running time: 199.1738s / 67777.3010 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2684
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2809
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 547.1,                last time consumption/overall running time: 201.5470s / 67978.8480 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3056
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3237
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 557.7,                last time consumption/overall running time: 201.7969s / 68180.6449 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2852
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3014
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 579.05,                last time consumption/overall running time: 210.9850s / 68391.6299 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2740
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2902
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 547.7,                last time consumption/overall running time: 199.6262s / 68591.2562 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2912
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3102
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 546.9,                last time consumption/overall running time: 200.2589s / 68791.5151 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2854
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3035
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 568.0,                last time consumption/overall running time: 207.3752s / 68998.8903 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2899
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3094
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 565.8,                last time consumption/overall running time: 205.1509s / 69204.0411 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2940
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3036
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 539.3,                last time consumption/overall running time: 196.0921s / 69400.1333 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2773
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3045
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 609.85,                last time consumption/overall running time: 222.1885s / 69622.3218 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2816
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3038
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 203.8324s / 69826.1543 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2845
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3030
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 562.8,                last time consumption/overall running time: 205.1547s / 70031.3090 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2931
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3236
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 567.35,                last time consumption/overall running time: 207.6018s / 70238.9108 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2954
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3238
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 566.7,                last time consumption/overall running time: 206.7395s / 70445.6503 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2891
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3118
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 546.05,                last time consumption/overall running time: 200.4150s / 70646.0653 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2730
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2955
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 543.65,                last time consumption/overall running time: 199.8281s / 70845.8934 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2902
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3104
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 548.2,                last time consumption/overall running time: 200.9236s / 71046.8170 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2893
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2949
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 208.6831s / 71255.5001 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2941
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3201
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 562.6,                last time consumption/overall running time: 204.2208s / 71459.7209 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2597
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2703
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 543.55,                last time consumption/overall running time: 199.1561s / 71658.8769 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2903
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3095
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 577.4,                last time consumption/overall running time: 212.1722s / 71871.0492 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2908
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3180
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 593.05,                last time consumption/overall running time: 215.7896s / 72086.8387 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3140
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 585.05,                last time consumption/overall running time: 212.8239s / 72299.6627 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2815
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3072
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 529.9,                last time consumption/overall running time: 195.8496s / 72495.5122 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2878
env0_second_0:                 episode reward: 1.3500,                 loss: 0.3095
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 579.4,                last time consumption/overall running time: 210.2911s / 72705.8033 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2886
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3066
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 614.3,                last time consumption/overall running time: 222.7137s / 72928.5170 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2563
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2755
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 568.55,                last time consumption/overall running time: 208.0481s / 73136.5651 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2786
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2990
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 569.4,                last time consumption/overall running time: 207.2558s / 73343.8209 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2681
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2919
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 574.9,                last time consumption/overall running time: 211.9658s / 73555.7866 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2995
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3047
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 568.15,                last time consumption/overall running time: 207.3964s / 73763.1830 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2433
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2657
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 553.65,                last time consumption/overall running time: 202.4922s / 73965.6751 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3072
env0_second_0:                 episode reward: -1.2500,                 loss: 0.3134
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 550.2,                last time consumption/overall running time: 199.8754s / 74165.5506 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2859
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3022
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 594.45,                last time consumption/overall running time: 216.0530s / 74381.6035 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2868
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3020
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 593.95,                last time consumption/overall running time: 215.9627s / 74597.5662 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2916
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3108
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 557.25,                last time consumption/overall running time: 204.2592s / 74801.8254 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2830
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3116
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 589.55,                last time consumption/overall running time: 214.2397s / 75016.0651 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2991
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3073
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 589.2,                last time consumption/overall running time: 214.6730s / 75230.7381 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2973
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3184
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 588.9,                last time consumption/overall running time: 216.7133s / 75447.4514 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2768
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2961
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 202.0354s / 75649.4868 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2828
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2998
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 579.1,                last time consumption/overall running time: 209.1609s / 75858.6477 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2717
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2763
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 558.55,                last time consumption/overall running time: 205.2170s / 76063.8647 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2725
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2821
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 584.05,                last time consumption/overall running time: 212.6649s / 76276.5296 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2721
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2759
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 583.1,                last time consumption/overall running time: 211.3204s / 76487.8500 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2968
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3190
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 586.45,                last time consumption/overall running time: 213.5040s / 76701.3539 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2713
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2849
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 566.4,                last time consumption/overall running time: 206.7185s / 76908.0724 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2849
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3006
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 542.85,                last time consumption/overall running time: 197.7954s / 77105.8679 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2779
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3028
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 575.3,                last time consumption/overall running time: 209.4053s / 77315.2731 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2738
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2880
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 608.7,                last time consumption/overall running time: 220.4890s / 77535.7621 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3099
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3284
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 587.95,                last time consumption/overall running time: 212.8148s / 77748.5769 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2745
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3096
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 578.8,                last time consumption/overall running time: 208.8917s / 77957.4686 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2719
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2815
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 573.75,                last time consumption/overall running time: 208.2253s / 78165.6939 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2824
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2970
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 594.55,                last time consumption/overall running time: 214.9923s / 78380.6861 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3122
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3224
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 570.4,                last time consumption/overall running time: 207.3785s / 78588.0646 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2904
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3009
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 584.65,                last time consumption/overall running time: 213.4268s / 78801.4914 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2757
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2906
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 570.7,                last time consumption/overall running time: 207.8686s / 79009.3600 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2761
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2973
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 581.9,                last time consumption/overall running time: 212.4781s / 79221.8381 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2689
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2987
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 581.4,                last time consumption/overall running time: 213.2760s / 79435.1141 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2895
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3241
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 558.3,                last time consumption/overall running time: 203.8298s / 79638.9439 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2582
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2623
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 595.05,                last time consumption/overall running time: 214.6020s / 79853.5459 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2940
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3178
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 551.0,                last time consumption/overall running time: 201.1662s / 80054.7121 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2656
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2896
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 552.05,                last time consumption/overall running time: 201.1152s / 80255.8273 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2637
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2880
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 583.75,                last time consumption/overall running time: 211.7569s / 80467.5842 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2811
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3009
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 541.35,                last time consumption/overall running time: 198.7799s / 80666.3641 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2993
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3271
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 597.55,                last time consumption/overall running time: 214.9863s / 80881.3504 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2818
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2954
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 565.15,                last time consumption/overall running time: 206.4255s / 81087.7759 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2726
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2955
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 546.75,                last time consumption/overall running time: 200.5605s / 81288.3365 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2645
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2838
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 561.8,                last time consumption/overall running time: 203.7146s / 81492.0510 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2758
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2916
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 559.65,                last time consumption/overall running time: 202.7878s / 81694.8389 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2923
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 592.85,                last time consumption/overall running time: 215.5758s / 81910.4147 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2933
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3185
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 583.8,                last time consumption/overall running time: 210.7389s / 82121.1536 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2705
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2803
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 589.95,                last time consumption/overall running time: 213.5193s / 82334.6729 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2666
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2821
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 567.0,                last time consumption/overall running time: 206.2425s / 82540.9154 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3051
env0_second_0:                 episode reward: -1.4000,                 loss: 0.3043
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 578.05,                last time consumption/overall running time: 210.0194s / 82750.9348 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2598
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2859
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 575.8,                last time consumption/overall running time: 208.5257s / 82959.4605 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2791
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2947
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 593.5,                last time consumption/overall running time: 216.2367s / 83175.6972 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2716
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2807
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 531.1,                last time consumption/overall running time: 194.1632s / 83369.8604 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2871
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3081
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 598.35,                last time consumption/overall running time: 216.5440s / 83586.4043 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2890
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2939
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 563.9,                last time consumption/overall running time: 206.9019s / 83793.3062 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2771
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2942
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 569.5,                last time consumption/overall running time: 208.1103s / 84001.4165 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2798
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3039
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 573.55,                last time consumption/overall running time: 209.1895s / 84210.6060 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2665
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2737
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 577.45,                last time consumption/overall running time: 210.0020s / 84420.6080 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2841
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3036
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 553.55,                last time consumption/overall running time: 202.8383s / 84623.4463 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2785
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2945
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 542.45,                last time consumption/overall running time: 197.7909s / 84821.2372 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2721
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2844
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 568.05,                last time consumption/overall running time: 205.9383s / 85027.1755 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2820
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2871
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 570.35,                last time consumption/overall running time: 206.8894s / 85234.0649 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2661
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2960
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 579.8,                last time consumption/overall running time: 210.3180s / 85444.3829 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2876
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2991
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 560.35,                last time consumption/overall running time: 204.5433s / 85648.9262 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2701
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2983
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 554.45,                last time consumption/overall running time: 203.2907s / 85852.2170 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2995
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3195
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 580.25,                last time consumption/overall running time: 211.5260s / 86063.7430 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2902
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2952
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 573.1,                last time consumption/overall running time: 208.5302s / 86272.2731 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3090
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3219
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 582.1,                last time consumption/overall running time: 212.4062s / 86484.6793 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2788
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2980
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 572.25,                last time consumption/overall running time: 210.3067s / 86694.9861 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3063
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3187
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 538.05,                last time consumption/overall running time: 197.6416s / 86892.6277 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2865
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3148
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 536.5,                last time consumption/overall running time: 197.6911s / 87090.3188 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2980
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3076
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 594.35,                last time consumption/overall running time: 216.0946s / 87306.4135 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2756
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2777
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 570.95,                last time consumption/overall running time: 210.2864s / 87516.6998 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2689
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2833
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 549.1,                last time consumption/overall running time: 200.7994s / 87717.4992 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3106
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3204
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 578.85,                last time consumption/overall running time: 213.0516s / 87930.5508 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2842
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2988
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 577.95,                last time consumption/overall running time: 212.3849s / 88142.9357 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2920
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3215
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 581.35,                last time consumption/overall running time: 211.9801s / 88354.9159 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2810
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2876
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 592.05,                last time consumption/overall running time: 217.3877s / 88572.3035 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2932
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3205
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 593.95,                last time consumption/overall running time: 217.3754s / 88789.6789 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2800
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3032
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 536.95,                last time consumption/overall running time: 197.1221s / 88986.8010 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2574
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2829
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 558.85,                last time consumption/overall running time: 205.6552s / 89192.4562 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2657
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3270
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 576.45,                last time consumption/overall running time: 210.1815s / 89402.6377 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2922
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3405
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 559.65,                last time consumption/overall running time: 205.8899s / 89608.5276 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2842
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3117
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 579.85,                last time consumption/overall running time: 210.4999s / 89819.0275 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2839
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3156
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 572.0,                last time consumption/overall running time: 209.6459s / 90028.6733 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.2810
env0_second_0:                 episode reward: -1.4000,                 loss: 0.3026
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 578.8,                last time consumption/overall running time: 213.1306s / 90241.8039 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3038
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3113
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 562.9,                last time consumption/overall running time: 208.2479s / 90450.0519 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2838
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2957
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 578.35,                last time consumption/overall running time: 209.6185s / 90659.6704 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2613
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2809
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 542.4,                last time consumption/overall running time: 199.6718s / 90859.3422 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2941
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3223
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 558.5,                last time consumption/overall running time: 206.3804s / 91065.7227 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2798
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2884
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 560.55,                last time consumption/overall running time: 205.4542s / 91271.1768 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2833
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2950
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 575.45,                last time consumption/overall running time: 209.4090s / 91480.5859 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2986
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3178
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 559.15,                last time consumption/overall running time: 205.4158s / 91686.0016 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2634
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2967
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 541.35,                last time consumption/overall running time: 200.2790s / 91886.2806 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2956
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3098
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 571.75,                last time consumption/overall running time: 208.0842s / 92094.3648 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2789
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2938
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 586.7,                last time consumption/overall running time: 213.3708s / 92307.7356 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2780
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2876
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 557.85,                last time consumption/overall running time: 204.9606s / 92512.6962 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2937
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3096
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 569.0,                last time consumption/overall running time: 207.5751s / 92720.2714 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2937
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2999
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 564.05,                last time consumption/overall running time: 209.1551s / 92929.4265 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2641
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2677
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 572.55,                last time consumption/overall running time: 212.8307s / 93142.2572 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2873
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3061
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 588.6,                last time consumption/overall running time: 214.3946s / 93356.6519 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2971
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3040
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 573.3,                last time consumption/overall running time: 208.1279s / 93564.7798 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2812
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2809Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 587.3,                last time consumption/overall running time: 213.1566s / 93777.9364 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2707
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2671
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 551.25,                last time consumption/overall running time: 202.0283s / 93979.9647 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2673
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2774
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 553.3,                last time consumption/overall running time: 202.5110s / 94182.4757 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2799
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2947
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 555.5,                last time consumption/overall running time: 203.9981s / 94386.4739 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2578
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2747
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 590.9,                last time consumption/overall running time: 215.1643s / 94601.6381 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3018
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3215
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 594.3,                last time consumption/overall running time: 216.4049s / 94818.0430 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2616
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2726
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 579.95,                last time consumption/overall running time: 213.4761s / 95031.5191 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2873
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2957
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 561.05,                last time consumption/overall running time: 205.3765s / 95236.8957 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2757
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2954
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 574.2,                last time consumption/overall running time: 209.3902s / 95446.2858 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2874
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3035
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
