2022-05-11 10:36:00.137050: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:36:00.137138: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:36:00.137145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 126
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f8c84a7f588>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 8000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_8000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_8000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8304s / 0.8304 s
agent0:                 episode reward: 0.9254,                 loss: nan
agent1:                 episode reward: -0.9254,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1146s / 0.9450 s
agent0:                 episode reward: 1.0379,                 loss: nan
agent1:                 episode reward: -1.0379,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1106s / 1.0556 s
agent0:                 episode reward: 1.2212,                 loss: nan
agent1:                 episode reward: -1.2212,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1184s / 1.1739 s
agent0:                 episode reward: 0.8961,                 loss: nan
agent1:                 episode reward: -0.8961,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1104s / 1.2844 s
agent0:                 episode reward: 0.5314,                 loss: nan
agent1:                 episode reward: -0.5314,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1104s / 1.3948 s
agent0:                 episode reward: 1.0076,                 loss: nan
agent1:                 episode reward: -1.0076,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1468s / 1.5416 s
agent0:                 episode reward: 0.5552,                 loss: nan
agent1:                 episode reward: -0.5552,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3525s / 1.8941 s
agent0:                 episode reward: 1.4593,                 loss: nan
agent1:                 episode reward: -1.4593,                 loss: 0.4492
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4422s / 2.3363 s
agent0:                 episode reward: 1.4653,                 loss: nan
agent1:                 episode reward: -1.4653,                 loss: 0.4443
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4650s / 2.8014 s
agent0:                 episode reward: 0.7672,                 loss: nan
agent1:                 episode reward: -0.7672,                 loss: 0.4421
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4913s / 3.2927 s
agent0:                 episode reward: -0.0514,                 loss: nan
agent1:                 episode reward: 0.0514,                 loss: 0.4399
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4516s / 3.7442 s
agent0:                 episode reward: 1.4728,                 loss: nan
agent1:                 episode reward: -1.4728,                 loss: 0.4390
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4476s / 4.1918 s
agent0:                 episode reward: 1.5563,                 loss: nan
agent1:                 episode reward: -1.5563,                 loss: 0.4355
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4551s / 4.6470 s
agent0:                 episode reward: 0.1679,                 loss: nan
agent1:                 episode reward: -0.1679,                 loss: 0.4333
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4448s / 5.0918 s
agent0:                 episode reward: 1.9265,                 loss: nan
agent1:                 episode reward: -1.9265,                 loss: 0.4320
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4369s / 5.5286 s
agent0:                 episode reward: 0.9025,                 loss: nan
agent1:                 episode reward: -0.9025,                 loss: 0.4318
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4519s / 5.9806 s
agent0:                 episode reward: 0.3913,                 loss: nan
agent1:                 episode reward: -0.3913,                 loss: 0.4288
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4676s / 6.4481 s
agent0:                 episode reward: 1.7266,                 loss: nan
agent1:                 episode reward: -1.7266,                 loss: 0.3888
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4578s / 6.9059 s
agent0:                 episode reward: 1.5717,                 loss: nan
agent1:                 episode reward: -1.5717,                 loss: 0.3622
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4461s / 7.3521 s
agent0:                 episode reward: 1.5614,                 loss: nan
agent1:                 episode reward: -1.5614,                 loss: 0.3625
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4727s / 7.8248 s
agent0:                 episode reward: -0.0255,                 loss: nan
agent1:                 episode reward: 0.0255,                 loss: 0.3603
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4955s / 8.3202 s
agent0:                 episode reward: 0.6681,                 loss: nan
agent1:                 episode reward: -0.6681,                 loss: 0.3594
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4574s / 8.7776 s
agent0:                 episode reward: 1.4847,                 loss: nan
agent1:                 episode reward: -1.4847,                 loss: 0.3600
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4649s / 9.2425 s
agent0:                 episode reward: 1.4029,                 loss: nan
agent1:                 episode reward: -1.4029,                 loss: 0.3571
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4575s / 9.7000 s
agent0:                 episode reward: 1.3602,                 loss: nan
agent1:                 episode reward: -1.3602,                 loss: 0.3539
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4563s / 10.1563 s
agent0:                 episode reward: 1.4961,                 loss: nan
agent1:                 episode reward: -1.4961,                 loss: 0.3552
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4566s / 10.6130 s
agent0:                 episode reward: 0.7456,                 loss: nan
agent1:                 episode reward: -0.7456,                 loss: 0.3526
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4752s / 11.0882 s
agent0:                 episode reward: 0.3724,                 loss: nan
agent1:                 episode reward: -0.3724,                 loss: 0.3167
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4565s / 11.5447 s
agent0:                 episode reward: 1.4212,                 loss: nan
agent1:                 episode reward: -1.4212,                 loss: 0.2938
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5055s / 12.0502 s
agent0:                 episode reward: 1.5077,                 loss: nan
agent1:                 episode reward: -1.5077,                 loss: 0.2950
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4872s / 12.5374 s
agent0:                 episode reward: 0.6008,                 loss: nan
agent1:                 episode reward: -0.6008,                 loss: 0.2942
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4626s / 13.0000 s
agent0:                 episode reward: 0.6116,                 loss: nan
agent1:                 episode reward: -0.6116,                 loss: 0.2910
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4584s / 13.4584 s
agent0:                 episode reward: 0.2633,                 loss: nan
agent1:                 episode reward: -0.2633,                 loss: 0.2902
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4579s / 13.9163 s
agent0:                 episode reward: 1.4028,                 loss: nan
agent1:                 episode reward: -1.4028,                 loss: 0.2899
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4670s / 14.3834 s
agent0:                 episode reward: 1.0582,                 loss: nan
agent1:                 episode reward: -1.0582,                 loss: 0.2869
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4639s / 14.8473 s
agent0:                 episode reward: 1.5459,                 loss: nan
agent1:                 episode reward: -1.5459,                 loss: 0.2837
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4832s / 15.3305 s
agent0:                 episode reward: 1.4942,                 loss: nan
agent1:                 episode reward: -1.4942,                 loss: 0.2823
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4682s / 15.7988 s
agent0:                 episode reward: 0.6085,                 loss: nan
agent1:                 episode reward: -0.6085,                 loss: 0.2723
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4767s / 16.2755 s
agent0:                 episode reward: 0.2443,                 loss: nan
agent1:                 episode reward: -0.2443,                 loss: 0.2663
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4674s / 16.7428 s
agent0:                 episode reward: 1.4557,                 loss: nan
agent1:                 episode reward: -1.4557,                 loss: 0.2624
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4682s / 17.2111 s
agent0:                 episode reward: 1.5240,                 loss: nan
agent1:                 episode reward: -1.5240,                 loss: 0.2611
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4897s / 17.7007 s
agent0:                 episode reward: 0.7035,                 loss: nan
agent1:                 episode reward: -0.7035,                 loss: 0.2574
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4718s / 18.1725 s
agent0:                 episode reward: 1.9560,                 loss: nan
agent1:                 episode reward: -1.9560,                 loss: 0.2546
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4821s / 18.6547 s
agent0:                 episode reward: -0.5949,                 loss: nan
agent1:                 episode reward: 0.5949,                 loss: 0.2554
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4755s / 19.1301 s
agent0:                 episode reward: 0.7606,                 loss: nan
agent1:                 episode reward: -0.7606,                 loss: 0.2526
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5157s / 19.6458 s
agent0:                 episode reward: 1.0731,                 loss: nan
agent1:                 episode reward: -1.0731,                 loss: 0.2514
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4814s / 20.1271 s
agent0:                 episode reward: 1.4025,                 loss: nan
agent1:                 episode reward: -1.4025,                 loss: 0.2497
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4703s / 20.5975 s
agent0:                 episode reward: 1.0270,                 loss: nan
agent1:                 episode reward: -1.0270,                 loss: 0.2557
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4960s / 21.0935 s
agent0:                 episode reward: 0.4717,                 loss: nan
agent1:                 episode reward: -0.4717,                 loss: 0.2550
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4918s / 21.5853 s
agent0:                 episode reward: 0.6374,                 loss: nan
agent1:                 episode reward: -0.6374,                 loss: 0.2551
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5391s / 22.1244 s
agent0:                 episode reward: -0.0404,                 loss: nan
agent1:                 episode reward: 0.0404,                 loss: 0.2535
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4821s / 22.6065 s
agent0:                 episode reward: 0.4590,                 loss: nan
agent1:                 episode reward: -0.4590,                 loss: 0.2515
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4847s / 23.0912 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.2486
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4842s / 23.5754 s
agent0:                 episode reward: 1.2033,                 loss: nan
agent1:                 episode reward: -1.2033,                 loss: 0.2457
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4893s / 24.0647 s
agent0:                 episode reward: 0.5565,                 loss: nan
agent1:                 episode reward: -0.5565,                 loss: 0.2447
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5062s / 24.5708 s
agent0:                 episode reward: 0.0894,                 loss: nan
agent1:                 episode reward: -0.0894,                 loss: 0.2449
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4814s / 25.0522 s
agent0:                 episode reward: 0.0768,                 loss: nan
agent1:                 episode reward: -0.0768,                 loss: 0.2460
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4871s / 25.5393 s
agent0:                 episode reward: 0.9061,                 loss: nan
agent1:                 episode reward: -0.9061,                 loss: 0.2703
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4852s / 26.0244 s
agent0:                 episode reward: 1.0049,                 loss: nan
agent1:                 episode reward: -1.0049,                 loss: 0.2754
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4856s / 26.5100 s
agent0:                 episode reward: 1.3446,                 loss: nan
agent1:                 episode reward: -1.3446,                 loss: 0.2728
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4735s / 26.9835 s
agent0:                 episode reward: 0.4763,                 loss: nan
agent1:                 episode reward: -0.4763,                 loss: 0.2715
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5275s / 27.5110 s
agent0:                 episode reward: 1.0258,                 loss: nan
agent1:                 episode reward: -1.0258,                 loss: 0.2721
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4891s / 28.0001 s
agent0:                 episode reward: 0.7645,                 loss: nan
agent1:                 episode reward: -0.7645,                 loss: 0.2728
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4989s / 28.4990 s
agent0:                 episode reward: 1.1336,                 loss: nan
agent1:                 episode reward: -1.1336,                 loss: 0.2709
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4892s / 28.9882 s
agent0:                 episode reward: 1.0127,                 loss: nan
agent1:                 episode reward: -1.0127,                 loss: 0.2714
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4982s / 29.4864 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.2702
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4968s / 29.9832 s
agent0:                 episode reward: 0.9490,                 loss: nan
agent1:                 episode reward: -0.9490,                 loss: 0.2683
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5025s / 30.4857 s
agent0:                 episode reward: 0.4826,                 loss: nan
agent1:                 episode reward: -0.4826,                 loss: 0.2948
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5082s / 30.9939 s
agent0:                 episode reward: 0.8905,                 loss: nan
agent1:                 episode reward: -0.8905,                 loss: 0.2998
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4965s / 31.4904 s
agent0:                 episode reward: 1.1352,                 loss: nan
agent1:                 episode reward: -1.1352,                 loss: 0.2987
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4963s / 31.9867 s
agent0:                 episode reward: -0.3899,                 loss: nan
agent1:                 episode reward: 0.3899,                 loss: 0.2969
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5576s / 32.5444 s
agent0:                 episode reward: 0.3941,                 loss: nan
agent1:                 episode reward: -0.3941,                 loss: 0.2941
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5134s / 33.0578 s
agent0:                 episode reward: 1.0360,                 loss: nan
agent1:                 episode reward: -1.0360,                 loss: 0.2939
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4969s / 33.5546 s
agent0:                 episode reward: 0.6058,                 loss: nan
agent1:                 episode reward: -0.6058,                 loss: 0.2936
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5051s / 34.0597 s
agent0:                 episode reward: 0.1412,                 loss: nan
agent1:                 episode reward: -0.1412,                 loss: 0.2915
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5000s / 34.5597 s
agent0:                 episode reward: 0.3974,                 loss: nan
agent1:                 episode reward: -0.3974,                 loss: 0.2926
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5068s / 35.0665 s
agent0:                 episode reward: 1.0083,                 loss: nan
agent1:                 episode reward: -1.0083,                 loss: 0.2928
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4945s / 35.5610 s
agent0:                 episode reward: 1.0700,                 loss: nan
agent1:                 episode reward: -1.0700,                 loss: 0.3091
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5338s / 36.0948 s
agent0:                 episode reward: 0.8694,                 loss: nan
agent1:                 episode reward: -0.8694,                 loss: 0.3087
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5140s / 36.6088 s
agent0:                 episode reward: -0.4702,                 loss: nan
agent1:                 episode reward: 0.4702,                 loss: 0.3087
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5002s / 37.1090 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.3066
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4943s / 37.6033 s
agent0:                 episode reward: 1.1169,                 loss: nan
agent1:                 episode reward: -1.1169,                 loss: 0.3039
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5016s / 38.1049 s
agent0:                 episode reward: 0.4757,                 loss: nan
agent1:                 episode reward: -0.4757,                 loss: 0.3056
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5093s / 38.6143 s
agent0:                 episode reward: 0.7813,                 loss: nan
agent1:                 episode reward: -0.7813,                 loss: 0.3036
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5065s / 39.1208 s
agent0:                 episode reward: 0.7089,                 loss: nan
agent1:                 episode reward: -0.7089,                 loss: 0.3029
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5074s / 39.6281 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.3004
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5038s / 40.1319 s
agent0:                 episode reward: -0.1673,                 loss: nan
agent1:                 episode reward: 0.1673,                 loss: 0.3011
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5023s / 40.6342 s
agent0:                 episode reward: 1.1511,                 loss: nan
agent1:                 episode reward: -1.1511,                 loss: 0.3061
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4940s / 41.1282 s
agent0:                 episode reward: -0.0814,                 loss: nan
agent1:                 episode reward: 0.0814,                 loss: 0.3007
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4958s / 41.6240 s
agent0:                 episode reward: -0.0178,                 loss: nan
agent1:                 episode reward: 0.0178,                 loss: 0.2983
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5064s / 42.1304 s
agent0:                 episode reward: 0.3624,                 loss: nan
agent1:                 episode reward: -0.3624,                 loss: 0.3001
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5579s / 42.6883 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.2978
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5097s / 43.1979 s
agent0:                 episode reward: 1.2127,                 loss: nan
agent1:                 episode reward: -1.2127,                 loss: 0.2966
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4961s / 43.6940 s
agent0:                 episode reward: 0.8126,                 loss: nan
agent1:                 episode reward: -0.8126,                 loss: 0.2951
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5417s / 44.2358 s
agent0:                 episode reward: 1.6055,                 loss: nan
agent1:                 episode reward: -1.6055,                 loss: 0.2922
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5042s / 44.7400 s
agent0:                 episode reward: 0.4147,                 loss: nan
agent1:                 episode reward: -0.4147,                 loss: 0.2924
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5260s / 45.2659 s
agent0:                 episode reward: 1.0282,                 loss: nan
agent1:                 episode reward: -1.0282,                 loss: 0.2925
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5275s / 45.7934 s
agent0:                 episode reward: 0.7968,                 loss: nan
agent1:                 episode reward: -0.7968,                 loss: 0.2957
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4965s / 46.2899 s
agent0:                 episode reward: 0.7925,                 loss: nan
agent1:                 episode reward: -0.7925,                 loss: 0.2872
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5015s / 46.7914 s
agent0:                 episode reward: 0.6416,                 loss: nan
agent1:                 episode reward: -0.6416,                 loss: 0.2851
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5005s / 47.2919 s
agent0:                 episode reward: -0.0408,                 loss: nan
agent1:                 episode reward: 0.0408,                 loss: 0.2838
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5072s / 47.7991 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: 0.2822
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4949s / 48.2940 s
agent0:                 episode reward: -0.3770,                 loss: nan
agent1:                 episode reward: 0.3770,                 loss: 0.2823
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5326s / 48.8266 s
agent0:                 episode reward: 0.6518,                 loss: nan
agent1:                 episode reward: -0.6518,                 loss: 0.2814
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5102s / 49.3368 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.2802
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5074s / 49.8442 s
agent0:                 episode reward: 0.6074,                 loss: nan
agent1:                 episode reward: -0.6074,                 loss: 0.2816
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5063s / 50.3505 s
agent0:                 episode reward: -0.3129,                 loss: nan
agent1:                 episode reward: 0.3129,                 loss: 0.2805
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5112s / 50.8617 s
agent0:                 episode reward: 0.5669,                 loss: nan
agent1:                 episode reward: -0.5669,                 loss: 0.2943
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5161s / 51.3778 s
agent0:                 episode reward: -0.2693,                 loss: nan
agent1:                 episode reward: 0.2693,                 loss: 0.2941
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5217s / 51.8995 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.2927
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5232s / 52.4226 s
agent0:                 episode reward: 1.0187,                 loss: nan
agent1:                 episode reward: -1.0187,                 loss: 0.2898
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5822s / 53.0048 s
agent0:                 episode reward: 0.5673,                 loss: nan
agent1:                 episode reward: -0.5673,                 loss: 0.2868
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5235s / 53.5284 s
agent0:                 episode reward: 0.3797,                 loss: nan
agent1:                 episode reward: -0.3797,                 loss: 0.2892
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5358s / 54.0641 s
agent0:                 episode reward: -0.3402,                 loss: nan
agent1:                 episode reward: 0.3402,                 loss: 0.2887
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5236s / 54.5877 s
agent0:                 episode reward: 0.0441,                 loss: nan
agent1:                 episode reward: -0.0441,                 loss: 0.2899
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5157s / 55.1034 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: 0.2881
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5151s / 55.6186 s
agent0:                 episode reward: 0.3545,                 loss: nan
agent1:                 episode reward: -0.3545,                 loss: 0.2892
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5168s / 56.1354 s
agent0:                 episode reward: 0.4152,                 loss: nan
agent1:                 episode reward: -0.4152,                 loss: 0.3207
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5176s / 56.6530 s
agent0:                 episode reward: -0.1428,                 loss: nan
agent1:                 episode reward: 0.1428,                 loss: 0.3196
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5220s / 57.1751 s
agent0:                 episode reward: 0.7125,                 loss: nan
agent1:                 episode reward: -0.7125,                 loss: 0.3166
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5296s / 57.7046 s
agent0:                 episode reward: 0.1619,                 loss: nan
agent1:                 episode reward: -0.1619,                 loss: 0.3139
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5274s / 58.2320 s
agent0:                 episode reward: 0.1334,                 loss: nan
agent1:                 episode reward: -0.1334,                 loss: 0.3133
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5261s / 58.7581 s
agent0:                 episode reward: 0.8637,                 loss: nan
agent1:                 episode reward: -0.8637,                 loss: 0.3127
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5328s / 59.2909 s
agent0:                 episode reward: -0.0636,                 loss: nan
agent1:                 episode reward: 0.0636,                 loss: 0.3123
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5195s / 59.8103 s
agent0:                 episode reward: 0.2525,                 loss: nan
agent1:                 episode reward: -0.2525,                 loss: 0.3110
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5208s / 60.3311 s
agent0:                 episode reward: 0.2613,                 loss: nan
agent1:                 episode reward: -0.2613,                 loss: 0.3116
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5534s / 60.8846 s
agent0:                 episode reward: 0.8076,                 loss: nan
agent1:                 episode reward: -0.8076,                 loss: 0.3127
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5294s / 61.4140 s
agent0:                 episode reward: 2.6983,                 loss: nan
agent1:                 episode reward: -2.6983,                 loss: 0.3457
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5454s / 61.9594 s
agent0:                 episode reward: 0.6753,                 loss: nan
agent1:                 episode reward: -0.6753,                 loss: 0.3451
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5358s / 62.4952 s
agent0:                 episode reward: -1.1081,                 loss: nan
agent1:                 episode reward: 1.1081,                 loss: 0.3414
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5735s / 63.0687 s
agent0:                 episode reward: 0.7673,                 loss: nan
agent1:                 episode reward: -0.7673,                 loss: 0.3384
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5426s / 63.6113 s
agent0:                 episode reward: -0.7032,                 loss: nan
agent1:                 episode reward: 0.7032,                 loss: 0.3359
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5394s / 64.1507 s
agent0:                 episode reward: -0.0459,                 loss: nan
agent1:                 episode reward: 0.0459,                 loss: 0.3364
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5657s / 64.7164 s
agent0:                 episode reward: 0.5653,                 loss: nan
agent1:                 episode reward: -0.5653,                 loss: 0.3374
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5571s / 65.2736 s
agent0:                 episode reward: 0.3231,                 loss: nan
agent1:                 episode reward: -0.3231,                 loss: 0.3346
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5561s / 65.8297 s
agent0:                 episode reward: -0.0277,                 loss: nan
agent1:                 episode reward: 0.0277,                 loss: 0.3365
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5419s / 66.3716 s
agent0:                 episode reward: 0.9095,                 loss: nan
agent1:                 episode reward: -0.9095,                 loss: 0.3331
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5670s / 66.9385 s
agent0:                 episode reward: 0.3042,                 loss: nan
agent1:                 episode reward: -0.3042,                 loss: 0.3343
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5343s / 67.4729 s
agent0:                 episode reward: 0.1593,                 loss: nan
agent1:                 episode reward: -0.1593,                 loss: 0.3099
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5458s / 68.0187 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3055
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5480s / 68.5667 s
agent0:                 episode reward: 1.0565,                 loss: nan
agent1:                 episode reward: -1.0565,                 loss: 0.3012
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5676s / 69.1343 s
agent0:                 episode reward: 0.5126,                 loss: nan
agent1:                 episode reward: -0.5126,                 loss: 0.3010
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5481s / 69.6824 s
agent0:                 episode reward: 1.0933,                 loss: nan
agent1:                 episode reward: -1.0933,                 loss: 0.2979
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5415s / 70.2238 s
agent0:                 episode reward: -0.2560,                 loss: nan
agent1:                 episode reward: 0.2560,                 loss: 0.2962
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5435s / 70.7673 s
agent0:                 episode reward: 0.6419,                 loss: nan
agent1:                 episode reward: -0.6419,                 loss: 0.2966
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5531s / 71.3204 s
agent0:                 episode reward: 0.5576,                 loss: nan
agent1:                 episode reward: -0.5576,                 loss: 0.2938
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5423s / 71.8627 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: 0.2940
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5373s / 72.3999 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: 0.2542
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5840s / 72.9839 s
agent0:                 episode reward: 0.4073,                 loss: nan
agent1:                 episode reward: -0.4073,                 loss: 0.2175
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5842s / 73.5681 s
agent0:                 episode reward: -0.1393,                 loss: nan
agent1:                 episode reward: 0.1393,                 loss: 0.2160
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5366s / 74.1047 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.2152
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5457s / 74.6505 s
agent0:                 episode reward: 1.1145,                 loss: nan
agent1:                 episode reward: -1.1145,                 loss: 0.2155
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5485s / 75.1990 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.2149
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5573s / 75.7563 s
agent0:                 episode reward: 0.5396,                 loss: nan
agent1:                 episode reward: -0.5396,                 loss: 0.2136
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5432s / 76.2995 s
agent0:                 episode reward: -0.1711,                 loss: nan
agent1:                 episode reward: 0.1711,                 loss: 0.2124
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5515s / 76.8510 s
agent0:                 episode reward: -0.5071,                 loss: nan
agent1:                 episode reward: 0.5071,                 loss: 0.2118
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5696s / 77.4207 s
agent0:                 episode reward: 0.6035,                 loss: nan
agent1:                 episode reward: -0.6035,                 loss: 0.2122
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5491s / 77.9698 s
agent0:                 episode reward: 1.0701,                 loss: nan
agent1:                 episode reward: -1.0701,                 loss: 0.2040
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5468s / 78.5166 s
agent0:                 episode reward: 1.2618,                 loss: nan
agent1:                 episode reward: -1.2618,                 loss: 0.1881
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5673s / 79.0839 s
agent0:                 episode reward: 0.9978,                 loss: nan
agent1:                 episode reward: -0.9978,                 loss: 0.1876
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5551s / 79.6390 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.1841
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5487s / 80.1877 s
agent0:                 episode reward: -0.2342,                 loss: nan
agent1:                 episode reward: 0.2342,                 loss: 0.1842
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5712s / 80.7588 s
agent0:                 episode reward: 0.0682,                 loss: nan
agent1:                 episode reward: -0.0682,                 loss: 0.1833
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5531s / 81.3119 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.1829
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5721s / 81.8840 s
agent0:                 episode reward: -0.4343,                 loss: nan
agent1:                 episode reward: 0.4343,                 loss: 0.1810
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5474s / 82.4314 s
agent0:                 episode reward: 0.0379,                 loss: nan
agent1:                 episode reward: -0.0379,                 loss: 0.1822
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5522s / 82.9835 s
agent0:                 episode reward: -0.7715,                 loss: nan
agent1:                 episode reward: 0.7715,                 loss: 0.1818
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6073s / 83.5908 s
agent0:                 episode reward: 0.8574,                 loss: nan
agent1:                 episode reward: -0.8574,                 loss: 0.2057
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5622s / 84.1530 s
agent0:                 episode reward: 0.6649,                 loss: nan
agent1:                 episode reward: -0.6649,                 loss: 0.2068
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5577s / 84.7107 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.2087
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5730s / 85.2838 s
agent0:                 episode reward: -0.0316,                 loss: nan
agent1:                 episode reward: 0.0316,                 loss: 0.2061
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5728s / 85.8566 s
agent0:                 episode reward: 0.0155,                 loss: nan
agent1:                 episode reward: -0.0155,                 loss: 0.2086
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5558s / 86.4123 s
agent0:                 episode reward: 0.4493,                 loss: nan
agent1:                 episode reward: -0.4493,                 loss: 0.2043
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5477s / 86.9601 s
agent0:                 episode reward: 0.7239,                 loss: nan
agent1:                 episode reward: -0.7239,                 loss: 0.2045
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5557s / 87.5158 s
agent0:                 episode reward: 0.5332,                 loss: nan
agent1:                 episode reward: -0.5332,                 loss: 0.2048
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5733s / 88.0891 s
agent0:                 episode reward: -0.4916,                 loss: nan
agent1:                 episode reward: 0.4916,                 loss: 0.2027
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5589s / 88.6480 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: 0.2032
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5541s / 89.2021 s
agent0:                 episode reward: -0.1419,                 loss: nan
agent1:                 episode reward: 0.1419,                 loss: 0.2447
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 89.7852 s
agent0:                 episode reward: -0.2067,                 loss: nan
agent1:                 episode reward: 0.2067,                 loss: 0.2521
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5781s / 90.3634 s
agent0:                 episode reward: 0.3597,                 loss: nan
agent1:                 episode reward: -0.3597,                 loss: 0.2525
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5616s / 90.9250 s
agent0:                 episode reward: 0.5784,                 loss: nan
agent1:                 episode reward: -0.5784,                 loss: 0.2509
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5629s / 91.4879 s
agent0:                 episode reward: 0.9039,                 loss: nan
agent1:                 episode reward: -0.9039,                 loss: 0.2494
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5662s / 92.0541 s
agent0:                 episode reward: -0.5118,                 loss: nan
agent1:                 episode reward: 0.5118,                 loss: 0.2499
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5697s / 92.6238 s
agent0:                 episode reward: 0.4458,                 loss: nan
agent1:                 episode reward: -0.4458,                 loss: 0.2505
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5621s / 93.1860 s
agent0:                 episode reward: 0.0400,                 loss: nan
agent1:                 episode reward: -0.0400,                 loss: 0.2505
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6327s / 93.8187 s
agent0:                 episode reward: 0.5391,                 loss: nan
agent1:                 episode reward: -0.5391,                 loss: 0.2490
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5786s / 94.3974 s
agent0:                 episode reward: 0.4069,                 loss: nan
agent1:                 episode reward: -0.4069,                 loss: 0.2482
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5693s / 94.9666 s
agent0:                 episode reward: 0.0531,                 loss: nan
agent1:                 episode reward: -0.0531,                 loss: 0.2741
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5614s / 95.5280 s
agent0:                 episode reward: 0.3628,                 loss: nan
agent1:                 episode reward: -0.3628,                 loss: 0.2722
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5711s / 96.0991 s
agent0:                 episode reward: 0.2805,                 loss: nan
agent1:                 episode reward: -0.2805,                 loss: 0.2718
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5692s / 96.6684 s
agent0:                 episode reward: 1.1420,                 loss: nan
agent1:                 episode reward: -1.1420,                 loss: 0.2716
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5752s / 97.2436 s
agent0:                 episode reward: -0.3124,                 loss: nan
agent1:                 episode reward: 0.3124,                 loss: 0.2710
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5716s / 97.8152 s
agent0:                 episode reward: 0.3646,                 loss: nan
agent1:                 episode reward: -0.3646,                 loss: 0.2693
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5693s / 98.3844 s
agent0:                 episode reward: 0.3892,                 loss: nan
agent1:                 episode reward: -0.3892,                 loss: 0.2674
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5727s / 98.9572 s
agent0:                 episode reward: 0.3953,                 loss: nan
agent1:                 episode reward: -0.3953,                 loss: 0.2690
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5796s / 99.5368 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.2678
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5816s / 100.1183 s
agent0:                 episode reward: -0.3550,                 loss: nan
agent1:                 episode reward: 0.3550,                 loss: 0.2682
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5758s / 100.6942 s
agent0:                 episode reward: 1.0437,                 loss: nan
agent1:                 episode reward: -1.0437,                 loss: 0.2741
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5727s / 101.2668 s
agent0:                 episode reward: 0.0917,                 loss: nan
agent1:                 episode reward: -0.0917,                 loss: 0.2582
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5678s / 101.8347 s
agent0:                 episode reward: 0.9350,                 loss: nan
agent1:                 episode reward: -0.9350,                 loss: 0.2581
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5944s / 102.4291 s
agent0:                 episode reward: -0.0578,                 loss: nan
agent1:                 episode reward: 0.0578,                 loss: 0.2588
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5965s / 103.0255 s
agent0:                 episode reward: -0.2386,                 loss: nan
agent1:                 episode reward: 0.2386,                 loss: 0.2559
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5769s / 103.6024 s
agent0:                 episode reward: 0.2551,                 loss: nan
agent1:                 episode reward: -0.2551,                 loss: 0.2581
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6349s / 104.2373 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.2564
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5833s / 104.8206 s
agent0:                 episode reward: 0.2063,                 loss: nan
agent1:                 episode reward: -0.2063,                 loss: 0.2578
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5843s / 105.4049 s
agent0:                 episode reward: -0.0486,                 loss: nan
agent1:                 episode reward: 0.0486,                 loss: 0.2565
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5783s / 105.9832 s
agent0:                 episode reward: 0.4651,                 loss: nan
agent1:                 episode reward: -0.4651,                 loss: 0.2580
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5751s / 106.5583 s
agent0:                 episode reward: -0.1948,                 loss: nan
agent1:                 episode reward: 0.1948,                 loss: 0.2617
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5877s / 107.1460 s
agent0:                 episode reward: 0.9201,                 loss: nan
agent1:                 episode reward: -0.9201,                 loss: 0.2520
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5866s / 107.7326 s
agent0:                 episode reward: 1.0327,                 loss: nan
agent1:                 episode reward: -1.0327,                 loss: 0.2509
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5779s / 108.3105 s
agent0:                 episode reward: 0.8849,                 loss: nan
agent1:                 episode reward: -0.8849,                 loss: 0.2470
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5890s / 108.8995 s
agent0:                 episode reward: 0.8411,                 loss: nan
agent1:                 episode reward: -0.8411,                 loss: 0.2484
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6023s / 109.5018 s
agent0:                 episode reward: 0.4691,                 loss: nan
agent1:                 episode reward: -0.4691,                 loss: 0.2477
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5869s / 110.0887 s
agent0:                 episode reward: -0.1165,                 loss: nan
agent1:                 episode reward: 0.1165,                 loss: 0.2497
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6060s / 110.6947 s
agent0:                 episode reward: 0.4029,                 loss: nan
agent1:                 episode reward: -0.4029,                 loss: 0.2482
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5943s / 111.2889 s
agent0:                 episode reward: -0.1377,                 loss: nan
agent1:                 episode reward: 0.1377,                 loss: 0.2485
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5857s / 111.8747 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: 0.2484
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5932s / 112.4679 s
agent0:                 episode reward: 0.5982,                 loss: nan
agent1:                 episode reward: -0.5982,                 loss: 0.2772
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5906s / 113.0584 s
agent0:                 episode reward: 0.4786,                 loss: nan
agent1:                 episode reward: -0.4786,                 loss: 0.2804
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5877s / 113.6461 s
agent0:                 episode reward: 0.2613,                 loss: nan
agent1:                 episode reward: -0.2613,                 loss: 0.2781
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6503s / 114.2964 s
agent0:                 episode reward: 0.8349,                 loss: nan
agent1:                 episode reward: -0.8349,                 loss: 0.2776
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5922s / 114.8887 s
agent0:                 episode reward: 0.6262,                 loss: nan
agent1:                 episode reward: -0.6262,                 loss: 0.2782
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6428s / 115.5315 s
agent0:                 episode reward: 0.7257,                 loss: nan
agent1:                 episode reward: -0.7257,                 loss: 0.2766
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5887s / 116.1201 s
agent0:                 episode reward: 0.6589,                 loss: nan
agent1:                 episode reward: -0.6589,                 loss: 0.2779
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5869s / 116.7070 s
agent0:                 episode reward: 0.4991,                 loss: nan
agent1:                 episode reward: -0.4991,                 loss: 0.2782
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5911s / 117.2981 s
agent0:                 episode reward: 0.8857,                 loss: nan
agent1:                 episode reward: -0.8857,                 loss: 0.2762
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5934s / 117.8915 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.2774
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6116s / 118.5032 s
agent0:                 episode reward: 0.2859,                 loss: nan
agent1:                 episode reward: -0.2859,                 loss: 0.3184
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5927s / 119.0958 s
agent0:                 episode reward: -0.2493,                 loss: nan
agent1:                 episode reward: 0.2493,                 loss: 0.3241
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5996s / 119.6954 s
agent0:                 episode reward: 1.1761,                 loss: nan
agent1:                 episode reward: -1.1761,                 loss: 0.3202
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5988s / 120.2943 s
agent0:                 episode reward: 0.0057,                 loss: nan
agent1:                 episode reward: -0.0057,                 loss: 0.3178
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5837s / 120.8780 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.3171
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5936s / 121.4715 s
agent0:                 episode reward: 0.3441,                 loss: nan
agent1:                 episode reward: -0.3441,                 loss: 0.3153
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6254s / 122.0969 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.3193
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6001s / 122.6970 s
agent0:                 episode reward: -0.1134,                 loss: nan
agent1:                 episode reward: 0.1134,                 loss: 0.3164
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5854s / 123.2824 s
agent0:                 episode reward: -0.3447,                 loss: nan
agent1:                 episode reward: 0.3447,                 loss: 0.3139
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6042s / 123.8867 s
agent0:                 episode reward: 0.6620,                 loss: nan
agent1:                 episode reward: -0.6620,                 loss: 0.3132
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6538s / 124.5405 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.3183
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6037s / 125.1442 s
agent0:                 episode reward: -1.5495,                 loss: nan
agent1:                 episode reward: 1.5495,                 loss: 0.2953
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6050s / 125.7492 s
agent0:                 episode reward: -0.1963,                 loss: nan
agent1:                 episode reward: 0.1963,                 loss: 0.2876
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6058s / 126.3550 s
agent0:                 episode reward: 0.3927,                 loss: nan
agent1:                 episode reward: -0.3927,                 loss: 0.2867
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6409s / 126.9959 s
agent0:                 episode reward: -0.5664,                 loss: nan
agent1:                 episode reward: 0.5664,                 loss: 0.2862
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6027s / 127.5986 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.2897
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6035s / 128.2021 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.2851
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6206s / 128.8227 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.2859
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5929s / 129.4156 s
agent0:                 episode reward: -1.3670,                 loss: nan
agent1:                 episode reward: 1.3670,                 loss: 0.2847
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6159s / 130.0315 s
agent0:                 episode reward: 0.0038,                 loss: nan
agent1:                 episode reward: -0.0038,                 loss: 0.2854
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6050s / 130.6365 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: 0.2455
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6062s / 131.2427 s
agent0:                 episode reward: 0.3592,                 loss: nan
agent1:                 episode reward: -0.3592,                 loss: 0.2052
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5933s / 131.8360 s
agent0:                 episode reward: 0.1845,                 loss: nan
agent1:                 episode reward: -0.1845,                 loss: 0.2041
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6024s / 132.4383 s
agent0:                 episode reward: 1.1652,                 loss: nan
agent1:                 episode reward: -1.1652,                 loss: 0.2031
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6011s / 133.0395 s
agent0:                 episode reward: 0.4493,                 loss: nan
agent1:                 episode reward: -0.4493,                 loss: 0.2033
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6030s / 133.6425 s
agent0:                 episode reward: 0.2107,                 loss: nan
agent1:                 episode reward: -0.2107,                 loss: 0.2017
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6042s / 134.2468 s
agent0:                 episode reward: 0.0019,                 loss: nan
agent1:                 episode reward: -0.0019,                 loss: 0.2009
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6521s / 134.8989 s
agent0:                 episode reward: 0.9477,                 loss: nan
agent1:                 episode reward: -0.9477,                 loss: 0.2023
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6210s / 135.5199 s
agent0:                 episode reward: 0.1883,                 loss: nan
agent1:                 episode reward: -0.1883,                 loss: 0.2027
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6078s / 136.1276 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.2032
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6089s / 136.7365 s
agent0:                 episode reward: 0.3117,                 loss: nan
agent1:                 episode reward: -0.3117,                 loss: 0.1981
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6048s / 137.3413 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.1901
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6081s / 137.9493 s
agent0:                 episode reward: 0.4505,                 loss: nan
agent1:                 episode reward: -0.4505,                 loss: 0.1840
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6164s / 138.5657 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.1835
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6170s / 139.1827 s
agent0:                 episode reward: -0.3071,                 loss: nan
agent1:                 episode reward: 0.3071,                 loss: 0.1848
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6045s / 139.7872 s
agent0:                 episode reward: 0.2698,                 loss: nan
agent1:                 episode reward: -0.2698,                 loss: 0.1830
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6151s / 140.4023 s
agent0:                 episode reward: 0.0504,                 loss: nan
agent1:                 episode reward: -0.0504,                 loss: 0.1835
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6131s / 141.0154 s
agent0:                 episode reward: -0.7908,                 loss: nan
agent1:                 episode reward: 0.7908,                 loss: 0.1814
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6109s / 141.6264 s
agent0:                 episode reward: 0.1996,                 loss: nan
agent1:                 episode reward: -0.1996,                 loss: 0.1810
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6194s / 142.2457 s
agent0:                 episode reward: 1.0309,                 loss: nan
agent1:                 episode reward: -1.0309,                 loss: 0.1827
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6228s / 142.8685 s
agent0:                 episode reward: 0.8878,                 loss: nan
agent1:                 episode reward: -0.8878,                 loss: 0.2168
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 143.4961 s
agent0:                 episode reward: 0.2046,                 loss: nan
agent1:                 episode reward: -0.2046,                 loss: 0.2217
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6376s / 144.1338 s
agent0:                 episode reward: -0.3176,                 loss: nan
agent1:                 episode reward: 0.3176,                 loss: 0.2209
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6319s / 144.7657 s
agent0:                 episode reward: 0.2227,                 loss: nan
agent1:                 episode reward: -0.2227,                 loss: 0.2214
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6824s / 145.4480 s
agent0:                 episode reward: 0.1244,                 loss: nan
agent1:                 episode reward: -0.1244,                 loss: 0.2226
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6204s / 146.0684 s
agent0:                 episode reward: -0.0685,                 loss: nan
agent1:                 episode reward: 0.0685,                 loss: 0.2217
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6155s / 146.6840 s
agent0:                 episode reward: 0.1399,                 loss: nan
agent1:                 episode reward: -0.1399,                 loss: 0.2207
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6151s / 147.2991 s
agent0:                 episode reward: 0.0542,                 loss: nan
agent1:                 episode reward: -0.0542,                 loss: 0.2209
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6290s / 147.9282 s
agent0:                 episode reward: 0.0425,                 loss: nan
agent1:                 episode reward: -0.0425,                 loss: 0.2196
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6336s / 148.5618 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.2202
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6195s / 149.1814 s
agent0:                 episode reward: -0.1765,                 loss: nan
agent1:                 episode reward: 0.1765,                 loss: 0.2454
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6177s / 149.7991 s
agent0:                 episode reward: -0.0446,                 loss: nan
agent1:                 episode reward: 0.0446,                 loss: 0.2464
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6314s / 150.4305 s
agent0:                 episode reward: -0.1254,                 loss: nan
agent1:                 episode reward: 0.1254,                 loss: 0.2465
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6165s / 151.0470 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.2482
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6186s / 151.6655 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.2450
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6540s / 152.3195 s
agent0:                 episode reward: 0.2827,                 loss: nan
agent1:                 episode reward: -0.2827,                 loss: 0.2450
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6157s / 152.9352 s
agent0:                 episode reward: 1.3058,                 loss: nan
agent1:                 episode reward: -1.3058,                 loss: 0.2459
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6185s / 153.5537 s
agent0:                 episode reward: 0.0758,                 loss: nan
agent1:                 episode reward: -0.0758,                 loss: 0.2448
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6364s / 154.1901 s
agent0:                 episode reward: -0.5060,                 loss: nan
agent1:                 episode reward: 0.5060,                 loss: 0.2458
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6164s / 154.8064 s
agent0:                 episode reward: 0.2006,                 loss: nan
agent1:                 episode reward: -0.2006,                 loss: 0.2443
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6721s / 155.4785 s
agent0:                 episode reward: 0.4232,                 loss: nan
agent1:                 episode reward: -0.4232,                 loss: 0.2656
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6300s / 156.1085 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.2558
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6203s / 156.7288 s
agent0:                 episode reward: -0.0471,                 loss: nan
agent1:                 episode reward: 0.0471,                 loss: 0.2555
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6246s / 157.3534 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.2540
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6248s / 157.9782 s
agent0:                 episode reward: -0.0322,                 loss: nan
agent1:                 episode reward: 0.0322,                 loss: 0.2525
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6230s / 158.6012 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.2531
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6217s / 159.2229 s
agent0:                 episode reward: 0.0395,                 loss: nan
agent1:                 episode reward: -0.0395,                 loss: 0.2519
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6284s / 159.8513 s
agent0:                 episode reward: 0.7773,                 loss: nan
agent1:                 episode reward: -0.7773,                 loss: 0.2501
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6689s / 160.5202 s
agent0:                 episode reward: 0.3011,                 loss: nan
agent1:                 episode reward: -0.3011,                 loss: 0.2522
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6253s / 161.1455 s
agent0:                 episode reward: -0.0251,                 loss: nan
agent1:                 episode reward: 0.0251,                 loss: 0.2529
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 161.7731 s
agent0:                 episode reward: 0.1763,                 loss: nan
agent1:                 episode reward: -0.1763,                 loss: 0.2545
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6292s / 162.4022 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.2364
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6463s / 163.0486 s
agent0:                 episode reward: 0.1130,                 loss: nan
agent1:                 episode reward: -0.1130,                 loss: 0.2338
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 163.6761 s
agent0:                 episode reward: -0.7603,                 loss: nan
agent1:                 episode reward: 0.7603,                 loss: 0.2329
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6311s / 164.3073 s
agent0:                 episode reward: 0.0908,                 loss: nan
agent1:                 episode reward: -0.0908,                 loss: 0.2313
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6240s / 164.9313 s
agent0:                 episode reward: -0.0277,                 loss: nan
agent1:                 episode reward: 0.0277,                 loss: 0.2345
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6872s / 165.6185 s
agent0:                 episode reward: -0.1273,                 loss: nan
agent1:                 episode reward: 0.1273,                 loss: 0.2329
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6580s / 166.2764 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.2319
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6639s / 166.9403 s
agent0:                 episode reward: 0.8552,                 loss: nan
agent1:                 episode reward: -0.8552,                 loss: 0.2318
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6283s / 167.5686 s
agent0:                 episode reward: 0.3539,                 loss: nan
agent1:                 episode reward: -0.3539,                 loss: 0.2334
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6338s / 168.2024 s
agent0:                 episode reward: -0.0041,                 loss: nan
agent1:                 episode reward: 0.0041,                 loss: 0.2573
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6502s / 168.8527 s
agent0:                 episode reward: 0.0401,                 loss: nan
agent1:                 episode reward: -0.0401,                 loss: 0.2595
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6343s / 169.4870 s
agent0:                 episode reward: -0.0290,                 loss: nan
agent1:                 episode reward: 0.0290,                 loss: 0.2580
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6298s / 170.1167 s
agent0:                 episode reward: -0.3581,                 loss: nan
agent1:                 episode reward: 0.3581,                 loss: 0.2584
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6424s / 170.7591 s
agent0:                 episode reward: 0.5204,                 loss: nan
agent1:                 episode reward: -0.5204,                 loss: 0.2561
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6799s / 171.4390 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: 0.2591
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6342s / 172.0732 s
agent0:                 episode reward: 0.4990,                 loss: nan
agent1:                 episode reward: -0.4990,                 loss: 0.2558
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6430s / 172.7162 s
agent0:                 episode reward: 0.5746,                 loss: nan
agent1:                 episode reward: -0.5746,                 loss: 0.2571
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6479s / 173.3641 s
agent0:                 episode reward: -0.9752,                 loss: nan
agent1:                 episode reward: 0.9752,                 loss: 0.2567
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6294s / 173.9936 s
agent0:                 episode reward: 0.6398,                 loss: nan
agent1:                 episode reward: -0.6398,                 loss: 0.2553
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6356s / 174.6292 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.3066
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6402s / 175.2694 s
agent0:                 episode reward: 0.2568,                 loss: nan
agent1:                 episode reward: -0.2568,                 loss: 0.3210
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7166s / 175.9860 s
agent0:                 episode reward: 0.0844,                 loss: nan
agent1:                 episode reward: -0.0844,                 loss: 0.3155
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6351s / 176.6211 s
agent0:                 episode reward: 0.4074,                 loss: nan
agent1:                 episode reward: -0.4074,                 loss: 0.3164
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6535s / 177.2746 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3139
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6381s / 177.9127 s
agent0:                 episode reward: 0.3555,                 loss: nan
agent1:                 episode reward: -0.3555,                 loss: 0.3124
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6772s / 178.5900 s
agent0:                 episode reward: -0.5824,                 loss: nan
agent1:                 episode reward: 0.5824,                 loss: 0.3163
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6390s / 179.2290 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.3137
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6426s / 179.8716 s
agent0:                 episode reward: -0.3852,                 loss: nan
agent1:                 episode reward: 0.3852,                 loss: 0.3135
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6431s / 180.5147 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: 0.3112
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6381s / 181.1528 s
agent0:                 episode reward: 1.0805,                 loss: nan
agent1:                 episode reward: -1.0805,                 loss: 0.3426
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6594s / 181.8122 s
agent0:                 episode reward: 0.5977,                 loss: nan
agent1:                 episode reward: -0.5977,                 loss: 0.3406
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6351s / 182.4473 s
agent0:                 episode reward: -0.3034,                 loss: nan
agent1:                 episode reward: 0.3034,                 loss: 0.3393
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6456s / 183.0930 s
agent0:                 episode reward: 0.2713,                 loss: nan
agent1:                 episode reward: -0.2713,                 loss: 0.3377
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6546s / 183.7476 s
agent0:                 episode reward: -0.0738,                 loss: nan
agent1:                 episode reward: 0.0738,                 loss: 0.3369
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6865s / 184.4341 s
agent0:                 episode reward: -0.0596,                 loss: nan
agent1:                 episode reward: 0.0596,                 loss: 0.3367
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6609s / 185.0950 s
agent0:                 episode reward: -0.1343,                 loss: nan
agent1:                 episode reward: 0.1343,                 loss: 0.3340
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6753s / 185.7702 s
agent0:                 episode reward: -0.6744,                 loss: nan
agent1:                 episode reward: 0.6744,                 loss: 0.3349
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6632s / 186.4334 s
agent0:                 episode reward: -1.2803,                 loss: nan
agent1:                 episode reward: 1.2803,                 loss: 0.3377
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6397s / 187.0731 s
agent0:                 episode reward: 0.3305,                 loss: nan
agent1:                 episode reward: -0.3305,                 loss: 0.3349
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7117s / 187.7849 s
agent0:                 episode reward: 0.0607,                 loss: nan
agent1:                 episode reward: -0.0607,                 loss: 0.3034
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6480s / 188.4329 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: 0.2642
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6451s / 189.0779 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.2607
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6485s / 189.7265 s
agent0:                 episode reward: -0.1358,                 loss: nan
agent1:                 episode reward: 0.1358,                 loss: 0.2597
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6546s / 190.3811 s
agent0:                 episode reward: 0.0234,                 loss: nan
agent1:                 episode reward: -0.0234,                 loss: 0.2592
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6560s / 191.0371 s
agent0:                 episode reward: -0.2959,                 loss: nan
agent1:                 episode reward: 0.2959,                 loss: 0.2605
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6469s / 191.6840 s
agent0:                 episode reward: -0.1486,                 loss: nan
agent1:                 episode reward: 0.1486,                 loss: 0.2586
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6600s / 192.3440 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.2584
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6428s / 192.9868 s
agent0:                 episode reward: 0.2990,                 loss: nan
agent1:                 episode reward: -0.2990,                 loss: 0.2546
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7072s / 193.6939 s
agent0:                 episode reward: -0.4414,                 loss: nan
agent1:                 episode reward: 0.4414,                 loss: 0.2575
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6517s / 194.3456 s
agent0:                 episode reward: 0.3365,                 loss: nan
agent1:                 episode reward: -0.3365,                 loss: 0.2200
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6581s / 195.0038 s
agent0:                 episode reward: 0.2275,                 loss: nan
agent1:                 episode reward: -0.2275,                 loss: 0.1876
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6519s / 195.6556 s
agent0:                 episode reward: -0.3686,                 loss: nan
agent1:                 episode reward: 0.3686,                 loss: 0.1873
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6988s / 196.3544 s
agent0:                 episode reward: -0.4896,                 loss: nan
agent1:                 episode reward: 0.4896,                 loss: 0.1878
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6594s / 197.0139 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: 0.1866
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6540s / 197.6679 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.1850
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6616s / 198.3295 s
agent0:                 episode reward: -0.4033,                 loss: nan
agent1:                 episode reward: 0.4033,                 loss: 0.1848
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6620s / 198.9914 s
agent0:                 episode reward: 0.4726,                 loss: nan
agent1:                 episode reward: -0.4726,                 loss: 0.1865
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6691s / 199.6605 s
agent0:                 episode reward: -0.2040,                 loss: nan
agent1:                 episode reward: 0.2040,                 loss: 0.1853
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6575s / 200.3180 s
agent0:                 episode reward: -0.3293,                 loss: nan
agent1:                 episode reward: 0.3293,                 loss: 0.1849
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6650s / 200.9830 s
agent0:                 episode reward: 0.1642,                 loss: nan
agent1:                 episode reward: -0.1642,                 loss: 0.1976
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6719s / 201.6549 s
agent0:                 episode reward: -0.8701,                 loss: nan
agent1:                 episode reward: 0.8701,                 loss: 0.1935
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6646s / 202.3195 s
agent0:                 episode reward: -0.4020,                 loss: nan
agent1:                 episode reward: 0.4020,                 loss: 0.1901
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6948s / 203.0143 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.1886
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6583s / 203.6726 s
agent0:                 episode reward: 0.3529,                 loss: nan
agent1:                 episode reward: -0.3529,                 loss: 0.1891
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6657s / 204.3382 s
agent0:                 episode reward: -1.0449,                 loss: nan
agent1:                 episode reward: 1.0449,                 loss: 0.1886
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6677s / 205.0060 s
agent0:                 episode reward: 1.0370,                 loss: nan
agent1:                 episode reward: -1.0370,                 loss: 0.1871
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6608s / 205.6668 s
agent0:                 episode reward: 0.2560,                 loss: nan
agent1:                 episode reward: -0.2560,                 loss: 0.1892
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6972s / 206.3640 s
agent0:                 episode reward: -0.4265,                 loss: nan
agent1:                 episode reward: 0.4265,                 loss: 0.1882
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6690s / 207.0330 s
agent0:                 episode reward: -0.3479,                 loss: nan
agent1:                 episode reward: 0.3479,                 loss: 0.1911
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6642s / 207.6972 s
agent0:                 episode reward: -0.2474,                 loss: nan
agent1:                 episode reward: 0.2474,                 loss: 0.2175
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6649s / 208.3621 s
agent0:                 episode reward: 0.3938,                 loss: nan
agent1:                 episode reward: -0.3938,                 loss: 0.2225
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6732s / 209.0353 s
agent0:                 episode reward: 0.0761,                 loss: nan
agent1:                 episode reward: -0.0761,                 loss: 0.2231
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6735s / 209.7088 s
agent0:                 episode reward: 0.7840,                 loss: nan
agent1:                 episode reward: -0.7840,                 loss: 0.2226
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7153s / 210.4241 s
agent0:                 episode reward: 0.4464,                 loss: nan
agent1:                 episode reward: -0.4464,                 loss: 0.2202
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6850s / 211.1091 s
agent0:                 episode reward: -0.0739,                 loss: nan
agent1:                 episode reward: 0.0739,                 loss: 0.2198
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6769s / 211.7860 s
agent0:                 episode reward: 0.2306,                 loss: nan
agent1:                 episode reward: -0.2306,                 loss: 0.2219
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6708s / 212.4568 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.2214
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6721s / 213.1289 s
agent0:                 episode reward: -0.1381,                 loss: nan
agent1:                 episode reward: 0.1381,                 loss: 0.2188
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6781s / 213.8069 s
agent0:                 episode reward: -0.1574,                 loss: nan
agent1:                 episode reward: 0.1574,                 loss: 0.2204
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6672s / 214.4741 s
agent0:                 episode reward: 0.0887,                 loss: nan
agent1:                 episode reward: -0.0887,                 loss: 0.2466
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6794s / 215.1536 s
agent0:                 episode reward: -1.3783,                 loss: nan
agent1:                 episode reward: 1.3783,                 loss: 0.2514
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6728s / 215.8264 s
agent0:                 episode reward: 0.9556,                 loss: nan
agent1:                 episode reward: -0.9556,                 loss: 0.2513
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7057s / 216.5321 s
agent0:                 episode reward: -0.6008,                 loss: nan
agent1:                 episode reward: 0.6008,                 loss: 0.2489
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6898s / 217.2219 s
agent0:                 episode reward: -0.0336,                 loss: nan
agent1:                 episode reward: 0.0336,                 loss: 0.2493
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6850s / 217.9069 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.2462
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6999s / 218.6067 s
agent0:                 episode reward: 0.1651,                 loss: nan
agent1:                 episode reward: -0.1651,                 loss: 0.2466
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6757s / 219.2824 s
agent0:                 episode reward: -1.1326,                 loss: nan
agent1:                 episode reward: 1.1326,                 loss: 0.2453
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6869s / 219.9693 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.2469
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6831s / 220.6524 s
agent0:                 episode reward: 0.4037,                 loss: nan
agent1:                 episode reward: -0.4037,                 loss: 0.2460
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6755s / 221.3278 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.2662
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6783s / 222.0061 s
agent0:                 episode reward: 0.4081,                 loss: nan
agent1:                 episode reward: -0.4081,                 loss: 0.2606
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6840s / 222.6901 s
agent0:                 episode reward: 0.5957,                 loss: nan
agent1:                 episode reward: -0.5957,                 loss: 0.2605
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6766s / 223.3667 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: 0.2596
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6831s / 224.0498 s
agent0:                 episode reward: -0.1375,                 loss: nan
agent1:                 episode reward: 0.1375,                 loss: 0.2613
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6776s / 224.7274 s
agent0:                 episode reward: 0.0510,                 loss: nan
agent1:                 episode reward: -0.0510,                 loss: 0.2594
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6853s / 225.4127 s
agent0:                 episode reward: 0.2055,                 loss: nan
agent1:                 episode reward: -0.2055,                 loss: 0.2585
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6766s / 226.0892 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: 0.2598
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7945s / 226.8838 s
agent0:                 episode reward: -0.6901,                 loss: nan
agent1:                 episode reward: 0.6901,                 loss: 0.2575
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6770s / 227.5607 s
agent0:                 episode reward: 0.6767,                 loss: nan
agent1:                 episode reward: -0.6767,                 loss: 0.2574
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6804s / 228.2411 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.2587
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6835s / 228.9246 s
agent0:                 episode reward: 1.1352,                 loss: nan
agent1:                 episode reward: -1.1352,                 loss: 0.2466
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6752s / 229.5998 s
agent0:                 episode reward: 0.5152,                 loss: nan
agent1:                 episode reward: -0.5152,                 loss: 0.2458
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6857s / 230.2855 s
agent0:                 episode reward: -0.2998,                 loss: nan
agent1:                 episode reward: 0.2998,                 loss: 0.2446
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6962s / 230.9817 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.2423
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6870s / 231.6687 s
agent0:                 episode reward: 0.5676,                 loss: nan
agent1:                 episode reward: -0.5676,                 loss: 0.2427
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6921s / 232.3608 s
agent0:                 episode reward: -0.0988,                 loss: nan
agent1:                 episode reward: 0.0988,                 loss: 0.2428
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6990s / 233.0598 s
agent0:                 episode reward: -0.2476,                 loss: nan
agent1:                 episode reward: 0.2476,                 loss: 0.2437
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6821s / 233.7419 s
agent0:                 episode reward: 0.4436,                 loss: nan
agent1:                 episode reward: -0.4436,                 loss: 0.2431
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6860s / 234.4278 s
agent0:                 episode reward: -0.2269,                 loss: nan
agent1:                 episode reward: 0.2269,                 loss: 0.2397
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7051s / 235.1329 s
agent0:                 episode reward: -0.7923,                 loss: nan
agent1:                 episode reward: 0.7923,                 loss: 0.2603
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6936s / 235.8265 s
agent0:                 episode reward: 0.9063,                 loss: nan
agent1:                 episode reward: -0.9063,                 loss: 0.2551
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6918s / 236.5183 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.2516
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7404s / 237.2587 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.2539
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7174s / 237.9761 s
agent0:                 episode reward: 0.5555,                 loss: nan
agent1:                 episode reward: -0.5555,                 loss: 0.2508
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6998s / 238.6759 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.2523
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6859s / 239.3617 s
agent0:                 episode reward: -0.4099,                 loss: nan
agent1:                 episode reward: 0.4099,                 loss: 0.2513
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6891s / 240.0508 s
agent0:                 episode reward: 0.3471,                 loss: nan
agent1:                 episode reward: -0.3471,                 loss: 0.2505
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6938s / 240.7447 s
agent0:                 episode reward: 1.1252,                 loss: nan
agent1:                 episode reward: -1.1252,                 loss: 0.2477
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6995s / 241.4442 s
agent0:                 episode reward: 0.4710,                 loss: nan
agent1:                 episode reward: -0.4710,                 loss: 0.2503
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6977s / 242.1419 s
agent0:                 episode reward: -0.2025,                 loss: nan
agent1:                 episode reward: 0.2025,                 loss: 0.2879
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6974s / 242.8393 s
agent0:                 episode reward: -0.0667,                 loss: nan
agent1:                 episode reward: 0.0667,                 loss: 0.2933
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7432s / 243.5826 s
agent0:                 episode reward: 0.7764,                 loss: nan
agent1:                 episode reward: -0.7764,                 loss: 0.2946
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 244.2674 s
agent0:                 episode reward: -0.0976,                 loss: nan
agent1:                 episode reward: 0.0976,                 loss: 0.2904
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7169s / 244.9843 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.2901
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6961s / 245.6804 s
agent0:                 episode reward: -0.3666,                 loss: nan
agent1:                 episode reward: 0.3666,                 loss: 0.2904
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6877s / 246.3681 s
agent0:                 episode reward: -0.0821,                 loss: nan
agent1:                 episode reward: 0.0821,                 loss: 0.2877
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7095s / 247.0776 s
agent0:                 episode reward: -0.7766,                 loss: nan
agent1:                 episode reward: 0.7766,                 loss: 0.2884
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7472s / 247.8248 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.2853
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6957s / 248.5205 s
agent0:                 episode reward: -0.2533,                 loss: nan
agent1:                 episode reward: 0.2533,                 loss: 0.2872
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6940s / 249.2145 s
agent0:                 episode reward: -0.0925,                 loss: nan
agent1:                 episode reward: 0.0925,                 loss: 0.3052
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6920s / 249.9065 s
agent0:                 episode reward: 0.1007,                 loss: nan
agent1:                 episode reward: -0.1007,                 loss: 0.2885
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6907s / 250.5972 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.2880
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7024s / 251.2996 s
agent0:                 episode reward: 0.0305,                 loss: nan
agent1:                 episode reward: -0.0305,                 loss: 0.2860
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7249s / 252.0245 s
agent0:                 episode reward: -0.3913,                 loss: nan
agent1:                 episode reward: 0.3913,                 loss: 0.2844
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7392s / 252.7637 s
agent0:                 episode reward: -0.6920,                 loss: nan
agent1:                 episode reward: 0.6920,                 loss: 0.2836
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6945s / 253.4582 s
agent0:                 episode reward: 0.2684,                 loss: nan
agent1:                 episode reward: -0.2684,                 loss: 0.2844
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7049s / 254.1632 s
agent0:                 episode reward: -0.3368,                 loss: nan
agent1:                 episode reward: 0.3368,                 loss: 0.2842
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6919s / 254.8550 s
agent0:                 episode reward: -0.3289,                 loss: nan
agent1:                 episode reward: 0.3289,                 loss: 0.2842
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6975s / 255.5525 s
agent0:                 episode reward: -0.4876,                 loss: nan
agent1:                 episode reward: 0.4876,                 loss: 0.2852
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7011s / 256.2536 s
agent0:                 episode reward: 0.0254,                 loss: nan
agent1:                 episode reward: -0.0254,                 loss: 0.2368
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7085s / 256.9620 s
agent0:                 episode reward: -1.3392,                 loss: nan
agent1:                 episode reward: 1.3392,                 loss: 0.1948
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7358s / 257.6978 s
agent0:                 episode reward: -0.5735,                 loss: nan
agent1:                 episode reward: 0.5735,                 loss: 0.1937
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7050s / 258.4028 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.1941
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6961s / 259.0989 s
agent0:                 episode reward: 0.1525,                 loss: nan
agent1:                 episode reward: -0.1525,                 loss: 0.1943
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7139s / 259.8128 s
agent0:                 episode reward: -0.3017,                 loss: nan
agent1:                 episode reward: 0.3017,                 loss: 0.1934
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7046s / 260.5174 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.1936
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6973s / 261.2146 s
agent0:                 episode reward: 0.9286,                 loss: nan
agent1:                 episode reward: -0.9286,                 loss: 0.1918
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7078s / 261.9224 s
agent0:                 episode reward: -1.1981,                 loss: nan
agent1:                 episode reward: 1.1981,                 loss: 0.1922
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7034s / 262.6258 s
agent0:                 episode reward: 0.2560,                 loss: nan
agent1:                 episode reward: -0.2560,                 loss: 0.1922
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7273s / 263.3530 s
agent0:                 episode reward: -0.1751,                 loss: nan
agent1:                 episode reward: 0.1751,                 loss: 0.1803
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7335s / 264.0865 s
agent0:                 episode reward: 0.3838,                 loss: nan
agent1:                 episode reward: -0.3838,                 loss: 0.1647
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7082s / 264.7947 s
agent0:                 episode reward: -0.1572,                 loss: nan
agent1:                 episode reward: 0.1572,                 loss: 0.1612
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7064s / 265.5011 s
agent0:                 episode reward: -0.8428,                 loss: nan
agent1:                 episode reward: 0.8428,                 loss: 0.1609
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7187s / 266.2198 s
agent0:                 episode reward: -0.1553,                 loss: nan
agent1:                 episode reward: 0.1553,                 loss: 0.1579
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7142s / 266.9340 s
agent0:                 episode reward: 0.1582,                 loss: nan
agent1:                 episode reward: -0.1582,                 loss: 0.1576
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7467s / 267.6807 s
agent0:                 episode reward: -0.1623,                 loss: nan
agent1:                 episode reward: 0.1623,                 loss: 0.1587
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7308s / 268.4115 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: 0.1583
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 269.1438 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: 0.1597
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7081s / 269.8519 s
agent0:                 episode reward: 0.2590,                 loss: nan
agent1:                 episode reward: -0.2590,                 loss: 0.1590
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7065s / 270.5584 s
agent0:                 episode reward: 0.0890,                 loss: nan
agent1:                 episode reward: -0.0890,                 loss: 0.1846
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7088s / 271.2671 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1815
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7206s / 271.9877 s
agent0:                 episode reward: -0.0770,                 loss: nan
agent1:                 episode reward: 0.0770,                 loss: 0.1815
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7121s / 272.6998 s
agent0:                 episode reward: -0.3896,                 loss: nan
agent1:                 episode reward: 0.3896,                 loss: 0.1805
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7083s / 273.4081 s
agent0:                 episode reward: -1.1898,                 loss: nan
agent1:                 episode reward: 1.1898,                 loss: 0.1801
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7107s / 274.1188 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.1828
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7098s / 274.8286 s
agent0:                 episode reward: 0.2786,                 loss: nan
agent1:                 episode reward: -0.2786,                 loss: 0.1808
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7247s / 275.5532 s
agent0:                 episode reward: -0.0835,                 loss: nan
agent1:                 episode reward: 0.0835,                 loss: 0.1805
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7118s / 276.2650 s
agent0:                 episode reward: 0.5768,                 loss: nan
agent1:                 episode reward: -0.5768,                 loss: 0.1799
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7322s / 276.9973 s
agent0:                 episode reward: -0.0829,                 loss: nan
agent1:                 episode reward: 0.0829,                 loss: 0.1806
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7233s / 277.7206 s
agent0:                 episode reward: 0.2240,                 loss: nan
agent1:                 episode reward: -0.2240,                 loss: 0.2210
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7894s / 278.5100 s
agent0:                 episode reward: -1.4053,                 loss: nan
agent1:                 episode reward: 1.4053,                 loss: 0.2256
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7139s / 279.2239 s
agent0:                 episode reward: 0.1398,                 loss: nan
agent1:                 episode reward: -0.1398,                 loss: 0.2220
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7441s / 279.9679 s
agent0:                 episode reward: -0.3929,                 loss: nan
agent1:                 episode reward: 0.3929,                 loss: 0.2255
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7335s / 280.7014 s
agent0:                 episode reward: -0.0902,                 loss: nan
agent1:                 episode reward: 0.0902,                 loss: 0.2221
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7428s / 281.4442 s
agent0:                 episode reward: 0.2263,                 loss: nan
agent1:                 episode reward: -0.2263,                 loss: 0.2258
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7260s / 282.1702 s
agent0:                 episode reward: 0.1106,                 loss: nan
agent1:                 episode reward: -0.1106,                 loss: 0.2235
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7187s / 282.8889 s
agent0:                 episode reward: -0.6339,                 loss: nan
agent1:                 episode reward: 0.6339,                 loss: 0.2243
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7231s / 283.6120 s
agent0:                 episode reward: -0.8710,                 loss: nan
agent1:                 episode reward: 0.8710,                 loss: 0.2259
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7375s / 284.3495 s
agent0:                 episode reward: -0.9409,                 loss: nan
agent1:                 episode reward: 0.9409,                 loss: 0.2245
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7310s / 285.0805 s
agent0:                 episode reward: 0.0385,                 loss: nan
agent1:                 episode reward: -0.0385,                 loss: 0.2589
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7168s / 285.7973 s
agent0:                 episode reward: -0.6799,                 loss: nan
agent1:                 episode reward: 0.6799,                 loss: 0.2617
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7414s / 286.5387 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.2612
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7233s / 287.2620 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.2629
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7268s / 287.9888 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.2625
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7668s / 288.7557 s
agent0:                 episode reward: 0.3608,                 loss: nan
agent1:                 episode reward: -0.3608,                 loss: 0.2582
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7219s / 289.4776 s
agent0:                 episode reward: -0.4998,                 loss: nan
agent1:                 episode reward: 0.4998,                 loss: 0.2624
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7263s / 290.2039 s
agent0:                 episode reward: 0.2681,                 loss: nan
agent1:                 episode reward: -0.2681,                 loss: 0.2604
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7294s / 290.9333 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.2620
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7241s / 291.6574 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.2595
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7345s / 292.3919 s
agent0:                 episode reward: 0.2099,                 loss: nan
agent1:                 episode reward: -0.2099,                 loss: 0.2815
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7558s / 293.1476 s
agent0:                 episode reward: 0.2375,                 loss: nan
agent1:                 episode reward: -0.2375,                 loss: 0.2767
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7279s / 293.8756 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.2762
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7214s / 294.5970 s
agent0:                 episode reward: -0.7917,                 loss: nan
agent1:                 episode reward: 0.7917,                 loss: 0.2766
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7285s / 295.3255 s
agent0:                 episode reward: 0.9919,                 loss: nan
agent1:                 episode reward: -0.9919,                 loss: 0.2761
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7326s / 296.0581 s
agent0:                 episode reward: 0.0691,                 loss: nan
agent1:                 episode reward: -0.0691,                 loss: 0.2754
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7329s / 296.7910 s
agent0:                 episode reward: 0.9483,                 loss: nan
agent1:                 episode reward: -0.9483,                 loss: 0.2772
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7371s / 297.5281 s
agent0:                 episode reward: -0.0914,                 loss: nan
agent1:                 episode reward: 0.0914,                 loss: 0.2755
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7242s / 298.2523 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.2761
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7815s / 299.0339 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.2766
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7462s / 299.7800 s
agent0:                 episode reward: 0.0750,                 loss: nan
agent1:                 episode reward: -0.0750,                 loss: 0.2669
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7347s / 300.5147 s
agent0:                 episode reward: -0.9595,                 loss: nan
agent1:                 episode reward: 0.9595,                 loss: 0.2515
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7562s / 301.2709 s
agent0:                 episode reward: 1.0712,                 loss: nan
agent1:                 episode reward: -1.0712,                 loss: 0.2506
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7397s / 302.0106 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.2509
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7783s / 302.7889 s
agent0:                 episode reward: 0.2923,                 loss: nan
agent1:                 episode reward: -0.2923,                 loss: 0.2517
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7400s / 303.5289 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.2504
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7659s / 304.2947 s
agent0:                 episode reward: 0.1535,                 loss: nan
agent1:                 episode reward: -0.1535,                 loss: 0.2519
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7958s / 305.0906 s
agent0:                 episode reward: -0.5622,                 loss: nan
agent1:                 episode reward: 0.5622,                 loss: 0.2526
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7695s / 305.8600 s
agent0:                 episode reward: -0.0185,                 loss: nan
agent1:                 episode reward: 0.0185,                 loss: 0.2510
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7332s / 306.5933 s
agent0:                 episode reward: 0.1920,                 loss: nan
agent1:                 episode reward: -0.1920,                 loss: 0.2505
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7415s / 307.3348 s
agent0:                 episode reward: -0.7840,                 loss: nan
agent1:                 episode reward: 0.7840,                 loss: 0.2804
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7422s / 308.0771 s
agent0:                 episode reward: -0.7931,                 loss: nan
agent1:                 episode reward: 0.7931,                 loss: 0.2778
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8054s / 308.8825 s
agent0:                 episode reward: 0.6432,                 loss: nan
agent1:                 episode reward: -0.6432,                 loss: 0.2777
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7609s / 309.6434 s
agent0:                 episode reward: -0.5511,                 loss: nan
agent1:                 episode reward: 0.5511,                 loss: 0.2777
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7489s / 310.3923 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.2761
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7408s / 311.1331 s
agent0:                 episode reward: -0.0153,                 loss: nan
agent1:                 episode reward: 0.0153,                 loss: 0.2744
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7473s / 311.8804 s
agent0:                 episode reward: 0.9805,                 loss: nan
agent1:                 episode reward: -0.9805,                 loss: 0.2765
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7560s / 312.6364 s
agent0:                 episode reward: 0.4766,                 loss: nan
agent1:                 episode reward: -0.4766,                 loss: 0.2741
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7431s / 313.3794 s
agent0:                 episode reward: -0.1345,                 loss: nan
agent1:                 episode reward: 0.1345,                 loss: 0.2737
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7494s / 314.1289 s
agent0:                 episode reward: 0.0693,                 loss: nan
agent1:                 episode reward: -0.0693,                 loss: 0.2725
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7475s / 314.8764 s
agent0:                 episode reward: 1.0987,                 loss: nan
agent1:                 episode reward: -1.0987,                 loss: 0.3093
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7744s / 315.6508 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.3041
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7655s / 316.4163 s
agent0:                 episode reward: 0.0213,                 loss: nan
agent1:                 episode reward: -0.0213,                 loss: 0.3053
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7573s / 317.1736 s
agent0:                 episode reward: 0.4455,                 loss: nan
agent1:                 episode reward: -0.4455,                 loss: 0.3010
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7740s / 317.9476 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.3020
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7584s / 318.7060 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: 0.2994
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8323s / 319.5383 s
agent0:                 episode reward: -0.4216,                 loss: nan
agent1:                 episode reward: 0.4216,                 loss: 0.2975
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7619s / 320.3002 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.2996
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7575s / 321.0578 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.3001
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7409s / 321.7987 s
agent0:                 episode reward: 0.1481,                 loss: nan
agent1:                 episode reward: -0.1481,                 loss: 0.2975
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7586s / 322.5573 s
agent0:                 episode reward: 0.3150,                 loss: nan
agent1:                 episode reward: -0.3150,                 loss: 0.2778
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7729s / 323.3302 s
agent0:                 episode reward: 0.7818,                 loss: nan
agent1:                 episode reward: -0.7818,                 loss: 0.2482
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7515s / 324.0817 s
agent0:                 episode reward: 0.6042,                 loss: nan
agent1:                 episode reward: -0.6042,                 loss: 0.2465
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7493s / 324.8310 s
agent0:                 episode reward: 0.1669,                 loss: nan
agent1:                 episode reward: -0.1669,                 loss: 0.2481
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7599s / 325.5909 s
agent0:                 episode reward: -0.0797,                 loss: nan
agent1:                 episode reward: 0.0797,                 loss: 0.2477
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8219s / 326.4128 s
agent0:                 episode reward: 0.0535,                 loss: nan
agent1:                 episode reward: -0.0535,                 loss: 0.2447
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7690s / 327.1819 s
agent0:                 episode reward: -0.0500,                 loss: nan
agent1:                 episode reward: 0.0500,                 loss: 0.2426
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7859s / 327.9678 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.2453
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7825s / 328.7503 s
agent0:                 episode reward: 0.1460,                 loss: nan
agent1:                 episode reward: -0.1460,                 loss: 0.2440
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8175s / 329.5678 s
agent0:                 episode reward: -0.6529,                 loss: nan
agent1:                 episode reward: 0.6529,                 loss: 0.2455
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7495s / 330.3173 s
agent0:                 episode reward: -0.7468,                 loss: nan
agent1:                 episode reward: 0.7468,                 loss: 0.2040
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7614s / 331.0787 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: 0.1677
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7681s / 331.8467 s
agent0:                 episode reward: -0.9025,                 loss: nan
agent1:                 episode reward: 0.9025,                 loss: 0.1652
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 332.6218 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1647
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7588s / 333.3806 s
agent0:                 episode reward: 0.0686,                 loss: nan
agent1:                 episode reward: -0.0686,                 loss: 0.1658
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7656s / 334.1462 s
agent0:                 episode reward: -0.7274,                 loss: nan
agent1:                 episode reward: 0.7274,                 loss: 0.1635
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 334.9242 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.1636
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7740s / 335.6982 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: 0.1637
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 336.4510 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.1626
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7658s / 337.2168 s
agent0:                 episode reward: -1.3523,                 loss: nan
agent1:                 episode reward: 1.3523,                 loss: 0.1644
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7755s / 337.9923 s
agent0:                 episode reward: -1.2976,                 loss: nan
agent1:                 episode reward: 1.2976,                 loss: 0.1685
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7666s / 338.7589 s
agent0:                 episode reward: -0.3582,                 loss: nan
agent1:                 episode reward: 0.3582,                 loss: 0.1614
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8336s / 339.5925 s
agent0:                 episode reward: 0.3113,                 loss: nan
agent1:                 episode reward: -0.3113,                 loss: 0.1591
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7677s / 340.3602 s
agent0:                 episode reward: 0.3604,                 loss: nan
agent1:                 episode reward: -0.3604,                 loss: 0.1574
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7627s / 341.1229 s
agent0:                 episode reward: -0.4107,                 loss: nan
agent1:                 episode reward: 0.4107,                 loss: 0.1554
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7696s / 341.8925 s
agent0:                 episode reward: 0.3915,                 loss: nan
agent1:                 episode reward: -0.3915,                 loss: 0.1553
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7793s / 342.6718 s
agent0:                 episode reward: 0.2497,                 loss: nan
agent1:                 episode reward: -0.2497,                 loss: 0.1547
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 343.4461 s
agent0:                 episode reward: 0.2957,                 loss: nan
agent1:                 episode reward: -0.2957,                 loss: 0.1541
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7735s / 344.2196 s
agent0:                 episode reward: 0.0445,                 loss: nan
agent1:                 episode reward: -0.0445,                 loss: 0.1536
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 345.0047 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.1543
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7675s / 345.7722 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.1812
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7777s / 346.5499 s
agent0:                 episode reward: -0.4452,                 loss: nan
agent1:                 episode reward: 0.4452,                 loss: 0.1813
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7724s / 347.3223 s
agent0:                 episode reward: -0.7437,                 loss: nan
agent1:                 episode reward: 0.7437,                 loss: 0.1827
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8004s / 348.1228 s
agent0:                 episode reward: 0.4779,                 loss: nan
agent1:                 episode reward: -0.4779,                 loss: 0.1826
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7903s / 348.9130 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.1808
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8063s / 349.7193 s
agent0:                 episode reward: 0.3867,                 loss: nan
agent1:                 episode reward: -0.3867,                 loss: 0.1813
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8107s / 350.5300 s
agent0:                 episode reward: -0.3406,                 loss: nan
agent1:                 episode reward: 0.3406,                 loss: 0.1810
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7928s / 351.3228 s
agent0:                 episode reward: 1.4405,                 loss: nan
agent1:                 episode reward: -1.4405,                 loss: 0.1820
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7748s / 352.0976 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1823
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7811s / 352.8787 s
agent0:                 episode reward: -0.9874,                 loss: nan
agent1:                 episode reward: 0.9874,                 loss: 0.1821
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7847s / 353.6634 s
agent0:                 episode reward: -0.1166,                 loss: nan
agent1:                 episode reward: 0.1166,                 loss: 0.2230
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7782s / 354.4416 s
agent0:                 episode reward: 0.1522,                 loss: nan
agent1:                 episode reward: -0.1522,                 loss: 0.2343
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 355.2301 s
agent0:                 episode reward: -0.2329,                 loss: nan
agent1:                 episode reward: 0.2329,                 loss: 0.2331
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7821s / 356.0121 s
agent0:                 episode reward: -0.3329,                 loss: nan
agent1:                 episode reward: 0.3329,                 loss: 0.2311
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7894s / 356.8016 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.2325
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7839s / 357.5854 s
agent0:                 episode reward: -0.1741,                 loss: nan
agent1:                 episode reward: 0.1741,                 loss: 0.2310
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7760s / 358.3614 s
agent0:                 episode reward: 0.2123,                 loss: nan
agent1:                 episode reward: -0.2123,                 loss: 0.2289
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7826s / 359.1440 s
agent0:                 episode reward: -0.3170,                 loss: nan
agent1:                 episode reward: 0.3170,                 loss: 0.2312
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8486s / 359.9926 s
agent0:                 episode reward: 0.0297,                 loss: nan
agent1:                 episode reward: -0.0297,                 loss: 0.2300
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7932s / 360.7858 s
agent0:                 episode reward: -0.6006,                 loss: nan
agent1:                 episode reward: 0.6006,                 loss: 0.2300
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7962s / 361.5820 s
agent0:                 episode reward: 1.3751,                 loss: nan
agent1:                 episode reward: -1.3751,                 loss: 0.2670
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7787s / 362.3607 s
agent0:                 episode reward: 0.0092,                 loss: nan
agent1:                 episode reward: -0.0092,                 loss: 0.2735
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8229s / 363.1836 s
agent0:                 episode reward: -0.3906,                 loss: nan
agent1:                 episode reward: 0.3906,                 loss: 0.2722
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7959s / 363.9795 s
agent0:                 episode reward: 0.1016,                 loss: nan
agent1:                 episode reward: -0.1016,                 loss: 0.2740
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7869s / 364.7664 s
agent0:                 episode reward: 0.1208,                 loss: nan
agent1:                 episode reward: -0.1208,                 loss: 0.2712
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7853s / 365.5517 s
agent0:                 episode reward: -0.7203,                 loss: nan
agent1:                 episode reward: 0.7203,                 loss: 0.2724
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7888s / 366.3406 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.2689
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7931s / 367.1337 s
agent0:                 episode reward: 0.0929,                 loss: nan
agent1:                 episode reward: -0.0929,                 loss: 0.2722
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8106s / 367.9443 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.2721
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7973s / 368.7415 s
agent0:                 episode reward: 0.0927,                 loss: nan
agent1:                 episode reward: -0.0927,                 loss: 0.2712
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7827s / 369.5243 s
agent0:                 episode reward: 0.0773,                 loss: nan
agent1:                 episode reward: -0.0773,                 loss: 0.2838
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8366s / 370.3609 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.2688
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7853s / 371.1462 s
agent0:                 episode reward: 0.6263,                 loss: nan
agent1:                 episode reward: -0.6263,                 loss: 0.2715
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8174s / 371.9636 s
agent0:                 episode reward: 0.9062,                 loss: nan
agent1:                 episode reward: -0.9062,                 loss: 0.2699
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7923s / 372.7559 s
agent0:                 episode reward: -0.0586,                 loss: nan
agent1:                 episode reward: 0.0586,                 loss: 0.2697
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8023s / 373.5582 s
agent0:                 episode reward: -0.0526,                 loss: nan
agent1:                 episode reward: 0.0526,                 loss: 0.2699
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8358s / 374.3940 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.2686
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7903s / 375.1844 s
agent0:                 episode reward: -0.8509,                 loss: nan
agent1:                 episode reward: 0.8509,                 loss: 0.2704
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8261s / 376.0105 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.2693
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7913s / 376.8018 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.2687
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 377.5868 s
agent0:                 episode reward: -0.1461,                 loss: nan
agent1:                 episode reward: 0.1461,                 loss: 0.2805
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7987s / 378.3855 s
agent0:                 episode reward: -0.7337,                 loss: nan
agent1:                 episode reward: 0.7337,                 loss: 0.2699
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7880s / 379.1735 s
agent0:                 episode reward: -0.0883,                 loss: nan
agent1:                 episode reward: 0.0883,                 loss: 0.2714
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7860s / 379.9595 s
agent0:                 episode reward: 0.0116,                 loss: nan
agent1:                 episode reward: -0.0116,                 loss: 0.2691
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8584s / 380.8180 s
agent0:                 episode reward: 0.0553,                 loss: nan
agent1:                 episode reward: -0.0553,                 loss: 0.2674
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8060s / 381.6239 s
agent0:                 episode reward: 0.1137,                 loss: nan
agent1:                 episode reward: -0.1137,                 loss: 0.2683
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8044s / 382.4283 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.2677
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8066s / 383.2349 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: 0.2663
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8050s / 384.0399 s
agent0:                 episode reward: -0.0571,                 loss: nan
agent1:                 episode reward: 0.0571,                 loss: 0.2663
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8199s / 384.8598 s
agent0:                 episode reward: 0.1493,                 loss: nan
agent1:                 episode reward: -0.1493,                 loss: 0.2670
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8044s / 385.6642 s
agent0:                 episode reward: -0.4420,                 loss: nan
agent1:                 episode reward: 0.4420,                 loss: 0.2918
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8001s / 386.4643 s
agent0:                 episode reward: 0.0282,                 loss: nan
agent1:                 episode reward: -0.0282,                 loss: 0.2932
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8102s / 387.2745 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.2895
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7985s / 388.0730 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: 0.2916
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7990s / 388.8720 s
agent0:                 episode reward: 0.1915,                 loss: nan
agent1:                 episode reward: -0.1915,                 loss: 0.2899
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 389.6722 s
agent0:                 episode reward: -0.7700,                 loss: nan
agent1:                 episode reward: 0.7700,                 loss: 0.2899
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8108s / 390.4831 s
agent0:                 episode reward: -0.9024,                 loss: nan
agent1:                 episode reward: 0.9024,                 loss: 0.2904
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 391.3489 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.2890
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8025s / 392.1514 s
agent0:                 episode reward: -0.0204,                 loss: nan
agent1:                 episode reward: 0.0204,                 loss: 0.2878
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8238s / 392.9752 s
agent0:                 episode reward: -0.3702,                 loss: nan
agent1:                 episode reward: 0.3702,                 loss: 0.2878
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8118s / 393.7871 s
agent0:                 episode reward: 0.5097,                 loss: nan
agent1:                 episode reward: -0.5097,                 loss: 0.3138
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8051s / 394.5922 s
agent0:                 episode reward: -0.0021,                 loss: nan
agent1:                 episode reward: 0.0021,                 loss: 0.3044
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8021s / 395.3942 s
agent0:                 episode reward: -0.9163,                 loss: nan
agent1:                 episode reward: 0.9163,                 loss: 0.3019
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8068s / 396.2011 s
agent0:                 episode reward: 1.0911,                 loss: nan
agent1:                 episode reward: -1.0911,                 loss: 0.3008
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7942s / 396.9953 s
agent0:                 episode reward: -0.8922,                 loss: nan
agent1:                 episode reward: 0.8922,                 loss: 0.2968
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8086s / 397.8038 s
agent0:                 episode reward: -0.8921,                 loss: nan
agent1:                 episode reward: 0.8921,                 loss: 0.3004
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8079s / 398.6117 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.2982
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8261s / 399.4378 s
agent0:                 episode reward: -0.6274,                 loss: nan
agent1:                 episode reward: 0.6274,                 loss: 0.2996
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8057s / 400.2434 s
agent0:                 episode reward: 0.3787,                 loss: nan
agent1:                 episode reward: -0.3787,                 loss: 0.2973
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8537s / 401.0971 s
agent0:                 episode reward: -0.0165,                 loss: nan
agent1:                 episode reward: 0.0165,                 loss: 0.2949
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8096s / 401.9067 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.2597
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8196s / 402.7263 s
agent0:                 episode reward: 0.1747,                 loss: nan
agent1:                 episode reward: -0.1747,                 loss: 0.2188
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8626s / 403.5889 s
agent0:                 episode reward: -0.3594,                 loss: nan
agent1:                 episode reward: 0.3594,                 loss: 0.2155
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8098s / 404.3987 s
agent0:                 episode reward: -0.5457,                 loss: nan
agent1:                 episode reward: 0.5457,                 loss: 0.2139
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8102s / 405.2089 s
agent0:                 episode reward: -1.0470,                 loss: nan
agent1:                 episode reward: 1.0470,                 loss: 0.2144
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8146s / 406.0235 s
agent0:                 episode reward: -0.3873,                 loss: nan
agent1:                 episode reward: 0.3873,                 loss: 0.2116
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8120s / 406.8355 s
agent0:                 episode reward: 0.1006,                 loss: nan
agent1:                 episode reward: -0.1006,                 loss: 0.2103
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8054s / 407.6409 s
agent0:                 episode reward: -0.3946,                 loss: nan
agent1:                 episode reward: 0.3946,                 loss: 0.2117
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8233s / 408.4641 s
agent0:                 episode reward: 0.0904,                 loss: nan
agent1:                 episode reward: -0.0904,                 loss: 0.2114
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8290s / 409.2931 s
agent0:                 episode reward: -0.1629,                 loss: nan
agent1:                 episode reward: 0.1629,                 loss: 0.2117
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8652s / 410.1583 s
agent0:                 episode reward: -0.6482,                 loss: nan
agent1:                 episode reward: 0.6482,                 loss: 0.1842
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8230s / 410.9813 s
agent0:                 episode reward: -1.1855,                 loss: nan
agent1:                 episode reward: 1.1855,                 loss: 0.1600
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8544s / 411.8357 s
agent0:                 episode reward: 0.3179,                 loss: nan
agent1:                 episode reward: -0.3179,                 loss: 0.1577
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8090s / 412.6447 s
agent0:                 episode reward: -1.0769,                 loss: nan
agent1:                 episode reward: 1.0769,                 loss: 0.1581
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8331s / 413.4777 s
agent0:                 episode reward: 0.2459,                 loss: nan
agent1:                 episode reward: -0.2459,                 loss: 0.1571
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8452s / 414.3230 s
agent0:                 episode reward: -0.9098,                 loss: nan
agent1:                 episode reward: 0.9098,                 loss: 0.1560
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8234s / 415.1464 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1539
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8120s / 415.9584 s
agent0:                 episode reward: 0.1807,                 loss: nan
agent1:                 episode reward: -0.1807,                 loss: 0.1545
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8236s / 416.7820 s
agent0:                 episode reward: -0.2048,                 loss: nan
agent1:                 episode reward: 0.2048,                 loss: 0.1540
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8381s / 417.6201 s
agent0:                 episode reward: 0.0344,                 loss: nan
agent1:                 episode reward: -0.0344,                 loss: 0.1538
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8226s / 418.4427 s
agent0:                 episode reward: -0.7629,                 loss: nan
agent1:                 episode reward: 0.7629,                 loss: 0.1750
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8222s / 419.2648 s
agent0:                 episode reward: -0.4527,                 loss: nan
agent1:                 episode reward: 0.4527,                 loss: 0.1732
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8480s / 420.1128 s
agent0:                 episode reward: 0.1078,                 loss: nan
agent1:                 episode reward: -0.1078,                 loss: 0.1724
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8248s / 420.9376 s
agent0:                 episode reward: -0.1518,                 loss: nan
agent1:                 episode reward: 0.1518,                 loss: 0.1719
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8664s / 421.8040 s
agent0:                 episode reward: 0.3637,                 loss: nan
agent1:                 episode reward: -0.3637,                 loss: 0.1690
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8235s / 422.6275 s
agent0:                 episode reward: 0.4891,                 loss: nan
agent1:                 episode reward: -0.4891,                 loss: 0.1697
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8374s / 423.4649 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.1692
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8373s / 424.3022 s
agent0:                 episode reward: -0.1517,                 loss: nan
agent1:                 episode reward: 0.1517,                 loss: 0.1688
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8355s / 425.1377 s
agent0:                 episode reward: -0.7339,                 loss: nan
agent1:                 episode reward: 0.7339,                 loss: 0.1695
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8746s / 426.0122 s
agent0:                 episode reward: -0.9617,                 loss: nan
agent1:                 episode reward: 0.9617,                 loss: 0.1702
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8246s / 426.8368 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.2107
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8372s / 427.6740 s
agent0:                 episode reward: 0.3029,                 loss: nan
agent1:                 episode reward: -0.3029,                 loss: 0.2225
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8551s / 428.5291 s
agent0:                 episode reward: -0.6220,                 loss: nan
agent1:                 episode reward: 0.6220,                 loss: 0.2243
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8465s / 429.3756 s
agent0:                 episode reward: -0.3401,                 loss: nan
agent1:                 episode reward: 0.3401,                 loss: 0.2209
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8294s / 430.2050 s
agent0:                 episode reward: -0.1170,                 loss: nan
agent1:                 episode reward: 0.1170,                 loss: 0.2200
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8266s / 431.0316 s
agent0:                 episode reward: -0.1950,                 loss: nan
agent1:                 episode reward: 0.1950,                 loss: 0.2206
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8789s / 431.9105 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.2222
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8375s / 432.7480 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.2211
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8344s / 433.5824 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.2208
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8585s / 434.4409 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.2207
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8543s / 435.2953 s
agent0:                 episode reward: 0.6305,                 loss: nan
agent1:                 episode reward: -0.6305,                 loss: 0.2557
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8415s / 436.1367 s
agent0:                 episode reward: -1.0598,                 loss: nan
agent1:                 episode reward: 1.0598,                 loss: 0.2628
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8357s / 436.9724 s
agent0:                 episode reward: 0.6971,                 loss: nan
agent1:                 episode reward: -0.6971,                 loss: 0.2598
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8299s / 437.8023 s
agent0:                 episode reward: -0.6631,                 loss: nan
agent1:                 episode reward: 0.6631,                 loss: 0.2597
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8617s / 438.6640 s
agent0:                 episode reward: 0.8237,                 loss: nan
agent1:                 episode reward: -0.8237,                 loss: 0.2591
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8356s / 439.4997 s
agent0:                 episode reward: 0.2999,                 loss: nan
agent1:                 episode reward: -0.2999,                 loss: 0.2613
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8861s / 440.3858 s
agent0:                 episode reward: 0.6961,                 loss: nan
agent1:                 episode reward: -0.6961,                 loss: 0.2599
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8426s / 441.2284 s
agent0:                 episode reward: -0.5514,                 loss: nan
agent1:                 episode reward: 0.5514,                 loss: 0.2610
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8744s / 442.1028 s
agent0:                 episode reward: 0.3738,                 loss: nan
agent1:                 episode reward: -0.3738,                 loss: 0.2607
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8571s / 442.9599 s
agent0:                 episode reward: -1.4354,                 loss: nan
agent1:                 episode reward: 1.4354,                 loss: 0.2613
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8979s / 443.8578 s
agent0:                 episode reward: 0.4384,                 loss: nan
agent1:                 episode reward: -0.4384,                 loss: 0.2826
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8566s / 444.7144 s
agent0:                 episode reward: -1.4179,                 loss: nan
agent1:                 episode reward: 1.4179,                 loss: 0.2825
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8419s / 445.5563 s
agent0:                 episode reward: 0.0425,                 loss: nan
agent1:                 episode reward: -0.0425,                 loss: 0.2820
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8359s / 446.3922 s
agent0:                 episode reward: -0.0518,                 loss: nan
agent1:                 episode reward: 0.0518,                 loss: 0.2809
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8456s / 447.2378 s
agent0:                 episode reward: 0.6711,                 loss: nan
agent1:                 episode reward: -0.6711,                 loss: 0.2824
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8461s / 448.0839 s
agent0:                 episode reward: -0.6240,                 loss: nan
agent1:                 episode reward: 0.6240,                 loss: 0.2817
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8877s / 448.9716 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.2816
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8414s / 449.8130 s
agent0:                 episode reward: 0.0023,                 loss: nan
agent1:                 episode reward: -0.0023,                 loss: 0.2824
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8607s / 450.6737 s
agent0:                 episode reward: 0.5081,                 loss: nan
agent1:                 episode reward: -0.5081,                 loss: 0.2821
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8505s / 451.5242 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.2818
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8869s / 452.4111 s
agent0:                 episode reward: 0.7124,                 loss: nan
agent1:                 episode reward: -0.7124,                 loss: 0.2757
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8680s / 453.2791 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.2651
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8593s / 454.1384 s
agent0:                 episode reward: -0.0265,                 loss: nan
agent1:                 episode reward: 0.0265,                 loss: 0.2641
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8630s / 455.0015 s
agent0:                 episode reward: 0.5307,                 loss: nan
agent1:                 episode reward: -0.5307,                 loss: 0.2635
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8583s / 455.8597 s
agent0:                 episode reward: -0.7009,                 loss: nan
agent1:                 episode reward: 0.7009,                 loss: 0.2652
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8580s / 456.7177 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: 0.2672
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8415s / 457.5592 s
agent0:                 episode reward: -0.0013,                 loss: nan
agent1:                 episode reward: 0.0013,                 loss: 0.2644
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8502s / 458.4094 s
agent0:                 episode reward: 0.7892,                 loss: nan
agent1:                 episode reward: -0.7892,                 loss: 0.2639
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8820s / 459.2914 s
agent0:                 episode reward: 0.5763,                 loss: nan
agent1:                 episode reward: -0.5763,                 loss: 0.2652
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8614s / 460.1528 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.2642
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8518s / 461.0045 s
agent0:                 episode reward: 0.7129,                 loss: nan
agent1:                 episode reward: -0.7129,                 loss: 0.2776
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8551s / 461.8597 s
agent0:                 episode reward: 0.4436,                 loss: nan
agent1:                 episode reward: -0.4436,                 loss: 0.2766
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9122s / 462.7718 s
agent0:                 episode reward: -0.8017,                 loss: nan
agent1:                 episode reward: 0.8017,                 loss: 0.2748
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8472s / 463.6190 s
agent0:                 episode reward: -0.0835,                 loss: nan
agent1:                 episode reward: 0.0835,                 loss: 0.2730
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 464.4838 s
agent0:                 episode reward: 0.4755,                 loss: nan
agent1:                 episode reward: -0.4755,                 loss: 0.2739
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8672s / 465.3510 s
agent0:                 episode reward: -0.1038,                 loss: nan
agent1:                 episode reward: 0.1038,                 loss: 0.2719
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8632s / 466.2142 s
agent0:                 episode reward: -0.3121,                 loss: nan
agent1:                 episode reward: 0.3121,                 loss: 0.2742
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8558s / 467.0700 s
agent0:                 episode reward: 0.2413,                 loss: nan
agent1:                 episode reward: -0.2413,                 loss: 0.2715
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8676s / 467.9376 s
agent0:                 episode reward: 0.7073,                 loss: nan
agent1:                 episode reward: -0.7073,                 loss: 0.2738
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9143s / 468.8519 s
agent0:                 episode reward: -0.1301,                 loss: nan
agent1:                 episode reward: 0.1301,                 loss: 0.2735
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8535s / 469.7055 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3056
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8636s / 470.5691 s
agent0:                 episode reward: -0.2185,                 loss: nan
agent1:                 episode reward: 0.2185,                 loss: 0.3043
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8740s / 471.4431 s
agent0:                 episode reward: -0.6134,                 loss: nan
agent1:                 episode reward: 0.6134,                 loss: 0.3029
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8736s / 472.3167 s
agent0:                 episode reward: 0.5878,                 loss: nan
agent1:                 episode reward: -0.5878,                 loss: 0.3009
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9202s / 473.2369 s
agent0:                 episode reward: -0.8914,                 loss: nan
agent1:                 episode reward: 0.8914,                 loss: 0.3008
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8656s / 474.1025 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.2984
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8891s / 474.9917 s
agent0:                 episode reward: 0.3887,                 loss: nan
agent1:                 episode reward: -0.3887,                 loss: 0.2992
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8916s / 475.8832 s
agent0:                 episode reward: -0.1238,                 loss: nan
agent1:                 episode reward: 0.1238,                 loss: 0.3017
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8839s / 476.7671 s
agent0:                 episode reward: -0.0091,                 loss: nan
agent1:                 episode reward: 0.0091,                 loss: 0.2996
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8906s / 477.6577 s
agent0:                 episode reward: -0.6948,                 loss: nan
agent1:                 episode reward: 0.6948,                 loss: 0.2996
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8690s / 478.5266 s
agent0:                 episode reward: -0.5905,                 loss: nan
agent1:                 episode reward: 0.5905,                 loss: 0.2936
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8717s / 479.3983 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: 0.2684
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9019s / 480.3002 s
agent0:                 episode reward: -0.1768,                 loss: nan
agent1:                 episode reward: 0.1768,                 loss: 0.2632
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8800s / 481.1802 s
agent0:                 episode reward: -0.4176,                 loss: nan
agent1:                 episode reward: 0.4176,                 loss: 0.2652
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8719s / 482.0521 s
agent0:                 episode reward: -0.9086,                 loss: nan
agent1:                 episode reward: 0.9086,                 loss: 0.2611
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9135s / 482.9656 s
agent0:                 episode reward: -1.3541,                 loss: nan
agent1:                 episode reward: 1.3541,                 loss: 0.2617
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9015s / 483.8671 s
agent0:                 episode reward: -0.0693,                 loss: nan
agent1:                 episode reward: 0.0693,                 loss: 0.2587
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8816s / 484.7487 s
agent0:                 episode reward: -0.7098,                 loss: nan
agent1:                 episode reward: 0.7098,                 loss: 0.2572
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8761s / 485.6248 s
agent0:                 episode reward: -0.9405,                 loss: nan
agent1:                 episode reward: 0.9405,                 loss: 0.2561
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8824s / 486.5071 s
agent0:                 episode reward: -0.1517,                 loss: nan
agent1:                 episode reward: 0.1517,                 loss: 0.2589
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8679s / 487.3751 s
agent0:                 episode reward: -0.7535,                 loss: nan
agent1:                 episode reward: 0.7535,                 loss: 0.2191
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8735s / 488.2486 s
agent0:                 episode reward: -0.5076,                 loss: nan
agent1:                 episode reward: 0.5076,                 loss: 0.1803
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8796s / 489.1282 s
agent0:                 episode reward: -0.2826,                 loss: nan
agent1:                 episode reward: 0.2826,                 loss: 0.1768
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8941s / 490.0223 s
agent0:                 episode reward: -1.0121,                 loss: nan
agent1:                 episode reward: 1.0121,                 loss: 0.1771
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8832s / 490.9055 s
agent0:                 episode reward: -1.0299,                 loss: nan
agent1:                 episode reward: 1.0299,                 loss: 0.1744
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8808s / 491.7863 s
agent0:                 episode reward: 0.3850,                 loss: nan
agent1:                 episode reward: -0.3850,                 loss: 0.1726
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9280s / 492.7143 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.1744
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9366s / 493.6509 s
agent0:                 episode reward: -0.0489,                 loss: nan
agent1:                 episode reward: 0.0489,                 loss: 0.1748
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8887s / 494.5396 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.1740
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8935s / 495.4332 s
agent0:                 episode reward: -0.4563,                 loss: nan
agent1:                 episode reward: 0.4563,                 loss: 0.1744
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8873s / 496.3205 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.1738
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8928s / 497.2133 s
agent0:                 episode reward: -0.8941,                 loss: nan
agent1:                 episode reward: 0.8941,                 loss: 0.1593
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8908s / 498.1040 s
agent0:                 episode reward: -0.9549,                 loss: nan
agent1:                 episode reward: 0.9549,                 loss: 0.1546
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9142s / 499.0183 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.1547
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8908s / 499.9091 s
agent0:                 episode reward: -0.0000,                 loss: nan
agent1:                 episode reward: 0.0000,                 loss: 0.1566
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9052s / 500.8142 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: 0.1562
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8988s / 501.7130 s
agent0:                 episode reward: 0.1982,                 loss: nan
agent1:                 episode reward: -0.1982,                 loss: 0.1547
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9035s / 502.6165 s
agent0:                 episode reward: 0.8214,                 loss: nan
agent1:                 episode reward: -0.8214,                 loss: 0.1549
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9681s / 503.5846 s
agent0:                 episode reward: 0.0077,                 loss: nan
agent1:                 episode reward: -0.0077,                 loss: 0.1559
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9304s / 504.5150 s
agent0:                 episode reward: 0.6684,                 loss: nan
agent1:                 episode reward: -0.6684,                 loss: 0.1532
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9051s / 505.4201 s
agent0:                 episode reward: -0.4485,                 loss: nan
agent1:                 episode reward: 0.4485,                 loss: 0.1828
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9027s / 506.3228 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.1867
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8895s / 507.2123 s
agent0:                 episode reward: -0.2714,                 loss: nan
agent1:                 episode reward: 0.2714,                 loss: 0.1904
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8989s / 508.1112 s
agent0:                 episode reward: -0.1981,                 loss: nan
agent1:                 episode reward: 0.1981,                 loss: 0.1865
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9157s / 509.0269 s
agent0:                 episode reward: -0.2556,                 loss: nan
agent1:                 episode reward: 0.2556,                 loss: 0.1860
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8927s / 509.9196 s
agent0:                 episode reward: 0.3679,                 loss: nan
agent1:                 episode reward: -0.3679,                 loss: 0.1871
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8927s / 510.8123 s
agent0:                 episode reward: -1.4018,                 loss: nan
agent1:                 episode reward: 1.4018,                 loss: 0.1857
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9036s / 511.7159 s
agent0:                 episode reward: -0.8714,                 loss: nan
agent1:                 episode reward: 0.8714,                 loss: 0.1880
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8869s / 512.6028 s
agent0:                 episode reward: 0.3611,                 loss: nan
agent1:                 episode reward: -0.3611,                 loss: 0.1882
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9155s / 513.5183 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: 0.1855
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9475s / 514.4658 s
agent0:                 episode reward: 0.0432,                 loss: nan
agent1:                 episode reward: -0.0432,                 loss: 0.2253
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9051s / 515.3709 s
agent0:                 episode reward: -0.9440,                 loss: nan
agent1:                 episode reward: 0.9440,                 loss: 0.2324
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9041s / 516.2750 s
agent0:                 episode reward: -0.9968,                 loss: nan
agent1:                 episode reward: 0.9968,                 loss: 0.2355
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9468s / 517.2219 s
agent0:                 episode reward: 0.6191,                 loss: nan
agent1:                 episode reward: -0.6191,                 loss: 0.2342
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9065s / 518.1284 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.2345
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9049s / 519.0332 s
agent0:                 episode reward: -0.5274,                 loss: nan
agent1:                 episode reward: 0.5274,                 loss: 0.2338
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9074s / 519.9406 s
agent0:                 episode reward: -0.5302,                 loss: nan
agent1:                 episode reward: 0.5302,                 loss: 0.2328
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9066s / 520.8472 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.2332
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8954s / 521.7427 s
agent0:                 episode reward: -0.8470,                 loss: nan
agent1:                 episode reward: 0.8470,                 loss: 0.2338
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9521s / 522.6948 s
agent0:                 episode reward: -0.7845,                 loss: nan
agent1:                 episode reward: 0.7845,                 loss: 0.2315
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9173s / 523.6121 s
agent0:                 episode reward: 0.0625,                 loss: nan
agent1:                 episode reward: -0.0625,                 loss: 0.2738
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9439s / 524.5560 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.2755
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9383s / 525.4942 s
agent0:                 episode reward: 0.6068,                 loss: nan
agent1:                 episode reward: -0.6068,                 loss: 0.2737
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9394s / 526.4337 s
agent0:                 episode reward: 0.5302,                 loss: nan
agent1:                 episode reward: -0.5302,                 loss: 0.2772
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9254s / 527.3591 s
agent0:                 episode reward: 0.9491,                 loss: nan
agent1:                 episode reward: -0.9491,                 loss: 0.2764
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9015s / 528.2606 s
agent0:                 episode reward: 0.1738,                 loss: nan
agent1:                 episode reward: -0.1738,                 loss: 0.2749
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9175s / 529.1781 s
agent0:                 episode reward: 0.4619,                 loss: nan
agent1:                 episode reward: -0.4619,                 loss: 0.2751
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9134s / 530.0915 s
agent0:                 episode reward: -0.1222,                 loss: nan
agent1:                 episode reward: 0.1222,                 loss: 0.2758
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9204s / 531.0120 s
agent0:                 episode reward: -1.2770,                 loss: nan
agent1:                 episode reward: 1.2770,                 loss: 0.2732
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9146s / 531.9266 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.2762
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9139s / 532.8405 s
agent0:                 episode reward: 0.2156,                 loss: nan
agent1:                 episode reward: -0.2156,                 loss: 0.2910
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9286s / 533.7691 s
agent0:                 episode reward: 0.3513,                 loss: nan
agent1:                 episode reward: -0.3513,                 loss: 0.2820
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9809s / 534.7500 s
agent0:                 episode reward: -0.0553,                 loss: nan
agent1:                 episode reward: 0.0553,                 loss: 0.2841
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9374s / 535.6874 s
agent0:                 episode reward: -0.4327,                 loss: nan
agent1:                 episode reward: 0.4327,                 loss: 0.2834
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9141s / 536.6015 s
agent0:                 episode reward: -0.1185,                 loss: nan
agent1:                 episode reward: 0.1185,                 loss: 0.2826
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9263s / 537.5278 s
agent0:                 episode reward: 0.3165,                 loss: nan
agent1:                 episode reward: -0.3165,                 loss: 0.2833
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9482s / 538.4760 s
agent0:                 episode reward: 0.3634,                 loss: nan
agent1:                 episode reward: -0.3634,                 loss: 0.2849
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9469s / 539.4229 s
agent0:                 episode reward: -0.0781,                 loss: nan
agent1:                 episode reward: 0.0781,                 loss: 0.2827
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9748s / 540.3977 s
agent0:                 episode reward: 0.8051,                 loss: nan
agent1:                 episode reward: -0.8051,                 loss: 0.2828
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0189s / 541.4166 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.2811
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9567s / 542.3733 s
agent0:                 episode reward: 0.3517,                 loss: nan
agent1:                 episode reward: -0.3517,                 loss: 0.2890
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9883s / 543.3616 s
agent0:                 episode reward: 0.0674,                 loss: nan
agent1:                 episode reward: -0.0674,                 loss: 0.2835
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0188s / 544.3804 s
agent0:                 episode reward: 0.6201,                 loss: nan
agent1:                 episode reward: -0.6201,                 loss: 0.2811
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0106s / 545.3911 s
agent0:                 episode reward: 0.5465,                 loss: nan
agent1:                 episode reward: -0.5465,                 loss: 0.2829
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9996s / 546.3907 s
agent0:                 episode reward: -0.0720,                 loss: nan
agent1:                 episode reward: 0.0720,                 loss: 0.2821
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9933s / 547.3840 s
agent0:                 episode reward: -0.3542,                 loss: nan
agent1:                 episode reward: 0.3542,                 loss: 0.2832
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0096s / 548.3936 s
agent0:                 episode reward: -0.1172,                 loss: nan
agent1:                 episode reward: 0.1172,                 loss: 0.2823
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9879s / 549.3814 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.2798
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0133s / 550.3948 s
agent0:                 episode reward: 0.1120,                 loss: nan
agent1:                 episode reward: -0.1120,                 loss: 0.2805
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9966s / 551.3914 s
agent0:                 episode reward: 0.7997,                 loss: nan
agent1:                 episode reward: -0.7997,                 loss: 0.2826
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9893s / 552.3807 s
agent0:                 episode reward: 1.1010,                 loss: nan
agent1:                 episode reward: -1.1010,                 loss: 0.2998
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0386s / 553.4193 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.2913
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9906s / 554.4099 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.2910
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0554s / 555.4652 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.2878
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0164s / 556.4817 s
agent0:                 episode reward: 0.8721,                 loss: nan
agent1:                 episode reward: -0.8721,                 loss: 0.2855
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9909s / 557.4726 s
agent0:                 episode reward: 0.8171,                 loss: nan
agent1:                 episode reward: -0.8171,                 loss: 0.2867
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0224s / 558.4950 s
agent0:                 episode reward: 0.6759,                 loss: nan
agent1:                 episode reward: -0.6759,                 loss: 0.2858
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0213s / 559.5163 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.2870
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0015s / 560.5178 s
agent0:                 episode reward: -0.2200,                 loss: nan
agent1:                 episode reward: 0.2200,                 loss: 0.2843
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9985s / 561.5163 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: 0.2836
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0058s / 562.5220 s
agent0:                 episode reward: 0.7687,                 loss: nan
agent1:                 episode reward: -0.7687,                 loss: 0.2964
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0034s / 563.5254 s
agent0:                 episode reward: 0.2362,                 loss: nan
agent1:                 episode reward: -0.2362,                 loss: 0.2797
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9892s / 564.5147 s
agent0:                 episode reward: 0.1552,                 loss: nan
agent1:                 episode reward: -0.1552,                 loss: 0.2801
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0464s / 565.5610 s
agent0:                 episode reward: -0.1246,                 loss: nan
agent1:                 episode reward: 0.1246,                 loss: 0.2796
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0052s / 566.5663 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.2768
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0284s / 567.5946 s
agent0:                 episode reward: 0.4462,                 loss: nan
agent1:                 episode reward: -0.4462,                 loss: 0.2764
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0117s / 568.6064 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: 0.2758
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9984s / 569.6047 s
agent0:                 episode reward: -0.0675,                 loss: nan
agent1:                 episode reward: 0.0675,                 loss: 0.2739
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9963s / 570.6011 s
agent0:                 episode reward: 0.3744,                 loss: nan
agent1:                 episode reward: -0.3744,                 loss: 0.2742
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0062s / 571.6073 s
agent0:                 episode reward: 0.0148,                 loss: nan
agent1:                 episode reward: -0.0148,                 loss: 0.2748
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0065s / 572.6138 s
agent0:                 episode reward: 0.0503,                 loss: nan
agent1:                 episode reward: -0.0503,                 loss: 0.2481
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0162s / 573.6299 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.2123
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0174s / 574.6473 s
agent0:                 episode reward: 0.4998,                 loss: nan
agent1:                 episode reward: -0.4998,                 loss: 0.2139
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0736s / 575.7209 s
agent0:                 episode reward: 0.0625,                 loss: nan
agent1:                 episode reward: -0.0625,                 loss: 0.2149
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0065s / 576.7274 s
agent0:                 episode reward: -0.8650,                 loss: nan
agent1:                 episode reward: 0.8650,                 loss: 0.2115
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0208s / 577.7482 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: 0.2119
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9952s / 578.7434 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.2116
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0256s / 579.7690 s
agent0:                 episode reward: 0.6356,                 loss: nan
agent1:                 episode reward: -0.6356,                 loss: 0.2109
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0286s / 580.7977 s
agent0:                 episode reward: 0.5597,                 loss: nan
agent1:                 episode reward: -0.5597,                 loss: 0.2105
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9986s / 581.7962 s
agent0:                 episode reward: 0.8768,                 loss: nan
agent1:                 episode reward: -0.8768,                 loss: 0.2101
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9997s / 582.7959 s
agent0:                 episode reward: 0.5430,                 loss: nan
agent1:                 episode reward: -0.5430,                 loss: 0.1888
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0291s / 583.8251 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.1628
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0068s / 584.8319 s
agent0:                 episode reward: 0.6485,                 loss: nan
agent1:                 episode reward: -0.6485,                 loss: 0.1637
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0752s / 585.9071 s
agent0:                 episode reward: -0.7107,                 loss: nan
agent1:                 episode reward: 0.7107,                 loss: 0.1623
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0234s / 586.9305 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: 0.1599
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9996s / 587.9301 s
agent0:                 episode reward: 1.5446,                 loss: nan
agent1:                 episode reward: -1.5446,                 loss: 0.1609
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0010s / 588.9311 s
agent0:                 episode reward: -0.4219,                 loss: nan
agent1:                 episode reward: 0.4219,                 loss: 0.1617
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0130s / 589.9441 s
agent0:                 episode reward: 0.6779,                 loss: nan
agent1:                 episode reward: -0.6779,                 loss: 0.1620
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0091s / 590.9531 s
agent0:                 episode reward: 0.3659,                 loss: nan
agent1:                 episode reward: -0.3659,                 loss: 0.1592
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0546s / 592.0077 s
agent0:                 episode reward: 0.5582,                 loss: nan
agent1:                 episode reward: -0.5582,                 loss: 0.1607
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0025s / 593.0102 s
agent0:                 episode reward: -0.6034,                 loss: nan
agent1:                 episode reward: 0.6034,                 loss: 0.1731
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0043s / 594.0145 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: 0.1709
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0013s / 595.0158 s
agent0:                 episode reward: -0.8286,                 loss: nan
agent1:                 episode reward: 0.8286,                 loss: 0.1698
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0874s / 596.1032 s
agent0:                 episode reward: 0.4783,                 loss: nan
agent1:                 episode reward: -0.4783,                 loss: 0.1702
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 597.1242 s
agent0:                 episode reward: 0.1829,                 loss: nan
agent1:                 episode reward: -0.1829,                 loss: 0.1702
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0084s / 598.1326 s
agent0:                 episode reward: 0.7174,                 loss: nan
agent1:                 episode reward: -0.7174,                 loss: 0.1699
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0323s / 599.1650 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.1704
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0585s / 600.2235 s
agent0:                 episode reward: 0.4103,                 loss: nan
agent1:                 episode reward: -0.4103,                 loss: 0.1698
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0111s / 601.2346 s
agent0:                 episode reward: 0.7184,                 loss: nan
agent1:                 episode reward: -0.7184,                 loss: 0.1706
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0119s / 602.2466 s
agent0:                 episode reward: 0.6317,                 loss: nan
agent1:                 episode reward: -0.6317,                 loss: 0.1714
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0181s / 603.2647 s
agent0:                 episode reward: 0.0696,                 loss: nan
agent1:                 episode reward: -0.0696,                 loss: 0.2102
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0385s / 604.3032 s
agent0:                 episode reward: 0.3574,                 loss: nan
agent1:                 episode reward: -0.3574,                 loss: 0.2204
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0062s / 605.3095 s
agent0:                 episode reward: 0.2342,                 loss: nan
agent1:                 episode reward: -0.2342,                 loss: 0.2218
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0523s / 606.3617 s
agent0:                 episode reward: 0.4751,                 loss: nan
agent1:                 episode reward: -0.4751,                 loss: 0.2225
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0084s / 607.3701 s
agent0:                 episode reward: 0.0378,                 loss: nan
agent1:                 episode reward: -0.0378,                 loss: 0.2216
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0257s / 608.3958 s
agent0:                 episode reward: 0.4282,                 loss: nan
agent1:                 episode reward: -0.4282,                 loss: 0.2232
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0068s / 609.4026 s
agent0:                 episode reward: -0.0926,                 loss: nan
agent1:                 episode reward: 0.0926,                 loss: 0.2199
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0207s / 610.4233 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.2192
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0069s / 611.4302 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: 0.2233
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0092s / 612.4394 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.2198
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0177s / 613.4572 s
agent0:                 episode reward: 0.0508,                 loss: nan
agent1:                 episode reward: -0.0508,                 loss: 0.2614
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0090s / 614.4662 s
agent0:                 episode reward: -0.0905,                 loss: nan
agent1:                 episode reward: 0.0905,                 loss: 0.2736
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0427s / 615.5088 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.2724
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1507s / 616.6595 s
agent0:                 episode reward: 0.1144,                 loss: nan
agent1:                 episode reward: -0.1144,                 loss: 0.2697
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0294s / 617.6889 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.2732
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0163s / 618.7052 s
agent0:                 episode reward: 0.4817,                 loss: nan
agent1:                 episode reward: -0.4817,                 loss: 0.2739
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9998s / 619.7050 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.2705
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0064s / 620.7114 s
agent0:                 episode reward: 0.3412,                 loss: nan
agent1:                 episode reward: -0.3412,                 loss: 0.2709
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0240s / 621.7354 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.2700
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9987s / 622.7341 s
agent0:                 episode reward: -0.2891,                 loss: nan
agent1:                 episode reward: 0.2891,                 loss: 0.2719
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0338s / 623.7679 s
agent0:                 episode reward: 0.3521,                 loss: nan
agent1:                 episode reward: -0.3521,                 loss: 0.2893
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0111s / 624.7790 s
agent0:                 episode reward: -0.0649,                 loss: nan
agent1:                 episode reward: 0.0649,                 loss: 0.2852
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0200s / 625.7990 s
agent0:                 episode reward: 0.2548,                 loss: nan
agent1:                 episode reward: -0.2548,                 loss: 0.2836
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0703s / 626.8694 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.2829
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0219s / 627.8913 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.2826
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0259s / 628.9172 s
agent0:                 episode reward: 0.6670,                 loss: nan
agent1:                 episode reward: -0.6670,                 loss: 0.2843
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0169s / 629.9342 s
agent0:                 episode reward: -0.7400,                 loss: nan
agent1:                 episode reward: 0.7400,                 loss: 0.2812
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0152s / 630.9493 s
agent0:                 episode reward: 0.5417,                 loss: nan
agent1:                 episode reward: -0.5417,                 loss: 0.2827
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0179s / 631.9672 s
agent0:                 episode reward: -0.8171,                 loss: nan
agent1:                 episode reward: 0.8171,                 loss: 0.2816
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0149s / 632.9821 s
agent0:                 episode reward: 0.5668,                 loss: nan
agent1:                 episode reward: -0.5668,                 loss: 0.2814
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0378s / 634.0199 s
agent0:                 episode reward: 0.8420,                 loss: nan
agent1:                 episode reward: -0.8420,                 loss: 0.2916
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1084s / 635.1284 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.2833
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0293s / 636.1577 s
agent0:                 episode reward: 0.5422,                 loss: nan
agent1:                 episode reward: -0.5422,                 loss: 0.2809
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0850s / 637.2427 s
agent0:                 episode reward: 0.3735,                 loss: nan
agent1:                 episode reward: -0.3735,                 loss: 0.2801
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0357s / 638.2783 s
agent0:                 episode reward: 0.3323,                 loss: nan
agent1:                 episode reward: -0.3323,                 loss: 0.2788
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0372s / 639.3155 s
agent0:                 episode reward: -0.3772,                 loss: nan
agent1:                 episode reward: 0.3772,                 loss: 0.2795
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0278s / 640.3433 s
agent0:                 episode reward: 0.8897,                 loss: nan
agent1:                 episode reward: -0.8897,                 loss: 0.2789
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0715s / 641.4148 s
agent0:                 episode reward: -0.1945,                 loss: nan
agent1:                 episode reward: 0.1945,                 loss: 0.2797
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0506s / 642.4654 s
agent0:                 episode reward: 0.5338,                 loss: nan
agent1:                 episode reward: -0.5338,                 loss: 0.2787
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0243s / 643.4896 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.2795
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0474s / 644.5371 s
agent0:                 episode reward: 0.1605,                 loss: nan
agent1:                 episode reward: -0.1605,                 loss: 0.2913
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0372s / 645.5742 s
agent0:                 episode reward: 0.1408,                 loss: nan
agent1:                 episode reward: -0.1408,                 loss: 0.2828
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0230s / 646.5972 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.2820
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1112s / 647.7084 s
agent0:                 episode reward: 0.4353,                 loss: nan
agent1:                 episode reward: -0.4353,                 loss: 0.2805
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0439s / 648.7524 s
agent0:                 episode reward: 0.3660,                 loss: nan
agent1:                 episode reward: -0.3660,                 loss: 0.2784
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0570s / 649.8094 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.2813
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0590s / 650.8684 s
agent0:                 episode reward: 0.2215,                 loss: nan
agent1:                 episode reward: -0.2215,                 loss: 0.2797
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0593s / 651.9277 s
agent0:                 episode reward: 0.1278,                 loss: nan
agent1:                 episode reward: -0.1278,                 loss: 0.2808
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0748s / 653.0025 s
agent0:                 episode reward: -0.5459,                 loss: nan
agent1:                 episode reward: 0.5459,                 loss: 0.2780
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0525s / 654.0550 s
agent0:                 episode reward: 0.4349,                 loss: nan
agent1:                 episode reward: -0.4349,                 loss: 0.2779
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0665s / 655.1215 s
agent0:                 episode reward: 0.5491,                 loss: nan
agent1:                 episode reward: -0.5491,                 loss: 0.2936
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0531s / 656.1747 s
agent0:                 episode reward: -1.2090,                 loss: nan
agent1:                 episode reward: 1.2090,                 loss: 0.2777
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0910s / 657.2656 s
agent0:                 episode reward: 0.7495,                 loss: nan
agent1:                 episode reward: -0.7495,                 loss: 0.2768
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0709s / 658.3365 s
agent0:                 episode reward: -0.7696,                 loss: nan
agent1:                 episode reward: 0.7696,                 loss: 0.2757
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0643s / 659.4008 s
agent0:                 episode reward: 1.4888,                 loss: nan
agent1:                 episode reward: -1.4888,                 loss: 0.2743
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0569s / 660.4577 s
agent0:                 episode reward: -0.5392,                 loss: nan
agent1:                 episode reward: 0.5392,                 loss: 0.2754
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0504s / 661.5081 s
agent0:                 episode reward: -0.1771,                 loss: nan
agent1:                 episode reward: 0.1771,                 loss: 0.2758
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0695s / 662.5776 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.2754
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0613s / 663.6389 s
agent0:                 episode reward: -0.4688,                 loss: nan
agent1:                 episode reward: 0.4688,                 loss: 0.2757
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0614s / 664.7003 s
agent0:                 episode reward: -0.5342,                 loss: nan
agent1:                 episode reward: 0.5342,                 loss: 0.2757
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0619s / 665.7622 s
agent0:                 episode reward: 0.0437,                 loss: nan
agent1:                 episode reward: -0.0437,                 loss: 0.2681
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0743s / 666.8365 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.2482
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1117s / 667.9481 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.2448
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0685s / 669.0166 s
agent0:                 episode reward: 0.7057,                 loss: nan
agent1:                 episode reward: -0.7057,                 loss: 0.2469
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0593s / 670.0759 s
agent0:                 episode reward: 0.3565,                 loss: nan
agent1:                 episode reward: -0.3565,                 loss: 0.2463
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0964s / 671.1723 s
agent0:                 episode reward: 0.2962,                 loss: nan
agent1:                 episode reward: -0.2962,                 loss: 0.2451
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0563s / 672.2286 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.2449
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0594s / 673.2881 s
agent0:                 episode reward: 0.3191,                 loss: nan
agent1:                 episode reward: -0.3191,                 loss: 0.2430
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0615s / 674.3496 s
agent0:                 episode reward: 0.4164,                 loss: nan
agent1:                 episode reward: -0.4164,                 loss: 0.2425
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0714s / 675.4209 s
agent0:                 episode reward: 0.5646,                 loss: nan
agent1:                 episode reward: -0.5646,                 loss: 0.2422
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0584s / 676.4793 s
agent0:                 episode reward: -0.2295,                 loss: nan
agent1:                 episode reward: 0.2295,                 loss: 0.2217
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1167s / 677.5960 s
agent0:                 episode reward: -0.0657,                 loss: nan
agent1:                 episode reward: 0.0657,                 loss: 0.1871
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 678.6768 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1848
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0687s / 679.7455 s
agent0:                 episode reward: 0.0819,                 loss: nan
agent1:                 episode reward: -0.0819,                 loss: 0.1827
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0914s / 680.8369 s
agent0:                 episode reward: 0.3704,                 loss: nan
agent1:                 episode reward: -0.3704,                 loss: 0.1833
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0698s / 681.9067 s
agent0:                 episode reward: 0.3179,                 loss: nan
agent1:                 episode reward: -0.3179,                 loss: 0.1817
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0970s / 683.0037 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: 0.1831
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0763s / 684.0800 s
agent0:                 episode reward: 0.3899,                 loss: nan
agent1:                 episode reward: -0.3899,                 loss: 0.1832
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0712s / 685.1511 s
agent0:                 episode reward: -0.6861,                 loss: nan
agent1:                 episode reward: 0.6861,                 loss: 0.1820
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0704s / 686.2215 s
agent0:                 episode reward: 0.2532,                 loss: nan
agent1:                 episode reward: -0.2532,                 loss: 0.1820
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0742s / 687.2957 s
agent0:                 episode reward: 0.1742,                 loss: nan
agent1:                 episode reward: -0.1742,                 loss: 0.1747
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1119s / 688.4076 s
agent0:                 episode reward: -0.1106,                 loss: nan
agent1:                 episode reward: 0.1106,                 loss: 0.1513
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0983s / 689.5060 s
agent0:                 episode reward: -0.3333,                 loss: nan
agent1:                 episode reward: 0.3333,                 loss: 0.1506
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0736s / 690.5795 s
agent0:                 episode reward: 0.3224,                 loss: nan
agent1:                 episode reward: -0.3224,                 loss: 0.1536
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1186s / 691.6982 s
agent0:                 episode reward: 0.9068,                 loss: nan
agent1:                 episode reward: -0.9068,                 loss: 0.1514
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0710s / 692.7692 s
agent0:                 episode reward: 0.8535,                 loss: nan
agent1:                 episode reward: -0.8535,                 loss: 0.1520
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0775s / 693.8467 s
agent0:                 episode reward: -0.0454,                 loss: nan
agent1:                 episode reward: 0.0454,                 loss: 0.1506
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0680s / 694.9147 s
agent0:                 episode reward: 0.0224,                 loss: nan
agent1:                 episode reward: -0.0224,                 loss: 0.1515
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0736s / 695.9883 s
agent0:                 episode reward: 0.0369,                 loss: nan
agent1:                 episode reward: -0.0369,                 loss: 0.1508
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0726s / 697.0609 s
agent0:                 episode reward: 1.3932,                 loss: nan
agent1:                 episode reward: -1.3932,                 loss: 0.1514
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1210s / 698.1819 s
agent0:                 episode reward: -0.1641,                 loss: nan
agent1:                 episode reward: 0.1641,                 loss: 0.1827
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0828s / 699.2647 s
agent0:                 episode reward: 0.2513,                 loss: nan
agent1:                 episode reward: -0.2513,                 loss: 0.1841
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0894s / 700.3541 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1825
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0804s / 701.4345 s
agent0:                 episode reward: -0.2199,                 loss: nan
agent1:                 episode reward: 0.2199,                 loss: 0.1797
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0709s / 702.5054 s
agent0:                 episode reward: 0.1346,                 loss: nan
agent1:                 episode reward: -0.1346,                 loss: 0.1805
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0743s / 703.5797 s
agent0:                 episode reward: 1.1064,                 loss: nan
agent1:                 episode reward: -1.1064,                 loss: 0.1790
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0839s / 704.6636 s
agent0:                 episode reward: 0.2574,                 loss: nan
agent1:                 episode reward: -0.2574,                 loss: 0.1793
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0692s / 705.7328 s
agent0:                 episode reward: -1.4738,                 loss: nan
agent1:                 episode reward: 1.4738,                 loss: 0.1782
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0828s / 706.8156 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.1795
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1094s / 707.9251 s
agent0:                 episode reward: 0.0511,                 loss: nan
agent1:                 episode reward: -0.0511,                 loss: 0.1775
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1153s / 709.0404 s
agent0:                 episode reward: -0.4555,                 loss: nan
agent1:                 episode reward: 0.4555,                 loss: 0.2386
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0779s / 710.1183 s
agent0:                 episode reward: 0.3205,                 loss: nan
agent1:                 episode reward: -0.3205,                 loss: 0.2537
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1017s / 711.2199 s
agent0:                 episode reward: 0.3530,                 loss: nan
agent1:                 episode reward: -0.3530,                 loss: 0.2543
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0802s / 712.3001 s
agent0:                 episode reward: 0.0779,                 loss: nan
agent1:                 episode reward: -0.0779,                 loss: 0.2580
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0868s / 713.3869 s
agent0:                 episode reward: 0.5440,                 loss: nan
agent1:                 episode reward: -0.5440,                 loss: 0.2552
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0850s / 714.4718 s
agent0:                 episode reward: 0.2489,                 loss: nan
agent1:                 episode reward: -0.2489,                 loss: 0.2550
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 715.5527 s
agent0:                 episode reward: 0.5314,                 loss: nan
agent1:                 episode reward: -0.5314,                 loss: 0.2557
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1062s / 716.6588 s
agent0:                 episode reward: -0.4191,                 loss: nan
agent1:                 episode reward: 0.4191,                 loss: 0.2570
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0860s / 717.7448 s
agent0:                 episode reward: 0.4275,                 loss: nan
agent1:                 episode reward: -0.4275,                 loss: 0.2556
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1382s / 718.8830 s
agent0:                 episode reward: 0.0235,                 loss: nan
agent1:                 episode reward: -0.0235,                 loss: 0.2557
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0967s / 719.9797 s
agent0:                 episode reward: -0.3799,                 loss: nan
agent1:                 episode reward: 0.3799,                 loss: 0.2765
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0897s / 721.0695 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.2748
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0939s / 722.1634 s
agent0:                 episode reward: 0.3168,                 loss: nan
agent1:                 episode reward: -0.3168,                 loss: 0.2739
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0997s / 723.2631 s
agent0:                 episode reward: 0.4925,                 loss: nan
agent1:                 episode reward: -0.4925,                 loss: 0.2715
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1060s / 724.3691 s
agent0:                 episode reward: 0.6250,                 loss: nan
agent1:                 episode reward: -0.6250,                 loss: 0.2727
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1003s / 725.4694 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.2724
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0888s / 726.5582 s
agent0:                 episode reward: -1.2183,                 loss: nan
agent1:                 episode reward: 1.2183,                 loss: 0.2725
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0842s / 727.6425 s
agent0:                 episode reward: 0.0638,                 loss: nan
agent1:                 episode reward: -0.0638,                 loss: 0.2737
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1216s / 728.7641 s
agent0:                 episode reward: -0.4261,                 loss: nan
agent1:                 episode reward: 0.4261,                 loss: 0.2729
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1207s / 729.8848 s
agent0:                 episode reward: -0.1880,                 loss: nan
agent1:                 episode reward: 0.1880,                 loss: 0.2719
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1220s / 731.0068 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.2762
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1190s / 732.1257 s
agent0:                 episode reward: 0.2768,                 loss: nan
agent1:                 episode reward: -0.2768,                 loss: 0.2631
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1175s / 733.2432 s
agent0:                 episode reward: -0.4402,                 loss: nan
agent1:                 episode reward: 0.4402,                 loss: 0.2619
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0868s / 734.3300 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.2619
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0951s / 735.4251 s
agent0:                 episode reward: -0.5566,                 loss: nan
agent1:                 episode reward: 0.5566,                 loss: 0.2653
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0913s / 736.5164 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.2640
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0947s / 737.6111 s
agent0:                 episode reward: -0.1296,                 loss: nan
agent1:                 episode reward: 0.1296,                 loss: 0.2614
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1098s / 738.7209 s
agent0:                 episode reward: 0.0149,                 loss: nan
agent1:                 episode reward: -0.0149,                 loss: 0.2628
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1439s / 739.8648 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.2615
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1196s / 740.9844 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.2612
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1008s / 742.0852 s
agent0:                 episode reward: 0.0975,                 loss: nan
agent1:                 episode reward: -0.0975,                 loss: 0.2686
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1029s / 743.1881 s
agent0:                 episode reward: 1.2574,                 loss: nan
agent1:                 episode reward: -1.2574,                 loss: 0.2614
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1108s / 744.2989 s
agent0:                 episode reward: 0.3699,                 loss: nan
agent1:                 episode reward: -0.3699,                 loss: 0.2608
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1028s / 745.4017 s
agent0:                 episode reward: -0.5183,                 loss: nan
agent1:                 episode reward: 0.5183,                 loss: 0.2601
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1019s / 746.5036 s
agent0:                 episode reward: 0.4025,                 loss: nan
agent1:                 episode reward: -0.4025,                 loss: 0.2602
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1046s / 747.6082 s
agent0:                 episode reward: 0.2600,                 loss: nan
agent1:                 episode reward: -0.2600,                 loss: 0.2601
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1062s / 748.7144 s
agent0:                 episode reward: -0.6771,                 loss: nan
agent1:                 episode reward: 0.6771,                 loss: 0.2598
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1706s / 749.8850 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: 1.0719,                 loss: nan
agent1:                 episode reward: -1.0719,                 loss: 0.2605
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1054s / 750.9903 s
agent0:                 episode reward: 0.0288,                 loss: nan
agent1:                 episode reward: -0.0288,                 loss: 0.2590
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0987s / 752.0891 s
agent0:                 episode reward: 0.0715,                 loss: nan
agent1:                 episode reward: -0.0715,                 loss: 0.2612
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1562s / 753.2452 s
agent0:                 episode reward: -0.5867,                 loss: nan
agent1:                 episode reward: 0.5867,                 loss: 0.2812
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1103s / 754.3555 s
agent0:                 episode reward: -0.1002,                 loss: nan
agent1:                 episode reward: 0.1002,                 loss: 0.2708
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1132s / 755.4687 s
agent0:                 episode reward: -1.0178,                 loss: nan
agent1:                 episode reward: 1.0178,                 loss: 0.2636
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1166s / 756.5854 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.2636
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1334s / 757.7188 s
agent0:                 episode reward: -1.6747,                 loss: nan
agent1:                 episode reward: 1.6747,                 loss: 0.2639
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1222s / 758.8410 s
agent0:                 episode reward: -0.9307,                 loss: nan
agent1:                 episode reward: 0.9307,                 loss: 0.2652
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1499s / 759.9909 s
agent0:                 episode reward: -0.1316,                 loss: nan
agent1:                 episode reward: 0.1316,                 loss: 0.2618
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1382s / 761.1291 s
agent0:                 episode reward: 0.1246,                 loss: nan
agent1:                 episode reward: -0.1246,                 loss: 0.2613
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1213s / 762.2504 s
agent0:                 episode reward: -0.1847,                 loss: nan
agent1:                 episode reward: 0.1847,                 loss: 0.2645
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1146s / 763.3650 s
agent0:                 episode reward: 0.2269,                 loss: nan
agent1:                 episode reward: -0.2269,                 loss: 0.2617
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1123s / 764.4773 s
agent0:                 episode reward: 0.5178,                 loss: nan
agent1:                 episode reward: -0.5178,                 loss: 0.2800
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1278s / 765.6051 s
agent0:                 episode reward: -0.3836,                 loss: nan
agent1:                 episode reward: 0.3836,                 loss: 0.2653
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1343s / 766.7394 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.2615
