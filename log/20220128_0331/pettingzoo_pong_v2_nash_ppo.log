pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220128_0331/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220128_0331/pettingzoo_pong_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1353.0,                last time consumption/overall running time: 17.0804s / 17.0804 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.2521
env0_second_0:                 episode reward: 6.0000,                 loss: 0.2585
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1180.85,                last time consumption/overall running time: 277.8374s / 294.9178 s
env0_first_0:                 episode reward: 6.7000,                 loss: 0.2939
env0_second_0:                 episode reward: -6.7000,                 loss: 0.3100
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1157.85,                last time consumption/overall running time: 272.3129s / 567.2307 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.5247
env0_second_0:                 episode reward: -3.1500,                 loss: 0.5667
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1090.2,                last time consumption/overall running time: 257.3183s / 824.5491 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.6950
env0_second_0:                 episode reward: -4.4500,                 loss: 0.7118
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1113.55,                last time consumption/overall running time: 264.1643s / 1088.7134 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.7473
env0_second_0:                 episode reward: -2.0000,                 loss: 0.7260
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1073.15,                last time consumption/overall running time: 255.2983s / 1344.0117 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.7252
env0_second_0:                 episode reward: -2.8000,                 loss: 0.7046
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1081.25,                last time consumption/overall running time: 258.8838s / 1602.8955 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.7567
env0_second_0:                 episode reward: 2.0000,                 loss: 0.7437
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1201.75,                last time consumption/overall running time: 286.2842s / 1889.1797 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.7105
env0_second_0:                 episode reward: 0.6500,                 loss: 0.6907
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1111.8,                last time consumption/overall running time: 267.1242s / 2156.3039 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.6855
env0_second_0:                 episode reward: -3.2500,                 loss: 0.6809
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1217.4,                last time consumption/overall running time: 290.8522s / 2447.1562 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.6687
env0_second_0:                 episode reward: 1.9000,                 loss: 0.6647
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1129.5,                last time consumption/overall running time: 271.1591s / 2718.3153 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6621
env0_second_0:                 episode reward: 0.1500,                 loss: 0.6568
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1099.45,                last time consumption/overall running time: 264.6850s / 2983.0003 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.6698
env0_second_0:                 episode reward: -4.8500,                 loss: 0.6667
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1162.4,                last time consumption/overall running time: 275.1244s / 3258.1248 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.6575
env0_second_0:                 episode reward: -0.5500,                 loss: 0.6532
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1223.55,                last time consumption/overall running time: 289.2095s / 3547.3343 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.6829
env0_second_0:                 episode reward: -5.2500,                 loss: 0.6771
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1115.6,                last time consumption/overall running time: 265.2906s / 3812.6249 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.5984
env0_second_0:                 episode reward: 0.1500,                 loss: 0.6010
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1164.85,                last time consumption/overall running time: 276.6996s / 4089.3245 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.6152
env0_second_0:                 episode reward: -1.0000,                 loss: 0.6104
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1198.2,                last time consumption/overall running time: 284.8653s / 4374.1898 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.6141
env0_second_0:                 episode reward: 2.7500,                 loss: 0.5995
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1165.4,                last time consumption/overall running time: 276.8198s / 4651.0095 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.5278
env0_second_0:                 episode reward: 8.0500,                 loss: 0.5171
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1195.05,                last time consumption/overall running time: 282.9586s / 4933.9681 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.4912
env0_second_0:                 episode reward: 7.1000,                 loss: 0.4988
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1136.55,                last time consumption/overall running time: 266.9876s / 5200.9557 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.5618
env0_second_0:                 episode reward: 8.2000,                 loss: 0.5637
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1109.05,                last time consumption/overall running time: 260.2575s / 5461.2131 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.4369
env0_second_0:                 episode reward: 11.2500,                 loss: 0.4500
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1111.35,                last time consumption/overall running time: 262.3559s / 5723.5690 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.4336
env0_second_0:                 episode reward: 11.8500,                 loss: 0.4370
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1146.8,                last time consumption/overall running time: 270.9666s / 5994.5356 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.3910
env0_second_0:                 episode reward: 11.7500,                 loss: 0.3895
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1246.25,                last time consumption/overall running time: 289.4434s / 6283.9790 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.4035
env0_second_0:                 episode reward: 9.2500,                 loss: 0.4045
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1332.85,                last time consumption/overall running time: 309.5510s / 6593.5300 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.4397
env0_second_0:                 episode reward: 9.3500,                 loss: 0.4354
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1567.7,                last time consumption/overall running time: 360.8370s / 6954.3670 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.4108
env0_second_0:                 episode reward: 4.1500,                 loss: 0.4142
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1784.7,                last time consumption/overall running time: 410.4119s / 7364.7789 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3909
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3919
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1922.25,                last time consumption/overall running time: 442.9851s / 7807.7640 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3353
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3302
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1934.6,                last time consumption/overall running time: 446.0022s / 8253.7662 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.3320
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3274
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1949.35,                last time consumption/overall running time: 447.3058s / 8701.0720 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.2966
env0_second_0:                 episode reward: 2.6000,                 loss: 0.2887
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1913.95,                last time consumption/overall running time: 439.2432s / 9140.3153 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.3298
env0_second_0:                 episode reward: 4.8000,                 loss: 0.3214
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1906.1,                last time consumption/overall running time: 437.7270s / 9578.0423 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.2958
env0_second_0:                 episode reward: 5.0500,                 loss: 0.2907
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2017.4,                last time consumption/overall running time: 466.8485s / 10044.8908 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3030
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2975
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1974.2,                last time consumption/overall running time: 456.9240s / 10501.8148 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2871
env0_second_0:                 episode reward: 1.8000,                 loss: 0.2911
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 2049.15,                last time consumption/overall running time: 472.8751s / 10974.6900 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.2880
env0_second_0:                 episode reward: 2.5500,                 loss: 0.2853
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1995.6,                last time consumption/overall running time: 460.0688s / 11434.7588 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2989
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2921
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1955.5,                last time consumption/overall running time: 452.4011s / 11887.1598 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.2945
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2969
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1852.05,                last time consumption/overall running time: 427.5990s / 12314.7589 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.3279
env0_second_0:                 episode reward: 5.9500,                 loss: 0.3258
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1916.4,                last time consumption/overall running time: 445.7399s / 12760.4988 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.3061
env0_second_0:                 episode reward: 5.6000,                 loss: 0.3082
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1838.7,                last time consumption/overall running time: 427.3849s / 13187.8837 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.3181
env0_second_0:                 episode reward: 7.5000,                 loss: 0.3198
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1917.8,                last time consumption/overall running time: 445.7490s / 13633.6326 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.2817
env0_second_0:                 episode reward: 6.2000,                 loss: 0.2758
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1891.35,                last time consumption/overall running time: 437.8202s / 14071.4528 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.2962
env0_second_0:                 episode reward: 7.8000,                 loss: 0.2993
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1867.95,                last time consumption/overall running time: 428.4765s / 14499.9293 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.2645
env0_second_0:                 episode reward: 9.3500,                 loss: 0.2583
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1981.9,                last time consumption/overall running time: 454.3108s / 14954.2401 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2599
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2667
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1984.25,                last time consumption/overall running time: 454.7156s / 15408.9556 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.2563
env0_second_0:                 episode reward: 5.5000,                 loss: 0.2563
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1896.95,                last time consumption/overall running time: 437.8966s / 15846.8523 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.2757
env0_second_0:                 episode reward: 8.4500,                 loss: 0.2762
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1948.15,                last time consumption/overall running time: 450.6130s / 16297.4653 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.2578
env0_second_0:                 episode reward: 8.4000,                 loss: 0.2665
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1911.1,                last time consumption/overall running time: 442.3462s / 16739.8115 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2781
env0_second_0:                 episode reward: 9.0000,                 loss: 0.2835
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1957.2,                last time consumption/overall running time: 451.7213s / 17191.5328 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.2915
env0_second_0:                 episode reward: 8.2500,                 loss: 0.2959
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1876.5,                last time consumption/overall running time: 430.8811s / 17622.4139 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.2893
env0_second_0:                 episode reward: 9.1500,                 loss: 0.2921
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1939.0,                last time consumption/overall running time: 444.9019s / 18067.3157 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2376
env0_second_0:                 episode reward: 8.0500,                 loss: 0.2411
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1902.5,                last time consumption/overall running time: 436.8120s / 18504.1277 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.2534
env0_second_0:                 episode reward: 9.6500,                 loss: 0.2580
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1821.8,                last time consumption/overall running time: 417.8530s / 18921.9807 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.2349
env0_second_0:                 episode reward: 8.9000,                 loss: 0.2521
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1906.6,                last time consumption/overall running time: 441.6372s / 19363.6179 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.2295
env0_second_0:                 episode reward: 9.6000,                 loss: 0.2303
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1881.2,                last time consumption/overall running time: 435.9542s / 19799.5722 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1966
env0_second_0:                 episode reward: 10.5500,                 loss: 0.2108
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1833.6,                last time consumption/overall running time: 424.0554s / 20223.6276 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.2552
env0_second_0:                 episode reward: 9.8000,                 loss: 0.2504
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1814.45,                last time consumption/overall running time: 420.6413s / 20644.2689 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.2609
env0_second_0:                 episode reward: 10.9000,                 loss: 0.2797
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1842.55,                last time consumption/overall running time: 426.2910s / 21070.5600 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.2366
env0_second_0:                 episode reward: 8.6000,                 loss: 0.2538
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1699.7,                last time consumption/overall running time: 397.1068s / 21467.6668 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.2398
env0_second_0:                 episode reward: 11.7500,                 loss: 0.2488
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1606.05,                last time consumption/overall running time: 376.9138s / 21844.5806 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.2450
env0_second_0:                 episode reward: 13.5500,                 loss: 0.2649
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1815.95,                last time consumption/overall running time: 426.2998s / 22270.8803 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.2613
env0_second_0:                 episode reward: 11.8500,                 loss: 0.2704
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1701.9,                last time consumption/overall running time: 394.4342s / 22665.3145 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.2551
env0_second_0:                 episode reward: 12.5500,                 loss: 0.2450
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1774.3,                last time consumption/overall running time: 411.6729s / 23076.9874 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2319
env0_second_0:                 episode reward: 12.6000,                 loss: 0.2484
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1663.6,                last time consumption/overall running time: 388.3990s / 23465.3865 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.2541
env0_second_0:                 episode reward: 10.6500,                 loss: 0.2670
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1721.75,                last time consumption/overall running time: 399.7271s / 23865.1136 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.2293
env0_second_0:                 episode reward: 14.5500,                 loss: 0.2442
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1730.3,                last time consumption/overall running time: 400.7802s / 24265.8937 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.2232
env0_second_0:                 episode reward: 11.3000,                 loss: 0.2498
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1916.3,                last time consumption/overall running time: 443.7697s / 24709.6635 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.2029
env0_second_0:                 episode reward: 10.7000,                 loss: 0.2301
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1705.5,                last time consumption/overall running time: 395.5026s / 25105.1660 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.2446
env0_second_0:                 episode reward: 12.2000,                 loss: 0.2406
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1694.05,                last time consumption/overall running time: 395.0271s / 25500.1932 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.2138
env0_second_0:                 episode reward: 13.9500,                 loss: 0.2190
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1841.2,                last time consumption/overall running time: 427.2614s / 25927.4545 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.2122
env0_second_0:                 episode reward: 11.2000,                 loss: 0.2315
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1870.25,                last time consumption/overall running time: 430.7678s / 26358.2223 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.2194
env0_second_0:                 episode reward: 9.3000,                 loss: 0.2615
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1768.95,                last time consumption/overall running time: 407.6651s / 26765.8874 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1974
env0_second_0:                 episode reward: 13.1000,                 loss: 0.2279
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1817.35,                last time consumption/overall running time: 417.0265s / 27182.9139 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.2109
env0_second_0:                 episode reward: 10.9500,                 loss: 0.2268
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1828.4,                last time consumption/overall running time: 386.5234s / 27569.4373 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1972
env0_second_0:                 episode reward: 12.9500,                 loss: 0.2333
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1833.35,                last time consumption/overall running time: 385.0899s / 27954.5272 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1805
env0_second_0:                 episode reward: 12.2000,                 loss: 0.2075
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1904.45,                last time consumption/overall running time: 400.5351s / 28355.0623 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.1685
env0_second_0:                 episode reward: 11.5000,                 loss: 0.1768
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1894.55,                last time consumption/overall running time: 400.7201s / 28755.7824 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1425
env0_second_0:                 episode reward: 12.1000,                 loss: 0.1635
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1879.1,                last time consumption/overall running time: 398.1109s / 29153.8933 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1809
env0_second_0:                 episode reward: 13.2500,                 loss: 0.2020
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1846.65,                last time consumption/overall running time: 391.0125s / 29544.9058 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.1959
env0_second_0:                 episode reward: 12.1500,                 loss: 0.2207
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1815.75,                last time consumption/overall running time: 385.1581s / 29930.0639 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.1580
env0_second_0:                 episode reward: 12.4500,                 loss: 0.1998
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1762.7,                last time consumption/overall running time: 375.0202s / 30305.0841 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1636
env0_second_0:                 episode reward: 13.2500,                 loss: 0.1962
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1842.2,                last time consumption/overall running time: 388.9217s / 30694.0058 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1513
env0_second_0:                 episode reward: 13.3000,                 loss: 0.1691
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1875.7,                last time consumption/overall running time: 398.0819s / 31092.0877 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.1737
env0_second_0:                 episode reward: 14.4000,                 loss: 0.1926
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2083.75,                last time consumption/overall running time: 437.3372s / 31529.4249 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.1829
env0_second_0:                 episode reward: 10.1500,                 loss: 0.2311
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2283.85,                last time consumption/overall running time: 475.5986s / 32005.0235 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.1498
env0_second_0:                 episode reward: 10.6500,                 loss: 0.1686
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 2200.0,                last time consumption/overall running time: 459.7330s / 32464.7565 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.1682
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1981
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2264.15,                last time consumption/overall running time: 475.9361s / 32940.6925 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.1278
env0_second_0:                 episode reward: 11.3500,                 loss: 0.1490
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2176.1,                last time consumption/overall running time: 455.6281s / 33396.3207 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.1495
env0_second_0:                 episode reward: 11.2500,                 loss: 0.1803
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2198.8,                last time consumption/overall running time: 459.0636s / 33855.3843 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1320
env0_second_0:                 episode reward: 11.8000,                 loss: 0.1624
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2226.35,                last time consumption/overall running time: 463.8408s / 34319.2250 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1175
env0_second_0:                 episode reward: 12.2000,                 loss: 0.1399
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2276.65,                last time consumption/overall running time: 479.9583s / 34799.1833 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1493
env0_second_0:                 episode reward: 11.6000,                 loss: 0.1956
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2242.4,                last time consumption/overall running time: 466.5570s / 35265.7403 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1301
env0_second_0:                 episode reward: 10.7000,                 loss: 0.1557
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2317.6,                last time consumption/overall running time: 483.3075s / 35749.0479 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.1227
env0_second_0:                 episode reward: 12.3500,                 loss: 0.1526
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2253.3,                last time consumption/overall running time: 465.8030s / 36214.8508 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0896
env0_second_0:                 episode reward: 13.8000,                 loss: 0.1068
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2124.3,                last time consumption/overall running time: 440.6127s / 36655.4636 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1102
env0_second_0:                 episode reward: 13.4000,                 loss: 0.1442
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2282.85,                last time consumption/overall running time: 471.6794s / 37127.1430 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1401
env0_second_0:                 episode reward: 12.1000,                 loss: 0.1521
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2347.5,                last time consumption/overall running time: 484.8779s / 37612.0208 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1118
env0_second_0:                 episode reward: 13.2500,                 loss: 0.1292
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1947.45,                last time consumption/overall running time: 413.1818s / 38025.2026 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.5221
env0_second_0:                 episode reward: 1.4500,                 loss: 1.4995
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2404.45,                last time consumption/overall running time: 506.4848s / 38531.6874 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.1618
env0_second_0:                 episode reward: 11.4000,                 loss: 1.5641
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2373.4,                last time consumption/overall running time: 497.3618s / 39029.0492 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1366
env0_second_0:                 episode reward: 10.8500,                 loss: 2.0334
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2280.3,                last time consumption/overall running time: 476.8245s / 39505.8737 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1438
env0_second_0:                 episode reward: 11.6500,                 loss: 1.9284
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2158.15,                last time consumption/overall running time: 450.9053s / 39956.7790 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1867
env0_second_0:                 episode reward: 11.7500,                 loss: 1.6690
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2308.95,                last time consumption/overall running time: 484.8694s / 40441.6483 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.1457
env0_second_0:                 episode reward: 11.0500,                 loss: 1.4910
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2420.8,                last time consumption/overall running time: 508.1858s / 40949.8342 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1087
env0_second_0:                 episode reward: 11.7500,                 loss: 1.4163
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2272.6,                last time consumption/overall running time: 477.3352s / 41427.1693 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1250
env0_second_0:                 episode reward: 13.0500,                 loss: 3.8436
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2273.85,                last time consumption/overall running time: 482.0779s / 41909.2472 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.1307
env0_second_0:                 episode reward: 13.9500,                 loss: 2.1994
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2379.85,                last time consumption/overall running time: 504.5210s / 42413.7682 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.1668
env0_second_0:                 episode reward: 10.0500,                 loss: 4.3191
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2182.8,                last time consumption/overall running time: 465.8066s / 42879.5748 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.1631
env0_second_0:                 episode reward: 10.2500,                 loss: 3.7549
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2388.6,                last time consumption/overall running time: 509.4041s / 43388.9789 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.1363
env0_second_0:                 episode reward: 10.9500,                 loss: 1.9427
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2309.35,                last time consumption/overall running time: 488.5246s / 43877.5035 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1571
env0_second_0:                 episode reward: 12.2000,                 loss: 0.9367
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2129.75,                last time consumption/overall running time: 450.7761s / 44328.2796 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.1670
env0_second_0:                 episode reward: 13.4500,                 loss: 0.6789
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2215.65,                last time consumption/overall running time: 466.6974s / 44794.9770 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.1599
env0_second_0:                 episode reward: 12.3000,                 loss: 0.9854
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2082.0,                last time consumption/overall running time: 439.3545s / 45234.3315 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1438
env0_second_0:                 episode reward: 13.4000,                 loss: 0.4535
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2159.9,                last time consumption/overall running time: 456.2200s / 45690.5515 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1315
env0_second_0:                 episode reward: 13.1500,                 loss: 0.3674
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1505.35,                last time consumption/overall running time: 320.0647s / 46010.6162 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.2434
env0_second_0:                 episode reward: 15.3500,                 loss: 1.2779
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1946.1,                last time consumption/overall running time: 410.7130s / 46421.3292 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.1696
env0_second_0:                 episode reward: 15.4000,                 loss: 1.8809
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1927.85,                last time consumption/overall running time: 411.7687s / 46833.0979 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1473
env0_second_0:                 episode reward: 14.6000,                 loss: 1.9473
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1902.65,                last time consumption/overall running time: 404.5148s / 47237.6126 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1640
env0_second_0:                 episode reward: 14.6500,                 loss: 1.3511
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2203.6,                last time consumption/overall running time: 467.2548s / 47704.8674 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.1276
env0_second_0:                 episode reward: 12.3000,                 loss: 0.4361
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1454.35,                last time consumption/overall running time: 313.9300s / 48018.7974 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.2026
env0_second_0:                 episode reward: 16.0500,                 loss: 1.4986
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 848.0,                last time consumption/overall running time: 187.1659s / 48205.9633 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.4064
env0_second_0:                 episode reward: 2.0000,                 loss: 2.0375
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 945.5,                last time consumption/overall running time: 207.0982s / 48413.0616 s
env0_first_0:                 episode reward: 8.1000,                 loss: 0.2914
env0_second_0:                 episode reward: -8.1000,                 loss: 2.2242
env1_first_0:                 episode reward: 7.1500,                 loss: nan
env1_second_0:                 episode reward: -7.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 986.6,                last time consumption/overall running time: 215.1400s / 48628.2016 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.2607
env0_second_0:                 episode reward: 16.1000,                 loss: 1.2797
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 793.05,                last time consumption/overall running time: 175.7488s / 48803.9504 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2675
env0_second_0:                 episode reward: 0.9000,                 loss: 1.1162
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 728.0,                last time consumption/overall running time: 163.0760s / 48967.0264 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.1588
env0_second_0:                 episode reward: -20.9500,                 loss: 0.5314
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 728.0,                last time consumption/overall running time: 161.6800s / 49128.7064 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1238
env0_second_0:                 episode reward: -20.8000,                 loss: 1.0901
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 728.15,                last time consumption/overall running time: 162.8900s / 49291.5964 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0769
env0_second_0:                 episode reward: -20.8000,                 loss: 0.7450
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 728.6,                last time consumption/overall running time: 162.5585s / 49454.1549 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0422
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2624
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 728.05,                last time consumption/overall running time: 160.4602s / 49614.6151 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0606
env0_second_0:                 episode reward: -20.8000,                 loss: 0.1865
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 728.25,                last time consumption/overall running time: 161.6613s / 49776.2764 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0341
env0_second_0:                 episode reward: -20.8500,                 loss: 0.4251
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 728.05,                last time consumption/overall running time: 161.3886s / 49937.6649 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0352
env0_second_0:                 episode reward: -20.8000,                 loss: 0.5911
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 728.55,                last time consumption/overall running time: 161.9610s / 50099.6260 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0208
env0_second_0:                 episode reward: -20.7500,                 loss: 0.6089
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 729.35,                last time consumption/overall running time: 162.1745s / 50261.8005 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0167
env0_second_0:                 episode reward: -20.7500,                 loss: 0.8149
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 783.15,                last time consumption/overall running time: 173.4358s / 50435.2364 s
env0_first_0:                 episode reward: 16.2000,                 loss: 0.1200
env0_second_0:                 episode reward: -16.2000,                 loss: 0.5951
env1_first_0:                 episode reward: 17.5000,                 loss: nan
env1_second_0:                 episode reward: -17.5000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1063.8,                last time consumption/overall running time: 228.8748s / 50664.1111 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6188
env0_second_0:                 episode reward: -0.4500,                 loss: 1.0494
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 887.95,                last time consumption/overall running time: 193.4500s / 50857.5611 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.3592
env0_second_0:                 episode reward: 17.2500,                 loss: 0.5942
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 733.65,                last time consumption/overall running time: 161.4415s / 51019.0026 s
env0_first_0:                 episode reward: 16.6500,                 loss: 0.1105
env0_second_0:                 episode reward: -16.6500,                 loss: 1.2971
env1_first_0:                 episode reward: 16.4500,                 loss: nan
env1_second_0:                 episode reward: -16.4500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 766.8,                last time consumption/overall running time: 170.0628s / 51189.0653 s
env0_first_0:                 episode reward: 16.2500,                 loss: 0.1281
env0_second_0:                 episode reward: -16.2500,                 loss: 0.4905
env1_first_0:                 episode reward: 15.9000,                 loss: nan
env1_second_0:                 episode reward: -15.9000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 849.9,                last time consumption/overall running time: 186.0180s / 51375.0834 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.2443
env0_second_0:                 episode reward: 18.0000,                 loss: 1.7789
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 802.45,                last time consumption/overall running time: 175.4712s / 51550.5546 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0795
env0_second_0:                 episode reward: 18.9500,                 loss: 0.7235
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1016.75,                last time consumption/overall running time: 217.7106s / 51768.2652 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.2735
env0_second_0:                 episode reward: 16.2500,                 loss: 0.8503
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1204.1,                last time consumption/overall running time: 258.1307s / 52026.3958 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.2688
env0_second_0:                 episode reward: 15.0000,                 loss: 0.8550
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1128.3,                last time consumption/overall running time: 240.2377s / 52266.6335 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.4509
env0_second_0:                 episode reward: 11.9000,                 loss: 0.7354
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 956.35,                last time consumption/overall running time: 207.3559s / 52473.9894 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.2860
env0_second_0:                 episode reward: 14.6000,                 loss: 2.0364
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 874.8,                last time consumption/overall running time: 188.9713s / 52662.9607 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.2641
env0_second_0:                 episode reward: 15.3500,                 loss: 1.7141
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 925.8,                last time consumption/overall running time: 199.5936s / 52862.5543 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.2865
env0_second_0:                 episode reward: 15.6500,                 loss: 1.2825
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 921.0,                last time consumption/overall running time: 197.7357s / 53060.2900 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.3826
env0_second_0:                 episode reward: 14.4500,                 loss: 4.3715
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 819.9,                last time consumption/overall running time: 176.4767s / 53236.7667 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.3771
env0_second_0:                 episode reward: 12.7500,                 loss: 2.2232
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 986.95,                last time consumption/overall running time: 210.9464s / 53447.7131 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.2830
env0_second_0:                 episode reward: 15.1500,                 loss: 1.3593
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1011.05,                last time consumption/overall running time: 213.9313s / 53661.6444 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.2727
env0_second_0:                 episode reward: 15.3000,                 loss: 1.2157
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1003.6,                last time consumption/overall running time: 215.2343s / 53876.8787 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.2435
env0_second_0:                 episode reward: 17.2000,                 loss: 0.8576
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 980.2,                last time consumption/overall running time: 209.3516s / 54086.2304 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.1867
env0_second_0:                 episode reward: 17.5500,                 loss: 0.5858
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 919.65,                last time consumption/overall running time: 198.5358s / 54284.7661 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.1736
env0_second_0:                 episode reward: 17.7000,                 loss: 0.3735
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1034.9,                last time consumption/overall running time: 221.6369s / 54506.4031 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.2161
env0_second_0:                 episode reward: 17.0500,                 loss: 0.6537
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1036.4,                last time consumption/overall running time: 222.4189s / 54728.8220 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.2994
env0_second_0:                 episode reward: 15.4500,                 loss: 0.6438
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1079.0,                last time consumption/overall running time: 230.6542s / 54959.4762 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.3320
env0_second_0:                 episode reward: 15.2500,                 loss: 0.5400
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1230.75,                last time consumption/overall running time: 260.9159s / 55220.3921 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.4611
env0_second_0:                 episode reward: 11.6000,                 loss: 0.7115
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1173.15,                last time consumption/overall running time: 247.4080s / 55467.8001 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.3539
env0_second_0:                 episode reward: 13.9500,                 loss: 0.8760
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1275.75,                last time consumption/overall running time: 272.9649s / 55740.7651 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.2001
env0_second_0:                 episode reward: 14.8500,                 loss: 0.4294
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1325.35,                last time consumption/overall running time: 282.8965s / 56023.6616 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1727
env0_second_0:                 episode reward: 12.7000,                 loss: 0.2962
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1466.15,                last time consumption/overall running time: 313.0334s / 56336.6950 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.1877
env0_second_0:                 episode reward: 14.3500,                 loss: 0.3158
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1542.0,                last time consumption/overall running time: 329.0620s / 56665.7570 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.2282
env0_second_0:                 episode reward: 12.0000,                 loss: 0.3382
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1474.7,                last time consumption/overall running time: 316.9067s / 56982.6637 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.1870
env0_second_0:                 episode reward: 15.1000,                 loss: 0.2598
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1479.85,                last time consumption/overall running time: 318.0411s / 57300.7048 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.1374
env0_second_0:                 episode reward: 15.6500,                 loss: 0.1955
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1470.95,                last time consumption/overall running time: 314.5898s / 57615.2946 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.1032
env0_second_0:                 episode reward: 15.8500,                 loss: 0.2076
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1667.15,                last time consumption/overall running time: 357.1278s / 57972.4223 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0623
env0_second_0:                 episode reward: 15.7500,                 loss: 0.1901
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1673.6,                last time consumption/overall running time: 362.7030s / 58335.1253 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.0570
env0_second_0:                 episode reward: 16.7500,                 loss: 0.1752
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1700.3,                last time consumption/overall running time: 364.1542s / 58699.2795 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0603
env0_second_0:                 episode reward: 16.6500,                 loss: 0.1978
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1657.85,                last time consumption/overall running time: 352.7348s / 59052.0144 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.0126
env0_second_0:                 episode reward: 16.9500,                 loss: 0.0839
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1593.85,                last time consumption/overall running time: 340.3129s / 59392.3273 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.2406
env0_second_0:                 episode reward: 10.3000,                 loss: 1.1905
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1734.5,                last time consumption/overall running time: 369.0363s / 59761.3636 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0207
env0_second_0:                 episode reward: 16.2000,                 loss: 5.6181
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1798.0,                last time consumption/overall running time: 384.5055s / 60145.8692 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0175
env0_second_0:                 episode reward: 15.7500,                 loss: 3.9106
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1697.6,                last time consumption/overall running time: 358.4190s / 60504.2882 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0190
env0_second_0:                 episode reward: 15.8500,                 loss: 1.7319
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1768.2,                last time consumption/overall running time: 368.4179s / 60872.7061 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0335
env0_second_0:                 episode reward: 16.2000,                 loss: 0.4379
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1868.4,                last time consumption/overall running time: 388.7488s / 61261.4548 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0443
env0_second_0:                 episode reward: 15.0000,                 loss: 0.1953
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2039.4,                last time consumption/overall running time: 422.2658s / 61683.7206 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0469
env0_second_0:                 episode reward: 14.6000,                 loss: 0.1538
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2063.05,                last time consumption/overall running time: 429.5022s / 62113.2228 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0888
env0_second_0:                 episode reward: 12.8500,                 loss: 2.0988
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2055.65,                last time consumption/overall running time: 400.1141s / 62513.3369 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0645
env0_second_0:                 episode reward: 15.6000,                 loss: 2.0990
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1943.8,                last time consumption/overall running time: 363.6737s / 62877.0106 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0688
env0_second_0:                 episode reward: 15.1500,                 loss: 0.3322
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1932.5,                last time consumption/overall running time: 363.5643s / 63240.5749 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0806
env0_second_0:                 episode reward: 15.5500,                 loss: 1.2789
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1944.75,                last time consumption/overall running time: 365.4403s / 63606.0152 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.0758
env0_second_0:                 episode reward: 15.1000,                 loss: 0.7297
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1619.75,                last time consumption/overall running time: 307.5753s / 63913.5905 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.3646
env0_second_0:                 episode reward: 5.1500,                 loss: 0.8858
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1872.5,                last time consumption/overall running time: 351.1413s / 64264.7318 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0383
env0_second_0:                 episode reward: 17.1000,                 loss: 0.2419
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1919.7,                last time consumption/overall running time: 365.6111s / 64630.3429 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0696
env0_second_0:                 episode reward: 16.0000,                 loss: 0.1932
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1894.3,                last time consumption/overall running time: 360.6135s / 64990.9565 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0263
env0_second_0:                 episode reward: 15.6000,                 loss: 0.1163
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1954.95,                last time consumption/overall running time: 371.9766s / 65362.9330 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0151
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0965
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1888.55,                last time consumption/overall running time: 360.5891s / 65723.5222 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0313
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0758
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 996.15,                last time consumption/overall running time: 196.6322s / 65920.1544 s
env0_first_0:                 episode reward: 13.3000,                 loss: 0.2090
env0_second_0:                 episode reward: -13.3000,                 loss: 0.9915
env1_first_0:                 episode reward: 12.8500,                 loss: nan
env1_second_0:                 episode reward: -12.8500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 816.5,                last time consumption/overall running time: 165.1501s / 66085.3045 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4130
env0_second_0:                 episode reward: -2.8500,                 loss: 1.2212
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 875.15,                last time consumption/overall running time: 173.8903s / 66259.1948 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.3024
env0_second_0:                 episode reward: 16.7500,                 loss: 0.4244
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 845.85,                last time consumption/overall running time: 170.6196s / 66429.8144 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.2733
env0_second_0:                 episode reward: 17.3000,                 loss: 0.3569
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 793.95,                last time consumption/overall running time: 161.6199s / 66591.4343 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.2204
env0_second_0:                 episode reward: 15.0000,                 loss: 0.3082
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 750.0,                last time consumption/overall running time: 152.8689s / 66744.3032 s
env0_first_0:                 episode reward: 15.0500,                 loss: 0.2531
env0_second_0:                 episode reward: -15.0500,                 loss: 0.4429
env1_first_0:                 episode reward: 13.2000,                 loss: nan
env1_second_0:                 episode reward: -13.2000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 809.65,                last time consumption/overall running time: 163.0389s / 66907.3421 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.3014
env0_second_0:                 episode reward: 14.4000,                 loss: 0.3935
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 815.3,                last time consumption/overall running time: 162.4247s / 67069.7668 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.3642
env0_second_0:                 episode reward: 17.4500,                 loss: 0.5818
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 789.3,                last time consumption/overall running time: 157.3473s / 67227.1141 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.1940
env0_second_0:                 episode reward: 17.4000,                 loss: 0.3187
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 909.25,                last time consumption/overall running time: 179.3794s / 67406.4935 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.3245
env0_second_0:                 episode reward: 15.9000,                 loss: 0.6691
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 772.05,                last time consumption/overall running time: 154.0141s / 67560.5076 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.1783
env0_second_0:                 episode reward: 19.6000,                 loss: 0.3777
env1_first_0:                 episode reward: -19.2000,                 loss: nan
env1_second_0:                 episode reward: 19.2000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 740.65,                last time consumption/overall running time: 147.8453s / 67708.3530 s
env0_first_0:                 episode reward: 8.7500,                 loss: 0.2793
env0_second_0:                 episode reward: -8.7500,                 loss: 1.9606
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 728.25,                last time consumption/overall running time: 145.8189s / 67854.1719 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1443
env0_second_0:                 episode reward: -20.7000,                 loss: 0.3215
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 728.0,                last time consumption/overall running time: 145.8297s / 68000.0015 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0966
env0_second_0:                 episode reward: -20.9000,                 loss: 0.1707
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 773.65,                last time consumption/overall running time: 154.0783s / 68154.0798 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.2597
env0_second_0:                 episode reward: 5.0000,                 loss: 1.4907
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 832.05,                last time consumption/overall running time: 165.2515s / 68319.3313 s
env0_first_0:                 episode reward: -17.9500,                 loss: 0.1938
env0_second_0:                 episode reward: 17.9500,                 loss: 2.0135
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 736.95,                last time consumption/overall running time: 148.5205s / 68467.8517 s
env0_first_0:                 episode reward: 10.9000,                 loss: 0.1578
env0_second_0:                 episode reward: -10.9000,                 loss: 2.7453
env1_first_0:                 episode reward: 11.2000,                 loss: nan
env1_second_0:                 episode reward: -11.2000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 728.45,                last time consumption/overall running time: 145.6047s / 68613.4564 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0561
env0_second_0:                 episode reward: -20.7000,                 loss: 3.5011
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 729.1,                last time consumption/overall running time: 145.5968s / 68759.0532 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0324
env0_second_0:                 episode reward: -20.7500,                 loss: 3.8051
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 728.15,                last time consumption/overall running time: 144.4479s / 68903.5011 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0534
env0_second_0:                 episode reward: -20.9000,                 loss: 3.3736
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 728.0,                last time consumption/overall running time: 143.5910s / 69047.0921 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0272
env0_second_0:                 episode reward: -20.9000,                 loss: 2.8857
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 733.45,                last time consumption/overall running time: 144.6908s / 69191.7830 s
env0_first_0:                 episode reward: 16.4500,                 loss: 0.1378
env0_second_0:                 episode reward: -16.4500,                 loss: 2.0030
env1_first_0:                 episode reward: 14.7000,                 loss: nan
env1_second_0:                 episode reward: -14.7000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 742.1,                last time consumption/overall running time: 147.3120s / 69339.0950 s
env0_first_0:                 episode reward: 16.7000,                 loss: 0.0926
env0_second_0:                 episode reward: -16.7000,                 loss: 0.7682
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 729.7,                last time consumption/overall running time: 143.5970s / 69482.6919 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0340
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4735
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 729.0,                last time consumption/overall running time: 143.7285s / 69626.4204 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0624
env0_second_0:                 episode reward: -20.6500,                 loss: 0.3446
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 729.2,                last time consumption/overall running time: 144.7573s / 69771.1777 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0062
env0_second_0:                 episode reward: -20.5500,                 loss: 0.3828
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 729.4,                last time consumption/overall running time: 144.3811s / 69915.5588 s
env0_first_0:                 episode reward: 20.7000,                 loss: -0.0088
env0_second_0:                 episode reward: -20.7000,                 loss: 0.3845
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 728.5,                last time consumption/overall running time: 144.2465s / 70059.8053 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0144
env0_second_0:                 episode reward: -20.6500,                 loss: 0.1961
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 728.45,                last time consumption/overall running time: 144.7195s / 70204.5249 s
env0_first_0:                 episode reward: 20.8500,                 loss: -0.0232
env0_second_0:                 episode reward: -20.8500,                 loss: 0.0739
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 917.35,                last time consumption/overall running time: 179.0087s / 70383.5335 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.5517
env0_second_0:                 episode reward: 1.6000,                 loss: 0.6411
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 789.85,                last time consumption/overall running time: 158.5701s / 70542.1036 s
env0_first_0:                 episode reward: -18.2500,                 loss: 0.1280
env0_second_0:                 episode reward: 18.2500,                 loss: 0.1935
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 793.65,                last time consumption/overall running time: 157.2050s / 70699.3086 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.3203
env0_second_0:                 episode reward: 14.6000,                 loss: 0.4625
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 795.25,                last time consumption/overall running time: 156.6641s / 70855.9728 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.1816
env0_second_0:                 episode reward: 19.8000,                 loss: 0.2653
env1_first_0:                 episode reward: -18.2000,                 loss: nan
env1_second_0:                 episode reward: 18.2000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 785.55,                last time consumption/overall running time: 155.1991s / 71011.1718 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.1669
env0_second_0:                 episode reward: 18.7500,                 loss: 0.4091
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 797.8,                last time consumption/overall running time: 158.7211s / 71169.8929 s
env0_first_0:                 episode reward: -17.3500,                 loss: 0.1247
env0_second_0:                 episode reward: 17.3500,                 loss: 0.3600
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 824.05,                last time consumption/overall running time: 162.4353s / 71332.3282 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.2523
env0_second_0:                 episode reward: 15.3500,                 loss: 0.4103
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1278.6,                last time consumption/overall running time: 246.6300s / 71578.9582 s
env0_first_0:                 episode reward: 10.5000,                 loss: 0.5385
env0_second_0:                 episode reward: -10.5000,                 loss: 3.5318
env1_first_0:                 episode reward: 11.0500,                 loss: nan
env1_second_0:                 episode reward: -11.0500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1717.8,                last time consumption/overall running time: 325.0133s / 71903.9715 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.3956
env0_second_0:                 episode reward: -3.7000,                 loss: 3.4772
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1900.5,                last time consumption/overall running time: 353.5126s / 72257.4841 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.2886
env0_second_0:                 episode reward: 2.7500,                 loss: 3.8157
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1894.7,                last time consumption/overall running time: 354.4739s / 72611.9581 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.1681
env0_second_0:                 episode reward: 8.5500,                 loss: 5.5940
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1905.65,                last time consumption/overall running time: 364.6736s / 72976.6316 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.1668
env0_second_0:                 episode reward: 8.8000,                 loss: 4.1175
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1884.45,                last time consumption/overall running time: 361.5081s / 73338.1398 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1029
env0_second_0:                 episode reward: 11.1500,                 loss: 3.7491
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2059.45,                last time consumption/overall running time: 394.1222s / 73732.2619 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.1547
env0_second_0:                 episode reward: 7.1000,                 loss: 4.4698
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2023.7,                last time consumption/overall running time: 384.3143s / 74116.5763 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.1466
env0_second_0:                 episode reward: 10.1000,                 loss: 3.2334
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1832.0,                last time consumption/overall running time: 351.8217s / 74468.3980 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.0935
env0_second_0:                 episode reward: 14.8000,                 loss: 3.1311
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1771.5,                last time consumption/overall running time: 340.3396s / 74808.7375 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.2382
env0_second_0:                 episode reward: 11.3000,                 loss: 4.5040
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1767.05,                last time consumption/overall running time: 340.7390s / 75149.4765 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.2035
env0_second_0:                 episode reward: 10.1000,                 loss: 4.1282
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1677.35,                last time consumption/overall running time: 321.8222s / 75471.2988 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1523
env0_second_0:                 episode reward: 12.6500,                 loss: 3.5465
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1620.95,                last time consumption/overall running time: 310.2006s / 75781.4994 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1620
env0_second_0:                 episode reward: 13.4000,                 loss: 0.8962
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1771.6,                last time consumption/overall running time: 336.6360s / 76118.1355 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.3057
env0_second_0:                 episode reward: 7.2000,                 loss: 0.6419
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1765.85,                last time consumption/overall running time: 332.3385s / 76450.4739 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.3148
env0_second_0:                 episode reward: 9.9000,                 loss: 0.6381
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1660.75,                last time consumption/overall running time: 314.5854s / 76765.0593 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.2885
env0_second_0:                 episode reward: 10.4000,                 loss: 0.7520
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1636.6,                last time consumption/overall running time: 310.1028s / 77075.1622 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1742
env0_second_0:                 episode reward: 13.1000,                 loss: 0.4268
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1626.05,                last time consumption/overall running time: 304.2117s / 77379.3739 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.2074
env0_second_0:                 episode reward: 10.6500,                 loss: 0.4921
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1679.65,                last time consumption/overall running time: 315.6689s / 77695.0428 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.1520
env0_second_0:                 episode reward: 12.1500,                 loss: 0.4782
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1598.55,                last time consumption/overall running time: 303.3888s / 77998.4316 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.1736
env0_second_0:                 episode reward: 14.8000,                 loss: 0.4352
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1683.75,                last time consumption/overall running time: 315.7929s / 78314.2245 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1440
env0_second_0:                 episode reward: 14.6000,                 loss: 0.3325
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1768.7,                last time consumption/overall running time: 332.5523s / 78646.7767 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.1157
env0_second_0:                 episode reward: 14.3500,                 loss: 0.7893
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1732.2,                last time consumption/overall running time: 322.7333s / 78969.5101 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1320
env0_second_0:                 episode reward: 12.8500,                 loss: 1.0035
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1773.3,                last time consumption/overall running time: 334.4474s / 79303.9575 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0703
env0_second_0:                 episode reward: 12.6000,                 loss: 0.2844
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2048.05,                last time consumption/overall running time: 389.0727s / 79693.0302 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.2512
env0_second_0:                 episode reward: 5.8000,                 loss: 0.5597
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1951.8,                last time consumption/overall running time: 370.1506s / 80063.1808 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1427
env0_second_0:                 episode reward: 11.4500,                 loss: 0.2623
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1832.25,                last time consumption/overall running time: 345.1107s / 80408.2915 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1078
env0_second_0:                 episode reward: 13.6500,                 loss: 0.8692
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1863.1,                last time consumption/overall running time: 352.7443s / 80761.0358 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1694
env0_second_0:                 episode reward: 13.5500,                 loss: 1.7645
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1985.45,                last time consumption/overall running time: 377.3915s / 81138.4273 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2002
env0_second_0:                 episode reward: 11.9000,                 loss: 0.9480
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1904.55,                last time consumption/overall running time: 362.8721s / 81501.2994 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1187
env0_second_0:                 episode reward: 12.9500,                 loss: 0.5510
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1877.75,                last time consumption/overall running time: 355.4999s / 81856.7993 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0878
env0_second_0:                 episode reward: 14.8500,                 loss: 0.4429
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1890.15,                last time consumption/overall running time: 358.1010s / 82214.9004 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1351
env0_second_0:                 episode reward: 14.7000,                 loss: 0.2336
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1971.15,                last time consumption/overall running time: 377.3090s / 82592.2093 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1128
env0_second_0:                 episode reward: 13.5000,                 loss: 0.2660
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1864.3,                last time consumption/overall running time: 355.2196s / 82947.4289 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1506
env0_second_0:                 episode reward: 13.8000,                 loss: 0.2628
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1778.55,                last time consumption/overall running time: 337.8614s / 83285.2903 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0777
env0_second_0:                 episode reward: 15.4500,                 loss: 0.1872
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1844.2,                last time consumption/overall running time: 352.4375s / 83637.7278 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0648
env0_second_0:                 episode reward: 16.1500,                 loss: 0.1222
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1535.15,                last time consumption/overall running time: 291.0323s / 83928.7601 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.2382
env0_second_0:                 episode reward: 7.2000,                 loss: 0.4269
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 822.25,                last time consumption/overall running time: 161.5352s / 84090.2953 s
env0_first_0:                 episode reward: 17.8000,                 loss: 0.4877
env0_second_0:                 episode reward: -17.8000,                 loss: 1.7800
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 812.95,                last time consumption/overall running time: 160.6474s / 84250.9427 s
env0_first_0:                 episode reward: 17.8000,                 loss: 0.2659
env0_second_0:                 episode reward: -17.8000,                 loss: 0.8413
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1147.1,                last time consumption/overall running time: 222.4583s / 84473.4009 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.3972
env0_second_0:                 episode reward: -10.0000,                 loss: 0.8869
env1_first_0:                 episode reward: 12.1500,                 loss: nan
env1_second_0:                 episode reward: -12.1500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1632.65,                last time consumption/overall running time: 316.6387s / 84790.0396 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.3090
env0_second_0:                 episode reward: 6.6500,                 loss: 0.4939
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1511.9,                last time consumption/overall running time: 288.4104s / 85078.4501 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1969
env0_second_0:                 episode reward: 13.7500,                 loss: 0.2858
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1440.25,                last time consumption/overall running time: 272.6027s / 85351.0527 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.1460
env0_second_0:                 episode reward: 15.6000,                 loss: 0.2279
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1543.6,                last time consumption/overall running time: 290.2998s / 85641.3525 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1651
env0_second_0:                 episode reward: 14.2000,                 loss: 0.2471
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1525.65,                last time consumption/overall running time: 290.5879s / 85931.9404 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.2046
env0_second_0:                 episode reward: 14.5000,                 loss: 0.2641
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1496.15,                last time consumption/overall running time: 284.4469s / 86216.3872 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.1551
env0_second_0:                 episode reward: 15.0000,                 loss: 0.2091
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1396.65,                last time consumption/overall running time: 263.2485s / 86479.6357 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1770
env0_second_0:                 episode reward: 15.5500,                 loss: 0.2251
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1309.95,                last time consumption/overall running time: 248.9406s / 86728.5763 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.4042
env0_second_0:                 episode reward: 1.7000,                 loss: 0.6541
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1481.0,                last time consumption/overall running time: 279.9049s / 87008.4812 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1823
env0_second_0:                 episode reward: 14.7500,                 loss: 0.2551
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1461.3,                last time consumption/overall running time: 277.6484s / 87286.1296 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1613
env0_second_0:                 episode reward: 15.3000,                 loss: 0.4207
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1452.0,                last time consumption/overall running time: 274.8742s / 87561.0038 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.1230
env0_second_0:                 episode reward: 15.8000,                 loss: 0.1512
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1348.45,                last time consumption/overall running time: 255.3687s / 87816.3725 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0819
env0_second_0:                 episode reward: 15.9500,                 loss: 0.1436
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1474.55,                last time consumption/overall running time: 277.1165s / 88093.4890 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.3391
env0_second_0:                 episode reward: 9.1000,                 loss: 0.4756
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1485.3,                last time consumption/overall running time: 272.4375s / 88365.9265 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.1850
env0_second_0:                 episode reward: 15.0500,                 loss: 0.2571
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1419.7,                last time consumption/overall running time: 258.6855s / 88624.6120 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.1291
env0_second_0:                 episode reward: 16.3500,                 loss: 0.3349
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1399.85,                last time consumption/overall running time: 261.2668s / 88885.8789 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1959
env0_second_0:                 episode reward: 14.9000,                 loss: 0.4684
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1528.2,                last time consumption/overall running time: 284.8724s / 89170.7513 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.3589
env0_second_0:                 episode reward: 13.3000,                 loss: 0.7519
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2032.3,                last time consumption/overall running time: 376.9570s / 89547.7083 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.3286
env0_second_0:                 episode reward: 19.3000,                 loss: 1.0635
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1747.0,                last time consumption/overall running time: 323.7982s / 89871.5065 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1514
env0_second_0:                 episode reward: 14.9000,                 loss: 0.3564
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1905.9,                last time consumption/overall running time: 351.9551s / 90223.4617 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1232
env0_second_0:                 episode reward: 15.2000,                 loss: 0.2342
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2179.35,                last time consumption/overall running time: 398.7152s / 90622.1769 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1995
env0_second_0:                 episode reward: 9.6000,                 loss: 1.9574
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 2114.1,                last time consumption/overall running time: 386.2996s / 91008.4764 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1409
env0_second_0:                 episode reward: 12.6000,                 loss: 1.6345
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 2149.25,                last time consumption/overall running time: 398.0932s / 91406.5696 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1066
env0_second_0:                 episode reward: 11.8500,                 loss: 1.9142
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1595.85,                last time consumption/overall running time: 299.7791s / 91706.3487 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.2694
env0_second_0:                 episode reward: 6.2500,                 loss: 3.9033
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 877.95,                last time consumption/overall running time: 168.2795s / 91874.6282 s
env0_first_0:                 episode reward: 6.6500,                 loss: 0.3524
env0_second_0:                 episode reward: -6.6500,                 loss: 4.2500
env1_first_0:                 episode reward: 9.3500,                 loss: nan
env1_second_0:                 episode reward: -9.3500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 894.05,                last time consumption/overall running time: 172.2852s / 92046.9134 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.5030
env0_second_0:                 episode reward: 14.3500,                 loss: 2.1078
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 929.65,                last time consumption/overall running time: 175.6783s / 92222.5917 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.3827
env0_second_0:                 episode reward: 14.7000,                 loss: 5.3563
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 960.9,                last time consumption/overall running time: 178.9708s / 92401.5625 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.4206
env0_second_0:                 episode reward: 10.7500,                 loss: 2.4096
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 811.95,                last time consumption/overall running time: 157.3862s / 92558.9487 s
env0_first_0:                 episode reward: 14.4500,                 loss: 0.3180
env0_second_0:                 episode reward: -14.4500,                 loss: 1.6113
env1_first_0:                 episode reward: 13.9000,                 loss: nan
env1_second_0:                 episode reward: -13.9000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1350.95,                last time consumption/overall running time: 250.8503s / 92809.7990 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.6826
env0_second_0:                 episode reward: -3.0500,                 loss: 3.0073
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1834.0,                last time consumption/overall running time: 342.0471s / 93151.8461 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.3977
env0_second_0:                 episode reward: -5.6500,                 loss: 0.9913
env1_first_0:                 episode reward: 6.6000,                 loss: nan
env1_second_0:                 episode reward: -6.6000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1799.35,                last time consumption/overall running time: 337.1244s / 93488.9705 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.4037
env0_second_0:                 episode reward: -5.7500,                 loss: 0.7726
env1_first_0:                 episode reward: 8.1000,                 loss: nan
env1_second_0:                 episode reward: -8.1000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 2071.45,                last time consumption/overall running time: 392.2539s / 93881.2243 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.3372
env0_second_0:                 episode reward: -2.4500,                 loss: 0.5646
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 2191.4,                last time consumption/overall running time: 414.7976s / 94296.0219 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.2997
env0_second_0:                 episode reward: 2.2500,                 loss: 0.3912
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 2379.05,                last time consumption/overall running time: 442.2010s / 94738.2229 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.2389
env0_second_0:                 episode reward: 7.8000,                 loss: 0.2918
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 2290.9,                last time consumption/overall running time: 419.8506s / 95158.0734 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.1954
env0_second_0:                 episode reward: 8.2000,                 loss: 0.2423
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2292.35,                last time consumption/overall running time: 414.6066s / 95572.6800 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.1850
env0_second_0:                 episode reward: 8.9500,                 loss: 0.2272
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2196.2,                last time consumption/overall running time: 397.3050s / 95969.9850 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.1986
env0_second_0:                 episode reward: 9.5500,                 loss: 0.2728
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2152.75,                last time consumption/overall running time: 388.7249s / 96358.7099 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.2220
env0_second_0:                 episode reward: 10.4500,                 loss: 0.4165
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2041.15,                last time consumption/overall running time: 369.4483s / 96728.1582 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1709
env0_second_0:                 episode reward: 13.8000,                 loss: 0.2218
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 2154.7,                last time consumption/overall running time: 388.8135s / 97116.9718 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1883
env0_second_0:                 episode reward: 13.6500,                 loss: 0.3656
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 823.7,                last time consumption/overall running time: 157.7352s / 97274.7070 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.3429
env0_second_0:                 episode reward: 15.6000,                 loss: 1.0447
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 753.65,                last time consumption/overall running time: 143.7539s / 97418.4609 s
env0_first_0:                 episode reward: -20.4000,                 loss: 0.0412
env0_second_0:                 episode reward: 20.4000,                 loss: 0.3903
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 745.65,                last time consumption/overall running time: 142.0683s / 97560.5292 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2860
env0_second_0:                 episode reward: -0.3500,                 loss: 0.8155
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 728.0,                last time consumption/overall running time: 142.3523s / 97702.8815 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1127
env0_second_0:                 episode reward: -21.0000,                 loss: 0.9206
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 776.0,                last time consumption/overall running time: 149.3799s / 97852.2614 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.3928
env0_second_0:                 episode reward: 4.5000,                 loss: 1.1852
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 764.75,                last time consumption/overall running time: 145.1202s / 97997.3816 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1206
env0_second_0:                 episode reward: 20.1000,                 loss: 0.5662
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 954.9,                last time consumption/overall running time: 180.8491s / 98178.2308 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.2737
env0_second_0:                 episode reward: 16.1000,                 loss: 0.9935
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 875.4,                last time consumption/overall running time: 167.4885s / 98345.7192 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.1693
env0_second_0:                 episode reward: 18.9500,                 loss: 1.4907
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 799.7,                last time consumption/overall running time: 153.6359s / 98499.3552 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.2466
env0_second_0:                 episode reward: 16.0000,                 loss: 1.8759
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 748.2,                last time consumption/overall running time: 144.6777s / 98644.0329 s
env0_first_0:                 episode reward: 7.9500,                 loss: 0.3191
env0_second_0:                 episode reward: -7.9500,                 loss: 2.7489
env1_first_0:                 episode reward: 6.6000,                 loss: nan
env1_second_0:                 episode reward: -6.6000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 728.0,                last time consumption/overall running time: 142.9938s / 98787.0267 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.1778
env0_second_0:                 episode reward: -19.7000,                 loss: 1.2719
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 728.05,                last time consumption/overall running time: 142.4545s / 98929.4813 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.1054
env0_second_0:                 episode reward: -20.9000,                 loss: 0.4182
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 728.0,                last time consumption/overall running time: 142.3349s / 99071.8161 s
env0_first_0:                 episode reward: 18.7000,                 loss: 0.0942
env0_second_0:                 episode reward: -18.7000,                 loss: 0.4199
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 743.45,                last time consumption/overall running time: 145.7580s / 99217.5741 s
env0_first_0:                 episode reward: 5.0000,                 loss: 0.2064
env0_second_0:                 episode reward: -5.0000,                 loss: 0.4831
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 752.6,                last time consumption/overall running time: 146.4684s / 99364.0425 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.1614
env0_second_0:                 episode reward: 8.1500,                 loss: 0.3995
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 759.7,                last time consumption/overall running time: 147.7312s / 99511.7738 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 20.8000,                 loss: 0.1692
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 765.1,                last time consumption/overall running time: 149.2224s / 99660.9962 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.1507
env0_second_0:                 episode reward: 18.4000,                 loss: 0.3801
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 751.6,                last time consumption/overall running time: 147.5185s / 99808.5147 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0847
env0_second_0:                 episode reward: 7.9000,                 loss: 0.5175
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 728.5,                last time consumption/overall running time: 142.4415s / 99950.9562 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0095
env0_second_0:                 episode reward: -20.8500,                 loss: 0.5087
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 728.05,                last time consumption/overall running time: 140.8876s / 100091.8437 s
env0_first_0:                 episode reward: 20.9000,                 loss: -0.0434
env0_second_0:                 episode reward: -20.9000,                 loss: -0.0383
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 806.5,                last time consumption/overall running time: 156.9191s / 100248.7628 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.3281
env0_second_0:                 episode reward: 10.4000,                 loss: 0.5702
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 854.0,                last time consumption/overall running time: 165.4393s / 100414.2021 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.3563
env0_second_0:                 episode reward: 16.3500,                 loss: 0.9967
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1508.15,                last time consumption/overall running time: 283.9483s / 100698.1504 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.5600
env0_second_0:                 episode reward: 6.1500,                 loss: 2.1878
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1758.65,                last time consumption/overall running time: 333.3774s / 101031.5277 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.4438
env0_second_0:                 episode reward: 6.0000,                 loss: 0.6101
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 2062.25,                last time consumption/overall running time: 391.1816s / 101422.7093 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.2818
env0_second_0:                 episode reward: 8.6500,                 loss: 0.3822
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 2199.1,                last time consumption/overall running time: 414.0683s / 101836.7776 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.2250
env0_second_0:                 episode reward: 8.7500,                 loss: 0.3090
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 2111.85,                last time consumption/overall running time: 391.9642s / 102228.7418 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1793
env0_second_0:                 episode reward: 10.6000,                 loss: 0.3871
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 2126.6,                last time consumption/overall running time: 395.4654s / 102624.2072 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.1814
env0_second_0:                 episode reward: 9.8500,                 loss: 0.3728
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 2285.5,                last time consumption/overall running time: 425.0998s / 103049.3070 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.1921
env0_second_0:                 episode reward: 10.3500,                 loss: 0.3389
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 2310.85,                last time consumption/overall running time: 423.5560s / 103472.8629 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.2117
env0_second_0:                 episode reward: 8.8000,                 loss: 0.3893
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 2266.4,                last time consumption/overall running time: 417.7750s / 103890.6379 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.1804
env0_second_0:                 episode reward: 11.4000,                 loss: 0.3686
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2225.95,                last time consumption/overall running time: 412.0877s / 104302.7256 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1724
env0_second_0:                 episode reward: 12.0000,                 loss: 0.4189
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 2190.15,                last time consumption/overall running time: 404.2464s / 104706.9720 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1371
env0_second_0:                 episode reward: 13.1500,                 loss: 0.4510
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2242.6,                last time consumption/overall running time: 375.2791s / 105082.2511 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1722
env0_second_0:                 episode reward: 12.0000,                 loss: 0.3850
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1823.45,                last time consumption/overall running time: 308.1372s / 105390.3883 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.3732
env0_second_0:                 episode reward: 7.5500,                 loss: 1.0376
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 2091.5,                last time consumption/overall running time: 347.0785s / 105737.4668 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.3273
env0_second_0:                 episode reward: 6.1500,                 loss: 0.9129
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2224.0,                last time consumption/overall running time: 379.1512s / 106116.6180 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1547
env0_second_0:                 episode reward: 13.7500,                 loss: 0.4505
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 2159.75,                last time consumption/overall running time: 367.8464s / 106484.4644 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1447
env0_second_0:                 episode reward: 13.3500,                 loss: 0.4659
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 2028.05,                last time consumption/overall running time: 343.5320s / 106827.9965 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1444
env0_second_0:                 episode reward: 14.1000,                 loss: 0.7554
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2165.05,                last time consumption/overall running time: 367.0612s / 107195.0576 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1807
env0_second_0:                 episode reward: 14.6000,                 loss: 0.5555
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 2142.55,                last time consumption/overall running time: 369.9136s / 107564.9712 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.1518
env0_second_0:                 episode reward: 13.9000,                 loss: 0.4662
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 2103.4,                last time consumption/overall running time: 365.6363s / 107930.6075 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.2106
env0_second_0:                 episode reward: 15.1500,                 loss: 0.6336
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 2140.95,                last time consumption/overall running time: 368.6758s / 108299.2833 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1791
env0_second_0:                 episode reward: 13.5500,                 loss: 0.4890
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 2192.5,                last time consumption/overall running time: 370.1196s / 108669.4029 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1390
env0_second_0:                 episode reward: 13.6500,                 loss: 0.3778
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 2170.3,                last time consumption/overall running time: 353.3971s / 109022.8000 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1152
env0_second_0:                 episode reward: 15.4500,                 loss: 0.4201
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 2160.15,                last time consumption/overall running time: 350.7811s / 109373.5811 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.1136
env0_second_0:                 episode reward: 14.8500,                 loss: 0.4134
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2256.55,                last time consumption/overall running time: 365.1237s / 109738.7048 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1613
env0_second_0:                 episode reward: 12.9000,                 loss: 0.4055
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 2185.6,                last time consumption/overall running time: 354.9148s / 110093.6196 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1327
env0_second_0:                 episode reward: 13.5000,                 loss: 0.4156
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1848.85,                last time consumption/overall running time: 303.6065s / 110397.2261 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.2655
env0_second_0:                 episode reward: 11.2000,                 loss: 0.5299
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2270.3,                last time consumption/overall running time: 371.6263s / 110768.8523 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.1863
env0_second_0:                 episode reward: 10.2000,                 loss: 0.4137
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 966.95,                last time consumption/overall running time: 166.4563s / 110935.3086 s
env0_first_0:                 episode reward: 15.5000,                 loss: 0.3164
env0_second_0:                 episode reward: -15.5000,                 loss: 1.2482
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1857.6,                last time consumption/overall running time: 305.3115s / 111240.6202 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4111
env0_second_0:                 episode reward: -3.5500,                 loss: 0.9378
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 2565.8,                last time consumption/overall running time: 422.3144s / 111662.9346 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.1493
env0_second_0:                 episode reward: 7.9000,                 loss: 0.9503
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 2486.3,                last time consumption/overall running time: 411.1207s / 112074.0553 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.1374
env0_second_0:                 episode reward: 10.4500,                 loss: 0.3862
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 2463.45,                last time consumption/overall running time: 402.0385s / 112476.0938 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1276
env0_second_0:                 episode reward: 11.6000,                 loss: 0.3544
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 2352.5,                last time consumption/overall running time: 380.5490s / 112856.6427 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1278
env0_second_0:                 episode reward: 13.1000,                 loss: 0.3461
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 2388.55,                last time consumption/overall running time: 385.3715s / 113242.0142 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1292
env0_second_0:                 episode reward: 11.4500,                 loss: 0.3467
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2345.45,                last time consumption/overall running time: 393.2482s / 113635.2624 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1311
env0_second_0:                 episode reward: 12.6000,                 loss: 0.3924
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 2243.1,                last time consumption/overall running time: 386.2372s / 114021.4996 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1406
env0_second_0:                 episode reward: 12.8000,                 loss: 0.4564
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 2043.75,                last time consumption/overall running time: 346.4782s / 114367.9777 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.2486
env0_second_0:                 episode reward: 14.8500,                 loss: 0.6033
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2202.4,                last time consumption/overall running time: 374.9333s / 114742.9111 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4049
env0_second_0:                 episode reward: -3.5500,                 loss: 1.1132
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 2241.4,                last time consumption/overall running time: 377.2557s / 115120.1668 s
env0_first_0:                 episode reward: 7.5500,                 loss: 0.2045
env0_second_0:                 episode reward: -7.5500,                 loss: 0.7798
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 2710.4,                last time consumption/overall running time: 452.1012s / 115572.2679 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.1917
env0_second_0:                 episode reward: 1.9000,                 loss: 0.4810
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 2367.1,                last time consumption/overall running time: 395.9231s / 115968.1911 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1410
env0_second_0:                 episode reward: 10.8500,                 loss: 0.3838
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 2547.2,                last time consumption/overall running time: 425.6816s / 116393.8727 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.1090
env0_second_0:                 episode reward: 10.0000,                 loss: 0.2833
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 2198.8,                last time consumption/overall running time: 363.3788s / 116757.2515 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0993
env0_second_0:                 episode reward: 11.6500,                 loss: 0.3471
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1451.7,                last time consumption/overall running time: 244.2187s / 117001.4702 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.3913
env0_second_0:                 episode reward: 12.2500,                 loss: 1.1628
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1493.7,                last time consumption/overall running time: 255.1954s / 117256.6657 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.3628
env0_second_0:                 episode reward: 14.1000,                 loss: 0.8724
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1321.7,                last time consumption/overall running time: 223.3467s / 117480.0123 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.2198
env0_second_0:                 episode reward: 16.5500,                 loss: 0.4888
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1345.9,                last time consumption/overall running time: 229.7648s / 117709.7771 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.1828
env0_second_0:                 episode reward: 15.2500,                 loss: 0.3608
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1495.0,                last time consumption/overall running time: 254.3237s / 117964.1008 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.3501
env0_second_0:                 episode reward: 13.1000,                 loss: 0.6381
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 728.05,                last time consumption/overall running time: 127.1837s / 118091.2845 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.2031
env0_second_0:                 episode reward: -20.9500,                 loss: 0.6290
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 844.35,                last time consumption/overall running time: 144.4457s / 118235.7302 s
env0_first_0:                 episode reward: 9.8000,                 loss: 0.4553
env0_second_0:                 episode reward: -9.8000,                 loss: 0.5803
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1228.2,                last time consumption/overall running time: 205.7887s / 118441.5189 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.6026
env0_second_0:                 episode reward: 6.6500,                 loss: 1.0892
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1405.1,                last time consumption/overall running time: 230.4035s / 118671.9224 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.3270
env0_second_0:                 episode reward: 13.5000,                 loss: 0.6453
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1293.95,                last time consumption/overall running time: 216.8300s / 118888.7524 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.3401
env0_second_0:                 episode reward: 11.6500,                 loss: 0.7093
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1304.05,                last time consumption/overall running time: 218.5448s / 119107.2971 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.4576
env0_second_0:                 episode reward: 9.8000,                 loss: 0.8320
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 947.35,                last time consumption/overall running time: 161.5432s / 119268.8404 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.2425
env0_second_0:                 episode reward: 17.0000,                 loss: 0.7034
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 737.9,                last time consumption/overall running time: 125.0334s / 119393.8738 s
env0_first_0:                 episode reward: 14.5500,                 loss: 0.2394
env0_second_0:                 episode reward: -14.5500,                 loss: 2.1018
env1_first_0:                 episode reward: 14.6500,                 loss: nan
env1_second_0:                 episode reward: -14.6500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 728.8,                last time consumption/overall running time: 126.7491s / 119520.6229 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.1059
env0_second_0:                 episode reward: -20.5000,                 loss: 1.2275
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 731.45,                last time consumption/overall running time: 127.7568s / 119648.3797 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0645
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4301
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 730.95,                last time consumption/overall running time: 128.5987s / 119776.9784 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0766
env0_second_0:                 episode reward: -20.5000,                 loss: 0.4739
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 732.3,                last time consumption/overall running time: 128.8249s / 119905.8033 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0494
env0_second_0:                 episode reward: -20.8000,                 loss: 0.1902
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 729.45,                last time consumption/overall running time: 130.2564s / 120036.0597 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0322
env0_second_0:                 episode reward: -20.5500,                 loss: 0.1164
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 729.3,                last time consumption/overall running time: 128.8366s / 120164.8963 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0339
env0_second_0:                 episode reward: -20.7000,                 loss: 0.0777
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 734.65,                last time consumption/overall running time: 129.5109s / 120294.4072 s
env0_first_0:                 episode reward: 18.9500,                 loss: 0.0718
env0_second_0:                 episode reward: -18.9500,                 loss: 0.2273
env1_first_0:                 episode reward: 18.7000,                 loss: nan
env1_second_0:                 episode reward: -18.7000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 728.5,                last time consumption/overall running time: 128.9395s / 120423.3467 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0117
env0_second_0:                 episode reward: -20.6500,                 loss: 0.0866
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 728.5,                last time consumption/overall running time: 129.5200s / 120552.8667 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0114
env0_second_0:                 episode reward: -20.8000,                 loss: 0.0669
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 730.05,                last time consumption/overall running time: 128.7847s / 120681.6514 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0416
env0_second_0:                 episode reward: -20.7500,                 loss: 0.1259
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 729.45,                last time consumption/overall running time: 128.3746s / 120810.0260 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0194
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2112
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 728.3,                last time consumption/overall running time: 129.6370s / 120939.6629 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0599
env0_second_0:                 episode reward: -20.7000,                 loss: 0.1727
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 728.1,                last time consumption/overall running time: 132.3126s / 121071.9755 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0412
env0_second_0:                 episode reward: -20.7500,                 loss: 0.2044
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 728.0,                last time consumption/overall running time: 133.6503s / 121205.6259 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0150
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0772
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 728.05,                last time consumption/overall running time: 131.4651s / 121337.0910 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0053
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1533
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 728.25,                last time consumption/overall running time: 130.5655s / 121467.6565 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0312
env0_second_0:                 episode reward: -20.8000,                 loss: 0.2198
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 728.2,                last time consumption/overall running time: 130.7814s / 121598.4379 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0210
env0_second_0:                 episode reward: -20.8000,                 loss: 0.1846
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 728.15,                last time consumption/overall running time: 131.3360s / 121729.7739 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0257
env0_second_0:                 episode reward: -20.9000,                 loss: 0.1429
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 728.05,                last time consumption/overall running time: 134.3279s / 121864.1018 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0354
env0_second_0:                 episode reward: -20.9000,                 loss: 0.1439
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 728.0,                last time consumption/overall running time: 130.9179s / 121995.0197 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0411
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1295
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 728.0,                last time consumption/overall running time: 131.4107s / 122126.4304 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0389
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1201
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 728.0,                last time consumption/overall running time: 129.4088s / 122255.8392 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0380
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0991
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 728.0,                last time consumption/overall running time: 131.7935s / 122387.6327 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0335
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1185
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 728.0,                last time consumption/overall running time: 131.2832s / 122518.9160 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0276
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1336
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 728.0,                last time consumption/overall running time: 129.8280s / 122648.7440 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0403
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1071
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 728.0,                last time consumption/overall running time: 132.7100s / 122781.4540 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0423
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1241
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 728.0,                last time consumption/overall running time: 130.0587s / 122911.5127 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0486
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0888
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 728.0,                last time consumption/overall running time: 129.3659s / 123040.8786 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0364
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0447
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 728.0,                last time consumption/overall running time: 129.6295s / 123170.5081 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0268
env0_second_0:                 episode reward: -21.0000,                 loss: 0.0371
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 728.0,                last time consumption/overall running time: 128.8828s / 123299.3910 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0286
env0_second_0:                 episode reward: -20.8000,                 loss: 0.0552
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 728.0,                last time consumption/overall running time: 128.1117s / 123427.5026 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0260
env0_second_0:                 episode reward: -20.8500,                 loss: -0.0014
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 728.0,                last time consumption/overall running time: 125.7655s / 123553.2682 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0208
env0_second_0:                 episode reward: -20.8500,                 loss: 0.0859
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 728.0,                last time consumption/overall running time: 125.0497s / 123678.3178 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0363
env0_second_0:                 episode reward: -20.8500,                 loss: 0.0612
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 728.0,                last time consumption/overall running time: 126.4112s / 123804.7290 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0265
env0_second_0:                 episode reward: -20.9000,                 loss: 0.2143
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 733.2,                last time consumption/overall running time: 127.4484s / 123932.1775 s
env0_first_0:                 episode reward: 18.9500,                 loss: 0.0973
env0_second_0:                 episode reward: -18.9500,                 loss: 1.0593
env1_first_0:                 episode reward: 19.3500,                 loss: nan
env1_second_0:                 episode reward: -19.3500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 829.0,                last time consumption/overall running time: 144.1769s / 124076.3543 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.3849
env0_second_0:                 episode reward: 11.4000,                 loss: 1.6354
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 829.1,                last time consumption/overall running time: 141.9124s / 124218.2667 s
env0_first_0:                 episode reward: -18.1000,                 loss: 0.1879
env0_second_0:                 episode reward: 18.1000,                 loss: 0.8975
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 818.4,                last time consumption/overall running time: 143.5038s / 124361.7706 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2157
env0_second_0:                 episode reward: 1.3500,                 loss: 0.8200
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 839.4,                last time consumption/overall running time: 144.0917s / 124505.8622 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.2264
env0_second_0:                 episode reward: 9.4000,                 loss: 0.9698
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 851.45,                last time consumption/overall running time: 146.7687s / 124652.6310 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.1068
env0_second_0:                 episode reward: 16.9500,                 loss: 0.9000
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 868.5,                last time consumption/overall running time: 150.2039s / 124802.8349 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.2226
env0_second_0:                 episode reward: 15.1000,                 loss: 1.3421
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 823.75,                last time consumption/overall running time: 143.1801s / 124946.0150 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.1213
env0_second_0:                 episode reward: 18.3500,                 loss: 0.6068
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 813.55,                last time consumption/overall running time: 139.5498s / 125085.5648 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0690
env0_second_0:                 episode reward: 17.8500,                 loss: 0.7338
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 862.85,                last time consumption/overall running time: 148.7342s / 125234.2990 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.3162
env0_second_0:                 episode reward: 12.9000,                 loss: 1.2347
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 833.3,                last time consumption/overall running time: 142.5979s / 125376.8969 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.2615
env0_second_0:                 episode reward: 16.2000,                 loss: 0.9389
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 817.0,                last time consumption/overall running time: 140.6200s / 125517.5169 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1687
env0_second_0:                 episode reward: 15.2000,                 loss: 0.6288
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 830.9,                last time consumption/overall running time: 144.7963s / 125662.3131 s
env0_first_0:                 episode reward: -17.8000,                 loss: 0.1269
env0_second_0:                 episode reward: 17.8000,                 loss: 0.7181
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 823.4,                last time consumption/overall running time: 144.8831s / 125807.1962 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.0588
env0_second_0:                 episode reward: 17.0500,                 loss: 1.9365
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 826.7,                last time consumption/overall running time: 147.7894s / 125954.9856 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0422
env0_second_0:                 episode reward: 17.0000,                 loss: 0.4521
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 814.75,                last time consumption/overall running time: 139.0617s / 126094.0474 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.1210
env0_second_0:                 episode reward: 18.0000,                 loss: 0.6066
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 814.0,                last time consumption/overall running time: 142.1170s / 126236.1643 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.1018
env0_second_0:                 episode reward: 16.5000,                 loss: 1.4852
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 865.95,                last time consumption/overall running time: 151.0705s / 126387.2348 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.3912
env0_second_0:                 episode reward: -6.0000,                 loss: 1.5680
env1_first_0:                 episode reward: 8.8000,                 loss: nan
env1_second_0:                 episode reward: -8.8000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 738.4,                last time consumption/overall running time: 131.3603s / 126518.5951 s
env0_first_0:                 episode reward: 18.2500,                 loss: 0.1911
env0_second_0:                 episode reward: -18.2500,                 loss: 0.6809
env1_first_0:                 episode reward: 19.3500,                 loss: nan
env1_second_0:                 episode reward: -19.3500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 728.75,                last time consumption/overall running time: 129.1892s / 126647.7843 s
env0_first_0:                 episode reward: 18.8500,                 loss: 0.0954
env0_second_0:                 episode reward: -18.8500,                 loss: 1.5399
env1_first_0:                 episode reward: 19.1000,                 loss: nan
env1_second_0:                 episode reward: -19.1000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 748.45,                last time consumption/overall running time: 131.4963s / 126779.2806 s
env0_first_0:                 episode reward: 15.0500,                 loss: 0.1547
env0_second_0:                 episode reward: -15.0500,                 loss: 0.8717
env1_first_0:                 episode reward: 13.4000,                 loss: nan
env1_second_0:                 episode reward: -13.4000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 731.45,                last time consumption/overall running time: 130.1871s / 126909.4677 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.0418
env0_second_0:                 episode reward: -20.3000,                 loss: 0.9204
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 761.75,                last time consumption/overall running time: 135.1784s / 127044.6461 s
env0_first_0:                 episode reward: 9.4000,                 loss: 0.1804
env0_second_0:                 episode reward: -9.4000,                 loss: 0.8398
env1_first_0:                 episode reward: 9.3000,                 loss: nan
env1_second_0:                 episode reward: -9.3000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 851.25,                last time consumption/overall running time: 148.8813s / 127193.5274 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.2600
env0_second_0:                 episode reward: 15.4500,                 loss: 0.5890
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 771.55,                last time consumption/overall running time: 131.5897s / 127325.1171 s
env0_first_0:                 episode reward: 10.5000,                 loss: 0.3620
env0_second_0:                 episode reward: -10.5000,                 loss: 1.4602
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 728.4,                last time consumption/overall running time: 126.3114s / 127451.4285 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0540
env0_second_0:                 episode reward: -20.7000,                 loss: 1.3618
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 783.95,                last time consumption/overall running time: 137.7227s / 127589.1512 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.1764
env0_second_0:                 episode reward: 6.2000,                 loss: 0.8686
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 823.7,                last time consumption/overall running time: 147.3478s / 127736.4990 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.1030
env0_second_0:                 episode reward: 18.3500,                 loss: 0.9417
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 804.0,                last time consumption/overall running time: 137.9426s / 127874.4416 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0502
env0_second_0:                 episode reward: 17.4500,                 loss: 0.6387
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 809.15,                last time consumption/overall running time: 144.0624s / 128018.5041 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0645
env0_second_0:                 episode reward: 19.3000,                 loss: 0.5967
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 792.75,                last time consumption/overall running time: 139.5028s / 128158.0069 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0097
env0_second_0:                 episode reward: 17.8500,                 loss: 0.6269
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 783.6,                last time consumption/overall running time: 134.3322s / 128292.3391 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1101
env0_second_0:                 episode reward: 15.5500,                 loss: 0.4415
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 816.55,                last time consumption/overall running time: 139.3365s / 128431.6755 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.1522
env0_second_0:                 episode reward: 14.8500,                 loss: 1.3304
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 802.25,                last time consumption/overall running time: 141.6115s / 128573.2870 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.3097
env0_second_0:                 episode reward: 14.9000,                 loss: 0.9674
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 2382.45,                last time consumption/overall running time: 392.7782s / 128966.0652 s
env0_first_0:                 episode reward: -64.1000,                 loss: 0.4699
env0_second_0:                 episode reward: 64.1000,                 loss: 2.2063
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 9572.95,                last time consumption/overall running time: 1546.5295s / 130512.5947 s
env0_first_0:                 episode reward: -306.9500,                 loss: 0.6516
env0_second_0:                 episode reward: 306.9500,                 loss: 1.4134
env1_first_0:                 episode reward: -306.3000,                 loss: nan
env1_second_0:                 episode reward: 306.3000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 9580.2,                last time consumption/overall running time: 1549.3117s / 132061.9064 s
env0_first_0:                 episode reward: -304.5000,                 loss: 0.6413
env0_second_0:                 episode reward: 304.5000,                 loss: 0.8129
env1_first_0:                 episode reward: -304.8000,                 loss: nan
env1_second_0:                 episode reward: 304.8000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3496.85,                last time consumption/overall running time: 570.6212s / 132632.5276 s
env0_first_0:                 episode reward: -79.7500,                 loss: 0.4288
env0_second_0:                 episode reward: 79.7500,                 loss: 2.1313
env1_first_0:                 episode reward: -79.5500,                 loss: nan
env1_second_0:                 episode reward: 79.5500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1914.3,                last time consumption/overall running time: 313.6554s / 132946.1830 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.4009
env0_second_0:                 episode reward: 2.9000,                 loss: 3.0775
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 2037.75,                last time consumption/overall running time: 337.5066s / 133283.6895 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.2404
env0_second_0:                 episode reward: 6.9500,                 loss: 1.6800
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 2282.35,                last time consumption/overall running time: 371.9091s / 133655.5986 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.1779
env0_second_0:                 episode reward: 9.2000,                 loss: 0.9465
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 2186.55,                last time consumption/overall running time: 361.6140s / 134017.2126 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.1841
env0_second_0:                 episode reward: 10.1000,                 loss: 1.1919
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 2075.9,                last time consumption/overall running time: 344.3502s / 134361.5628 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1569
env0_second_0:                 episode reward: 13.1500,                 loss: 0.9552
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 2031.8,                last time consumption/overall running time: 336.1613s / 134697.7241 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.1387
env0_second_0:                 episode reward: 11.0500,                 loss: 0.8943
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 2096.55,                last time consumption/overall running time: 344.7557s / 135042.4798 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1126
env0_second_0:                 episode reward: 14.6500,                 loss: 1.4498
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 2043.2,                last time consumption/overall running time: 338.5676s / 135381.0474 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1136
env0_second_0:                 episode reward: 13.8000,                 loss: 0.8302
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 2144.45,                last time consumption/overall running time: 356.4177s / 135737.4651 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0879
env0_second_0:                 episode reward: 14.9500,                 loss: 1.0764
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 2223.5,                last time consumption/overall running time: 370.3533s / 136107.8184 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0699
env0_second_0:                 episode reward: 14.5000,                 loss: 0.7316
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 2232.5,                last time consumption/overall running time: 378.5723s / 136486.3908 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.1256
env0_second_0:                 episode reward: 10.9000,                 loss: 0.7746
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 2166.05,                last time consumption/overall running time: 366.7159s / 136853.1066 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0322
env0_second_0:                 episode reward: 15.9000,                 loss: 0.8737
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 2048.8,                last time consumption/overall running time: 346.7691s / 137199.8757 s
env0_first_0:                 episode reward: -17.1500,                 loss: -0.0009
env0_second_0:                 episode reward: 17.1500,                 loss: 2.1105
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 2192.2,                last time consumption/overall running time: 372.2541s / 137572.1298 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0161
env0_second_0:                 episode reward: 15.1500,                 loss: 1.4749
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 2073.3,                last time consumption/overall running time: 354.0608s / 137926.1906 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0421
env0_second_0:                 episode reward: 14.9000,                 loss: 1.2012
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 2227.45,                last time consumption/overall running time: 373.6189s / 138299.8095 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0001
env0_second_0:                 episode reward: 15.2000,                 loss: 5.9698
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 2270.25,                last time consumption/overall running time: 379.1610s / 138678.9705 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.0385
env0_second_0:                 episode reward: 14.8000,                 loss: 5.8719
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 2272.1,                last time consumption/overall running time: 382.2818s / 139061.2523 s
env0_first_0:                 episode reward: -14.4500,                 loss: -0.0008
env0_second_0:                 episode reward: 14.4500,                 loss: 1.1915
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 2244.1,                last time consumption/overall running time: 375.3933s / 139436.6456 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0211
env0_second_0:                 episode reward: 15.2000,                 loss: 0.8103
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 2143.15,                last time consumption/overall running time: 360.6117s / 139797.2573 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0185
env0_second_0:                 episode reward: 16.8500,                 loss: 0.6815
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 2161.7,                last time consumption/overall running time: 363.7186s / 140160.9759 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0053
env0_second_0:                 episode reward: 16.7000,                 loss: 0.6507
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1101.85,                last time consumption/overall running time: 188.4786s / 140349.4545 s
env0_first_0:                 episode reward: -17.9500,                 loss: 0.1847
env0_second_0:                 episode reward: 17.9500,                 loss: 1.3937
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 818.65,                last time consumption/overall running time: 139.9633s / 140489.4178 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.0217
env0_second_0:                 episode reward: 18.7500,                 loss: 1.3948
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 897.7,                last time consumption/overall running time: 154.5708s / 140643.9886 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.3154
env0_second_0:                 episode reward: 11.5000,                 loss: 2.0999
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 917.45,                last time consumption/overall running time: 156.7199s / 140800.7085 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.3613
env0_second_0:                 episode reward: 9.4500,                 loss: 1.8820
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 948.5,                last time consumption/overall running time: 161.4186s / 140962.1271 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.4260
env0_second_0:                 episode reward: 11.7500,                 loss: 2.0804
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 974.5,                last time consumption/overall running time: 167.3981s / 141129.5251 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.5842
env0_second_0:                 episode reward: -3.3500,                 loss: 503.9911
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 855.95,                last time consumption/overall running time: 148.2944s / 141277.8196 s
env0_first_0:                 episode reward: 13.1500,                 loss: 0.5078
env0_second_0:                 episode reward: -13.1500,                 loss: 3.8227
env1_first_0:                 episode reward: 14.2000,                 loss: nan
env1_second_0:                 episode reward: -14.2000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 783.65,                last time consumption/overall running time: 137.2041s / 141415.0236 s
env0_first_0:                 episode reward: 18.8500,                 loss: 0.2594
env0_second_0:                 episode reward: -18.8500,                 loss: 3.1167
env1_first_0:                 episode reward: 17.0500,                 loss: nan
env1_second_0:                 episode reward: -17.0500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 752.05,                last time consumption/overall running time: 130.7626s / 141545.7863 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.1748
env0_second_0:                 episode reward: -20.4500,                 loss: 2.8415
env1_first_0:                 episode reward: 19.9500,                 loss: nan
env1_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 742.2,                last time consumption/overall running time: 127.4437s / 141673.2300 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0585
env0_second_0:                 episode reward: -20.4000,                 loss: 3.9123
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 744.95,                last time consumption/overall running time: 129.6093s / 141802.8393 s
env0_first_0:                 episode reward: 19.8500,                 loss: 0.1379
env0_second_0:                 episode reward: -19.8500,                 loss: 2.4111
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 741.25,                last time consumption/overall running time: 128.2968s / 141931.1361 s
env0_first_0:                 episode reward: 19.5500,                 loss: 0.2584
env0_second_0:                 episode reward: -19.5500,                 loss: 2.9838
env1_first_0:                 episode reward: 19.6000,                 loss: nan
env1_second_0:                 episode reward: -19.6000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 741.0,                last time consumption/overall running time: 125.1150s / 142056.2511 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0235
env0_second_0:                 episode reward: -20.4500,                 loss: 2.7614
env1_first_0:                 episode reward: 20.0500,                 loss: nan
env1_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 739.45,                last time consumption/overall running time: 126.7067s / 142182.9578 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0240
env0_second_0:                 episode reward: -20.6000,                 loss: 4.2654
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 856.25,                last time consumption/overall running time: 143.2093s / 142326.1671 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: 11.9500,                 loss: 0.3320
env0_second_0:                 episode reward: -11.9500,                 loss: 4.0657
env1_first_0:                 episode reward: 9.4000,                 loss: nan
env1_second_0:                 episode reward: -9.4000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 754.35,                last time consumption/overall running time: 130.1348s / 142456.3019 s
env0_first_0:                 episode reward: 16.7500,                 loss: 0.1756
env0_second_0:                 episode reward: -16.7500,                 loss: 3.7939
env1_first_0:                 episode reward: 20.0500,                 loss: nan
env1_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 740.75,                last time consumption/overall running time: 126.8180s / 142583.1199 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0370
env0_second_0:                 episode reward: -20.6500,                 loss: 2.7252
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 3934.4,                last time consumption/overall running time: 634.8670s / 143217.9869 s
env0_first_0:                 episode reward: 11.7000,                 loss: 0.5571
env0_second_0:                 episode reward: -11.7000,                 loss: 4.7080
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1502.5,                last time consumption/overall running time: 246.5648s / 143464.5517 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.2224
env0_second_0:                 episode reward: 15.2500,                 loss: 3.5782
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1370.65,                last time consumption/overall running time: 228.0475s / 143692.5992 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.1415
env0_second_0:                 episode reward: 15.9000,                 loss: 3.1067
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1267.85,                last time consumption/overall running time: 214.0758s / 143906.6750 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1465
env0_second_0:                 episode reward: 14.9000,                 loss: 2.7867
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1323.25,                last time consumption/overall running time: 225.1437s / 144131.8187 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1610
env0_second_0:                 episode reward: 15.5500,                 loss: 2.6199
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1299.3,                last time consumption/overall running time: 221.0098s / 144352.8284 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0980
env0_second_0:                 episode reward: 16.1500,                 loss: 2.9690
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1360.75,                last time consumption/overall running time: 233.3912s / 144586.2197 s
env0_first_0:                 episode reward: -17.5000,                 loss: 0.0718
env0_second_0:                 episode reward: 17.5000,                 loss: 2.3093
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
