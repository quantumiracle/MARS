pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 283
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f2e7609b438>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.071 0.071 0.071 ... 0.071 0.071 0.071]
 [0.071 0.071 0.071 ... 0.071 0.071 0.071]]
Load checkpoints (policy family):  [['41' '765' '1023' ... '4860' '6177' '7662']
 ['242' '786' '1094' ... '4918' '6207' '7695']]
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220429_0152/pettingzoo_tennis_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 7, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152_exploit_first_2/pettingzoo_tennis_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152_exploit_first_2/pettingzoo_tennis_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 9.6696s / 9.6696 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.1347
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3968s / 98.0663 s
first_0:                 episode reward: 2.3500,                 loss: nan
second_0:                 episode reward: -2.3500,                 loss: 0.0889
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.8957s / 186.9620 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0330
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.5911s / 276.5531 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0345
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.2395s / 366.7926 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0339
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.6053s / 457.3979 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0325
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.6837s / 548.0817 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0311
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.2637s / 639.3454 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0300
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.6838s / 731.0292 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0274
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.1204s / 823.1496 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0259
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.1045s / 916.2541 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0245
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.7249s / 1009.9790 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0243
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.9358s / 1103.9148 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0235
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.5383s / 1198.4531 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0227
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 94.8566s / 1293.3097 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0221
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.4353s / 1388.7450 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0217
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 95.9525s / 1484.6975 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0214
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 96.6784s / 1581.3759 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0223
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1301s / 1678.5060 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0220
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3364s / 1775.8424 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0218
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.1712s / 1873.0136 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0204
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.3827s / 1970.3963 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0192
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.4126s / 2067.8089 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0189
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.2855s / 2165.0944 s
first_0:                 episode reward: -2.3000,                 loss: nan
second_0:                 episode reward: 2.3000,                 loss: 0.0187
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.7562s / 2262.8506 s
first_0:                 episode reward: -2.1500,                 loss: nan
second_0:                 episode reward: 2.1500,                 loss: 0.0183
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 97.9253s / 2360.7759 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0181
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.0069s / 2458.7828 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0173
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.2138s / 2556.9966 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0181
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3958s / 2655.3924 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0176
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3241s / 2753.7165 s
first_0:                 episode reward: -2.7500,                 loss: nan
second_0:                 episode reward: 2.7500,                 loss: 0.0171
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.4379s / 2852.1545 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0176
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7004s / 2950.8549 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0174
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0711s / 3049.9260 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0162
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7309s / 3148.6569 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0172
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.7684s / 3247.4253 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0174
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8470s / 3346.2723 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0162
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2290s / 3445.5012 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0161
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.9842s / 3544.4854 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0160
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8279s / 3643.3133 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0163
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.3700s / 3741.6833 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0161
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8914s / 3840.5748 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0155
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.0759s / 3939.6507 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0164
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8631s / 4038.5138 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0163
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2968s / 4137.8106 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0161
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4303s / 4237.2409 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0164
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7967s / 4337.0376 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0159
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6508s / 4436.6883 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0164
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0810s / 4536.7693 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0166
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9270s / 4636.6963 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0170
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9304s / 4736.6267 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0169
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8317s / 4836.4583 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0161
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2933s / 4936.7516 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0151
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7466s / 5036.4982 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0144
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5266s / 5136.0247 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0142
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7265s / 5235.7512 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0145
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3024s / 5335.0536 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0142
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3756s / 5434.4292 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0146
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4672s / 5533.8965 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0146
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8046s / 5633.7011 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0142
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0040s / 5733.7051 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0143
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8609s / 5833.5660 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0144
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5863s / 5933.1523 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0143
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6650s / 6032.8173 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0143
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5725s / 6132.3898 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0142
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8977s / 6232.2875 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0141
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8933s / 6332.1808 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0139
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7210s / 6431.9018 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0136
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3224s / 6531.2242 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0138
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6843s / 6630.9085 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0132
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7375s / 6730.6460 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0133
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5417s / 6830.1877 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0135
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6108s / 6929.7985 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0141
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8529s / 7029.6514 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0136
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1148s / 7129.7661 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0140
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4179s / 7229.1841 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0136
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6199s / 7328.8040 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0143
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6879s / 7428.4920 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0139
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7797s / 7528.2717 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0141
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8833s / 7628.1550 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0138
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1608s / 7728.3158 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0138
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3840s / 7827.6998 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0134
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7215s / 7927.4213 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0140
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7247s / 8027.1460 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0145
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6675s / 8126.8135 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0140
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7294s / 8226.5430 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0144
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5715s / 8326.1145 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0143
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8268s / 8425.9413 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0144
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2861s / 8525.2274 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0139
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 98.8791s / 8624.1065 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0136
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.1596s / 8723.2660 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0138
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6179s / 8822.8840 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0135
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5922s / 8922.4762 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0128
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7917s / 9022.2679 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0127
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8956s / 9122.1635 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0124
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5651s / 9221.7287 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0127
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2402s / 9321.9689 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0125
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2575s / 9422.2264 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0121
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8635s / 9522.0899 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0123
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2622s / 9622.3521 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0125
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9336s / 9722.2857 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0124
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6531s / 9821.9388 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0127
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0445s / 9921.9833 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0132
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1627s / 10022.1460 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0130
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9345s / 10122.0805 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0129
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6362s / 10221.7167 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0131
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8709s / 10321.5876 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0131
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1420s / 10421.7297 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0132
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6688s / 10521.3985 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0130
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8733s / 10621.2718 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0131
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1568s / 10721.4286 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0130
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8477s / 10821.2763 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0129
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8751s / 10921.1515 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0130
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7819s / 11020.9334 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0128
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9269s / 11120.8603 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0128
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0041s / 11220.8644 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0132
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0282s / 11320.8926 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0138
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0236s / 11420.9162 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0129
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2268s / 11521.1429 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0125
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2716s / 11621.4146 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0124
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5678s / 11720.9824 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0122
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9324s / 11820.9148 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0121
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8741s / 11920.7889 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0117
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5101s / 12020.2989 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0119
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8532s / 12120.1521 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0117
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6904s / 12219.8425 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0120
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5961s / 12319.4386 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0119
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7122s / 12419.1508 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0123
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7289s / 12518.8797 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0118
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1610s / 12619.0408 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0122
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0296s / 12719.0704 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0124
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9345s / 12819.0050 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0122
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7030s / 12918.7080 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0120
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0266s / 13018.7345 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0119
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0312s / 13118.7657 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0123
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6305s / 13218.3962 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0123
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9657s / 13318.3618 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0123
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8167s / 13418.1785 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0124
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7178s / 13517.8963 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0124
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9019s / 13617.7982 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0123
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7025s / 13717.5008 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0122
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0745s / 13817.5753 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0125
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7468s / 13917.3221 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0125
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3876s / 14016.7097 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0130
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7223s / 14116.4320 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0129
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5246s / 14215.9566 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0133
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3948s / 14315.3514 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0132
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7332s / 14415.0846 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0133
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.3636s / 14514.4482 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0134
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6247s / 14614.0729 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0135
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8482s / 14713.9211 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0135
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7891s / 14813.7102 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0140
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6629s / 14913.3731 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0136
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5912s / 15012.9644 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0134
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6041s / 15112.5685 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0133
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6432s / 15212.2117 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0134
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0381s / 15312.2498 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0134
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1051s / 15412.3550 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0135
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1096s / 15512.4645 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0128
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2407s / 15612.7053 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0130
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8683s / 15712.5735 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0134
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8100s / 15812.3835 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0131
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9470s / 15912.3305 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0131
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8990s / 16012.2295 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0126
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0459s / 16112.2753 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0126
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9446s / 16212.2199 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0129
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7377s / 16311.9576 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0127
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7392s / 16411.6968 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0124
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7646s / 16511.4614 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0129
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4872s / 16610.9486 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0130
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6609s / 16710.6095 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0129
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1199s / 16810.7294 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0131
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9415s / 16910.6710 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0135
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8899s / 17010.5608 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0131
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7340s / 17110.2948 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0132
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5989s / 17209.8937 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0132
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.2555s / 17309.1492 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0132
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0488s / 17409.1980 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0132
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7198s / 17508.9178 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0127
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9850s / 17608.9028 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0133
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.5689s / 17708.4717 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0139
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7558s / 17808.2275 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0135
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9376s / 17908.1651 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0133
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6921s / 18007.8572 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0135
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8568s / 18107.7140 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0137
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6679s / 18207.3819 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0140
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9686s / 18307.3505 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0140
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3163s / 18407.6669 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0139
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1067s / 18507.7736 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0140
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0655s / 18607.8390 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0137
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7143s / 18707.5533 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0134
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9988s / 18807.5522 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0135
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1400s / 18907.6922 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0133
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0974s / 19007.7896 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0133
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8179s / 19107.6075 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0134
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1617s / 19207.7692 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0136
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2406s / 19308.0098 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0136
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7314s / 19407.7412 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0139
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2092s / 19507.9505 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0137
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6816s / 19607.6321 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0135
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8479s / 19707.4799 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0142
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9071s / 19807.3871 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0143
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6063s / 19906.9934 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0143
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8005s / 20006.7939 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0139
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9629s / 20106.7567 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0139
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6024s / 20206.3592 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0138
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1351s / 20306.4943 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0133
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1802s / 20406.6745 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0135
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.5314s / 20507.2059 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0138
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.4861s / 20607.6920 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0138
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2289s / 20707.9209 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0137
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9499s / 20807.8708 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0142
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2393s / 20908.1101 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0140
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8088s / 21007.9189 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0136
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6796s / 21107.5985 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0137
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8986s / 21207.4971 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0142
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.4926s / 21306.9897 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0140
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.6976s / 21406.6873 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0140
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8057s / 21506.4930 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0147
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8030s / 21606.2960 s
first_0:                 episode reward: -3.4000,                 loss: nan
second_0:                 episode reward: 3.4000,                 loss: 0.0144
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7559s / 21706.0519 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0146
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9246s / 21805.9765 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0147
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0165s / 21905.9930 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0142
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8267s / 22005.8198 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0140
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.3116s / 22106.1313 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0140
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2451s / 22206.3764 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0141
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.2569s / 22306.6333 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0146
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1776s / 22406.8108 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0147
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.7899s / 22506.6008 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0149
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.9577s / 22606.5584 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0149
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8415s / 22706.3999 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0151
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8038s / 22806.2037 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0157
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.0476s / 22906.2514 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0161
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 100.1530s / 23006.4043 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0164
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 99.8528s / 23106.2571 s